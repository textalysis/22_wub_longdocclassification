[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/lib64/python3.6/site-packages/h5py/__init__.py:39: UserWarning: h5py is running against HDF5 1.10.8 when it was built against 1.10.7, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
ECtHR_ToBERT_256_25_4
----------
Epoch 1/40
time = 932.52 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.20010861498010052 micro_f1_score 0.7304946455889852 
 
time = 54.12 secondes

Val loss 0.16457779265818048 micro_f1_score 0.7566302652106084
 
----------
Epoch 2/40
time = 912.72 secondes

Train loss 0.1364933298883943 micro_f1_score 0.8221331064932961 
 
time = 52.32 secondes

Val loss 0.15628052973112122 micro_f1_score 0.777306059436511
 
----------
Epoch 3/40
time = 921.18 secondes

Train loss 0.11847368633659842 micro_f1_score 0.8519455487290688 
 
time = 46.78 secondes

Val loss 0.16438355577773736 micro_f1_score 0.7804143126177026
 
----------
Epoch 4/40
time = 880.46 secondes

Train loss 0.10575542732200643 micro_f1_score 0.8717376578873969 
 
time = 52.12 secondes

Val loss 0.15934415753991876 micro_f1_score 0.7867479055597867
 
----------
Epoch 5/40
time = 741.46 secondes

Train loss 0.09436865880464514 micro_f1_score 0.8873741776967583 
 
time = 53.14 secondes

Val loss 0.1632078078071602 micro_f1_score 0.7914601601219978
 
----------
Epoch 6/40
time = 764.35 secondes

Train loss 0.08527079078343672 micro_f1_score 0.9017363851617995 
 
time = 54.25 secondes

Val loss 0.17744694894454519 micro_f1_score 0.7828677839851025
 
----------
Epoch 7/40
time = 825.04 secondes

Train loss 0.07575376666536941 micro_f1_score 0.912992125984252 
 
time = 52.34 secondes

Val loss 0.18107550713371057 micro_f1_score 0.7906976744186046
 
----------
Epoch 8/40
time = 736.76 secondes

Train loss 0.06831450832604959 micro_f1_score 0.9230347420782578 
 
time = 52.89 secondes

Val loss 0.1945515655469699 micro_f1_score 0.7836644591611479
 
----------
Epoch 9/40
time = 726.52 secondes

Train loss 0.06126097197233288 micro_f1_score 0.9321848081440878 
 
time = 52.76 secondes

Val loss 0.19523186303797316 micro_f1_score 0.7972433804860356
 
----------
Epoch 10/40
time = 727.45 secondes

Train loss 0.05475427679159586 micro_f1_score 0.9410618986404893 
 
time = 52.98 secondes

Val loss 0.20649079031875875 micro_f1_score 0.7965367965367965
 
----------
Epoch 11/40
time = 732.28 secondes

Train loss 0.048270933044579314 micro_f1_score 0.949264391910252 
 
time = 51.84 secondes

Val loss 0.21670839379801124 micro_f1_score 0.7878571428571428
 
----------
Epoch 12/40
time = 733.90 secondes

Train loss 0.043124553397914545 micro_f1_score 0.9548991521814875 
 
time = 52.86 secondes

Val loss 0.21778375576021242 micro_f1_score 0.8018498754891499
 
----------
Epoch 13/40
time = 753.66 secondes

Train loss 0.03615743065890562 micro_f1_score 0.9620214040103543 
 
time = 53.01 secondes

Val loss 0.2261857747665194 micro_f1_score 0.8056239015817223
 
----------
Epoch 14/40
time = 757.16 secondes

Train loss 0.031930604166569405 micro_f1_score 0.9669516986364687 
 
time = 52.55 secondes

Val loss 0.2456537271376516 micro_f1_score 0.7925340990667624
 
----------
Epoch 15/40
time = 934.44 secondes

Train loss 0.02706282820294586 micro_f1_score 0.9724312701581939 
 
time = 40.85 secondes

Val loss 0.2687316412930606 micro_f1_score 0.7931769722814499
 
----------
Epoch 16/40
time = 1948.94 secondes

Train loss 0.02323817718508737 micro_f1_score 0.9753304641869044 
 
time = 40.47 secondes

Val loss 0.2751807585114338 micro_f1_score 0.7958077340079509
 
----------
Epoch 17/40
time = 1717.86 secondes

Train loss 0.01949645061636352 micro_f1_score 0.9796027911969941 
 
time = 42.30 secondes

Val loss 0.28776143130953197 micro_f1_score 0.7946365561044461
 
----------
Epoch 18/40
time = 1278.34 secondes

Train loss 0.017522526610310205 micro_f1_score 0.9826213443576788 
 
time = 45.48 secondes

Val loss 0.3043173170480572 micro_f1_score 0.7902608695652175
 
----------
Epoch 19/40
