[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_1
----------
Epoch 1/40
time = 51.01 secondes

Train loss 0.6484671542138765 accuracy 0.5988371968269348 macro_avg {'precision': 0.5110780423280423, 'recall': 0.5065341417031028, 'f1-score': 0.48207592457002096, 'support': 516} weighted_avg {'precision': 0.5468878173577786, 'recall': 0.5988372093023255, 'f1-score': 0.5497498120475199, 'support': 516}
 
time = 1.55 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.5683221146464348 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 44.12 secondes

Train loss 0.4316922918413625 accuracy 0.7926356792449951 macro_avg {'precision': 0.7960464015151515, 'recall': 0.743908782081498, 'f1-score': 0.757253338140314, 'support': 516} weighted_avg {'precision': 0.7941244751291989, 'recall': 0.7926356589147286, 'f1-score': 0.7827573460081663, 'support': 516}
 
time = 1.46 secondes

Val loss 0.449489651247859 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 3/40
time = 43.89 secondes

Train loss 0.2424559767047564 accuracy 0.9089147448539734 macro_avg {'precision': 0.9004681950274459, 'recall': 0.903182549615591, 'f1-score': 0.9017879198979488, 'support': 516} weighted_avg {'precision': 0.9092873698728202, 'recall': 0.9089147286821705, 'f1-score': 0.909068544699096, 'support': 516}
 
time = 1.55 secondes

Val loss 0.4411683026701212 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 44.17 secondes

Train loss 0.1529593360469197 accuracy 0.9457364082336426 macro_avg {'precision': 0.9422062545929616, 'recall': 0.9401362092225671, 'f1-score': 0.9411534701857283, 'support': 516} weighted_avg {'precision': 0.9456397168615254, 'recall': 0.9457364341085271, 'f1-score': 0.9456727818318217, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5802359767258167 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 45.27 secondes

Train loss 0.12945584704478583 accuracy 0.9554263353347778 macro_avg {'precision': 0.9496527777777778, 'recall': 0.9546592331323245, 'f1-score': 0.9520459660507421, 'support': 516} weighted_avg {'precision': 0.9558637489233419, 'recall': 0.9554263565891473, 'f1-score': 0.9555497285066072, 'support': 516}
 
time = 1.55 secondes

Val loss 0.7515546977519989 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 6/40
time = 44.18 secondes

Train loss 0.21710896671213437 accuracy 0.9379844665527344 macro_avg {'precision': 0.9294591283038685, 'recall': 0.9386733416770964, 'f1-score': 0.933641975308642, 'support': 516} weighted_avg {'precision': 0.939382097406025, 'recall': 0.937984496124031, 'f1-score': 0.9383134749736817, 'support': 516}
 
time = 1.55 secondes

Val loss 0.5084730144590139 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 7/40
time = 44.01 secondes

Train loss 0.10898110413020759 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9283211827278137 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 8/40
time = 44.55 secondes

Train loss 0.11305292753968388 accuracy 0.9709302186965942 macro_avg {'precision': 0.9634177215189874, 'recall': 0.9760496074638754, 'f1-score': 0.9689922480620154, 'support': 516} weighted_avg {'precision': 0.9726140712393289, 'recall': 0.9709302325581395, 'f1-score': 0.9711255333213148, 'support': 516}
 
time = 1.58 secondes

Val loss 0.7843436300754547 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 9/40
time = 44.00 secondes

Train loss 0.05085022477997524 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8264092803001404 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 44.06 secondes

Train loss 0.158899184715031 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9702771045267582 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 11/40
time = 44.35 secondes

Train loss 0.25782609717377153 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 1.57 secondes

Val loss 1.470630556344986 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 12/40
time = 43.90 secondes

Train loss 0.1689814520950401 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.55 secondes

Val loss 1.090615674853325 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 13/40
time = 43.92 secondes

Train loss 0.09597611122157876 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 1.59 secondes

Val loss 1.825234591960907 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 45.56 secondes

Train loss 0.2778898612613733 accuracy 0.9496123790740967 macro_avg {'precision': 0.9508524573771311, 'recall': 0.9397136030427644, 'f1-score': 0.9448246364414028, 'support': 516} weighted_avg {'precision': 0.9497654962213129, 'recall': 0.9496124031007752, 'f1-score': 0.9492974184521322, 'support': 516}
 
time = 1.56 secondes

Val loss 1.219543695449829 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 15/40
time = 44.01 secondes

Train loss 0.34743856010380003 accuracy 0.9282945990562439 macro_avg {'precision': 0.9255952380952381, 'recall': 0.9183801180046487, 'f1-score': 0.9217717317817705, 'support': 516} weighted_avg {'precision': 0.9280523255813954, 'recall': 0.9282945736434108, 'f1-score': 0.9279881314083002, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2637725472450256 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 43.99 secondes

Train loss 0.11533800290657603 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.45 secondes

Val loss 0.7785346657037735 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 17/40
time = 44.31 secondes

Train loss 0.0562764307198284 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5886543691158295 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 18/40
time = 43.99 secondes

Train loss 0.047533505874911716 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.55 secondes

Val loss 2.50537246465683 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 19/40
time = 44.07 secondes

Train loss 0.19089577305765654 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 1.58 secondes

Val loss 1.4012825787067413 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 20/40
time = 44.89 secondes

Train loss 0.11779450446413124 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.55 secondes

Val loss 1.0541197881102562 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 21/40
time = 44.36 secondes

Train loss 0.3096776276105436 accuracy 0.9418604373931885 macro_avg {'precision': 0.9308755760368663, 'recall': 0.9544072948328268, 'f1-score': 0.9389859368102416, 'support': 516} weighted_avg {'precision': 0.9498981888329225, 'recall': 0.9418604651162791, 'f1-score': 0.9426304280553963, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2989709228277206 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 22/40
time = 44.08 secondes

Train loss 0.037103814627643616 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4808869734406471 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 23/40
time = 43.88 secondes

Train loss 0.10719815791217667 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.57 secondes

Val loss 1.588595598936081 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 45.78 secondes

Train loss 0.0005445388616697693 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.1775003522634506 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 25/40
time = 43.48 secondes

Train loss 0.03956041625122342 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.4926774203777313 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 26/40
time = 44.06 secondes

Train loss 0.039494372762750245 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.47 secondes

Val loss 0.9543888717889786 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 27/40
time = 44.02 secondes

Train loss 0.20654129833300514 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1127036213874817 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 28/40
time = 44.38 secondes

Train loss 0.08597790196566193 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.56 secondes

Val loss 0.9251856654882431 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 29/40
time = 43.94 secondes

Train loss 0.05596733741527494 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.55 secondes

Val loss 1.495246946811676 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 30/40
time = 44.32 secondes

Train loss 0.0015362289687442226 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2893417179584503 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 31/40
time = 43.91 secondes

Train loss 0.032513707035060645 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5993940383195877 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 32/40
time = 45.50 secondes

Train loss 0.0002029587110772616 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0544578731060028 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 43.52 secondes

Train loss 0.029213577178201045 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.55 secondes

Val loss 1.403256580233574 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 34/40
time = 44.14 secondes

Train loss 0.009672270263598131 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1019640415906906 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 35/40
time = 44.15 secondes

Train loss 0.06142923340093782 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.55 secondes

Val loss 1.8624211996793747 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 36/40
time = 44.10 secondes

Train loss 0.08137650245396688 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.55 secondes

Val loss 1.3643712997436523 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 43.92 secondes

Train loss 0.00014526665957722193 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.829428106546402 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 38/40
time = 45.52 secondes

Train loss 0.017648513299002043 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4478777945041656 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 39/40
time = 43.93 secondes

Train loss 7.32476613793e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.1653912216424942 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 40/40
time = 43.80 secondes

Train loss 6.468607578867567e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0635102614760399 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 26 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}

average train time 44.42560328841209

average val time 1.5440983295440673
 
time = 1.87 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.975, 'recall': 0.962962962962963, 'f1-score': 0.9679487179487178, 'support': 65} weighted_avg {'precision': 0.9707692307692308, 'recall': 0.9692307692307692, 'f1-score': 0.969033530571992, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 38.10 secondes

Train loss 0.6118795040881995 accuracy 0.6705426573753357 macro_avg {'precision': 0.8036640898019697, 'recall': 0.5466085854070836, 'f1-score': 0.4844730717694351, 'support': 516} weighted_avg {'precision': 0.7641175490314387, 'recall': 0.6705426356589147, 'f1-score': 0.5697049365188096, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5209976881742477 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 37.85 secondes

Train loss 0.48955667289820587 accuracy 0.7965116500854492 macro_avg {'precision': 0.781183155080214, 'recall': 0.7734912146676852, 'f1-score': 0.7768965645035764, 'support': 516} weighted_avg {'precision': 0.7944553693570452, 'recall': 0.7965116279069767, 'f1-score': 0.7951013945903923, 'support': 516}
 
time = 1.08 secondes

Val loss 0.595069408416748 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 3/40
time = 37.81 secondes

Train loss 0.30316798772775766 accuracy 0.8895348906517029 macro_avg {'precision': 0.880791788856305, 'recall': 0.8799067015587667, 'f1-score': 0.8803451488362822, 'support': 516} weighted_avg {'precision': 0.8894134518478103, 'recall': 0.8895348837209303, 'f1-score': 0.889470619840618, 'support': 516}
 
time = 1.19 secondes

Val loss 0.5372880846261978 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 4/40
time = 37.85 secondes

Train loss 0.20889812222484386 accuracy 0.9224806427955627 macro_avg {'precision': 0.9218768328445748, 'recall': 0.9092046876777791, 'f1-score': 0.914900634946813, 'support': 516} weighted_avg {'precision': 0.9223933256041282, 'recall': 0.9224806201550387, 'f1-score': 0.9218899719569951, 'support': 516}
 
time = 1.20 secondes

Val loss 0.4207959845662117 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 5/40
time = 37.82 secondes

Train loss 0.18637056183069944 accuracy 0.9302325248718262 macro_avg {'precision': 0.9262541229754344, 'recall': 0.9222079547486306, 'f1-score': 0.9241610190250674, 'support': 516} weighted_avg {'precision': 0.930020374930783, 'recall': 0.9302325581395349, 'f1-score': 0.9300662146021522, 'support': 516}
 
time = 1.21 secondes

Val loss 0.6602529734373093 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 6/40
time = 37.79 secondes

Train loss 0.14330859389156103 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.21 secondes

Val loss 1.461461827158928 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 7/40
time = 37.87 secondes

Train loss 0.18790496054641675 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4476582985371351 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 8/40
time = 37.69 secondes

Train loss 0.09559408770733033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.26 secondes

Val loss 0.5406880658119917 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 9/40
time = 37.75 secondes

Train loss 0.1151893291142628 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4370921105146408 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 10/40
time = 37.75 secondes

Train loss 0.07336072456867744 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 1.21 secondes

Val loss 0.702195331454277 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 11/40
time = 37.78 secondes

Train loss 0.3720530061594521 accuracy 0.9224806427955627 macro_avg {'precision': 0.9147160692710431, 'recall': 0.9184370072980836, 'f1-score': 0.9165089073345956, 'support': 516} weighted_avg {'precision': 0.9229441754316953, 'recall': 0.9224806201550387, 'f1-score': 0.9226537132802691, 'support': 516}
 
time = 1.20 secondes

Val loss 0.8342920988798141 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 12/40
time = 37.75 secondes

Train loss 0.07604224078717049 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.20 secondes

Val loss 1.607848584651947 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 37.72 secondes

Train loss 0.06278472877756665 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.12 secondes

Val loss 1.1636684089899063 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 37.88 secondes

Train loss 0.0886974026860006 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0803441554307938 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 15/40
time = 37.73 secondes

Train loss 0.18989273916249108 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1421115472912788 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 16/40
time = 37.75 secondes

Train loss 0.134410434301103 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 1.20 secondes

Val loss 0.840247965825256 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 17/40
time = 37.81 secondes

Train loss 0.2334456879268118 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.15 secondes

Val loss 1.9791456758975983 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 18/40
time = 37.81 secondes

Train loss 0.3454848953829655 accuracy 0.9321705102920532 macro_avg {'precision': 0.9218514328808447, 'recall': 0.9364221510654552, 'f1-score': 0.9279418747082364, 'support': 516} weighted_avg {'precision': 0.9354191512621743, 'recall': 0.9321705426356589, 'f1-score': 0.9327456414737882, 'support': 516}
 
time = 1.21 secondes

Val loss 1.0730529874563217 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 37.80 secondes

Train loss 0.5731687560927998 accuracy 0.893410861492157 macro_avg {'precision': 0.8810267995296157, 'recall': 0.9002568145246493, 'f1-score': 0.887839829902265, 'support': 516} weighted_avg {'precision': 0.901010158075819, 'recall': 0.8934108527131783, 'f1-score': 0.8947188319818274, 'support': 516}
 
time = 1.20 secondes

Val loss 1.6587252020835876 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 20/40
time = 37.78 secondes

Train loss 0.01211984952290853 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.20 secondes

Val loss 1.930421382188797 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 21/40
time = 37.77 secondes

Train loss 0.045483751377270724 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.21 secondes

Val loss 1.6416117027401924 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 22/40
time = 37.76 secondes

Train loss 0.29783655986389157 accuracy 0.9476743936538696 macro_avg {'precision': 0.9601904164051056, 'recall': 0.9289615265835541, 'f1-score': 0.9415523121908653, 'support': 516} weighted_avg {'precision': 0.9509337930318529, 'recall': 0.9476744186046512, 'f1-score': 0.9467579356085755, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1994608283857815 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 23/40
time = 37.74 secondes

Train loss 0.14321513218932191 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.13 secondes

Val loss 2.326024055480957 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 24/40
time = 37.84 secondes

Train loss 0.13996493708779753 accuracy 0.9689922332763672 macro_avg {'precision': 0.9723513824308785, 'recall': 0.9606813711945126, 'f1-score': 0.9660459301177864, 'support': 516} weighted_avg {'precision': 0.9694069560087888, 'recall': 0.9689922480620154, 'f1-score': 0.9687984113551584, 'support': 516}
 
time = 1.21 secondes

Val loss 1.151353769004345 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 25/40
time = 37.77 secondes

Train loss 0.07647180854110047 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 1.20 secondes

Val loss 1.5654735565185547 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 26/40
time = 37.81 secondes

Train loss 0.06018229337959466 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.54 secondes

Val loss 2.059539884328842 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 27/40
time = 37.69 secondes

Train loss 0.007575753189898519 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 1.2836417332291603 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 28/40
time = 37.66 secondes

Train loss 0.013093511755648775 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.21 secondes

Val loss 1.4585321545600891 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 37.74 secondes

Train loss 0.002264237272108651 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.11 secondes

Val loss 0.7938464358448982 accuracy 0.890625 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}
 
----------
Epoch 30/40
time = 37.75 secondes

Train loss 0.03174836540512677 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.20 secondes

Val loss 2.0029105246067047 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 31/40
time = 37.73 secondes

Train loss 0.0012360489841243675 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.2074059695005417 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 32/40
time = 37.75 secondes

Train loss 0.02636931425667805 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.21 secondes

Val loss 1.9673902988433838 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 33/40
time = 37.83 secondes

Train loss 0.007728801291677607 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.21 secondes

Val loss 1.282075360417366 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 34/40
time = 37.73 secondes

Train loss 0.07562345547392563 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.21 secondes

Val loss 1.3651388138532639 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 35/40
time = 37.86 secondes

Train loss 0.030789600984655517 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4954889714717865 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 37.92 secondes

Train loss 0.007754079878698879 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 2.5611753165721893 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 37/40
time = 37.74 secondes

Train loss 0.028849033851160624 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4328311383724213 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 38/40
time = 37.83 secondes

Train loss 0.0003410180462665404 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4899351298809052 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 37.80 secondes

Train loss 9.842868486444014e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4465883821249008 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 40/40
time = 37.73 secondes

Train loss 9.114195045461229e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4567785859107971 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 29 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}

average train time 37.78849007487297

average val time 1.206836348772049
 
time = 1.33 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_1
----------
Epoch 1/40
time = 110.88 secondes

Train loss 0.6208415446859418 accuracy 0.6744186282157898 macro_avg {'precision': 0.6623230428108478, 'recall': 0.5773450579458088, 'f1-score': 0.558974358974359, 'support': 516} weighted_avg {'precision': 0.6667727054567667, 'recall': 0.6744186046511628, 'f1-score': 0.6210693699065791, 'support': 516}
 
time = 3.19 secondes

Val loss 0.574383407831192 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 2/40
time = 109.91 secondes

Train loss 0.3958620198748328 accuracy 0.8449612259864807 macro_avg {'precision': 0.8415011809990377, 'recall': 0.81725533540302, 'f1-score': 0.8265779391006252, 'support': 516} weighted_avg {'precision': 0.8440338017318607, 'recall': 0.8449612403100775, 'f1-score': 0.8421162055990907, 'support': 516}
 
time = 3.28 secondes

Val loss 0.4010474197566509 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 3/40
time = 109.93 secondes

Train loss 0.3053324529618928 accuracy 0.8759689927101135 macro_avg {'precision': 0.8691565421728913, 'recall': 0.8600360840661216, 'f1-score': 0.8641837204711456, 'support': 516} weighted_avg {'precision': 0.8751279490289051, 'recall': 0.875968992248062, 'f1-score': 0.8751936454206333, 'support': 516}
 
time = 3.27 secondes

Val loss 0.38428428024053574 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 4/40
time = 109.08 secondes

Train loss 0.2765027183023366 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 3.26 secondes

Val loss 0.7334373593330383 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 110.76 secondes

Train loss 0.22509805762180776 accuracy 0.9147287011146545 macro_avg {'precision': 0.9085000408263249, 'recall': 0.9065877801797702, 'f1-score': 0.9075268817204302, 'support': 516} weighted_avg {'precision': 0.9145580344624819, 'recall': 0.9147286821705426, 'f1-score': 0.9146286571642912, 'support': 516}
 
time = 3.25 secondes

Val loss 0.7033235356211662 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 6/40
time = 110.85 secondes

Train loss 0.15903478742323138 accuracy 0.9418604373931885 macro_avg {'precision': 0.944808641871282, 'recall': 0.9290184158769891, 'f1-score': 0.9360119047619048, 'support': 516} weighted_avg {'precision': 0.9423460471700442, 'recall': 0.9418604651162791, 'f1-score': 0.9413355943152454, 'support': 516}
 
time = 3.25 secondes

Val loss 0.49331944435834885 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 7/40
time = 110.33 secondes

Train loss 0.12874467689261743 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 3.25 secondes

Val loss 0.8076917231082916 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 8/40
time = 108.78 secondes

Train loss 0.33719487134790554 accuracy 0.9031007885932922 macro_avg {'precision': 0.8929307452671938, 'recall': 0.8997773190514117, 'f1-score': 0.896093435360451, 'support': 516} weighted_avg {'precision': 0.9043922075654308, 'recall': 0.9031007751937985, 'f1-score': 0.9035191238405655, 'support': 516}
 
time = 3.32 secondes

Val loss 0.5185783058404922 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 9/40
time = 111.68 secondes

Train loss 0.11759842450335396 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 3.27 secondes

Val loss 1.3767000436782837 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 110.36 secondes

Train loss 0.14430443289915496 accuracy 0.9651162624359131 macro_avg {'precision': 0.9724383422323926, 'recall': 0.9530256977065488, 'f1-score': 0.9615072194685277, 'support': 516} weighted_avg {'precision': 0.9664628653985261, 'recall': 0.9651162790697675, 'f1-score': 0.9647508046797686, 'support': 516}
 
time = 3.27 secondes

Val loss 1.8720239400863647 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 11/40
time = 110.00 secondes

Train loss 0.12741439464452647 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 3.22 secondes

Val loss 0.9112781442236155 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 12/40
time = 109.55 secondes

Train loss 0.22378833774674797 accuracy 0.9515503644943237 macro_avg {'precision': 0.9511904761904761, 'recall': 0.9435414397867464, 'f1-score': 0.9471430620147098, 'support': 516} weighted_avg {'precision': 0.9515180878552972, 'recall': 0.9515503875968992, 'f1-score': 0.9513433320326352, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4541483521461487 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 13/40
time = 111.18 secondes

Train loss 0.08695977868399385 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 3.38 secondes

Val loss 1.3499275147914886 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 14/40
time = 109.51 secondes

Train loss 0.04540810167831792 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.28 secondes

Val loss 1.129255250096321 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 109.35 secondes

Train loss 0.10000095951854195 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 3.24 secondes

Val loss 1.1267386078834534 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 16/40
time = 109.07 secondes

Train loss 0.1841409852671804 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 3.25 secondes

Val loss 1.2525547221302986 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 17/40
time = 111.61 secondes

Train loss 0.14371543455865432 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 3.25 secondes

Val loss 1.8017287254333496 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 110.01 secondes

Train loss 0.026182726556505782 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 3.17 secondes

Val loss 2.1328561305999756 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 19/40
time = 109.64 secondes

Train loss 0.05814073682422256 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 3.28 secondes

Val loss 1.7090198695659637 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 20/40
time = 111.29 secondes

Train loss 0.3225959445028848 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 3.34 secondes

Val loss 1.4081890285015106 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 21/40
time = 109.58 secondes

Train loss 0.18450812213510895 accuracy 0.9670542478561401 macro_avg {'precision': 0.9620949074074074, 'recall': 0.9672398940233733, 'f1-score': 0.9645557140375051, 'support': 516} weighted_avg {'precision': 0.9674299723657767, 'recall': 0.9670542635658915, 'f1-score': 0.9671454515048837, 'support': 516}
 
time = 3.34 secondes

Val loss 1.443152278661728 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 22/40
time = 109.29 secondes

Train loss 0.1166973254073651 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 3.29 secondes

Val loss 1.3189547210931778 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 23/40
time = 110.10 secondes

Train loss 0.03705972561764418 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.70 secondes

Val loss 0.9670058307237923 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 24/40
time = 108.54 secondes

Train loss 0.025352893767624417 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 3.23 secondes

Val loss 1.124589666724205 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 25/40
time = 111.11 secondes

Train loss 0.003198813354670578 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.26 secondes

Val loss 2.3936354517936707 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 26/40
time = 110.60 secondes

Train loss 0.4131214476651759 accuracy 0.9321705102920532 macro_avg {'precision': 0.9477564102564102, 'recall': 0.9087251922045414, 'f1-score': 0.9235804626640205, 'support': 516} weighted_avg {'precision': 0.9369074239713775, 'recall': 0.9321705426356589, 'f1-score': 0.9306312797505676, 'support': 516}
 
time = 3.22 secondes

Val loss 1.064063373953104 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 27/40
time = 110.08 secondes

Train loss 0.051691933078638445 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 2.3253433406352997 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 28/40
time = 109.66 secondes

Train loss 0.07212349785241355 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 3.28 secondes

Val loss 1.338636502623558 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 29/40
time = 109.71 secondes

Train loss 0.01786365759581906 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.81 secondes

Val loss 2.1446223855018616 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 30/40
time = 110.43 secondes

Train loss 0.03289659313811695 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 3.14 secondes

Val loss 2.208230972290039 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 31/40
time = 109.60 secondes

Train loss 0.12458896116379148 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 3.41 secondes

Val loss 1.610340178012848 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 32/40
time = 110.46 secondes

Train loss 0.08795193974087438 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 3.23 secondes

Val loss 1.4975502341985703 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 33/40
time = 110.99 secondes

Train loss 0.011843261595596701 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.22 secondes

Val loss 1.7452628016471863 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 109.94 secondes

Train loss 0.05261105974116645 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 1.709677278995514 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 35/40
time = 111.28 secondes

Train loss 0.00017651771265787608 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.22 secondes

Val loss 1.3155423551797867 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 36/40
time = 110.01 secondes

Train loss 0.08733464148870994 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 3.22 secondes

Val loss 1.668299823999405 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 37/40
time = 110.29 secondes

Train loss 0.0001407871130857419 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.26 secondes

Val loss 2.0013616383075714 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 38/40
time = 111.20 secondes

Train loss 0.05291752666292296 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 3.27 secondes

Val loss 2.1024787425994873 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 39/40
time = 109.91 secondes

Train loss 0.00010726286101006818 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.24 secondes

Val loss 1.9849089980125427 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 40/40
time = 110.32 secondes

Train loss 0.00011339108084829411 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.27 secondes

Val loss 1.9019729495048523 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 23 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 110.17144976854324

average val time 3.2268829464912416
 
time = 3.95 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9366471734892787, 'recall': 0.9366471734892787, 'f1-score': 0.9366471734892787, 'support': 65} weighted_avg {'precision': 0.9384615384615385, 'recall': 0.9384615384615385, 'f1-score': 0.9384615384615385, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 75.91 GiB already allocated; 15.62 MiB free; 77.17 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 74.19 GiB already allocated; 333.62 MiB free; 76.86 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 835.62 MiB free; 76.37 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_1
----------
Epoch 1/40
time = 34.11 secondes

Train loss 0.6567783157030741 accuracy 0.5968992114067078 macro_avg {'precision': 0.506608419822477, 'recall': 0.503860344911659, 'f1-score': 0.4783318751822689, 'support': 516} weighted_avg {'precision': 0.5432406892730166, 'recall': 0.5968992248062015, 'f1-score': 0.5467731908188479, 'support': 516}
 
time = 1.72 secondes

Val loss 0.6483345180749893 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 30.15 secondes

Train loss 0.4736546386371959 accuracy 0.7674418687820435 macro_avg {'precision': 0.7691305157326382, 'recall': 0.7114575036978041, 'f1-score': 0.7233491198284336, 'support': 516} weighted_avg {'precision': 0.768242408147497, 'recall': 0.7674418604651163, 'f1-score': 0.7537431449275062, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4845489114522934 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 3/40
time = 30.09 secondes

Train loss 0.4114030446067001 accuracy 0.8217054009437561 macro_avg {'precision': 0.8068540362118344, 'recall': 0.8082505729564553, 'f1-score': 0.8075376232485729, 'support': 516} weighted_avg {'precision': 0.8221359014332488, 'recall': 0.8217054263565892, 'f1-score': 0.8219078235438464, 'support': 516}
 
time = 1.51 secondes

Val loss 0.4701610952615738 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 4/40
time = 30.33 secondes

Train loss 0.23988865823908287 accuracy 0.9089147448539734 macro_avg {'precision': 0.9011092371562014, 'recall': 0.9020285096630528, 'f1-score': 0.9015646879756469, 'support': 516} weighted_avg {'precision': 0.90902623570397, 'recall': 0.9089147286821705, 'f1-score': 0.9089668566304437, 'support': 516}
 
time = 1.54 secondes

Val loss 0.5063801445066929 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 5/40
time = 30.12 secondes

Train loss 0.19853529572543321 accuracy 0.9341084957122803 macro_avg {'precision': 0.9374523264683448, 'recall': 0.9194772686637518, 'f1-score': 0.9272914145516635, 'support': 516} weighted_avg {'precision': 0.9347234787339092, 'recall': 0.9341085271317829, 'f1-score': 0.9334181866173404, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6985029019415379 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 6/40
time = 29.68 secondes

Train loss 0.13120987192219633 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.53 secondes

Val loss 0.89257001131773 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 7/40
time = 30.08 secondes

Train loss 0.25928406263913284 accuracy 0.9244186282157898 macro_avg {'precision': 0.912962962962963, 'recall': 0.9349592835199845, 'f1-score': 0.9206113134006872, 'support': 516} weighted_avg {'precision': 0.9323284524834912, 'recall': 0.9244186046511628, 'f1-score': 0.9253956970959751, 'support': 516}
 
time = 1.52 secondes

Val loss 1.392895758152008 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 8/40
time = 30.36 secondes

Train loss 0.16238292923310038 accuracy 0.9476743936538696 macro_avg {'precision': 0.9520348837209303, 'recall': 0.9347317263462445, 'f1-score': 0.9423361078114459, 'support': 516} weighted_avg {'precision': 0.9484349648458626, 'recall': 0.9476744186046512, 'f1-score': 0.9471643889110329, 'support': 516}
 
time = 1.16 secondes

Val loss 1.112002745270729 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 9/40
time = 29.99 secondes

Train loss 0.17208194819095574 accuracy 0.9515503644943237 macro_avg {'precision': 0.9523801608935576, 'recall': 0.9423873998342083, 'f1-score': 0.9470127949723769, 'support': 516} weighted_avg {'precision': 0.9516437370927733, 'recall': 0.9515503875968992, 'f1-score': 0.951279935056365, 'support': 516}
 
time = 1.54 secondes

Val loss 1.9113911390304565 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 10/40
time = 30.00 secondes

Train loss 0.12845719239681563 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.44 secondes

Val loss 1.2405556738376617 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 11/40
time = 30.26 secondes

Train loss 0.12190856214235254 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.56 secondes

Val loss 1.4983333051204681 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 12/40
time = 30.20 secondes

Train loss 0.3027792275860327 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6353834420442581 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 13/40
time = 30.58 secondes

Train loss 0.13359660844787757 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.51 secondes

Val loss 1.317705549299717 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 14/40
time = 30.22 secondes

Train loss 0.35118401451803616 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6398965418338776 accuracy 0.75 macro_avg {'precision': 0.7658730158730158, 'recall': 0.771255060728745, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.7896825396825398, 'recall': 0.75, 'f1-score': 0.7512218963831867, 'support': 64}
 
----------
Epoch 15/40
time = 30.09 secondes

Train loss 0.2099811704432465 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0730313323438168 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 16/40
time = 29.83 secondes

Train loss 0.1772331207202197 accuracy 0.9496123790740967 macro_avg {'precision': 0.9395900755124056, 'recall': 0.9570242023308356, 'f1-score': 0.9466289005935427, 'support': 516} weighted_avg {'precision': 0.9535427276452338, 'recall': 0.9496124031007752, 'f1-score': 0.9501015018724527, 'support': 516}
 
time = 1.52 secondes

Val loss 0.8848967030644417 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 30.43 secondes

Train loss 0.12311049633894017 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.54 secondes

Val loss 1.6023304760456085 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 18/40
time = 30.37 secondes

Train loss 0.1917411569946015 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6791450828313828 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 19/40
time = 30.56 secondes

Train loss 0.12897297652649065 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.25 secondes

Val loss 2.6572521924972534 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 20/40
time = 30.00 secondes

Train loss 0.060254706360865384 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5116469860076904 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 21/40
time = 30.25 secondes

Train loss 0.06364064671145046 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.53 secondes

Val loss 2.110848158597946 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 30.22 secondes

Train loss 0.12491783101281864 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.52 secondes

Val loss 1.531773641705513 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 23/40
time = 30.21 secondes

Train loss 0.012602947508143685 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 2.040704756975174 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 30.00 secondes

Train loss 0.05516036900812513 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.7398687303066254 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 25/40
time = 29.99 secondes

Train loss 0.06968361505344299 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4831435531377792 accuracy 0.65625 macro_avg {'precision': 0.6916666666666667, 'recall': 0.6862348178137652, 'f1-score': 0.6559139784946237, 'support': 64} weighted_avg {'precision': 0.7182291666666667, 'recall': 0.65625, 'f1-score': 0.6538978494623656, 'support': 64}
 
----------
Epoch 26/40
time = 30.16 secondes

Train loss 0.26840145522785885 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 1.51 secondes

Val loss 2.416386902332306 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 27/40
time = 30.61 secondes

Train loss 0.1729861014719063 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.53 secondes

Val loss 1.3513858765363693 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 28/40
time = 30.34 secondes

Train loss 0.09652199355729284 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.52 secondes

Val loss 1.4449278712272644 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 29/40
time = 30.13 secondes

Train loss 0.06417314555338552 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6720838844776154 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 30/40
time = 30.15 secondes

Train loss 0.027461881629609376 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1987587958574295 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 31/40
time = 30.22 secondes

Train loss 0.019796533098115382 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.50 secondes

Val loss 1.758107453584671 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 32/40
time = 30.60 secondes

Train loss 0.0010739933647776277 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.749803751707077 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 33/40
time = 30.48 secondes

Train loss 0.0030313041213296606 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.52 secondes

Val loss 1.9742971658706665 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 34/40
time = 30.12 secondes

Train loss 0.04233543748920387 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6585697829723358 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 30.02 secondes

Train loss 0.03061917360294804 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9593395292758942 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 36/40
time = 30.42 secondes

Train loss 0.00010399735522999738 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5130765438079834 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 29.91 secondes

Train loss 0.025205528952056105 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 1.288802832365036 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 38/40
time = 30.42 secondes

Train loss 0.0004712519331598852 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5494403094053268 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 39/40
time = 29.81 secondes

Train loss 0.011907795049685801 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5029142796993256 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 40/40
time = 29.96 secondes

Train loss 6.596711186416955e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.487855225801468 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 16 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 30.286575692892075

average val time 1.5072179853916168
 
time = 1.77 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_1
----------
Epoch 1/40
time = 42.42 secondes

Train loss 0.6250356182907567 accuracy 0.6705426573753357 macro_avg {'precision': 0.6828752642706131, 'recall': 0.5604570648375404, 'f1-score': 0.5244497452022119, 'support': 516} weighted_avg {'precision': 0.6788026287755872, 'recall': 0.6705426356589147, 'f1-score': 0.5969853761282671, 'support': 516}
 
time = 1.89 secondes

Val loss 0.6419084966182709 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 2/40
time = 39.83 secondes

Train loss 0.42234978328148526 accuracy 0.815891444683075 macro_avg {'precision': 0.8018849206349206, 'recall': 0.7967670627245096, 'f1-score': 0.7991436356558972, 'support': 516} weighted_avg {'precision': 0.8146344745908699, 'recall': 0.8158914728682171, 'f1-score': 0.8151046617240141, 'support': 516}
 
time = 1.70 secondes

Val loss 0.5241179391741753 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 3/40
time = 39.82 secondes

Train loss 0.23846285417675972 accuracy 0.9050387740135193 macro_avg {'precision': 0.897605083088954, 'recall': 0.8966809160801652, 'f1-score': 0.8971388121575057, 'support': 516} weighted_avg {'precision': 0.9049355141815757, 'recall': 0.9050387596899225, 'f1-score': 0.9049835153015839, 'support': 516}
 
time = 1.70 secondes

Val loss 0.6524151861667633 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 40.28 secondes

Train loss 0.2745478278533979 accuracy 0.9069767594337463 macro_avg {'precision': 0.9153321706040907, 'recall': 0.883198153536076, 'f1-score': 0.8956504154097642, 'support': 516} weighted_avg {'precision': 0.9093398950921601, 'recall': 0.9069767441860465, 'f1-score': 0.9051112312111295, 'support': 516}
 
time = 1.73 secondes

Val loss 1.2008797079324722 accuracy 0.703125 macro_avg {'precision': 0.7232232232232232, 'recall': 0.7257085020242915, 'f1-score': 0.703052503052503, 'support': 64} weighted_avg {'precision': 0.7473410910910911, 'recall': 0.703125, 'f1-score': 0.7039224664224664, 'support': 64}
 
----------
Epoch 5/40
time = 40.08 secondes

Train loss 0.28934638497109216 accuracy 0.8798449635505676 macro_avg {'precision': 0.8689971808296415, 'recall': 0.8723079173642379, 'f1-score': 0.8705888063686229, 'support': 516} weighted_avg {'precision': 0.880492589921544, 'recall': 0.8798449612403101, 'f1-score': 0.8801132555844169, 'support': 516}
 
time = 1.70 secondes

Val loss 0.7955436855554581 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 39.92 secondes

Train loss 0.2750699918233846 accuracy 0.9418604373931885 macro_avg {'precision': 0.9309719704364803, 'recall': 0.9520992149277505, 'f1-score': 0.9387658227848101, 'support': 516} weighted_avg {'precision': 0.9481515953757185, 'recall': 0.9418604651162791, 'f1-score': 0.9425540918457462, 'support': 516}
 
time = 1.73 secondes

Val loss 1.878673255443573 accuracy 0.6875 macro_avg {'precision': 0.7678571428571428, 'recall': 0.6214574898785425, 'f1-score': 0.5994993742177722, 'support': 64} weighted_avg {'precision': 0.7477678571428572, 'recall': 0.6875, 'f1-score': 0.6346996245306633, 'support': 64}
 
----------
Epoch 7/40
time = 39.94 secondes

Train loss 0.28978963807193475 accuracy 0.9186046719551086 macro_avg {'precision': 0.9366415676313163, 'recall': 0.8911626546169725, 'f1-score': 0.9076104564909707, 'support': 516} weighted_avg {'precision': 0.9246731464232292, 'recall': 0.9186046511627907, 'f1-score': 0.9163811061729844, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1333815194666386 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 8/40
time = 39.81 secondes

Train loss 0.21337093538463567 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.72 secondes

Val loss 1.1721819788217545 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 9/40
time = 39.85 secondes

Train loss 0.0754368415981651 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.76 secondes

Val loss 2.0241373777389526 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 39.76 secondes

Train loss 0.08350599995262173 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.70 secondes

Val loss 2.0022046864032745 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 11/40
time = 39.74 secondes

Train loss 0.6093260882449668 accuracy 0.8798449635505676 macro_avg {'precision': 0.8726522222038029, 'recall': 0.8653836776490094, 'f1-score': 0.8687539999015408, 'support': 516} weighted_avg {'precision': 0.8791165826037017, 'recall': 0.8798449612403101, 'f1-score': 0.8792534433022423, 'support': 516}
 
time = 1.70 secondes

Val loss 2.404471606016159 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 12/40
time = 39.98 secondes

Train loss 0.3092179125083159 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.70 secondes

Val loss 1.633028268814087 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 13/40
time = 40.14 secondes

Train loss 0.13167497588526175 accuracy 0.9573643207550049 macro_avg {'precision': 0.9521224325412807, 'recall': 0.9561789899712303, 'f1-score': 0.9540798990340276, 'support': 516} weighted_avg {'precision': 0.9576772908490916, 'recall': 0.9573643410852714, 'f1-score': 0.957459542304148, 'support': 516}
 
time = 1.75 secondes

Val loss 1.672478049993515 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 14/40
time = 39.49 secondes

Train loss 0.4766141516663607 accuracy 0.9263566136360168 macro_avg {'precision': 0.9438772754280775, 'recall': 0.9007038018302098, 'f1-score': 0.9166609996599795, 'support': 516} weighted_avg {'precision': 0.9320299542286858, 'recall': 0.9263565891472868, 'f1-score': 0.9244835775417842, 'support': 516}
 
time = 1.69 secondes

Val loss 2.2375268042087555 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 15/40
time = 40.06 secondes

Train loss 0.05417639433069395 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.70 secondes

Val loss 2.018381655216217 accuracy 0.65625 macro_avg {'precision': 0.735632183908046, 'recall': 0.5829959514170041, 'f1-score': 0.5416666666666667, 'support': 64} weighted_avg {'precision': 0.7173132183908046, 'recall': 0.65625, 'f1-score': 0.5846354166666667, 'support': 64}
 
----------
Epoch 16/40
time = 40.26 secondes

Train loss 0.22395754638493987 accuracy 0.9670542478561401 macro_avg {'precision': 0.9613081897931741, 'recall': 0.9683939339759114, 'f1-score': 0.96463345307643, 'support': 516} weighted_avg {'precision': 0.9676827403847825, 'recall': 0.9670542635658915, 'f1-score': 0.9671797870727524, 'support': 516}
 
time = 1.74 secondes

Val loss 1.5666281580924988 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 17/40
time = 39.89 secondes

Train loss 0.11491544869810848 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.70 secondes

Val loss 1.9758648425340652 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 18/40
time = 40.18 secondes

Train loss 0.08700183632985996 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.70 secondes

Val loss 2.046614795923233 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 19/40
time = 39.76 secondes

Train loss 0.1932369931115924 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.71 secondes

Val loss 3.070172905921936 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 20/40
time = 39.60 secondes

Train loss 0.0617340229288278 accuracy 0.9844961166381836 macro_avg {'precision': 0.982185330809184, 'recall': 0.9843798254311396, 'f1-score': 0.9832641411520499, 'support': 516} weighted_avg {'precision': 0.9845631035446839, 'recall': 0.9844961240310077, 'f1-score': 0.9845137237864214, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9089334458112717 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 21/40
time = 39.93 secondes

Train loss 0.15142547276197796 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.68 secondes

Val loss 2.0300595462322235 accuracy 0.734375 macro_avg {'precision': 0.7292358803986712, 'recall': 0.7095141700404858, 'f1-score': 0.7142106645652745, 'support': 64} weighted_avg {'precision': 0.7320390365448506, 'recall': 0.734375, 'f1-score': 0.7284443131074336, 'support': 64}
 
----------
Epoch 22/40
time = 40.49 secondes

Train loss 0.025180068211105237 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.48 secondes

Val loss 2.083932340145111 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 23/40
time = 40.11 secondes

Train loss 0.10263278931729887 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.73 secondes

Val loss 2.140805721282959 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 24/40
time = 40.12 secondes

Train loss 0.09598735824847333 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.71 secondes

Val loss 1.9200657904148102 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 25/40
time = 39.90 secondes

Train loss 0.03630040398605739 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.71 secondes

Val loss 2.409125506877899 accuracy 0.6875 macro_avg {'precision': 0.7115384615384616, 'recall': 0.6336032388663968, 'f1-score': 0.6257309941520468, 'support': 64} weighted_avg {'precision': 0.7043269230769231, 'recall': 0.6875, 'f1-score': 0.6542397660818713, 'support': 64}
 
----------
Epoch 26/40
time = 40.28 secondes

Train loss 0.11398647684109164 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.70 secondes

Val loss 1.6969991028308868 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 27/40
time = 39.74 secondes

Train loss 0.03631438125398056 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.66 secondes

Val loss 2.0768578946590424 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 28/40
time = 40.67 secondes

Train loss 0.021378272981427002 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.70 secondes

Val loss 1.80338816344738 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 29/40
time = 42.45 secondes

Train loss 0.1305558308681198 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.80 secondes

Val loss 2.1289318799972534 accuracy 0.71875 macro_avg {'precision': 0.7198067632850241, 'recall': 0.6842105263157895, 'f1-score': 0.6883116883116883, 'support': 64} weighted_avg {'precision': 0.7193538647342995, 'recall': 0.71875, 'f1-score': 0.7065746753246753, 'support': 64}
 
----------
Epoch 30/40
time = 44.53 secondes

Train loss 0.03969892109528177 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.48625186085701 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 31/40
time = 44.24 secondes

Train loss 0.04418978331175987 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.05 secondes

Val loss 3.244371175765991 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 32/40
time = 47.47 secondes

Train loss 0.16101114878675257 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.06 secondes

Val loss 2.9142743349075317 accuracy 0.703125 macro_avg {'precision': 0.7040050062578223, 'recall': 0.6649797570850202, 'f1-score': 0.6673050615595076, 'support': 64} weighted_avg {'precision': 0.7036530037546934, 'recall': 0.703125, 'f1-score': 0.6877735978112176, 'support': 64}
 
----------
Epoch 33/40
time = 47.88 secondes

Train loss 2.1954282078006532e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9673337638378143 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 34/40
time = 46.76 secondes

Train loss 0.03560937149769884 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.08 secondes

Val loss 1.7495750486850739 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 35/40
time = 47.76 secondes

Train loss 0.006746183475942499 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.98 secondes

Val loss 2.435919463634491 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 36/40
time = 48.03 secondes

Train loss 3.4828258514718264e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9676964730024338 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 37/40
time = 45.91 secondes

Train loss 0.016310500819958124 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.06 secondes

Val loss 2.0135097205638885 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 38/40
time = 47.30 secondes

Train loss 0.00013055886004374108 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 2.496764689683914 accuracy 0.71875 macro_avg {'precision': 0.7136363636363636, 'recall': 0.6902834008097165, 'f1-score': 0.6945917285259808, 'support': 64} weighted_avg {'precision': 0.7161931818181818, 'recall': 0.71875, 'f1-score': 0.7106972428419936, 'support': 64}
 
----------
Epoch 39/40
time = 47.50 secondes

Train loss 3.786359433654456e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.07 secondes

Val loss 2.6430184841156006 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 40/40
time = 46.40 secondes

Train loss 4.828717950052427e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 2.6777721643447876 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 3 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}

average train time 41.95685896277428

average val time 1.7974827766418457
 
time = 2.38 secondes

test_accuracy 0.9230769276618958 macro_avg {'precision': 0.9303861788617886, 'recall': 0.9127680311890838, 'f1-score': 0.9193348225366097, 'support': 65} weighted_avg {'precision': 0.9256566604127581, 'recall': 0.9230769230769231, 'f1-score': 0.9222750443897131, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_1
----------
Epoch 1/40
time = 61.82 secondes

Train loss 0.6339394504373724 accuracy 0.6782945990562439 macro_avg {'precision': 0.7138382541720154, 'recall': 0.5676901321457016, 'f1-score': 0.5327310814349306, 'support': 516} weighted_avg {'precision': 0.7022087550128867, 'recall': 0.6782945736434108, 'f1-score': 0.6045019699543897, 'support': 516}
 
time = 2.62 secondes

Val loss 0.4559163898229599 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 58.22 secondes

Train loss 0.4738170120752219 accuracy 0.786821722984314 macro_avg {'precision': 0.7700048074532102, 'recall': 0.7647383905206182, 'f1-score': 0.7671441933737015, 'support': 516} weighted_avg {'precision': 0.7851187284164176, 'recall': 0.7868217054263565, 'f1-score': 0.7857722381168817, 'support': 516}
 
time = 2.35 secondes

Val loss 0.38838502764701843 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 58.31 secondes

Train loss 0.3877472387570323 accuracy 0.8527131676673889 macro_avg {'precision': 0.8473997563612031, 'recall': 0.8291045625213335, 'f1-score': 0.8366081695915204, 'support': 516} weighted_avg {'precision': 0.8515453932542725, 'recall': 0.8527131782945736, 'f1-score': 0.8507249056151844, 'support': 516}
 
time = 2.36 secondes

Val loss 0.3989737406373024 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 58.86 secondes

Train loss 0.26272348845095345 accuracy 0.9069767594337463 macro_avg {'precision': 0.8986942381437795, 'recall': 0.9005087528241471, 'f1-score': 0.8995848469122989, 'support': 516} weighted_avg {'precision': 0.9072168168249528, 'recall': 0.9069767441860465, 'f1-score': 0.9070823427185286, 'support': 516}
 
time = 2.38 secondes

Val loss 0.4658821187913418 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 58.26 secondes

Train loss 0.23204717748431544 accuracy 0.9166666865348816 macro_avg {'precision': 0.9184121047262837, 'recall': 0.9000292573509094, 'f1-score': 0.9079240585122939, 'support': 516} weighted_avg {'precision': 0.9170038535645473, 'recall': 0.9166666666666666, 'f1-score': 0.915731922398589, 'support': 516}
 
time = 2.45 secondes

Val loss 0.4648912623524666 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 6/40
time = 59.51 secondes

Train loss 0.18294251295314592 accuracy 0.9437984228134155 macro_avg {'precision': 0.9396383186705768, 'recall': 0.9386164523836614, 'f1-score': 0.9391229704605646, 'support': 516} weighted_avg {'precision': 0.9437406700159889, 'recall': 0.9437984496124031, 'f1-score': 0.9437657539539986, 'support': 516}
 
time = 2.45 secondes

Val loss 0.5831400752067566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 7/40
time = 58.56 secondes

Train loss 0.11872421393601337 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 2.36 secondes

Val loss 0.7752330601215363 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 8/40
time = 58.48 secondes

Train loss 0.1414358509566889 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 2.45 secondes

Val loss 1.2355355620384216 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 9/40
time = 59.07 secondes

Train loss 0.33448161012986954 accuracy 0.9127907156944275 macro_avg {'precision': 0.9153325123152709, 'recall': 0.8946816637680217, 'f1-score': 0.9033848586348223, 'support': 516} weighted_avg {'precision': 0.9133273029874875, 'recall': 0.9127906976744186, 'f1-score': 0.9116806918250254, 'support': 516}
 
time = 2.40 secondes

Val loss 0.9954286515712738 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.31 secondes

Train loss 0.1268364178778773 accuracy 0.9689922332763672 macro_avg {'precision': 0.9630002396357537, 'recall': 0.9710677307673553, 'f1-score': 0.9667498993153444, 'support': 516} weighted_avg {'precision': 0.9697531380209059, 'recall': 0.9689922480620154, 'f1-score': 0.9691261196289811, 'support': 516}
 
time = 2.40 secondes

Val loss 1.954167127609253 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 58.91 secondes

Train loss 0.36159477563694853 accuracy 0.9360464811325073 macro_avg {'precision': 0.9484901685393259, 'recall': 0.9152268257399672, 'f1-score': 0.928361976482467, 'support': 516} weighted_avg {'precision': 0.9394748660830938, 'recall': 0.936046511627907, 'f1-score': 0.9348188048295232, 'support': 516}
 
time = 2.48 secondes

Val loss 1.4643760919570923 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 58.41 secondes

Train loss 0.21275364523965187 accuracy 0.9437984228134155 macro_avg {'precision': 0.9387649195640893, 'recall': 0.9397704923361995, 'f1-score': 0.9392633181126333, 'support': 516} weighted_avg {'precision': 0.9438703571845218, 'recall': 0.9437984496124031, 'f1-score': 0.943830613665593, 'support': 516}
 
time = 2.41 secondes

Val loss 1.2357655763626099 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 13/40
time = 58.06 secondes

Train loss 0.1287964549688199 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 2.42 secondes

Val loss 1.1264150738716125 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 14/40
time = 58.88 secondes

Train loss 0.10440204414286806 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 2.41 secondes

Val loss 1.4035854237154126 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 15/40
time = 58.88 secondes

Train loss 0.48789847710445017 accuracy 0.9108527302742004 macro_avg {'precision': 0.8991163131399716, 'recall': 0.9162427059798774, 'f1-score': 0.9057556699066133, 'support': 516} weighted_avg {'precision': 0.9161221172771334, 'recall': 0.9108527131782945, 'f1-score': 0.9117871711114361, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3586439620703459 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 16/40
time = 58.00 secondes

Train loss 0.0835169197272273 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.26 secondes

Val loss 1.465189978480339 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 17/40
time = 58.59 secondes

Train loss 0.20039999671897737 accuracy 0.9515503644943237 macro_avg {'precision': 0.9490243583027763, 'recall': 0.9458495196918226, 'f1-score': 0.9473965363269734, 'support': 516} weighted_avg {'precision': 0.9514479810038943, 'recall': 0.9515503875968992, 'f1-score': 0.9514644458464872, 'support': 516}
 
time = 2.42 secondes

Val loss 1.5267489701509476 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 59.03 secondes

Train loss 0.15735966191101453 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 2.16 secondes

Val loss 1.1849833708256483 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 19/40
time = 58.74 secondes

Train loss 0.16154145083507473 accuracy 0.9689922332763672 macro_avg {'precision': 0.9697699348561062, 'recall': 0.9629894510995888, 'f1-score': 0.966212676794133, 'support': 516} weighted_avg {'precision': 0.9690528470329837, 'recall': 0.9689922480620154, 'f1-score': 0.9688795627403446, 'support': 516}
 
time = 2.42 secondes

Val loss 1.720089614391327 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 20/40
time = 58.46 secondes

Train loss 0.004716151664483318 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.42 secondes

Val loss 2.0340465307235718 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 21/40
time = 58.66 secondes

Train loss 0.2387493375894282 accuracy 0.9534883499145508 macro_avg {'precision': 0.9593185863208746, 'recall': 0.9404450368155, 'f1-score': 0.9486762926247037, 'support': 516} weighted_avg {'precision': 0.9545605953992947, 'recall': 0.9534883720930233, 'f1-score': 0.953001072906358, 'support': 516}
 
time = 2.41 secondes

Val loss 1.6022708751261234 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 22/40
time = 58.13 secondes

Train loss 0.05865256421163918 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.14 secondes

Val loss 1.5636188238859177 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 23/40
time = 58.35 secondes

Train loss 0.07743679428963471 accuracy 0.9767441749572754 macro_avg {'precision': 0.9795766125690035, 'recall': 0.97022251840775, 'f1-score': 0.9745975483680402, 'support': 516} weighted_avg {'precision': 0.9770310140487893, 'recall': 0.9767441860465116, 'f1-score': 0.9766296987036599, 'support': 516}
 
time = 2.38 secondes

Val loss 1.8072308003902435 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 24/40
time = 58.15 secondes

Train loss 0.02226735371346656 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.2751631364226341 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 25/40
time = 58.87 secondes

Train loss 0.12391318097202615 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2276369780302048 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 26/40
time = 59.12 secondes

Train loss 0.32974892150455026 accuracy 0.9496123790740967 macro_avg {'precision': 0.9521407624633431, 'recall': 0.9385595630902264, 'f1-score': 0.9446854127154284, 'support': 516} weighted_avg {'precision': 0.9499779490327127, 'recall': 0.9496124031007752, 'f1-score': 0.9492284817720469, 'support': 516}
 
time = 2.35 secondes

Val loss 1.8140016496181488 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 27/40
time = 57.89 secondes

Train loss 0.1245776131483691 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3423852026462555 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 28/40
time = 59.42 secondes

Train loss 0.048813668804624205 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.25 secondes

Val loss 1.7185466327355243 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 29/40
time = 58.82 secondes

Train loss 0.12386098914584816 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.41 secondes

Val loss 1.7375836186110973 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 30/40
time = 57.85 secondes

Train loss 0.28565631554837717 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 2.42 secondes

Val loss 1.2771421447396278 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 59.25 secondes

Train loss 0.03930170394530499 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.38 secondes

Val loss 1.3815643042325974 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 32/40
time = 58.58 secondes

Train loss 0.04664655021770159 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.36 secondes

Val loss 1.896320316940546 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 33/40
time = 58.45 secondes

Train loss 0.05259972890042153 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.42 secondes

Val loss 1.584839090704918 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 34/40
time = 58.90 secondes

Train loss 0.0065927045802571665 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.40 secondes

Val loss 1.713086411356926 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 35/40
time = 58.26 secondes

Train loss 6.341708991165046e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.37 secondes

Val loss 1.5881700813770294 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 59.00 secondes

Train loss 0.03260832701617443 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6551595330238342 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 37/40
time = 58.72 secondes

Train loss 4.282978018939806e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.42 secondes

Val loss 1.847426414489746 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 38/40
time = 58.59 secondes

Train loss 0.001748274674327783 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.44 secondes

Val loss 1.9580502212047577 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 39/40
time = 58.92 secondes

Train loss 2.799836141948066e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.43 secondes

Val loss 1.7082684509950923 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 40/40
time = 58.69 secondes

Train loss 2.625838103333742e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.23 secondes

Val loss 1.714829411037499 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 5 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 58.70047608613968

average val time 2.3862047672271727
 
time = 2.68 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9049707602339181, 'recall': 0.9049707602339181, 'f1-score': 0.9049707602339181, 'support': 65} weighted_avg {'precision': 0.9076923076923077, 'recall': 0.9076923076923077, 'f1-score': 0.9076923076923077, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_1
----------
Epoch 1/40
time = 106.88 secondes

Train loss 0.6526508042306611 accuracy 0.6279069781303406 macro_avg {'precision': 0.4541854185418542, 'recall': 0.4958633356630853, 'f1-score': 0.40004360148245044, 'support': 516} weighted_avg {'precision': 0.5041215749481925, 'recall': 0.627906976744186, 'f1-score': 0.5017939137062444, 'support': 516}
 
time = 3.11 secondes

Val loss 0.6721367835998535 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 106.89 secondes

Train loss 0.43885405948667816 accuracy 0.8062015771865845 macro_avg {'precision': 0.8098145330585675, 'recall': 0.7614713196690668, 'f1-score': 0.7750575434191254, 'support': 516} weighted_avg {'precision': 0.8076945184334525, 'recall': 0.8062015503875969, 'f1-score': 0.7980911319062242, 'support': 516}
 
time = 2.88 secondes

Val loss 0.4404994025826454 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 3/40
time = 106.60 secondes

Train loss 0.40031165674780356 accuracy 0.8217054009437561 macro_avg {'precision': 0.8062950527505053, 'recall': 0.8128667327666076, 'f1-score': 0.8092206790123456, 'support': 516} weighted_avg {'precision': 0.8242317171116847, 'recall': 0.8217054263565892, 'f1-score': 0.8226512405493349, 'support': 516}
 
time = 2.92 secondes

Val loss 0.391114741563797 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 4/40
time = 105.75 secondes

Train loss 0.28435496082811645 accuracy 0.8798449635505676 macro_avg {'precision': 0.8699998374591615, 'recall': 0.8699998374591615, 'f1-score': 0.8699998374591615, 'support': 516} weighted_avg {'precision': 0.8798449612403101, 'recall': 0.8798449612403101, 'f1-score': 0.8798449612403101, 'support': 516}
 
time = 2.95 secondes

Val loss 0.4086569473147392 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 5/40
time = 106.16 secondes

Train loss 0.20852691790258343 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 2.94 secondes

Val loss 0.5047884732484818 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 6/40
time = 106.52 secondes

Train loss 0.16236198668819712 accuracy 0.9476743936538696 macro_avg {'precision': 0.949331550802139, 'recall': 0.9370398062513207, 'f1-score': 0.9426305451580625, 'support': 516} weighted_avg {'precision': 0.9478967168262654, 'recall': 0.9476744186046512, 'f1-score': 0.9473117871803867, 'support': 516}
 
time = 2.58 secondes

Val loss 0.8151003122329712 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 105.54 secondes

Train loss 0.08078327928458086 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 2.92 secondes

Val loss 0.6999615952372551 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 8/40
time = 106.53 secondes

Train loss 0.11735291272458254 accuracy 0.9709302186965942 macro_avg {'precision': 0.9725198412698413, 'recall': 0.9645092079384945, 'f1-score': 0.9682858372088259, 'support': 516} weighted_avg {'precision': 0.9710728897502153, 'recall': 0.9709302325581395, 'f1-score': 0.9708059992195812, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2831183820962906 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 9/40
time = 106.23 secondes

Train loss 0.0728111248145896 accuracy 0.9864341020584106 macro_avg {'precision': 0.9870350969093766, 'recall': 0.9835915023649693, 'f1-score': 0.9852710301715525, 'support': 516} weighted_avg {'precision': 0.9864584729210066, 'recall': 0.9864341085271318, 'f1-score': 0.9864100448370163, 'support': 516}
 
time = 2.91 secondes

Val loss 0.9561516046524048 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 10/40
time = 105.93 secondes

Train loss 0.2727364226893494 accuracy 0.9379844665527344 macro_avg {'precision': 0.9270919120503458, 'recall': 0.9467516213448629, 'f1-score': 0.9345624019149374, 'support': 516} weighted_avg {'precision': 0.943546666714849, 'recall': 0.937984496124031, 'f1-score': 0.9386805152852027, 'support': 516}
 
time = 2.96 secondes

Val loss 1.4376361966133118 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 106.26 secondes

Train loss 0.12369245507447472 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 2.72 secondes

Val loss 1.1686341911554337 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 12/40
time = 106.88 secondes

Train loss 0.2239398792400166 accuracy 0.9573643207550049 macro_avg {'precision': 0.9570050300981281, 'recall': 0.9504087902085399, 'f1-score': 0.953542430591933, 'support': 516} weighted_avg {'precision': 0.9573363428265328, 'recall': 0.9573643410852714, 'f1-score': 0.9572093987679738, 'support': 516}
 
time = 2.86 secondes

Val loss 1.1280450572958216 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 13/40
time = 106.33 secondes

Train loss 0.3481568852316052 accuracy 0.9263566136360168 macro_avg {'precision': 0.9149700229644129, 'recall': 0.9376330803114283, 'f1-score': 0.9227155199596393, 'support': 516} weighted_avg {'precision': 0.9346882229396336, 'recall': 0.9263565891472868, 'f1-score': 0.9273318755368353, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4471633285284042 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 106.67 secondes

Train loss 0.48193736072007043 accuracy 0.9050387740135193 macro_avg {'precision': 0.8969252724442138, 'recall': 0.8978349560327032, 'f1-score': 0.8973759512937596, 'support': 516} weighted_avg {'precision': 0.9051546666505755, 'recall': 0.9050387596899225, 'f1-score': 0.9050931058487606, 'support': 516}
 
time = 2.98 secondes

Val loss 0.9556056782603264 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 107.11 secondes

Train loss 0.10950636746587628 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 2.92 secondes

Val loss 0.8155350387096405 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 16/40
time = 106.23 secondes

Train loss 0.06793631725612971 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 2.93 secondes

Val loss 1.228388026356697 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 106.23 secondes

Train loss 0.05855598292758011 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 2.83 secondes

Val loss 1.8716845214366913 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 18/40
time = 107.01 secondes

Train loss 0.14278572121486033 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 2.84 secondes

Val loss 1.782495766878128 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 19/40
time = 106.10 secondes

Train loss 0.07426900208740721 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 2.93 secondes

Val loss 2.292722076177597 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 20/40
time = 106.35 secondes

Train loss 0.41266337134275644 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.85 secondes

Val loss 1.568615734577179 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 21/40
time = 106.13 secondes

Train loss 0.17685734642763043 accuracy 0.9689922332763672 macro_avg {'precision': 0.9752439373767674, 'recall': 0.9583732912894365, 'f1-score': 0.9658730158730159, 'support': 516} weighted_avg {'precision': 0.9700219380667982, 'recall': 0.9689922480620154, 'f1-score': 0.968712316968131, 'support': 516}
 
time = 2.93 secondes

Val loss 1.8788590763724642 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 22/40
time = 106.25 secondes

Train loss 0.12393657735017106 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 2.94 secondes

Val loss 1.6335791498422623 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 23/40
time = 105.71 secondes

Train loss 0.11917145702450811 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 2.95 secondes

Val loss 2.4499506056308746 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 106.71 secondes

Train loss 0.19166216588818122 accuracy 0.9670542478561401 macro_avg {'precision': 0.9629480142072974, 'recall': 0.9660858540708352, 'f1-score': 0.9644764816652156, 'support': 516} weighted_avg {'precision': 0.9672354216258294, 'recall': 0.9670542635658915, 'f1-score': 0.9671098991464816, 'support': 516}
 
time = 2.69 secondes

Val loss 1.499965339899063 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 25/40
time = 107.58 secondes

Train loss 0.10124347070990497 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2261934950947762 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 26/40
time = 106.31 secondes

Train loss 0.06265152328353107 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.82 secondes

Val loss 1.6787316799163818 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 27/40
time = 105.84 secondes

Train loss 0.1743168470257484 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 2.94 secondes

Val loss 1.4443295896053314 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 28/40
time = 106.49 secondes

Train loss 0.023845222142523253 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.92 secondes

Val loss 2.4346551597118378 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 29/40
time = 106.91 secondes

Train loss 0.39005585973350343 accuracy 0.9418604373931885 macro_avg {'precision': 0.958217270194986, 'recall': 0.9197860962566845, 'f1-score': 0.934593023255814, 'support': 516} weighted_avg {'precision': 0.9467189220703505, 'recall': 0.9418604651162791, 'f1-score': 0.9405928880475933, 'support': 516}
 
time = 2.92 secondes

Val loss 1.48084257543087 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 30/40
time = 106.69 secondes

Train loss 0.1493743916686402 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.86 secondes

Val loss 1.705119117628783 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 106.46 secondes

Train loss 0.0026505435958053126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.80 secondes

Val loss 1.864279255270958 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 32/40
time = 106.03 secondes

Train loss 0.11904445267789539 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.91 secondes

Val loss 1.48716489225626 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 33/40
time = 106.60 secondes

Train loss 0.0001673200391506367 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.95 secondes

Val loss 2.412769377231598 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 34/40
time = 106.07 secondes

Train loss 0.022556991701783387 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.98 secondes

Val loss 1.9907635897397995 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 35/40
time = 105.99 secondes

Train loss 0.0002379695541810978 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.75 secondes

Val loss 2.076480969786644 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 36/40
time = 106.13 secondes

Train loss 0.020897628651613504 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.87 secondes

Val loss 2.1474937796592712 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 106.13 secondes

Train loss 6.45406376641018e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.761106714606285 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 38/40
time = 105.97 secondes

Train loss 3.172502009406206e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.92 secondes

Val loss 1.883382573723793 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 39/40
time = 106.09 secondes

Train loss 0.0002561505991087126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.94 secondes

Val loss 1.8005222529172897 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 40/40
time = 107.34 secondes

Train loss 2.7276694240616493e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.7226413786411285 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 15 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 106.39002574682236

average val time 2.8956131041049957
 
time = 3.26 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 69.25 GiB already allocated; 718.62 MiB free; 74.20 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 70.56 GiB already allocated; 1.80 GiB free; 73.10 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_1
----------
Epoch 1/40
time = 755.49 secondes

Train loss 1.372331961638512 accuracy 0.6310155391693115 macro_avg {'precision': 0.6227990152221288, 'recall': 0.6155942767044172, 'f1-score': 0.6085424596125351, 'support': 10182} weighted_avg {'precision': 0.6352206755249442, 'recall': 0.6310155175800433, 'f1-score': 0.6229050349104075, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.7946031366435575 accuracy 0.7667844295501709 macro_avg {'precision': 0.7464748114842101, 'recall': 0.7624202961575086, 'f1-score': 0.7477227027896178, 'support': 1132} weighted_avg {'precision': 0.7591497875513612, 'recall': 0.7667844522968198, 'f1-score': 0.7563077766068933, 'support': 1132}
 
----------
Epoch 2/40
time = 754.78 secondes

Train loss 0.5510137719007171 accuracy 0.8354940414428711 macro_avg {'precision': 0.822608970862451, 'recall': 0.8234619063329716, 'f1-score': 0.8207997313937538, 'support': 10182} weighted_avg {'precision': 0.8317195020277058, 'recall': 0.8354940090355529, 'f1-score': 0.8319458919253531, 'support': 10182}
 
time = 23.78 secondes

Val loss 0.6106695998722399 accuracy 0.8162544369697571 macro_avg {'precision': 0.8211281532337369, 'recall': 0.8109693318799313, 'f1-score': 0.8100367090302376, 'support': 1132} weighted_avg {'precision': 0.8237026913105493, 'recall': 0.8162544169611308, 'f1-score': 0.8143292364742848, 'support': 1132}
 
----------
Epoch 3/40
time = 754.66 secondes

Train loss 0.31115727099989143 accuracy 0.9104301929473877 macro_avg {'precision': 0.904979919710013, 'recall': 0.9038584653721854, 'f1-score': 0.9040340139091496, 'support': 10182} weighted_avg {'precision': 0.910529177052902, 'recall': 0.9104301708898055, 'f1-score': 0.9101392321502128, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.6279412276754287 accuracy 0.8365724682807922 macro_avg {'precision': 0.8530049729151175, 'recall': 0.8441911531931096, 'f1-score': 0.8391021139442414, 'support': 1132} weighted_avg {'precision': 0.8585270263452727, 'recall': 0.8365724381625441, 'f1-score': 0.8375765214643205, 'support': 1132}
 
----------
Epoch 4/40
time = 754.37 secondes

Train loss 0.21366391299596552 accuracy 0.9412689208984375 macro_avg {'precision': 0.9377447098015473, 'recall': 0.9374400275467858, 'f1-score': 0.9374969290738285, 'support': 10182} weighted_avg {'precision': 0.940974003326342, 'recall': 0.9412689059123944, 'f1-score': 0.9410440233637504, 'support': 10182}
 
time = 24.28 secondes

Val loss 0.6924298346488619 accuracy 0.843639612197876 macro_avg {'precision': 0.8682274146955926, 'recall': 0.8342303827464101, 'f1-score': 0.8407482412610522, 'support': 1132} weighted_avg {'precision': 0.8709878243092795, 'recall': 0.8436395759717314, 'f1-score': 0.84865035955994, 'support': 1132}
 
----------
Epoch 5/40
time = 752.90 secondes

Train loss 0.16139613372109995 accuracy 0.9572775959968567 macro_avg {'precision': 0.9546306415889925, 'recall': 0.9544967785595271, 'f1-score': 0.9545189898105397, 'support': 10182} weighted_avg {'precision': 0.9574269291066994, 'recall': 0.9572775486152033, 'f1-score': 0.9573085003398356, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.7453474432662864 accuracy 0.8683745861053467 macro_avg {'precision': 0.8653046063444083, 'recall': 0.8638709351951821, 'f1-score': 0.8621702824770379, 'support': 1132} weighted_avg {'precision': 0.8708572071679808, 'recall': 0.8683745583038869, 'f1-score': 0.8670814269455164, 'support': 1132}
 
----------
Epoch 6/40
time = 751.19 secondes

Train loss 0.1632520506621574 accuracy 0.9606168270111084 macro_avg {'precision': 0.9593769843422366, 'recall': 0.959295033199024, 'f1-score': 0.9592826166285946, 'support': 10182} weighted_avg {'precision': 0.9607009086743692, 'recall': 0.9606167747004518, 'f1-score': 0.9606035512368668, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.8076046266770122 accuracy 0.8586572408676147 macro_avg {'precision': 0.8733611505879111, 'recall': 0.8603918737860127, 'f1-score': 0.8611976506316774, 'support': 1132} weighted_avg {'precision': 0.8745645268805701, 'recall': 0.8586572438162544, 'f1-score': 0.8610883425250137, 'support': 1132}
 
----------
Epoch 7/40
time = 752.98 secondes

Train loss 0.1319472046252457 accuracy 0.9680809378623962 macro_avg {'precision': 0.9667779673844444, 'recall': 0.9664714537450386, 'f1-score': 0.9665962629174363, 'support': 10182} weighted_avg {'precision': 0.9680453594040704, 'recall': 0.9680809271263013, 'f1-score': 0.9680377537003787, 'support': 10182}
 
time = 24.23 secondes

Val loss 0.7400198687330334 accuracy 0.8763250708580017 macro_avg {'precision': 0.882719054172991, 'recall': 0.8795807675518855, 'f1-score': 0.8765283658987331, 'support': 1132} weighted_avg {'precision': 0.8845500008690171, 'recall': 0.8763250883392226, 'f1-score': 0.8756405291375831, 'support': 1132}
 
----------
Epoch 8/40
time = 753.98 secondes

Train loss 0.11714227561021276 accuracy 0.9732862114906311 macro_avg {'precision': 0.9730610650496192, 'recall': 0.9731039324220108, 'f1-score': 0.9730458775072742, 'support': 10182} weighted_avg {'precision': 0.9733179267287682, 'recall': 0.9732861913180122, 'f1-score': 0.9732642852113152, 'support': 10182}
 
time = 24.06 secondes

Val loss 0.8056871728515778 accuracy 0.8745583295822144 macro_avg {'precision': 0.8798159382358636, 'recall': 0.8699355610932809, 'f1-score': 0.8694207096865416, 'support': 1132} weighted_avg {'precision': 0.8786456874570715, 'recall': 0.8745583038869258, 'f1-score': 0.8720014860472374, 'support': 1132}
 
----------
Epoch 9/40
time = 751.96 secondes

Train loss 0.11801415112559842 accuracy 0.9736790657043457 macro_avg {'precision': 0.972644628486076, 'recall': 0.9725788801775138, 'f1-score': 0.972562795589426, 'support': 10182} weighted_avg {'precision': 0.9738008963208308, 'recall': 0.9736790414456885, 'f1-score': 0.9736979908628413, 'support': 10182}
 
time = 24.35 secondes

Val loss 1.0753419020801003 accuracy 0.8533568978309631 macro_avg {'precision': 0.8679677448365062, 'recall': 0.8564901278422747, 'f1-score': 0.8529149614998224, 'support': 1132} weighted_avg {'precision': 0.8700975756978135, 'recall': 0.8533568904593639, 'f1-score': 0.8523570552222254, 'support': 1132}
 
----------
Epoch 10/40
time = 749.13 secondes

Train loss 0.10305417418138897 accuracy 0.9778040051460266 macro_avg {'precision': 0.9776383737383597, 'recall': 0.9776333215872335, 'f1-score': 0.977607878384223, 'support': 10182} weighted_avg {'precision': 0.9779062634343646, 'recall': 0.9778039677862895, 'f1-score': 0.9778262756359387, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.9331279173257685 accuracy 0.8683745861053467 macro_avg {'precision': 0.8768015519988897, 'recall': 0.8702840547955544, 'f1-score': 0.8702798287425673, 'support': 1132} weighted_avg {'precision': 0.8767348440272853, 'recall': 0.8683745583038869, 'f1-score': 0.8691743120305949, 'support': 1132}
 
----------
Epoch 11/40
time = 753.27 secondes

Train loss 0.11408827397798271 accuracy 0.976527214050293 macro_avg {'precision': 0.9760512242354531, 'recall': 0.9752069771980449, 'f1-score': 0.9755615259145831, 'support': 10182} weighted_avg {'precision': 0.9766349309311828, 'recall': 0.9765272048713416, 'f1-score': 0.976516826796692, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.8731713990548061 accuracy 0.8816254734992981 macro_avg {'precision': 0.8852490276105718, 'recall': 0.8813630113595456, 'f1-score': 0.8800319787214775, 'support': 1132} weighted_avg {'precision': 0.8892986528284939, 'recall': 0.8816254416961131, 'f1-score': 0.8827693127374225, 'support': 1132}
 
----------
Epoch 12/40
time = 745.70 secondes

Train loss 0.09350815200219639 accuracy 0.9817324876785278 macro_avg {'precision': 0.9811533373948553, 'recall': 0.9812864309053259, 'f1-score': 0.9811952368034825, 'support': 10182} weighted_avg {'precision': 0.9817763636396301, 'recall': 0.9817324690630524, 'f1-score': 0.9817327587328296, 'support': 10182}
 
time = 24.12 secondes

Val loss 0.6727751348406227 accuracy 0.898409903049469 macro_avg {'precision': 0.899681050613302, 'recall': 0.901665548309509, 'f1-score': 0.8990898194638367, 'support': 1132} weighted_avg {'precision': 0.9026512091959225, 'recall': 0.8984098939929329, 'f1-score': 0.8989089010985141, 'support': 1132}
 
----------
Epoch 13/40
time = 753.68 secondes

Train loss 0.08819657378679974 accuracy 0.9833039045333862 macro_avg {'precision': 0.9827605320841689, 'recall': 0.9826348888497225, 'f1-score': 0.9826756627843956, 'support': 10182} weighted_avg {'precision': 0.9833198066214602, 'recall': 0.9833038695737576, 'f1-score': 0.9832906199431807, 'support': 10182}
 
time = 25.46 secondes

Val loss 0.773803951294968 accuracy 0.8886925578117371 macro_avg {'precision': 0.8938634676689954, 'recall': 0.8931172197065278, 'f1-score': 0.8905624794033737, 'support': 1132} weighted_avg {'precision': 0.8958193315622673, 'recall': 0.8886925795053003, 'f1-score': 0.8892571244970706, 'support': 1132}
 
----------
Epoch 14/40
time = 752.32 secondes

Train loss 0.0932274632471103 accuracy 0.980553925037384 macro_avg {'precision': 0.9804310136897358, 'recall': 0.98020414388562, 'f1-score': 0.9802714302140234, 'support': 10182} weighted_avg {'precision': 0.980597048195714, 'recall': 0.9805539186800236, 'f1-score': 0.9805301347474901, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.7728160917353127 accuracy 0.8904593586921692 macro_avg {'precision': 0.8942876348892301, 'recall': 0.8898960402382146, 'f1-score': 0.890230523091845, 'support': 1132} weighted_avg {'precision': 0.8965893111519456, 'recall': 0.8904593639575972, 'f1-score': 0.8915145460515232, 'support': 1132}
 
----------
Epoch 15/40
time = 753.87 secondes

Train loss 0.0719670745086744 accuracy 0.9861520528793335 macro_avg {'precision': 0.9858527859212373, 'recall': 0.9852419916401732, 'f1-score': 0.9855118632423577, 'support': 10182} weighted_avg {'precision': 0.9861667119229981, 'recall': 0.9861520329994107, 'f1-score': 0.9861296046393095, 'support': 10182}
 
time = 24.21 secondes

Val loss 0.9237031098707287 accuracy 0.8860424160957336 macro_avg {'precision': 0.8955202697406713, 'recall': 0.8906077846906573, 'f1-score': 0.8892029419574626, 'support': 1132} weighted_avg {'precision': 0.8953263719726176, 'recall': 0.8860424028268551, 'f1-score': 0.8864554977098054, 'support': 1132}
 
----------
Epoch 16/40
time = 751.91 secondes

Train loss 0.09111707174977444 accuracy 0.9833039045333862 macro_avg {'precision': 0.9832043072807435, 'recall': 0.9829076347767767, 'f1-score': 0.9829997136447165, 'support': 10182} weighted_avg {'precision': 0.9833759323360373, 'recall': 0.9833038695737576, 'f1-score': 0.9832827748837946, 'support': 10182}
 
time = 24.17 secondes

Val loss 0.9377645152257378 accuracy 0.8789752721786499 macro_avg {'precision': 0.8930652443457742, 'recall': 0.8828843825303483, 'f1-score': 0.8838259068861909, 'support': 1132} weighted_avg {'precision': 0.8905908069390202, 'recall': 0.8789752650176679, 'f1-score': 0.8801836820631088, 'support': 1132}
 
----------
Epoch 17/40
time = 753.83 secondes

Train loss 0.08425878126803256 accuracy 0.9853663444519043 macro_avg {'precision': 0.9846060863228274, 'recall': 0.9844686300106302, 'f1-score': 0.9844948491595954, 'support': 10182} weighted_avg {'precision': 0.9854143644602418, 'recall': 0.9853663327440582, 'f1-score': 0.9853520739409795, 'support': 10182}
 
time = 24.16 secondes

Val loss 0.9657834803055919 accuracy 0.8772084712982178 macro_avg {'precision': 0.8925533149624533, 'recall': 0.8767410997234475, 'f1-score': 0.8793459031255132, 'support': 1132} weighted_avg {'precision': 0.8887904444433735, 'recall': 0.877208480565371, 'f1-score': 0.8775853051960477, 'support': 1132}
 
----------
Epoch 18/40
time = 752.53 secondes

Train loss 0.07976119425824882 accuracy 0.9853663444519043 macro_avg {'precision': 0.9844619872694128, 'recall': 0.9844023646004441, 'f1-score': 0.984414797763027, 'support': 10182} weighted_avg {'precision': 0.9853762106376384, 'recall': 0.9853663327440582, 'f1-score': 0.9853535442115765, 'support': 10182}
 
time = 23.92 secondes

Val loss 0.992117074271705 accuracy 0.870141327381134 macro_avg {'precision': 0.8812779685143189, 'recall': 0.8709005611704322, 'f1-score': 0.8700869466852816, 'support': 1132} weighted_avg {'precision': 0.8864467610957574, 'recall': 0.8701413427561837, 'f1-score': 0.8729543336143502, 'support': 1132}
 
----------
Epoch 19/40
time = 754.19 secondes

Train loss 0.07153822533315518 accuracy 0.9869377613067627 macro_avg {'precision': 0.9863034044808192, 'recall': 0.9863121378785034, 'f1-score': 0.9862765358079466, 'support': 10182} weighted_avg {'precision': 0.9870431902998108, 'recall': 0.9869377332547633, 'f1-score': 0.9869595653434582, 'support': 10182}
 
time = 24.15 secondes

Val loss 1.0845947651230259 accuracy 0.8630741834640503 macro_avg {'precision': 0.8914171758759473, 'recall': 0.8651150588094595, 'f1-score': 0.8684040236646009, 'support': 1132} weighted_avg {'precision': 0.8907204520585983, 'recall': 0.8630742049469965, 'f1-score': 0.8667269863309442, 'support': 1132}
 
----------
Epoch 20/40
time = 753.25 secondes

Train loss 0.05953320252072964 accuracy 0.9890002012252808 macro_avg {'precision': 0.9884552427468485, 'recall': 0.9880638701675956, 'f1-score': 0.988238361198521, 'support': 10182} weighted_avg {'precision': 0.9890085218145828, 'recall': 0.9890001964250639, 'f1-score': 0.9889867107018898, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8541200280906452 accuracy 0.8895759582519531 macro_avg {'precision': 0.9003426887178707, 'recall': 0.8931741703920248, 'f1-score': 0.8920724608782201, 'support': 1132} weighted_avg {'precision': 0.8998147142118282, 'recall': 0.8895759717314488, 'f1-score': 0.8898306106926647, 'support': 1132}
 
----------
Epoch 21/40
time = 750.66 secondes

Train loss 0.0641876879211967 accuracy 0.9891966581344604 macro_avg {'precision': 0.988963734983898, 'recall': 0.988961383182707, 'f1-score': 0.9889300115687074, 'support': 10182} weighted_avg {'precision': 0.9892470618587771, 'recall': 0.989196621488902, 'f1-score': 0.989188623316835, 'support': 10182}
 
time = 23.99 secondes

Val loss 0.9540071966604929 accuracy 0.8869258165359497 macro_avg {'precision': 0.8987006263142356, 'recall': 0.8883460023219281, 'f1-score': 0.8890146844100295, 'support': 1132} weighted_avg {'precision': 0.8978512785134412, 'recall': 0.8869257950530035, 'f1-score': 0.8875584304481257, 'support': 1132}
 
----------
Epoch 22/40
time = 753.34 secondes

Train loss 0.06019574741347833 accuracy 0.9892948865890503 macro_avg {'precision': 0.9890623680386547, 'recall': 0.9889867640602665, 'f1-score': 0.9890062111654334, 'support': 10182} weighted_avg {'precision': 0.9893163025733535, 'recall': 0.9892948340208211, 'f1-score': 0.9892872415353429, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8117108292869271 accuracy 0.8948763608932495 macro_avg {'precision': 0.9094741174817651, 'recall': 0.8977009907009121, 'f1-score': 0.9007949655864523, 'support': 1132} weighted_avg {'precision': 0.9066520601007092, 'recall': 0.8948763250883393, 'f1-score': 0.897736830091526, 'support': 1132}
 
----------
Epoch 23/40
time = 751.85 secondes

Train loss 0.046891239848781234 accuracy 0.9912590980529785 macro_avg {'precision': 0.9910942812121457, 'recall': 0.9910986806467094, 'f1-score': 0.9910815748197365, 'support': 10182} weighted_avg {'precision': 0.9912890290931287, 'recall': 0.9912590846592025, 'f1-score': 0.9912597869873107, 'support': 10182}
 
time = 24.30 secondes

Val loss 0.861574079609262 accuracy 0.8904593586921692 macro_avg {'precision': 0.8974093724344812, 'recall': 0.8940962135174175, 'f1-score': 0.8937967626774256, 'support': 1132} weighted_avg {'precision': 0.8954076185669162, 'recall': 0.8904593639575972, 'f1-score': 0.8909618234218524, 'support': 1132}
 
----------
Epoch 24/40
time = 753.34 secondes

Train loss 0.049776418264081024 accuracy 0.9920448064804077 macro_avg {'precision': 0.9918456049048275, 'recall': 0.9919515415120166, 'f1-score': 0.9918861996140059, 'support': 10182} weighted_avg {'precision': 0.9920642555785829, 'recall': 0.9920447849145551, 'f1-score': 0.9920429598966232, 'support': 10182}
 
time = 24.06 secondes

Val loss 1.080848942467128 accuracy 0.8683745861053467 macro_avg {'precision': 0.8831733072203105, 'recall': 0.8774287583732457, 'f1-score': 0.8701177522078671, 'support': 1132} weighted_avg {'precision': 0.8852145054137567, 'recall': 0.8683745583038869, 'f1-score': 0.8652123310618849, 'support': 1132}
 
----------
Epoch 25/40
time = 752.36 secondes

Train loss 0.04876870376791824 accuracy 0.9916519522666931 macro_avg {'precision': 0.9913750579598197, 'recall': 0.9914745311552249, 'f1-score': 0.9914163293884884, 'support': 10182} weighted_avg {'precision': 0.9916604006652592, 'recall': 0.9916519347868789, 'f1-score': 0.9916476377050246, 'support': 10182}
 
time = 23.90 secondes

Val loss 0.8584901109039288 accuracy 0.9010601043701172 macro_avg {'precision': 0.906664111515259, 'recall': 0.9039321342098422, 'f1-score': 0.9025330574532333, 'support': 1132} weighted_avg {'precision': 0.907080063437981, 'recall': 0.901060070671378, 'f1-score': 0.9013085333087916, 'support': 1132}
 
----------
Epoch 26/40
time = 752.67 secondes

Train loss 0.06092188786274371 accuracy 0.9907680749893188 macro_avg {'precision': 0.9902960777763882, 'recall': 0.9901684877515627, 'f1-score': 0.9902061139446289, 'support': 10182} weighted_avg {'precision': 0.9908022183772769, 'recall': 0.9907680219996071, 'f1-score': 0.9907594011698361, 'support': 10182}
 
time = 23.82 secondes

Val loss 0.8058353072652531 accuracy 0.8922261595726013 macro_avg {'precision': 0.9007005797570399, 'recall': 0.8977463799964355, 'f1-score': 0.8949957781346468, 'support': 1132} weighted_avg {'precision': 0.9039005456709617, 'recall': 0.892226148409894, 'f1-score': 0.8937555336541271, 'support': 1132}
 
----------
Epoch 27/40
time = 752.86 secondes

Train loss 0.051702512698568535 accuracy 0.9913573265075684 macro_avg {'precision': 0.9907966184798582, 'recall': 0.990612683320145, 'f1-score': 0.9906936862196385, 'support': 10182} weighted_avg {'precision': 0.9913793385484096, 'recall': 0.9913572971911215, 'f1-score': 0.9913591786920781, 'support': 10182}
 
time = 25.31 secondes

Val loss 0.8526200375970188 accuracy 0.8939929604530334 macro_avg {'precision': 0.9022921238290584, 'recall': 0.8971818502208588, 'f1-score': 0.8971399674248456, 'support': 1132} weighted_avg {'precision': 0.9011302072928531, 'recall': 0.8939929328621908, 'f1-score': 0.8949328188899834, 'support': 1132}
 
----------
Epoch 28/40
time = 751.36 secondes

Train loss 0.03535121138044459 accuracy 0.9940090775489807 macro_avg {'precision': 0.9939766947761284, 'recall': 0.9936788171249026, 'f1-score': 0.993813496075914, 'support': 10182} weighted_avg {'precision': 0.9940224143819081, 'recall': 0.9940090355529365, 'f1-score': 0.9940036751855822, 'support': 10182}
 
time = 24.41 secondes

Val loss 1.1391332672197088 accuracy 0.8736749291419983 macro_avg {'precision': 0.8927321653928899, 'recall': 0.8676111026509574, 'f1-score': 0.8737096387857376, 'support': 1132} weighted_avg {'precision': 0.8863971339958189, 'recall': 0.8736749116607774, 'f1-score': 0.8735081407763031, 'support': 1132}
 
----------
Epoch 29/40
time = 754.37 secondes

Train loss 0.03715499011462212 accuracy 0.9939108490943909 macro_avg {'precision': 0.993902243134484, 'recall': 0.9938488303088301, 'f1-score': 0.9938670676472212, 'support': 10182} weighted_avg {'precision': 0.9939322691752885, 'recall': 0.9939108230210175, 'f1-score': 0.9939128252095553, 'support': 10182}
 
time = 23.95 secondes

Val loss 1.067693534377687 accuracy 0.8683745861053467 macro_avg {'precision': 0.8850390007258714, 'recall': 0.8708386806164906, 'f1-score': 0.8728853808123708, 'support': 1132} weighted_avg {'precision': 0.882983007776834, 'recall': 0.8683745583038869, 'f1-score': 0.8701166865905084, 'support': 1132}
 
----------
Epoch 30/40
time = 754.63 secondes

Train loss 0.03644347898339869 accuracy 0.9939108490943909 macro_avg {'precision': 0.993760722179388, 'recall': 0.9939054746857945, 'f1-score': 0.9938271576707992, 'support': 10182} weighted_avg {'precision': 0.9939266251779809, 'recall': 0.9939108230210175, 'f1-score': 0.9939134313789806, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.8739052489636122 accuracy 0.8957597017288208 macro_avg {'precision': 0.9001009851411821, 'recall': 0.8968236109848619, 'f1-score': 0.897262923002286, 'support': 1132} weighted_avg {'precision': 0.899072132739794, 'recall': 0.8957597173144877, 'f1-score': 0.8961455170153119, 'support': 1132}
 
----------
Epoch 31/40
time = 753.45 secondes

Train loss 0.025959832525053975 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953250005870793, 'recall': 0.9954097565633775, 'f1-score': 0.9953618758032269, 'support': 10182} weighted_avg {'precision': 0.9953871187961189, 'recall': 0.9953840109998036, 'f1-score': 0.9953801139582318, 'support': 10182}
 
time = 24.75 secondes

Val loss 0.8779223775988138 accuracy 0.8966431021690369 macro_avg {'precision': 0.9043230630068578, 'recall': 0.8988354828975277, 'f1-score': 0.9004111605597072, 'support': 1132} weighted_avg {'precision': 0.901194346969186, 'recall': 0.8966431095406361, 'f1-score': 0.8977860509808875, 'support': 1132}
 
----------
Epoch 32/40
time = 758.62 secondes

Train loss 0.0277228288420189 accuracy 0.9955804944038391 macro_avg {'precision': 0.995286567472126, 'recall': 0.9954263545153028, 'f1-score': 0.9953509225906689, 'support': 10182} weighted_avg {'precision': 0.9955943473834448, 'recall': 0.9955804360636418, 'f1-score': 0.9955822926445846, 'support': 10182}
 
time = 24.68 secondes

Val loss 0.9034856507832572 accuracy 0.9001767039299011 macro_avg {'precision': 0.9048637021085796, 'recall': 0.9033264056112049, 'f1-score': 0.9022439062009578, 'support': 1132} weighted_avg {'precision': 0.9033795517018438, 'recall': 0.9001766784452296, 'f1-score': 0.8999772359278706, 'support': 1132}
 
----------
Epoch 33/40
time = 757.29 secondes

Train loss 0.02274574027798915 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963307586288079, 'recall': 0.9961586202089784, 'f1-score': 0.9962361309740665, 'support': 10182} weighted_avg {'precision': 0.9962866130673353, 'recall': 0.9962679237870752, 'f1-score': 0.9962688876045266, 'support': 10182}
 
time = 24.38 secondes

Val loss 0.9153745993161734 accuracy 0.8904593586921692 macro_avg {'precision': 0.894230099447137, 'recall': 0.8954176026269571, 'f1-score': 0.8924236178395379, 'support': 1132} weighted_avg {'precision': 0.8976734824924806, 'recall': 0.8904593639575972, 'f1-score': 0.8918156718475612, 'support': 1132}
 
----------
Epoch 34/40
time = 755.53 secondes

Train loss 0.0196310529865408 accuracy 0.9962679743766785 macro_avg {'precision': 0.996221252384412, 'recall': 0.9962593320220797, 'f1-score': 0.9962367319673626, 'support': 10182} weighted_avg {'precision': 0.9962773393346889, 'recall': 0.9962679237870752, 'f1-score': 0.9962690892243178, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.952540274721658 accuracy 0.898409903049469 macro_avg {'precision': 0.9057842277530691, 'recall': 0.9010000842328447, 'f1-score': 0.901156343135351, 'support': 1132} weighted_avg {'precision': 0.904929523636246, 'recall': 0.8984098939929329, 'f1-score': 0.8993834992448966, 'support': 1132}
 
----------
Epoch 35/40
time = 755.48 secondes

Train loss 0.015508589382747863 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975190877969418, 'recall': 0.9974545048840687, 'f1-score': 0.9974853024850476, 'support': 10182} weighted_avg {'precision': 0.9975486329986448, 'recall': 0.9975446867020232, 'f1-score': 0.9975452542278265, 'support': 10182}
 
time = 24.48 secondes

Val loss 0.9013555614728317 accuracy 0.9028268456459045 macro_avg {'precision': 0.9084692932448064, 'recall': 0.9043041288912319, 'f1-score': 0.9047638500189679, 'support': 1132} weighted_avg {'precision': 0.9074167596953874, 'recall': 0.9028268551236749, 'f1-score': 0.9034216790751081, 'support': 1132}
 
----------
Epoch 36/40
time = 756.23 secondes

Train loss 0.01311352847341578 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977195787365696, 'recall': 0.99773183359121, 'f1-score': 0.9977242089918377, 'support': 10182} weighted_avg {'precision': 0.9976432963101047, 'recall': 0.9976428992339422, 'f1-score': 0.997641534596836, 'support': 10182}
 
time = 24.03 secondes

Val loss 0.8549421874387764 accuracy 0.9010601043701172 macro_avg {'precision': 0.9080053111380012, 'recall': 0.9036995578189959, 'f1-score': 0.9039883277153746, 'support': 1132} weighted_avg {'precision': 0.9081317789132044, 'recall': 0.901060070671378, 'f1-score': 0.9026620832775903, 'support': 1132}
 
----------
Epoch 37/40
time = 749.67 secondes

Train loss 0.011699782797074235 accuracy 0.997741162776947 macro_avg {'precision': 0.9977984990264328, 'recall': 0.9977821899592556, 'f1-score': 0.9977869008189482, 'support': 10182} weighted_avg {'precision': 0.997749217959591, 'recall': 0.9977411117658613, 'f1-score': 0.9977416244722362, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.9261157800301076 accuracy 0.9019434452056885 macro_avg {'precision': 0.9059935992413385, 'recall': 0.9047054121594371, 'f1-score': 0.9044833680821153, 'support': 1132} weighted_avg {'precision': 0.9048351628181854, 'recall': 0.9019434628975265, 'f1-score': 0.9025225154597547, 'support': 1132}
 
----------
Epoch 38/40
time = 751.72 secondes

Train loss 0.008788656654223171 accuracy 0.9983304142951965 macro_avg {'precision': 0.9984002265102557, 'recall': 0.9983954854416333, 'f1-score': 0.9983962324272045, 'support': 10182} weighted_avg {'precision': 0.9983341028334072, 'recall': 0.9983303869573757, 'f1-score': 0.9983305700738241, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.934349763100637 accuracy 0.8992933034896851 macro_avg {'precision': 0.9036948669274061, 'recall': 0.9017666057022637, 'f1-score': 0.9013226556836932, 'support': 1132} weighted_avg {'precision': 0.9038802477116822, 'recall': 0.8992932862190812, 'f1-score': 0.9001004984642382, 'support': 1132}
 
----------
Epoch 39/40
time = 752.52 secondes

Train loss 0.0065723362446275715 accuracy 0.998919665813446 macro_avg {'precision': 0.9989627855156149, 'recall': 0.9989661221551002, 'f1-score': 0.9989641871717895, 'support': 10182} weighted_avg {'precision': 0.9989200438405521, 'recall': 0.9989196621488902, 'f1-score': 0.9989195755867342, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.9459367514915664 accuracy 0.9028268456459045 macro_avg {'precision': 0.9070013583830117, 'recall': 0.9055171140746486, 'f1-score': 0.9054042451182214, 'support': 1132} weighted_avg {'precision': 0.9054935666872914, 'recall': 0.9028268551236749, 'f1-score': 0.9032424345292964, 'support': 1132}
 
----------
Epoch 40/40
time = 752.91 secondes

Train loss 0.002053271436787704 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996224065117731, 'recall': 0.9996220883649922, 'f1-score': 0.9996218870502203, 'support': 10182} weighted_avg {'precision': 0.9996078915605738, 'recall': 0.9996071498723237, 'f1-score': 0.9996071478785676, 'support': 10182}
 
time = 24.53 secondes

Val loss 0.9393784564454749 accuracy 0.9045936465263367 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}
 
----------
best_accuracy 0.9045936465263367 best_epoch 40 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}

average train time 753.1714322268963

average val time 24.193848645687105
 
time = 155.53 secondes

test_accuracy 0.8394848704338074 macro_avg {'precision': 0.8360665862079324, 'recall': 0.8314777131359555, 'f1-score': 0.8318660812130627, 'support': 7532} weighted_avg {'precision': 0.8416371158070496, 'recall': 0.8394848645778014, 'f1-score': 0.8387477349344281, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 476.60 secondes

Train loss 1.4331473210355739 accuracy 0.6079356074333191 macro_avg {'precision': 0.595532368398952, 'recall': 0.5917237987707078, 'f1-score': 0.5790491296094726, 'support': 10182} weighted_avg {'precision': 0.6042763200476227, 'recall': 0.6079355725790611, 'f1-score': 0.593853690526893, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.7841680335326934 accuracy 0.7667844295501709 macro_avg {'precision': 0.739943149202323, 'recall': 0.7618544356319451, 'f1-score': 0.7458947088746772, 'support': 1132} weighted_avg {'precision': 0.75182844061862, 'recall': 0.7667844522968198, 'f1-score': 0.7541985476968371, 'support': 1132}
 
----------
Epoch 2/40
time = 476.04 secondes

Train loss 0.583929990013269 accuracy 0.8282263278961182 macro_avg {'precision': 0.8161602902699846, 'recall': 0.8165633833367003, 'f1-score': 0.8128140616937282, 'support': 10182} weighted_avg {'precision': 0.8244776185406745, 'recall': 0.8282262816735415, 'f1-score': 0.8237937923967038, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.5993993981203563 accuracy 0.8250883221626282 macro_avg {'precision': 0.8195563635230922, 'recall': 0.8193174818530942, 'f1-score': 0.8152797294673576, 'support': 1132} weighted_avg {'precision': 0.8230771856693206, 'recall': 0.8250883392226148, 'f1-score': 0.8202999495405455, 'support': 1132}
 
----------
Epoch 3/40
time = 476.00 secondes

Train loss 0.340324222538591 accuracy 0.9025731682777405 macro_avg {'precision': 0.8967596834557, 'recall': 0.8958669568700433, 'f1-score': 0.8958695376090751, 'support': 10182} weighted_avg {'precision': 0.9024620646147935, 'recall': 0.9025731683362798, 'f1-score': 0.9021430590220308, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.5815014537476318 accuracy 0.8560070991516113 macro_avg {'precision': 0.8634590795475925, 'recall': 0.8556529482332225, 'f1-score': 0.8552210975889697, 'support': 1132} weighted_avg {'precision': 0.8646713003522922, 'recall': 0.8560070671378092, 'f1-score': 0.8560157507643367, 'support': 1132}
 
----------
Epoch 4/40
time = 476.22 secondes

Train loss 0.23231736694578098 accuracy 0.9345904588699341 macro_avg {'precision': 0.9319368347980402, 'recall': 0.9317686101997366, 'f1-score': 0.9317570155734156, 'support': 10182} weighted_avg {'precision': 0.9348861108546099, 'recall': 0.9345904537418974, 'f1-score': 0.9346498251221417, 'support': 10182}
 
time = 18.96 secondes

Val loss 0.6259556379641446 accuracy 0.8551236987113953 macro_avg {'precision': 0.8609540977768008, 'recall': 0.8556226015645432, 'f1-score': 0.8544318344221775, 'support': 1132} weighted_avg {'precision': 0.8625570425443255, 'recall': 0.8551236749116607, 'f1-score': 0.8548984432087424, 'support': 1132}
 
----------
Epoch 5/40
time = 475.88 secondes

Train loss 0.1748830053386581 accuracy 0.9533490538597107 macro_avg {'precision': 0.9516033261806103, 'recall': 0.9514170434662741, 'f1-score': 0.9514570429770532, 'support': 10182} weighted_avg {'precision': 0.9534326157275188, 'recall': 0.9533490473384404, 'f1-score': 0.953336799730088, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.7272236547465633 accuracy 0.8630741834640503 macro_avg {'precision': 0.8708896460916961, 'recall': 0.8644282370593244, 'f1-score': 0.8641041655066886, 'support': 1132} weighted_avg {'precision': 0.8726354679099134, 'recall': 0.8630742049469965, 'f1-score': 0.8642412809883327, 'support': 1132}
 
----------
Epoch 6/40
time = 476.16 secondes

Train loss 0.1584024625383332 accuracy 0.9604203701019287 macro_avg {'precision': 0.9592065042520094, 'recall': 0.9592835233329247, 'f1-score': 0.9592294929828862, 'support': 10182} weighted_avg {'precision': 0.9604347813263789, 'recall': 0.9604203496366136, 'f1-score': 0.9604123345468925, 'support': 10182}
 
time = 18.86 secondes

Val loss 0.758953261697455 accuracy 0.8577738404273987 macro_avg {'precision': 0.8614111064327519, 'recall': 0.8589454743813493, 'f1-score': 0.8549817886692553, 'support': 1132} weighted_avg {'precision': 0.8660030040975224, 'recall': 0.857773851590106, 'f1-score': 0.856284031270566, 'support': 1132}
 
----------
Epoch 7/40
time = 475.84 secondes

Train loss 0.14216014674765656 accuracy 0.9653310179710388 macro_avg {'precision': 0.9645655522809855, 'recall': 0.9641619498612242, 'f1-score': 0.9642924550541008, 'support': 10182} weighted_avg {'precision': 0.9655337846443575, 'recall': 0.9653309762325673, 'f1-score': 0.9653611515450293, 'support': 10182}
 
time = 18.85 secondes

Val loss 0.7416990194010588 accuracy 0.8780918717384338 macro_avg {'precision': 0.8811785459790918, 'recall': 0.8804205108422221, 'f1-score': 0.8781174879349164, 'support': 1132} weighted_avg {'precision': 0.8849644983260769, 'recall': 0.8780918727915195, 'f1-score': 0.8787998994126525, 'support': 1132}
 
----------
Epoch 8/40
time = 476.10 secondes

Train loss 0.12067588076754429 accuracy 0.9725005030632019 macro_avg {'precision': 0.9722001082472236, 'recall': 0.9721257796000968, 'f1-score': 0.9721351711975579, 'support': 10182} weighted_avg {'precision': 0.9725739050575131, 'recall': 0.9725004910626596, 'f1-score': 0.9725087613223514, 'support': 10182}
 
time = 18.82 secondes

Val loss 0.7339283946235861 accuracy 0.8745583295822144 macro_avg {'precision': 0.8826095081904173, 'recall': 0.874568146580154, 'f1-score': 0.8769547797901808, 'support': 1132} weighted_avg {'precision': 0.8811637837674384, 'recall': 0.8745583038869258, 'f1-score': 0.8761188850333996, 'support': 1132}
 
----------
Epoch 9/40
time = 476.04 secondes

Train loss 0.10903065326039532 accuracy 0.9746611714363098 macro_avg {'precision': 0.9741865901387794, 'recall': 0.9742351137255751, 'f1-score': 0.9741962233526994, 'support': 10182} weighted_avg {'precision': 0.974724442373857, 'recall': 0.9746611667648792, 'f1-score': 0.9746785518769862, 'support': 10182}
 
time = 18.88 secondes

Val loss 0.8223847077159674 accuracy 0.8772084712982178 macro_avg {'precision': 0.8826345561067571, 'recall': 0.8770441957968472, 'f1-score': 0.8769333427693777, 'support': 1132} weighted_avg {'precision': 0.8831914359483808, 'recall': 0.877208480565371, 'f1-score': 0.8773411367960622, 'support': 1132}
 
----------
Epoch 10/40
time = 475.82 secondes

Train loss 0.11789070985461728 accuracy 0.9738755226135254 macro_avg {'precision': 0.9731961377927348, 'recall': 0.973200740770074, 'f1-score': 0.9731627640154048, 'support': 10182} weighted_avg {'precision': 0.9739487252486413, 'recall': 0.9738754665095266, 'f1-score': 0.9738776717658235, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.8175750739454755 accuracy 0.8825088143348694 macro_avg {'precision': 0.8913923704669908, 'recall': 0.883866773636696, 'f1-score': 0.8847052732973243, 'support': 1132} weighted_avg {'precision': 0.8909649461121127, 'recall': 0.8825088339222615, 'f1-score': 0.8837968176779287, 'support': 1132}
 
----------
Epoch 11/40
time = 475.91 secondes

Train loss 0.09919397233814671 accuracy 0.9790807366371155 macro_avg {'precision': 0.9790703489237936, 'recall': 0.9788592044062174, 'f1-score': 0.9789447022959307, 'support': 10182} weighted_avg {'precision': 0.9791428167988073, 'recall': 0.9790807307012375, 'f1-score': 0.9790913360341983, 'support': 10182}
 
time = 18.77 secondes

Val loss 0.8908824549281222 accuracy 0.8754417300224304 macro_avg {'precision': 0.8821615968382085, 'recall': 0.8794177991914369, 'f1-score': 0.8789325370424491, 'support': 1132} weighted_avg {'precision': 0.8815647475126456, 'recall': 0.8754416961130742, 'f1-score': 0.8765026701389428, 'support': 1132}
 
----------
Epoch 12/40
time = 475.88 secondes

Train loss 0.09129590717917549 accuracy 0.9806521534919739 macro_avg {'precision': 0.9800866581385748, 'recall': 0.9802607772683853, 'f1-score': 0.9801439160742735, 'support': 10182} weighted_avg {'precision': 0.9807138847737596, 'recall': 0.9806521312119426, 'f1-score': 0.9806558565390472, 'support': 10182}
 
time = 18.48 secondes

Val loss 0.9937783832445374 accuracy 0.8630741834640503 macro_avg {'precision': 0.8733898391893451, 'recall': 0.8670089084551453, 'f1-score': 0.8648809298645034, 'support': 1132} weighted_avg {'precision': 0.8755908746722945, 'recall': 0.8630742049469965, 'f1-score': 0.8639046796658957, 'support': 1132}
 
----------
Epoch 13/40
time = 476.11 secondes

Train loss 0.08980626681439609 accuracy 0.980455756187439 macro_avg {'precision': 0.9795998189242281, 'recall': 0.979604220809508, 'f1-score': 0.9795927062112714, 'support': 10182} weighted_avg {'precision': 0.9804728958930987, 'recall': 0.9804557061481045, 'f1-score': 0.9804549758499381, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.8969723584669852 accuracy 0.8895759582519531 macro_avg {'precision': 0.8922436621638152, 'recall': 0.8912214320652373, 'f1-score': 0.8895649057737479, 'support': 1132} weighted_avg {'precision': 0.8935681143745808, 'recall': 0.8895759717314488, 'f1-score': 0.8893378676623295, 'support': 1132}
 
----------
Epoch 14/40
time = 475.84 secondes

Train loss 0.10348619175381762 accuracy 0.9797682762145996 macro_avg {'precision': 0.9789901199294879, 'recall': 0.9787463913066874, 'f1-score': 0.9788377776155285, 'support': 10182} weighted_avg {'precision': 0.9798523975319084, 'recall': 0.979768218424671, 'f1-score': 0.979779436900201, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9059342153333079 accuracy 0.8754417300224304 macro_avg {'precision': 0.8778813571448472, 'recall': 0.877441965291202, 'f1-score': 0.8741509322557416, 'support': 1132} weighted_avg {'precision': 0.8851415609220239, 'recall': 0.8754416961130742, 'f1-score': 0.8771474591746815, 'support': 1132}
 
----------
Epoch 15/40
time = 476.03 secondes

Train loss 0.08314088314661176 accuracy 0.9836967587471008 macro_avg {'precision': 0.9832150597916243, 'recall': 0.9831992157949017, 'f1-score': 0.983199031298537, 'support': 10182} weighted_avg {'precision': 0.9837254619249084, 'recall': 0.9836967197014339, 'f1-score': 0.9837026716596627, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.9432870343968627 accuracy 0.8780918717384338 macro_avg {'precision': 0.8845226477766779, 'recall': 0.8791886345536408, 'f1-score': 0.8780385805480032, 'support': 1132} weighted_avg {'precision': 0.8873804611747138, 'recall': 0.8780918727915195, 'f1-score': 0.8791053029753878, 'support': 1132}
 
----------
Epoch 16/40
time = 476.35 secondes

Train loss 0.0940445225161075 accuracy 0.982518196105957 macro_avg {'precision': 0.9817548134222344, 'recall': 0.9816643902481731, 'f1-score': 0.9816593986344646, 'support': 10182} weighted_avg {'precision': 0.9826808035717151, 'recall': 0.9825181693184051, 'f1-score': 0.9825537198533938, 'support': 10182}
 
time = 18.84 secondes

Val loss 0.9672756871394239 accuracy 0.8789752721786499 macro_avg {'precision': 0.8884270418708559, 'recall': 0.8825164724944143, 'f1-score': 0.88057735833649, 'support': 1132} weighted_avg {'precision': 0.8906840871781373, 'recall': 0.8789752650176679, 'f1-score': 0.8797962694336531, 'support': 1132}
 
----------
Epoch 17/40
time = 476.65 secondes

Train loss 0.0818525345824826 accuracy 0.9848753213882446 macro_avg {'precision': 0.9849107728893282, 'recall': 0.9847533387775153, 'f1-score': 0.9848087326962881, 'support': 10182} weighted_avg {'precision': 0.9849143428672977, 'recall': 0.9848752700844627, 'f1-score': 0.9848711988006121, 'support': 10182}
 
time = 16.81 secondes

Val loss 0.8446089303164831 accuracy 0.8939929604530334 macro_avg {'precision': 0.9006322439249818, 'recall': 0.8984693505945536, 'f1-score': 0.895063622639484, 'support': 1132} weighted_avg {'precision': 0.901506280142878, 'recall': 0.8939929328621908, 'f1-score': 0.8927643861731265, 'support': 1132}
 
----------
Epoch 18/40
time = 476.49 secondes

Train loss 0.08235502529404037 accuracy 0.9848753213882446 macro_avg {'precision': 0.9843885036380129, 'recall': 0.9848336893572034, 'f1-score': 0.9845820441279723, 'support': 10182} weighted_avg {'precision': 0.9848976904712462, 'recall': 0.9848752700844627, 'f1-score': 0.9848594575484368, 'support': 10182}
 
time = 16.90 secondes

Val loss 0.8545968070694714 accuracy 0.8904593586921692 macro_avg {'precision': 0.8956289533222371, 'recall': 0.8935548211794837, 'f1-score': 0.8913272082898652, 'support': 1132} weighted_avg {'precision': 0.8996540634020332, 'recall': 0.8904593639575972, 'f1-score': 0.8916909484994318, 'support': 1132}
 
----------
Epoch 19/40
time = 476.27 secondes

Train loss 0.06282364381961082 accuracy 0.9881163239479065 macro_avg {'precision': 0.9875385327508319, 'recall': 0.9876985328735055, 'f1-score': 0.987598871641884, 'support': 10182} weighted_avg {'precision': 0.9881654007767301, 'recall': 0.9881162836377921, 'f1-score': 0.988122278611521, 'support': 10182}
 
time = 16.82 secondes

Val loss 0.8057548724572767 accuracy 0.8922261595726013 macro_avg {'precision': 0.8977223620467759, 'recall': 0.8933680720438512, 'f1-score': 0.8928635548307208, 'support': 1132} weighted_avg {'precision': 0.8974182953616768, 'recall': 0.892226148409894, 'f1-score': 0.892260650990808, 'support': 1132}
 
----------
Epoch 20/40
time = 476.61 secondes

Train loss 0.052562987162582 accuracy 0.98978590965271 macro_avg {'precision': 0.9891761708337553, 'recall': 0.9892604113527611, 'f1-score': 0.9892034050464359, 'support': 10182} weighted_avg {'precision': 0.9898173625653797, 'recall': 0.9897858966804164, 'f1-score': 0.9897878889952575, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.9763796942340929 accuracy 0.8745583295822144 macro_avg {'precision': 0.8959231728469849, 'recall': 0.8823246687327038, 'f1-score': 0.8784921639339665, 'support': 1132} weighted_avg {'precision': 0.9024436496660545, 'recall': 0.8745583038869258, 'f1-score': 0.8774899066285587, 'support': 1132}
 
----------
Epoch 21/40
time = 476.40 secondes

Train loss 0.07425018755057125 accuracy 0.9866431355476379 macro_avg {'precision': 0.9865689620766265, 'recall': 0.986778149810112, 'f1-score': 0.986658241498629, 'support': 10182} weighted_avg {'precision': 0.9866694270713218, 'recall': 0.9866430956590061, 'f1-score': 0.9866419029432296, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.8224266537015891 accuracy 0.8913427591323853 macro_avg {'precision': 0.8970380007732738, 'recall': 0.8939182246500144, 'f1-score': 0.8925762853483103, 'support': 1132} weighted_avg {'precision': 0.8982436703140954, 'recall': 0.8913427561837456, 'f1-score': 0.8918994657342718, 'support': 1132}
 
----------
Epoch 22/40
time = 476.26 secondes

Train loss 0.05776682668380844 accuracy 0.9899823665618896 macro_avg {'precision': 0.9898832208283483, 'recall': 0.9898323684349215, 'f1-score': 0.9898448652004305, 'support': 10182} weighted_avg {'precision': 0.9899877544583315, 'recall': 0.9899823217442546, 'f1-score': 0.9899717822955614, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8461720995633378 accuracy 0.8939929604530334 macro_avg {'precision': 0.9015471875027007, 'recall': 0.8932644188617118, 'f1-score': 0.8927044858621975, 'support': 1132} weighted_avg {'precision': 0.9017710974474212, 'recall': 0.8939929328621908, 'f1-score': 0.8937859038335254, 'support': 1132}
 
----------
Epoch 23/40
time = 476.22 secondes

Train loss 0.04697093484487074 accuracy 0.9911609292030334 macro_avg {'precision': 0.9910013300213396, 'recall': 0.9910493216952705, 'f1-score': 0.9910115989662931, 'support': 10182} weighted_avg {'precision': 0.9911955383611514, 'recall': 0.9911608721272834, 'f1-score': 0.9911641665669635, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.7270659135557112 accuracy 0.9028268456459045 macro_avg {'precision': 0.9062091506547768, 'recall': 0.904765264201895, 'f1-score': 0.904517030128479, 'support': 1132} weighted_avg {'precision': 0.9059847331977929, 'recall': 0.9028268551236749, 'f1-score': 0.9034375725753206, 'support': 1132}
 
----------
Epoch 24/40
time = 476.30 secondes

Train loss 0.05323730014505181 accuracy 0.9914555549621582 macro_avg {'precision': 0.9911679139192643, 'recall': 0.9910527066005498, 'f1-score': 0.9910947134898889, 'support': 10182} weighted_avg {'precision': 0.9914771992689536, 'recall': 0.9914555097230406, 'f1-score': 0.9914527204680895, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8383258971479732 accuracy 0.8957597017288208 macro_avg {'precision': 0.9025643848897058, 'recall': 0.8990701955651718, 'f1-score': 0.8976995556023345, 'support': 1132} weighted_avg {'precision': 0.9017608386305206, 'recall': 0.8957597173144877, 'f1-score': 0.8956881652653363, 'support': 1132}
 
----------
Epoch 25/40
time = 476.33 secondes

Train loss 0.049769247696713995 accuracy 0.9921430349349976 macro_avg {'precision': 0.9922156831705223, 'recall': 0.9922917962845117, 'f1-score': 0.9922432922975473, 'support': 10182} weighted_avg {'precision': 0.9921478885978211, 'recall': 0.9921429974464742, 'f1-score': 0.9921349017016393, 'support': 10182}
 
time = 16.90 secondes

Val loss 1.2118418849469736 accuracy 0.8639575839042664 macro_avg {'precision': 0.8784330995646729, 'recall': 0.8666925028105087, 'f1-score': 0.8664674732898282, 'support': 1132} weighted_avg {'precision': 0.881337250102642, 'recall': 0.8639575971731449, 'f1-score': 0.8664615583449901, 'support': 1132}
 
----------
Epoch 26/40
time = 476.35 secondes

Train loss 0.04962862467934944 accuracy 0.991750180721283 macro_avg {'precision': 0.9908647049469523, 'recall': 0.9911753156672493, 'f1-score': 0.9909945533362012, 'support': 10182} weighted_avg {'precision': 0.9917978212614529, 'recall': 0.9917501473187978, 'f1-score': 0.991754284990792, 'support': 10182}
 
time = 17.10 secondes

Val loss 0.9946132900272652 accuracy 0.8780918717384338 macro_avg {'precision': 0.886844770451769, 'recall': 0.880248149772868, 'f1-score': 0.8784473175089064, 'support': 1132} weighted_avg {'precision': 0.890620579613345, 'recall': 0.8780918727915195, 'f1-score': 0.8802463425347955, 'support': 1132}
 
----------
Epoch 27/40
time = 476.24 secondes

Train loss 0.037443653197178337 accuracy 0.9928305149078369 macro_avg {'precision': 0.9923604881152501, 'recall': 0.9925993536713094, 'f1-score': 0.9924711511501763, 'support': 10182} weighted_avg {'precision': 0.992858005407245, 'recall': 0.9928304851699077, 'f1-score': 0.992835871514283, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8570922745954742 accuracy 0.8966431021690369 macro_avg {'precision': 0.8997127327141022, 'recall': 0.9016370238578795, 'f1-score': 0.8988682934835366, 'support': 1132} weighted_avg {'precision': 0.9010992175565485, 'recall': 0.8966431095406361, 'f1-score': 0.896947512131109, 'support': 1132}
 
----------
Epoch 28/40
time = 476.34 secondes

Train loss 0.043723354749204725 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919919339144008, 'recall': 0.9920220277396986, 'f1-score': 0.9920011773727777, 'support': 10182} weighted_avg {'precision': 0.9920538260037121, 'recall': 0.9920447849145551, 'f1-score': 0.9920434542402128, 'support': 10182}
 
time = 16.76 secondes

Val loss 0.8313640775060622 accuracy 0.898409903049469 macro_avg {'precision': 0.9061009294875714, 'recall': 0.9015306506607855, 'f1-score': 0.9021619417995221, 'support': 1132} weighted_avg {'precision': 0.9025417665778662, 'recall': 0.8984098939929329, 'f1-score': 0.8987797359314919, 'support': 1132}
 
----------
Epoch 29/40
time = 476.24 secondes

Train loss 0.031085909932283513 accuracy 0.9941073060035706 macro_avg {'precision': 0.9940725275169824, 'recall': 0.9941480105977402, 'f1-score': 0.9941061328427813, 'support': 10182} weighted_avg {'precision': 0.994114057034208, 'recall': 0.9941072480848556, 'f1-score': 0.9941066487754239, 'support': 10182}
 
time = 16.17 secondes

Val loss 0.992737110735132 accuracy 0.8886925578117371 macro_avg {'precision': 0.9009585520205844, 'recall': 0.8863641622063806, 'f1-score': 0.8886403409719144, 'support': 1132} weighted_avg {'precision': 0.8995411403023295, 'recall': 0.8886925795053003, 'f1-score': 0.8899843997219234, 'support': 1132}
 
----------
Epoch 30/40
time = 476.58 secondes

Train loss 0.03888092267498481 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934250948877779, 'recall': 0.9934886079499444, 'f1-score': 0.9934468610963197, 'support': 10182} weighted_avg {'precision': 0.9940202929890849, 'recall': 0.9940090355529365, 'f1-score': 0.9940050584084523, 'support': 10182}
 
time = 16.68 secondes

Val loss 0.886118140636337 accuracy 0.8922261595726013 macro_avg {'precision': 0.9006095908515904, 'recall': 0.8950692334630697, 'f1-score': 0.8936173151022802, 'support': 1132} weighted_avg {'precision': 0.8996652193836726, 'recall': 0.892226148409894, 'f1-score': 0.8920199450739377, 'support': 1132}
 
----------
Epoch 31/40
time = 476.22 secondes

Train loss 0.028713607613170544 accuracy 0.994892954826355 macro_avg {'precision': 0.9946646465126282, 'recall': 0.9946425407239985, 'f1-score': 0.9946491755579986, 'support': 10182} weighted_avg {'precision': 0.9949013888135394, 'recall': 0.9948929483402082, 'f1-score': 0.994892985163133, 'support': 10182}
 
time = 16.89 secondes

Val loss 0.8772494216123883 accuracy 0.9081271886825562 macro_avg {'precision': 0.9166574954576159, 'recall': 0.9118808200266096, 'f1-score': 0.9125847218581361, 'support': 1132} weighted_avg {'precision': 0.9127131316103466, 'recall': 0.9081272084805654, 'f1-score': 0.9087118330973951, 'support': 1132}
 
----------
Epoch 32/40
time = 476.12 secondes

Train loss 0.038586022712079684 accuracy 0.9936162233352661 macro_avg {'precision': 0.9937714285862491, 'recall': 0.9936985801093063, 'f1-score': 0.993728398576048, 'support': 10182} weighted_avg {'precision': 0.9936375960701547, 'recall': 0.9936161854252603, 'f1-score': 0.9936201772640636, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8376955747209368 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126703005774628, 'recall': 0.91050410830889, 'f1-score': 0.9106161324321006, 'support': 1132} weighted_avg {'precision': 0.9103768495176995, 'recall': 0.9081272084805654, 'f1-score': 0.9082280056250128, 'support': 1132}
 
----------
Epoch 33/40
time = 477.06 secondes

Train loss 0.022106994634426086 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960348085684627, 'recall': 0.9959239975075697, 'f1-score': 0.9959766413322289, 'support': 10182} weighted_avg {'precision': 0.9960763174345807, 'recall': 0.9960714987232371, 'f1-score': 0.9960714828076999, 'support': 10182}
 
time = 16.86 secondes

Val loss 0.8938071656801595 accuracy 0.9054770469665527 macro_avg {'precision': 0.9089023322543677, 'recall': 0.907206830352122, 'f1-score': 0.9062887458539539, 'support': 1132} weighted_avg {'precision': 0.9098721753018832, 'recall': 0.9054770318021201, 'f1-score': 0.9059075922778872, 'support': 1132}
 
----------
Epoch 34/40
time = 476.11 secondes

Train loss 0.02002061514667016 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963586041890611, 'recall': 0.9963882587223306, 'f1-score': 0.9963660536643802, 'support': 10182} weighted_avg {'precision': 0.9962904601872715, 'recall': 0.9962679237870752, 'f1-score': 0.9962715798892713, 'support': 10182}
 
time = 16.54 secondes

Val loss 0.9732385666069296 accuracy 0.8939929604530334 macro_avg {'precision': 0.9024351907424117, 'recall': 0.8994889048217717, 'f1-score': 0.8971986517749485, 'support': 1132} weighted_avg {'precision': 0.9046193260034942, 'recall': 0.8939929328621908, 'f1-score': 0.8956300749622467, 'support': 1132}
 
----------
Epoch 35/40
time = 476.38 secondes

Train loss 0.015641405498072445 accuracy 0.9970536828041077 macro_avg {'precision': 0.997186663684358, 'recall': 0.997134246896984, 'f1-score': 0.9971470633025602, 'support': 10182} weighted_avg {'precision': 0.9970814979283738, 'recall': 0.9970536240424278, 'f1-score': 0.9970537399642208, 'support': 10182}
 
time = 16.93 secondes

Val loss 0.8120080086814148 accuracy 0.9116607904434204 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}
 
----------
Epoch 36/40
time = 476.52 secondes

Train loss 0.015949043090050786 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975256556069297, 'recall': 0.9973727067699185, 'f1-score': 0.9974413372715596, 'support': 10182} weighted_avg {'precision': 0.9975572648351069, 'recall': 0.9975446867020232, 'f1-score': 0.9975438718809831, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9054440364443636 accuracy 0.9054770469665527 macro_avg {'precision': 0.9098100446437348, 'recall': 0.908338583070797, 'f1-score': 0.9079247398369761, 'support': 1132} weighted_avg {'precision': 0.909363568992873, 'recall': 0.9054770318021201, 'f1-score': 0.9062233633137983, 'support': 1132}
 
----------
Epoch 37/40
time = 476.33 secondes

Train loss 0.0065117422103141975 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986604452327945, 'recall': 0.9986403734244002, 'f1-score': 0.9986495940363275, 'support': 10182} weighted_avg {'precision': 0.9987247312286821, 'recall': 0.9987232370850521, 'f1-score': 0.9987231987033319, 'support': 10182}
 
time = 16.92 secondes

Val loss 0.9217688095203697 accuracy 0.9010601043701172 macro_avg {'precision': 0.9029670784735023, 'recall': 0.9040157579397295, 'f1-score': 0.9018182850077678, 'support': 1132} weighted_avg {'precision': 0.9056168332215249, 'recall': 0.901060070671378, 'f1-score': 0.9017167851383562, 'support': 1132}
 
----------
Epoch 38/40
time = 476.60 secondes

Train loss 0.009076425064661034 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986561952378381, 'recall': 0.9987010040805717, 'f1-score': 0.9986767750580696, 'support': 10182} weighted_avg {'precision': 0.9987254040347094, 'recall': 0.9987232370850521, 'f1-score': 0.9987224450350004, 'support': 10182}
 
time = 17.19 secondes

Val loss 1.1009912460943616 accuracy 0.8904593586921692 macro_avg {'precision': 0.8930635853249503, 'recall': 0.8951290034856629, 'f1-score': 0.8915758679621119, 'support': 1132} weighted_avg {'precision': 0.8973040338994697, 'recall': 0.8904593639575972, 'f1-score': 0.8914447556334754, 'support': 1132}
 
----------
Epoch 39/40
time = 476.36 secondes

Train loss 0.004712479369310978 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992373015787427, 'recall': 0.9992411211620341, 'f1-score': 0.9992389826265702, 'support': 10182} weighted_avg {'precision': 0.9993127050759184, 'recall': 0.9993125122765665, 'f1-score': 0.9993123996889289, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.9440119815970601 accuracy 0.8992933034896851 macro_avg {'precision': 0.9043786351635557, 'recall': 0.9034703667960795, 'f1-score': 0.901970580444825, 'support': 1132} weighted_avg {'precision': 0.904949066983656, 'recall': 0.8992932862190812, 'f1-score': 0.8999977322225842, 'support': 1132}
 
----------
Epoch 40/40
time = 476.27 secondes

Train loss 0.0029121377023918088 accuracy 0.9994107484817505 macro_avg {'precision': 0.999418394131815, 'recall': 0.9993780990979012, 'f1-score': 0.9993977770860285, 'support': 10182} weighted_avg {'precision': 0.9994115870018708, 'recall': 0.9994107248084856, 'f1-score': 0.9994106819482753, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9745304558480609 accuracy 0.9001767039299011 macro_avg {'precision': 0.9058208282388479, 'recall': 0.9037579696344862, 'f1-score': 0.902814940267515, 'support': 1132} weighted_avg {'precision': 0.9059259916519704, 'recall': 0.9001766784452296, 'f1-score': 0.900934748385834, 'support': 1132}
 
----------
best_accuracy 0.9116607904434204 best_epoch 35 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}

average train time 476.2516987025738

average val time 17.631594270467758
 
time = 107.53 secondes

test_accuracy 0.8348379731178284 macro_avg {'precision': 0.8316073449511627, 'recall': 0.8290983707098822, 'f1-score': 0.8284636763392512, 'support': 7532} weighted_avg {'precision': 0.8375247937439214, 'recall': 0.8348380244291025, 'f1-score': 0.8343998913511087, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_1
----------
Epoch 1/40
time = 1922.63 secondes

Train loss 1.3563601410650945 accuracy 0.6342565417289734 macro_avg {'precision': 0.6311249056630124, 'recall': 0.6183001475305336, 'f1-score': 0.6069341533632095, 'support': 10182} weighted_avg {'precision': 0.6394093685392014, 'recall': 0.6342565311333727, 'f1-score': 0.6219575282769404, 'support': 10182}
 
time = 52.82 secondes

Val loss 0.7800213056550899 accuracy 0.7614840865135193 macro_avg {'precision': 0.7543278013263962, 'recall': 0.7587375685957276, 'f1-score': 0.7454669955773282, 'support': 1132} weighted_avg {'precision': 0.7669285197252486, 'recall': 0.7614840989399293, 'f1-score': 0.7520640590829529, 'support': 1132}
 
----------
Epoch 2/40
time = 1917.88 secondes

Train loss 0.5498222497231919 accuracy 0.8326458930969238 macro_avg {'precision': 0.8194822777281006, 'recall': 0.8198686414206552, 'f1-score': 0.8160250599070608, 'support': 10182} weighted_avg {'precision': 0.8289016402609096, 'recall': 0.8326458456098998, 'f1-score': 0.8281176786290024, 'support': 10182}
 
time = 53.45 secondes

Val loss 0.6661390110220707 accuracy 0.7959364056587219 macro_avg {'precision': 0.8078255781927763, 'recall': 0.79421757987355, 'f1-score': 0.7926226676191326, 'support': 1132} weighted_avg {'precision': 0.8157289939906799, 'recall': 0.7959363957597173, 'f1-score': 0.7967029108383243, 'support': 1132}
 
----------
Epoch 3/40
time = 1921.35 secondes

Train loss 0.32057227810707345 accuracy 0.9056177735328674 macro_avg {'precision': 0.9001688138780143, 'recall': 0.8995811872248136, 'f1-score': 0.8996746042331776, 'support': 10182} weighted_avg {'precision': 0.9056635843204324, 'recall': 0.905617756825771, 'f1-score': 0.9054525271801049, 'support': 10182}
 
time = 53.00 secondes

Val loss 0.5940035742930543 accuracy 0.851590096950531 macro_avg {'precision': 0.8549678790264492, 'recall': 0.8489949452380243, 'f1-score': 0.8491355095612892, 'support': 1132} weighted_avg {'precision': 0.8529812738975073, 'recall': 0.8515901060070671, 'f1-score': 0.8495391534753041, 'support': 1132}
 
----------
Epoch 4/40
time = 1923.23 secondes

Train loss 0.22492251191449059 accuracy 0.9388136267662048 macro_avg {'precision': 0.9351679169472039, 'recall': 0.9348968995233135, 'f1-score': 0.9349479551161674, 'support': 10182} weighted_avg {'precision': 0.9390748474958273, 'recall': 0.9388135926144175, 'f1-score': 0.9388596497932974, 'support': 10182}
 
time = 52.26 secondes

Val loss 0.6839744140931838 accuracy 0.8454063534736633 macro_avg {'precision': 0.8578191346968701, 'recall': 0.8419427275782103, 'f1-score': 0.8434235817190616, 'support': 1132} weighted_avg {'precision': 0.8564730236320933, 'recall': 0.8454063604240283, 'f1-score': 0.8446783177814201, 'support': 1132}
 
----------
Epoch 5/40
time = 1922.14 secondes

Train loss 0.16780832892881772 accuracy 0.9569829106330872 macro_avg {'precision': 0.9544422617033348, 'recall': 0.9543776813274839, 'f1-score': 0.9543436729105828, 'support': 10182} weighted_avg {'precision': 0.957082899244578, 'recall': 0.9569829110194461, 'f1-score': 0.956971829480186, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.7324177780267324 accuracy 0.862190842628479 macro_avg {'precision': 0.8700550486432188, 'recall': 0.862658951325076, 'f1-score': 0.8618377666814778, 'support': 1132} weighted_avg {'precision': 0.873109662625358, 'recall': 0.8621908127208481, 'f1-score': 0.8630627353570113, 'support': 1132}
 
----------
Epoch 6/40
time = 1923.40 secondes

Train loss 0.15209646134844176 accuracy 0.9624828696250916 macro_avg {'precision': 0.960568671406927, 'recall': 0.9608502644411872, 'f1-score': 0.9606605022504654, 'support': 10182} weighted_avg {'precision': 0.9625860675937754, 'recall': 0.9624828128069142, 'f1-score': 0.9624869699524449, 'support': 10182}
 
time = 53.30 secondes

Val loss 0.7910824491098051 accuracy 0.8630741834640503 macro_avg {'precision': 0.8739048415669337, 'recall': 0.8649658670323206, 'f1-score': 0.8652424836198026, 'support': 1132} weighted_avg {'precision': 0.8734628770828299, 'recall': 0.8630742049469965, 'f1-score': 0.864391520109176, 'support': 1132}
 
----------
Epoch 7/40
time = 1919.33 secondes

Train loss 0.13056213132912087 accuracy 0.9688666462898254 macro_avg {'precision': 0.9679842675373426, 'recall': 0.9678890453720749, 'f1-score': 0.9679058774256072, 'support': 10182} weighted_avg {'precision': 0.9688315105119321, 'recall': 0.9688666273816539, 'f1-score': 0.9688183985908866, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.8152730234924861 accuracy 0.8586572408676147 macro_avg {'precision': 0.8618898470234162, 'recall': 0.8578494890896333, 'f1-score': 0.8564586708214851, 'support': 1132} weighted_avg {'precision': 0.8626374034537093, 'recall': 0.8586572438162544, 'f1-score': 0.8569071639887107, 'support': 1132}
 
----------
Epoch 8/40
time = 1921.80 secondes

Train loss 0.11953015721076295 accuracy 0.9719112515449524 macro_avg {'precision': 0.9708811688815364, 'recall': 0.970867716324298, 'f1-score': 0.9708578367637344, 'support': 10182} weighted_avg {'precision': 0.9719537730489218, 'recall': 0.9719112158711452, 'f1-score': 0.9719167378769186, 'support': 10182}
 
time = 47.72 secondes

Val loss 0.723524037891225 accuracy 0.870141327381134 macro_avg {'precision': 0.8746950269223799, 'recall': 0.8721629700856346, 'f1-score': 0.8711095389842092, 'support': 1132} weighted_avg {'precision': 0.8719913764890239, 'recall': 0.8701413427561837, 'f1-score': 0.86854589786337, 'support': 1132}
 
----------
Epoch 9/40
time = 1918.96 secondes

Train loss 0.13171000592310048 accuracy 0.972304105758667 macro_avg {'precision': 0.9717382670856548, 'recall': 0.9712567131204042, 'f1-score': 0.9714287478747371, 'support': 10182} weighted_avg {'precision': 0.9723688042388928, 'recall': 0.9723040659988215, 'f1-score': 0.9722685409838638, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.9472246942312037 accuracy 0.8613074421882629 macro_avg {'precision': 0.8645305687267678, 'recall': 0.8658064686955044, 'f1-score': 0.8625773274148827, 'support': 1132} weighted_avg {'precision': 0.8679684289177609, 'recall': 0.8613074204946997, 'f1-score': 0.8621420085395792, 'support': 1132}
 
----------
Epoch 10/40
time = 1923.81 secondes

Train loss 0.11088613241697476 accuracy 0.9764290452003479 macro_avg {'precision': 0.9752179625554758, 'recall': 0.9757292537258643, 'f1-score': 0.9754248844175107, 'support': 10182} weighted_avg {'precision': 0.9765642114085306, 'recall': 0.9764289923394225, 'f1-score': 0.9764529073533446, 'support': 10182}
 
time = 53.15 secondes

Val loss 0.9061960216282053 accuracy 0.8630741834640503 macro_avg {'precision': 0.8696380771859384, 'recall': 0.8629405265607378, 'f1-score': 0.8641900206670261, 'support': 1132} weighted_avg {'precision': 0.8670442748293664, 'recall': 0.8630742049469965, 'f1-score': 0.8629459112608805, 'support': 1132}
 
----------
Epoch 11/40
time = 1926.41 secondes

Train loss 0.12593862606340242 accuracy 0.9740719199180603 macro_avg {'precision': 0.97320767702232, 'recall': 0.9730492711817892, 'f1-score': 0.9730752685218379, 'support': 10182} weighted_avg {'precision': 0.9741435792867559, 'recall': 0.9740718915733647, 'f1-score': 0.9740558624456227, 'support': 10182}
 
time = 52.65 secondes

Val loss 0.988449477814638 accuracy 0.8586572408676147 macro_avg {'precision': 0.8704122690058755, 'recall': 0.862907702325314, 'f1-score': 0.8612213325199256, 'support': 1132} weighted_avg {'precision': 0.8731343707645367, 'recall': 0.8586572438162544, 'f1-score': 0.8603554732585362, 'support': 1132}
 
----------
Epoch 12/40
time = 1925.91 secondes

Train loss 0.09780363976829587 accuracy 0.9790807366371155 macro_avg {'precision': 0.9789912996390843, 'recall': 0.9786940928669632, 'f1-score': 0.9788103392987646, 'support': 10182} weighted_avg {'precision': 0.9791057645519969, 'recall': 0.9790807307012375, 'f1-score': 0.9790608398837547, 'support': 10182}
 
time = 53.57 secondes

Val loss 0.9447666060695552 accuracy 0.8692579865455627 macro_avg {'precision': 0.8822035510822925, 'recall': 0.870140490982644, 'f1-score': 0.8715210373253462, 'support': 1132} weighted_avg {'precision': 0.8796936638294879, 'recall': 0.8692579505300353, 'f1-score': 0.8696165541610031, 'support': 1132}
 
----------
Epoch 13/40
time = 1925.57 secondes

Train loss 0.09539037328187867 accuracy 0.9821253418922424 macro_avg {'precision': 0.9819608823115014, 'recall': 0.9816884186048762, 'f1-score': 0.9817998872982969, 'support': 10182} weighted_avg {'precision': 0.9821601583233321, 'recall': 0.9821253191907288, 'f1-score': 0.9821184038666043, 'support': 10182}
 
time = 45.94 secondes

Val loss 1.0016799879794889 accuracy 0.8586572408676147 macro_avg {'precision': 0.8684059091195225, 'recall': 0.8608938541306881, 'f1-score': 0.860962575838778, 'support': 1132} weighted_avg {'precision': 0.8701210110355243, 'recall': 0.8586572438162544, 'f1-score': 0.8611124521960787, 'support': 1132}
 
----------
Epoch 14/40
time = 1926.82 secondes

Train loss 0.11129338205935016 accuracy 0.9789825677871704 macro_avg {'precision': 0.9784174033921422, 'recall': 0.9785844470958601, 'f1-score': 0.9784459855069632, 'support': 10182} weighted_avg {'precision': 0.9790609670846595, 'recall': 0.9789825181693184, 'f1-score': 0.9789691467485602, 'support': 10182}
 
time = 52.47 secondes

Val loss 0.9710275931283832 accuracy 0.8780918717384338 macro_avg {'precision': 0.8846317515333902, 'recall': 0.8787632844145318, 'f1-score': 0.8792075248447777, 'support': 1132} weighted_avg {'precision': 0.8832890099271713, 'recall': 0.8780918727915195, 'f1-score': 0.8782152057655278, 'support': 1132}
 
----------
Epoch 15/40
time = 1924.49 secondes

Train loss 0.08928665776178807 accuracy 0.98448246717453 macro_avg {'precision': 0.9839703015806924, 'recall': 0.9836706278261932, 'f1-score': 0.9837949825103255, 'support': 10182} weighted_avg {'precision': 0.9844939578968811, 'recall': 0.9844824199567865, 'f1-score': 0.9844649200208041, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.8860850506654816 accuracy 0.8736749291419983 macro_avg {'precision': 0.8755093733853874, 'recall': 0.8773560619391303, 'f1-score': 0.8736251287469301, 'support': 1132} weighted_avg {'precision': 0.8807208340134238, 'recall': 0.8736749116607774, 'f1-score': 0.8747173575783868, 'support': 1132}
 
----------
Epoch 16/40
time = 1923.23 secondes

Train loss 0.07685961915589277 accuracy 0.9863485097885132 macro_avg {'precision': 0.9863689821094754, 'recall': 0.9864582943156721, 'f1-score': 0.9864041617136952, 'support': 10182} weighted_avg {'precision': 0.9863482048486378, 'recall': 0.9863484580632489, 'f1-score': 0.9863388154446698, 'support': 10182}
 
time = 53.15 secondes

Val loss 1.0277355745044114 accuracy 0.862190842628479 macro_avg {'precision': 0.8685718206044944, 'recall': 0.8659779453270373, 'f1-score': 0.8640419867507088, 'support': 1132} weighted_avg {'precision': 0.869050366035999, 'recall': 0.8621908127208481, 'f1-score': 0.8622182386974463, 'support': 1132}
 
----------
Epoch 17/40
time = 1923.90 secondes

Train loss 0.07368812286173693 accuracy 0.9861520528793335 macro_avg {'precision': 0.9862564145756009, 'recall': 0.9860893933386711, 'f1-score': 0.9861586219834747, 'support': 10182} weighted_avg {'precision': 0.9861647238005923, 'recall': 0.9861520329994107, 'f1-score': 0.9861442141611498, 'support': 10182}
 
time = 52.52 secondes

Val loss 0.8700165179774123 accuracy 0.8869258165359497 macro_avg {'precision': 0.8931426906995149, 'recall': 0.8876121128460899, 'f1-score': 0.8884694447619121, 'support': 1132} weighted_avg {'precision': 0.8935023600343338, 'recall': 0.8869257950530035, 'f1-score': 0.8884043120449301, 'support': 1132}
 
----------
Epoch 18/40
time = 1924.82 secondes

Train loss 0.07652928455529173 accuracy 0.9865449070930481 macro_avg {'precision': 0.9863488721926548, 'recall': 0.9857695342716145, 'f1-score': 0.9860421402531097, 'support': 10182} weighted_avg {'precision': 0.9865619322924669, 'recall': 0.986544883127087, 'f1-score': 0.986538407053708, 'support': 10182}
 
time = 52.99 secondes

Val loss 0.9044486876418503 accuracy 0.8842756152153015 macro_avg {'precision': 0.8937313516046311, 'recall': 0.8858495780447873, 'f1-score': 0.8869339654307481, 'support': 1132} weighted_avg {'precision': 0.8935036054082099, 'recall': 0.8842756183745583, 'f1-score': 0.886007217329685, 'support': 1132}
 
----------
Epoch 19/40
time = 1926.83 secondes

Train loss 0.058053445491742496 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893489618120093, 'recall': 0.9892613929212845, 'f1-score': 0.9892885189261232, 'support': 10182} weighted_avg {'precision': 0.9894263616148029, 'recall': 0.9893930465527401, 'f1-score': 0.9893926587968289, 'support': 10182}
 
time = 53.42 secondes

Val loss 0.9706725447357084 accuracy 0.8772084712982178 macro_avg {'precision': 0.8814805948713327, 'recall': 0.879018767882501, 'f1-score': 0.877464054413893, 'support': 1132} weighted_avg {'precision': 0.8824810592201481, 'recall': 0.877208480565371, 'f1-score': 0.8771666246351415, 'support': 1132}
 
----------
Epoch 20/40
time = 1924.45 secondes

Train loss 0.06300680484962916 accuracy 0.9882145524024963 macro_avg {'precision': 0.9877677264913267, 'recall': 0.9880019096493753, 'f1-score': 0.9878743323204955, 'support': 10182} weighted_avg {'precision': 0.9882439270756346, 'recall': 0.9882144961697112, 'f1-score': 0.9882203170945527, 'support': 10182}
 
time = 53.21 secondes

Val loss 0.9521126986446816 accuracy 0.8780918717384338 macro_avg {'precision': 0.8798887704165328, 'recall': 0.8782878167631981, 'f1-score': 0.8777599651068119, 'support': 1132} weighted_avg {'precision': 0.8809338736239282, 'recall': 0.8780918727915195, 'f1-score': 0.878421345252993, 'support': 1132}
 
----------
Epoch 21/40
time = 1923.15 secondes

Train loss 0.07824257556795877 accuracy 0.9857591986656189 macro_avg {'precision': 0.985840597304418, 'recall': 0.984086487438633, 'f1-score': 0.9848382511506582, 'support': 10182} weighted_avg {'precision': 0.9859228773977913, 'recall': 0.9857591828717345, 'f1-score': 0.9857402985938656, 'support': 10182}
 
time = 52.70 secondes

Val loss 0.9927527360153068 accuracy 0.8772084712982178 macro_avg {'precision': 0.8835282917005148, 'recall': 0.8820352740659377, 'f1-score': 0.8804827005671392, 'support': 1132} weighted_avg {'precision': 0.8848160537524499, 'recall': 0.877208480565371, 'f1-score': 0.8787463172878207, 'support': 1132}
 
----------
Epoch 22/40
time = 1926.16 secondes

Train loss 0.05917944625622938 accuracy 0.9901787638664246 macro_avg {'precision': 0.9898743945996505, 'recall': 0.989740317913465, 'f1-score': 0.9897991293985544, 'support': 10182} weighted_avg {'precision': 0.9901890500679325, 'recall': 0.9901787468080927, 'f1-score': 0.9901759445840763, 'support': 10182}
 
time = 49.55 secondes

Val loss 0.9722528517900878 accuracy 0.8816254734992981 macro_avg {'precision': 0.8844381453628462, 'recall': 0.8849774814053759, 'f1-score': 0.8818433196642932, 'support': 1132} weighted_avg {'precision': 0.8893295059654718, 'recall': 0.8816254416961131, 'f1-score': 0.8826534818694257, 'support': 1132}
 
----------
Epoch 23/40
time = 1925.36 secondes

Train loss 0.05707894403375186 accuracy 0.9904733896255493 macro_avg {'precision': 0.9900934967659655, 'recall': 0.9903033550474338, 'f1-score': 0.9901789164534873, 'support': 10182} weighted_avg {'precision': 0.9905138277826692, 'recall': 0.9904733844038499, 'f1-score': 0.9904751217906759, 'support': 10182}
 
time = 50.76 secondes

Val loss 0.9718114211376507 accuracy 0.8719081282615662 macro_avg {'precision': 0.8833144234525211, 'recall': 0.8777655854007431, 'f1-score': 0.876947930317454, 'support': 1132} weighted_avg {'precision': 0.881913225723505, 'recall': 0.8719081272084805, 'f1-score': 0.8731597823037501, 'support': 1132}
 
----------
Epoch 24/40
time = 1925.71 secondes

Train loss 0.04441417406164952 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925075816579714, 'recall': 0.9925122621835454, 'f1-score': 0.9925008763457207, 'support': 10182} weighted_avg {'precision': 0.992449699274889, 'recall': 0.9924376350422314, 'f1-score': 0.9924343666725506, 'support': 10182}
 
time = 53.57 secondes

Val loss 1.007799237595361 accuracy 0.8745583295822144 macro_avg {'precision': 0.8799363695774852, 'recall': 0.8766669179769615, 'f1-score': 0.8763303706917125, 'support': 1132} weighted_avg {'precision': 0.8820500544723547, 'recall': 0.8745583038869258, 'f1-score': 0.876077307803354, 'support': 1132}
 
----------
Epoch 25/40
time = 1926.13 secondes

Train loss 0.04336232122994809 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915988010549031, 'recall': 0.99140053169114, 'f1-score': 0.9914934443229579, 'support': 10182} weighted_avg {'precision': 0.9919537961292039, 'recall': 0.9919465723826361, 'f1-score': 0.9919454015576321, 'support': 10182}
 
time = 53.25 secondes

Val loss 1.0714047893014422 accuracy 0.8763250708580017 macro_avg {'precision': 0.8803821672825437, 'recall': 0.8773740867016034, 'f1-score': 0.8761304546576433, 'support': 1132} weighted_avg {'precision': 0.8818467373045039, 'recall': 0.8763250883392226, 'f1-score': 0.8762557273842883, 'support': 1132}
 
----------
Epoch 26/40
time = 1926.06 secondes

Train loss 0.04405674952443004 accuracy 0.9920448064804077 macro_avg {'precision': 0.9917129657906509, 'recall': 0.9916486585460671, 'f1-score': 0.9916777101722516, 'support': 10182} weighted_avg {'precision': 0.9920473994322461, 'recall': 0.9920447849145551, 'f1-score': 0.9920429739459726, 'support': 10182}
 
time = 53.62 secondes

Val loss 0.9922698019086761 accuracy 0.8710247278213501 macro_avg {'precision': 0.8770376594655487, 'recall': 0.8725879163545269, 'f1-score': 0.8724271771412498, 'support': 1132} weighted_avg {'precision': 0.8779787702852488, 'recall': 0.8710247349823321, 'f1-score': 0.8720216575380861, 'support': 1132}
 
----------
Epoch 27/40
time = 1923.80 secondes

Train loss 0.04048159152341187 accuracy 0.993714451789856 macro_avg {'precision': 0.9930176239382298, 'recall': 0.99316472392157, 'f1-score': 0.9930853193862438, 'support': 10182} weighted_avg {'precision': 0.9937346682143964, 'recall': 0.9937143979571793, 'f1-score': 0.9937187122428861, 'support': 10182}
 
time = 51.45 secondes

Val loss 1.0452644777747402 accuracy 0.8683745861053467 macro_avg {'precision': 0.8766248069718794, 'recall': 0.8717888101025875, 'f1-score': 0.8661161066207091, 'support': 1132} weighted_avg {'precision': 0.8830330714568839, 'recall': 0.8683745583038869, 'f1-score': 0.8688581565330564, 'support': 1132}
 
----------
Epoch 28/40
time = 1929.63 secondes

Train loss 0.030535827016240573 accuracy 0.9942054748535156 macro_avg {'precision': 0.9937993440574834, 'recall': 0.9936505876274806, 'f1-score': 0.9937188787148183, 'support': 10182} weighted_avg {'precision': 0.9942101680466461, 'recall': 0.9942054606167747, 'f1-score': 0.9942021326525127, 'support': 10182}
 
time = 52.65 secondes

Val loss 1.0851200424765177 accuracy 0.8674911856651306 macro_avg {'precision': 0.8797832042382016, 'recall': 0.8692305690711069, 'f1-score': 0.8704689642891641, 'support': 1132} weighted_avg {'precision': 0.879810926535638, 'recall': 0.8674911660777385, 'f1-score': 0.8694007591733018, 'support': 1132}
 
----------
Epoch 29/40
time = 1925.39 secondes

Train loss 0.030600916608801675 accuracy 0.9945983290672302 macro_avg {'precision': 0.9942783728606294, 'recall': 0.9942634538467681, 'f1-score': 0.9942622562237384, 'support': 10182} weighted_avg {'precision': 0.9946120873584051, 'recall': 0.994598310744451, 'f1-score': 0.9945974359884104, 'support': 10182}
 
time = 51.39 secondes

Val loss 1.0528666132771654 accuracy 0.8789752721786499 macro_avg {'precision': 0.8813937472817669, 'recall': 0.8800530262753788, 'f1-score': 0.8781674462065501, 'support': 1132} weighted_avg {'precision': 0.8831588111594484, 'recall': 0.8789752650176679, 'f1-score': 0.8787804730826417, 'support': 1132}
 
----------
Epoch 30/40
time = 1923.95 secondes

Train loss 0.03010589234865757 accuracy 0.994892954826355 macro_avg {'precision': 0.9948017621494252, 'recall': 0.9948835609585036, 'f1-score': 0.9948398842379668, 'support': 10182} weighted_avg {'precision': 0.9949038204950252, 'recall': 0.9948929483402082, 'f1-score': 0.9948956174304118, 'support': 10182}
 
time = 53.18 secondes

Val loss 1.049861646002785 accuracy 0.8860424160957336 macro_avg {'precision': 0.8879239719981712, 'recall': 0.8898785262282825, 'f1-score': 0.8871081927103696, 'support': 1132} weighted_avg {'precision': 0.8903102616499255, 'recall': 0.8860424028268551, 'f1-score': 0.8862392747210929, 'support': 1132}
 
----------
Epoch 31/40
time = 1925.34 secondes

Train loss 0.031239954956912144 accuracy 0.9949911832809448 macro_avg {'precision': 0.9949259949187338, 'recall': 0.9949012063151168, 'f1-score': 0.9949056155895963, 'support': 10182} weighted_avg {'precision': 0.9950095092910202, 'recall': 0.9949911608721272, 'f1-score': 0.9949921864766119, 'support': 10182}
 
time = 51.59 secondes

Val loss 0.9067690765463032 accuracy 0.8816254734992981 macro_avg {'precision': 0.8900480519188705, 'recall': 0.8848260367040772, 'f1-score': 0.8848908093622733, 'support': 1132} weighted_avg {'precision': 0.8911637600368186, 'recall': 0.8816254416961131, 'f1-score': 0.8839344924266814, 'support': 1132}
 
----------
Epoch 32/40
time = 1924.65 secondes

Train loss 0.02606130519045532 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955498132941709, 'recall': 0.995574787569074, 'f1-score': 0.9955590027536465, 'support': 10182} weighted_avg {'precision': 0.995583354417422, 'recall': 0.9955804360636418, 'f1-score': 0.9955785276215163, 'support': 10182}
 
time = 47.48 secondes

Val loss 1.0529112987019225 accuracy 0.8860424160957336 macro_avg {'precision': 0.8909394111948714, 'recall': 0.888534480745846, 'f1-score': 0.8875710963744359, 'support': 1132} weighted_avg {'precision': 0.8912025951065586, 'recall': 0.8860424028268551, 'f1-score': 0.8863777126629514, 'support': 1132}
 
----------
Epoch 33/40
time = 1924.26 secondes

Train loss 0.019704478370709304 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959369396216406, 'recall': 0.9958711815793823, 'f1-score': 0.9958976668196142, 'support': 10182} weighted_avg {'precision': 0.9958892736588832, 'recall': 0.995875073659399, 'f1-score': 0.9958760532402782, 'support': 10182}
 
time = 52.87 secondes

Val loss 1.0400636622685904 accuracy 0.8851590156555176 macro_avg {'precision': 0.8911848613651605, 'recall': 0.8889798150428788, 'f1-score': 0.8877332855538261, 'support': 1132} weighted_avg {'precision': 0.8904328323813739, 'recall': 0.8851590106007067, 'f1-score': 0.8853210391553842, 'support': 1132}
 
----------
Epoch 34/40
time = 1925.76 secondes

Train loss 0.01887077924283185 accuracy 0.9965626001358032 macro_avg {'precision': 0.9966108245646031, 'recall': 0.9966706007732787, 'f1-score': 0.9966347272092528, 'support': 10182} weighted_avg {'precision': 0.9965741231950103, 'recall': 0.9965625613828325, 'f1-score': 0.9965621465340625, 'support': 10182}
 
time = 54.28 secondes

Val loss 1.0790454606800446 accuracy 0.879858672618866 macro_avg {'precision': 0.888118672919707, 'recall': 0.8833889789116706, 'f1-score': 0.883754840702724, 'support': 1132} weighted_avg {'precision': 0.8860430951362872, 'recall': 0.8798586572438163, 'f1-score': 0.8808052664943157, 'support': 1132}
 
----------
Epoch 35/40
time = 1926.79 secondes

Train loss 0.014778358710219654 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972162445227143, 'recall': 0.9972785872464612, 'f1-score': 0.9972443093858636, 'support': 10182} weighted_avg {'precision': 0.9973565146195259, 'recall': 0.997348261638185, 'f1-score': 0.9973493773789662, 'support': 10182}
 
time = 54.69 secondes

Val loss 1.0786697066205435 accuracy 0.8886925578117371 macro_avg {'precision': 0.8959009612291744, 'recall': 0.8899114974130269, 'f1-score': 0.8908720786253719, 'support': 1132} weighted_avg {'precision': 0.8946432941143623, 'recall': 0.8886925795053003, 'f1-score': 0.8894511111357427, 'support': 1132}
 
----------
Epoch 36/40
time = 1925.42 secondes

Train loss 0.01220237803720933 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974277131818313, 'recall': 0.9974008406522369, 'f1-score': 0.9974062434480224, 'support': 10182} weighted_avg {'precision': 0.9973678705435329, 'recall': 0.997348261638185, 'f1-score': 0.9973499140052285, 'support': 10182}
 
time = 52.76 secondes

Val loss 1.0539087854689517 accuracy 0.8939929604530334 macro_avg {'precision': 0.8958798770744021, 'recall': 0.8981414944716875, 'f1-score': 0.8952873443112443, 'support': 1132} weighted_avg {'precision': 0.8971607431497904, 'recall': 0.8939929328621908, 'f1-score': 0.8937159348690917, 'support': 1132}
 
----------
Epoch 37/40
time = 1926.21 secondes

Train loss 0.009664884859855623 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984908428383779, 'recall': 0.9983198279417973, 'f1-score': 0.998402181345482, 'support': 10182} weighted_avg {'precision': 0.9984330610506704, 'recall': 0.9984285994892949, 'f1-score': 0.9984279306000589, 'support': 10182}
 
time = 52.74 secondes

Val loss 1.129610355541688 accuracy 0.8878092169761658 macro_avg {'precision': 0.8923239460506778, 'recall': 0.8898042306114557, 'f1-score': 0.8890304484021764, 'support': 1132} weighted_avg {'precision': 0.8937366734051472, 'recall': 0.8878091872791519, 'f1-score': 0.8885696007261187, 'support': 1132}
 
----------
Epoch 38/40
time = 1925.75 secondes

Train loss 0.007589568203100789 accuracy 0.9983304142951965 macro_avg {'precision': 0.9983669476266931, 'recall': 0.9983627998577298, 'f1-score': 0.9983641997127103, 'support': 10182} weighted_avg {'precision': 0.9983309902814754, 'recall': 0.9983303869573757, 'f1-score': 0.9983300171454224, 'support': 10182}
 
time = 49.04 secondes

Val loss 1.1061923502577973 accuracy 0.8904593586921692 macro_avg {'precision': 0.89884907294286, 'recall': 0.891867345420696, 'f1-score': 0.8935320328213084, 'support': 1132} weighted_avg {'precision': 0.8963860370343055, 'recall': 0.8904593639575972, 'f1-score': 0.8913690098553065, 'support': 1132}
 
----------
Epoch 39/40
time = 1929.13 secondes

Train loss 0.007862999214065062 accuracy 0.998821496963501 macro_avg {'precision': 0.998862820977471, 'recall': 0.9988432610494009, 'f1-score': 0.9988511332337288, 'support': 10182} weighted_avg {'precision': 0.9988240631875992, 'recall': 0.9988214496169712, 'f1-score': 0.9988207930402909, 'support': 10182}
 
time = 52.97 secondes

Val loss 1.0694306313768502 accuracy 0.8931095600128174 macro_avg {'precision': 0.8951089535840115, 'recall': 0.8958892082524024, 'f1-score': 0.894471172056261, 'support': 1132} weighted_avg {'precision': 0.8961022608526231, 'recall': 0.8931095406360424, 'f1-score': 0.8935923295626962, 'support': 1132}
 
----------
Epoch 40/40
time = 1923.09 secondes

Train loss 0.00139931480836302 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992924742294085, 'recall': 0.9993102389281765, 'f1-score': 0.9993006996513566, 'support': 10182} weighted_avg {'precision': 0.9993139020345132, 'recall': 0.9993125122765665, 'f1-score': 0.9993125425696948, 'support': 10182}
 
time = 53.29 secondes

Val loss 1.0966424070061613 accuracy 0.8922261595726013 macro_avg {'precision': 0.8940231384011208, 'recall': 0.894137447579635, 'f1-score': 0.8928719143902357, 'support': 1132} weighted_avg {'precision': 0.8953994341185428, 'recall': 0.892226148409894, 'f1-score': 0.8925203626413257, 'support': 1132}
 
----------
best_accuracy 0.8939929604530334 best_epoch 36 macro_avg {'precision': 0.8958798770744021, 'recall': 0.8981414944716875, 'f1-score': 0.8952873443112443, 'support': 1132} weighted_avg {'precision': 0.8971607431497904, 'recall': 0.8939929328621908, 'f1-score': 0.8937159348690917, 'support': 1132}

average train time 1924.466408675909

average val time 52.29433569908142
 
time = 341.87 secondes

test_accuracy 0.8178438544273376 macro_avg {'precision': 0.8155176182049638, 'recall': 0.8116830788520085, 'f1-score': 0.81019355211842, 'support': 7532} weighted_avg {'precision': 0.8237974198027052, 'recall': 0.8178438661710037, 'f1-score': 0.8175809962052483, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 76.01 GiB already allocated; 53.62 MiB free; 77.13 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.39 GiB already allocated; 611.62 MiB free; 76.59 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 491.62 MiB free; 76.70 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_1
----------
Epoch 1/40
time = 581.21 secondes

Train loss 1.0997844924404632 accuracy 0.6861127614974976 macro_avg {'precision': 0.6878223629508194, 'recall': 0.6729178962543869, 'f1-score': 0.6721297509404207, 'support': 10182} weighted_avg {'precision': 0.6956524222591759, 'recall': 0.6861127479866431, 'f1-score': 0.6840004088255723, 'support': 10182}
 
time = 18.82 secondes

Val loss 0.5717216832956797 accuracy 0.833038866519928 macro_avg {'precision': 0.8386367628487523, 'recall': 0.8245681382101415, 'f1-score': 0.8207821860571547, 'support': 1132} weighted_avg {'precision': 0.8378692369447163, 'recall': 0.8330388692579506, 'f1-score': 0.8270416372844065, 'support': 1132}
 
----------
Epoch 2/40
time = 566.75 secondes

Train loss 0.40704016378690344 accuracy 0.8822432160377502 macro_avg {'precision': 0.8752735792271855, 'recall': 0.8745541897813902, 'f1-score': 0.8745763031441725, 'support': 10182} weighted_avg {'precision': 0.8816789860809193, 'recall': 0.8822431742290316, 'f1-score': 0.8816711831440355, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.4574692384143111 accuracy 0.8736749291419983 macro_avg {'precision': 0.881415959764826, 'recall': 0.8741984461779699, 'f1-score': 0.8705682918666191, 'support': 1132} weighted_avg {'precision': 0.8851687665051708, 'recall': 0.8736749116607774, 'f1-score': 0.8718099374204078, 'support': 1132}
 
----------
Epoch 3/40
time = 568.96 secondes

Train loss 0.2454467580552846 accuracy 0.9308584332466125 macro_avg {'precision': 0.927630674171642, 'recall': 0.9272972056209188, 'f1-score': 0.9273796603674984, 'support': 10182} weighted_avg {'precision': 0.9309349970556781, 'recall': 0.9308583775289727, 'f1-score': 0.9308123761028597, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.46486418503402194 accuracy 0.8904593586921692 macro_avg {'precision': 0.8994531005694231, 'recall': 0.8897539196848097, 'f1-score': 0.8882109704176395, 'support': 1132} weighted_avg {'precision': 0.9014696443224971, 'recall': 0.8904593639575972, 'f1-score': 0.888976916863139, 'support': 1132}
 
----------
Epoch 4/40
time = 571.70 secondes

Train loss 0.18130900196583424 accuracy 0.9511883854866028 macro_avg {'precision': 0.94903760794517, 'recall': 0.948972217985596, 'f1-score': 0.9489514067251463, 'support': 10182} weighted_avg {'precision': 0.9514490924990217, 'recall': 0.9511883716362208, 'f1-score': 0.9512675676613145, 'support': 10182}
 
time = 22.31 secondes

Val loss 0.5223398927999267 accuracy 0.9001767039299011 macro_avg {'precision': 0.9037222448145432, 'recall': 0.8952700161461056, 'f1-score': 0.8963815749080849, 'support': 1132} weighted_avg {'precision': 0.9029071593106182, 'recall': 0.9001766784452296, 'f1-score': 0.8990242975910558, 'support': 1132}
 
----------
Epoch 5/40
time = 568.88 secondes

Train loss 0.15910032841529012 accuracy 0.9578668475151062 macro_avg {'precision': 0.9558232171618899, 'recall': 0.9562655842105297, 'f1-score': 0.9559723967517655, 'support': 10182} weighted_avg {'precision': 0.9581461275314505, 'recall': 0.9578668238067177, 'f1-score': 0.9579463864388865, 'support': 10182}
 
time = 21.52 secondes

Val loss 0.5856672568987845 accuracy 0.8922261595726013 macro_avg {'precision': 0.8997137958281142, 'recall': 0.8891268024479665, 'f1-score': 0.8893412214279248, 'support': 1132} weighted_avg {'precision': 0.9011749976596474, 'recall': 0.892226148409894, 'f1-score': 0.8918931685279649, 'support': 1132}
 
----------
Epoch 6/40
time = 569.56 secondes

Train loss 0.13620848548627829 accuracy 0.9667059779167175 macro_avg {'precision': 0.965756837524688, 'recall': 0.9658960181756789, 'f1-score': 0.9657949575553163, 'support': 10182} weighted_avg {'precision': 0.9667920417903485, 'recall': 0.9667059516794343, 'f1-score': 0.9667172703136984, 'support': 10182}
 
time = 22.99 secondes

Val loss 0.6211046260038824 accuracy 0.9001767039299011 macro_avg {'precision': 0.9097708305076235, 'recall': 0.9003060140788355, 'f1-score': 0.9004568033453528, 'support': 1132} weighted_avg {'precision': 0.9077751284901967, 'recall': 0.9001766784452296, 'f1-score': 0.899516949997132, 'support': 1132}
 
----------
Epoch 7/40
time = 568.58 secondes

Train loss 0.14060994152168288 accuracy 0.9674916863441467 macro_avg {'precision': 0.9657636934158909, 'recall': 0.9659428998488201, 'f1-score': 0.9657854557103047, 'support': 10182} weighted_avg {'precision': 0.9675845261329659, 'recall': 0.9674916519347869, 'f1-score': 0.9674697746364863, 'support': 10182}
 
time = 22.47 secondes

Val loss 0.6259111564386715 accuracy 0.8939929604530334 macro_avg {'precision': 0.8969172167054127, 'recall': 0.8933137607148727, 'f1-score': 0.8935809854286839, 'support': 1132} weighted_avg {'precision': 0.8979980680296133, 'recall': 0.8939929328621908, 'f1-score': 0.8944690031342328, 'support': 1132}
 
----------
Epoch 8/40
time = 566.88 secondes

Train loss 0.12771233250257258 accuracy 0.9722058773040771 macro_avg {'precision': 0.9712930916106481, 'recall': 0.9713612746614052, 'f1-score': 0.9712988374532783, 'support': 10182} weighted_avg {'precision': 0.9722540032180205, 'recall': 0.9722058534669024, 'f1-score': 0.9722027082206208, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.5971771128611757 accuracy 0.9054770469665527 macro_avg {'precision': 0.9077629076248632, 'recall': 0.9058117275971055, 'f1-score': 0.9050505492257284, 'support': 1132} weighted_avg {'precision': 0.9098739258728, 'recall': 0.9054770318021201, 'f1-score': 0.9058584177959661, 'support': 1132}
 
----------
Epoch 9/40
time = 569.27 secondes

Train loss 0.11264855949065773 accuracy 0.9746611714363098 macro_avg {'precision': 0.9739610485905796, 'recall': 0.9744113720523837, 'f1-score': 0.9741632925494711, 'support': 10182} weighted_avg {'precision': 0.9747671867878094, 'recall': 0.9746611667648792, 'f1-score': 0.9746959832376051, 'support': 10182}
 
time = 19.98 secondes

Val loss 0.5857540229831422 accuracy 0.9098939895629883 macro_avg {'precision': 0.9151304347258045, 'recall': 0.9098693990078022, 'f1-score': 0.9112148759651747, 'support': 1132} weighted_avg {'precision': 0.913024851243534, 'recall': 0.9098939929328622, 'f1-score': 0.9103827329880712, 'support': 1132}
 
----------
Epoch 10/40
time = 570.71 secondes

Train loss 0.11006642056957473 accuracy 0.9761343598365784 macro_avg {'precision': 0.9755068972550086, 'recall': 0.9747584223271473, 'f1-score': 0.9750624507457555, 'support': 10182} weighted_avg {'precision': 0.976132781160238, 'recall': 0.9761343547436653, 'f1-score': 0.976068707268918, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6262095260428114 accuracy 0.9098939895629883 macro_avg {'precision': 0.912360188045789, 'recall': 0.910753869803209, 'f1-score': 0.9099619377241446, 'support': 1132} weighted_avg {'precision': 0.9132089063022603, 'recall': 0.9098939929328622, 'f1-score': 0.9101099412482753, 'support': 1132}
 
----------
Epoch 11/40
time = 571.36 secondes

Train loss 0.10754663762127509 accuracy 0.978491485118866 macro_avg {'precision': 0.9778355232559915, 'recall': 0.9778824417236158, 'f1-score': 0.9778155073811925, 'support': 10182} weighted_avg {'precision': 0.9785173990910035, 'recall': 0.978491455509723, 'f1-score': 0.9784619337493538, 'support': 10182}
 
time = 23.09 secondes

Val loss 0.7612517384589244 accuracy 0.9019434452056885 macro_avg {'precision': 0.9124614369007716, 'recall': 0.8960991220487523, 'f1-score': 0.8976232884462869, 'support': 1132} weighted_avg {'precision': 0.9098837526415684, 'recall': 0.9019434628975265, 'f1-score': 0.9004680581764399, 'support': 1132}
 
----------
Epoch 12/40
time = 567.28 secondes

Train loss 0.09653138334164213 accuracy 0.9802592992782593 macro_avg {'precision': 0.9792459332568859, 'recall': 0.979399304997498, 'f1-score': 0.9792997853621499, 'support': 10182} weighted_avg {'precision': 0.9803020057989634, 'recall': 0.9802592810842663, 'f1-score': 0.9802576528219215, 'support': 10182}
 
time = 21.97 secondes

Val loss 0.6487794487551019 accuracy 0.9054770469665527 macro_avg {'precision': 0.9087437615091417, 'recall': 0.9048731067367475, 'f1-score': 0.905231778875294, 'support': 1132} weighted_avg {'precision': 0.9080026868659407, 'recall': 0.9054770318021201, 'f1-score': 0.9051446489513533, 'support': 1132}
 
----------
Epoch 13/40
time = 569.78 secondes

Train loss 0.09991124910759806 accuracy 0.9801610708236694 macro_avg {'precision': 0.9798032510074283, 'recall': 0.9799536088097793, 'f1-score': 0.9798268194934746, 'support': 10182} weighted_avg {'precision': 0.9803190081697329, 'recall': 0.9801610685523473, 'f1-score': 0.980189552748413, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.8331731364492108 accuracy 0.8886925578117371 macro_avg {'precision': 0.9099100103909891, 'recall': 0.8941205797277842, 'f1-score': 0.8917505922606492, 'support': 1132} weighted_avg {'precision': 0.9137066256465101, 'recall': 0.8886925795053003, 'f1-score': 0.8897393659258223, 'support': 1132}
 
----------
Epoch 14/40
time = 569.20 secondes

Train loss 0.08957526916527907 accuracy 0.982518196105957 macro_avg {'precision': 0.9819867767028739, 'recall': 0.9819425588172415, 'f1-score': 0.9819311124190329, 'support': 10182} weighted_avg {'precision': 0.9825746384243267, 'recall': 0.9825181693184051, 'f1-score': 0.9825130912895955, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.6198957062387449 accuracy 0.9116607904434204 macro_avg {'precision': 0.9134349767672948, 'recall': 0.9100723979251372, 'f1-score': 0.9088721685778911, 'support': 1132} weighted_avg {'precision': 0.9140991481012057, 'recall': 0.911660777385159, 'f1-score': 0.9105650086600348, 'support': 1132}
 
----------
Epoch 15/40
time = 569.76 secondes

Train loss 0.08130494207590622 accuracy 0.9845806360244751 macro_avg {'precision': 0.9840898004902654, 'recall': 0.9840411981837857, 'f1-score': 0.9840478204553623, 'support': 10182} weighted_avg {'precision': 0.9846198394993596, 'recall': 0.9845806324887055, 'f1-score': 0.9845826195583136, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.736500205383878 accuracy 0.9081271886825562 macro_avg {'precision': 0.9124411749476702, 'recall': 0.9121352855358502, 'f1-score': 0.9100584693671229, 'support': 1132} weighted_avg {'precision': 0.9124594309393222, 'recall': 0.9081272084805654, 'f1-score': 0.9078527377867529, 'support': 1132}
 
----------
Epoch 16/40
time = 567.40 secondes

Train loss 0.07226363240243276 accuracy 0.9861520528793335 macro_avg {'precision': 0.9862162055633202, 'recall': 0.9861244912895429, 'f1-score': 0.9861322053963884, 'support': 10182} weighted_avg {'precision': 0.9862858951762472, 'recall': 0.9861520329994107, 'f1-score': 0.9861800981490159, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.6699839285138296 accuracy 0.9143109321594238 macro_avg {'precision': 0.919009887218945, 'recall': 0.9180488745409587, 'f1-score': 0.9164457886366538, 'support': 1132} weighted_avg {'precision': 0.9173797317646774, 'recall': 0.9143109540636042, 'f1-score': 0.9133762741460606, 'support': 1132}
 
----------
Epoch 17/40
time = 569.99 secondes

Train loss 0.08442813955509931 accuracy 0.9838931560516357 macro_avg {'precision': 0.9837005833034109, 'recall': 0.9830349654779068, 'f1-score': 0.9833334517521821, 'support': 10182} weighted_avg {'precision': 0.9839366444689909, 'recall': 0.983893144765272, 'f1-score': 0.9838838444844287, 'support': 10182}
 
time = 23.12 secondes

Val loss 0.5684089975224146 accuracy 0.9231448769569397 macro_avg {'precision': 0.9275263087349108, 'recall': 0.9224495408941145, 'f1-score': 0.9237667346418574, 'support': 1132} weighted_avg {'precision': 0.9272330022050027, 'recall': 0.9231448763250883, 'f1-score': 0.9239894149203999, 'support': 1132}
 
----------
Epoch 18/40
time = 568.24 secondes

Train loss 0.06837783576344263 accuracy 0.9872323870658875 macro_avg {'precision': 0.9869274373258211, 'recall': 0.9866682103813756, 'f1-score': 0.9867699357841211, 'support': 10182} weighted_avg {'precision': 0.9872889657639354, 'recall': 0.9872323708505205, 'f1-score': 0.9872370432704687, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.7245235085793981 accuracy 0.9019434452056885 macro_avg {'precision': 0.9103656795901724, 'recall': 0.9055475240669517, 'f1-score': 0.9045226453658828, 'support': 1132} weighted_avg {'precision': 0.9104162037090102, 'recall': 0.9019434628975265, 'f1-score': 0.902612953649647, 'support': 1132}
 
----------
Epoch 19/40
time = 567.23 secondes

Train loss 0.06162013111984101 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881464693884302, 'recall': 0.9880874514230653, 'f1-score': 0.9880946116906395, 'support': 10182} weighted_avg {'precision': 0.9886681964847601, 'recall': 0.9886073462973876, 'f1-score': 0.9886157439385127, 'support': 10182}
 
time = 22.87 secondes

Val loss 0.6461030066257849 accuracy 0.916077733039856 macro_avg {'precision': 0.9222679725385026, 'recall': 0.9157488432392521, 'f1-score': 0.9175853248123097, 'support': 1132} weighted_avg {'precision': 0.9190664101156943, 'recall': 0.916077738515901, 'f1-score': 0.9160948459810878, 'support': 1132}
 
----------
Epoch 20/40
time = 568.61 secondes

Train loss 0.06008451648484247 accuracy 0.9890984296798706 macro_avg {'precision': 0.98874886151684, 'recall': 0.9887605574919547, 'f1-score': 0.9887489411941054, 'support': 10182} weighted_avg {'precision': 0.989121544417881, 'recall': 0.9890984089569829, 'f1-score': 0.9891039599151528, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6826558990370601 accuracy 0.916077733039856 macro_avg {'precision': 0.9213986751742551, 'recall': 0.9159593516187297, 'f1-score': 0.9174591064194658, 'support': 1132} weighted_avg {'precision': 0.9193517622238973, 'recall': 0.916077738515901, 'f1-score': 0.9165032112474463, 'support': 1132}
 
----------
Epoch 21/40
time = 570.98 secondes

Train loss 0.07264790180803743 accuracy 0.9883127212524414 macro_avg {'precision': 0.9882600986131267, 'recall': 0.988292285424785, 'f1-score': 0.9882634871463777, 'support': 10182} weighted_avg {'precision': 0.9883421597300297, 'recall': 0.9883127087016303, 'f1-score': 0.9883143358434967, 'support': 10182}
 
time = 22.53 secondes

Val loss 0.7115465479812332 accuracy 0.916077733039856 macro_avg {'precision': 0.9180924077298851, 'recall': 0.9203140810930895, 'f1-score': 0.9172304573723012, 'support': 1132} weighted_avg {'precision': 0.9197443915952173, 'recall': 0.916077738515901, 'f1-score': 0.9157364139538529, 'support': 1132}
 
----------
Epoch 22/40
time = 567.57 secondes

Train loss 0.04627847142944164 accuracy 0.990669846534729 macro_avg {'precision': 0.9906670496917711, 'recall': 0.9906100764986853, 'f1-score': 0.990629723707789, 'support': 10182} weighted_avg {'precision': 0.9906914782148939, 'recall': 0.9906698094676881, 'f1-score': 0.9906723223391357, 'support': 10182}
 
time = 22.47 secondes

Val loss 0.7149649650467401 accuracy 0.9072438478469849 macro_avg {'precision': 0.914228594271189, 'recall': 0.9064139816869741, 'f1-score': 0.9078804801969493, 'support': 1132} weighted_avg {'precision': 0.9109863264063237, 'recall': 0.907243816254417, 'f1-score': 0.9067905086601493, 'support': 1132}
 
----------
Epoch 23/40
time = 565.67 secondes

Train loss 0.05535319043619508 accuracy 0.9901787638664246 macro_avg {'precision': 0.990186951100212, 'recall': 0.990124147630481, 'f1-score': 0.9901497003195704, 'support': 10182} weighted_avg {'precision': 0.9901917663371294, 'recall': 0.9901787468080927, 'f1-score': 0.9901792908721005, 'support': 10182}
 
time = 22.96 secondes

Val loss 0.6508283611105404 accuracy 0.9240282773971558 macro_avg {'precision': 0.9366664094952825, 'recall': 0.9259534090111563, 'f1-score': 0.9288168137690798, 'support': 1132} weighted_avg {'precision': 0.9342302780459693, 'recall': 0.9240282685512368, 'f1-score': 0.9261973176748851, 'support': 1132}
 
----------
Epoch 24/40
time = 568.55 secondes

Train loss 0.06327921495516081 accuracy 0.98978590965271 macro_avg {'precision': 0.9898740157385616, 'recall': 0.989846709156674, 'f1-score': 0.9898421761775588, 'support': 10182} weighted_avg {'precision': 0.9898389475204836, 'recall': 0.9897858966804164, 'f1-score': 0.9897938642701466, 'support': 10182}
 
time = 21.87 secondes

Val loss 0.5872606872270436 accuracy 0.9240282773971558 macro_avg {'precision': 0.9278130874820842, 'recall': 0.9248879966636677, 'f1-score': 0.9250840209268002, 'support': 1132} weighted_avg {'precision': 0.9283898956116178, 'recall': 0.9240282685512368, 'f1-score': 0.9249206197611685, 'support': 1132}
 
----------
Epoch 25/40
time = 568.38 secondes

Train loss 0.055695615151800305 accuracy 0.9902769923210144 macro_avg {'precision': 0.989638540545163, 'recall': 0.9899676315543582, 'f1-score': 0.9897862839603734, 'support': 10182} weighted_avg {'precision': 0.9903207138817037, 'recall': 0.9902769593400118, 'f1-score': 0.9902846998738876, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6996566899744695 accuracy 0.9178445339202881 macro_avg {'precision': 0.9228005448663922, 'recall': 0.9191730097156443, 'f1-score': 0.9198230069121912, 'support': 1132} weighted_avg {'precision': 0.9210933833101572, 'recall': 0.9178445229681979, 'f1-score': 0.9182307356314999, 'support': 1132}
 
----------
Epoch 26/40
time = 567.84 secondes

Train loss 0.05720731950577186 accuracy 0.9898841381072998 macro_avg {'precision': 0.9898395035750791, 'recall': 0.9893704645747586, 'f1-score': 0.9895835952250518, 'support': 10182} weighted_avg {'precision': 0.9899250104888522, 'recall': 0.9898841092123355, 'f1-score': 0.9898851433263859, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.745639404899098 accuracy 0.9116607904434204 macro_avg {'precision': 0.9194050032652497, 'recall': 0.9131450484667027, 'f1-score': 0.9144200376384657, 'support': 1132} weighted_avg {'precision': 0.9152045567947985, 'recall': 0.911660777385159, 'f1-score': 0.911415288268597, 'support': 1132}
 
----------
Epoch 27/40
time = 570.83 secondes

Train loss 0.03986610048967728 accuracy 0.9918484091758728 macro_avg {'precision': 0.9919231049033768, 'recall': 0.991785135863292, 'f1-score': 0.9918458545143632, 'support': 10182} weighted_avg {'precision': 0.9918595256574687, 'recall': 0.991848359850717, 'f1-score': 0.9918455083480605, 'support': 10182}
 
time = 22.49 secondes

Val loss 0.6731796365278006 accuracy 0.9178445339202881 macro_avg {'precision': 0.9208235796663387, 'recall': 0.9190095045331848, 'f1-score': 0.9181915026624416, 'support': 1132} weighted_avg {'precision': 0.9209932670079181, 'recall': 0.9178445229681979, 'f1-score': 0.9176805744553524, 'support': 1132}
 
----------
Epoch 28/40
time = 568.50 secondes

Train loss 0.032457609364185486 accuracy 0.9933215975761414 macro_avg {'precision': 0.9928703029951341, 'recall': 0.9927731606546549, 'f1-score': 0.9928084945106965, 'support': 10182} weighted_avg {'precision': 0.993347949064254, 'recall': 0.993321547829503, 'f1-score': 0.9933224560846786, 'support': 10182}
 
time = 22.99 secondes

Val loss 0.6252692301897415 accuracy 0.9222614765167236 macro_avg {'precision': 0.9244180129375724, 'recall': 0.9239414973762999, 'f1-score': 0.9229170114160116, 'support': 1132} weighted_avg {'precision': 0.9250430125543274, 'recall': 0.9222614840989399, 'f1-score': 0.9223270133362111, 'support': 1132}
 
----------
Epoch 29/40
time = 568.54 secondes

Train loss 0.033094426515419925 accuracy 0.9944019317626953 macro_avg {'precision': 0.994266865963646, 'recall': 0.9944099948202224, 'f1-score': 0.9943267563565771, 'support': 10182} weighted_avg {'precision': 0.9944343699938575, 'recall': 0.9944018856806128, 'f1-score': 0.994407527818004, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.6935569354699651 accuracy 0.916077733039856 macro_avg {'precision': 0.9191349646753567, 'recall': 0.9199074823319904, 'f1-score': 0.9179013286697536, 'support': 1132} weighted_avg {'precision': 0.9194420309525343, 'recall': 0.916077738515901, 'f1-score': 0.9160193615350452, 'support': 1132}
 
----------
Epoch 30/40
time = 570.31 secondes

Train loss 0.02754991813643794 accuracy 0.9953840374946594 macro_avg {'precision': 0.9951300532390805, 'recall': 0.9951662566650572, 'f1-score': 0.9951445103633233, 'support': 10182} weighted_avg {'precision': 0.9953912520521064, 'recall': 0.9953840109998036, 'f1-score': 0.9953838635348673, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.8568371036420962 accuracy 0.9054770469665527 macro_avg {'precision': 0.9145535951779165, 'recall': 0.9107899892302747, 'f1-score': 0.9092286228580473, 'support': 1132} weighted_avg {'precision': 0.9160403352328731, 'recall': 0.9054770318021201, 'f1-score': 0.9071584973952783, 'support': 1132}
 
----------
Epoch 31/40
time = 566.75 secondes

Train loss 0.030780450883074743 accuracy 0.9947947859764099 macro_avg {'precision': 0.9945845669913982, 'recall': 0.9949203821561211, 'f1-score': 0.9947385138220188, 'support': 10182} weighted_avg {'precision': 0.9948274471324077, 'recall': 0.9947947358082891, 'f1-score': 0.9947991777831807, 'support': 10182}
 
time = 21.46 secondes

Val loss 0.640830552365412 accuracy 0.9204947352409363 macro_avg {'precision': 0.9206119024416003, 'recall': 0.922666832475801, 'f1-score': 0.9208566674404374, 'support': 1132} weighted_avg {'precision': 0.9224254223788018, 'recall': 0.9204946996466431, 'f1-score': 0.9206773631391556, 'support': 1132}
 
----------
Epoch 32/40
time = 569.22 secondes

Train loss 0.02501534679010677 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959612091258544, 'recall': 0.9959994597358144, 'f1-score': 0.9959732117381881, 'support': 10182} weighted_avg {'precision': 0.9958879975482428, 'recall': 0.995875073659399, 'f1-score': 0.9958741771530268, 'support': 10182}
 
time = 23.05 secondes

Val loss 0.730176873688193 accuracy 0.9125441908836365 macro_avg {'precision': 0.9190780866840615, 'recall': 0.9177783618009501, 'f1-score': 0.9161540633403641, 'support': 1132} weighted_avg {'precision': 0.9198549743026266, 'recall': 0.9125441696113075, 'f1-score': 0.9137067885166853, 'support': 1132}
 
----------
Epoch 33/40
time = 569.17 secondes

Train loss 0.02540881446326336 accuracy 0.9959732890129089 macro_avg {'precision': 0.9960479369506793, 'recall': 0.995878459398868, 'f1-score': 0.9959595869896158, 'support': 10182} weighted_avg {'precision': 0.9959795809782355, 'recall': 0.995973286191318, 'f1-score': 0.9959731031817924, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.6662445256722133 accuracy 0.9275618195533752 macro_avg {'precision': 0.9336782565302391, 'recall': 0.9300994181729199, 'f1-score': 0.9300195454945219, 'support': 1132} weighted_avg {'precision': 0.9313546021075164, 'recall': 0.9275618374558304, 'f1-score': 0.9274345345013225, 'support': 1132}
 
----------
Epoch 34/40
time = 568.89 secondes

Train loss 0.022051664146526307 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961429014884177, 'recall': 0.9960567308486814, 'f1-score': 0.9960966677107267, 'support': 10182} weighted_avg {'precision': 0.9961748919567782, 'recall': 0.9961697112551562, 'f1-score': 0.9961691038634074, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.6422726279879882 accuracy 0.9257950782775879 macro_avg {'precision': 0.9270609073772021, 'recall': 0.927334133542189, 'f1-score': 0.9263920139445634, 'support': 1132} weighted_avg {'precision': 0.9285323346284616, 'recall': 0.9257950530035336, 'f1-score': 0.9263256754760463, 'support': 1132}
 
----------
Epoch 35/40
time = 569.13 secondes

Train loss 0.023852976278935876 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967579748735433, 'recall': 0.9968296127425121, 'f1-score': 0.9967919630907008, 'support': 10182} weighted_avg {'precision': 0.9967647868615698, 'recall': 0.9967589864466706, 'f1-score': 0.9967600652448388, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.7615392201561251 accuracy 0.9187279343605042 macro_avg {'precision': 0.9211051131337198, 'recall': 0.9218576191198921, 'f1-score': 0.9195387567184776, 'support': 1132} weighted_avg {'precision': 0.9238320603744885, 'recall': 0.9187279151943463, 'f1-score': 0.9192571856841164, 'support': 1132}
 
----------
Epoch 36/40
time = 567.32 secondes

Train loss 0.01369270134272536 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977032552777985, 'recall': 0.9976916292537913, 'f1-score': 0.9976964188037002, 'support': 10182} weighted_avg {'precision': 0.9976454979759907, 'recall': 0.9976428992339422, 'f1-score': 0.9976431610623315, 'support': 10182}
 
time = 21.89 secondes

Val loss 0.7570653648613893 accuracy 0.9178445339202881 macro_avg {'precision': 0.9205535380787901, 'recall': 0.9215436539892039, 'f1-score': 0.9195183530830746, 'support': 1132} weighted_avg {'precision': 0.9218094958718972, 'recall': 0.9178445229681979, 'f1-score': 0.9182585164764622, 'support': 1132}
 
----------
Epoch 37/40
time = 567.43 secondes

Train loss 0.00997892185016664 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982460861740521, 'recall': 0.9982607131334602, 'f1-score': 0.9982491342914181, 'support': 10182} weighted_avg {'precision': 0.9982419307037276, 'recall': 0.9982321744254566, 'f1-score': 0.9982327240097675, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.7021187144034652 accuracy 0.9213780760765076 macro_avg {'precision': 0.9274487700382018, 'recall': 0.9250196409626212, 'f1-score': 0.924276953604703, 'support': 1132} weighted_avg {'precision': 0.928108178508317, 'recall': 0.9213780918727915, 'f1-score': 0.9227715392228071, 'support': 1132}
 
----------
Epoch 38/40
time = 568.35 secondes

Train loss 0.007034634148214045 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986823890283881, 'recall': 0.9986385616001732, 'f1-score': 0.9986594091860332, 'support': 10182} weighted_avg {'precision': 0.9986266755670796, 'recall': 0.998625024553133, 'f1-score': 0.9986247926292628, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.7297383999649983 accuracy 0.9213780760765076 macro_avg {'precision': 0.9273215708110456, 'recall': 0.9244346094494826, 'f1-score': 0.9236617758271011, 'support': 1132} weighted_avg {'precision': 0.9279772669766249, 'recall': 0.9213780918727915, 'f1-score': 0.9223094224211992, 'support': 1132}
 
----------
Epoch 39/40
time = 567.33 secondes

Train loss 0.0038555220481002535 accuracy 0.998919665813446 macro_avg {'precision': 0.9989550398228026, 'recall': 0.9989585218583039, 'f1-score': 0.9989563442116005, 'support': 10182} weighted_avg {'precision': 0.9989209513446808, 'recall': 0.9989196621488902, 'f1-score': 0.9989198480450608, 'support': 10182}
 
time = 23.10 secondes

Val loss 0.6610273372210377 accuracy 0.926678478717804 macro_avg {'precision': 0.931425210021635, 'recall': 0.9288085050576769, 'f1-score': 0.928744926798486, 'support': 1132} weighted_avg {'precision': 0.9312726613707057, 'recall': 0.926678445229682, 'f1-score': 0.9275206493644735, 'support': 1132}
 
----------
Epoch 40/40
time = 566.85 secondes

Train loss 0.001980297838251276 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994290350638242, 'recall': 0.9994295411549491, 'f1-score': 0.9994284700236122, 'support': 10182} weighted_avg {'precision': 0.9994122226199517, 'recall': 0.9994107248084856, 'f1-score': 0.9994106317396382, 'support': 10182}
 
time = 22.79 secondes

Val loss 0.6384202894389321 accuracy 0.9337455630302429 macro_avg {'precision': 0.9356420141771536, 'recall': 0.9364045709811245, 'f1-score': 0.934549535413906, 'support': 1132} weighted_avg {'precision': 0.9374851619329218, 'recall': 0.9337455830388692, 'f1-score': 0.9340527406543453, 'support': 1132}
 
----------
best_accuracy 0.9337455630302429 best_epoch 40 macro_avg {'precision': 0.9356420141771536, 'recall': 0.9364045709811245, 'f1-score': 0.934549535413906, 'support': 1132} weighted_avg {'precision': 0.9374851619329218, 'recall': 0.9337455830388692, 'f1-score': 0.9340527406543453, 'support': 1132}

average train time 568.973794388771

average val time 22.61776723265648
 
time = 135.37 secondes

test_accuracy 0.8571428060531616 macro_avg {'precision': 0.852638320366168, 'recall': 0.8505574077051123, 'f1-score': 0.8501829177548832, 'support': 7532} weighted_avg {'precision': 0.8603521296097905, 'recall': 0.8571428571428571, 'f1-score': 0.8576074944622527, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_1
----------
Epoch 1/40
time = 757.44 secondes

Train loss 1.067798031344893 accuracy 0.7016303539276123 macro_avg {'precision': 0.689415715612215, 'recall': 0.6873953178033035, 'f1-score': 0.6813353605589858, 'support': 10182} weighted_avg {'precision': 0.6985808428468387, 'recall': 0.7016303280298566, 'f1-score': 0.6942105389661598, 'support': 10182}
 
time = 27.12 secondes

Val loss 0.6049767572065474 accuracy 0.8197879791259766 macro_avg {'precision': 0.8000029032443076, 'recall': 0.8064661812888614, 'f1-score': 0.7945626610029521, 'support': 1132} weighted_avg {'precision': 0.8118149894148093, 'recall': 0.8197879858657244, 'f1-score': 0.8081064907337447, 'support': 1132}
 
----------
Epoch 2/40
time = 741.15 secondes

Train loss 0.4077547368516026 accuracy 0.8780200481414795 macro_avg {'precision': 0.870404540927687, 'recall': 0.8691917050025317, 'f1-score': 0.8688421552855854, 'support': 10182} weighted_avg {'precision': 0.8766509772448181, 'recall': 0.8780200353565115, 'f1-score': 0.876601743382305, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.48729738514398185 accuracy 0.8745583295822144 macro_avg {'precision': 0.8769273775755242, 'recall': 0.8787816769406641, 'f1-score': 0.872815410815921, 'support': 1132} weighted_avg {'precision': 0.8806972839958443, 'recall': 0.8745583038869258, 'f1-score': 0.8718304747764215, 'support': 1132}
 
----------
Epoch 3/40
time = 741.75 secondes

Train loss 0.24104407903836278 accuracy 0.9345904588699341 macro_avg {'precision': 0.9308374427709826, 'recall': 0.9306607443701169, 'f1-score': 0.9306834539630184, 'support': 10182} weighted_avg {'precision': 0.9347949329092828, 'recall': 0.9345904537418974, 'f1-score': 0.9346334951694397, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.5053113101076492 accuracy 0.8789752721786499 macro_avg {'precision': 0.8874284098661713, 'recall': 0.8825021677097402, 'f1-score': 0.878670691712248, 'support': 1132} weighted_avg {'precision': 0.8851961714552051, 'recall': 0.8789752650176679, 'f1-score': 0.8746082308992357, 'support': 1132}
 
----------
Epoch 4/40
time = 741.20 secondes

Train loss 0.18862622271341623 accuracy 0.9517776966094971 macro_avg {'precision': 0.9491331330812077, 'recall': 0.9491934063633485, 'f1-score': 0.9491056183875667, 'support': 10182} weighted_avg {'precision': 0.9517881990343844, 'recall': 0.9517776468277352, 'f1-score': 0.9517269059898908, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.47849033646036304 accuracy 0.9037102460861206 macro_avg {'precision': 0.9064522498775689, 'recall': 0.903021260865628, 'f1-score': 0.9025512358044846, 'support': 1132} weighted_avg {'precision': 0.9068567752098445, 'recall': 0.9037102473498233, 'f1-score': 0.9030229745179893, 'support': 1132}
 
----------
Epoch 5/40
time = 741.94 secondes

Train loss 0.1570842513628889 accuracy 0.9607149958610535 macro_avg {'precision': 0.9590935258319517, 'recall': 0.9592323627386905, 'f1-score': 0.9591047836515774, 'support': 10182} weighted_avg {'precision': 0.9608061731015225, 'recall': 0.9607149872323708, 'f1-score': 0.9607030377387079, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.4913541349356102 accuracy 0.9134275913238525 macro_avg {'precision': 0.9171615251855905, 'recall': 0.9133468571773822, 'f1-score': 0.9133161864822743, 'support': 1132} weighted_avg {'precision': 0.9170058604104768, 'recall': 0.9134275618374559, 'f1-score': 0.9131924362827103, 'support': 1132}
 
----------
Epoch 6/40
time = 739.46 secondes

Train loss 0.14387712991570548 accuracy 0.9650363922119141 macro_avg {'precision': 0.9644483074996104, 'recall': 0.9639398180333252, 'f1-score': 0.9641373466839761, 'support': 10182} weighted_avg {'precision': 0.9651564569770116, 'recall': 0.96503633863681, 'f1-score': 0.9650399736606838, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.5941956521070917 accuracy 0.9010601043701172 macro_avg {'precision': 0.9087130626164951, 'recall': 0.904106062241468, 'f1-score': 0.9020721243246707, 'support': 1132} weighted_avg {'precision': 0.9110418150152381, 'recall': 0.901060070671378, 'f1-score': 0.9012349700227741, 'support': 1132}
 
----------
Epoch 7/40
time = 740.34 secondes

Train loss 0.1268328278786225 accuracy 0.9711255431175232 macro_avg {'precision': 0.9698964663775718, 'recall': 0.9699187050218538, 'f1-score': 0.969887022683349, 'support': 10182} weighted_avg {'precision': 0.9711429816988653, 'recall': 0.9711255156157925, 'f1-score': 0.9711136218923345, 'support': 10182}
 
time = 26.25 secondes

Val loss 0.6087041122873288 accuracy 0.9001767039299011 macro_avg {'precision': 0.9010504480137825, 'recall': 0.9018885770338209, 'f1-score': 0.899518362023127, 'support': 1132} weighted_avg {'precision': 0.9048404257681146, 'recall': 0.9001766784452296, 'f1-score': 0.9005891660784079, 'support': 1132}
 
----------
Epoch 8/40
time = 741.28 secondes

Train loss 0.12267424219932693 accuracy 0.9727951288223267 macro_avg {'precision': 0.9718982569062966, 'recall': 0.9720439141144359, 'f1-score': 0.971942871547804, 'support': 10182} weighted_avg {'precision': 0.9728877353027319, 'recall': 0.9727951286584168, 'f1-score': 0.9728157699428968, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.7390257180537242 accuracy 0.8772084712982178 macro_avg {'precision': 0.8947629361430172, 'recall': 0.8793656261027577, 'f1-score': 0.8764685992162213, 'support': 1132} weighted_avg {'precision': 0.8959454185051968, 'recall': 0.877208480565371, 'f1-score': 0.8752764375775305, 'support': 1132}
 
----------
Epoch 9/40
time = 739.56 secondes

Train loss 0.10797943744127306 accuracy 0.9750540256500244 macro_avg {'precision': 0.974545506609506, 'recall': 0.9747651665969486, 'f1-score': 0.9746316201061417, 'support': 10182} weighted_avg {'precision': 0.9750917306914992, 'recall': 0.9750540168925554, 'f1-score': 0.9750492939097616, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.6898673409087793 accuracy 0.8931095600128174 macro_avg {'precision': 0.8969710111571981, 'recall': 0.8953717822494559, 'f1-score': 0.89382870907819, 'support': 1132} weighted_avg {'precision': 0.8979701368656378, 'recall': 0.8931095406360424, 'f1-score': 0.8930800472332661, 'support': 1132}
 
----------
Epoch 10/40
time = 738.80 secondes

Train loss 0.11189251246354419 accuracy 0.9760361909866333 macro_avg {'precision': 0.9754492627051926, 'recall': 0.9756425731229251, 'f1-score': 0.9755221451747831, 'support': 10182} weighted_avg {'precision': 0.9761050241731488, 'recall': 0.9760361422117462, 'f1-score': 0.9760487238585813, 'support': 10182}
 
time = 25.58 secondes

Val loss 0.6636729107648676 accuracy 0.9054770469665527 macro_avg {'precision': 0.9088054598813938, 'recall': 0.9068251659899687, 'f1-score': 0.905353969448546, 'support': 1132} weighted_avg {'precision': 0.9080374590342742, 'recall': 0.9054770318021201, 'f1-score': 0.9042233349822986, 'support': 1132}
 
----------
Epoch 11/40
time = 738.28 secondes

Train loss 0.11567561895711921 accuracy 0.9772146940231323 macro_avg {'precision': 0.9768793978402586, 'recall': 0.9767335666253425, 'f1-score': 0.9767920544436299, 'support': 10182} weighted_avg {'precision': 0.9772425450326749, 'recall': 0.9772146925947751, 'f1-score': 0.9772141093347688, 'support': 10182}
 
time = 26.29 secondes

Val loss 0.8265081515790268 accuracy 0.8842756152153015 macro_avg {'precision': 0.9029671822847629, 'recall': 0.8887484523746976, 'f1-score': 0.8886394404409476, 'support': 1132} weighted_avg {'precision': 0.9001169007102447, 'recall': 0.8842756183745583, 'f1-score': 0.8838538945298537, 'support': 1132}
 
----------
Epoch 12/40
time = 741.21 secondes

Train loss 0.09651679695758686 accuracy 0.9776075482368469 macro_avg {'precision': 0.9767307007138275, 'recall': 0.9767740991880428, 'f1-score': 0.9767121791895915, 'support': 10182} weighted_avg {'precision': 0.9776567980682875, 'recall': 0.9776075427224514, 'f1-score': 0.9775945693256013, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.7057185967302796 accuracy 0.9028268456459045 macro_avg {'precision': 0.9119201211053405, 'recall': 0.9050814109134716, 'f1-score': 0.9047944394179981, 'support': 1132} weighted_avg {'precision': 0.9106397920822509, 'recall': 0.9028268551236749, 'f1-score': 0.9031768082140432, 'support': 1132}
 
----------
Epoch 13/40
time = 741.89 secondes

Train loss 0.0914899179829998 accuracy 0.9817324876785278 macro_avg {'precision': 0.9808155208506436, 'recall': 0.9806251332649193, 'f1-score': 0.9807021507235454, 'support': 10182} weighted_avg {'precision': 0.9817422267753262, 'recall': 0.9817324690630524, 'f1-score': 0.9817202808088199, 'support': 10182}
 
time = 26.36 secondes

Val loss 0.7198496686920203 accuracy 0.8939929604530334 macro_avg {'precision': 0.905193419412373, 'recall': 0.8945004097507139, 'f1-score': 0.8965854329068469, 'support': 1132} weighted_avg {'precision': 0.902465658438745, 'recall': 0.8939929328621908, 'f1-score': 0.8949362891991499, 'support': 1132}
 
----------
Epoch 14/40
time = 741.40 secondes

Train loss 0.08021377659931134 accuracy 0.9835003018379211 macro_avg {'precision': 0.98352976282507, 'recall': 0.983429661311743, 'f1-score': 0.9834665350982938, 'support': 10182} weighted_avg {'precision': 0.9835243517991831, 'recall': 0.9835002946375958, 'f1-score': 0.9834990932826536, 'support': 10182}
 
time = 26.70 secondes

Val loss 0.7022605328004918 accuracy 0.9054770469665527 macro_avg {'precision': 0.9082206715100117, 'recall': 0.9045674406018878, 'f1-score': 0.9043507389329871, 'support': 1132} weighted_avg {'precision': 0.9093112365325018, 'recall': 0.9054770318021201, 'f1-score': 0.9053941134629477, 'support': 1132}
 
----------
Epoch 15/40
time = 741.82 secondes

Train loss 0.0790946289721611 accuracy 0.9839913845062256 macro_avg {'precision': 0.983434350194518, 'recall': 0.9833472495411666, 'f1-score': 0.9833685104709591, 'support': 10182} weighted_avg {'precision': 0.9840417513531857, 'recall': 0.9839913572971911, 'f1-score': 0.9839951398787784, 'support': 10182}
 
time = 26.66 secondes

Val loss 0.742345088355622 accuracy 0.8975265026092529 macro_avg {'precision': 0.9084385328930861, 'recall': 0.9000980199530375, 'f1-score': 0.9014797196933234, 'support': 1132} weighted_avg {'precision': 0.9070391224516714, 'recall': 0.8975265017667845, 'f1-score': 0.899290309320324, 'support': 1132}
 
----------
Epoch 16/40
time = 741.65 secondes

Train loss 0.08041946146893471 accuracy 0.985660970211029 macro_avg {'precision': 0.9856194615547731, 'recall': 0.9850751147582638, 'f1-score': 0.985323247579873, 'support': 10182} weighted_avg {'precision': 0.9856764666022644, 'recall': 0.9856609703398154, 'f1-score': 0.985647899550956, 'support': 10182}
 
time = 26.52 secondes

Val loss 0.769576097836531 accuracy 0.9037102460861206 macro_avg {'precision': 0.9068528839497777, 'recall': 0.9053150481951061, 'f1-score': 0.9028945254021863, 'support': 1132} weighted_avg {'precision': 0.9121460600617717, 'recall': 0.9037102473498233, 'f1-score': 0.9053154300903647, 'support': 1132}
 
----------
Epoch 17/40
time = 739.88 secondes

Train loss 0.08199295089703022 accuracy 0.9843842387199402 macro_avg {'precision': 0.9839996172202279, 'recall': 0.9838387656725741, 'f1-score': 0.9838822683010452, 'support': 10182} weighted_avg {'precision': 0.9844269472042982, 'recall': 0.9843842074248674, 'f1-score': 0.9843679668682467, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.7372903117996519 accuracy 0.9054770469665527 macro_avg {'precision': 0.9120023222328577, 'recall': 0.9067428365018685, 'f1-score': 0.9076047656091356, 'support': 1132} weighted_avg {'precision': 0.9109331477884002, 'recall': 0.9054770318021201, 'f1-score': 0.9063305675357956, 'support': 1132}
 
----------
Epoch 18/40
time = 740.74 secondes

Train loss 0.07239913372410411 accuracy 0.9866431355476379 macro_avg {'precision': 0.9858954866972613, 'recall': 0.9859583950976148, 'f1-score': 0.9859224639008856, 'support': 10182} weighted_avg {'precision': 0.9866642342375027, 'recall': 0.9866430956590061, 'f1-score': 0.9866493265396147, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.6861671443846614 accuracy 0.9090105891227722 macro_avg {'precision': 0.9127632989568417, 'recall': 0.9102842402810751, 'f1-score': 0.9093280172921888, 'support': 1132} weighted_avg {'precision': 0.9134039445898802, 'recall': 0.9090106007067138, 'f1-score': 0.9091041899072085, 'support': 1132}
 
----------
Epoch 19/40
time = 738.37 secondes

Train loss 0.06984597953873037 accuracy 0.985562801361084 macro_avg {'precision': 0.98533777249865, 'recall': 0.985311776637209, 'f1-score': 0.9853048527155084, 'support': 10182} weighted_avg {'precision': 0.9856540620623843, 'recall': 0.9855627578078963, 'f1-score': 0.9855883157343173, 'support': 10182}
 
time = 26.63 secondes

Val loss 0.6924549462039041 accuracy 0.916077733039856 macro_avg {'precision': 0.9202099043302393, 'recall': 0.9195242837868183, 'f1-score': 0.9175606425781451, 'support': 1132} weighted_avg {'precision': 0.9212210884517269, 'recall': 0.916077738515901, 'f1-score': 0.9163553080387207, 'support': 1132}
 
----------
Epoch 20/40
time = 741.87 secondes

Train loss 0.05960764062768261 accuracy 0.9889020323753357 macro_avg {'precision': 0.9889904292166264, 'recall': 0.9888139177566625, 'f1-score': 0.9888876332920307, 'support': 10182} weighted_avg {'precision': 0.9889328856205835, 'recall': 0.9889019838931448, 'f1-score': 0.9889027163760898, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.803423566248454 accuracy 0.8992933034896851 macro_avg {'precision': 0.9110905595391937, 'recall': 0.9008805228219268, 'f1-score': 0.9018995167338888, 'support': 1132} weighted_avg {'precision': 0.9109057465043133, 'recall': 0.8992932862190812, 'f1-score': 0.9007011097203244, 'support': 1132}
 
----------
Epoch 21/40
time = 741.00 secondes

Train loss 0.06990170718090152 accuracy 0.987625241279602 macro_avg {'precision': 0.9875345238523895, 'recall': 0.9874866263078026, 'f1-score': 0.9875001570044841, 'support': 10182} weighted_avg {'precision': 0.9876471953310395, 'recall': 0.9876252209781968, 'f1-score': 0.9876262640324085, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.6673800612403334 accuracy 0.9151943325996399 macro_avg {'precision': 0.9162917830525578, 'recall': 0.9150399117287342, 'f1-score': 0.9148216850611461, 'support': 1132} weighted_avg {'precision': 0.9177255489919146, 'recall': 0.9151943462897526, 'f1-score': 0.9156309148219633, 'support': 1132}
 
----------
Epoch 22/40
time = 738.51 secondes

Train loss 0.0603438206285097 accuracy 0.9894912838935852 macro_avg {'precision': 0.9891432796650415, 'recall': 0.9892950628494843, 'f1-score': 0.9892011211073545, 'support': 10182} weighted_avg {'precision': 0.9895282727046321, 'recall': 0.9894912590846592, 'f1-score': 0.989493811728639, 'support': 10182}
 
time = 26.25 secondes

Val loss 0.6747164836486033 accuracy 0.9151943325996399 macro_avg {'precision': 0.9170414508360965, 'recall': 0.9160886874918981, 'f1-score': 0.9150041167005958, 'support': 1132} weighted_avg {'precision': 0.9189854188021072, 'recall': 0.9151943462897526, 'f1-score': 0.915681508816901, 'support': 1132}
 
----------
Epoch 23/40
time = 740.28 secondes

Train loss 0.04946355698713139 accuracy 0.9910627007484436 macro_avg {'precision': 0.990923219199398, 'recall': 0.9910935628481324, 'f1-score': 0.991000887336741, 'support': 10182} weighted_avg {'precision': 0.9910762974295053, 'recall': 0.9910626595953643, 'f1-score': 0.9910628047612561, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.6650558603356894 accuracy 0.9125441908836365 macro_avg {'precision': 0.9153826219095352, 'recall': 0.9150549698631691, 'f1-score': 0.913675770313057, 'support': 1132} weighted_avg {'precision': 0.918230788594679, 'recall': 0.9125441696113075, 'f1-score': 0.9139862238245208, 'support': 1132}
 
----------
Epoch 24/40
time = 740.27 secondes

Train loss 0.052766339043718656 accuracy 0.9908662438392639 macro_avg {'precision': 0.9907926013721167, 'recall': 0.9906270979786591, 'f1-score': 0.9906934524776357, 'support': 10182} weighted_avg {'precision': 0.9908706467046494, 'recall': 0.9908662345315262, 'f1-score': 0.9908526961480695, 'support': 10182}
 
time = 23.64 secondes

Val loss 0.657197671531065 accuracy 0.9204947352409363 macro_avg {'precision': 0.9260149249062577, 'recall': 0.9207762954249082, 'f1-score': 0.9221204507028384, 'support': 1132} weighted_avg {'precision': 0.9239464152651099, 'recall': 0.9204946996466431, 'f1-score': 0.920915201980197, 'support': 1132}
 
----------
Epoch 25/40
time = 740.30 secondes

Train loss 0.059204727546806266 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888869132805848, 'recall': 0.9887595055213557, 'f1-score': 0.9887831356245611, 'support': 10182} weighted_avg {'precision': 0.9889915182621664, 'recall': 0.9889019838931448, 'f1-score': 0.9889057062056977, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.7011238908911969 accuracy 0.9098939895629883 macro_avg {'precision': 0.9145265498540385, 'recall': 0.9138268047137597, 'f1-score': 0.912098840550885, 'support': 1132} weighted_avg {'precision': 0.9148943048924367, 'recall': 0.9098939929328622, 'f1-score': 0.9103216210774013, 'support': 1132}
 
----------
Epoch 26/40
time = 741.31 secondes

Train loss 0.04673843390219547 accuracy 0.9929287433624268 macro_avg {'precision': 0.9925480788181538, 'recall': 0.9924104668513885, 'f1-score': 0.9924619902747309, 'support': 10182} weighted_avg {'precision': 0.9929375995355554, 'recall': 0.9929286977018268, 'f1-score': 0.9929170895513297, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.6461966410902342 accuracy 0.9196113348007202 macro_avg {'precision': 0.9190376672570583, 'recall': 0.9201189236131475, 'f1-score': 0.9175895654175417, 'support': 1132} weighted_avg {'precision': 0.9230444943936457, 'recall': 0.9196113074204947, 'f1-score': 0.9193898715384634, 'support': 1132}
 
----------
Epoch 27/40
time = 739.79 secondes

Train loss 0.03241056676628635 accuracy 0.9941073060035706 macro_avg {'precision': 0.9939833983816335, 'recall': 0.9941516150528752, 'f1-score': 0.9940607898708617, 'support': 10182} weighted_avg {'precision': 0.9941270993023057, 'recall': 0.9941072480848556, 'f1-score': 0.9941104602613525, 'support': 10182}
 
time = 25.33 secondes

Val loss 0.7210868510913533 accuracy 0.9134275913238525 macro_avg {'precision': 0.9142484223869836, 'recall': 0.9153470683859558, 'f1-score': 0.9132207807274412, 'support': 1132} weighted_avg {'precision': 0.9181906589929572, 'recall': 0.9134275618374559, 'f1-score': 0.9142962802950307, 'support': 1132}
 
----------
Epoch 28/40
time = 740.80 secondes

Train loss 0.03714516977087266 accuracy 0.9942054748535156 macro_avg {'precision': 0.9942320106443902, 'recall': 0.9940894919658811, 'f1-score': 0.9941538490268845, 'support': 10182} weighted_avg {'precision': 0.9942095224602665, 'recall': 0.9942054606167747, 'f1-score': 0.994200727502615, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.727250716769869 accuracy 0.916077733039856 macro_avg {'precision': 0.9167778236910429, 'recall': 0.9173629614199392, 'f1-score': 0.915686194541179, 'support': 1132} weighted_avg {'precision': 0.9183370029426168, 'recall': 0.916077738515901, 'f1-score': 0.9157528157842735, 'support': 1132}
 
----------
Epoch 29/40
time = 739.80 secondes

Train loss 0.03338839421875958 accuracy 0.9931251406669617 macro_avg {'precision': 0.9925239514861086, 'recall': 0.9928720766310292, 'f1-score': 0.9926885197645431, 'support': 10182} weighted_avg {'precision': 0.9931559893934012, 'recall': 0.9931251227656649, 'f1-score': 0.9931325755829903, 'support': 10182}
 
time = 26.41 secondes

Val loss 0.6895060297676127 accuracy 0.9187279343605042 macro_avg {'precision': 0.9219513941469861, 'recall': 0.9195959618656726, 'f1-score': 0.9185471360024984, 'support': 1132} weighted_avg {'precision': 0.9238932221029444, 'recall': 0.9187279151943463, 'f1-score': 0.9189589859309414, 'support': 1132}
 
----------
Epoch 30/40
time = 739.06 secondes

Train loss 0.029190190497586282 accuracy 0.9945001006126404 macro_avg {'precision': 0.9943866651165274, 'recall': 0.9943215973648867, 'f1-score': 0.9943508009063484, 'support': 10182} weighted_avg {'precision': 0.9945040315542736, 'recall': 0.9945000982125319, 'f1-score': 0.9944988472155075, 'support': 10182}
 
time = 26.70 secondes

Val loss 0.7396101179780397 accuracy 0.916077733039856 macro_avg {'precision': 0.9167691753138234, 'recall': 0.9182768458707022, 'f1-score': 0.9162172599627197, 'support': 1132} weighted_avg {'precision': 0.9206499007889762, 'recall': 0.916077738515901, 'f1-score': 0.9171578913104284, 'support': 1132}
 
----------
Epoch 31/40
time = 739.93 secondes

Train loss 0.027109427578541376 accuracy 0.9951876401901245 macro_avg {'precision': 0.9949895872052503, 'recall': 0.9950413954405116, 'f1-score': 0.9950063417646706, 'support': 10182} weighted_avg {'precision': 0.9952071052449616, 'recall': 0.9951875859359655, 'f1-score': 0.9951890306190915, 'support': 10182}
 
time = 26.53 secondes

Val loss 0.8120902511089068 accuracy 0.9098939895629883 macro_avg {'precision': 0.9130010329943273, 'recall': 0.912081165898336, 'f1-score': 0.9112192888731186, 'support': 1132} weighted_avg {'precision': 0.9136964255422609, 'recall': 0.9098939929328622, 'f1-score': 0.9104842866137749, 'support': 1132}
 
----------
Epoch 32/40
time = 740.85 secondes

Train loss 0.02384930686628427 accuracy 0.9956786632537842 macro_avg {'precision': 0.9956538574188082, 'recall': 0.9956480498857134, 'f1-score': 0.9956455940699842, 'support': 10182} weighted_avg {'precision': 0.9956899435800555, 'recall': 0.9956786485955608, 'f1-score': 0.9956787972167519, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.8175571015999081 accuracy 0.9125441908836365 macro_avg {'precision': 0.9130971272685177, 'recall': 0.9133825305249337, 'f1-score': 0.9108379900103266, 'support': 1132} weighted_avg {'precision': 0.9172564985842215, 'recall': 0.9125441696113075, 'f1-score': 0.9127354836661481, 'support': 1132}
 
----------
Epoch 33/40
time = 739.35 secondes

Train loss 0.026375233416319543 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953367399467815, 'recall': 0.9953794863201114, 'f1-score': 0.9953522968401238, 'support': 10182} weighted_avg {'precision': 0.995390371648045, 'recall': 0.9953840109998036, 'f1-score': 0.9953813112753177, 'support': 10182}
 
time = 26.26 secondes

Val loss 0.7233253677900201 accuracy 0.9116607904434204 macro_avg {'precision': 0.9142741648563633, 'recall': 0.9111500250967792, 'f1-score': 0.9112245726401287, 'support': 1132} weighted_avg {'precision': 0.9159137529952537, 'recall': 0.911660777385159, 'f1-score': 0.9123331181774936, 'support': 1132}
 
----------
Epoch 34/40
time = 740.15 secondes

Train loss 0.025712768454448472 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959007497516538, 'recall': 0.995880436563537, 'f1-score': 0.9958888761394367, 'support': 10182} weighted_avg {'precision': 0.9958837509148133, 'recall': 0.995875073659399, 'f1-score': 0.9958776463279092, 'support': 10182}
 
time = 22.70 secondes

Val loss 0.7438799435163469 accuracy 0.916077733039856 macro_avg {'precision': 0.9176371525202146, 'recall': 0.9170617030456473, 'f1-score': 0.9158393086581338, 'support': 1132} weighted_avg {'precision': 0.9191453985752768, 'recall': 0.916077738515901, 'f1-score': 0.9161227697614773, 'support': 1132}
 
----------
Epoch 35/40
time = 738.90 secondes

Train loss 0.023817625896026727 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963580412947628, 'recall': 0.9964386227422732, 'f1-score': 0.9963928615950387, 'support': 10182} weighted_avg {'precision': 0.9963679270756913, 'recall': 0.9963661363189943, 'f1-score': 0.9963614843192848, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.7840364932625574 accuracy 0.9072438478469849 macro_avg {'precision': 0.9106305479408265, 'recall': 0.9101035957225235, 'f1-score': 0.9087039330445617, 'support': 1132} weighted_avg {'precision': 0.9122961653453384, 'recall': 0.907243816254417, 'f1-score': 0.9079768426669993, 'support': 1132}
 
----------
Epoch 36/40
time = 740.89 secondes

Train loss 0.018018320269304805 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971243322083077, 'recall': 0.9971953062242752, 'f1-score': 0.9971556500577439, 'support': 10182} weighted_avg {'precision': 0.9971594675151301, 'recall': 0.9971518365743469, 'f1-score': 0.9971513735443994, 'support': 10182}
 
time = 26.40 secondes

Val loss 0.725838111334359 accuracy 0.9151943325996399 macro_avg {'precision': 0.9164335369932074, 'recall': 0.9168996797563137, 'f1-score': 0.9155931824776327, 'support': 1132} weighted_avg {'precision': 0.9185444641095326, 'recall': 0.9151943462897526, 'f1-score': 0.9158920286179242, 'support': 1132}
 
----------
Epoch 37/40
time = 738.68 secondes

Train loss 0.00976412360589788 accuracy 0.9985268115997314 macro_avg {'precision': 0.998500742059156, 'recall': 0.9985793814898003, 'f1-score': 0.9985392553556908, 'support': 10182} weighted_avg {'precision': 0.9985278999819355, 'recall': 0.998526812021214, 'f1-score': 0.9985265749682621, 'support': 10182}
 
time = 26.29 secondes

Val loss 0.7364242106342432 accuracy 0.916077733039856 macro_avg {'precision': 0.9177379845910192, 'recall': 0.9168168323873906, 'f1-score': 0.9161720322525255, 'support': 1132} weighted_avg {'precision': 0.9195279313251004, 'recall': 0.916077738515901, 'f1-score': 0.9165914193763598, 'support': 1132}
 
----------
Epoch 38/40
time = 738.30 secondes

Train loss 0.00913411911748411 accuracy 0.9984286427497864 macro_avg {'precision': 0.9985031571860066, 'recall': 0.998440342463088, 'f1-score': 0.9984688304127944, 'support': 10182} weighted_avg {'precision': 0.9984341760037645, 'recall': 0.9984285994892949, 'f1-score': 0.9984283536093479, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7219096824802095 accuracy 0.9098939895629883 macro_avg {'precision': 0.9154098450303522, 'recall': 0.9117638931213733, 'f1-score': 0.9111083212738571, 'support': 1132} weighted_avg {'precision': 0.9195739779073222, 'recall': 0.9098939929328622, 'f1-score': 0.9123235627748953, 'support': 1132}
 
----------
Epoch 39/40
time = 738.53 secondes

Train loss 0.005906547227136705 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990947479849261, 'recall': 0.9991440811883082, 'f1-score': 0.9991190777505532, 'support': 10182} weighted_avg {'precision': 0.9991163778365768, 'recall': 0.9991160872127284, 'f1-score': 0.9991159258406755, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.718827218840962 accuracy 0.9134275913238525 macro_avg {'precision': 0.9136026979394847, 'recall': 0.9154091315280066, 'f1-score': 0.9133300873557838, 'support': 1132} weighted_avg {'precision': 0.9159357704759735, 'recall': 0.9134275618374559, 'f1-score': 0.9134775033893502, 'support': 1132}
 
----------
Epoch 40/40
time = 739.24 secondes

Train loss 0.005780669942423471 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990265749348868, 'recall': 0.9991463890745791, 'f1-score': 0.9990853072726438, 'support': 10182} weighted_avg {'precision': 0.9991185752901142, 'recall': 0.9991160872127284, 'f1-score': 0.9991162878656017, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.736280445923115 accuracy 0.9204947352409363 macro_avg {'precision': 0.9219199705417429, 'recall': 0.9215476334594381, 'f1-score': 0.9203826526178835, 'support': 1132} weighted_avg {'precision': 0.9238507094838615, 'recall': 0.9204946996466431, 'f1-score': 0.9208397671869567, 'support': 1132}
 
----------
best_accuracy 0.9204947352409363 best_epoch 24 macro_avg {'precision': 0.9260149249062577, 'recall': 0.9207762954249082, 'f1-score': 0.9221204507028384, 'support': 1132} weighted_avg {'precision': 0.9239464152651099, 'recall': 0.9204946996466431, 'f1-score': 0.920915201980197, 'support': 1132}

average train time 740.6495288848877

average val time 26.20484483242035
 
time = 172.78 secondes

test_accuracy 0.845724880695343 macro_avg {'precision': 0.8532066722717243, 'recall': 0.8377080461963533, 'f1-score': 0.8406472891327885, 'support': 7532} weighted_avg {'precision': 0.8558311960373348, 'recall': 0.845724907063197, 'f1-score': 0.8461164063018622, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_1
----------
Epoch 1/40
time = 1024.73 secondes

Train loss 1.0764871449962703 accuracy 0.6921037435531616 macro_avg {'precision': 0.6989353558920762, 'recall': 0.6786177804249685, 'f1-score': 0.6743226744744403, 'support': 10182} weighted_avg {'precision': 0.70754554828902, 'recall': 0.6921037124337065, 'f1-score': 0.6880747486713723, 'support': 10182}
 
time = 33.39 secondes

Val loss 0.5713264046000762 accuracy 0.8180211782455444 macro_avg {'precision': 0.8109526498545913, 'recall': 0.8146258637086656, 'f1-score': 0.8016251461389331, 'support': 1132} weighted_avg {'precision': 0.8133134601000619, 'recall': 0.8180212014134276, 'f1-score': 0.8051901952751507, 'support': 1132}
 
----------
Epoch 2/40
time = 1024.88 secondes

Train loss 0.40039510071991097 accuracy 0.8826360702514648 macro_avg {'precision': 0.8758733773066554, 'recall': 0.8742138797621607, 'f1-score': 0.8741973631673231, 'support': 10182} weighted_avg {'precision': 0.881403436162132, 'recall': 0.882636024356708, 'f1-score': 0.8813563793482955, 'support': 10182}
 
time = 32.13 secondes

Val loss 0.4230448785959415 accuracy 0.8789752721786499 macro_avg {'precision': 0.8788910042158777, 'recall': 0.8813849615033627, 'f1-score': 0.8763149826366614, 'support': 1132} weighted_avg {'precision': 0.8819612400735175, 'recall': 0.8789752650176679, 'f1-score': 0.8762303693288115, 'support': 1132}
 
----------
Epoch 3/40
time = 1024.56 secondes

Train loss 0.2420178523062022 accuracy 0.9332154989242554 macro_avg {'precision': 0.92946100192798, 'recall': 0.9292492778904551, 'f1-score': 0.9292890871333093, 'support': 10182} weighted_avg {'precision': 0.9332812868300278, 'recall': 0.9332154782950305, 'f1-score': 0.933186765997232, 'support': 10182}
 
time = 32.88 secondes

Val loss 0.5215500641194447 accuracy 0.8754417300224304 macro_avg {'precision': 0.8859820120760912, 'recall': 0.8741572627149308, 'f1-score': 0.8731580006970427, 'support': 1132} weighted_avg {'precision': 0.8850048095596816, 'recall': 0.8754416961130742, 'f1-score': 0.8735646808714558, 'support': 1132}
 
----------
Epoch 4/40
time = 1023.80 secondes

Train loss 0.18833751894469306 accuracy 0.9514830112457275 macro_avg {'precision': 0.949836997565812, 'recall': 0.9497692062983422, 'f1-score': 0.9497581244605877, 'support': 10182} weighted_avg {'precision': 0.9516857887679225, 'recall': 0.951483009231978, 'f1-score': 0.9515411981086018, 'support': 10182}
 
time = 32.37 secondes

Val loss 0.5048644639302412 accuracy 0.8957597017288208 macro_avg {'precision': 0.8994287948279396, 'recall': 0.8975256073643303, 'f1-score': 0.8957028425472228, 'support': 1132} weighted_avg {'precision': 0.9030830093196656, 'recall': 0.8957597173144877, 'f1-score': 0.8968656724809984, 'support': 1132}
 
----------
Epoch 5/40
time = 1023.62 secondes

Train loss 0.16764402912042925 accuracy 0.9563936591148376 macro_avg {'precision': 0.9548907326756815, 'recall': 0.9546959294228488, 'f1-score': 0.9547561068155591, 'support': 10182} weighted_avg {'precision': 0.9564483977281206, 'recall': 0.9563936358279317, 'f1-score': 0.9563839811531614, 'support': 10182}
 
time = 32.12 secondes

Val loss 0.4989143911745845 accuracy 0.9037102460861206 macro_avg {'precision': 0.9116752640438224, 'recall': 0.9078492079918238, 'f1-score': 0.9059647927742119, 'support': 1132} weighted_avg {'precision': 0.9108301997182671, 'recall': 0.9037102473498233, 'f1-score': 0.9029797676950134, 'support': 1132}
 
----------
Epoch 6/40
time = 1023.31 secondes

Train loss 0.1337077824113411 accuracy 0.967197060585022 macro_avg {'precision': 0.9662199351030918, 'recall': 0.9661776152779131, 'f1-score': 0.9661655569653327, 'support': 10182} weighted_avg {'precision': 0.9672937677541613, 'recall': 0.9671970143390297, 'f1-score': 0.9672127133947387, 'support': 10182}
 
time = 31.97 secondes

Val loss 0.5888678016613277 accuracy 0.9001767039299011 macro_avg {'precision': 0.9021497043225967, 'recall': 0.9019262738947169, 'f1-score': 0.898988420300643, 'support': 1132} weighted_avg {'precision': 0.9018684865446347, 'recall': 0.9001766784452296, 'f1-score': 0.8978217976281426, 'support': 1132}
 
----------
Epoch 7/40
time = 1024.31 secondes

Train loss 0.13921104858088815 accuracy 0.9680809378623962 macro_avg {'precision': 0.9673034889477906, 'recall': 0.967623358851216, 'f1-score': 0.9674127527477898, 'support': 10182} weighted_avg {'precision': 0.9682930249412235, 'recall': 0.9680809271263013, 'f1-score': 0.9681376640224285, 'support': 10182}
 
time = 32.21 secondes

Val loss 0.5170876113328965 accuracy 0.9125441908836365 macro_avg {'precision': 0.913673221245927, 'recall': 0.9149591568131509, 'f1-score': 0.912488553097554, 'support': 1132} weighted_avg {'precision': 0.9150097998980778, 'recall': 0.9125441696113075, 'f1-score': 0.911683042082315, 'support': 1132}
 
----------
Epoch 8/40
time = 1025.47 secondes

Train loss 0.11626573737997276 accuracy 0.9730898141860962 macro_avg {'precision': 0.9723350677871645, 'recall': 0.9722601852915472, 'f1-score': 0.972263023039569, 'support': 10182} weighted_avg {'precision': 0.9731247521410942, 'recall': 0.973089766254174, 'f1-score': 0.9730718018811687, 'support': 10182}
 
time = 32.35 secondes

Val loss 0.5456302823120905 accuracy 0.916077733039856 macro_avg {'precision': 0.9193781441528728, 'recall': 0.9163604414353875, 'f1-score': 0.9156069427943929, 'support': 1132} weighted_avg {'precision': 0.9202814937487964, 'recall': 0.916077738515901, 'f1-score': 0.9159545993975302, 'support': 1132}
 
----------
Epoch 9/40
time = 1026.01 secondes

Train loss 0.11917532363765232 accuracy 0.9742683172225952 macro_avg {'precision': 0.9736690191122819, 'recall': 0.9735052843706165, 'f1-score': 0.9735500079234717, 'support': 10182} weighted_avg {'precision': 0.9742855222952774, 'recall': 0.9742683166372029, 'f1-score': 0.9742393061479586, 'support': 10182}
 
time = 31.37 secondes

Val loss 0.5794078572194131 accuracy 0.9090105891227722 macro_avg {'precision': 0.9103936069843879, 'recall': 0.908889471199801, 'f1-score': 0.9075193690068566, 'support': 1132} weighted_avg {'precision': 0.9138158359621101, 'recall': 0.9090106007067138, 'f1-score': 0.9093388870387071, 'support': 1132}
 
----------
Epoch 10/40
time = 1024.99 secondes

Train loss 0.10208787572402192 accuracy 0.9770182967185974 macro_avg {'precision': 0.9769046699231152, 'recall': 0.9767388802066215, 'f1-score': 0.9767831067505883, 'support': 10182} weighted_avg {'precision': 0.9770801096987111, 'recall': 0.9770182675309369, 'f1-score': 0.9770094624813929, 'support': 10182}
 
time = 32.14 secondes

Val loss 0.802321792209216 accuracy 0.8860424160957336 macro_avg {'precision': 0.9017795318988118, 'recall': 0.889982668480369, 'f1-score': 0.8878401607550638, 'support': 1132} weighted_avg {'precision': 0.9010901365422572, 'recall': 0.8860424028268551, 'f1-score': 0.8842115410745749, 'support': 1132}
 
----------
Epoch 11/40
time = 1023.54 secondes

Train loss 0.11900583090324772 accuracy 0.9766254425048828 macro_avg {'precision': 0.9759220936624328, 'recall': 0.9754643701611917, 'f1-score': 0.9756239153766586, 'support': 10182} weighted_avg {'precision': 0.9767299944829103, 'recall': 0.9766254174032607, 'f1-score': 0.9766143095190633, 'support': 10182}
 
time = 32.39 secondes

Val loss 0.7003994588608998 accuracy 0.9072438478469849 macro_avg {'precision': 0.9169625158842898, 'recall': 0.9022135512968706, 'f1-score': 0.9063577132710261, 'support': 1132} weighted_avg {'precision': 0.9134926586076244, 'recall': 0.907243816254417, 'f1-score': 0.9072182758298172, 'support': 1132}
 
----------
Epoch 12/40
time = 1023.69 secondes

Train loss 0.0948579298518333 accuracy 0.9803575277328491 macro_avg {'precision': 0.9799248106440437, 'recall': 0.9792507793314679, 'f1-score': 0.979544327525416, 'support': 10182} weighted_avg {'precision': 0.9803865695694135, 'recall': 0.9803574936161854, 'f1-score': 0.9803335041463639, 'support': 10182}
 
time = 32.05 secondes

Val loss 0.7162997829936885 accuracy 0.8975265026092529 macro_avg {'precision': 0.9096217770953745, 'recall': 0.9043810045872422, 'f1-score': 0.9019505673330327, 'support': 1132} weighted_avg {'precision': 0.9113000998310312, 'recall': 0.8975265017667845, 'f1-score': 0.8990503119632081, 'support': 1132}
 
----------
Epoch 13/40
time = 1024.37 secondes

Train loss 0.08759451265084255 accuracy 0.9834021329879761 macro_avg {'precision': 0.9828528838566075, 'recall': 0.982548556309561, 'f1-score': 0.9826839435784056, 'support': 10182} weighted_avg {'precision': 0.9834082355559699, 'recall': 0.9834020821056767, 'f1-score': 0.9833890809469851, 'support': 10182}
 
time = 32.19 secondes

Val loss 0.6333463275610407 accuracy 0.9116607904434204 macro_avg {'precision': 0.9144524622705832, 'recall': 0.9128713759201726, 'f1-score': 0.9114515951900162, 'support': 1132} weighted_avg {'precision': 0.9160664960753082, 'recall': 0.911660777385159, 'f1-score': 0.9118002493452724, 'support': 1132}
 
----------
Epoch 14/40
time = 1022.93 secondes

Train loss 0.07619648648108765 accuracy 0.9863485097885132 macro_avg {'precision': 0.9859986146533031, 'recall': 0.9862264685357068, 'f1-score': 0.986095438956885, 'support': 10182} weighted_avg {'precision': 0.986376968929731, 'recall': 0.9863484580632489, 'f1-score': 0.9863460049264852, 'support': 10182}
 
time = 32.39 secondes

Val loss 0.6455491539834864 accuracy 0.9107773900032043 macro_avg {'precision': 0.9131196935254653, 'recall': 0.9102782780721868, 'f1-score': 0.9105239967706436, 'support': 1132} weighted_avg {'precision': 0.9146643433437743, 'recall': 0.9107773851590106, 'f1-score': 0.9114657033383425, 'support': 1132}
 
----------
Epoch 15/40
time = 1023.83 secondes

Train loss 0.08517470872267702 accuracy 0.9838931560516357 macro_avg {'precision': 0.9833933455486872, 'recall': 0.983380465534473, 'f1-score': 0.9833730826419075, 'support': 10182} weighted_avg {'precision': 0.9839035861370429, 'recall': 0.983893144765272, 'f1-score': 0.9838847052142307, 'support': 10182}
 
time = 31.44 secondes

Val loss 0.7082462010007027 accuracy 0.9037102460861206 macro_avg {'precision': 0.9081686981855771, 'recall': 0.904097424430278, 'f1-score': 0.9035471839636419, 'support': 1132} weighted_avg {'precision': 0.9092821241804081, 'recall': 0.9037102473498233, 'f1-score': 0.9041944468252558, 'support': 1132}
 
----------
Epoch 16/40
time = 1022.52 secondes

Train loss 0.07840290349383938 accuracy 0.9847770929336548 macro_avg {'precision': 0.9845098830512576, 'recall': 0.9844287530118118, 'f1-score': 0.984459791822436, 'support': 10182} weighted_avg {'precision': 0.9848135757333448, 'recall': 0.9847770575525437, 'f1-score': 0.9847858137163709, 'support': 10182}
 
time = 27.38 secondes

Val loss 0.7684039675231373 accuracy 0.9019434452056885 macro_avg {'precision': 0.9100004327471769, 'recall': 0.904821488953624, 'f1-score': 0.9031367300777513, 'support': 1132} weighted_avg {'precision': 0.9150503220765733, 'recall': 0.9019434628975265, 'f1-score': 0.9040074225574136, 'support': 1132}
 
----------
Epoch 17/40
time = 1024.98 secondes

Train loss 0.08607077978776542 accuracy 0.9847770929336548 macro_avg {'precision': 0.9846597977138695, 'recall': 0.9847014285800911, 'f1-score': 0.9846705905871749, 'support': 10182} weighted_avg {'precision': 0.9848100785405829, 'recall': 0.9847770575525437, 'f1-score': 0.9847832513969191, 'support': 10182}
 
time = 32.01 secondes

Val loss 0.7243563837698057 accuracy 0.9090105891227722 macro_avg {'precision': 0.9106598171721997, 'recall': 0.9066930096813891, 'f1-score': 0.906390704053465, 'support': 1132} weighted_avg {'precision': 0.9121019375082015, 'recall': 0.9090106007067138, 'f1-score': 0.9083999941659323, 'support': 1132}
 
----------
Epoch 18/40
time = 1024.89 secondes

Train loss 0.0871782258107821 accuracy 0.9840896129608154 macro_avg {'precision': 0.9839252750337076, 'recall': 0.9835773936975519, 'f1-score': 0.9837085594122131, 'support': 10182} weighted_avg {'precision': 0.9841583823497522, 'recall': 0.9840895698291102, 'f1-score': 0.9840867751411763, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.8798971516736062 accuracy 0.8886925578117371 macro_avg {'precision': 0.9056214489619334, 'recall': 0.8815948840071794, 'f1-score': 0.8826733483555099, 'support': 1132} weighted_avg {'precision': 0.9036010418090042, 'recall': 0.8886925795053003, 'f1-score': 0.8872738334330628, 'support': 1132}
 
----------
Epoch 19/40
time = 1023.49 secondes

Train loss 0.08396983491434791 accuracy 0.985660970211029 macro_avg {'precision': 0.9855351618181224, 'recall': 0.9853002327324688, 'f1-score': 0.9853638042093793, 'support': 10182} weighted_avg {'precision': 0.9857298528103167, 'recall': 0.9856609703398154, 'f1-score': 0.9856440589921959, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.7885613369810375 accuracy 0.9054770469665527 macro_avg {'precision': 0.9141753950991817, 'recall': 0.9048764966759221, 'f1-score': 0.9065057751072862, 'support': 1132} weighted_avg {'precision': 0.9119084971595932, 'recall': 0.9054770318021201, 'f1-score': 0.9057179635513991, 'support': 1132}
 
----------
Epoch 20/40
time = 1022.01 secondes

Train loss 0.06521608722985353 accuracy 0.9880180954933167 macro_avg {'precision': 0.9878408008143629, 'recall': 0.9878430246478539, 'f1-score': 0.9878218811575475, 'support': 10182} weighted_avg {'precision': 0.9880566754410776, 'recall': 0.9880180711058731, 'f1-score': 0.9880182396920765, 'support': 10182}
 
time = 29.96 secondes

Val loss 0.7892391096108222 accuracy 0.9010601043701172 macro_avg {'precision': 0.9049833292933496, 'recall': 0.9046196876335573, 'f1-score': 0.9019367974695571, 'support': 1132} weighted_avg {'precision': 0.9078830952655106, 'recall': 0.901060070671378, 'f1-score': 0.9015470221879509, 'support': 1132}
 
----------
Epoch 21/40
time = 1021.26 secondes

Train loss 0.05363096450391065 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893936497157068, 'recall': 0.9892291643738365, 'f1-score': 0.9893042463429733, 'support': 10182} weighted_avg {'precision': 0.9893939293803005, 'recall': 0.9893930465527401, 'f1-score': 0.9893865680849641, 'support': 10182}
 
time = 32.29 secondes

Val loss 0.6728296002164453 accuracy 0.9081271886825562 macro_avg {'precision': 0.9133416761702664, 'recall': 0.910485402002621, 'f1-score': 0.9101630683453182, 'support': 1132} weighted_avg {'precision': 0.9129775920756867, 'recall': 0.9081272084805654, 'f1-score': 0.9086213477597148, 'support': 1132}
 
----------
Epoch 22/40
time = 1023.61 secondes

Train loss 0.05319750729750997 accuracy 0.98978590965271 macro_avg {'precision': 0.9892031194918856, 'recall': 0.9894409932576554, 'f1-score': 0.9893029882605173, 'support': 10182} weighted_avg {'precision': 0.9898360916610388, 'recall': 0.9897858966804164, 'f1-score': 0.9897949757731386, 'support': 10182}
 
time = 31.86 secondes

Val loss 0.6254858621378703 accuracy 0.9151943325996399 macro_avg {'precision': 0.9265359487121005, 'recall': 0.9158014832220314, 'f1-score': 0.9182005604578786, 'support': 1132} weighted_avg {'precision': 0.9230379317991607, 'recall': 0.9151943462897526, 'f1-score': 0.9160990686902539, 'support': 1132}
 
----------
Epoch 23/40
time = 1023.53 secondes

Train loss 0.052342122080309125 accuracy 0.9900805354118347 macro_avg {'precision': 0.9899369822816826, 'recall': 0.9897464084948181, 'f1-score': 0.989833037251865, 'support': 10182} weighted_avg {'precision': 0.9900906150484255, 'recall': 0.9900805342761736, 'f1-score': 0.9900770090388121, 'support': 10182}
 
time = 32.15 secondes

Val loss 0.7347447222514155 accuracy 0.9090105891227722 macro_avg {'precision': 0.914712483385436, 'recall': 0.9105420957684445, 'f1-score': 0.910023156960127, 'support': 1132} weighted_avg {'precision': 0.9155791237871072, 'recall': 0.9090106007067138, 'f1-score': 0.9096436630715687, 'support': 1132}
 
----------
Epoch 24/40
time = 1023.31 secondes

Train loss 0.05032281281491062 accuracy 0.9908662438392639 macro_avg {'precision': 0.9906778736034367, 'recall': 0.9908040264347958, 'f1-score': 0.9907309672227707, 'support': 10182} weighted_avg {'precision': 0.9908999346708558, 'recall': 0.9908662345315262, 'f1-score': 0.9908732262356009, 'support': 10182}
 
time = 32.33 secondes

Val loss 0.6937136523085147 accuracy 0.9107773900032043 macro_avg {'precision': 0.9173381742673131, 'recall': 0.91141970086484, 'f1-score': 0.9114140823846395, 'support': 1132} weighted_avg {'precision': 0.9172641329512923, 'recall': 0.9107773851590106, 'f1-score': 0.9111317237858253, 'support': 1132}
 
----------
Epoch 25/40
time = 1023.42 secondes

Train loss 0.05059528794895364 accuracy 0.9910627007484436 macro_avg {'precision': 0.9910399681188113, 'recall': 0.9908526413466433, 'f1-score': 0.9909393757838029, 'support': 10182} weighted_avg {'precision': 0.9910786345650375, 'recall': 0.9910626595953643, 'f1-score': 0.9910638165527865, 'support': 10182}
 
time = 32.35 secondes

Val loss 0.6318720468167465 accuracy 0.9222614765167236 macro_avg {'precision': 0.9263564499513233, 'recall': 0.9254998028334643, 'f1-score': 0.9247504879146774, 'support': 1132} weighted_avg {'precision': 0.9261497212395516, 'recall': 0.9222614840989399, 'f1-score': 0.9230779030990901, 'support': 1132}
 
----------
Epoch 26/40
time = 1020.10 secondes

Train loss 0.04826078841197416 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925334785646791, 'recall': 0.9925898436881884, 'f1-score': 0.9925498554360583, 'support': 10182} weighted_avg {'precision': 0.9924587940857116, 'recall': 0.9924376350422314, 'f1-score': 0.992436165450382, 'support': 10182}
 
time = 32.85 secondes

Val loss 0.781056670097519 accuracy 0.9037102460861206 macro_avg {'precision': 0.9117605694543827, 'recall': 0.9065991570316484, 'f1-score': 0.9049555568221322, 'support': 1132} weighted_avg {'precision': 0.9138754068374562, 'recall': 0.9037102473498233, 'f1-score': 0.9048172138321514, 'support': 1132}
 
----------
Epoch 27/40
time = 1023.53 secondes

Train loss 0.04693756652963048 accuracy 0.9915537238121033 macro_avg {'precision': 0.9915586792065868, 'recall': 0.9916186563177811, 'f1-score': 0.9915739933213648, 'support': 10182} weighted_avg {'precision': 0.991583298803238, 'recall': 0.9915537222549597, 'f1-score': 0.991554975669787, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.7433063546169494 accuracy 0.9116607904434204 macro_avg {'precision': 0.9195482081091615, 'recall': 0.9157739566737311, 'f1-score': 0.9141116771702971, 'support': 1132} weighted_avg {'precision': 0.9202397461922291, 'recall': 0.911660777385159, 'f1-score': 0.9124206618080247, 'support': 1132}
 
----------
Epoch 28/40
time = 1022.67 secondes

Train loss 0.03352071545165729 accuracy 0.9942054748535156 macro_avg {'precision': 0.9940638515455344, 'recall': 0.9938380850640949, 'f1-score': 0.9939410843752011, 'support': 10182} weighted_avg {'precision': 0.9942223934270951, 'recall': 0.9942054606167747, 'f1-score': 0.9942050699699828, 'support': 10182}
 
time = 29.84 secondes

Val loss 0.6136548646771215 accuracy 0.9257950782775879 macro_avg {'precision': 0.9261890387781962, 'recall': 0.927527474329113, 'f1-score': 0.9258986065261141, 'support': 1132} weighted_avg {'precision': 0.9282907866147594, 'recall': 0.9257950530035336, 'f1-score': 0.9261871154353502, 'support': 1132}
 
----------
Epoch 29/40
time = 1025.33 secondes

Train loss 0.03794319252154587 accuracy 0.9940090775489807 macro_avg {'precision': 0.9940288545245842, 'recall': 0.9940976841958514, 'f1-score': 0.9940580107573715, 'support': 10182} weighted_avg {'precision': 0.9940203922734654, 'recall': 0.9940090355529365, 'f1-score': 0.9940093761842484, 'support': 10182}
 
time = 32.16 secondes

Val loss 0.8497533677983087 accuracy 0.898409903049469 macro_avg {'precision': 0.9094989341187137, 'recall': 0.9013542881636225, 'f1-score': 0.9007917410850789, 'support': 1132} weighted_avg {'precision': 0.9088848367793927, 'recall': 0.8984098939929329, 'f1-score': 0.8988418114816893, 'support': 1132}
 
----------
Epoch 30/40
time = 1021.84 secondes

Train loss 0.03229315254807896 accuracy 0.9941073060035706 macro_avg {'precision': 0.9941060671956461, 'recall': 0.9942003284438146, 'f1-score': 0.994149623443892, 'support': 10182} weighted_avg {'precision': 0.9941150955698097, 'recall': 0.9941072480848556, 'f1-score': 0.9941076820260373, 'support': 10182}
 
time = 32.00 secondes

Val loss 0.7707429613283111 accuracy 0.9090105891227722 macro_avg {'precision': 0.9102810005403663, 'recall': 0.9133509245035059, 'f1-score': 0.909894421116301, 'support': 1132} weighted_avg {'precision': 0.9150273805420497, 'recall': 0.9090106007067138, 'f1-score': 0.9103721593768063, 'support': 1132}
 
----------
Epoch 31/40
time = 1021.77 secondes

Train loss 0.028931595027913048 accuracy 0.9946965575218201 macro_avg {'precision': 0.9943452192097464, 'recall': 0.9945492956856523, 'f1-score': 0.9944428486979742, 'support': 10182} weighted_avg {'precision': 0.994714773790324, 'recall': 0.99469652327637, 'f1-score': 0.9947017309683652, 'support': 10182}
 
time = 32.09 secondes

Val loss 0.6980843476486486 accuracy 0.926678478717804 macro_avg {'precision': 0.9290148260773934, 'recall': 0.9280001124588309, 'f1-score': 0.9269605044843872, 'support': 1132} weighted_avg {'precision': 0.9294689815228299, 'recall': 0.926678445229682, 'f1-score': 0.9265211179030904, 'support': 1132}
 
----------
Epoch 32/40
time = 1022.71 secondes

Train loss 0.027609420178314723 accuracy 0.9951876401901245 macro_avg {'precision': 0.9947826102728874, 'recall': 0.9948554440038295, 'f1-score': 0.9948156256473327, 'support': 10182} weighted_avg {'precision': 0.9951995880631027, 'recall': 0.9951875859359655, 'f1-score': 0.9951900733474559, 'support': 10182}
 
time = 31.84 secondes

Val loss 0.6637529068428475 accuracy 0.9249116778373718 macro_avg {'precision': 0.9298462396672985, 'recall': 0.9274962085894514, 'f1-score': 0.9275663791894517, 'support': 1132} weighted_avg {'precision': 0.9296648332725056, 'recall': 0.9249116607773852, 'f1-score': 0.9262263390407763, 'support': 1132}
 
----------
Epoch 33/40
time = 1023.67 secondes

Train loss 0.020966692196621117 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963536611214172, 'recall': 0.9963261282384058, 'f1-score': 0.9963372981336466, 'support': 10182} weighted_avg {'precision': 0.996373596408241, 'recall': 0.9963661363189943, 'f1-score': 0.9963672295221706, 'support': 10182}
 
time = 32.06 secondes

Val loss 0.6737364090669717 accuracy 0.9222614765167236 macro_avg {'precision': 0.9230647144304166, 'recall': 0.925935109054147, 'f1-score': 0.9226002375884583, 'support': 1132} weighted_avg {'precision': 0.9263850375947325, 'recall': 0.9222614840989399, 'f1-score': 0.9223991253656294, 'support': 1132}
 
----------
Epoch 34/40
time = 1023.92 secondes

Train loss 0.01736722682300403 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970576672908406, 'recall': 0.996860718946271, 'f1-score': 0.9969547627935643, 'support': 10182} weighted_avg {'precision': 0.9970627707997125, 'recall': 0.9970536240424278, 'f1-score': 0.9970543058014356, 'support': 10182}
 
time = 31.73 secondes

Val loss 0.673796150401986 accuracy 0.9293286204338074 macro_avg {'precision': 0.9299768617851454, 'recall': 0.9315996543959338, 'f1-score': 0.9302742390965264, 'support': 1132} weighted_avg {'precision': 0.9304241448829335, 'recall': 0.9293286219081273, 'f1-score': 0.9293400499691428, 'support': 1132}
 
----------
Epoch 35/40
time = 1019.83 secondes

Train loss 0.01447960056464001 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974159039329888, 'recall': 0.9974839430322107, 'f1-score': 0.9974478303652583, 'support': 10182} weighted_avg {'precision': 0.9975478677892999, 'recall': 0.9975446867020232, 'f1-score': 0.9975441790571511, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.6800740208553846 accuracy 0.9231448769569397 macro_avg {'precision': 0.9260764015335804, 'recall': 0.9251093431543002, 'f1-score': 0.9244193833771333, 'support': 1132} weighted_avg {'precision': 0.9273594221585976, 'recall': 0.9231448763250883, 'f1-score': 0.9240520418342951, 'support': 1132}
 
----------
Epoch 36/40
time = 1025.23 secondes

Train loss 0.015896143655050675 accuracy 0.9974464774131775 macro_avg {'precision': 0.9973569231090554, 'recall': 0.9972952701392976, 'f1-score': 0.9973240042159082, 'support': 10182} weighted_avg {'precision': 0.9974505490993197, 'recall': 0.9974464741701041, 'f1-score': 0.9974465183593655, 'support': 10182}
 
time = 31.90 secondes

Val loss 0.6662674955925826 accuracy 0.926678478717804 macro_avg {'precision': 0.9301860572142472, 'recall': 0.9296967992957695, 'f1-score': 0.9285908529627112, 'support': 1132} weighted_avg {'precision': 0.9311983969843084, 'recall': 0.926678445229682, 'f1-score': 0.9274622436561737, 'support': 1132}
 
----------
Epoch 37/40
time = 1021.97 secondes

Train loss 0.013099403011266638 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979486218250646, 'recall': 0.9979970627581303, 'f1-score': 0.9979720700420248, 'support': 10182} weighted_avg {'precision': 0.9979394735508683, 'recall': 0.9979375368296994, 'f1-score': 0.9979377406047404, 'support': 10182}
 
time = 32.24 secondes

Val loss 0.6471279403573955 accuracy 0.9293286204338074 macro_avg {'precision': 0.929011195241902, 'recall': 0.9314181471854551, 'f1-score': 0.929466130963081, 'support': 1132} weighted_avg {'precision': 0.9305399754034203, 'recall': 0.9293286219081273, 'f1-score': 0.9291355635277382, 'support': 1132}
 
----------
Epoch 38/40
time = 1023.10 secondes

Train loss 0.006901817827863372 accuracy 0.998821496963501 macro_avg {'precision': 0.9987674010496406, 'recall': 0.9988156465219026, 'f1-score': 0.9987895956898504, 'support': 10182} weighted_avg {'precision': 0.9988260711924489, 'recall': 0.9988214496169712, 'f1-score': 0.9988219604946775, 'support': 10182}
 
time = 32.37 secondes

Val loss 0.6256438842882116 accuracy 0.9293286204338074 macro_avg {'precision': 0.9316416419171178, 'recall': 0.9314050869651889, 'f1-score': 0.9306949557452026, 'support': 1132} weighted_avg {'precision': 0.9312202264227943, 'recall': 0.9293286219081273, 'f1-score': 0.9294039472553818, 'support': 1132}
 
----------
Epoch 39/40
time = 1021.24 secondes

Train loss 0.0063288639659525815 accuracy 0.9986250400543213 macro_avg {'precision': 0.998606797307352, 'recall': 0.9985914825240249, 'f1-score': 0.9985986376511177, 'support': 10182} weighted_avg {'precision': 0.9986259830449353, 'recall': 0.998625024553133, 'f1-score': 0.9986250138321305, 'support': 10182}
 
time = 32.03 secondes

Val loss 0.6061988778854126 accuracy 0.9310954213142395 macro_avg {'precision': 0.933987495217897, 'recall': 0.9321895747423883, 'f1-score': 0.9320592735262041, 'support': 1132} weighted_avg {'precision': 0.9341731535538638, 'recall': 0.931095406360424, 'f1-score': 0.9315568966794563, 'support': 1132}
 
----------
Epoch 40/40
time = 1020.74 secondes

Train loss 0.004333297478742493 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990591229477446, 'recall': 0.9989439235377358, 'f1-score': 0.9990007140303611, 'support': 10182} weighted_avg {'precision': 0.9990187988262491, 'recall': 0.9990178746808093, 'f1-score': 0.9990176671201049, 'support': 10182}
 
time = 32.13 secondes

Val loss 0.5915937128540437 accuracy 0.9319788217544556 macro_avg {'precision': 0.9326777394132142, 'recall': 0.9328893226306914, 'f1-score': 0.9318583708818962, 'support': 1132} weighted_avg {'precision': 0.9341479903319505, 'recall': 0.9319787985865724, 'f1-score': 0.9321455803184886, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 40 macro_avg {'precision': 0.9326777394132142, 'recall': 0.9328893226306914, 'f1-score': 0.9318583708818962, 'support': 1132} weighted_avg {'precision': 0.9341479903319505, 'recall': 0.9319787985865724, 'f1-score': 0.9321455803184886, 'support': 1132}

average train time 1023.3677491486072

average val time 31.93425275683403
 
time = 210.42 secondes

test_accuracy 0.8617897033691406 macro_avg {'precision': 0.858259258985367, 'recall': 0.8556613697009052, 'f1-score': 0.8556487069878284, 'support': 7532} weighted_avg {'precision': 0.8645963733802579, 'recall': 0.8617896972915561, 'f1-score': 0.8620557420766171, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_1
----------
Epoch 1/40
time = 1905.07 secondes

Train loss 1.1205053262330673 accuracy 0.6849341988563538 macro_avg {'precision': 0.6888700275608535, 'recall': 0.6719184649134656, 'f1-score': 0.6702189229652065, 'support': 10182} weighted_avg {'precision': 0.696145916669827, 'recall': 0.6849341976036142, 'f1-score': 0.6821807466822836, 'support': 10182}
 
time = 38.53 secondes

Val loss 0.5259604499163762 accuracy 0.8462897539138794 macro_avg {'precision': 0.8367901759190604, 'recall': 0.8376149208962568, 'f1-score': 0.833020872390934, 'support': 1132} weighted_avg {'precision': 0.8416703214825941, 'recall': 0.8462897526501767, 'f1-score': 0.8404629809666786, 'support': 1132}
 
----------
Epoch 2/40
time = 1905.53 secondes

Train loss 0.38995731358227775 accuracy 0.8863681554794312 macro_avg {'precision': 0.8804857545631689, 'recall': 0.8786709073741467, 'f1-score': 0.8787179719134949, 'support': 10182} weighted_avg {'precision': 0.8854661250052038, 'recall': 0.8863681005696327, 'f1-score': 0.8852457743350424, 'support': 10182}
 
time = 39.58 secondes

Val loss 0.48555777106486575 accuracy 0.8692579865455627 macro_avg {'precision': 0.8738400226857996, 'recall': 0.8695366426114199, 'f1-score': 0.8647704544126741, 'support': 1132} weighted_avg {'precision': 0.8782375537764225, 'recall': 0.8692579505300353, 'f1-score': 0.8664370533106831, 'support': 1132}
 
----------
Epoch 3/40
time = 1905.91 secondes

Train loss 0.22789580522841968 accuracy 0.9375368356704712 macro_avg {'precision': 0.9340760918132711, 'recall': 0.9336831210564339, 'f1-score': 0.9337983421859388, 'support': 10182} weighted_avg {'precision': 0.9375134595167559, 'recall': 0.9375368296994696, 'f1-score': 0.9374489549532355, 'support': 10182}
 
time = 38.71 secondes

Val loss 0.5257196729596127 accuracy 0.8851590156555176 macro_avg {'precision': 0.8890661953349468, 'recall': 0.884321286541543, 'f1-score': 0.8811081083333757, 'support': 1132} weighted_avg {'precision': 0.8932114375858254, 'recall': 0.8851590106007067, 'f1-score': 0.8837593318086477, 'support': 1132}
 
----------
Epoch 4/40
time = 1903.76 secondes

Train loss 0.17593539886547946 accuracy 0.9538401365280151 macro_avg {'precision': 0.9518463495929002, 'recall': 0.9516120219152876, 'f1-score': 0.951653304294213, 'support': 10182} weighted_avg {'precision': 0.9540765773918135, 'recall': 0.9538401099980357, 'f1-score': 0.9538840825797064, 'support': 10182}
 
time = 40.17 secondes

Val loss 0.4766560439381119 accuracy 0.8966431021690369 macro_avg {'precision': 0.8994398928742463, 'recall': 0.8964093662380032, 'f1-score': 0.8955930955579803, 'support': 1132} weighted_avg {'precision': 0.9001403842839368, 'recall': 0.8966431095406361, 'f1-score': 0.8959481066941135, 'support': 1132}
 
----------
Epoch 5/40
time = 1902.50 secondes

Train loss 0.15017285644335546 accuracy 0.9606168270111084 macro_avg {'precision': 0.9588979738570582, 'recall': 0.9591811855853214, 'f1-score': 0.9589876665039189, 'support': 10182} weighted_avg {'precision': 0.9607438154655036, 'recall': 0.9606167747004518, 'f1-score': 0.960633843466138, 'support': 10182}
 
time = 39.28 secondes

Val loss 0.5888939439417453 accuracy 0.8975265026092529 macro_avg {'precision': 0.8972340263178988, 'recall': 0.8973326652149988, 'f1-score': 0.8955003597018326, 'support': 1132} weighted_avg {'precision': 0.9003165691833224, 'recall': 0.8975265017667845, 'f1-score': 0.8972247371013566, 'support': 1132}
 
----------
Epoch 6/40
time = 1902.15 secondes

Train loss 0.13933931167779878 accuracy 0.9666077494621277 macro_avg {'precision': 0.9649204993127185, 'recall': 0.9650847901950976, 'f1-score': 0.9649487887022928, 'support': 10182} weighted_avg {'precision': 0.9667006581816554, 'recall': 0.9666077391475152, 'f1-score': 0.9666004788194609, 'support': 10182}
 
time = 38.08 secondes

Val loss 0.5884069170061709 accuracy 0.9037102460861206 macro_avg {'precision': 0.9044684064344904, 'recall': 0.9002979219888735, 'f1-score': 0.8988389768119178, 'support': 1132} weighted_avg {'precision': 0.9067598164649491, 'recall': 0.9037102473498233, 'f1-score': 0.9022873602126934, 'support': 1132}
 
----------
Epoch 7/40
time = 1902.28 secondes

Train loss 0.13373836576439707 accuracy 0.9702416062355042 macro_avg {'precision': 0.9695934944949238, 'recall': 0.9695216011698411, 'f1-score': 0.9695187626001831, 'support': 10182} weighted_avg {'precision': 0.9702842839409753, 'recall': 0.9702416028285209, 'f1-score': 0.9702249932457309, 'support': 10182}
 
time = 37.85 secondes

Val loss 0.5814524267654223 accuracy 0.9072438478469849 macro_avg {'precision': 0.9110691186336666, 'recall': 0.9053487194530371, 'f1-score': 0.9061455681080244, 'support': 1132} weighted_avg {'precision': 0.9115102233649242, 'recall': 0.907243816254417, 'f1-score': 0.9072576158955372, 'support': 1132}
 
----------
Epoch 8/40
time = 1903.59 secondes

Train loss 0.10812582822129667 accuracy 0.9767236709594727 macro_avg {'precision': 0.9764423492231575, 'recall': 0.9763487018184236, 'f1-score': 0.9763804710587598, 'support': 10182} weighted_avg {'precision': 0.9767560548427489, 'recall': 0.9767236299351797, 'f1-score': 0.9767246651099624, 'support': 10182}
 
time = 38.27 secondes

Val loss 0.5138284770934186 accuracy 0.9143109321594238 macro_avg {'precision': 0.9188695008251632, 'recall': 0.9174555280046507, 'f1-score': 0.9156176480802515, 'support': 1132} weighted_avg {'precision': 0.9183297475897167, 'recall': 0.9143109540636042, 'f1-score': 0.9135160916436184, 'support': 1132}
 
----------
Epoch 9/40
time = 1980.54 secondes

Train loss 0.11244370048120764 accuracy 0.9760361909866333 macro_avg {'precision': 0.9750860114069727, 'recall': 0.9745868006380786, 'f1-score': 0.9747866616954818, 'support': 10182} weighted_avg {'precision': 0.9761296697564137, 'recall': 0.9760361422117462, 'f1-score': 0.9760355398517749, 'support': 10182}
 
time = 37.99 secondes

Val loss 0.6065358025207132 accuracy 0.9116607904434204 macro_avg {'precision': 0.9184957979721613, 'recall': 0.9125899320156516, 'f1-score': 0.9127350174153268, 'support': 1132} weighted_avg {'precision': 0.9176068514709099, 'recall': 0.911660777385159, 'f1-score': 0.9118209173392098, 'support': 1132}
 
----------
Epoch 10/40
time = 1919.79 secondes

Train loss 0.10695423956569708 accuracy 0.9781968593597412 macro_avg {'precision': 0.977527483450835, 'recall': 0.9776261227283228, 'f1-score': 0.9775673477335257, 'support': 10182} weighted_avg {'precision': 0.978206628455565, 'recall': 0.9781968179139658, 'f1-score': 0.978192828358459, 'support': 10182}
 
time = 38.13 secondes

Val loss 0.7047820852398807 accuracy 0.8913427591323853 macro_avg {'precision': 0.9043754559144397, 'recall': 0.8924242112734466, 'f1-score': 0.8940625821663948, 'support': 1132} weighted_avg {'precision': 0.8981796068338481, 'recall': 0.8913427561837456, 'f1-score': 0.8901482914400568, 'support': 1132}
 
----------
Epoch 11/40
time = 1900.42 secondes

Train loss 0.10113796948463406 accuracy 0.9773129224777222 macro_avg {'precision': 0.9770845803308109, 'recall': 0.9771694613391926, 'f1-score': 0.9771017026734075, 'support': 10182} weighted_avg {'precision': 0.9774434620067302, 'recall': 0.9773129051266942, 'f1-score': 0.9773537275139177, 'support': 10182}
 
time = 37.60 secondes

Val loss 0.6287051244820452 accuracy 0.9054770469665527 macro_avg {'precision': 0.9080986235736856, 'recall': 0.9068819152330818, 'f1-score': 0.9054338244641593, 'support': 1132} weighted_avg {'precision': 0.9103726183973925, 'recall': 0.9054770318021201, 'f1-score': 0.9060057071547207, 'support': 1132}
 
----------
Epoch 12/40
time = 2040.07 secondes

Train loss 0.08617716367733687 accuracy 0.9817324876785278 macro_avg {'precision': 0.9811334698522989, 'recall': 0.9811672103192759, 'f1-score': 0.9811267362499132, 'support': 10182} weighted_avg {'precision': 0.9817720074582165, 'recall': 0.9817324690630524, 'f1-score': 0.9817292221112568, 'support': 10182}
 
time = 48.06 secondes

Val loss 0.585300954819975 accuracy 0.9125441908836365 macro_avg {'precision': 0.9179873366170479, 'recall': 0.9150478423393975, 'f1-score': 0.9146974958869085, 'support': 1132} weighted_avg {'precision': 0.9163932432776302, 'recall': 0.9125441696113075, 'f1-score': 0.9125454362587012, 'support': 1132}
 
----------
Epoch 13/40
time = 2124.19 secondes

Train loss 0.10819553624578347 accuracy 0.9795718193054199 macro_avg {'precision': 0.9792336384201275, 'recall': 0.9786047609840143, 'f1-score': 0.978853858040171, 'support': 10182} weighted_avg {'precision': 0.9796528007033156, 'recall': 0.9795717933608329, 'f1-score': 0.9795540549150478, 'support': 10182}
 
time = 48.14 secondes

Val loss 0.7345305131492122 accuracy 0.9001767039299011 macro_avg {'precision': 0.9061084479370063, 'recall': 0.9056800992331097, 'f1-score': 0.9032773380046851, 'support': 1132} weighted_avg {'precision': 0.9076859213914781, 'recall': 0.9001766784452296, 'f1-score': 0.9012842574979977, 'support': 1132}
 
----------
Epoch 14/40
time = 2122.03 secondes

Train loss 0.09124500429026747 accuracy 0.9819289445877075 macro_avg {'precision': 0.9817926380488, 'recall': 0.9815666461929895, 'f1-score': 0.9816565644823282, 'support': 10182} weighted_avg {'precision': 0.9819740030293084, 'recall': 0.9819288941268906, 'f1-score': 0.9819291341264594, 'support': 10182}
 
time = 48.96 secondes

Val loss 0.6810643338126091 accuracy 0.9134275913238525 macro_avg {'precision': 0.9198825708113905, 'recall': 0.9140672107936686, 'f1-score': 0.9153541274370427, 'support': 1132} weighted_avg {'precision': 0.9182135776156307, 'recall': 0.9134275618374559, 'f1-score': 0.914202745038032, 'support': 1132}
 
----------
Epoch 15/40
time = 2060.85 secondes

Train loss 0.09871532943805997 accuracy 0.9808486104011536 macro_avg {'precision': 0.9806494110454527, 'recall': 0.9804752619523667, 'f1-score': 0.9805179669351421, 'support': 10182} weighted_avg {'precision': 0.9810222602464229, 'recall': 0.9808485562757808, 'f1-score': 0.9808895812415336, 'support': 10182}
 
time = 47.80 secondes

Val loss 0.553848441905206 accuracy 0.9222614765167236 macro_avg {'precision': 0.9250074117225351, 'recall': 0.9253214580331746, 'f1-score': 0.9237605855983511, 'support': 1132} weighted_avg {'precision': 0.9246153199288919, 'recall': 0.9222614840989399, 'f1-score': 0.9219209810363115, 'support': 1132}
 
----------
Epoch 16/40
time = 2127.40 secondes

Train loss 0.08201466460904695 accuracy 0.985660970211029 macro_avg {'precision': 0.9854104141884402, 'recall': 0.9855020709317894, 'f1-score': 0.9854212639256842, 'support': 10182} weighted_avg {'precision': 0.9857433806092081, 'recall': 0.9856609703398154, 'f1-score': 0.9856694574470957, 'support': 10182}
 
time = 47.74 secondes

Val loss 0.7002011709481734 accuracy 0.9072438478469849 macro_avg {'precision': 0.9142125660777587, 'recall': 0.9107055992792995, 'f1-score': 0.9099038256277934, 'support': 1132} weighted_avg {'precision': 0.9140386785165261, 'recall': 0.907243816254417, 'f1-score': 0.9079017991039653, 'support': 1132}
 
----------
Epoch 17/40
time = 2044.43 secondes

Train loss 0.08366531127825257 accuracy 0.9840896129608154 macro_avg {'precision': 0.9839680135077906, 'recall': 0.9836171316926595, 'f1-score': 0.983766664835765, 'support': 10182} weighted_avg {'precision': 0.9841096443277013, 'recall': 0.9840895698291102, 'f1-score': 0.9840750776638535, 'support': 10182}
 
time = 37.92 secondes

Val loss 0.6603569410299442 accuracy 0.9116607904434204 macro_avg {'precision': 0.9144224309513618, 'recall': 0.9143972684781614, 'f1-score': 0.9129792045827033, 'support': 1132} weighted_avg {'precision': 0.914757328042731, 'recall': 0.911660777385159, 'f1-score': 0.9117791169230579, 'support': 1132}
 
----------
Epoch 18/40
time = 2149.18 secondes

Train loss 0.0714174468829207 accuracy 0.9870359897613525 macro_avg {'precision': 0.9861649931172108, 'recall': 0.9860975294336933, 'f1-score': 0.9861151642441296, 'support': 10182} weighted_avg {'precision': 0.9870591458271288, 'recall': 0.9870359457866824, 'f1-score': 0.9870319883930724, 'support': 10182}
 
time = 47.33 secondes

Val loss 0.6291328434363863 accuracy 0.916077733039856 macro_avg {'precision': 0.9190846236148609, 'recall': 0.9177412212306795, 'f1-score': 0.9164666404428555, 'support': 1132} weighted_avg {'precision': 0.9198893737867287, 'recall': 0.916077738515901, 'f1-score': 0.9160512583121256, 'support': 1132}
 
----------
Epoch 19/40
time = 2154.60 secondes

Train loss 0.07241392521006004 accuracy 0.9869377613067627 macro_avg {'precision': 0.9867328391570425, 'recall': 0.9867226200844085, 'f1-score': 0.9867133765342645, 'support': 10182} weighted_avg {'precision': 0.9869518919041432, 'recall': 0.9869377332547633, 'f1-score': 0.986930454843812, 'support': 10182}
 
time = 47.85 secondes

Val loss 0.8314769241680525 accuracy 0.8957597017288208 macro_avg {'precision': 0.9081525515649419, 'recall': 0.9009193539735241, 'f1-score': 0.899145759023663, 'support': 1132} weighted_avg {'precision': 0.9102577922846292, 'recall': 0.8957597173144877, 'f1-score': 0.8974559847735232, 'support': 1132}
 
----------
Epoch 20/40
time = 2152.42 secondes

Train loss 0.0717819512752995 accuracy 0.9873306155204773 macro_avg {'precision': 0.986738217244765, 'recall': 0.9871639173330363, 'f1-score': 0.9869278333886701, 'support': 10182} weighted_avg {'precision': 0.9873924521754223, 'recall': 0.9873305833824396, 'f1-score': 0.9873427083141749, 'support': 10182}
 
time = 46.84 secondes

Val loss 0.6780765880168577 accuracy 0.9081271886825562 macro_avg {'precision': 0.9140136671453563, 'recall': 0.9103852618091353, 'f1-score': 0.9102431530924001, 'support': 1132} weighted_avg {'precision': 0.9131416877524424, 'recall': 0.9081272084805654, 'f1-score': 0.9085898257464095, 'support': 1132}
 
----------
Epoch 21/40
time = 2158.41 secondes

Train loss 0.06320664156228761 accuracy 0.9882145524024963 macro_avg {'precision': 0.9879479344602291, 'recall': 0.988016137809986, 'f1-score': 0.9879692396290652, 'support': 10182} weighted_avg {'precision': 0.9882278172258595, 'recall': 0.9882144961697112, 'f1-score': 0.9882089880889836, 'support': 10182}
 
time = 47.92 secondes

Val loss 0.6760288282388962 accuracy 0.9090105891227722 macro_avg {'precision': 0.9102182010245858, 'recall': 0.9093904892962712, 'f1-score': 0.9080974296603694, 'support': 1132} weighted_avg {'precision': 0.9117076556166245, 'recall': 0.9090106007067138, 'f1-score': 0.9088287214596937, 'support': 1132}
 
----------
Epoch 22/40
time = 2111.69 secondes

Train loss 0.07758028933092295 accuracy 0.9883127212524414 macro_avg {'precision': 0.9882669111236826, 'recall': 0.988278734386111, 'f1-score': 0.98823127711681, 'support': 10182} weighted_avg {'precision': 0.9883981464302051, 'recall': 0.9883127087016303, 'f1-score': 0.9883134348230969, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.6356262355173027 accuracy 0.9125441908836365 macro_avg {'precision': 0.9158009618817584, 'recall': 0.9134573290680716, 'f1-score': 0.9131806014194627, 'support': 1132} weighted_avg {'precision': 0.9161095885069024, 'recall': 0.9125441696113075, 'f1-score': 0.9129070644588356, 'support': 1132}
 
----------
Epoch 23/40
time = 1911.08 secondes

Train loss 0.059018114147842325 accuracy 0.989589512348175 macro_avg {'precision': 0.9892973645375879, 'recall': 0.9893006063837072, 'f1-score': 0.9892849053411107, 'support': 10182} weighted_avg {'precision': 0.9896339405313096, 'recall': 0.9895894716165783, 'f1-score': 0.989597550455413, 'support': 10182}
 
time = 39.30 secondes

Val loss 0.7092625546889317 accuracy 0.9063604474067688 macro_avg {'precision': 0.9102901015741267, 'recall': 0.9064624350595313, 'f1-score': 0.9058580432952711, 'support': 1132} weighted_avg {'precision': 0.9134579169436569, 'recall': 0.9063604240282686, 'f1-score': 0.9073786253323705, 'support': 1132}
 
----------
Epoch 24/40
time = 1913.02 secondes

Train loss 0.052221872190530635 accuracy 0.9911609292030334 macro_avg {'precision': 0.9908799169053703, 'recall': 0.9909411310418763, 'f1-score': 0.9908990599520393, 'support': 10182} weighted_avg {'precision': 0.9911760504026889, 'recall': 0.9911608721272834, 'f1-score': 0.9911567900236038, 'support': 10182}
 
time = 39.66 secondes

Val loss 0.7643609443362999 accuracy 0.9028268456459045 macro_avg {'precision': 0.9071735146036503, 'recall': 0.8984901590483663, 'f1-score': 0.8996492739471835, 'support': 1132} weighted_avg {'precision': 0.9077772867330666, 'recall': 0.9028268551236749, 'f1-score': 0.9022424010264417, 'support': 1132}
 
----------
Epoch 25/40
time = 1911.04 secondes

Train loss 0.04230558340462336 accuracy 0.9927322864532471 macro_avg {'precision': 0.9926758165910871, 'recall': 0.9924986163960637, 'f1-score': 0.9925763378794054, 'support': 10182} weighted_avg {'precision': 0.9927473833937369, 'recall': 0.9927322726379886, 'f1-score': 0.9927292399914478, 'support': 10182}
 
time = 39.50 secondes

Val loss 0.7817445465130527 accuracy 0.9054770469665527 macro_avg {'precision': 0.906861639202741, 'recall': 0.9090966453829517, 'f1-score': 0.9058034704678682, 'support': 1132} weighted_avg {'precision': 0.9106944175961698, 'recall': 0.9054770318021201, 'f1-score': 0.9058285569210767, 'support': 1132}
 
----------
Epoch 26/40
time = 1911.51 secondes

Train loss 0.04851724282365341 accuracy 0.9913573265075684 macro_avg {'precision': 0.9911691638401893, 'recall': 0.9910470127700695, 'f1-score': 0.9910998140300921, 'support': 10182} weighted_avg {'precision': 0.9913825735140195, 'recall': 0.9913572971911215, 'f1-score': 0.9913614515544082, 'support': 10182}
 
time = 48.89 secondes

Val loss 0.856581264329602 accuracy 0.8957597017288208 macro_avg {'precision': 0.9026637212038187, 'recall': 0.8994316098851278, 'f1-score': 0.8971259217873193, 'support': 1132} weighted_avg {'precision': 0.905213740177932, 'recall': 0.8957597173144877, 'f1-score': 0.8965282060933666, 'support': 1132}
 
----------
Epoch 27/40
time = 2159.98 secondes

Train loss 0.04223478866164559 accuracy 0.9928305149078369 macro_avg {'precision': 0.9930527683176236, 'recall': 0.9928317158219346, 'f1-score': 0.9929228388517896, 'support': 10182} weighted_avg {'precision': 0.9928898416673239, 'recall': 0.9928304851699077, 'f1-score': 0.992840286368866, 'support': 10182}
 
time = 48.04 secondes

Val loss 0.8138090606896096 accuracy 0.9037102460861206 macro_avg {'precision': 0.9160669887478445, 'recall': 0.9087021155813024, 'f1-score': 0.9090472390304548, 'support': 1132} weighted_avg {'precision': 0.9161039850187296, 'recall': 0.9037102473498233, 'f1-score': 0.9062746934099546, 'support': 1132}
 
----------
Epoch 28/40
time = 2156.46 secondes

Train loss 0.04451652782687687 accuracy 0.9920448064804077 macro_avg {'precision': 0.9915857331658426, 'recall': 0.991499499881337, 'f1-score': 0.9915318710115402, 'support': 10182} weighted_avg {'precision': 0.9920658571569596, 'recall': 0.9920447849145551, 'f1-score': 0.9920445162170827, 'support': 10182}
 
time = 47.18 secondes

Val loss 0.808506310186562 accuracy 0.9010601043701172 macro_avg {'precision': 0.9187251178217698, 'recall': 0.9050638282506009, 'f1-score': 0.907410414698812, 'support': 1132} weighted_avg {'precision': 0.916517413579897, 'recall': 0.901060070671378, 'f1-score': 0.9041290028936136, 'support': 1132}
 
----------
Epoch 29/40
time = 2156.88 secondes

Train loss 0.04444346560509072 accuracy 0.9930269122123718 macro_avg {'precision': 0.9925024635047617, 'recall': 0.9925295307270803, 'f1-score': 0.9924984992933817, 'support': 10182} weighted_avg {'precision': 0.9930437515203543, 'recall': 0.9930269102337458, 'f1-score': 0.9930202574542651, 'support': 10182}
 
time = 47.81 secondes

Val loss 0.7298810416133664 accuracy 0.9107773900032043 macro_avg {'precision': 0.9187140411393342, 'recall': 0.9119797804180759, 'f1-score': 0.9116871687865553, 'support': 1132} weighted_avg {'precision': 0.9182528210282341, 'recall': 0.9107773851590106, 'f1-score': 0.9110596808578899, 'support': 1132}
 
----------
Epoch 30/40
time = 2159.81 secondes

Train loss 0.03122448402588889 accuracy 0.9946965575218201 macro_avg {'precision': 0.9946951213505522, 'recall': 0.9947376682720112, 'f1-score': 0.9947095878863543, 'support': 10182} weighted_avg {'precision': 0.9947062919689105, 'recall': 0.99469652327637, 'f1-score': 0.9946945112157918, 'support': 10182}
 
time = 48.17 secondes

Val loss 0.7394343704986632 accuracy 0.9098939895629883 macro_avg {'precision': 0.9121503780674329, 'recall': 0.9127817757345456, 'f1-score': 0.9097171413292587, 'support': 1132} weighted_avg {'precision': 0.9172676935363232, 'recall': 0.9098939929328622, 'f1-score': 0.9111258401972475, 'support': 1132}
 
----------
Epoch 31/40
time = 2181.05 secondes

Train loss 0.026095411540594356 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955694337324429, 'recall': 0.9956061725410871, 'f1-score': 0.9955836570987024, 'support': 10182} weighted_avg {'precision': 0.9955878701458087, 'recall': 0.9955804360636418, 'f1-score': 0.9955799824849897, 'support': 10182}
 
time = 47.94 secondes

Val loss 0.7603093923482934 accuracy 0.9116607904434204 macro_avg {'precision': 0.9167729996295618, 'recall': 0.9135815426882001, 'f1-score': 0.9126206617316075, 'support': 1132} weighted_avg {'precision': 0.9181617758343101, 'recall': 0.911660777385159, 'f1-score': 0.9123596745279325, 'support': 1132}
 
----------
Epoch 32/40
time = 2160.61 secondes

Train loss 0.024942817518566293 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960234861604732, 'recall': 0.9960104271999383, 'f1-score': 0.9960137584487907, 'support': 10182} weighted_avg {'precision': 0.9960767311775123, 'recall': 0.9960714987232371, 'f1-score': 0.9960712105678028, 'support': 10182}
 
time = 48.03 secondes

Val loss 0.708478327377826 accuracy 0.9134275913238525 macro_avg {'precision': 0.9176187796777009, 'recall': 0.9160699960914288, 'f1-score': 0.9148099008525907, 'support': 1132} weighted_avg {'precision': 0.9162965206357123, 'recall': 0.9134275618374559, 'f1-score': 0.9128717788785847, 'support': 1132}
 
----------
Epoch 33/40
time = 2159.53 secondes

Train loss 0.024676660401774044 accuracy 0.9958751201629639 macro_avg {'precision': 0.9958605500233269, 'recall': 0.9958005364688945, 'f1-score': 0.9958276699902884, 'support': 10182} weighted_avg {'precision': 0.9958855614596863, 'recall': 0.995875073659399, 'f1-score': 0.9958774096691759, 'support': 10182}
 
time = 47.78 secondes

Val loss 0.7168481043000086 accuracy 0.9143109321594238 macro_avg {'precision': 0.9152315023921702, 'recall': 0.9174024081453833, 'f1-score': 0.9152533378073121, 'support': 1132} weighted_avg {'precision': 0.9160662371042418, 'recall': 0.9143109540636042, 'f1-score': 0.9141187513978153, 'support': 1132}
 
----------
Epoch 34/40
time = 2161.25 secondes

Train loss 0.02235577041920953 accuracy 0.9961697459220886 macro_avg {'precision': 0.9958472059764686, 'recall': 0.9958269195932635, 'f1-score': 0.9958318400419902, 'support': 10182} weighted_avg {'precision': 0.9961813613027164, 'recall': 0.9961697112551562, 'f1-score': 0.9961704081240912, 'support': 10182}
 
time = 47.62 secondes

Val loss 0.683466312304415 accuracy 0.9222614765167236 macro_avg {'precision': 0.9271007985380668, 'recall': 0.9254099586956412, 'f1-score': 0.9254256415666481, 'support': 1132} weighted_avg {'precision': 0.9235688538751108, 'recall': 0.9222614840989399, 'f1-score': 0.9220570623830887, 'support': 1132}
 
----------
Epoch 35/40
time = 2162.55 secondes

Train loss 0.016322639307937283 accuracy 0.9966608285903931 macro_avg {'precision': 0.9965307362504399, 'recall': 0.9965999562083953, 'f1-score': 0.9965619697596431, 'support': 10182} weighted_avg {'precision': 0.996666278157454, 'recall': 0.9966607739147515, 'f1-score': 0.9966605081800972, 'support': 10182}
 
time = 48.43 secondes

Val loss 0.6464281499974673 accuracy 0.9293286204338074 macro_avg {'precision': 0.9332490013212367, 'recall': 0.933119560782318, 'f1-score': 0.9323966395091825, 'support': 1132} weighted_avg {'precision': 0.9312757414431184, 'recall': 0.9293286219081273, 'f1-score': 0.9294655883429623, 'support': 1132}
 
----------
Epoch 36/40
time = 2161.56 secondes

Train loss 0.01171362398999518 accuracy 0.9974464774131775 macro_avg {'precision': 0.997242163401531, 'recall': 0.9972211542176371, 'f1-score': 0.9972294795114826, 'support': 10182} weighted_avg {'precision': 0.9974506436898356, 'recall': 0.9974464741701041, 'f1-score': 0.99744636412729, 'support': 10182}
 
time = 48.13 secondes

Val loss 0.6981696736473962 accuracy 0.926678478717804 macro_avg {'precision': 0.9265650246452107, 'recall': 0.9304126761455873, 'f1-score': 0.9275804013571266, 'support': 1132} weighted_avg {'precision': 0.9282975357135458, 'recall': 0.926678445229682, 'f1-score': 0.9265386486689217, 'support': 1132}
 
----------
Epoch 37/40
time = 2059.34 secondes

Train loss 0.010138371551352459 accuracy 0.9985268115997314 macro_avg {'precision': 0.9983998079667403, 'recall': 0.998464724023777, 'f1-score': 0.998430028944702, 'support': 10182} weighted_avg {'precision': 0.9985315462264761, 'recall': 0.998526812021214, 'f1-score': 0.9985271147355406, 'support': 10182}
 
time = 39.36 secondes

Val loss 0.6816274705532277 accuracy 0.9284452199935913 macro_avg {'precision': 0.9301206538591066, 'recall': 0.9320159622986788, 'f1-score': 0.9299139492552964, 'support': 1132} weighted_avg {'precision': 0.9299374594464477, 'recall': 0.9284452296819788, 'f1-score': 0.9278821956520056, 'support': 1132}
 
----------
Epoch 38/40
time = 1907.94 secondes

Train loss 0.007738084421096579 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985862099406975, 'recall': 0.9985588905807307, 'f1-score': 0.998571461502092, 'support': 10182} weighted_avg {'precision': 0.9985285984497417, 'recall': 0.998526812021214, 'f1-score': 0.998526586307973, 'support': 10182}
 
time = 40.21 secondes

Val loss 0.5945624369344931 accuracy 0.9363957643508911 macro_avg {'precision': 0.9399203473006688, 'recall': 0.9384499900655767, 'f1-score': 0.9384928286758492, 'support': 1132} weighted_avg {'precision': 0.938331470837759, 'recall': 0.9363957597173145, 'f1-score': 0.9366085038010538, 'support': 1132}
 
----------
Epoch 39/40
time = 1908.33 secondes

Train loss 0.011908268075491477 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979749083901759, 'recall': 0.9979908081335045, 'f1-score': 0.9979781676883823, 'support': 10182} weighted_avg {'precision': 0.9979428408421454, 'recall': 0.9979375368296994, 'f1-score': 0.9979354491127322, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6279981948686788 accuracy 0.9319788217544556 macro_avg {'precision': 0.9359320002317313, 'recall': 0.9349507219114569, 'f1-score': 0.9344379397801701, 'support': 1132} weighted_avg {'precision': 0.9338410483286432, 'recall': 0.9319787985865724, 'f1-score': 0.9318385667317426, 'support': 1132}
 
----------
Epoch 40/40
time = 1908.01 secondes

Train loss 0.004059259332616863 accuracy 0.9992143511772156 macro_avg {'precision': 0.9991850610390396, 'recall': 0.9992302543749861, 'f1-score': 0.9992065952408312, 'support': 10182} weighted_avg {'precision': 0.999216101086216, 'recall': 0.9992142997446474, 'f1-score': 0.9992141469464708, 'support': 10182}
 
time = 39.84 secondes

Val loss 0.6197170782537617 accuracy 0.9302120208740234 macro_avg {'precision': 0.9340925491746171, 'recall': 0.9331618993583726, 'f1-score': 0.9326572599277279, 'support': 1132} weighted_avg {'precision': 0.931636130149612, 'recall': 0.9302120141342756, 'f1-score': 0.9299353822194143, 'support': 1132}
 
----------
best_accuracy 0.9363957643508911 best_epoch 38 macro_avg {'precision': 0.9399203473006688, 'recall': 0.9384499900655767, 'f1-score': 0.9384928286758492, 'support': 1132} weighted_avg {'precision': 0.938331470837759, 'recall': 0.9363957597173145, 'f1-score': 0.9366085038010538, 'support': 1132}

average train time 2033.1693645000457

average val time 43.43557958006859
 
time = 259.38 secondes

test_accuracy 0.8639139533042908 macro_avg {'precision': 0.866037351750699, 'recall': 0.8557117391725685, 'f1-score': 0.8574969597245664, 'support': 7532} weighted_avg {'precision': 0.871757103253119, 'recall': 0.8639139670738184, 'f1-score': 0.8645714593713931, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 772.00 MiB (GPU 0; 79.21 GiB total capacity; 70.37 GiB already allocated; 294.62 MiB free; 75.04 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 70.56 GiB already allocated; 2.25 GiB free; 73.08 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_2
----------
Epoch 1/40
time = 34.87 secondes

Train loss 0.6107581411347245 accuracy 0.6860464811325073 macro_avg {'precision': 0.8168598045898658, 'recall': 0.5679989597386343, 'f1-score': 0.5224733222128282, 'support': 516} weighted_avg {'precision': 0.7766531214716882, 'recall': 0.686046511627907, 'f1-score': 0.5993852192225673, 'support': 516}
 
time = 1.50 secondes

Val loss 0.49588315933942795 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 2/40
time = 34.77 secondes

Train loss 0.4357805053393046 accuracy 0.7984496355056763 macro_avg {'precision': 0.7825513317390946, 'recall': 0.7784730913642053, 'f1-score': 0.7803823991618648, 'support': 516} weighted_avg {'precision': 0.7972107853383729, 'recall': 0.7984496124031008, 'f1-score': 0.7977171578122398, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4898282662034035 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 33.97 secondes

Train loss 0.26846230639652774 accuracy 0.8914728760719299 macro_avg {'precision': 0.8839167035888347, 'recall': 0.8802724184451344, 'f1-score': 0.8820282518167715, 'support': 516} weighted_avg {'precision': 0.8910698727702159, 'recall': 0.8914728682170543, 'f1-score': 0.8912141116033478, 'support': 516}
 
time = 1.51 secondes

Val loss 0.40541649237275124 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 4/40
time = 34.18 secondes

Train loss 0.1592753194836956 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.51 secondes

Val loss 0.38632142543792725 accuracy 0.90625 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}
 
----------
Epoch 5/40
time = 34.18 secondes

Train loss 0.17247542645782232 accuracy 0.9418604373931885 macro_avg {'precision': 0.933040597308308, 'recall': 0.9440209352599841, 'f1-score': 0.937920082131571, 'support': 516} weighted_avg {'precision': 0.9436543365348494, 'recall': 0.9418604651162791, 'f1-score': 0.942224192776406, 'support': 516}
 
time = 1.50 secondes

Val loss 0.45868580788373947 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 6/40
time = 34.30 secondes

Train loss 0.32523808801885357 accuracy 0.895348846912384 macro_avg {'precision': 0.8834416657485953, 'recall': 0.8960063716008647, 'f1-score': 0.8887131560028756, 'support': 516} weighted_avg {'precision': 0.8988127416342353, 'recall': 0.8953488372093024, 'f1-score': 0.8961914633942454, 'support': 516}
 
time = 1.54 secondes

Val loss 0.6355594284832478 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 7/40
time = 34.04 secondes

Train loss 0.11072410329837691 accuracy 0.9689922332763672 macro_avg {'precision': 0.9710226613397874, 'recall': 0.9618354111470506, 'f1-score': 0.9661300644907203, 'support': 516} weighted_avg {'precision': 0.9691978595331823, 'recall': 0.9689922480620154, 'f1-score': 0.9688395982715464, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9443796724081039 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 8/40
time = 34.19 secondes

Train loss 0.09683909679932351 accuracy 0.9651162624359131 macro_avg {'precision': 0.9655149666034468, 'recall': 0.9587958974692392, 'f1-score': 0.9619892613933996, 'support': 516} weighted_avg {'precision': 0.9651473456308333, 'recall': 0.9651162790697675, 'f1-score': 0.9649895080828875, 'support': 516}
 
time = 1.48 secondes

Val loss 0.8127479278482497 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 9/40
time = 34.10 secondes

Train loss 0.2704446563906403 accuracy 0.9302325248718262 macro_avg {'precision': 0.9293535323233839, 'recall': 0.9187458348910164, 'f1-score': 0.9236033427650194, 'support': 516} weighted_avg {'precision': 0.9301240364338372, 'recall': 0.9302325581395349, 'f1-score': 0.9297964255491064, 'support': 516}
 
time = 1.51 secondes

Val loss 0.5891431677155197 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 10/40
time = 34.10 secondes

Train loss 0.18111762638330797 accuracy 0.9534883499145508 macro_avg {'precision': 0.9447998104714522, 'recall': 0.9577556361035711, 'f1-score': 0.9504386245757828, 'support': 516} weighted_avg {'precision': 0.9556224047720056, 'recall': 0.9534883720930233, 'f1-score': 0.9538219382277215, 'support': 516}
 
time = 1.57 secondes

Val loss 1.3484899550676346 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 11/40
time = 34.62 secondes

Train loss 0.2402300181019007 accuracy 0.9457364082336426 macro_avg {'precision': 0.9465526723663817, 'recall': 0.935520049412415, 'f1-score': 0.9405803777061261, 'support': 516} weighted_avg {'precision': 0.9458372042638178, 'recall': 0.9457364341085271, 'f1-score': 0.945397219871527, 'support': 516}
 
time = 1.57 secondes

Val loss 0.6374709606170654 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 12/40
time = 33.97 secondes

Train loss 0.045062111350213825 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3050492703914642 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 13/40
time = 33.94 secondes

Train loss 0.11939008744560521 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.44 secondes

Val loss 0.9848721772432327 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 14/40
time = 33.92 secondes

Train loss 0.2913572263496462 accuracy 0.9437984228134155 macro_avg {'precision': 0.9476744186046512, 'recall': 0.9305381727158948, 'f1-score': 0.9380647083900715, 'support': 516} weighted_avg {'precision': 0.9444744907157022, 'recall': 0.9437984496124031, 'f1-score': 0.9432506399414797, 'support': 516}
 
time = 1.48 secondes

Val loss 1.1201077327132225 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 15/40
time = 34.03 secondes

Train loss 0.36632283535436727 accuracy 0.9224806427955627 macro_avg {'precision': 0.9243325705568268, 'recall': 0.9068966077727029, 'f1-score': 0.9144604877078395, 'support': 516} weighted_avg {'precision': 0.922821208734678, 'recall': 0.9224806201550387, 'f1-score': 0.92166845484393, 'support': 516}
 
time = 1.50 secondes

Val loss 1.13884936273098 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 16/40
time = 34.13 secondes

Train loss 0.052836215072382016 accuracy 0.9844961166381836 macro_avg {'precision': 0.982185330809184, 'recall': 0.9843798254311396, 'f1-score': 0.9832641411520499, 'support': 516} weighted_avg {'precision': 0.9845631035446839, 'recall': 0.9844961240310077, 'f1-score': 0.9845137237864214, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3301789313554764 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 34.59 secondes

Train loss 0.33300172169004905 accuracy 0.9437984228134155 macro_avg {'precision': 0.9328703703703703, 'recall': 0.9559270516717325, 'f1-score': 0.9409673868876904, 'support': 516} weighted_avg {'precision': 0.9513440281366637, 'recall': 0.9437984496124031, 'f1-score': 0.9445250055329046, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9965019971132278 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 18/40
time = 34.13 secondes

Train loss 0.4197355931418398 accuracy 0.9263566136360168 macro_avg {'precision': 0.9482288828337875, 'recall': 0.8983957219251337, 'f1-score': 0.9161535303776682, 'support': 516} weighted_avg {'precision': 0.9339817924508376, 'recall': 0.9263565891472868, 'f1-score': 0.9242026100737006, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5774069279432297 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 34.65 secondes

Train loss 0.21415513989102858 accuracy 0.961240291595459 macro_avg {'precision': 0.954091943414541, 'recall': 0.9638346634591941, 'f1-score': 0.9585262345679012, 'support': 516} weighted_avg {'precision': 0.9624121734648929, 'recall': 0.9612403100775194, 'f1-score': 0.961445921858551, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6707407236099243 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 20/40
time = 33.96 secondes

Train loss 0.02310774569129783 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6526921689510345 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 21/40
time = 34.21 secondes

Train loss 0.0768780970587007 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.50 secondes

Val loss 1.703554093837738 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 22/40
time = 34.10 secondes

Train loss 0.07030590908481937 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.55 secondes

Val loss 1.500977709889412 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 23/40
time = 34.15 secondes

Train loss 0.11323480788842337 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.51 secondes

Val loss 1.509798675775528 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 24/40
time = 33.92 secondes

Train loss 0.022001946979964323 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.52 secondes

Val loss 1.2816107720136642 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 25/40
time = 34.78 secondes

Train loss 0.04268207642775396 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5122756510972977 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 34.19 secondes

Train loss 0.02142661197682504 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6555854976177216 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 27/40
time = 34.01 secondes

Train loss 0.07036008313761241 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.33 secondes

Val loss 2.6913294196128845 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 28/40
time = 33.98 secondes

Train loss 0.0898894755133149 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6057852804660797 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 29/40
time = 34.84 secondes

Train loss 0.11133792869937183 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4230136722326279 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 30/40
time = 34.06 secondes

Train loss 0.04395649281319824 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.49 secondes

Val loss 1.2934226095676422 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 31/40
time = 34.22 secondes

Train loss 0.03373657888710802 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.47 secondes

Val loss 1.39627193659544 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 32/40
time = 34.05 secondes

Train loss 0.0017817309102004704 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.48 secondes

Val loss 2.2256408631801605 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 33/40
time = 34.12 secondes

Train loss 0.16150784425002657 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4890313297510147 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 34/40
time = 34.68 secondes

Train loss 0.0008754433264116277 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.6566524074878544 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 35/40
time = 34.22 secondes

Train loss 0.006783406547611142 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.41 secondes

Val loss 2.014328509569168 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 36/40
time = 34.14 secondes

Train loss 0.056957905013625736 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4628697335720062 accuracy 0.734375 macro_avg {'precision': 0.7571428571428571, 'recall': 0.6912955465587045, 'f1-score': 0.694981777403981, 'support': 64} weighted_avg {'precision': 0.7491071428571429, 'recall': 0.734375, 'f1-score': 0.7155347631062519, 'support': 64}
 
----------
Epoch 37/40
time = 33.61 secondes

Train loss 0.00012023055916704999 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.523040845990181 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 38/40
time = 34.64 secondes

Train loss 7.210184853509858e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.490858182311058 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 33.74 secondes

Train loss 8.158302906932394e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.53 secondes

Val loss 1.3377542436737713 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 40/40
time = 34.08 secondes

Train loss 0.00029813356178982014 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.3483676348814697 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 4 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}

average train time 34.208909338712694

average val time 1.4956054151058198
 
time = 1.72 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9425, 'recall': 0.9312865497076024, 'f1-score': 0.9358974358974359, 'support': 65} weighted_avg {'precision': 0.9395384615384614, 'recall': 0.9384615384615385, 'f1-score': 0.9380670611439843, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_2
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 22.67 secondes

Train loss 0.6167737236528685 accuracy 0.6744186282157898 macro_avg {'precision': 0.7272727272727273, 'recall': 0.5588804187051997, 'f1-score': 0.5147335423197492, 'support': 516} weighted_avg {'precision': 0.710594315245478, 'recall': 0.6744186046511628, 'f1-score': 0.5913392141138732, 'support': 516}
 
time = 1.09 secondes

Val loss 0.5244618356227875 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 2/40
time = 22.39 secondes

Train loss 0.435084421526302 accuracy 0.8003876209259033 macro_avg {'precision': 0.7868242094525671, 'recall': 0.7742226484404207, 'f1-score': 0.7794460006224712, 'support': 516} weighted_avg {'precision': 0.7977673970515751, 'recall': 0.8003875968992248, 'f1-score': 0.7981485583035971, 'support': 516}
 
time = 1.13 secondes

Val loss 0.46717724204063416 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 22.46 secondes

Train loss 0.2983296414216359 accuracy 0.8856589198112488 macro_avg {'precision': 0.8812764670296431, 'recall': 0.8687889082131885, 'f1-score': 0.8743183159876315, 'support': 516} weighted_avg {'precision': 0.8849806787752594, 'recall': 0.8856589147286822, 'f1-score': 0.8847077677374973, 'support': 516}
 
time = 1.14 secondes

Val loss 0.6183440908789635 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 4/40
time = 22.42 secondes

Train loss 0.2524723759429021 accuracy 0.9166666865348816 macro_avg {'precision': 0.908179012345679, 'recall': 0.9127236968288283, 'f1-score': 0.9103468060948656, 'support': 516} weighted_avg {'precision': 0.917309670781893, 'recall': 0.9166666666666666, 'f1-score': 0.9168973185123528, 'support': 516}
 
time = 1.15 secondes

Val loss 0.8304944038391113 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 5/40
time = 22.54 secondes

Train loss 0.23848583842768814 accuracy 0.9205426573753357 macro_avg {'precision': 0.9152370350969093, 'recall': 0.9123010906490255, 'f1-score': 0.9137303195762363, 'support': 516} weighted_avg {'precision': 0.9203275437442389, 'recall': 0.9205426356589147, 'f1-score': 0.9204016911882387, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7162928432226181 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 6/40
time = 22.36 secondes

Train loss 0.1536944911561229 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.11 secondes

Val loss 0.8266520500183105 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 7/40
time = 22.40 secondes

Train loss 0.13110328520732847 accuracy 0.963178277015686 macro_avg {'precision': 0.9606549364613881, 'recall': 0.9595842205354095, 'f1-score': 0.960115049612094, 'support': 516} weighted_avg {'precision': 0.9631432479331955, 'recall': 0.9631782945736435, 'f1-score': 0.9631568732802058, 'support': 516}
 
time = 1.13 secondes

Val loss 0.7191703170537949 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 8/40
time = 22.41 secondes

Train loss 0.36044774259525264 accuracy 0.8972868323326111 macro_avg {'precision': 0.8855868070883521, 'recall': 0.8975261284397705, 'f1-score': 0.8906635429201966, 'support': 516} weighted_avg {'precision': 0.9004207541921426, 'recall': 0.8972868217054264, 'f1-score': 0.898069098727304, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0168915092945099 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 9/40
time = 22.44 secondes

Train loss 0.12554533697424852 accuracy 0.9573643207550049 macro_avg {'precision': 0.9581917344959634, 'recall': 0.9492547502560018, 'f1-score': 0.9534288386747403, 'support': 516} weighted_avg {'precision': 0.9574481277597718, 'recall': 0.9573643410852714, 'f1-score': 0.9571544476233763, 'support': 516}
 
time = 1.15 secondes

Val loss 1.3144756704568863 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 10/40
time = 22.44 secondes

Train loss 0.09364884840253966 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2429487332701683 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 11/40
time = 22.48 secondes

Train loss 0.15311901879877868 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.08 secondes

Val loss 1.0324603170156479 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 22.41 secondes

Train loss 0.14248338292324633 accuracy 0.9651162624359131 macro_avg {'precision': 0.9596239914018512, 'recall': 0.9657201371844676, 'f1-score': 0.9625121084920891, 'support': 516} weighted_avg {'precision': 0.9656232594698828, 'recall': 0.9651162790697675, 'f1-score': 0.9652311689481944, 'support': 516}
 
time = 1.15 secondes

Val loss 1.675163060426712 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 13/40
time = 22.44 secondes

Train loss 0.12471018949608234 accuracy 0.9593023061752319 macro_avg {'precision': 0.9622660427807486, 'recall': 0.9496204671423696, 'f1-score': 0.9553793129007152, 'support': 516} weighted_avg {'precision': 0.9596998974008207, 'recall': 0.9593023255813954, 'f1-score': 0.9590202789180785, 'support': 516}
 
time = 1.15 secondes

Val loss 1.0459697991609573 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 14/40
time = 22.52 secondes

Train loss 0.13607965282051626 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7980930507183075 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 15/40
time = 22.80 secondes

Train loss 0.08037947558367511 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2590135633945465 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 16/40
time = 22.45 secondes

Train loss 0.051105541512229 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.14 secondes

Val loss 1.205783188343048 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 17/40
time = 22.48 secondes

Train loss 0.2287309629733279 accuracy 0.9554263353347778 macro_avg {'precision': 0.9470886075949367, 'recall': 0.9592753929424769, 'f1-score': 0.9524547803617571, 'support': 516} weighted_avg {'precision': 0.9572951623981946, 'recall': 0.9554263565891473, 'f1-score': 0.9557258177593495, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4767717123031616 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 18/40
time = 22.46 secondes

Train loss 0.1379061563577235 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1209143879823387 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 19/40
time = 22.51 secondes

Train loss 0.384863747811213 accuracy 0.9379844665527344 macro_avg {'precision': 0.9556786703601108, 'recall': 0.9144385026737968, 'f1-score': 0.9300279684719044, 'support': 516} weighted_avg {'precision': 0.9434817153041722, 'recall': 0.937984496124031, 'f1-score': 0.9365212266707664, 'support': 516}
 
time = 1.14 secondes

Val loss 0.965694934129715 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 20/40
time = 22.48 secondes

Train loss 0.4903039717341237 accuracy 0.9108527302742004 macro_avg {'precision': 0.8990033222591363, 'recall': 0.9197048258374917, 'f1-score': 0.9062781331438048, 'support': 516} weighted_avg {'precision': 0.9185685956372814, 'recall': 0.9108527131782945, 'f1-score': 0.9119762942393973, 'support': 516}
 
time = 1.15 secondes

Val loss 2.3952926099300385 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 21/40
time = 22.41 secondes

Train loss 0.12148973315594379 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.15 secondes

Val loss 0.6598966401070356 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 22/40
time = 22.40 secondes

Train loss 0.07964720045900762 accuracy 0.9786821603775024 macro_avg {'precision': 0.9810515873015873, 'recall': 0.9728963151991938, 'f1-score': 0.9767429472864724, 'support': 516} weighted_avg {'precision': 0.9788948105081826, 'recall': 0.9786821705426356, 'f1-score': 0.9785910660943596, 'support': 516}
 
time = 1.15 secondes

Val loss 1.2253367006778717 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 23/40
time = 22.45 secondes

Train loss 0.057591520821337 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.11 secondes

Val loss 1.5710323452949524 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 24/40
time = 22.67 secondes

Train loss 0.03446070773475874 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.6608185172080994 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 25/40
time = 22.38 secondes

Train loss 0.09677309625928474 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4285009801387787 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 26/40
time = 22.43 secondes

Train loss 0.0001630657151867071 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.15 secondes

Val loss 1.1869536936283112 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 27/40
time = 22.42 secondes

Train loss 0.03373741787623713 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.15 secondes

Val loss 2.4898957312107086 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 28/40
time = 22.63 secondes

Train loss 0.1520137002908362 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4145686626434326 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 29/40
time = 22.43 secondes

Train loss 0.0604176648211609 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9188126623630524 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 30/40
time = 22.45 secondes

Train loss 0.009569180952508539 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.14 secondes

Val loss 1.3491852134466171 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 22.40 secondes

Train loss 0.03699352401886382 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.387839525938034 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 32/40
time = 22.45 secondes

Train loss 0.0891150056731104 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7806488573551178 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 33/40
time = 22.37 secondes

Train loss 0.02626541508608639 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4844457507133484 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 34/40
time = 22.49 secondes

Train loss 0.02267914373916221 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7631206512451172 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 35/40
time = 22.40 secondes

Train loss 0.0013142807563946751 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.5328086018562317 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 36/40
time = 22.58 secondes

Train loss 9.359126786214553e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.16 secondes

Val loss 1.8098794519901276 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 37/40
time = 22.40 secondes

Train loss 0.00018376635588620874 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.08 secondes

Val loss 1.9785844385623932 accuracy 0.71875 macro_avg {'precision': 0.7137254901960783, 'recall': 0.7206477732793521, 'f1-score': 0.7142857142857142, 'support': 64} weighted_avg {'precision': 0.7287990196078431, 'recall': 0.71875, 'f1-score': 0.7209821428571428, 'support': 64}
 
----------
Epoch 38/40
time = 22.43 secondes

Train loss 6.832664671078832e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4581730961799622 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 39/40
time = 22.47 secondes

Train loss 5.085709055878617e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.5829847157001495 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 40/40
time = 23.13 secondes

Train loss 4.722524130501728e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.13 secondes

Val loss 1.5780180990695953 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 21 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}

average train time 22.48459569811821

average val time 1.1368390560150146
 
time = 1.27 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 79.21 GiB total capacity; 73.85 GiB already allocated; 240.62 MiB free; 75.10 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 72.48 GiB already allocated; 18.62 MiB free; 75.31 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 79.21 GiB total capacity; 70.25 GiB already allocated; 864.62 MiB free; 74.49 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 73.98 GiB already allocated; 166.62 MiB free; 75.17 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_2
----------
Epoch 1/40
time = 33.51 secondes

Train loss 0.6475304627057278 accuracy 0.5930232405662537 macro_avg {'precision': 0.4676408411526908, 'recall': 0.48581831185085256, 'f1-score': 0.43958294544777515, 'support': 516} weighted_avg {'precision': 0.5123752705041966, 'recall': 0.5930232558139535, 'f1-score': 0.520281182751469, 'support': 516}
 
time = 1.59 secondes

Val loss 0.7083943486213684 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 29.50 secondes

Train loss 0.42203118381175125 accuracy 0.8217054009437561 macro_avg {'precision': 0.8196135353352083, 'recall': 0.7863238138582318, 'f1-score': 0.7976229046945074, 'support': 516} weighted_avg {'precision': 0.821001612555003, 'recall': 0.8217054263565892, 'f1-score': 0.8168348039979659, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4099496230483055 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 3/40
time = 29.66 secondes

Train loss 0.35895142856646667 accuracy 0.8662790656089783 macro_avg {'precision': 0.858038029386344, 'recall': 0.8501292199665167, 'f1-score': 0.8537553141237602, 'support': 516} weighted_avg {'precision': 0.8653519527245684, 'recall': 0.8662790697674418, 'f1-score': 0.8655326207555667, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4666159972548485 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 4/40
time = 29.48 secondes

Train loss 0.26389843598008156 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 1.50 secondes

Val loss 0.45101945102214813 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 5/40
time = 30.42 secondes

Train loss 0.3361745086131674 accuracy 0.8740310072898865 macro_avg {'precision': 0.8666145867960906, 'recall': 0.8585163272272158, 'f1-score': 0.8622332669281797, 'support': 516} weighted_avg {'precision': 0.8731966603944052, 'recall': 0.874031007751938, 'f1-score': 0.8733278311465482, 'support': 516}
 
time = 1.50 secondes

Val loss 0.7286281734704971 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 6/40
time = 29.62 secondes

Train loss 0.14450984333895825 accuracy 0.9496123790740967 macro_avg {'precision': 0.9464195313137911, 'recall': 0.9443297628529168, 'f1-score': 0.9453567937438906, 'support': 516} weighted_avg {'precision': 0.9495249271614058, 'recall': 0.9496124031007752, 'f1-score': 0.949553297415263, 'support': 516}
 
time = 1.54 secondes

Val loss 1.100200206041336 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 7/40
time = 29.72 secondes

Train loss 0.23602946410943387 accuracy 0.9399224519729614 macro_avg {'precision': 0.9383928571428571, 'recall': 0.9309607788956975, 'f1-score': 0.9344573968982401, 'support': 516} weighted_avg {'precision': 0.9397852067183463, 'recall': 0.939922480620155, 'f1-score': 0.9396657317204679, 'support': 516}
 
time = 1.46 secondes

Val loss 0.7699343338608742 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 8/40
time = 30.30 secondes

Train loss 0.14147428501482037 accuracy 0.9496123790740967 macro_avg {'precision': 0.9496377832667473, 'recall': 0.9408676429953026, 'f1-score': 0.9449613547974203, 'support': 516} weighted_avg {'precision': 0.9496149732441648, 'recall': 0.9496124031007752, 'f1-score': 0.9493643471912628, 'support': 516}
 
time = 1.49 secondes

Val loss 0.7722413912415504 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 9/40
time = 29.41 secondes

Train loss 0.23634909218967412 accuracy 0.9360464811325073 macro_avg {'precision': 0.9266772151898734, 'recall': 0.9383076247907287, 'f1-score': 0.931782945736434, 'support': 516} weighted_avg {'precision': 0.9381465263467766, 'recall': 0.936046511627907, 'f1-score': 0.9364761733068926, 'support': 516}
 
time = 1.51 secondes

Val loss 2.0838717222213745 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 29.63 secondes

Train loss 0.28145725717309467 accuracy 0.9437984228134155 macro_avg {'precision': 0.9426587301587301, 'recall': 0.9351543325260472, 'f1-score': 0.9386859519370634, 'support': 516} weighted_avg {'precision': 0.9436961670973298, 'recall': 0.9437984496124031, 'f1-score': 0.9435582651578568, 'support': 516}
 
time = 1.49 secondes

Val loss 1.5464751422405243 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 30.40 secondes

Train loss 0.07481547386851162 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9185861051082611 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 12/40
time = 29.57 secondes

Train loss 0.04924594718878242 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.49 secondes

Val loss 1.582143098115921 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 13/40
time = 29.62 secondes

Train loss 0.2810587146668695 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.49 secondes

Val loss 1.9639479517936707 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 14/40
time = 29.42 secondes

Train loss 0.2577873559282373 accuracy 0.9496123790740967 macro_avg {'precision': 0.9438099073701167, 'recall': 0.9477918827105309, 'f1-score': 0.945730789767487, 'support': 516} weighted_avg {'precision': 0.9499588207563369, 'recall': 0.9496124031007752, 'f1-score': 0.9497249136321749, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7793902158737183 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 15/40
time = 29.66 secondes

Train loss 0.8498475341281543 accuracy 0.8391472697257996 macro_avg {'precision': 0.8274801587301588, 'recall': 0.8219283845066073, 'f1-score': 0.8245149658888365, 'support': 516} weighted_avg {'precision': 0.8381002368647718, 'recall': 0.8391472868217055, 'f1-score': 0.8384598623483492, 'support': 516}
 
time = 1.35 secondes

Val loss 1.4469317197799683 accuracy 0.734375 macro_avg {'precision': 0.7831389183457051, 'recall': 0.7702429149797572, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.815648197242842, 'recall': 0.734375, 'f1-score': 0.7314503303156348, 'support': 64}
 
----------
Epoch 16/40
time = 29.14 secondes

Train loss 0.17465578574355636 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2758662402629852 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 17/40
time = 29.24 secondes

Train loss 0.11771224275280749 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3625833839178085 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 18/40
time = 29.85 secondes

Train loss 0.18607385589910502 accuracy 0.9534883499145508 macro_avg {'precision': 0.9465132997843277, 'recall': 0.9542935162459568, 'f1-score': 0.9501248489730165, 'support': 516} weighted_avg {'precision': 0.9543740955607941, 'recall': 0.9534883720930233, 'f1-score': 0.9536891794434714, 'support': 516}
 
time = 1.49 secondes

Val loss 1.7884128093719482 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 19/40
time = 29.86 secondes

Train loss 0.015877145777763377 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 1.1756044030189514 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 20/40
time = 29.48 secondes

Train loss 0.2552405175229069 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.49 secondes

Val loss 1.8118287175893784 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 21/40
time = 29.67 secondes

Train loss 0.03961147017914548 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.52 secondes

Val loss 1.0463383793830872 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 22/40
time = 29.79 secondes

Train loss 0.05133507452939574 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.51 secondes

Val loss 1.6739418804645538 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 23/40
time = 30.30 secondes

Train loss 0.05230777274956574 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4711760580539703 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 24/40
time = 29.20 secondes

Train loss 0.15117053577242504 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8639224469661713 accuracy 0.734375 macro_avg {'precision': 0.7831389183457051, 'recall': 0.7702429149797572, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.815648197242842, 'recall': 0.734375, 'f1-score': 0.7314503303156348, 'support': 64}
 
----------
Epoch 25/40
time = 29.31 secondes

Train loss 0.19051371277733284 accuracy 0.963178277015686 macro_avg {'precision': 0.9616946045049765, 'recall': 0.9584301805828714, 'f1-score': 0.9600213676084998, 'support': 516} weighted_avg {'precision': 0.963118144976265, 'recall': 0.9631782945736435, 'f1-score': 0.9631129788433301, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8302887082099915 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 26/40
time = 29.69 secondes

Train loss 0.3512852616230234 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 1.50 secondes

Val loss 2.512796938419342 accuracy 0.6875 macro_avg {'precision': 0.7125506072874495, 'recall': 0.7125506072874495, 'f1-score': 0.6875, 'support': 64} weighted_avg {'precision': 0.7376012145748988, 'recall': 0.6875, 'f1-score': 0.6875, 'support': 64}
 
----------
Epoch 27/40
time = 30.10 secondes

Train loss 0.127518662728879 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 1.49 secondes

Val loss 1.9411473274230957 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 29.57 secondes

Train loss 0.023900695492171286 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4101785868406296 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 29/40
time = 29.63 secondes

Train loss 0.09125459259226001 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 1.41 secondes

Val loss 1.828465074300766 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 30/40
time = 29.96 secondes

Train loss 0.02837956353610163 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.42 secondes

Val loss 1.6108421087265015 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 29.56 secondes

Train loss 0.058269222108664864 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.50 secondes

Val loss 2.103816479444504 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 32/40
time = 29.43 secondes

Train loss 0.0001987830980920769 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5849519670009613 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 33/40
time = 29.65 secondes

Train loss 0.03568422019485628 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.41 secondes

Val loss 1.7188564240932465 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 34/40
time = 29.95 secondes

Train loss 0.02700615874478403 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5791853815317154 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 35/40
time = 29.60 secondes

Train loss 0.032690027961397194 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5868118852376938 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 36/40
time = 29.59 secondes

Train loss 7.612257347015354e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.40 secondes

Val loss 1.8571529984474182 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 37/40
time = 29.93 secondes

Train loss 0.053658525528810445 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.50 secondes

Val loss 1.9650072157382965 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 38/40
time = 29.53 secondes

Train loss 9.3332518714085e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.44 secondes

Val loss 1.5446757525205612 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 29.24 secondes

Train loss 0.0011272098829177787 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.593379721045494 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 40/40
time = 29.58 secondes

Train loss 9.441589855035117e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5509000271558762 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 8 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}

average train time 29.769939368963243

average val time 1.4873810946941375
 
time = 1.76 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_2
----------
Epoch 1/40
time = 42.18 secondes

Train loss 0.6555672152475878 accuracy 0.6104651093482971 macro_avg {'precision': 0.430690737833595, 'recall': 0.4856476439705476, 'f1-score': 0.4054583913738844, 'support': 516} weighted_avg {'precision': 0.48570789675440845, 'recall': 0.6104651162790697, 'f1-score': 0.5015341502403409, 'support': 516}
 
time = 1.87 secondes

Val loss 0.6241297423839569 accuracy 0.609375 macro_avg {'precision': 0.8015873015873016, 'recall': 0.5192307692307693, 'f1-score': 0.4132746607994132, 'support': 64} weighted_avg {'precision': 0.7643849206349207, 'recall': 0.609375, 'f1-score': 0.47687477081041435, 'support': 64}
 
----------
Epoch 2/40
time = 39.11 secondes

Train loss 0.4623080442349116 accuracy 0.7945736646652222 macro_avg {'precision': 0.7978169968000942, 'recall': 0.7465825788729419, 'f1-score': 0.759936797752809, 'support': 516} weighted_avg {'precision': 0.795974772075005, 'recall': 0.7945736434108527, 'f1-score': 0.785030838994861, 'support': 516}
 
time = 1.68 secondes

Val loss 0.475628562271595 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 3/40
time = 38.93 secondes

Train loss 0.35720553000768024 accuracy 0.856589138507843 macro_avg {'precision': 0.8437414780474503, 'recall': 0.848300635534678, 'f1-score': 0.8458831126896997, 'support': 516} weighted_avg {'precision': 0.8577750859858406, 'recall': 0.8565891472868217, 'f1-score': 0.8570614723425772, 'support': 516}
 
time = 1.68 secondes

Val loss 0.443993978202343 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 4/40
time = 39.11 secondes

Train loss 0.33298397560914356 accuracy 0.8585271239280701 macro_avg {'precision': 0.8467176959003633, 'recall': 0.8475123124685078, 'f1-score': 0.8471111111111111, 'support': 516} weighted_avg {'precision': 0.8586958380098398, 'recall': 0.8585271317829457, 'f1-score': 0.8586080964685617, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7837258130311966 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 5/40
time = 39.46 secondes

Train loss 0.23290079860298923 accuracy 0.9050387740135193 macro_avg {'precision': 0.8957368827160495, 'recall': 0.9001430359377793, 'f1-score': 0.8978370581081027, 'support': 516} weighted_avg {'precision': 0.9057434473394583, 'recall': 0.9050387596899225, 'f1-score': 0.9053015955140765, 'support': 516}
 
time = 1.68 secondes

Val loss 0.5245716944336891 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 6/40
time = 39.03 secondes

Train loss 0.1942745461128652 accuracy 0.9399224519729614 macro_avg {'precision': 0.9407085561497326, 'recall': 0.9286526989906214, 'f1-score': 0.9341313666629606, 'support': 516} weighted_avg {'precision': 0.9400279297765618, 'recall': 0.939922480620155, 'f1-score': 0.9395061260219253, 'support': 516}
 
time = 1.68 secondes

Val loss 0.5026249848306179 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 7/40
time = 39.04 secondes

Train loss 0.07058443783810645 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1306364983320236 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 8/40
time = 39.57 secondes

Train loss 0.26600922409543826 accuracy 0.9515503644943237 macro_avg {'precision': 0.9578884733083985, 'recall': 0.9377712400240561, 'f1-score': 0.9464674758792405, 'support': 516} weighted_avg {'precision': 0.9527747905184388, 'recall': 0.9515503875968992, 'f1-score': 0.9510069316270866, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2687376290559769 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 9/40
time = 38.95 secondes

Train loss 0.18545627389385394 accuracy 0.9457364082336426 macro_avg {'precision': 0.9376700666740926, 'recall': 0.9470604489377956, 'f1-score': 0.9419367283950617, 'support': 516} weighted_avg {'precision': 0.9470587894256475, 'recall': 0.9457364341085271, 'f1-score': 0.9460242906019716, 'support': 516}
 
time = 1.69 secondes

Val loss 0.9364564269781113 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 10/40
time = 39.09 secondes

Train loss 0.20767450123446796 accuracy 0.9496123790740967 macro_avg {'precision': 0.9446143391097519, 'recall': 0.9466378427579929, 'f1-score': 0.945608458744162, 'support': 516} weighted_avg {'precision': 0.9497572745208048, 'recall': 0.9496124031007752, 'f1-score': 0.9496696023058697, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8848605304956436 accuracy 0.6875 macro_avg {'precision': 0.759090909090909, 'recall': 0.7307692307692308, 'f1-score': 0.6847290640394088, 'support': 64} weighted_avg {'precision': 0.7948863636363637, 'recall': 0.6875, 'f1-score': 0.6791871921182266, 'support': 64}
 
----------
Epoch 11/40
time = 38.95 secondes

Train loss 0.2100696270583395 accuracy 0.9457364082336426 macro_avg {'precision': 0.9376700666740926, 'recall': 0.9470604489377956, 'f1-score': 0.9419367283950617, 'support': 516} weighted_avg {'precision': 0.9470587894256475, 'recall': 0.9457364341085271, 'f1-score': 0.9460242906019716, 'support': 516}
 
time = 1.68 secondes

Val loss 1.0696163177490234 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 12/40
time = 39.41 secondes

Train loss 0.06660915913137917 accuracy 0.9806201457977295 macro_avg {'precision': 0.9790322318482518, 'recall': 0.9790322318482518, 'f1-score': 0.9790322318482518, 'support': 516} weighted_avg {'precision': 0.9806201550387597, 'recall': 0.9806201550387597, 'f1-score': 0.9806201550387597, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5876917243003845 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 13/40
time = 38.95 secondes

Train loss 0.1793901840252202 accuracy 0.9515503644943237 macro_avg {'precision': 0.9536430481283422, 'recall': 0.9412333598816702, 'f1-score': 0.9468801344056134, 'support': 516} weighted_avg {'precision': 0.9518311103511171, 'recall': 0.9515503875968992, 'f1-score': 0.9512146177596172, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4049699306488037 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 38.97 secondes

Train loss 0.34415544388475333 accuracy 0.9302325248718262 macro_avg {'precision': 0.934467881929642, 'recall': 0.9141296750808641, 'f1-score': 0.9228109833122797, 'support': 516} weighted_avg {'precision': 0.9310891404791071, 'recall': 0.9302325581395349, 'f1-score': 0.9293976309714688, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5579393655061722 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 15/40
time = 38.90 secondes

Train loss 0.2563078854108233 accuracy 0.9573643207550049 macro_avg {'precision': 0.9480040781115207, 'recall': 0.9642572696389968, 'f1-score': 0.9547512755102041, 'support': 516} weighted_avg {'precision': 0.9605432983216394, 'recall': 0.9573643410852714, 'f1-score': 0.9577436570558456, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1268788501620293 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 16/40
time = 38.82 secondes

Train loss 0.19371314242633877 accuracy 0.9418604373931885 macro_avg {'precision': 0.9347920242544796, 'recall': 0.9405588154023699, 'f1-score': 0.9375201808201485, 'support': 516} weighted_avg {'precision': 0.9425129365804452, 'recall': 0.9418604651162791, 'f1-score': 0.9420519482469907, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0940574407577515 accuracy 0.703125 macro_avg {'precision': 0.7348717948717949, 'recall': 0.7317813765182186, 'f1-score': 0.703052503052503, 'support': 64} weighted_avg {'precision': 0.7620833333333333, 'recall': 0.703125, 'f1-score': 0.7021825396825396, 'support': 64}
 
----------
Epoch 17/40
time = 39.34 secondes

Train loss 0.16121363794037746 accuracy 0.961240291595459 macro_avg {'precision': 0.9590593614762799, 'recall': 0.9569104237439656, 'f1-score': 0.9579667644183774, 'support': 516} weighted_avg {'precision': 0.9611805580610471, 'recall': 0.9612403100775194, 'f1-score': 0.9611948441655869, 'support': 516}
 
time = 1.70 secondes

Val loss 1.3676226884126663 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 18/40
time = 39.11 secondes

Train loss 0.20731974554258736 accuracy 0.961240291595459 macro_avg {'precision': 0.9696638985045103, 'recall': 0.947678104123661, 'f1-score': 0.9571172129512666, 'support': 516} weighted_avg {'precision': 0.9629439571751132, 'recall': 0.9612403100775194, 'f1-score': 0.960776461650816, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5335567891597748 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 19/40
time = 39.69 secondes

Train loss 0.009458745214501643 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.66 secondes

Val loss 1.3708432167768478 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 20/40
time = 38.90 secondes

Train loss 0.052204695358258585 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.59 secondes

Val loss 1.0896385461091995 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 21/40
time = 38.87 secondes

Train loss 0.05444419103503495 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8378577306866646 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 22/40
time = 39.06 secondes

Train loss 0.18807474224696774 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5025874078273773 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 23/40
time = 39.42 secondes

Train loss 0.05493548797169227 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.69 secondes

Val loss 2.6201913952827454 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 24/40
time = 39.04 secondes

Train loss 0.09378782977199246 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.69 secondes

Val loss 1.306048035621643 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 25/40
time = 38.95 secondes

Train loss 0.001589335169476478 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 2.103917270898819 accuracy 0.671875 macro_avg {'precision': 0.6822660098522167, 'recall': 0.687246963562753, 'f1-score': 0.6711524345485687, 'support': 64} weighted_avg {'precision': 0.7030480295566502, 'recall': 0.671875, 'f1-score': 0.6740426963542941, 'support': 64}
 
----------
Epoch 26/40
time = 39.07 secondes

Train loss 0.12223833685791098 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5069844126701355 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 27/40
time = 39.57 secondes

Train loss 0.0005898199070185055 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8067156642573536 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 28/40
time = 38.96 secondes

Train loss 0.11718871032071272 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0857377350330353 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 29/40
time = 39.10 secondes

Train loss 0.17772504432871233 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2420360028918367 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 30/40
time = 38.98 secondes

Train loss 0.1693459220204011 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.69 secondes

Val loss 2.5796729922294617 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 31/40
time = 39.49 secondes

Train loss 0.07465762542729366 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5371061116456985 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 32/40
time = 38.90 secondes

Train loss 0.08386265135402826 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.69 secondes

Val loss 1.659396767616272 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 33/40
time = 38.92 secondes

Train loss 0.01044204055550367 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0651585310697556 accuracy 0.734375 macro_avg {'precision': 0.7252252252252251, 'recall': 0.7277327935222673, 'f1-score': 0.7262893081761006, 'support': 64} weighted_avg {'precision': 0.736204954954955, 'recall': 0.734375, 'f1-score': 0.7351100628930818, 'support': 64}
 
----------
Epoch 34/40
time = 39.27 secondes

Train loss 5.9012645027850695e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8369644284248352 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 35/40
time = 38.90 secondes

Train loss 0.046226227718734386 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8239893317222595 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 39.01 secondes

Train loss 0.06501754248093869 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.69 secondes

Val loss 2.023897707462311 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 37/40
time = 39.27 secondes

Train loss 0.012795402774413973 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7853127121925354 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 38.86 secondes

Train loss 0.003434390439272675 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.68 secondes

Val loss 1.9607832431793213 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 39/40
time = 38.90 secondes

Train loss 3.448791269902634e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.784013107419014 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 40/40
time = 38.66 secondes

Train loss 2.9361412364806078e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8619033992290497 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 6 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 39.166828972101214

average val time 1.689553564786911
 
time = 1.95 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_2
----------
Epoch 1/40
time = 53.09 secondes

Train loss 0.5833969901908528 accuracy 0.6841084957122803 macro_avg {'precision': 0.7242873651771957, 'recall': 0.5757115225200332, 'f1-score': 0.5454383319551859, 'support': 516} weighted_avg {'precision': 0.7109570030219419, 'recall': 0.6841085271317829, 'f1-score': 0.614530148499315, 'support': 516}
 
time = 2.22 secondes

Val loss 0.6091241240501404 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 52.25 secondes

Train loss 0.36270364667430066 accuracy 0.8449612259864807 macro_avg {'precision': 0.832257854786015, 'recall': 0.832257854786015, 'f1-score': 0.832257854786015, 'support': 516} weighted_avg {'precision': 0.8449612403100775, 'recall': 0.8449612403100775, 'f1-score': 0.8449612403100775, 'support': 516}
 
time = 1.96 secondes

Val loss 0.48631010204553604 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 3/40
time = 52.41 secondes

Train loss 0.23433682909517578 accuracy 0.9069767594337463 macro_avg {'precision': 0.9008516713434747, 'recall': 0.8970466329665329, 'f1-score': 0.8988813587000898, 'support': 516} weighted_avg {'precision': 0.9066500736344427, 'recall': 0.9069767441860465, 'f1-score': 0.9067549528028697, 'support': 516}
 
time = 2.01 secondes

Val loss 0.6130590289831161 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 4/40
time = 52.38 secondes

Train loss 0.1298781200029859 accuracy 0.963178277015686 macro_avg {'precision': 0.9587826929286407, 'recall': 0.9618923004404857, 'f1-score': 0.9602972442140645, 'support': 516} weighted_avg {'precision': 0.9633722181756288, 'recall': 0.9631782945736435, 'f1-score': 0.9632404755166558, 'support': 516}
 
time = 2.00 secondes

Val loss 0.847844734787941 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 5/40
time = 52.36 secondes

Train loss 0.11252477818704916 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.98 secondes

Val loss 0.8415037021040916 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 6/40
time = 52.78 secondes

Train loss 0.0797471240141683 accuracy 0.9767441749572754 macro_avg {'precision': 0.9770590262393541, 'recall': 0.9725305983128261, 'f1-score': 0.9747203396750224, 'support': 516} weighted_avg {'precision': 0.9767609775234631, 'recall': 0.9767441860465116, 'f1-score': 0.9766887382007174, 'support': 516}
 
time = 2.02 secondes

Val loss 1.1072355508804321 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 7/40
time = 52.15 secondes

Train loss 0.35272751956698345 accuracy 0.9263566136360168 macro_avg {'precision': 0.9315066142786061, 'recall': 0.9087820814979763, 'f1-score': 0.9183040847957602, 'support': 516} weighted_avg {'precision': 0.927488462802522, 'recall': 0.9263565891472868, 'f1-score': 0.9253624528075922, 'support': 516}
 
time = 2.01 secondes

Val loss 2.12711963057518 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 8/40
time = 52.20 secondes

Train loss 0.11378850685044502 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 2.00 secondes

Val loss 2.061117708683014 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 52.48 secondes

Train loss 0.12384556586656606 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.98 secondes

Val loss 1.29923215508461 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 10/40
time = 52.17 secondes

Train loss 0.1949585756078842 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 2.02 secondes

Val loss 1.0354160368442535 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 11/40
time = 52.48 secondes

Train loss 0.1907080349769923 accuracy 0.9515503644943237 macro_avg {'precision': 0.9523801608935576, 'recall': 0.9423873998342083, 'f1-score': 0.9470127949723769, 'support': 516} weighted_avg {'precision': 0.9516437370927733, 'recall': 0.9515503875968992, 'f1-score': 0.951279935056365, 'support': 516}
 
time = 2.02 secondes

Val loss 1.6785454452037811 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 12/40
time = 52.69 secondes

Train loss 0.35345037005467794 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.02 secondes

Val loss 1.7714714407920837 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 13/40
time = 52.16 secondes

Train loss 0.052914088795660064 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9337725937366486 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 52.34 secondes

Train loss 0.1472338330296969 accuracy 0.9728682041168213 macro_avg {'precision': 0.9679013137843084, 'recall': 0.9741072444451668, 'f1-score': 0.9708427510494027, 'support': 516} weighted_avg {'precision': 0.9733267004330286, 'recall': 0.9728682170542635, 'f1-score': 0.9729575758485957, 'support': 516}
 
time = 2.01 secondes

Val loss 1.0379770547151566 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 15/40
time = 52.24 secondes

Train loss 0.31382875656312204 accuracy 0.9379844665527344 macro_avg {'precision': 0.9536397991590227, 'recall': 0.9155925426263349, 'f1-score': 0.930232558139535, 'support': 516} weighted_avg {'precision': 0.9426345861344245, 'recall': 0.937984496124031, 'f1-score': 0.9366324139174329, 'support': 516}
 
time = 2.02 secondes

Val loss 1.1665081232786179 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 16/40
time = 51.95 secondes

Train loss 0.08019948772870879 accuracy 0.9806201457977295 macro_avg {'precision': 0.9770600080547724, 'recall': 0.981340311753328, 'f1-score': 0.9791272268336488, 'support': 516} weighted_avg {'precision': 0.980832701127356, 'recall': 0.9806201550387597, 'f1-score': 0.9806634283200673, 'support': 516}
 
time = 2.02 secondes

Val loss 1.4316941797733307 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 17/40
time = 52.18 secondes

Train loss 0.4010231781155171 accuracy 0.9205426573753357 macro_avg {'precision': 0.9422737955346651, 'recall': 0.8915283715033402, 'f1-score': 0.9093942054433715, 'support': 516} weighted_avg {'precision': 0.9282473196148625, 'recall': 0.9205426356589147, 'f1-score': 0.9181404877119193, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7091509774327278 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 18/40
time = 52.26 secondes

Train loss 0.39845155684231554 accuracy 0.9244186282157898 macro_avg {'precision': 0.9130151439920556, 'recall': 0.9326512036149082, 'f1-score': 0.9203221323450808, 'support': 516} weighted_avg {'precision': 0.9306161376180688, 'recall': 0.9244186046511628, 'f1-score': 0.9252939192464795, 'support': 516}
 
time = 2.02 secondes

Val loss 2.2788559198379517 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 19/40
time = 52.22 secondes

Train loss 0.041362368322690156 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.01 secondes

Val loss 2.4088056683540344 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 20/40
time = 52.41 secondes

Train loss 0.2596123782625937 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 2.06 secondes

Val loss 1.6195314526557922 accuracy 0.71875 macro_avg {'precision': 0.71875, 'recall': 0.7267206477732794, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.736328125, 'recall': 0.71875, 'f1-score': 0.7212438423645322, 'support': 64}
 
----------
Epoch 21/40
time = 52.19 secondes

Train loss 0.06865998973477293 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 2.02 secondes

Val loss 1.3441333025693893 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 22/40
time = 52.62 secondes

Train loss 0.06940425779039013 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9734576046466827 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 23/40
time = 53.30 secondes

Train loss 0.025542320336447148 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.02 secondes

Val loss 1.3643543124198914 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 24/40
time = 52.07 secondes

Train loss 0.01352803500600258 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.01 secondes

Val loss 2.4524176120758057 accuracy 0.6875 macro_avg {'precision': 0.6785714285714286, 'recall': 0.6821862348178138, 'f1-score': 0.6796796796796798, 'support': 64} weighted_avg {'precision': 0.6919642857142857, 'recall': 0.6875, 'f1-score': 0.6890640640640642, 'support': 64}
 
----------
Epoch 25/40
time = 52.39 secondes

Train loss 0.049532211827957355 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 2.03 secondes

Val loss 2.8765435218811035 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 26/40
time = 51.89 secondes

Train loss 0.0514389947021493 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.02 secondes

Val loss 1.415438286960125 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 27/40
time = 52.41 secondes

Train loss 0.04499867034808796 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.01 secondes

Val loss 1.9735614508390427 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 28/40
time = 52.24 secondes

Train loss 0.13563564800422295 accuracy 0.9670542478561401 macro_avg {'precision': 0.9583333333333333, 'recall': 0.9741641337386018, 'f1-score': 0.9650003391440005, 'support': 516} weighted_avg {'precision': 0.9697997416020671, 'recall': 0.9670542635658915, 'f1-score': 0.9673335972872688, 'support': 516}
 
time = 2.02 secondes

Val loss 3.001997709274292 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 29/40
time = 52.14 secondes

Train loss 0.17342427447913383 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7675100266933441 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 30/40
time = 52.40 secondes

Train loss 0.131379376133268 accuracy 0.9709302186965942 macro_avg {'precision': 0.9628712871287128, 'recall': 0.9772036474164134, 'f1-score': 0.9690557196943952, 'support': 516} weighted_avg {'precision': 0.9730888786553075, 'recall': 0.9709302325581395, 'f1-score': 0.9711516317152747, 'support': 516}
 
time = 2.01 secondes

Val loss 1.710803936352022 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 31/40
time = 52.19 secondes

Train loss 0.07621385476660648 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 2.01 secondes

Val loss 2.9281861186027527 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 32/40
time = 52.28 secondes

Train loss 0.0054895701102368275 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.01 secondes

Val loss 2.015319302678108 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 33/40
time = 52.34 secondes

Train loss 0.008955868980068992 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.01 secondes

Val loss 1.9089668095111847 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 34/40
time = 52.57 secondes

Train loss 0.11316054986210392 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 2.02 secondes

Val loss 2.71492663025856 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 35/40
time = 52.67 secondes

Train loss 0.0412375432826979 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.01 secondes

Val loss 1.8236069232225418 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 52.45 secondes

Train loss 0.04948113863026789 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7146564573049545 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 52.40 secondes

Train loss 0.0038976439149833327 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.91 secondes

Val loss 2.6327152252197266 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 38/40
time = 52.11 secondes

Train loss 0.005813561608110004 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.02 secondes

Val loss 2.1486160457134247 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 39/40
time = 52.48 secondes

Train loss 2.1948599114142724e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 1.824658527970314 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 40/40
time = 52.06 secondes

Train loss 2.0531253484836213e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7083893418312073 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 5 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}

average train time 52.360049152374266

average val time 2.014763057231903
 
time = 2.26 secondes

test_accuracy 0.9846153855323792 macro_avg {'precision': 0.9821428571428572, 'recall': 0.986842105263158, 'f1-score': 0.9842424242424241, 'support': 65} weighted_avg {'precision': 0.985164835164835, 'recall': 0.9846153846153847, 'f1-score': 0.9846526806526806, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_2
----------
Epoch 1/40
time = 98.91 secondes

Train loss 0.6024269262949625 accuracy 0.6647287011146545 macro_avg {'precision': 0.6590656799259944, 'recall': 0.5558977943208231, 'f1-score': 0.5204950394001084, 'support': 516} weighted_avg {'precision': 0.6609622514324233, 'recall': 0.6647286821705426, 'f1-score': 0.5928666905428704, 'support': 516}
 
time = 2.64 secondes

Val loss 0.6430978029966354 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 2/40
time = 98.33 secondes

Train loss 0.36249683887669537 accuracy 0.8352712988853455 macro_avg {'precision': 0.8237317997473572, 'recall': 0.8165807909237196, 'f1-score': 0.8198435029060813, 'support': 516} weighted_avg {'precision': 0.833973122045221, 'recall': 0.8352713178294574, 'f1-score': 0.8343517791916404, 'support': 516}
 
time = 2.45 secondes

Val loss 0.41042762622237206 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 3/40
time = 99.02 secondes

Train loss 0.22579158591388754 accuracy 0.9147287011146545 macro_avg {'precision': 0.9093191552207945, 'recall': 0.9054337402272321, 'f1-score': 0.907307912141749, 'support': 516} weighted_avg {'precision': 0.9144401740665561, 'recall': 0.9147286821705426, 'f1-score': 0.9145253734026304, 'support': 516}
 
time = 2.43 secondes

Val loss 0.5109597258269787 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 4/40
time = 98.16 secondes

Train loss 0.2133080643234831 accuracy 0.9108527302742004 macro_avg {'precision': 0.9124703715703495, 'recall': 0.8931619069291159, 'f1-score': 0.901369589787913, 'support': 516} weighted_avg {'precision': 0.9111798800441034, 'recall': 0.9108527131782945, 'f1-score': 0.9097858617968768, 'support': 516}
 
time = 2.38 secondes

Val loss 0.879143238067627 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 5/40
time = 98.70 secondes

Train loss 0.15221554476584337 accuracy 0.9476743936538696 macro_avg {'precision': 0.9400191326530613, 'recall': 0.9485802057767014, 'f1-score': 0.9439507255589037, 'support': 516} weighted_avg {'precision': 0.9487856697911722, 'recall': 0.9476744186046512, 'f1-score': 0.9479263978333107, 'support': 516}
 
time = 2.43 secondes

Val loss 0.988392099738121 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 6/40
time = 98.42 secondes

Train loss 0.2377275975004798 accuracy 0.9321705102920532 macro_avg {'precision': 0.934593023255814, 'recall': 0.917957511824846, 'f1-score': 0.9252505101259483, 'support': 516} weighted_avg {'precision': 0.9325930683252208, 'recall': 0.9321705426356589, 'f1-score': 0.9315093930328202, 'support': 516}
 
time = 2.46 secondes

Val loss 1.018186055123806 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 7/40
time = 98.22 secondes

Train loss 0.07895018553333075 accuracy 0.9748061895370483 macro_avg {'precision': 0.9681246426529446, 'recall': 0.9790891211416868, 'f1-score': 0.9730705152652603, 'support': 516} weighted_avg {'precision': 0.9760311540149189, 'recall': 0.9748062015503876, 'f1-score': 0.9749519462002839, 'support': 516}
 
time = 2.45 secondes

Val loss 1.0385638177394867 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 8/40
time = 98.07 secondes

Train loss 0.0588014733265013 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 2.45 secondes

Val loss 1.439433068037033 accuracy 0.71875 macro_avg {'precision': 0.7099567099567099, 'recall': 0.6963562753036436, 'f1-score': 0.7, 'support': 64} weighted_avg {'precision': 0.715232683982684, 'recall': 0.71875, 'f1-score': 0.7140624999999999, 'support': 64}
 
----------
Epoch 9/40
time = 98.33 secondes

Train loss 0.04361056499306649 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 2.44 secondes

Val loss 1.4392589330673218 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 10/40
time = 98.01 secondes

Train loss 0.09356870301461172 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 2.45 secondes

Val loss 1.420652523636818 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 11/40
time = 98.05 secondes

Train loss 0.07416208411715078 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 2.45 secondes

Val loss 0.9790362119674683 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 12/40
time = 97.98 secondes

Train loss 0.20156166314678337 accuracy 0.9534883499145508 macro_avg {'precision': 0.9472080078281653, 'recall': 0.9531394762934187, 'f1-score': 0.9500161446561188, 'support': 516} weighted_avg {'precision': 0.954068098025164, 'recall': 0.9534883720930233, 'f1-score': 0.9536415585975925, 'support': 516}
 
time = 2.38 secondes

Val loss 2.284541040658951 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 97.98 secondes

Train loss 0.08632578116212795 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 2.45 secondes

Val loss 1.8178586959838867 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 14/40
time = 98.07 secondes

Train loss 0.08351632171693243 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1441345730054309 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 15/40
time = 98.14 secondes

Train loss 0.11480961798048211 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 2.45 secondes

Val loss 1.64809550344944 accuracy 0.71875 macro_avg {'precision': 0.7137254901960783, 'recall': 0.7206477732793521, 'f1-score': 0.7142857142857142, 'support': 64} weighted_avg {'precision': 0.7287990196078431, 'recall': 0.71875, 'f1-score': 0.7209821428571428, 'support': 64}
 
----------
Epoch 16/40
time = 97.98 secondes

Train loss 0.03821758329264192 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 2.41 secondes

Val loss 1.1895389966666698 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 17/40
time = 97.87 secondes

Train loss 0.18665564705059462 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 2.46 secondes

Val loss 1.8395435959100723 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 18/40
time = 98.42 secondes

Train loss 0.2255554021367888 accuracy 0.9593023061752319 macro_avg {'precision': 0.9555007784120395, 'recall': 0.956544706857598, 'f1-score': 0.9560182648401826, 'support': 516} weighted_avg {'precision': 0.9593566333981004, 'recall': 0.9593023255813954, 'f1-score': 0.959325616792326, 'support': 516}
 
time = 2.46 secondes

Val loss 1.6018936932086945 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 19/40
time = 98.18 secondes

Train loss 0.17259653278465106 accuracy 0.9709302186965942 macro_avg {'precision': 0.9634177215189874, 'recall': 0.9760496074638754, 'f1-score': 0.9689922480620154, 'support': 516} weighted_avg {'precision': 0.9726140712393289, 'recall': 0.9709302325581395, 'f1-score': 0.9711255333213148, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6698111295700073 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 20/40
time = 98.01 secondes

Train loss 0.13350400302795495 accuracy 0.9767441749572754 macro_avg {'precision': 0.9712437095614666, 'recall': 0.9794548380280546, 'f1-score': 0.9750624244865083, 'support': 516} weighted_avg {'precision': 0.9774426592509617, 'recall': 0.9767441860465116, 'f1-score': 0.9768445897217357, 'support': 516}
 
time = 3.13 secondes

Val loss 1.7129133939743042 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 21/40
time = 98.04 secondes

Train loss 0.03695104888439263 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6833245158195496 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 22/40
time = 97.91 secondes

Train loss 0.03257010011833644 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.714388132095337 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 23/40
time = 98.68 secondes

Train loss 0.030647415792455748 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.42 secondes

Val loss 1.4659121483564377 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 24/40
time = 98.16 secondes

Train loss 0.21972589120967756 accuracy 0.9534883499145508 macro_avg {'precision': 0.9431279620853081, 'recall': 0.9635258358662614, 'f1-score': 0.9509218014362031, 'support': 516} weighted_avg {'precision': 0.9587787942246224, 'recall': 0.9534883720930233, 'f1-score': 0.9540103864639019, 'support': 516}
 
time = 2.42 secondes

Val loss 2.2653622031211853 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 25/40
time = 98.00 secondes

Train loss 0.23635321306353557 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1281770281493664 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 26/40
time = 98.45 secondes

Train loss 0.045909477865886096 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.46 secondes

Val loss 1.7962218523025513 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 27/40
time = 98.03 secondes

Train loss 0.04409828166723001 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6856117695569992 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 28/40
time = 98.08 secondes

Train loss 0.002576150226421746 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.45 secondes

Val loss 1.2452254984527826 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 29/40
time = 98.05 secondes

Train loss 0.016584523124258725 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.44 secondes

Val loss 2.6514423489570618 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 30/40
time = 98.19 secondes

Train loss 0.06720089920351958 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 2.46 secondes

Val loss 2.3989083096385 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 31/40
time = 97.96 secondes

Train loss 0.10148110103314552 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.45 secondes

Val loss 2.186294049024582 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 32/40
time = 98.53 secondes

Train loss 0.2520188182689074 accuracy 0.963178277015686 macro_avg {'precision': 0.9727011494252873, 'recall': 0.9491978609625669, 'f1-score': 0.9592069403124805, 'support': 516} weighted_avg {'precision': 0.9651886750423238, 'recall': 0.9631782945736435, 'f1-score': 0.962709625437233, 'support': 516}
 
time = 2.45 secondes

Val loss 2.074417859315872 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 33/40
time = 97.93 secondes

Train loss 0.0023512114859675585 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.42 secondes

Val loss 2.248430870473385 accuracy 0.703125 macro_avg {'precision': 0.7003910068426198, 'recall': 0.7074898785425101, 'f1-score': 0.6995305164319249, 'support': 64} weighted_avg {'precision': 0.7167949657869013, 'recall': 0.703125, 'f1-score': 0.7056924882629108, 'support': 64}
 
----------
Epoch 34/40
time = 97.79 secondes

Train loss 5.55346748363015e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.44 secondes

Val loss 1.8767977058887482 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 35/40
time = 98.01 secondes

Train loss 0.09549594673830364 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 2.46 secondes

Val loss 1.7408701181411743 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 36/40
time = 97.86 secondes

Train loss 0.00021810277295034294 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6516127735376358 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 37/40
time = 98.04 secondes

Train loss 0.0004332988444895653 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.46 secondes

Val loss 1.4425709396600723 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 98.42 secondes

Train loss 5.8261231143577873e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.45 secondes

Val loss 2.17784920334816 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 39/40
time = 98.26 secondes

Train loss 0.026134299623663537 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.45 secondes

Val loss 2.281267136335373 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 40/40
time = 98.05 secondes

Train loss 0.002723809409596442 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.46 secondes

Val loss 2.1472451388835907 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 28 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}

average train time 98.18187269568443

average val time 2.4612273931503297
 
time = 2.67 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.05 GiB already allocated; 359.62 MiB free; 76.83 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 1.43 GiB free; 75.75 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_2
----------
Epoch 1/40
time = 641.32 secondes

Train loss 1.3743937719654251 accuracy 0.6254174113273621 macro_avg {'precision': 0.6207999980874489, 'recall': 0.6098394237592502, 'f1-score': 0.5987962838819725, 'support': 10182} weighted_avg {'precision': 0.629954055502062, 'recall': 0.6254174032606561, 'f1-score': 0.6135133416582608, 'support': 10182}
 
time = 24.32 secondes

Val loss 0.7873054495160009 accuracy 0.7667844295501709 macro_avg {'precision': 0.7479607145214444, 'recall': 0.7615485924839616, 'f1-score': 0.7475525254502291, 'support': 1132} weighted_avg {'precision': 0.756964447749439, 'recall': 0.7667844522968198, 'f1-score': 0.7540061432927142, 'support': 1132}
 
----------
Epoch 2/40
time = 640.01 secondes

Train loss 0.54269981340416 accuracy 0.8362797498703003 macro_avg {'precision': 0.8253405580789938, 'recall': 0.8252530123471671, 'f1-score': 0.8228703806016766, 'support': 10182} weighted_avg {'precision': 0.8331609286052729, 'recall': 0.8362797092909056, 'f1-score': 0.8329175483871702, 'support': 10182}
 
time = 23.40 secondes

Val loss 0.5993480531262679 accuracy 0.8295053243637085 macro_avg {'precision': 0.8264152516675425, 'recall': 0.8257395755153117, 'f1-score': 0.8229507223449701, 'support': 1132} weighted_avg {'precision': 0.8306994959167684, 'recall': 0.8295053003533569, 'f1-score': 0.8269484007592944, 'support': 1132}
 
----------
Epoch 3/40
time = 641.36 secondes

Train loss 0.3152994331779482 accuracy 0.9113141298294067 macro_avg {'precision': 0.9070556168139217, 'recall': 0.9060762176915166, 'f1-score': 0.9063188008714362, 'support': 10182} weighted_avg {'precision': 0.9112173273274752, 'recall': 0.9113140836770772, 'f1-score': 0.9110414440298951, 'support': 10182}
 
time = 23.53 secondes

Val loss 0.6457513648439461 accuracy 0.8356890678405762 macro_avg {'precision': 0.8399762059843964, 'recall': 0.8301471791988911, 'f1-score': 0.8291548806881577, 'support': 1132} weighted_avg {'precision': 0.8448806270795217, 'recall': 0.8356890459363958, 'f1-score': 0.8346448469012424, 'support': 1132}
 
----------
Epoch 4/40
time = 641.34 secondes

Train loss 0.21090251133372215 accuracy 0.9419564008712769 macro_avg {'precision': 0.9399356674154472, 'recall': 0.9393860384681327, 'f1-score': 0.9394987749534833, 'support': 10182} weighted_avg {'precision': 0.9423451075164403, 'recall': 0.941956393635828, 'f1-score': 0.9419882408961141, 'support': 10182}
 
time = 23.36 secondes

Val loss 0.6724121720057873 accuracy 0.8533568978309631 macro_avg {'precision': 0.863750622255391, 'recall': 0.8484350218888126, 'f1-score': 0.8508449338519706, 'support': 1132} weighted_avg {'precision': 0.8641741327723131, 'recall': 0.8533568904593639, 'f1-score': 0.8535080147831696, 'support': 1132}
 
----------
Epoch 5/40
time = 640.77 secondes

Train loss 0.16500134181028037 accuracy 0.9575722217559814 macro_avg {'precision': 0.9562800795268652, 'recall': 0.9562072855645107, 'f1-score': 0.9562203527143895, 'support': 10182} weighted_avg {'precision': 0.9576358958250323, 'recall': 0.9575721862109605, 'f1-score': 0.9575805149238045, 'support': 10182}
 
time = 23.57 secondes

Val loss 0.7424329212328917 accuracy 0.8586572408676147 macro_avg {'precision': 0.870560040211552, 'recall': 0.858041913414619, 'f1-score': 0.8575629351350573, 'support': 1132} weighted_avg {'precision': 0.8695717097197081, 'recall': 0.8586572438162544, 'f1-score': 0.8576914449198932, 'support': 1132}
 
----------
Epoch 6/40
time = 640.88 secondes

Train loss 0.14552043945553422 accuracy 0.9638578295707703 macro_avg {'precision': 0.9633301823638731, 'recall': 0.9633927424950242, 'f1-score': 0.963306075042906, 'support': 10182} weighted_avg {'precision': 0.9639875866695266, 'recall': 0.9638577882537812, 'f1-score': 0.9638673429346658, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.6845272604300654 accuracy 0.8772084712982178 macro_avg {'precision': 0.8864887264964135, 'recall': 0.872337605211488, 'f1-score': 0.8755004801893828, 'support': 1132} weighted_avg {'precision': 0.8849071085277007, 'recall': 0.877208480565371, 'f1-score': 0.8771761698920191, 'support': 1132}
 
----------
Epoch 7/40
time = 641.35 secondes

Train loss 0.1327383387037933 accuracy 0.9700452089309692 macro_avg {'precision': 0.9693465555897586, 'recall': 0.9692612140780209, 'f1-score': 0.9692765870378898, 'support': 10182} weighted_avg {'precision': 0.9701082640417572, 'recall': 0.9700451777646828, 'f1-score': 0.9700489795419378, 'support': 10182}
 
time = 23.39 secondes

Val loss 0.8889208629278099 accuracy 0.8489399552345276 macro_avg {'precision': 0.8517478780138955, 'recall': 0.8524983935654632, 'f1-score': 0.8483487835568498, 'support': 1132} weighted_avg {'precision': 0.8566275890944571, 'recall': 0.848939929328622, 'f1-score': 0.849178327862589, 'support': 1132}
 
----------
Epoch 8/40
time = 787.77 secondes

Train loss 0.1312422520478126 accuracy 0.9707326889038086 macro_avg {'precision': 0.9705385568194174, 'recall': 0.9705186853546394, 'f1-score': 0.9704971780492111, 'support': 10182} weighted_avg {'precision': 0.9708620825794664, 'recall': 0.9707326654881163, 'f1-score': 0.9707655323968435, 'support': 10182}
 
time = 26.16 secondes

Val loss 0.7226198210502306 accuracy 0.870141327381134 macro_avg {'precision': 0.8708614395790162, 'recall': 0.8713848698935228, 'f1-score': 0.8693761657309759, 'support': 1132} weighted_avg {'precision': 0.8729089331805177, 'recall': 0.8701413427561837, 'f1-score': 0.8701387135278044, 'support': 1132}
 
----------
Epoch 9/40
time = 837.05 secondes

Train loss 0.1156830641769459 accuracy 0.9746611714363098 macro_avg {'precision': 0.9745525344951625, 'recall': 0.9744737071931852, 'f1-score': 0.9744764387183246, 'support': 10182} weighted_avg {'precision': 0.9747430014650953, 'recall': 0.9746611667648792, 'f1-score': 0.9746656180136798, 'support': 10182}
 
time = 25.96 secondes

Val loss 0.8705467145765384 accuracy 0.8630741834640503 macro_avg {'precision': 0.8701514381160662, 'recall': 0.8648049904967483, 'f1-score': 0.863691512182367, 'support': 1132} weighted_avg {'precision': 0.8734150502480255, 'recall': 0.8630742049469965, 'f1-score': 0.8643676633168985, 'support': 1132}
 
----------
Epoch 10/40
time = 838.06 secondes

Train loss 0.11355060124656498 accuracy 0.9761343598365784 macro_avg {'precision': 0.9754471893685371, 'recall': 0.9750520765142239, 'f1-score': 0.9752060400169323, 'support': 10182} weighted_avg {'precision': 0.9761736336494541, 'recall': 0.9761343547436653, 'f1-score': 0.9761189826101938, 'support': 10182}
 
time = 26.02 secondes

Val loss 0.8756576360010256 accuracy 0.8692579865455627 macro_avg {'precision': 0.8776181395865074, 'recall': 0.8721087591965102, 'f1-score': 0.8704396769255031, 'support': 1132} weighted_avg {'precision': 0.8816503327013967, 'recall': 0.8692579505300353, 'f1-score': 0.8710740470544799, 'support': 1132}
 
----------
Epoch 11/40
time = 837.66 secondes

Train loss 0.10617609211611302 accuracy 0.9775093793869019 macro_avg {'precision': 0.977538718349677, 'recall': 0.9772289112566673, 'f1-score': 0.9773697670928418, 'support': 10182} weighted_avg {'precision': 0.9775149832789348, 'recall': 0.9775093301905323, 'f1-score': 0.9774994762125223, 'support': 10182}
 
time = 26.05 secondes

Val loss 0.9611990161073676 accuracy 0.8648409843444824 macro_avg {'precision': 0.8770506212707753, 'recall': 0.8640129568775118, 'f1-score': 0.866214878747871, 'support': 1132} weighted_avg {'precision': 0.8781365005906817, 'recall': 0.8648409893992933, 'f1-score': 0.8670213126603833, 'support': 1132}
 
----------
Epoch 12/40
time = 835.52 secondes

Train loss 0.09463980655337383 accuracy 0.9808486104011536 macro_avg {'precision': 0.9809932123719356, 'recall': 0.9809425976107102, 'f1-score': 0.9809384604874165, 'support': 10182} weighted_avg {'precision': 0.980853907886144, 'recall': 0.9808485562757808, 'f1-score': 0.9808208449821441, 'support': 10182}
 
time = 25.86 secondes

Val loss 0.9174645882031002 accuracy 0.8736749291419983 macro_avg {'precision': 0.8743525205611787, 'recall': 0.870163025428693, 'f1-score': 0.8687193048497773, 'support': 1132} weighted_avg {'precision': 0.8776903671736073, 'recall': 0.8736749116607774, 'f1-score': 0.8728125846396697, 'support': 1132}
 
----------
Epoch 13/40
time = 837.00 secondes

Train loss 0.11175556105454276 accuracy 0.978295087814331 macro_avg {'precision': 0.9786328604950926, 'recall': 0.9786475512368286, 'f1-score': 0.9785980129455355, 'support': 10182} weighted_avg {'precision': 0.9784768940605688, 'recall': 0.978295030445885, 'f1-score': 0.9783425604685464, 'support': 10182}
 
time = 25.45 secondes

Val loss 0.9927065817440014 accuracy 0.8604240417480469 macro_avg {'precision': 0.8769641991139032, 'recall': 0.8641370154753665, 'f1-score': 0.8661844522014368, 'support': 1132} weighted_avg {'precision': 0.8761393965251432, 'recall': 0.8604240282685512, 'f1-score': 0.8636989740585369, 'support': 1132}
 
----------
Epoch 14/40
time = 836.82 secondes

Train loss 0.10366895973799915 accuracy 0.9813396334648132 macro_avg {'precision': 0.9798089720628406, 'recall': 0.9798977842149753, 'f1-score': 0.9798281433625101, 'support': 10182} weighted_avg {'precision': 0.9813920571501208, 'recall': 0.9813396189353761, 'f1-score': 0.9813423274712456, 'support': 10182}
 
time = 25.45 secondes

Val loss 0.9724630708207743 accuracy 0.8674911856651306 macro_avg {'precision': 0.8746871756895345, 'recall': 0.8600148412253942, 'f1-score': 0.8597599007614314, 'support': 1132} weighted_avg {'precision': 0.87357120576156, 'recall': 0.8674911660777385, 'f1-score': 0.864474835786315, 'support': 1132}
 
----------
Epoch 15/40
time = 832.96 secondes

Train loss 0.09316526724072119 accuracy 0.9822235703468323 macro_avg {'precision': 0.9816155842815588, 'recall': 0.9814443093470887, 'f1-score': 0.9814931604500188, 'support': 10182} weighted_avg {'precision': 0.9822594947651405, 'recall': 0.9822235317226478, 'f1-score': 0.9822050880187012, 'support': 10182}
 
time = 25.53 secondes

Val loss 1.1260967991801805 accuracy 0.8630741834640503 macro_avg {'precision': 0.8841012896285472, 'recall': 0.8640307986204027, 'f1-score': 0.8648174693635902, 'support': 1132} weighted_avg {'precision': 0.8806157466821105, 'recall': 0.8630742049469965, 'f1-score': 0.8627788518613921, 'support': 1132}
 
----------
Epoch 16/40
time = 837.71 secondes

Train loss 0.08060992584564751 accuracy 0.9849734902381897 macro_avg {'precision': 0.9842698935065657, 'recall': 0.9843649161260221, 'f1-score': 0.9843006958719647, 'support': 10182} weighted_avg {'precision': 0.9850019893364226, 'recall': 0.9849734826163818, 'f1-score': 0.9849705327106564, 'support': 10182}
 
time = 25.98 secondes

Val loss 0.9158615016497952 accuracy 0.8772084712982178 macro_avg {'precision': 0.8893542302416856, 'recall': 0.8792573582413347, 'f1-score': 0.8803179863934423, 'support': 1132} weighted_avg {'precision': 0.8887202091014308, 'recall': 0.877208480565371, 'f1-score': 0.878830348053801, 'support': 1132}
 
----------
Epoch 17/40
time = 836.10 secondes

Train loss 0.07923141300407409 accuracy 0.9860538244247437 macro_avg {'precision': 0.9862305111550622, 'recall': 0.9858897528597051, 'f1-score': 0.9860245447506649, 'support': 10182} weighted_avg {'precision': 0.9861789801137762, 'recall': 0.9860538204674917, 'f1-score': 0.9860802520630646, 'support': 10182}
 
time = 25.62 secondes

Val loss 0.8938685422515231 accuracy 0.8869258165359497 macro_avg {'precision': 0.8935427594427706, 'recall': 0.8901451853894644, 'f1-score': 0.8895678867770765, 'support': 1132} weighted_avg {'precision': 0.8949359545526747, 'recall': 0.8869257950530035, 'f1-score': 0.8887462025829816, 'support': 1132}
 
----------
Epoch 18/40
time = 838.47 secondes

Train loss 0.08319271065736006 accuracy 0.9845806360244751 macro_avg {'precision': 0.9846152965407102, 'recall': 0.9843694770783756, 'f1-score': 0.9844711316318262, 'support': 10182} weighted_avg {'precision': 0.9846026620567924, 'recall': 0.9845806324887055, 'f1-score': 0.9845701177161026, 'support': 10182}
 
time = 25.89 secondes

Val loss 0.9057115840444401 accuracy 0.8895759582519531 macro_avg {'precision': 0.8942787861076276, 'recall': 0.8931888098733289, 'f1-score': 0.8919486714424283, 'support': 1132} weighted_avg {'precision': 0.8944543472285617, 'recall': 0.8895759717314488, 'f1-score': 0.8902188542552565, 'support': 1132}
 
----------
Epoch 19/40
time = 837.20 secondes

Train loss 0.07601610734437005 accuracy 0.9852681756019592 macro_avg {'precision': 0.9844603151410551, 'recall': 0.9847334091426987, 'f1-score': 0.9845620805041435, 'support': 10182} weighted_avg {'precision': 0.9853574667728118, 'recall': 0.985268120212139, 'f1-score': 0.9852816122111708, 'support': 10182}
 
time = 26.08 secondes

Val loss 0.9073039649729125 accuracy 0.8886925578117371 macro_avg {'precision': 0.8915067146620064, 'recall': 0.8902018697311871, 'f1-score': 0.8886763628145996, 'support': 1132} weighted_avg {'precision': 0.8943883021006185, 'recall': 0.8886925795053003, 'f1-score': 0.8892977000921026, 'support': 1132}
 
----------
Epoch 20/40
time = 836.79 secondes

Train loss 0.06786750769910845 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881799973406107, 'recall': 0.9886124392926261, 'f1-score': 0.9883585970666507, 'support': 10182} weighted_avg {'precision': 0.9886729832216284, 'recall': 0.9886073462973876, 'f1-score': 0.9886091939255275, 'support': 10182}
 
time = 25.57 secondes

Val loss 0.9216227587723398 accuracy 0.8816254734992981 macro_avg {'precision': 0.8842874549224206, 'recall': 0.8847048594026656, 'f1-score': 0.8823608132726948, 'support': 1132} weighted_avg {'precision': 0.884860107462588, 'recall': 0.8816254416961131, 'f1-score': 0.8809332483844815, 'support': 1132}
 
----------
Epoch 21/40
time = 837.66 secondes

Train loss 0.06867338805865843 accuracy 0.9875270128250122 macro_avg {'precision': 0.9873690842860267, 'recall': 0.9870481888191198, 'f1-score': 0.9871964964888893, 'support': 10182} weighted_avg {'precision': 0.9875662806424296, 'recall': 0.9875270084462777, 'f1-score': 0.9875348111884352, 'support': 10182}
 
time = 25.88 secondes

Val loss 1.0431820057196424 accuracy 0.8736749291419983 macro_avg {'precision': 0.9009845807571757, 'recall': 0.875733765979726, 'f1-score': 0.8771964838580887, 'support': 1132} weighted_avg {'precision': 0.8963444105688528, 'recall': 0.8736749116607774, 'f1-score': 0.872691912395025, 'support': 1132}
 
----------
Epoch 22/40
time = 827.37 secondes

Train loss 0.0540032207424346 accuracy 0.98978590965271 macro_avg {'precision': 0.9899928571751492, 'recall': 0.990062980315671, 'f1-score': 0.9900057108860085, 'support': 10182} weighted_avg {'precision': 0.9898364502634802, 'recall': 0.9897858966804164, 'f1-score': 0.9897883628799112, 'support': 10182}
 
time = 23.25 secondes

Val loss 0.8020806166105231 accuracy 0.9019434452056885 macro_avg {'precision': 0.9052598465812232, 'recall': 0.9016280173194591, 'f1-score': 0.9024467713101005, 'support': 1132} weighted_avg {'precision': 0.9049834172473205, 'recall': 0.9019434628975265, 'f1-score': 0.9023924028192993, 'support': 1132}
 
----------
Epoch 23/40
time = 639.41 secondes

Train loss 0.054076517074387806 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896140765000292, 'recall': 0.9896042564360273, 'f1-score': 0.9895966448181728, 'support': 10182} weighted_avg {'precision': 0.989905913410055, 'recall': 0.9898841092123355, 'f1-score': 0.9898824064274162, 'support': 10182}
 
time = 23.63 secondes

Val loss 0.823391070404245 accuracy 0.9019434452056885 macro_avg {'precision': 0.9056072801871107, 'recall': 0.9018479180328987, 'f1-score': 0.9015873832212055, 'support': 1132} weighted_avg {'precision': 0.9077448184588971, 'recall': 0.9019434628975265, 'f1-score': 0.9030627386185328, 'support': 1132}
 
----------
Epoch 24/40
time = 638.78 secondes

Train loss 0.06165873431409194 accuracy 0.9890984296798706 macro_avg {'precision': 0.9887301098646508, 'recall': 0.9883080775512486, 'f1-score': 0.9884886487201564, 'support': 10182} weighted_avg {'precision': 0.9891151324786456, 'recall': 0.9890984089569829, 'f1-score': 0.9890819838232102, 'support': 10182}
 
time = 21.93 secondes

Val loss 0.8249663097255545 accuracy 0.9019434452056885 macro_avg {'precision': 0.9081451836524558, 'recall': 0.9022773540237568, 'f1-score': 0.9036393391714667, 'support': 1132} weighted_avg {'precision': 0.906463499731577, 'recall': 0.9019434628975265, 'f1-score': 0.9025310705396843, 'support': 1132}
 
----------
Epoch 25/40
time = 640.08 secondes

Train loss 0.042235242178474415 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915424752009733, 'recall': 0.9912906370297913, 'f1-score': 0.9913932248575479, 'support': 10182} weighted_avg {'precision': 0.9919737419845336, 'recall': 0.9919465723826361, 'f1-score': 0.9919394001952633, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.8793593217097866 accuracy 0.8904593586921692 macro_avg {'precision': 0.900676615667358, 'recall': 0.8918028642967102, 'f1-score': 0.8921830899990069, 'support': 1132} weighted_avg {'precision': 0.8997567582581208, 'recall': 0.8904593639575972, 'f1-score': 0.891748230216904, 'support': 1132}
 
----------
Epoch 26/40
time = 640.09 secondes

Train loss 0.04696438047307699 accuracy 0.9915537238121033 macro_avg {'precision': 0.9906586162044494, 'recall': 0.9909579782948349, 'f1-score': 0.9907892757066395, 'support': 10182} weighted_avg {'precision': 0.9916025669629606, 'recall': 0.9915537222549597, 'f1-score': 0.9915613791689488, 'support': 10182}
 
time = 23.49 secondes

Val loss 1.0078850205161511 accuracy 0.8833922147750854 macro_avg {'precision': 0.8846721498546921, 'recall': 0.8873490057678968, 'f1-score': 0.8822614298680167, 'support': 1132} weighted_avg {'precision': 0.8919391263858424, 'recall': 0.8833922261484098, 'f1-score': 0.8843886505945395, 'support': 1132}
 
----------
Epoch 27/40
time = 637.33 secondes

Train loss 0.041386545059611354 accuracy 0.9930269122123718 macro_avg {'precision': 0.9926696496806213, 'recall': 0.9928325906522373, 'f1-score': 0.9927440834653943, 'support': 10182} weighted_avg {'precision': 0.9930528290356434, 'recall': 0.9930269102337458, 'f1-score': 0.9930327956373979, 'support': 10182}
 
time = 23.40 secondes

Val loss 1.0143320002723453 accuracy 0.8948763608932495 macro_avg {'precision': 0.9033699327506355, 'recall': 0.897364945004784, 'f1-score': 0.8977440342649963, 'support': 1132} weighted_avg {'precision': 0.9022690138489569, 'recall': 0.8948763250883393, 'f1-score': 0.8957960002837481, 'support': 1132}
 
----------
Epoch 28/40
time = 638.23 secondes

Train loss 0.04992398067682458 accuracy 0.9927322864532471 macro_avg {'precision': 0.9927053788795396, 'recall': 0.9926731665329542, 'f1-score': 0.9926822927101349, 'support': 10182} weighted_avg {'precision': 0.9927369692592197, 'recall': 0.9927322726379886, 'f1-score': 0.9927276717822284, 'support': 10182}
 
time = 22.21 secondes

Val loss 0.809547954855563 accuracy 0.9054770469665527 macro_avg {'precision': 0.9114032350935073, 'recall': 0.9066966415107608, 'f1-score': 0.9080433958266149, 'support': 1132} weighted_avg {'precision': 0.9086497525398427, 'recall': 0.9054770318021201, 'f1-score': 0.9060532155937443, 'support': 1132}
 
----------
Epoch 29/40
time = 638.64 secondes

Train loss 0.0374347791728658 accuracy 0.9941073060035706 macro_avg {'precision': 0.9942380773889801, 'recall': 0.9940589030160819, 'f1-score': 0.9941429199427019, 'support': 10182} weighted_avg {'precision': 0.994112273857776, 'recall': 0.9941072480848556, 'f1-score': 0.9941044145092717, 'support': 10182}
 
time = 23.42 secondes

Val loss 0.9885589961798962 accuracy 0.8975265026092529 macro_avg {'precision': 0.9020113275686432, 'recall': 0.9009716394824661, 'f1-score': 0.8993834385602846, 'support': 1132} weighted_avg {'precision': 0.9020660509730407, 'recall': 0.8975265017667845, 'f1-score': 0.8976793844638904, 'support': 1132}
 
----------
Epoch 30/40
time = 705.41 secondes

Train loss 0.042311823512621916 accuracy 0.9936162233352661 macro_avg {'precision': 0.9935377033379227, 'recall': 0.993750939508063, 'f1-score': 0.9936314129061723, 'support': 10182} weighted_avg {'precision': 0.9936267750544493, 'recall': 0.9936161854252603, 'f1-score': 0.9936090841816292, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.8852098450616197 accuracy 0.8992933034896851 macro_avg {'precision': 0.9064757659073834, 'recall': 0.9000698669034601, 'f1-score': 0.9010142185734467, 'support': 1132} weighted_avg {'precision': 0.9068482180303824, 'recall': 0.8992932862190812, 'f1-score': 0.9008537847772174, 'support': 1132}
 
----------
Epoch 31/40
time = 717.64 secondes

Train loss 0.035865038700098044 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945390843363595, 'recall': 0.9946758954199986, 'f1-score': 0.9946027514979789, 'support': 10182} weighted_avg {'precision': 0.9946071631348953, 'recall': 0.994598310744451, 'f1-score': 0.9945981723390306, 'support': 10182}
 
time = 23.96 secondes

Val loss 0.8857434673952578 accuracy 0.898409903049469 macro_avg {'precision': 0.9076609217972255, 'recall': 0.9017255685142642, 'f1-score': 0.9020470769018992, 'support': 1132} weighted_avg {'precision': 0.9056896935223729, 'recall': 0.8984098939929329, 'f1-score': 0.8992160004657599, 'support': 1132}
 
----------
Epoch 32/40
time = 718.93 secondes

Train loss 0.01737048085757478 accuracy 0.996857225894928 macro_avg {'precision': 0.9965922851027459, 'recall': 0.9965964850830387, 'f1-score': 0.9965930030441983, 'support': 10182} weighted_avg {'precision': 0.9968601725240651, 'recall': 0.9968571989785897, 'f1-score': 0.9968573292278397, 'support': 10182}
 
time = 23.99 secondes

Val loss 0.8673109349010317 accuracy 0.9045936465263367 macro_avg {'precision': 0.9123126860329072, 'recall': 0.9067933867916921, 'f1-score': 0.907815800814461, 'support': 1132} weighted_avg {'precision': 0.9104437722268408, 'recall': 0.9045936395759717, 'f1-score': 0.905686201653122, 'support': 1132}
 
----------
Epoch 33/40
time = 719.85 secondes

Train loss 0.01908183911271428 accuracy 0.9962679743766785 macro_avg {'precision': 0.9962302748102676, 'recall': 0.9962026006022846, 'f1-score': 0.9962125626342841, 'support': 10182} weighted_avg {'precision': 0.9962726890305023, 'recall': 0.9962679237870752, 'f1-score': 0.9962664657690165, 'support': 10182}
 
time = 23.39 secondes

Val loss 0.960587005702468 accuracy 0.8975265026092529 macro_avg {'precision': 0.9084874781130571, 'recall': 0.8987659339428424, 'f1-score': 0.9006215780084339, 'support': 1132} weighted_avg {'precision': 0.9067867513105893, 'recall': 0.8975265017667845, 'f1-score': 0.899081119210979, 'support': 1132}
 
----------
Epoch 34/40
time = 720.44 secondes

Train loss 0.015326959784097784 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971738178892906, 'recall': 0.9972178766427492, 'f1-score': 0.9971943351554661, 'support': 10182} weighted_avg {'precision': 0.9971537453979965, 'recall': 0.9971518365743469, 'f1-score': 0.9971512750777651, 'support': 10182}
 
time = 24.20 secondes

Val loss 0.9240026213122126 accuracy 0.8957597017288208 macro_avg {'precision': 0.8972603826468395, 'recall': 0.8977690074949845, 'f1-score': 0.8959372856115027, 'support': 1132} weighted_avg {'precision': 0.9001916249699762, 'recall': 0.8957597173144877, 'f1-score': 0.8964161573982706, 'support': 1132}
 
----------
Epoch 35/40
time = 720.81 secondes

Train loss 0.02142309530165301 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971848591651806, 'recall': 0.9972031475103492, 'f1-score': 0.9971915895045431, 'support': 10182} weighted_avg {'precision': 0.9971563130324574, 'recall': 0.9971518365743469, 'f1-score': 0.9971516276297803, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.944493991353892 accuracy 0.8992933034896851 macro_avg {'precision': 0.9084956005116294, 'recall': 0.9032534204469396, 'f1-score': 0.9036668290907661, 'support': 1132} weighted_avg {'precision': 0.9061107420090534, 'recall': 0.8992932862190812, 'f1-score': 0.9003103841532892, 'support': 1132}
 
----------
Epoch 36/40
time = 719.31 secondes

Train loss 0.008777782325476614 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986539652285844, 'recall': 0.9986605999620022, 'f1-score': 0.9986558564277835, 'support': 10182} weighted_avg {'precision': 0.9986265551114746, 'recall': 0.998625024553133, 'f1-score': 0.9986243543818654, 'support': 10182}
 
time = 24.10 secondes

Val loss 0.8363662594547863 accuracy 0.9178445339202881 macro_avg {'precision': 0.9225881451332301, 'recall': 0.9200313723256354, 'f1-score': 0.920076210141573, 'support': 1132} weighted_avg {'precision': 0.921054087789988, 'recall': 0.9178445229681979, 'f1-score': 0.9181434047132578, 'support': 1132}
 
----------
Epoch 37/40
time = 720.96 secondes

Train loss 0.011582849999878355 accuracy 0.9981340169906616 macro_avg {'precision': 0.9982104027736064, 'recall': 0.9981998379879009, 'f1-score': 0.9982023150416698, 'support': 10182} weighted_avg {'precision': 0.9981400629681199, 'recall': 0.9981339618935376, 'f1-score': 0.9981341220971424, 'support': 10182}
 
time = 24.15 secondes

Val loss 0.9052395592850996 accuracy 0.9090105891227722 macro_avg {'precision': 0.9121052382666441, 'recall': 0.9122253194207304, 'f1-score': 0.9103837758286785, 'support': 1132} weighted_avg {'precision': 0.9136721134779537, 'recall': 0.9090106007067138, 'f1-score': 0.9096023537617903, 'support': 1132}
 
----------
Epoch 38/40
time = 720.33 secondes

Train loss 0.008313302486978038 accuracy 0.998821496963501 macro_avg {'precision': 0.9988512663391287, 'recall': 0.9988559482871772, 'f1-score': 0.998852332008763, 'support': 10182} weighted_avg {'precision': 0.9988246018295892, 'recall': 0.9988214496169712, 'f1-score': 0.9988217171558444, 'support': 10182}
 
time = 24.38 secondes

Val loss 0.9017778550646461 accuracy 0.9098939895629883 macro_avg {'precision': 0.9114992824115538, 'recall': 0.9117584308945362, 'f1-score': 0.9108806845659838, 'support': 1132} weighted_avg {'precision': 0.9127114504068359, 'recall': 0.9098939929328622, 'f1-score': 0.9105542915437483, 'support': 1132}
 
----------
Epoch 39/40
time = 720.35 secondes

Train loss 0.004415794848718403 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990556175849136, 'recall': 0.9990557948559132, 'f1-score': 0.9990548141045735, 'support': 10182} weighted_avg {'precision': 0.9990197198847299, 'recall': 0.9990178746808093, 'f1-score': 0.999017870763278, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.9412181954181172 accuracy 0.9090105891227722 macro_avg {'precision': 0.9115841138472375, 'recall': 0.9112732849315629, 'f1-score': 0.9103448842231285, 'support': 1132} weighted_avg {'precision': 0.9118296183706455, 'recall': 0.9090106007067138, 'f1-score': 0.9093206892378543, 'support': 1132}
 
----------
Epoch 40/40
time = 719.43 secondes

Train loss 0.005215827239922957 accuracy 0.9992143511772156 macro_avg {'precision': 0.9992450804989627, 'recall': 0.9992364998161716, 'f1-score': 0.9992392636668296, 'support': 10182} weighted_avg {'precision': 0.999218555129631, 'recall': 0.9992142997446474, 'f1-score': 0.9992148536231642, 'support': 10182}
 
time = 24.80 secondes

Val loss 0.9346085568990353 accuracy 0.9107773900032043 macro_avg {'precision': 0.9144943890123194, 'recall': 0.9128575032692463, 'f1-score': 0.9125734070381759, 'support': 1132} weighted_avg {'precision': 0.9138476734713233, 'recall': 0.9107773851590106, 'f1-score': 0.911190810940502, 'support': 1132}
 
----------
best_accuracy 0.9178445339202881 best_epoch 36 macro_avg {'precision': 0.9225881451332301, 'recall': 0.9200313723256354, 'f1-score': 0.920076210141573, 'support': 1132} weighted_avg {'precision': 0.921054087789988, 'recall': 0.9178445229681979, 'f1-score': 0.9181434047132578, 'support': 1132}

average train time 733.9297438800335

average val time 24.39423597455025
 
time = 155.35 secondes

test_accuracy 0.8275358080863953 macro_avg {'precision': 0.8260559319249452, 'recall': 0.8221825512176645, 'f1-score': 0.8222292337917094, 'support': 7532} weighted_avg {'precision': 0.832600867866986, 'recall': 0.8275358470525757, 'f1-score': 0.8284608665428768, 'support': 7532}

----------
/vol/fob-vol3/nebenf20/wubingti/data/22_wub_longdocclassification/trainer.py:82: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_2
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 427.31 secondes

Train loss 1.3944869267884379 accuracy 0.6181496977806091 macro_avg {'precision': 0.6045006226210984, 'recall': 0.6023568057655814, 'f1-score': 0.5899182731107757, 'support': 10182} weighted_avg {'precision': 0.6117337902996466, 'recall': 0.6181496758986447, 'f1-score': 0.6039109376752558, 'support': 10182}
 
time = 18.86 secondes

Val loss 0.788058576029791 accuracy 0.7623674869537354 macro_avg {'precision': 0.7472090891743186, 'recall': 0.7588656075897282, 'f1-score': 0.7421309130196391, 'support': 1132} weighted_avg {'precision': 0.7592242975126788, 'recall': 0.7623674911660777, 'f1-score': 0.7494949316621431, 'support': 1132}
 
----------
Epoch 2/40
time = 426.86 secondes

Train loss 0.5850483487174499 accuracy 0.8245924711227417 macro_avg {'precision': 0.8122776845412082, 'recall': 0.8131538194869453, 'f1-score': 0.8098732518066617, 'support': 10182} weighted_avg {'precision': 0.8204633086580889, 'recall': 0.8245924179925358, 'f1-score': 0.8204472778701701, 'support': 10182}
 
time = 19.03 secondes

Val loss 0.596053410373943 accuracy 0.8242049813270569 macro_avg {'precision': 0.8223741335017405, 'recall': 0.8181435430972808, 'f1-score': 0.8120008259362381, 'support': 1132} weighted_avg {'precision': 0.8276198653027891, 'recall': 0.8242049469964664, 'f1-score': 0.8188381949377425, 'support': 1132}
 
----------
Epoch 3/40
time = 427.36 secondes

Train loss 0.3575606437318109 accuracy 0.8985464572906494 macro_avg {'precision': 0.8933212892312646, 'recall': 0.8929839811862802, 'f1-score': 0.8929051815745856, 'support': 10182} weighted_avg {'precision': 0.8986419047575008, 'recall': 0.8985464545275977, 'f1-score': 0.8983564043106278, 'support': 10182}
 
time = 18.85 secondes

Val loss 0.5565338725040496 accuracy 0.8480565547943115 macro_avg {'precision': 0.8528758698680713, 'recall': 0.8477144025007576, 'f1-score': 0.8465388153138983, 'support': 1132} weighted_avg {'precision': 0.8552435632693681, 'recall': 0.8480565371024735, 'f1-score': 0.8476463890366434, 'support': 1132}
 
----------
Epoch 4/40
time = 426.68 secondes

Train loss 0.237381704627526 accuracy 0.9332154989242554 macro_avg {'precision': 0.930445629520219, 'recall': 0.9305066848475727, 'f1-score': 0.9303990640736878, 'support': 10182} weighted_avg {'precision': 0.9331704294143961, 'recall': 0.9332154782950305, 'f1-score': 0.933117835503915, 'support': 10182}
 
time = 18.56 secondes

Val loss 0.5852532469287095 accuracy 0.8736749291419983 macro_avg {'precision': 0.8776755776564509, 'recall': 0.8688361355115003, 'f1-score': 0.8696246691971175, 'support': 1132} weighted_avg {'precision': 0.8775439916697695, 'recall': 0.8736749116607774, 'f1-score': 0.8724567757484273, 'support': 1132}
 
----------
Epoch 5/40
time = 427.00 secondes

Train loss 0.17320953996660512 accuracy 0.95403653383255 macro_avg {'precision': 0.951707244460119, 'recall': 0.9517939456996107, 'f1-score': 0.9517229055027492, 'support': 10182} weighted_avg {'precision': 0.9541145581682021, 'recall': 0.9540365350618739, 'f1-score': 0.9540477064468614, 'support': 10182}
 
time = 18.67 secondes

Val loss 0.6530555817856073 accuracy 0.8763250708580017 macro_avg {'precision': 0.8875437649454596, 'recall': 0.8761900024143024, 'f1-score': 0.8781754998462954, 'support': 1132} weighted_avg {'precision': 0.8844696027439095, 'recall': 0.8763250883392226, 'f1-score': 0.8767880792855786, 'support': 1132}
 
----------
Epoch 6/40
time = 426.68 secondes

Train loss 0.1499853816716398 accuracy 0.9607149958610535 macro_avg {'precision': 0.9591360875080956, 'recall': 0.9592451188755666, 'f1-score': 0.9591433502451634, 'support': 10182} weighted_avg {'precision': 0.9609027966544885, 'recall': 0.9607149872323708, 'f1-score': 0.9607610887085988, 'support': 10182}
 
time = 18.09 secondes

Val loss 0.7074301727476832 accuracy 0.870141327381134 macro_avg {'precision': 0.8746033563183581, 'recall': 0.8710008207731071, 'f1-score': 0.8708220130576209, 'support': 1132} weighted_avg {'precision': 0.8752996486161535, 'recall': 0.8701413427561837, 'f1-score': 0.8706692570800069, 'support': 1132}
 
----------
Epoch 7/40
time = 426.04 secondes

Train loss 0.13629770623297055 accuracy 0.9678845405578613 macro_avg {'precision': 0.9664717062297828, 'recall': 0.9663277860561555, 'f1-score': 0.9663610212735894, 'support': 10182} weighted_avg {'precision': 0.9679270475444599, 'recall': 0.9678845020624631, 'f1-score': 0.9678682620281933, 'support': 10182}
 
time = 18.74 secondes

Val loss 0.7419142454828161 accuracy 0.8754417300224304 macro_avg {'precision': 0.8842747702719503, 'recall': 0.8764918851701544, 'f1-score': 0.8761088224777025, 'support': 1132} weighted_avg {'precision': 0.8846427210283666, 'recall': 0.8754416961130742, 'f1-score': 0.8759983589118007, 'support': 1132}
 
----------
Epoch 8/40
time = 426.50 secondes

Train loss 0.14834782267031385 accuracy 0.9676880836486816 macro_avg {'precision': 0.967121411813664, 'recall': 0.9668541421399324, 'f1-score': 0.9669416756162594, 'support': 10182} weighted_avg {'precision': 0.9676985893406989, 'recall': 0.967688076998625, 'f1-score': 0.9676485382233034, 'support': 10182}
 
time = 18.66 secondes

Val loss 0.9086899811739731 accuracy 0.8604240417480469 macro_avg {'precision': 0.8670106136329319, 'recall': 0.8615929771446554, 'f1-score': 0.8592571192966693, 'support': 1132} weighted_avg {'precision': 0.8696750623046163, 'recall': 0.8604240282685512, 'f1-score': 0.8601631210354338, 'support': 1132}
 
----------
Epoch 9/40
time = 426.37 secondes

Train loss 0.13137833078732142 accuracy 0.9725005030632019 macro_avg {'precision': 0.9720151576817531, 'recall': 0.971437653868921, 'f1-score': 0.9716862263128666, 'support': 10182} weighted_avg {'precision': 0.9724324476363007, 'recall': 0.9725004910626596, 'f1-score': 0.9724316753338268, 'support': 10182}
 
time = 18.68 secondes

Val loss 0.7998119518857673 accuracy 0.8789752721786499 macro_avg {'precision': 0.8879375515442411, 'recall': 0.877886114332326, 'f1-score': 0.8782433580770077, 'support': 1132} weighted_avg {'precision': 0.891058425140966, 'recall': 0.8789752650176679, 'f1-score': 0.88114296794068, 'support': 1132}
 
----------
Epoch 10/40
time = 427.19 secondes

Train loss 0.11925029340039302 accuracy 0.9744647741317749 macro_avg {'precision': 0.973440949820958, 'recall': 0.97359871301659, 'f1-score': 0.973487547668449, 'support': 10182} weighted_avg {'precision': 0.9745241718167451, 'recall': 0.974464741701041, 'f1-score': 0.974462297641218, 'support': 10182}
 
time = 18.49 secondes

Val loss 0.7808534845781125 accuracy 0.8825088143348694 macro_avg {'precision': 0.8868047564617708, 'recall': 0.8853518605353179, 'f1-score': 0.8835108788619813, 'support': 1132} weighted_avg {'precision': 0.888260858610339, 'recall': 0.8825088339222615, 'f1-score': 0.8826601189510983, 'support': 1132}
 
----------
Epoch 11/40
time = 428.50 secondes

Train loss 0.11701830308108585 accuracy 0.9752504825592041 macro_avg {'precision': 0.9750317882795846, 'recall': 0.9748261806906324, 'f1-score': 0.9749115164214164, 'support': 10182} weighted_avg {'precision': 0.9752820207947129, 'recall': 0.9752504419563937, 'f1-score': 0.9752482758621236, 'support': 10182}
 
time = 18.63 secondes

Val loss 0.7985545295056179 accuracy 0.879858672618866 macro_avg {'precision': 0.8848967198962313, 'recall': 0.8841142044478563, 'f1-score': 0.8800696985767693, 'support': 1132} weighted_avg {'precision': 0.8897030243905966, 'recall': 0.8798586572438163, 'f1-score': 0.880167748091954, 'support': 1132}
 
----------
Epoch 12/40
time = 427.04 secondes

Train loss 0.09020881973644422 accuracy 0.9808486104011536 macro_avg {'precision': 0.9806664243515517, 'recall': 0.9807692078478463, 'f1-score': 0.9806822634500525, 'support': 10182} weighted_avg {'precision': 0.9808985264497452, 'recall': 0.9808485562757808, 'f1-score': 0.9808372711420434, 'support': 10182}
 
time = 18.33 secondes

Val loss 0.8482931855054323 accuracy 0.8833922147750854 macro_avg {'precision': 0.887591686606602, 'recall': 0.8865967573786374, 'f1-score': 0.8848982868404478, 'support': 1132} weighted_avg {'precision': 0.8886467518272586, 'recall': 0.8833922261484098, 'f1-score': 0.8837899194909417, 'support': 1132}
 
----------
Epoch 13/40
time = 426.97 secondes

Train loss 0.09110393500773092 accuracy 0.9814378619194031 macro_avg {'precision': 0.9811586521147048, 'recall': 0.9808376155275319, 'f1-score': 0.9809426355577786, 'support': 10182} weighted_avg {'precision': 0.9815287905216034, 'recall': 0.9814378314672952, 'f1-score': 0.9814264878872099, 'support': 10182}
 
time = 18.30 secondes

Val loss 0.9327451979940672 accuracy 0.8710247278213501 macro_avg {'precision': 0.8781609115720521, 'recall': 0.8735901511007793, 'f1-score': 0.871934160526812, 'support': 1132} weighted_avg {'precision': 0.8806922230375215, 'recall': 0.8710247349823321, 'f1-score': 0.8718955173915479, 'support': 1132}
 
----------
Epoch 14/40
time = 427.86 secondes

Train loss 0.07938389505928213 accuracy 0.9834021329879761 macro_avg {'precision': 0.9834453078126719, 'recall': 0.9831931163322976, 'f1-score': 0.9832883621303885, 'support': 10182} weighted_avg {'precision': 0.9834271118775184, 'recall': 0.9834020821056767, 'f1-score': 0.983384118496638, 'support': 10182}
 
time = 18.77 secondes

Val loss 0.7628874563477592 accuracy 0.8913427591323853 macro_avg {'precision': 0.8977923199827755, 'recall': 0.8945243434939127, 'f1-score': 0.8945411728032946, 'support': 1132} weighted_avg {'precision': 0.8958691583497893, 'recall': 0.8913427561837456, 'f1-score': 0.891849923099418, 'support': 1132}
 
----------
Epoch 15/40
time = 427.19 secondes

Train loss 0.07602018751505789 accuracy 0.9846788644790649 macro_avg {'precision': 0.9846202710671946, 'recall': 0.9844197563032925, 'f1-score': 0.9845092076429147, 'support': 10182} weighted_avg {'precision': 0.984692214061963, 'recall': 0.9846788450206246, 'f1-score': 0.9846751652287741, 'support': 10182}
 
time = 18.73 secondes

Val loss 0.9119916264134587 accuracy 0.880742073059082 macro_avg {'precision': 0.8842946538606092, 'recall': 0.8835589762303402, 'f1-score': 0.8827416732109562, 'support': 1132} weighted_avg {'precision': 0.8848097430398214, 'recall': 0.8807420494699647, 'f1-score': 0.8815321353607817, 'support': 1132}
 
----------
Epoch 16/40
time = 426.93 secondes

Train loss 0.08259360741776532 accuracy 0.9843842387199402 macro_avg {'precision': 0.9837348465870284, 'recall': 0.9838818972906047, 'f1-score': 0.9837939466486694, 'support': 10182} weighted_avg {'precision': 0.9844258665525611, 'recall': 0.9843842074248674, 'f1-score': 0.9843910337324336, 'support': 10182}
 
time = 18.94 secondes

Val loss 0.8845736283151446 accuracy 0.8860424160957336 macro_avg {'precision': 0.8883999402241397, 'recall': 0.8888392586923484, 'f1-score': 0.8856627739400755, 'support': 1132} weighted_avg {'precision': 0.8912251673204233, 'recall': 0.8860424028268551, 'f1-score': 0.8857509061910637, 'support': 1132}
 
----------
Epoch 17/40
time = 427.45 secondes

Train loss 0.07498923799879151 accuracy 0.9857591986656189 macro_avg {'precision': 0.9852400366293516, 'recall': 0.985517855040748, 'f1-score': 0.9853670895153737, 'support': 10182} weighted_avg {'precision': 0.9857697466191391, 'recall': 0.9857591828717345, 'f1-score': 0.985753648853807, 'support': 10182}
 
time = 18.42 secondes

Val loss 0.7881237364047811 accuracy 0.8895759582519531 macro_avg {'precision': 0.8946488473168974, 'recall': 0.8921448009308399, 'f1-score': 0.8920979699744335, 'support': 1132} weighted_avg {'precision': 0.8927891165473598, 'recall': 0.8895759717314488, 'f1-score': 0.88984537103151, 'support': 1132}
 
----------
Epoch 18/40
time = 433.00 secondes

Train loss 0.06202199371863124 accuracy 0.9879198670387268 macro_avg {'precision': 0.9876474491089278, 'recall': 0.9876703226209267, 'f1-score': 0.9876486534852432, 'support': 10182} weighted_avg {'precision': 0.9879528686027453, 'recall': 0.987919858573954, 'f1-score': 0.9879258677404208, 'support': 10182}
 
time = 18.64 secondes

Val loss 0.9623970465870282 accuracy 0.8648409843444824 macro_avg {'precision': 0.8816679349603291, 'recall': 0.870846891235375, 'f1-score': 0.8707818192105693, 'support': 1132} weighted_avg {'precision': 0.880645383618342, 'recall': 0.8648409893992933, 'f1-score': 0.8666617259269059, 'support': 1132}
 
----------
Epoch 19/40
time = 426.56 secondes

Train loss 0.0677374617840239 accuracy 0.9869377613067627 macro_avg {'precision': 0.9867769289836282, 'recall': 0.9863990683830363, 'f1-score': 0.98656364598944, 'support': 10182} weighted_avg {'precision': 0.9869782294594618, 'recall': 0.9869377332547633, 'f1-score': 0.9869356693536722, 'support': 10182}
 
time = 19.00 secondes

Val loss 0.905616300331095 accuracy 0.8878092169761658 macro_avg {'precision': 0.8903850960633128, 'recall': 0.8929304059871962, 'f1-score': 0.8889787013354281, 'support': 1132} weighted_avg {'precision': 0.8938476582795393, 'recall': 0.8878091872791519, 'f1-score': 0.8881530432731333, 'support': 1132}
 
----------
Epoch 20/40
time = 426.70 secondes

Train loss 0.07014421330095044 accuracy 0.9873306155204773 macro_avg {'precision': 0.9873460270446376, 'recall': 0.9872685308386755, 'f1-score': 0.9872988793729724, 'support': 10182} weighted_avg {'precision': 0.9873357460619406, 'recall': 0.9873305833824396, 'f1-score': 0.9873249668992754, 'support': 10182}
 
time = 17.95 secondes

Val loss 0.9245256907493122 accuracy 0.8816254734992981 macro_avg {'precision': 0.8852891085519443, 'recall': 0.8869970639007159, 'f1-score': 0.8821162547527678, 'support': 1132} weighted_avg {'precision': 0.8895385281757208, 'recall': 0.8816254416961131, 'f1-score': 0.8815427504449098, 'support': 1132}
 
----------
Epoch 21/40
time = 426.18 secondes

Train loss 0.057022561286858904 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893378627560742, 'recall': 0.9893626247541162, 'f1-score': 0.989334031401486, 'support': 10182} weighted_avg {'precision': 0.9894168410047235, 'recall': 0.9893930465527401, 'f1-score': 0.9893889079726764, 'support': 10182}
 
time = 18.36 secondes

Val loss 0.8241545651888911 accuracy 0.8895759582519531 macro_avg {'precision': 0.8953562342109379, 'recall': 0.8918124651644262, 'f1-score': 0.8926665793052058, 'support': 1132} weighted_avg {'precision': 0.8936473588096309, 'recall': 0.8895759717314488, 'f1-score': 0.8906280895138791, 'support': 1132}
 
----------
Epoch 22/40
time = 426.99 secondes

Train loss 0.05812775582255408 accuracy 0.9894912838935852 macro_avg {'precision': 0.9896047939496411, 'recall': 0.9893884408214936, 'f1-score': 0.9894813273092277, 'support': 10182} weighted_avg {'precision': 0.9895298889564399, 'recall': 0.9894912590846592, 'f1-score': 0.989495600720612, 'support': 10182}
 
time = 18.74 secondes

Val loss 0.9095124921246602 accuracy 0.8833922147750854 macro_avg {'precision': 0.8879979221528123, 'recall': 0.8863466686297047, 'f1-score': 0.8848879495511939, 'support': 1132} weighted_avg {'precision': 0.8892548234236863, 'recall': 0.8833922261484098, 'f1-score': 0.8840605766749731, 'support': 1132}
 
----------
Epoch 23/40
time = 426.39 secondes

Train loss 0.04169038312657322 accuracy 0.9908662438392639 macro_avg {'precision': 0.9907101686278816, 'recall': 0.9907347715789898, 'f1-score': 0.9907160062168721, 'support': 10182} weighted_avg {'precision': 0.9908696308269275, 'recall': 0.9908662345315262, 'f1-score': 0.9908619034008569, 'support': 10182}
 
time = 19.11 secondes

Val loss 1.0273031553388392 accuracy 0.8586572408676147 macro_avg {'precision': 0.875394848507335, 'recall': 0.8667456872108785, 'f1-score': 0.8625773783643356, 'support': 1132} weighted_avg {'precision': 0.8768700028147991, 'recall': 0.8586572438162544, 'f1-score': 0.8587815159162229, 'support': 1132}
 
----------
Epoch 24/40
time = 426.52 secondes

Train loss 0.04430176816815071 accuracy 0.9924376606941223 macro_avg {'precision': 0.9924035060138975, 'recall': 0.9923118910648941, 'f1-score': 0.9923535726778251, 'support': 10182} weighted_avg {'precision': 0.9924487534123582, 'recall': 0.9924376350422314, 'f1-score': 0.992439290267036, 'support': 10182}
 
time = 19.05 secondes

Val loss 1.1557206330924115 accuracy 0.8710247278213501 macro_avg {'precision': 0.8772429866178504, 'recall': 0.8747271218739069, 'f1-score': 0.8711978193907293, 'support': 1132} weighted_avg {'precision': 0.8825432578461917, 'recall': 0.8710247349823321, 'f1-score': 0.8720002122301741, 'support': 1132}
 
----------
Epoch 25/40
time = 426.81 secondes

Train loss 0.07214749126611349 accuracy 0.9884109497070312 macro_avg {'precision': 0.9881437784790201, 'recall': 0.9884769191044912, 'f1-score': 0.988293566538734, 'support': 10182} weighted_avg {'precision': 0.988465432064931, 'recall': 0.9884109212335495, 'f1-score': 0.9884227931006876, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.8703565084411103 accuracy 0.8913427591323853 macro_avg {'precision': 0.8939708453646091, 'recall': 0.8967030885350038, 'f1-score': 0.8925369295699873, 'support': 1132} weighted_avg {'precision': 0.8967230758186376, 'recall': 0.8913427561837456, 'f1-score': 0.8910646120682261, 'support': 1132}
 
----------
Epoch 26/40
time = 425.75 secondes

Train loss 0.04745961950775353 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915073586874149, 'recall': 0.9915140337383775, 'f1-score': 0.9915012171200965, 'support': 10182} weighted_avg {'precision': 0.9919701218185927, 'recall': 0.9919465723826361, 'f1-score': 0.991949922477341, 'support': 10182}
 
time = 19.07 secondes

Val loss 0.8690545192723323 accuracy 0.8948763608932495 macro_avg {'precision': 0.9022120240509196, 'recall': 0.8978221002950827, 'f1-score': 0.897832307328294, 'support': 1132} weighted_avg {'precision': 0.900670595207782, 'recall': 0.8948763250883393, 'f1-score': 0.8953793087506162, 'support': 1132}
 
----------
Epoch 27/40
time = 426.06 secondes

Train loss 0.041583240879719464 accuracy 0.9927322864532471 macro_avg {'precision': 0.9925269197109348, 'recall': 0.9922288299278295, 'f1-score': 0.9923516912995762, 'support': 10182} weighted_avg {'precision': 0.9927853461157194, 'recall': 0.9927322726379886, 'f1-score': 0.9927364722911269, 'support': 10182}
 
time = 19.09 secondes

Val loss 1.2035920749207127 accuracy 0.8586572408676147 macro_avg {'precision': 0.8769976111556549, 'recall': 0.8616841737070124, 'f1-score': 0.8633512925140743, 'support': 1132} weighted_avg {'precision': 0.8763109447215587, 'recall': 0.8586572438162544, 'f1-score': 0.861226206528085, 'support': 1132}
 
----------
Epoch 28/40
time = 426.73 secondes

Train loss 0.040594573515012784 accuracy 0.9936162233352661 macro_avg {'precision': 0.9935913200631491, 'recall': 0.9935565100621984, 'f1-score': 0.9935692247024915, 'support': 10182} weighted_avg {'precision': 0.9936282358671814, 'recall': 0.9936161854252603, 'f1-score': 0.9936176532703719, 'support': 10182}
 
time = 18.31 secondes

Val loss 0.944949869870009 accuracy 0.8904593586921692 macro_avg {'precision': 0.8926181254976896, 'recall': 0.8926676999648893, 'f1-score': 0.8905797067033732, 'support': 1132} weighted_avg {'precision': 0.8949852675423717, 'recall': 0.8904593639575972, 'f1-score': 0.8907419316481088, 'support': 1132}
 
----------
Epoch 29/40
time = 426.34 secondes

Train loss 0.04400276573926744 accuracy 0.9924376606941223 macro_avg {'precision': 0.9923377285782928, 'recall': 0.9924724295619377, 'f1-score': 0.9923905179766006, 'support': 10182} weighted_avg {'precision': 0.9924527159814626, 'recall': 0.9924376350422314, 'f1-score': 0.9924304618441244, 'support': 10182}
 
time = 19.04 secondes

Val loss 0.9833480149251737 accuracy 0.8825088143348694 macro_avg {'precision': 0.8884369245109708, 'recall': 0.8861775306165107, 'f1-score': 0.8849164716317915, 'support': 1132} weighted_avg {'precision': 0.8907599367376277, 'recall': 0.8825088339222615, 'f1-score': 0.8842370662082859, 'support': 1132}
 
----------
Epoch 30/40
time = 426.23 secondes

Train loss 0.031844082074066006 accuracy 0.9946965575218201 macro_avg {'precision': 0.9947225132088858, 'recall': 0.9947545541406548, 'f1-score': 0.9947340428032355, 'support': 10182} weighted_avg {'precision': 0.9947104332827956, 'recall': 0.99469652327637, 'f1-score': 0.9946989626534372, 'support': 10182}
 
time = 19.06 secondes

Val loss 0.940710612721528 accuracy 0.8860424160957336 macro_avg {'precision': 0.8894782407212581, 'recall': 0.8905645808590433, 'f1-score': 0.888101816244386, 'support': 1132} weighted_avg {'precision': 0.8913551441985083, 'recall': 0.8860424028268551, 'f1-score': 0.8867444283056902, 'support': 1132}
 
----------
Epoch 31/40
time = 425.49 secondes

Train loss 0.03165554801254622 accuracy 0.994892954826355 macro_avg {'precision': 0.994667154382044, 'recall': 0.9946460142295266, 'f1-score': 0.9946524377807784, 'support': 10182} weighted_avg {'precision': 0.9949021354221078, 'recall': 0.9948929483402082, 'f1-score': 0.9948933361638173, 'support': 10182}
 
time = 19.11 secondes

Val loss 0.928568748897126 accuracy 0.8931095600128174 macro_avg {'precision': 0.8982822032106389, 'recall': 0.8981766485194049, 'f1-score': 0.8959304301923577, 'support': 1132} weighted_avg {'precision': 0.8985612422279412, 'recall': 0.8931095406360424, 'f1-score': 0.893578534819093, 'support': 1132}
 
----------
Epoch 32/40
time = 426.14 secondes

Train loss 0.03031601273644152 accuracy 0.9955804944038391 macro_avg {'precision': 0.9956526703773569, 'recall': 0.9956192163068474, 'f1-score': 0.9956308510196272, 'support': 10182} weighted_avg {'precision': 0.9955923657864651, 'recall': 0.9955804360636418, 'f1-score': 0.9955816018641301, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.9372132644599384 accuracy 0.8931095600128174 macro_avg {'precision': 0.8964893689554199, 'recall': 0.89573736338956, 'f1-score': 0.8943688593874313, 'support': 1132} weighted_avg {'precision': 0.8977879820445511, 'recall': 0.8931095406360424, 'f1-score': 0.8937944313855581, 'support': 1132}
 
----------
Epoch 33/40
time = 426.53 secondes

Train loss 0.020794112729821523 accuracy 0.9970536828041077 macro_avg {'precision': 0.9969938973186505, 'recall': 0.996896591190834, 'f1-score': 0.9969411129800451, 'support': 10182} weighted_avg {'precision': 0.9970589371310673, 'recall': 0.9970536240424278, 'f1-score': 0.9970524097307252, 'support': 10182}
 
time = 19.05 secondes

Val loss 0.9525722244173996 accuracy 0.8939929604530334 macro_avg {'precision': 0.8947483259208969, 'recall': 0.8993955605317782, 'f1-score': 0.8949880831938088, 'support': 1132} weighted_avg {'precision': 0.896809401415789, 'recall': 0.8939929328621908, 'f1-score': 0.893343097664538, 'support': 1132}
 
----------
Epoch 34/40
time = 426.06 secondes

Train loss 0.023359457895283563 accuracy 0.9959732890129089 macro_avg {'precision': 0.9954081142820677, 'recall': 0.9954159366010762, 'f1-score': 0.9954071659766685, 'support': 10182} weighted_avg {'precision': 0.9959858122666226, 'recall': 0.995973286191318, 'f1-score': 0.9959751356495137, 'support': 10182}
 
time = 19.03 secondes

Val loss 1.0343953092006801 accuracy 0.8922261595726013 macro_avg {'precision': 0.8952090813458018, 'recall': 0.893755825491543, 'f1-score': 0.8920311452597242, 'support': 1132} weighted_avg {'precision': 0.8989875218411926, 'recall': 0.892226148409894, 'f1-score': 0.8934443932821606, 'support': 1132}
 
----------
Epoch 35/40
time = 426.55 secondes

Train loss 0.021573402412605063 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970888024798121, 'recall': 0.9970510282145885, 'f1-score': 0.9970661744287529, 'support': 10182} weighted_avg {'precision': 0.9970610136668834, 'recall': 0.9970536240424278, 'f1-score': 0.9970535369876667, 'support': 10182}
 
time = 18.60 secondes

Val loss 0.9567452537322796 accuracy 0.8966431021690369 macro_avg {'precision': 0.9004785950170943, 'recall': 0.9006100464897806, 'f1-score': 0.8989713986024706, 'support': 1132} weighted_avg {'precision': 0.9002745750735334, 'recall': 0.8966431095406361, 'f1-score': 0.8967467148155048, 'support': 1132}
 
----------
Epoch 36/40
time = 426.96 secondes

Train loss 0.013004058093643361 accuracy 0.9978393316268921 macro_avg {'precision': 0.99788450120662, 'recall': 0.9978472585058231, 'f1-score': 0.9978635717040033, 'support': 10182} weighted_avg {'precision': 0.9978452671922962, 'recall': 0.9978393242977804, 'f1-score': 0.9978399501073051, 'support': 10182}
 
time = 19.01 secondes

Val loss 0.975105778936242 accuracy 0.8895759582519531 macro_avg {'precision': 0.8957427620760136, 'recall': 0.89515355161586, 'f1-score': 0.8938557757460595, 'support': 1132} weighted_avg {'precision': 0.8940092483359533, 'recall': 0.8895759717314488, 'f1-score': 0.8902290953256888, 'support': 1132}
 
----------
Epoch 37/40
time = 425.70 secondes

Train loss 0.00943229364545363 accuracy 0.9978393316268921 macro_avg {'precision': 0.9978402652714896, 'recall': 0.9977902738212254, 'f1-score': 0.9978138306914316, 'support': 10182} weighted_avg {'precision': 0.997841175262175, 'recall': 0.9978393242977804, 'f1-score': 0.997838813092588, 'support': 10182}
 
time = 19.07 secondes

Val loss 0.8825586544512781 accuracy 0.9028268456459045 macro_avg {'precision': 0.9066912895376058, 'recall': 0.9063720007865237, 'f1-score': 0.9053038847563236, 'support': 1132} weighted_avg {'precision': 0.9066068628639302, 'recall': 0.9028268551236749, 'f1-score': 0.9036168425523176, 'support': 1132}
 
----------
Epoch 38/40
time = 426.34 secondes

Train loss 0.008212427005386833 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985669614949311, 'recall': 0.9985539290336503, 'f1-score': 0.9985588856317591, 'support': 10182} weighted_avg {'precision': 0.9985314018322542, 'recall': 0.998526812021214, 'f1-score': 0.9985275159459209, 'support': 10182}
 
time = 18.90 secondes

Val loss 1.0047870648534845 accuracy 0.8957597017288208 macro_avg {'precision': 0.8989015172834132, 'recall': 0.8997662283043093, 'f1-score': 0.8977058688918685, 'support': 1132} weighted_avg {'precision': 0.8988992949578809, 'recall': 0.8957597173144877, 'f1-score': 0.8956337635069176, 'support': 1132}
 
----------
Epoch 39/40
time = 426.30 secondes

Train loss 0.004246219980333042 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990221364868519, 'recall': 0.9990014225863947, 'f1-score': 0.9990107862531905, 'support': 10182} weighted_avg {'precision': 0.9990199885757575, 'recall': 0.9990178746808093, 'f1-score': 0.9990179610584898, 'support': 10182}
 
time = 18.99 secondes

Val loss 0.9655810541983901 accuracy 0.8957597017288208 macro_avg {'precision': 0.8988581660235795, 'recall': 0.8995579643276101, 'f1-score': 0.8979800657565861, 'support': 1132} weighted_avg {'precision': 0.8972290555673637, 'recall': 0.8957597173144877, 'f1-score': 0.8952950919514423, 'support': 1132}
 
----------
Epoch 40/40
time = 426.85 secondes

Train loss 0.002261904084737764 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994090211675507, 'recall': 0.9993959958128634, 'f1-score': 0.9994018590493725, 'support': 10182} weighted_avg {'precision': 0.9994120259254384, 'recall': 0.9994107248084856, 'f1-score': 0.9994107138218524, 'support': 10182}
 
time = 19.03 secondes

Val loss 0.9742311146264142 accuracy 0.8992933034896851 macro_avg {'precision': 0.9021331399349644, 'recall': 0.9021143514647747, 'f1-score': 0.9011006422174637, 'support': 1132} weighted_avg {'precision': 0.9012405242466696, 'recall': 0.8992932862190812, 'f1-score': 0.8991827040177136, 'support': 1132}
 
----------
best_accuracy 0.9028268456459045 best_epoch 37 macro_avg {'precision': 0.9066912895376058, 'recall': 0.9063720007865237, 'f1-score': 0.9053038847563236, 'support': 1132} weighted_avg {'precision': 0.9066068628639302, 'recall': 0.9028268551236749, 'f1-score': 0.9036168425523176, 'support': 1132}

average train time 426.8266421914101

average val time 18.758907002210616
 
time = 119.87 secondes

test_accuracy 0.8300583958625793 macro_avg {'precision': 0.8303379544591627, 'recall': 0.8244955353573701, 'f1-score': 0.8240983181494551, 'support': 7532} weighted_avg {'precision': 0.8371012545924373, 'recall': 0.8300584174190122, 'f1-score': 0.83065317143114, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 73.33 GiB already allocated; 96.62 MiB free; 74.17 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 72.04 GiB already allocated; 318.62 MiB free; 73.95 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 79.21 GiB total capacity; 70.25 GiB already allocated; 566.62 MiB free; 73.71 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 72.00 GiB already allocated; 1006.62 MiB free; 73.28 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_2
----------
Epoch 1/40
time = 689.95 secondes

Train loss 1.0648636397097138 accuracy 0.7029070854187012 macro_avg {'precision': 0.7011784761765527, 'recall': 0.6888957237089472, 'f1-score': 0.6879746866403693, 'support': 10182} weighted_avg {'precision': 0.7121661622260655, 'recall': 0.7029070909448045, 'f1-score': 0.7011805198374493, 'support': 10182}
 
time = 28.53 secondes

Val loss 0.5944061526949976 accuracy 0.8286219239234924 macro_avg {'precision': 0.8403907593100776, 'recall': 0.8186808732339557, 'f1-score': 0.8071948192433973, 'support': 1132} weighted_avg {'precision': 0.8404758544124027, 'recall': 0.8286219081272085, 'f1-score': 0.817153755650542, 'support': 1132}
 
----------
Epoch 2/40
time = 677.25 secondes

Train loss 0.3923913303710041 accuracy 0.8847967386245728 macro_avg {'precision': 0.877454725507589, 'recall': 0.8759333221331561, 'f1-score': 0.8756781359873835, 'support': 10182} weighted_avg {'precision': 0.8837190345907199, 'recall': 0.8847967000589275, 'f1-score': 0.8834618651860512, 'support': 10182}
 
time = 27.89 secondes

Val loss 0.4297343905962689 accuracy 0.8878092169761658 macro_avg {'precision': 0.8909356644516613, 'recall': 0.8848946476291246, 'f1-score': 0.8832463885285147, 'support': 1132} weighted_avg {'precision': 0.893898221994255, 'recall': 0.8878091872791519, 'f1-score': 0.8863322997021555, 'support': 1132}
 
----------
Epoch 3/40
time = 676.24 secondes

Train loss 0.2255007883327687 accuracy 0.9363583326339722 macro_avg {'precision': 0.933138816466658, 'recall': 0.9326930439598973, 'f1-score': 0.9328081328954847, 'support': 10182} weighted_avg {'precision': 0.9367353408118962, 'recall': 0.9363582793164408, 'f1-score': 0.9364425072731885, 'support': 10182}
 
time = 27.41 secondes

Val loss 0.5017609025653399 accuracy 0.8851590156555176 macro_avg {'precision': 0.8909737334370218, 'recall': 0.8888125079406736, 'f1-score': 0.8838399785874144, 'support': 1132} weighted_avg {'precision': 0.8948380275214426, 'recall': 0.8851590106007067, 'f1-score': 0.8833920593582453, 'support': 1132}
 
----------
Epoch 4/40
time = 673.99 secondes

Train loss 0.17995120184729974 accuracy 0.9533490538597107 macro_avg {'precision': 0.9516245248484004, 'recall': 0.9513785199253764, 'f1-score': 0.9514563957108418, 'support': 10182} weighted_avg {'precision': 0.9534831099316328, 'recall': 0.9533490473384404, 'f1-score': 0.9533710863857153, 'support': 10182}
 
time = 27.57 secondes

Val loss 0.4457086962713322 accuracy 0.9072438478469849 macro_avg {'precision': 0.909498653620432, 'recall': 0.910128074030822, 'f1-score': 0.9078904178832925, 'support': 1132} weighted_avg {'precision': 0.9129032598469732, 'recall': 0.907243816254417, 'f1-score': 0.9081906706552095, 'support': 1132}
 
----------
Epoch 5/40
time = 689.29 secondes

Train loss 0.15065501185698402 accuracy 0.9607149958610535 macro_avg {'precision': 0.9595333950135109, 'recall': 0.9596436360531433, 'f1-score': 0.9595368717240443, 'support': 10182} weighted_avg {'precision': 0.960944530747199, 'recall': 0.9607149872323708, 'f1-score': 0.9607822916595203, 'support': 10182}
 
time = 27.97 secondes

Val loss 0.6421103626096123 accuracy 0.8851590156555176 macro_avg {'precision': 0.895872338532358, 'recall': 0.8889142262372818, 'f1-score': 0.8880039947460097, 'support': 1132} weighted_avg {'precision': 0.895581227081082, 'recall': 0.8851590106007067, 'f1-score': 0.8856563794965019, 'support': 1132}
 
----------
Epoch 6/40
time = 678.99 secondes

Train loss 0.1337366630575434 accuracy 0.967197060585022 macro_avg {'precision': 0.9665892639759651, 'recall': 0.9663698522952842, 'f1-score': 0.9664557137904515, 'support': 10182} weighted_avg {'precision': 0.9672817479885735, 'recall': 0.9671970143390297, 'f1-score': 0.9672149366987187, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.5651973541727631 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116147655684672, 'recall': 0.904817486523457, 'f1-score': 0.9054242887139864, 'support': 1132} weighted_avg {'precision': 0.9106131943346604, 'recall': 0.9054770318021201, 'f1-score': 0.9053814872378658, 'support': 1132}
 
----------
Epoch 7/40
time = 678.40 secondes

Train loss 0.12546591963447204 accuracy 0.9707326889038086 macro_avg {'precision': 0.9696318573163593, 'recall': 0.9695742465791491, 'f1-score': 0.9695722468076766, 'support': 10182} weighted_avg {'precision': 0.9708045650273542, 'recall': 0.9707326654881163, 'f1-score': 0.9707373293961113, 'support': 10182}
 
time = 28.53 secondes

Val loss 0.6232601411367642 accuracy 0.8966431021690369 macro_avg {'precision': 0.9021039660937387, 'recall': 0.894391623778378, 'f1-score': 0.893286647378495, 'support': 1132} weighted_avg {'precision': 0.9008673021644747, 'recall': 0.8966431095406361, 'f1-score': 0.8941434372795116, 'support': 1132}
 
----------
Epoch 8/40
time = 679.09 secondes

Train loss 0.11500833312890549 accuracy 0.9745630025863647 macro_avg {'precision': 0.973758158455278, 'recall': 0.973649932534628, 'f1-score': 0.9736499692689463, 'support': 10182} weighted_avg {'precision': 0.9746880956584338, 'recall': 0.9745629542329601, 'f1-score': 0.9745712249859729, 'support': 10182}
 
time = 28.09 secondes

Val loss 0.6538066652412428 accuracy 0.898409903049469 macro_avg {'precision': 0.9032010245856963, 'recall': 0.8997767358236033, 'f1-score': 0.8984549679001969, 'support': 1132} weighted_avg {'precision': 0.9040950382000954, 'recall': 0.8984098939929329, 'f1-score': 0.8980228872442687, 'support': 1132}
 
----------
Epoch 9/40
time = 679.34 secondes

Train loss 0.10809380609274029 accuracy 0.9760361909866333 macro_avg {'precision': 0.975400321638985, 'recall': 0.9755657325093239, 'f1-score': 0.9754542131920158, 'support': 10182} weighted_avg {'precision': 0.9760641591229584, 'recall': 0.9760361422117462, 'f1-score': 0.9760245665542596, 'support': 10182}
 
time = 28.55 secondes

Val loss 0.6726221283487844 accuracy 0.8992933034896851 macro_avg {'precision': 0.9029044320051683, 'recall': 0.9007506457614015, 'f1-score': 0.8987814054334148, 'support': 1132} weighted_avg {'precision': 0.9051025635811462, 'recall': 0.8992932862190812, 'f1-score': 0.8990838639239018, 'support': 1132}
 
----------
Epoch 10/40
time = 677.53 secondes

Train loss 0.11171707793383266 accuracy 0.9760361909866333 macro_avg {'precision': 0.9756776069172026, 'recall': 0.9756097349852386, 'f1-score': 0.9756210926614284, 'support': 10182} weighted_avg {'precision': 0.9760461309532492, 'recall': 0.9760361422117462, 'f1-score': 0.9760185231057372, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.485126080717006 accuracy 0.9249116778373718 macro_avg {'precision': 0.9252584585473258, 'recall': 0.9260725503120598, 'f1-score': 0.9251255648610066, 'support': 1132} weighted_avg {'precision': 0.9263473335376424, 'recall': 0.9249116607773852, 'f1-score': 0.9251312912208374, 'support': 1132}
 
----------
Epoch 11/40
time = 678.55 secondes

Train loss 0.09127712438789122 accuracy 0.980553925037384 macro_avg {'precision': 0.9799932209349818, 'recall': 0.980105403852526, 'f1-score': 0.9800316880361202, 'support': 10182} weighted_avg {'precision': 0.9806075006246813, 'recall': 0.9805539186800236, 'f1-score': 0.980563519280867, 'support': 10182}
 
time = 28.42 secondes

Val loss 0.7193589428979592 accuracy 0.898409903049469 macro_avg {'precision': 0.9068626300279703, 'recall': 0.9027874791642757, 'f1-score': 0.9003866197464004, 'support': 1132} weighted_avg {'precision': 0.9057758988416492, 'recall': 0.8984098939929329, 'f1-score': 0.8970528256072564, 'support': 1132}
 
----------
Epoch 12/40
time = 679.06 secondes

Train loss 0.0939806016084184 accuracy 0.980455756187439 macro_avg {'precision': 0.9800643102496144, 'recall': 0.9799538088668204, 'f1-score': 0.9799920196171458, 'support': 10182} weighted_avg {'precision': 0.9804969063462616, 'recall': 0.9804557061481045, 'f1-score': 0.9804589140933532, 'support': 10182}
 
time = 23.16 secondes

Val loss 0.7151397453142662 accuracy 0.9090105891227722 macro_avg {'precision': 0.9127627041418942, 'recall': 0.9120094859399834, 'f1-score': 0.909514057215068, 'support': 1132} weighted_avg {'precision': 0.9167135913667567, 'recall': 0.9090106007067138, 'f1-score': 0.909807654306905, 'support': 1132}
 
----------
Epoch 13/40
time = 679.56 secondes

Train loss 0.09801928723980988 accuracy 0.9810450077056885 macro_avg {'precision': 0.9810174748292406, 'recall': 0.9808918955668622, 'f1-score': 0.9809366020900911, 'support': 10182} weighted_avg {'precision': 0.9811085157326482, 'recall': 0.9810449813396189, 'f1-score': 0.9810582562885013, 'support': 10182}
 
time = 28.23 secondes

Val loss 0.6729797816127834 accuracy 0.9196113348007202 macro_avg {'precision': 0.9269560780298993, 'recall': 0.9166600547167937, 'f1-score': 0.9184911168744717, 'support': 1132} weighted_avg {'precision': 0.92628146411116, 'recall': 0.9196113074204947, 'f1-score': 0.9199546684598544, 'support': 1132}
 
----------
Epoch 14/40
time = 679.82 secondes

Train loss 0.08948837547288471 accuracy 0.9834021329879761 macro_avg {'precision': 0.9831847455740415, 'recall': 0.9829615180323934, 'f1-score': 0.9830576254866564, 'support': 10182} weighted_avg {'precision': 0.9834211065490392, 'recall': 0.9834020821056767, 'f1-score': 0.9833964902264297, 'support': 10182}
 
time = 28.09 secondes

Val loss 0.6134303797139502 accuracy 0.916961133480072 macro_avg {'precision': 0.9161903029460159, 'recall': 0.9190987813372891, 'f1-score': 0.9167080890199457, 'support': 1132} weighted_avg {'precision': 0.9175305009728836, 'recall': 0.9169611307420494, 'f1-score': 0.9163374633281215, 'support': 1132}
 
----------
Epoch 15/40
time = 680.56 secondes

Train loss 0.09384367837376384 accuracy 0.9824199676513672 macro_avg {'precision': 0.9824325277099109, 'recall': 0.9821987255545837, 'f1-score': 0.9822826364043793, 'support': 10182} weighted_avg {'precision': 0.982481410794599, 'recall': 0.982419956786486, 'f1-score': 0.9824169331041297, 'support': 10182}
 
time = 28.39 secondes

Val loss 0.7773786429367044 accuracy 0.9010601043701172 macro_avg {'precision': 0.9070996720907416, 'recall': 0.9027617683669646, 'f1-score': 0.9019056628313932, 'support': 1132} weighted_avg {'precision': 0.9076476162133977, 'recall': 0.901060070671378, 'f1-score': 0.9012523598327445, 'support': 1132}
 
----------
Epoch 16/40
time = 678.19 secondes

Train loss 0.0794803458437522 accuracy 0.9843842387199402 macro_avg {'precision': 0.9840698632856976, 'recall': 0.9839957545366744, 'f1-score': 0.9840204080896104, 'support': 10182} weighted_avg {'precision': 0.984414334987115, 'recall': 0.9843842074248674, 'f1-score': 0.9843879041347853, 'support': 10182}
 
time = 27.96 secondes

Val loss 0.6479874177770091 accuracy 0.9090105891227722 macro_avg {'precision': 0.9168563410713227, 'recall': 0.9104937269765617, 'f1-score': 0.9112369452767094, 'support': 1132} weighted_avg {'precision': 0.9167337549316272, 'recall': 0.9090106007067138, 'f1-score': 0.9103752927085841, 'support': 1132}
 
----------
Epoch 17/40
time = 677.32 secondes

Train loss 0.07316496025141904 accuracy 0.9861520528793335 macro_avg {'precision': 0.9856568949372502, 'recall': 0.9855399548737287, 'f1-score': 0.9855872940019854, 'support': 10182} weighted_avg {'precision': 0.9861396678936386, 'recall': 0.9861520329994107, 'f1-score': 0.9861353977023423, 'support': 10182}
 
time = 28.12 secondes

Val loss 0.7175711176101353 accuracy 0.9072438478469849 macro_avg {'precision': 0.9121688953437485, 'recall': 0.9092541353176016, 'f1-score': 0.9089475128843784, 'support': 1132} weighted_avg {'precision': 0.9111644581259689, 'recall': 0.907243816254417, 'f1-score': 0.9072473211806718, 'support': 1132}
 
----------
Epoch 18/40
time = 677.14 secondes

Train loss 0.0652009693033076 accuracy 0.987625241279602 macro_avg {'precision': 0.9872784287845591, 'recall': 0.987135461380318, 'f1-score': 0.9872012210392151, 'support': 10182} weighted_avg {'precision': 0.9876240345073292, 'recall': 0.9876252209781968, 'f1-score': 0.9876194507955603, 'support': 10182}
 
time = 28.11 secondes

Val loss 0.671513566831545 accuracy 0.9090105891227722 macro_avg {'precision': 0.9119657952212534, 'recall': 0.9106435889312555, 'f1-score': 0.9103550007153313, 'support': 1132} weighted_avg {'precision': 0.9126961901842592, 'recall': 0.9090106007067138, 'f1-score': 0.9098745452508873, 'support': 1132}
 
----------
Epoch 19/40
time = 679.41 secondes

Train loss 0.05456547916037951 accuracy 0.9891966581344604 macro_avg {'precision': 0.9883782808742471, 'recall': 0.9882126761245038, 'f1-score': 0.9882759313943449, 'support': 10182} weighted_avg {'precision': 0.9892325569183982, 'recall': 0.989196621488902, 'f1-score': 0.9891950307811724, 'support': 10182}
 
time = 28.18 secondes

Val loss 0.7175183505029745 accuracy 0.9116607904434204 macro_avg {'precision': 0.9207975104580701, 'recall': 0.9104174267336314, 'f1-score': 0.9128947360655755, 'support': 1132} weighted_avg {'precision': 0.9166067395961752, 'recall': 0.911660777385159, 'f1-score': 0.9114610332492935, 'support': 1132}
 
----------
Epoch 20/40
time = 678.11 secondes

Train loss 0.061901185965602554 accuracy 0.9886073470115662 macro_avg {'precision': 0.9878116135560602, 'recall': 0.988198287759616, 'f1-score': 0.9879907636080537, 'support': 10182} weighted_avg {'precision': 0.9886366000265374, 'recall': 0.9886073462973876, 'f1-score': 0.9886098636313682, 'support': 10182}
 
time = 28.12 secondes

Val loss 0.7314097603575903 accuracy 0.9134275913238525 macro_avg {'precision': 0.9165785422906332, 'recall': 0.914084455785123, 'f1-score': 0.9134136170958549, 'support': 1132} weighted_avg {'precision': 0.9175154753961594, 'recall': 0.9134275618374559, 'f1-score': 0.9136807591034821, 'support': 1132}
 
----------
Epoch 21/40
time = 678.41 secondes

Train loss 0.054353855628257265 accuracy 0.9901787638664246 macro_avg {'precision': 0.9902167678123119, 'recall': 0.9900944830009666, 'f1-score': 0.9901493505434024, 'support': 10182} weighted_avg {'precision': 0.990209054354457, 'recall': 0.9901787468080927, 'f1-score': 0.9901876240100392, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.7552122951251157 accuracy 0.9107773900032043 macro_avg {'precision': 0.9151794567853528, 'recall': 0.9126758780971997, 'f1-score': 0.9124130286287138, 'support': 1132} weighted_avg {'precision': 0.9145444333957059, 'recall': 0.9107773851590106, 'f1-score': 0.911090971022533, 'support': 1132}
 
----------
Epoch 22/40
time = 678.24 secondes

Train loss 0.06367194060062552 accuracy 0.9885091781616211 macro_avg {'precision': 0.9881704399847117, 'recall': 0.9887012992476301, 'f1-score': 0.9884043603327125, 'support': 10182} weighted_avg {'precision': 0.9885764333643812, 'recall': 0.9885091337654685, 'f1-score': 0.9885165405984639, 'support': 10182}
 
time = 28.06 secondes

Val loss 0.7499723480136132 accuracy 0.9090105891227722 macro_avg {'precision': 0.9144878621063801, 'recall': 0.9101998245341486, 'f1-score': 0.9110239183653311, 'support': 1132} weighted_avg {'precision': 0.914760241818829, 'recall': 0.9090106007067138, 'f1-score': 0.9105367570179281, 'support': 1132}
 
----------
Epoch 23/40
time = 598.82 secondes

Train loss 0.057264648153911225 accuracy 0.9893930554389954 macro_avg {'precision': 0.9892617955095802, 'recall': 0.9892371328300756, 'f1-score': 0.98923164950552, 'support': 10182} weighted_avg {'precision': 0.9894201361354653, 'recall': 0.9893930465527401, 'f1-score': 0.9893883881956556, 'support': 10182}
 
time = 18.15 secondes

Val loss 0.6979011791067741 accuracy 0.9151943325996399 macro_avg {'precision': 0.9187930909483898, 'recall': 0.9163989579631366, 'f1-score': 0.9165672392602744, 'support': 1132} weighted_avg {'precision': 0.9179966024329519, 'recall': 0.9151943462897526, 'f1-score': 0.9156264149995865, 'support': 1132}
 
----------
Epoch 24/40
time = 574.65 secondes

Train loss 0.06842237078276833 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881245546604356, 'recall': 0.9880673993935414, 'f1-score': 0.9880861580429035, 'support': 10182} weighted_avg {'precision': 0.988613820692359, 'recall': 0.9886073462973876, 'f1-score': 0.9886011962789569, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.6583629628379205 accuracy 0.9213780760765076 macro_avg {'precision': 0.92438288472696, 'recall': 0.923571676603893, 'f1-score': 0.9226161194956868, 'support': 1132} weighted_avg {'precision': 0.9250527394457707, 'recall': 0.9213780918727915, 'f1-score': 0.9218703299897453, 'support': 1132}
 
----------
Epoch 25/40
time = 576.80 secondes

Train loss 0.04682012442327152 accuracy 0.9907680749893188 macro_avg {'precision': 0.9904557747334405, 'recall': 0.99069437021588, 'f1-score': 0.9905557911209696, 'support': 10182} weighted_avg {'precision': 0.9907991986413701, 'recall': 0.9907680219996071, 'f1-score': 0.9907676518331444, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.7499318534053754 accuracy 0.9054770469665527 macro_avg {'precision': 0.9107943377269606, 'recall': 0.9104876273653311, 'f1-score': 0.9087806282479794, 'support': 1132} weighted_avg {'precision': 0.9106039692109619, 'recall': 0.9054770318021201, 'f1-score': 0.9060365700564128, 'support': 1132}
 
----------
Epoch 26/40
time = 576.24 secondes

Train loss 0.049328991466175254 accuracy 0.9916519522666931 macro_avg {'precision': 0.9915544187438023, 'recall': 0.9916841768447119, 'f1-score': 0.9916118877150826, 'support': 10182} weighted_avg {'precision': 0.9916624714597965, 'recall': 0.9916519347868789, 'f1-score': 0.991649786030057, 'support': 10182}
 
time = 22.96 secondes

Val loss 0.8515955820309923 accuracy 0.8975265026092529 macro_avg {'precision': 0.9064868883018239, 'recall': 0.9000609254082208, 'f1-score': 0.9001858368013623, 'support': 1132} weighted_avg {'precision': 0.9052772179663046, 'recall': 0.8975265017667845, 'f1-score': 0.8983094457610403, 'support': 1132}
 
----------
Epoch 27/40
time = 574.81 secondes

Train loss 0.0517714156308295 accuracy 0.9915537238121033 macro_avg {'precision': 0.9918519347454744, 'recall': 0.9917350403386134, 'f1-score': 0.9917651499271317, 'support': 10182} weighted_avg {'precision': 0.9915897922866741, 'recall': 0.9915537222549597, 'f1-score': 0.9915426037377291, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.7531595680968525 accuracy 0.9125441908836365 macro_avg {'precision': 0.9165873859019051, 'recall': 0.9152243949746133, 'f1-score': 0.9146677106405955, 'support': 1132} weighted_avg {'precision': 0.9148699350497063, 'recall': 0.9125441696113075, 'f1-score': 0.9124470772160663, 'support': 1132}
 
----------
Epoch 28/40
time = 577.18 secondes

Train loss 0.03385872828021293 accuracy 0.9928305149078369 macro_avg {'precision': 0.9927954076106676, 'recall': 0.9928954843034207, 'f1-score': 0.9928358280154217, 'support': 10182} weighted_avg {'precision': 0.992842080719854, 'recall': 0.9928304851699077, 'f1-score': 0.9928265244558131, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.6918095506137011 accuracy 0.9116607904434204 macro_avg {'precision': 0.9160674583712719, 'recall': 0.9154466700171012, 'f1-score': 0.9134833935275696, 'support': 1132} weighted_avg {'precision': 0.9199854213242903, 'recall': 0.911660777385159, 'f1-score': 0.9136399354766995, 'support': 1132}
 
----------
Epoch 29/40
time = 577.02 secondes

Train loss 0.03569428820578415 accuracy 0.993812620639801 macro_avg {'precision': 0.9936287490232351, 'recall': 0.9937711249122412, 'f1-score': 0.9936896486194214, 'support': 10182} weighted_avg {'precision': 0.9938391743543115, 'recall': 0.9938126104890984, 'f1-score': 0.9938157320479074, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.6827330803659004 accuracy 0.9196113348007202 macro_avg {'precision': 0.9218130209833028, 'recall': 0.9208911977723917, 'f1-score': 0.9209537619215027, 'support': 1132} weighted_avg {'precision': 0.92036793932817, 'recall': 0.9196113074204947, 'f1-score': 0.919574893574247, 'support': 1132}
 
----------
Epoch 30/40
time = 577.40 secondes

Train loss 0.022579545892580745 accuracy 0.9949911832809448 macro_avg {'precision': 0.9948492663055737, 'recall': 0.9947488784095002, 'f1-score': 0.9947918675325086, 'support': 10182} weighted_avg {'precision': 0.9950017729960694, 'recall': 0.9949911608721272, 'f1-score': 0.9949894387110673, 'support': 10182}
 
time = 22.26 secondes

Val loss 0.7605256792997698 accuracy 0.9134275913238525 macro_avg {'precision': 0.9194234218743714, 'recall': 0.9155627053289278, 'f1-score': 0.9161893842714568, 'support': 1132} weighted_avg {'precision': 0.9177389612457473, 'recall': 0.9134275618374559, 'f1-score': 0.9141122293935133, 'support': 1132}
 
----------
Epoch 31/40
time = 576.78 secondes

Train loss 0.029525759259922207 accuracy 0.994892954826355 macro_avg {'precision': 0.9947463470090296, 'recall': 0.9943300293789628, 'f1-score': 0.9945247110562472, 'support': 10182} weighted_avg {'precision': 0.9949231203033001, 'recall': 0.9948929483402082, 'f1-score': 0.99489662381005, 'support': 10182}
 
time = 23.40 secondes

Val loss 0.7419200460825149 accuracy 0.9116607904434204 macro_avg {'precision': 0.9136073479969417, 'recall': 0.9162135166465217, 'f1-score': 0.9128714398363199, 'support': 1132} weighted_avg {'precision': 0.918781776346413, 'recall': 0.911660777385159, 'f1-score': 0.9132602131443638, 'support': 1132}
 
----------
Epoch 32/40
time = 576.88 secondes

Train loss 0.022615470910005146 accuracy 0.9955804944038391 macro_avg {'precision': 0.995469066247146, 'recall': 0.9954943440664161, 'f1-score': 0.9954737855479916, 'support': 10182} weighted_avg {'precision': 0.9955974776883576, 'recall': 0.9955804360636418, 'f1-score': 0.9955808550752876, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.749269838988997 accuracy 0.916077733039856 macro_avg {'precision': 0.9218911028959157, 'recall': 0.9190524191973302, 'f1-score': 0.9186425283983484, 'support': 1132} weighted_avg {'precision': 0.920088842107591, 'recall': 0.916077738515901, 'f1-score': 0.916004658256601, 'support': 1132}
 
----------
Epoch 33/40
time = 573.78 secondes

Train loss 0.020340808968320967 accuracy 0.9964643716812134 macro_avg {'precision': 0.9962979677260769, 'recall': 0.9964143039826234, 'f1-score': 0.9963505360481051, 'support': 10182} weighted_avg {'precision': 0.9964739609311525, 'recall': 0.9964643488509134, 'f1-score': 0.996463512016655, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.7350900558177131 accuracy 0.9151943325996399 macro_avg {'precision': 0.9173868902975506, 'recall': 0.9184319382602221, 'f1-score': 0.9167857741785653, 'support': 1132} weighted_avg {'precision': 0.9188815067745779, 'recall': 0.9151943462897526, 'f1-score': 0.9158744417952057, 'support': 1132}
 
----------
Epoch 34/40
time = 573.36 secondes

Train loss 0.018005855267143756 accuracy 0.9967589974403381 macro_avg {'precision': 0.996662991865884, 'recall': 0.996653305017527, 'f1-score': 0.996654236410986, 'support': 10182} weighted_avg {'precision': 0.996766945749664, 'recall': 0.9967589864466706, 'f1-score': 0.9967589964265415, 'support': 10182}
 
time = 23.05 secondes

Val loss 0.6948523349332851 accuracy 0.9213780760765076 macro_avg {'precision': 0.9245932861159808, 'recall': 0.9231347453012134, 'f1-score': 0.9228615229151028, 'support': 1132} weighted_avg {'precision': 0.9241203363915182, 'recall': 0.9213780918727915, 'f1-score': 0.9216643881932206, 'support': 1132}
 
----------
Epoch 35/40
time = 574.28 secondes

Train loss 0.019400686105846363 accuracy 0.996857225894928 macro_avg {'precision': 0.9969005178972148, 'recall': 0.9969189837602285, 'f1-score': 0.9969063192880212, 'support': 10182} weighted_avg {'precision': 0.9968620158702369, 'recall': 0.9968571989785897, 'f1-score': 0.9968560293057103, 'support': 10182}
 
time = 21.07 secondes

Val loss 0.768560814370624 accuracy 0.9178445339202881 macro_avg {'precision': 0.9222224806867949, 'recall': 0.9213830633684484, 'f1-score': 0.9200304014936066, 'support': 1132} weighted_avg {'precision': 0.9228816731810083, 'recall': 0.9178445229681979, 'f1-score': 0.9184570557562751, 'support': 1132}
 
----------
Epoch 36/40
time = 572.79 secondes

Train loss 0.01697044402216459 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970103294425551, 'recall': 0.9971215238079795, 'f1-score': 0.9970602387599368, 'support': 10182} weighted_avg {'precision': 0.9970671984370202, 'recall': 0.9970536240424278, 'f1-score': 0.9970546681820002, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.6933600196535082 accuracy 0.9204947352409363 macro_avg {'precision': 0.9265402753374626, 'recall': 0.9229979630426384, 'f1-score': 0.9234658813627477, 'support': 1132} weighted_avg {'precision': 0.9240388138493385, 'recall': 0.9204946996466431, 'f1-score': 0.9208837140847499, 'support': 1132}
 
----------
Epoch 37/40
time = 574.16 secondes

Train loss 0.01202016773688337 accuracy 0.9980357885360718 macro_avg {'precision': 0.9980353719856687, 'recall': 0.9980368880127314, 'f1-score': 0.9980339570244509, 'support': 10182} weighted_avg {'precision': 0.99803801368565, 'recall': 0.9980357493616185, 'f1-score': 0.9980346858907279, 'support': 10182}
 
time = 22.06 secondes

Val loss 0.6790642933365362 accuracy 0.9231448769569397 macro_avg {'precision': 0.9271279095113709, 'recall': 0.9256551001819895, 'f1-score': 0.9255013641597433, 'support': 1132} weighted_avg {'precision': 0.925610220379282, 'recall': 0.9231448763250883, 'f1-score': 0.9234237070167496, 'support': 1132}
 
----------
Epoch 38/40
time = 575.07 secondes

Train loss 0.006404565581446723 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986649182664651, 'recall': 0.9986675968291501, 'f1-score': 0.9986660723923491, 'support': 10182} weighted_avg {'precision': 0.9986250181387363, 'recall': 0.998625024553133, 'f1-score': 0.998624832783119, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.7174773767153607 accuracy 0.9196113348007202 macro_avg {'precision': 0.9249212056455465, 'recall': 0.9216959150327162, 'f1-score': 0.9224262241490784, 'support': 1132} weighted_avg {'precision': 0.9225727238910092, 'recall': 0.9196113074204947, 'f1-score': 0.9201292126106125, 'support': 1132}
 
----------
Epoch 39/40
time = 577.44 secondes

Train loss 0.006736417593616591 accuracy 0.9987232685089111 macro_avg {'precision': 0.9987730511221006, 'recall': 0.9987300913460364, 'f1-score': 0.9987507130267858, 'support': 10182} weighted_avg {'precision': 0.9987249203018544, 'recall': 0.9987232370850521, 'f1-score': 0.9987232196014509, 'support': 10182}
 
time = 23.12 secondes

Val loss 0.7458333123439984 accuracy 0.9196113348007202 macro_avg {'precision': 0.9229628382901852, 'recall': 0.9212910922538431, 'f1-score': 0.9211198424990619, 'support': 1132} weighted_avg {'precision': 0.9216257294515989, 'recall': 0.9196113074204947, 'f1-score': 0.9195337970123669, 'support': 1132}
 
----------
Epoch 40/40
time = 573.91 secondes

Train loss 0.0030785780706367575 accuracy 0.9994107484817505 macro_avg {'precision': 0.999434812358697, 'recall': 0.9994288822000879, 'f1-score': 0.9994313963298971, 'support': 10182} weighted_avg {'precision': 0.9994114594094216, 'recall': 0.9994107248084856, 'f1-score': 0.9994106262127407, 'support': 10182}
 
time = 22.81 secondes

Val loss 0.7324529361520702 accuracy 0.9187279343605042 macro_avg {'precision': 0.9240401268485614, 'recall': 0.9199129295574571, 'f1-score': 0.9208257644681387, 'support': 1132} weighted_avg {'precision': 0.921774326295631, 'recall': 0.9187279151943463, 'f1-score': 0.9190190839288818, 'support': 1132}
 
----------
best_accuracy 0.9249116778373718 best_epoch 10 macro_avg {'precision': 0.9252584585473258, 'recall': 0.9260725503120598, 'f1-score': 0.9251255648610066, 'support': 1132} weighted_avg {'precision': 0.9263473335376424, 'recall': 0.9249116607773852, 'f1-score': 0.9251312912208374, 'support': 1132}

average train time 633.1461006164551

average val time 25.49382752776146
 
time = 149.97 secondes

test_accuracy 0.8469197750091553 macro_avg {'precision': 0.8459519244672362, 'recall': 0.8408163362472422, 'f1-score': 0.8406223261245171, 'support': 7532} weighted_avg {'precision': 0.8527882872613329, 'recall': 0.8469198088157196, 'f1-score': 0.8475454026582592, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_2
----------
Epoch 1/40
time = 752.61 secondes

Train loss 1.0864784701067949 accuracy 0.6898448467254639 macro_avg {'precision': 0.688709638746441, 'recall': 0.6757629256844186, 'f1-score': 0.6723254043802215, 'support': 10182} weighted_avg {'precision': 0.6961512613496823, 'recall': 0.6898448241995678, 'f1-score': 0.6848255101616522, 'support': 10182}
 
time = 27.18 secondes

Val loss 0.5516903954492488 accuracy 0.8401060104370117 macro_avg {'precision': 0.8602963372117568, 'recall': 0.8301542514879177, 'f1-score': 0.8177621073096436, 'support': 1132} weighted_avg {'precision': 0.8529001544701343, 'recall': 0.8401060070671378, 'f1-score': 0.8260151045849802, 'support': 1132}
 
----------
Epoch 2/40
time = 741.28 secondes

Train loss 0.38870213574655293 accuracy 0.8860734701156616 macro_avg {'precision': 0.878744130257, 'recall': 0.8776528171193027, 'f1-score': 0.8775222691559875, 'support': 10182} weighted_avg {'precision': 0.8847692488414601, 'recall': 0.8860734629738755, 'f1-score': 0.8848926752878391, 'support': 10182}
 
time = 26.54 secondes

Val loss 0.4479339871503098 accuracy 0.879858672618866 macro_avg {'precision': 0.8838666850911634, 'recall': 0.877483730786801, 'f1-score': 0.8729286441187991, 'support': 1132} weighted_avg {'precision': 0.8837110663469817, 'recall': 0.8798586572438163, 'f1-score': 0.8741908073346033, 'support': 1132}
 
----------
Epoch 3/40
time = 738.28 secondes

Train loss 0.23009972864823355 accuracy 0.9365547299385071 macro_avg {'precision': 0.9334939704535842, 'recall': 0.9332707371575678, 'f1-score': 0.9332305028704431, 'support': 10182} weighted_avg {'precision': 0.9367047811888429, 'recall': 0.9365547043802789, 'f1-score': 0.9364860519317351, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.5927967406402697 accuracy 0.8727915287017822 macro_avg {'precision': 0.8757679926746809, 'recall': 0.8739917032682285, 'f1-score': 0.8704150977701992, 'support': 1132} weighted_avg {'precision': 0.8812959875857554, 'recall': 0.872791519434629, 'f1-score': 0.8720450444525198, 'support': 1132}
 
----------
Epoch 4/40
time = 738.95 secondes

Train loss 0.1929792137845789 accuracy 0.9498134255409241 macro_avg {'precision': 0.9483548167022727, 'recall': 0.9477762859636124, 'f1-score': 0.9480004289110591, 'support': 10182} weighted_avg {'precision': 0.9498167301608033, 'recall': 0.9498133961893538, 'f1-score': 0.949752606036593, 'support': 10182}
 
time = 26.37 secondes

Val loss 0.47181424146360706 accuracy 0.9054770469665527 macro_avg {'precision': 0.907260821950415, 'recall': 0.9015793086885786, 'f1-score': 0.9030195438776001, 'support': 1132} weighted_avg {'precision': 0.9077826818610277, 'recall': 0.9054770318021201, 'f1-score': 0.9053163187710142, 'support': 1132}
 
----------
Epoch 5/40
time = 739.24 secondes

Train loss 0.16577308091519216 accuracy 0.9604203701019287 macro_avg {'precision': 0.9595127278581407, 'recall': 0.9590746674613702, 'f1-score': 0.9592131523088578, 'support': 10182} weighted_avg {'precision': 0.9606249928331574, 'recall': 0.9604203496366136, 'f1-score': 0.9604405941677476, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.5521321361917267 accuracy 0.8957597017288208 macro_avg {'precision': 0.9045827990693514, 'recall': 0.8934755375325713, 'f1-score': 0.8956907579555772, 'support': 1132} weighted_avg {'precision': 0.9024105487863646, 'recall': 0.8957597173144877, 'f1-score': 0.8958663440840913, 'support': 1132}
 
----------
Epoch 6/40
time = 739.07 secondes

Train loss 0.16285113811553595 accuracy 0.9611078500747681 macro_avg {'precision': 0.9596491672662113, 'recall': 0.9597758391191364, 'f1-score': 0.9596591181969254, 'support': 10182} weighted_avg {'precision': 0.9612975122935965, 'recall': 0.9611078373600471, 'f1-score': 0.9611573115914399, 'support': 10182}
 
time = 21.66 secondes

Val loss 0.6608560504121247 accuracy 0.8922261595726013 macro_avg {'precision': 0.9022586792211623, 'recall': 0.8900645312441269, 'f1-score': 0.8920941824406908, 'support': 1132} weighted_avg {'precision': 0.9016503100283775, 'recall': 0.892226148409894, 'f1-score': 0.8928749484429125, 'support': 1132}
 
----------
Epoch 7/40
time = 739.20 secondes

Train loss 0.13606278022226337 accuracy 0.9700452089309692 macro_avg {'precision': 0.9685610768840821, 'recall': 0.9687084522047641, 'f1-score': 0.9685713497414117, 'support': 10182} weighted_avg {'precision': 0.9702731252577695, 'recall': 0.9700451777646828, 'f1-score': 0.970102839183492, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6909955107552839 accuracy 0.8957597017288208 macro_avg {'precision': 0.9046949006706807, 'recall': 0.8964246931939244, 'f1-score': 0.8974611968994581, 'support': 1132} weighted_avg {'precision': 0.902108206001251, 'recall': 0.8957597173144877, 'f1-score': 0.8956796121842594, 'support': 1132}
 
----------
Epoch 8/40
time = 737.12 secondes

Train loss 0.13098238633866635 accuracy 0.972304105758667 macro_avg {'precision': 0.9716171905482854, 'recall': 0.9716222614254333, 'f1-score': 0.9715636039422171, 'support': 10182} weighted_avg {'precision': 0.9724909522715653, 'recall': 0.9723040659988215, 'f1-score': 0.9723435438191882, 'support': 10182}
 
time = 26.46 secondes

Val loss 0.5717095155088546 accuracy 0.9143109321594238 macro_avg {'precision': 0.918106180204958, 'recall': 0.9165550082134937, 'f1-score': 0.9153714908498192, 'support': 1132} weighted_avg {'precision': 0.9183570890429122, 'recall': 0.9143109540636042, 'f1-score': 0.9141911016892242, 'support': 1132}
 
----------
Epoch 9/40
time = 738.73 secondes

Train loss 0.12698343873306892 accuracy 0.9722058773040771 macro_avg {'precision': 0.9712853397620588, 'recall': 0.9711904520727803, 'f1-score': 0.9712081141996333, 'support': 10182} weighted_avg {'precision': 0.9722633591664649, 'recall': 0.9722058534669024, 'f1-score': 0.9722069467902626, 'support': 10182}
 
time = 26.47 secondes

Val loss 0.6018765576451879 accuracy 0.9090105891227722 macro_avg {'precision': 0.9142349754802298, 'recall': 0.9084778561477576, 'f1-score': 0.90986360458337, 'support': 1132} weighted_avg {'precision': 0.912624092716338, 'recall': 0.9090106007067138, 'f1-score': 0.909130456677194, 'support': 1132}
 
----------
Epoch 10/40
time = 737.00 secondes

Train loss 0.1263305998043712 accuracy 0.9755451083183289 macro_avg {'precision': 0.9753353703668705, 'recall': 0.9756025355400662, 'f1-score': 0.9754431406784377, 'support': 10182} weighted_avg {'precision': 0.9755816094253635, 'recall': 0.9755450795521509, 'f1-score': 0.9755391568332448, 'support': 10182}
 
time = 26.33 secondes

Val loss 0.7000068480179245 accuracy 0.898409903049469 macro_avg {'precision': 0.9078023373977014, 'recall': 0.9010118054098868, 'f1-score': 0.901038103229169, 'support': 1132} weighted_avg {'precision': 0.9047328180931291, 'recall': 0.8984098939929329, 'f1-score': 0.897941314089152, 'support': 1132}
 
----------
Epoch 11/40
time = 738.77 secondes

Train loss 0.09825171547882651 accuracy 0.9789825677871704 macro_avg {'precision': 0.9785369673898202, 'recall': 0.9785796495928725, 'f1-score': 0.9785488907943829, 'support': 10182} weighted_avg {'precision': 0.9790251500995634, 'recall': 0.9789825181693184, 'f1-score': 0.978994649586723, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6376551042112496 accuracy 0.9037102460861206 macro_avg {'precision': 0.9117344920096151, 'recall': 0.9022301809305219, 'f1-score': 0.9043679148656812, 'support': 1132} weighted_avg {'precision': 0.9086555359510174, 'recall': 0.9037102473498233, 'f1-score': 0.9037826013165955, 'support': 1132}
 
----------
Epoch 12/40
time = 739.62 secondes

Train loss 0.08249325049879615 accuracy 0.9829110503196716 macro_avg {'precision': 0.9824444136045315, 'recall': 0.9824888089383437, 'f1-score': 0.9824473102078585, 'support': 10182} weighted_avg {'precision': 0.982961519319646, 'recall': 0.9829110194460813, 'f1-score': 0.9829188620790048, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.6650568432771866 accuracy 0.9063604474067688 macro_avg {'precision': 0.9106499618534768, 'recall': 0.9069385702729453, 'f1-score': 0.9068718243839063, 'support': 1132} weighted_avg {'precision': 0.9105725819171943, 'recall': 0.9063604240282686, 'f1-score': 0.9065400534814894, 'support': 1132}
 
----------
Epoch 13/40
time = 926.94 secondes

Train loss 0.08834486232578971 accuracy 0.9822235703468323 macro_avg {'precision': 0.9814461333543054, 'recall': 0.9813502104789992, 'f1-score': 0.9813832095164978, 'support': 10182} weighted_avg {'precision': 0.9822479751598793, 'recall': 0.9822235317226478, 'f1-score': 0.9822203171585907, 'support': 10182}
 
time = 35.65 secondes

Val loss 0.6149100920668734 accuracy 0.9125441908836365 macro_avg {'precision': 0.914061059822259, 'recall': 0.9111505562081119, 'f1-score': 0.9106597129096995, 'support': 1132} weighted_avg {'precision': 0.9163971474348492, 'recall': 0.9125441696113075, 'f1-score': 0.912557368231023, 'support': 1132}
 
----------
Epoch 14/40
time = 998.84 secondes

Train loss 0.08939934446542831 accuracy 0.9835003018379211 macro_avg {'precision': 0.9823543379511213, 'recall': 0.9828896826163591, 'f1-score': 0.9825520488718922, 'support': 10182} weighted_avg {'precision': 0.9836509969472067, 'recall': 0.9835002946375958, 'f1-score': 0.9835202773492898, 'support': 10182}
 
time = 33.81 secondes

Val loss 0.6130739108683512 accuracy 0.9151943325996399 macro_avg {'precision': 0.923308241392367, 'recall': 0.917252193810078, 'f1-score': 0.9167313696138546, 'support': 1132} weighted_avg {'precision': 0.9212000017641433, 'recall': 0.9151943462897526, 'f1-score': 0.914646356799592, 'support': 1132}
 
----------
Epoch 15/40
time = 995.71 secondes

Train loss 0.08967642098324581 accuracy 0.9831074476242065 macro_avg {'precision': 0.9824369189773842, 'recall': 0.98274247173642, 'f1-score': 0.9825584561729122, 'support': 10182} weighted_avg {'precision': 0.9832003534817864, 'recall': 0.9831074445099195, 'f1-score': 0.9831273609644177, 'support': 10182}
 
time = 34.26 secondes

Val loss 0.7265222535247695 accuracy 0.9045936465263367 macro_avg {'precision': 0.9100804244017213, 'recall': 0.9066854712714525, 'f1-score': 0.9068330970494525, 'support': 1132} weighted_avg {'precision': 0.9081547801554255, 'recall': 0.9045936395759717, 'f1-score': 0.904921761066301, 'support': 1132}
 
----------
Epoch 16/40
time = 996.13 secondes

Train loss 0.07394998417691612 accuracy 0.9858574271202087 macro_avg {'precision': 0.9852328313315322, 'recall': 0.9854305209678704, 'f1-score': 0.9852989708160317, 'support': 10182} weighted_avg {'precision': 0.9859124931773807, 'recall': 0.9858573954036535, 'f1-score': 0.9858531979216519, 'support': 10182}
 
time = 33.90 secondes

Val loss 0.7146698933375121 accuracy 0.9063604474067688 macro_avg {'precision': 0.9100033623397021, 'recall': 0.904982476304174, 'f1-score': 0.9049885275946666, 'support': 1132} weighted_avg {'precision': 0.9096525016987779, 'recall': 0.9063604240282686, 'f1-score': 0.9054424709999817, 'support': 1132}
 
----------
Epoch 17/40
time = 994.75 secondes

Train loss 0.07152641811240881 accuracy 0.9861520528793335 macro_avg {'precision': 0.985857627133616, 'recall': 0.9859559840613297, 'f1-score': 0.9858707062439592, 'support': 10182} weighted_avg {'precision': 0.986260908953075, 'recall': 0.9861520329994107, 'f1-score': 0.9861703374184925, 'support': 10182}
 
time = 33.52 secondes

Val loss 0.6849757260023976 accuracy 0.9090105891227722 macro_avg {'precision': 0.9150387262054107, 'recall': 0.9158846436714672, 'f1-score': 0.9117270185292433, 'support': 1132} weighted_avg {'precision': 0.9179693837832417, 'recall': 0.9090106007067138, 'f1-score': 0.9099464038764857, 'support': 1132}
 
----------
Epoch 18/40
time = 995.99 secondes

Train loss 0.08286015596711355 accuracy 0.9843842387199402 macro_avg {'precision': 0.9841160643905831, 'recall': 0.9843586680121568, 'f1-score': 0.9842198481679839, 'support': 10182} weighted_avg {'precision': 0.9844168801992192, 'recall': 0.9843842074248674, 'f1-score': 0.9843830873268156, 'support': 10182}
 
time = 32.62 secondes

Val loss 0.6174911147090697 accuracy 0.9213780760765076 macro_avg {'precision': 0.9277291109543573, 'recall': 0.9238186383809504, 'f1-score': 0.9243363277859655, 'support': 1132} weighted_avg {'precision': 0.9260384946516375, 'recall': 0.9213780918727915, 'f1-score': 0.9222024606112866, 'support': 1132}
 
----------
Epoch 19/40
time = 993.08 secondes

Train loss 0.07701825029165535 accuracy 0.9866431355476379 macro_avg {'precision': 0.9863510900790222, 'recall': 0.9861043036716808, 'f1-score': 0.9862079651080974, 'support': 10182} weighted_avg {'precision': 0.9866791842289641, 'recall': 0.9866430956590061, 'f1-score': 0.9866414253335399, 'support': 10182}
 
time = 33.76 secondes

Val loss 0.7937350979120541 accuracy 0.9028268456459045 macro_avg {'precision': 0.9115413808735141, 'recall': 0.9038485559796271, 'f1-score': 0.9034612363462798, 'support': 1132} weighted_avg {'precision': 0.9116013647920284, 'recall': 0.9028268551236749, 'f1-score': 0.9029702852360755, 'support': 1132}
 
----------
Epoch 20/40
time = 995.99 secondes

Train loss 0.0639310936056911 accuracy 0.988705575466156 macro_avg {'precision': 0.9884239648755682, 'recall': 0.9880820446245606, 'f1-score': 0.9882247132275618, 'support': 10182} weighted_avg {'precision': 0.9887639920660419, 'recall': 0.9887055588293067, 'f1-score': 0.9887061868943879, 'support': 10182}
 
time = 33.80 secondes

Val loss 0.624860404502407 accuracy 0.9178445339202881 macro_avg {'precision': 0.9237281616161903, 'recall': 0.9192789744444179, 'f1-score': 0.9181758551149521, 'support': 1132} weighted_avg {'precision': 0.9258301102747301, 'recall': 0.9178445229681979, 'f1-score': 0.9188916010983093, 'support': 1132}
 
----------
Epoch 21/40
time = 992.13 secondes

Train loss 0.06303396749088284 accuracy 0.988705575466156 macro_avg {'precision': 0.988688458243588, 'recall': 0.9885421277888401, 'f1-score': 0.9886009312026556, 'support': 10182} weighted_avg {'precision': 0.9887336471614171, 'recall': 0.9887055588293067, 'f1-score': 0.9887048560348297, 'support': 10182}
 
time = 34.18 secondes

Val loss 0.7339044662959411 accuracy 0.9001767039299011 macro_avg {'precision': 0.8978006269437794, 'recall': 0.9002722340357003, 'f1-score': 0.8964234607784913, 'support': 1132} weighted_avg {'precision': 0.9040604564445324, 'recall': 0.9001766784452296, 'f1-score': 0.8996608897348495, 'support': 1132}
 
----------
Epoch 22/40
time = 991.97 secondes

Train loss 0.07091611471192803 accuracy 0.9885091781616211 macro_avg {'precision': 0.9884307353869657, 'recall': 0.9884264207792764, 'f1-score': 0.9884131596986903, 'support': 10182} weighted_avg {'precision': 0.9885173355254822, 'recall': 0.9885091337654685, 'f1-score': 0.9884974867539345, 'support': 10182}
 
time = 34.21 secondes

Val loss 0.6948364922694016 accuracy 0.916961133480072 macro_avg {'precision': 0.9201936469962432, 'recall': 0.9211713507772583, 'f1-score': 0.9189665342380426, 'support': 1132} weighted_avg {'precision': 0.9225546284432417, 'recall': 0.9169611307420494, 'f1-score': 0.918006535024266, 'support': 1132}
 
----------
Epoch 23/40
time = 994.21 secondes

Train loss 0.051877272318670065 accuracy 0.9909644722938538 macro_avg {'precision': 0.9907690792827498, 'recall': 0.9909048448007782, 'f1-score': 0.9908300336754623, 'support': 10182} weighted_avg {'precision': 0.9909762419732443, 'recall': 0.9909644470634453, 'f1-score': 0.9909639512208378, 'support': 10182}
 
time = 33.99 secondes

Val loss 0.7309458913106527 accuracy 0.9054770469665527 macro_avg {'precision': 0.912595499377128, 'recall': 0.9101375522074575, 'f1-score': 0.9085247298655051, 'support': 1132} weighted_avg {'precision': 0.9120374484031276, 'recall': 0.9054770318021201, 'f1-score': 0.9060531812390703, 'support': 1132}
 
----------
Epoch 24/40
time = 992.99 secondes

Train loss 0.044022838703481504 accuracy 0.991750180721283 macro_avg {'precision': 0.9917328680187578, 'recall': 0.9917585859727025, 'f1-score': 0.9917374679018811, 'support': 10182} weighted_avg {'precision': 0.9917763694041105, 'recall': 0.9917501473187978, 'f1-score': 0.9917547272450077, 'support': 10182}
 
time = 33.93 secondes

Val loss 0.7127971179963911 accuracy 0.9134275913238525 macro_avg {'precision': 0.9177965598628857, 'recall': 0.9172773289061041, 'f1-score': 0.9157834373829393, 'support': 1132} weighted_avg {'precision': 0.9171049300422921, 'recall': 0.9134275618374559, 'f1-score': 0.913447278788055, 'support': 1132}
 
----------
Epoch 25/40
time = 897.39 secondes

Train loss 0.04731089458917359 accuracy 0.9928305149078369 macro_avg {'precision': 0.9926694918699412, 'recall': 0.9928772796420532, 'f1-score': 0.9927601296185168, 'support': 10182} weighted_avg {'precision': 0.9928614637030125, 'recall': 0.9928304851699077, 'f1-score': 0.9928328196113871, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7808682031193289 accuracy 0.9072438478469849 macro_avg {'precision': 0.9169267630450341, 'recall': 0.9081407440407933, 'f1-score': 0.9101698152025571, 'support': 1132} weighted_avg {'precision': 0.9130704447442665, 'recall': 0.907243816254417, 'f1-score': 0.9079046352251591, 'support': 1132}
 
----------
Epoch 26/40
time = 737.51 secondes

Train loss 0.0491679084081976 accuracy 0.9924376606941223 macro_avg {'precision': 0.9920089435487689, 'recall': 0.9922952430965575, 'f1-score': 0.9921355965206903, 'support': 10182} weighted_avg {'precision': 0.9924653383462452, 'recall': 0.9924376350422314, 'f1-score': 0.9924370080390258, 'support': 10182}
 
time = 26.81 secondes

Val loss 0.6817966160314439 accuracy 0.9178445339202881 macro_avg {'precision': 0.9208524558233604, 'recall': 0.9210334981089459, 'f1-score': 0.919698905698346, 'support': 1132} weighted_avg {'precision': 0.9210013192238163, 'recall': 0.9178445229681979, 'f1-score': 0.9181056588062939, 'support': 1132}
 
----------
Epoch 27/40
time = 738.18 secondes

Train loss 0.04239041538567736 accuracy 0.9929287433624268 macro_avg {'precision': 0.9929966905047154, 'recall': 0.9927364979299741, 'f1-score': 0.9928575123413317, 'support': 10182} weighted_avg {'precision': 0.9929404907484445, 'recall': 0.9929286977018268, 'f1-score': 0.992926900735819, 'support': 10182}
 
time = 26.81 secondes

Val loss 0.722466159656211 accuracy 0.916077733039856 macro_avg {'precision': 0.9197074025025447, 'recall': 0.9176856175923798, 'f1-score': 0.9170660137206468, 'support': 1132} weighted_avg {'precision': 0.918089482965903, 'recall': 0.916077738515901, 'f1-score': 0.9154490084655779, 'support': 1132}
 
----------
Epoch 28/40
time = 740.39 secondes

Train loss 0.04192011910034488 accuracy 0.9927322864532471 macro_avg {'precision': 0.9924839300711742, 'recall': 0.9925544408024436, 'f1-score': 0.9925134520483567, 'support': 10182} weighted_avg {'precision': 0.992744421431618, 'recall': 0.9927322726379886, 'f1-score': 0.9927330042603736, 'support': 10182}
 
time = 24.76 secondes

Val loss 0.6668844974034508 accuracy 0.9178445339202881 macro_avg {'precision': 0.924514704862526, 'recall': 0.9179668909022339, 'f1-score': 0.9199242600608246, 'support': 1132} weighted_avg {'precision': 0.920685386936284, 'recall': 0.9178445229681979, 'f1-score': 0.9179308364977526, 'support': 1132}
 
----------
Epoch 29/40
time = 739.95 secondes

Train loss 0.03868839255184775 accuracy 0.993714451789856 macro_avg {'precision': 0.9933068714889325, 'recall': 0.9932341554439894, 'f1-score': 0.9932645357361827, 'support': 10182} weighted_avg {'precision': 0.9937176993070567, 'recall': 0.9937143979571793, 'f1-score': 0.9937105559161286, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.7240595026478716 accuracy 0.9204947352409363 macro_avg {'precision': 0.923227327227807, 'recall': 0.9239762091750185, 'f1-score': 0.9219502219334924, 'support': 1132} weighted_avg {'precision': 0.9228234170883239, 'recall': 0.9204946996466431, 'f1-score': 0.9199649852145455, 'support': 1132}
 
----------
Epoch 30/40
time = 738.88 secondes

Train loss 0.025692558039725047 accuracy 0.994892954826355 macro_avg {'precision': 0.9946680484139023, 'recall': 0.9947154313227984, 'f1-score': 0.9946890623998998, 'support': 10182} weighted_avg {'precision': 0.9948944381063517, 'recall': 0.9948929483402082, 'f1-score': 0.994891073158736, 'support': 10182}
 
time = 26.59 secondes

Val loss 0.7580771711799456 accuracy 0.9196113348007202 macro_avg {'precision': 0.9235439480323091, 'recall': 0.9222427857834073, 'f1-score': 0.9216091790167666, 'support': 1132} weighted_avg {'precision': 0.9223219281521321, 'recall': 0.9196113074204947, 'f1-score': 0.9196788139971669, 'support': 1132}
 
----------
Epoch 31/40
time = 740.73 secondes

Train loss 0.032355391263990896 accuracy 0.9942054748535156 macro_avg {'precision': 0.9942752774275693, 'recall': 0.9941951966430189, 'f1-score': 0.9942321572581584, 'support': 10182} weighted_avg {'precision': 0.9942057721892216, 'recall': 0.9942054606167747, 'f1-score': 0.9942025762667904, 'support': 10182}
 
time = 26.27 secondes

Val loss 0.6622242062266721 accuracy 0.926678478717804 macro_avg {'precision': 0.9290529276940805, 'recall': 0.9279023411928998, 'f1-score': 0.927831636476955, 'support': 1132} weighted_avg {'precision': 0.9279276219407703, 'recall': 0.926678445229682, 'f1-score': 0.9266311312718792, 'support': 1132}
 
----------
Epoch 32/40
time = 738.94 secondes

Train loss 0.03821109611050517 accuracy 0.9940090775489807 macro_avg {'precision': 0.9941544418697641, 'recall': 0.9939592412974294, 'f1-score': 0.9940377700144621, 'support': 10182} weighted_avg {'precision': 0.9940590589893007, 'recall': 0.9940090355529365, 'f1-score': 0.9940148528666589, 'support': 10182}
 
time = 26.17 secondes

Val loss 0.646027602401171 accuracy 0.9249116778373718 macro_avg {'precision': 0.928910550687473, 'recall': 0.9265376702339703, 'f1-score': 0.9268094648727209, 'support': 1132} weighted_avg {'precision': 0.9265479471310116, 'recall': 0.9249116607773852, 'f1-score': 0.9247156997694181, 'support': 1132}
 
----------
Epoch 33/40
time = 740.55 secondes

Train loss 0.022280626948269294 accuracy 0.9964643716812134 macro_avg {'precision': 0.9965778847556577, 'recall': 0.9964354413340413, 'f1-score': 0.996502541709931, 'support': 10182} weighted_avg {'precision': 0.9964743375396133, 'recall': 0.9964643488509134, 'f1-score': 0.9964652675113547, 'support': 10182}
 
time = 26.00 secondes

Val loss 0.7273582160041642 accuracy 0.9151943325996399 macro_avg {'precision': 0.9244603856503396, 'recall': 0.9182024630618351, 'f1-score': 0.9180863202564092, 'support': 1132} weighted_avg {'precision': 0.9242321080917832, 'recall': 0.9151943462897526, 'f1-score': 0.9164139224525298, 'support': 1132}
 
----------
Epoch 34/40
time = 738.82 secondes

Train loss 0.02021439096379725 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967924631819386, 'recall': 0.9966197935011317, 'f1-score': 0.9967007357837707, 'support': 10182} weighted_avg {'precision': 0.996768382958757, 'recall': 0.9967589864466706, 'f1-score': 0.9967585037376983, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7445546385711617 accuracy 0.9204947352409363 macro_avg {'precision': 0.9234647104694839, 'recall': 0.9225583970371634, 'f1-score': 0.9208253948624247, 'support': 1132} weighted_avg {'precision': 0.9244063246504619, 'recall': 0.9204946996466431, 'f1-score': 0.9201993677550028, 'support': 1132}
 
----------
Epoch 35/40
time = 738.97 secondes

Train loss 0.01905403306404 accuracy 0.996857225894928 macro_avg {'precision': 0.9968458270909517, 'recall': 0.9968566495705191, 'f1-score': 0.9968491519261351, 'support': 10182} weighted_avg {'precision': 0.9968622527530216, 'recall': 0.9968571989785897, 'f1-score': 0.9968576875603293, 'support': 10182}
 
time = 26.53 secondes

Val loss 0.6538155574790566 accuracy 0.9284452199935913 macro_avg {'precision': 0.9316580199017886, 'recall': 0.9309213322319486, 'f1-score': 0.9301224535300919, 'support': 1132} weighted_avg {'precision': 0.9310642568106168, 'recall': 0.9284452296819788, 'f1-score': 0.9285168080202073, 'support': 1132}
 
----------
Epoch 36/40
time = 738.24 secondes

Train loss 0.013378286444161662 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975441520045409, 'recall': 0.9975498883713412, 'f1-score': 0.9975451939071809, 'support': 10182} weighted_avg {'precision': 0.9975487559183014, 'recall': 0.9975446867020232, 'f1-score': 0.9975448509341326, 'support': 10182}
 
time = 26.49 secondes

Val loss 0.6407367818353289 accuracy 0.9293286204338074 macro_avg {'precision': 0.9306373927843554, 'recall': 0.9314911631992336, 'f1-score': 0.930071346853208, 'support': 1132} weighted_avg {'precision': 0.9316022434544768, 'recall': 0.9293286219081273, 'f1-score': 0.9294337957305251, 'support': 1132}
 
----------
Epoch 37/40
time = 738.57 secondes

Train loss 0.01465774472059679 accuracy 0.9978393316268921 macro_avg {'precision': 0.9977666345606432, 'recall': 0.9979157735361757, 'f1-score': 0.9978342368595327, 'support': 10182} weighted_avg {'precision': 0.9978553474183683, 'recall': 0.9978393242977804, 'f1-score': 0.9978409080319927, 'support': 10182}
 
time = 26.37 secondes

Val loss 0.6615774498085826 accuracy 0.9319788217544556 macro_avg {'precision': 0.9347333703269743, 'recall': 0.9342680596547529, 'f1-score': 0.933316909237576, 'support': 1132} weighted_avg {'precision': 0.9342529394678395, 'recall': 0.9319787985865724, 'f1-score': 0.9318829004548708, 'support': 1132}
 
----------
Epoch 38/40
time = 738.00 secondes

Train loss 0.006889319195041174 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984367376667459, 'recall': 0.9984061801117672, 'f1-score': 0.9984194639910908, 'support': 10182} weighted_avg {'precision': 0.9984312822787231, 'recall': 0.9984285994892949, 'f1-score': 0.9984279935448825, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.6337201250974777 accuracy 0.9275618195533752 macro_avg {'precision': 0.9308037705224871, 'recall': 0.9302419288464716, 'f1-score': 0.9291844621371185, 'support': 1132} weighted_avg {'precision': 0.9291210067130447, 'recall': 0.9275618374558304, 'f1-score': 0.9269235894218392, 'support': 1132}
 
----------
Epoch 39/40
time = 738.86 secondes

Train loss 0.006831785116754954 accuracy 0.9987232685089111 macro_avg {'precision': 0.998714276581221, 'recall': 0.9986982686505639, 'f1-score': 0.9987039843067158, 'support': 10182} weighted_avg {'precision': 0.9987269863398945, 'recall': 0.9987232370850521, 'f1-score': 0.9987228701148524, 'support': 10182}
 
time = 26.49 secondes

Val loss 0.6578070168377219 accuracy 0.9293286204338074 macro_avg {'precision': 0.9309299925343189, 'recall': 0.930664275183436, 'f1-score': 0.9295642025862814, 'support': 1132} weighted_avg {'precision': 0.9324360812276838, 'recall': 0.9293286219081273, 'f1-score': 0.9296239326141966, 'support': 1132}
 
----------
Epoch 40/40
time = 737.38 secondes

Train loss 0.001284631520429056 accuracy 0.9996072053909302 macro_avg {'precision': 0.99956617536331, 'recall': 0.9996219073039747, 'f1-score': 0.9995937073584875, 'support': 10182} weighted_avg {'precision': 0.9996078152968031, 'recall': 0.9996071498723237, 'f1-score': 0.9996071773056836, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6641196095528434 accuracy 0.9302120208740234 macro_avg {'precision': 0.9323305111534564, 'recall': 0.9317271510404362, 'f1-score': 0.930790495464219, 'support': 1132} weighted_avg {'precision': 0.932386590508397, 'recall': 0.9302120141342756, 'f1-score': 0.9299802203026147, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 37 macro_avg {'precision': 0.9347333703269743, 'recall': 0.9342680596547529, 'f1-score': 0.933316909237576, 'support': 1132} weighted_avg {'precision': 0.9342529394678395, 'recall': 0.9319787985865724, 'f1-score': 0.9318829004548708, 'support': 1132}

average train time 818.2491247832775

average val time 28.502375841140747
 
time = 172.77 secondes

test_accuracy 0.8604620099067688 macro_avg {'precision': 0.8580322116594037, 'recall': 0.8539583593507099, 'f1-score': 0.8541044548755401, 'support': 7532} weighted_avg {'precision': 0.8646526628955732, 'recall': 0.8604620286776421, 'f1-score': 0.8608210347121381, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_2
----------
Epoch 1/40
time = 981.16 secondes

Train loss 1.0547005530897078 accuracy 0.7048713564872742 macro_avg {'precision': 0.692424870761104, 'recall': 0.690423110602643, 'f1-score': 0.6868076541697761, 'support': 10182} weighted_avg {'precision': 0.7047801645939359, 'recall': 0.704871341583186, 'f1-score': 0.7002903935093981, 'support': 10182}
 
time = 32.82 secondes

Val loss 0.5667930741755056 accuracy 0.8286219239234924 macro_avg {'precision': 0.8216627988102131, 'recall': 0.8213825672930769, 'f1-score': 0.8148078600991797, 'support': 1132} weighted_avg {'precision': 0.8260518605376143, 'recall': 0.8286219081272085, 'f1-score': 0.8213796718193396, 'support': 1132}
 
----------
Epoch 2/40
time = 980.19 secondes

Train loss 0.3912757411072823 accuracy 0.8812610507011414 macro_avg {'precision': 0.8735153135796881, 'recall': 0.8719855223591946, 'f1-score': 0.8715828848379152, 'support': 10182} weighted_avg {'precision': 0.8799853943209274, 'recall': 0.8812610489098409, 'f1-score': 0.8797206621809145, 'support': 10182}
 
time = 31.94 secondes

Val loss 0.4708802367652386 accuracy 0.8745583295822144 macro_avg {'precision': 0.8808978459495655, 'recall': 0.8708093649741487, 'f1-score': 0.8698173401089295, 'support': 1132} weighted_avg {'precision': 0.882239250417987, 'recall': 0.8745583038869258, 'f1-score': 0.8726900592758567, 'support': 1132}
 
----------
Epoch 3/40
time = 981.34 secondes

Train loss 0.22831605895008641 accuracy 0.9347869157791138 macro_avg {'precision': 0.9310740013688308, 'recall': 0.930881794157969, 'f1-score': 0.930888784502006, 'support': 10182} weighted_avg {'precision': 0.9349949249239496, 'recall': 0.9347868788057356, 'f1-score': 0.9348080628507505, 'support': 10182}
 
time = 31.70 secondes

Val loss 0.4358914404923857 accuracy 0.8948763608932495 macro_avg {'precision': 0.8983502484904703, 'recall': 0.8949291134838966, 'f1-score': 0.8933351494048083, 'support': 1132} weighted_avg {'precision': 0.899443700750067, 'recall': 0.8948763250883393, 'f1-score': 0.8937749067378299, 'support': 1132}
 
----------
Epoch 4/40
time = 981.18 secondes

Train loss 0.1655177861884137 accuracy 0.9545276165008545 macro_avg {'precision': 0.9520706817062667, 'recall': 0.9520658704751395, 'f1-score': 0.951985449539421, 'support': 10182} weighted_avg {'precision': 0.9547612176827308, 'recall': 0.9545275977214692, 'f1-score': 0.9545662596726793, 'support': 10182}
 
time = 32.07 secondes

Val loss 0.5446290204721228 accuracy 0.8869258165359497 macro_avg {'precision': 0.8943818660734546, 'recall': 0.8810067749497152, 'f1-score': 0.8827343877381612, 'support': 1132} weighted_avg {'precision': 0.8921153393551489, 'recall': 0.8869257950530035, 'f1-score': 0.8850649632263683, 'support': 1132}
 
----------
Epoch 5/40
time = 980.82 secondes

Train loss 0.15323189299427897 accuracy 0.9612060785293579 macro_avg {'precision': 0.9597583511675397, 'recall': 0.9599871006427341, 'f1-score': 0.9598069629630533, 'support': 10182} weighted_avg {'precision': 0.9613905233150392, 'recall': 0.9612060498919662, 'f1-score': 0.9612377943427467, 'support': 10182}
 
time = 32.21 secondes

Val loss 0.5032299433074052 accuracy 0.9010601043701172 macro_avg {'precision': 0.9061980386235918, 'recall': 0.904123750039403, 'f1-score': 0.9023532521358069, 'support': 1132} weighted_avg {'precision': 0.9058343406416947, 'recall': 0.901060070671378, 'f1-score': 0.9003486279310298, 'support': 1132}
 
----------
Epoch 6/40
time = 981.36 secondes

Train loss 0.13971542446067034 accuracy 0.964152455329895 macro_avg {'precision': 0.9627850499839598, 'recall': 0.9627770687332824, 'f1-score': 0.9627715889131157, 'support': 10182} weighted_avg {'precision': 0.9642162074281821, 'recall': 0.9641524258495384, 'f1-score': 0.9641746204570731, 'support': 10182}
 
time = 32.14 secondes

Val loss 0.563846891099082 accuracy 0.9010601043701172 macro_avg {'precision': 0.906063095731023, 'recall': 0.9025098730712859, 'f1-score': 0.9012049463401395, 'support': 1132} weighted_avg {'precision': 0.9054510593497033, 'recall': 0.901060070671378, 'f1-score': 0.8999463747553172, 'support': 1132}
 
----------
Epoch 7/40
time = 979.99 secondes

Train loss 0.11498355607765696 accuracy 0.9716166257858276 macro_avg {'precision': 0.9711558252506391, 'recall': 0.9710862296581633, 'f1-score': 0.9711067301387111, 'support': 10182} weighted_avg {'precision': 0.9716296723520964, 'recall': 0.9716165782753879, 'f1-score': 0.971609010906919, 'support': 10182}
 
time = 32.20 secondes

Val loss 0.599229288216136 accuracy 0.9019434452056885 macro_avg {'precision': 0.9070523112299625, 'recall': 0.9065923940053239, 'f1-score': 0.9042637636185453, 'support': 1132} weighted_avg {'precision': 0.9068636826699332, 'recall': 0.9019434628975265, 'f1-score': 0.9016972866521769, 'support': 1132}
 
----------
Epoch 8/40
time = 978.78 secondes

Train loss 0.11898033900426377 accuracy 0.973384439945221 macro_avg {'precision': 0.9724916943214428, 'recall': 0.9722824359602861, 'f1-score': 0.972362723071291, 'support': 10182} weighted_avg {'precision': 0.9734254132336706, 'recall': 0.9733844038499313, 'f1-score': 0.9733820356322257, 'support': 10182}
 
time = 32.19 secondes

Val loss 0.5592887303947707 accuracy 0.9151943325996399 macro_avg {'precision': 0.9181082883453462, 'recall': 0.9136138109795213, 'f1-score': 0.9133636331734178, 'support': 1132} weighted_avg {'precision': 0.9181344676302581, 'recall': 0.9151943462897526, 'f1-score': 0.9144188416855835, 'support': 1132}
 
----------
Epoch 9/40
time = 978.86 secondes

Train loss 0.10544576687326916 accuracy 0.978491485118866 macro_avg {'precision': 0.9780552316623803, 'recall': 0.9781105872643951, 'f1-score': 0.9780529204459745, 'support': 10182} weighted_avg {'precision': 0.978517670016262, 'recall': 0.978491455509723, 'f1-score': 0.9784763551698453, 'support': 10182}
 
time = 32.04 secondes

Val loss 0.6371112851348941 accuracy 0.9072438478469849 macro_avg {'precision': 0.9110936463982645, 'recall': 0.9085581131094447, 'f1-score': 0.9073320595022409, 'support': 1132} weighted_avg {'precision': 0.9116096720274616, 'recall': 0.907243816254417, 'f1-score': 0.9071021890345189, 'support': 1132}
 
----------
Epoch 10/40
time = 1384.04 secondes

Train loss 0.11097088614918235 accuracy 0.9759379625320435 macro_avg {'precision': 0.9751262452450836, 'recall': 0.9750401070544111, 'f1-score': 0.9750256911824936, 'support': 10182} weighted_avg {'precision': 0.9760382083094303, 'recall': 0.9759379296798272, 'f1-score': 0.9759297111740233, 'support': 10182}
 
time = 41.18 secondes

Val loss 0.5650467651524798 accuracy 0.916077733039856 macro_avg {'precision': 0.9184497786267751, 'recall': 0.9175219263793378, 'f1-score': 0.9166821782525506, 'support': 1132} weighted_avg {'precision': 0.9186097112201331, 'recall': 0.916077738515901, 'f1-score': 0.9159583859840655, 'support': 1132}
 
----------
Epoch 11/40
time = 1422.17 secondes

Train loss 0.09257517249636944 accuracy 0.980553925037384 macro_avg {'precision': 0.9801654523616279, 'recall': 0.9798512513550927, 'f1-score': 0.9799880714161816, 'support': 10182} weighted_avg {'precision': 0.9805650361307909, 'recall': 0.9805539186800236, 'f1-score': 0.9805413592582043, 'support': 10182}
 
time = 40.14 secondes

Val loss 0.7517188138932704 accuracy 0.8975265026092529 macro_avg {'precision': 0.9079682063555504, 'recall': 0.9018351495946575, 'f1-score': 0.9012175187634245, 'support': 1132} weighted_avg {'precision': 0.9068855669091259, 'recall': 0.8975265017667845, 'f1-score': 0.8981125676562498, 'support': 1132}
 
----------
Epoch 12/40
time = 1409.79 secondes

Train loss 0.09207274496108354 accuracy 0.9812414646148682 macro_avg {'precision': 0.9809853512918119, 'recall': 0.9808258349910675, 'f1-score': 0.9808977975759567, 'support': 10182} weighted_avg {'precision': 0.9812541572981184, 'recall': 0.981241406403457, 'f1-score': 0.9812400845566748, 'support': 10182}
 
time = 37.32 secondes

Val loss 0.6567912130861734 accuracy 0.9028268456459045 macro_avg {'precision': 0.9148712107443968, 'recall': 0.9092718608288977, 'f1-score': 0.9089778585642885, 'support': 1132} weighted_avg {'precision': 0.9118569518548477, 'recall': 0.9028268551236749, 'f1-score': 0.9039210270875869, 'support': 1132}
 
----------
Epoch 13/40
time = 1409.64 secondes

Train loss 0.09847071221834992 accuracy 0.9799646735191345 macro_avg {'precision': 0.9798149873710248, 'recall': 0.97975091954725, 'f1-score': 0.9797584585792276, 'support': 10182} weighted_avg {'precision': 0.9800334062202475, 'recall': 0.9799646434885091, 'f1-score': 0.9799736921158825, 'support': 10182}
 
time = 36.93 secondes

Val loss 0.7423883201865952 accuracy 0.9098939895629883 macro_avg {'precision': 0.9178391007709819, 'recall': 0.9109969448002555, 'f1-score': 0.9121815767951397, 'support': 1132} weighted_avg {'precision': 0.9161556376733343, 'recall': 0.9098939929328622, 'f1-score': 0.9105783149946958, 'support': 1132}
 
----------
Epoch 14/40
time = 1406.24 secondes

Train loss 0.07422327145798546 accuracy 0.9854645729064941 macro_avg {'precision': 0.9849581073073159, 'recall': 0.9849370766970731, 'f1-score': 0.984940099079991, 'support': 10182} weighted_avg {'precision': 0.9854775814113865, 'recall': 0.9854645452759773, 'f1-score': 0.9854632754462345, 'support': 10182}
 
time = 36.80 secondes

Val loss 0.7363474444520224 accuracy 0.9019434452056885 macro_avg {'precision': 0.90967029466293, 'recall': 0.9045863834722747, 'f1-score': 0.9040320113075705, 'support': 1132} weighted_avg {'precision': 0.9079227809475044, 'recall': 0.9019434628975265, 'f1-score': 0.9016973761162551, 'support': 1132}
 
----------
Epoch 15/40
time = 1405.99 secondes

Train loss 0.10884946317513983 accuracy 0.9803575277328491 macro_avg {'precision': 0.9799423326447838, 'recall': 0.9795751045034257, 'f1-score': 0.9797063664057883, 'support': 10182} weighted_avg {'precision': 0.9804058386853179, 'recall': 0.9803574936161854, 'f1-score': 0.9803349175478682, 'support': 10182}
 
time = 38.26 secondes

Val loss 0.7037257165852999 accuracy 0.9063604474067688 macro_avg {'precision': 0.9104147666600483, 'recall': 0.9097771615018233, 'f1-score': 0.9081143189987255, 'support': 1132} weighted_avg {'precision': 0.9100068130322492, 'recall': 0.9063604240282686, 'f1-score': 0.9060100209960379, 'support': 1132}
 
----------
Epoch 16/40
time = 1406.50 secondes

Train loss 0.09690308585723274 accuracy 0.9814378619194031 macro_avg {'precision': 0.9810677464603398, 'recall': 0.9811123659277134, 'f1-score': 0.9810733710503508, 'support': 10182} weighted_avg {'precision': 0.9814516371222601, 'recall': 0.9814378314672952, 'f1-score': 0.9814275098662303, 'support': 10182}
 
time = 37.51 secondes

Val loss 0.6180400164757116 accuracy 0.9090105891227722 macro_avg {'precision': 0.9090808250278993, 'recall': 0.9107783413671404, 'f1-score': 0.9082472089758097, 'support': 1132} weighted_avg {'precision': 0.9135344383902245, 'recall': 0.9090106007067138, 'f1-score': 0.9097081923952675, 'support': 1132}
 
----------
Epoch 17/40
time = 1409.43 secondes

Train loss 0.06937161077916547 accuracy 0.9867413640022278 macro_avg {'precision': 0.986470548856131, 'recall': 0.986384881820527, 'f1-score': 0.9864151432282975, 'support': 10182} weighted_avg {'precision': 0.986747371245201, 'recall': 0.9867413081909252, 'f1-score': 0.9867315427916997, 'support': 10182}
 
time = 37.61 secondes

Val loss 0.5683057757921912 accuracy 0.916077733039856 macro_avg {'precision': 0.9200219818338061, 'recall': 0.9166373971535181, 'f1-score': 0.9174156558467281, 'support': 1132} weighted_avg {'precision': 0.9173557548263727, 'recall': 0.916077738515901, 'f1-score': 0.9157685922580376, 'support': 1132}
 
----------
Epoch 18/40
time = 1409.03 secondes

Train loss 0.07847863100966665 accuracy 0.9852681756019592 macro_avg {'precision': 0.98490962048366, 'recall': 0.9847725404137868, 'f1-score': 0.9848148796408871, 'support': 10182} weighted_avg {'precision': 0.9853296291957712, 'recall': 0.985268120212139, 'f1-score': 0.985272493014773, 'support': 10182}
 
time = 37.27 secondes

Val loss 0.6999966242515833 accuracy 0.9081271886825562 macro_avg {'precision': 0.9131085930946666, 'recall': 0.9084707792945219, 'f1-score': 0.9085614494049155, 'support': 1132} weighted_avg {'precision': 0.9127866186765916, 'recall': 0.9081272084805654, 'f1-score': 0.9082768709596032, 'support': 1132}
 
----------
Epoch 19/40
time = 1407.95 secondes

Train loss 0.07265006550694397 accuracy 0.9864466786384583 macro_avg {'precision': 0.9865592475116115, 'recall': 0.9863490106125591, 'f1-score': 0.9864405197681257, 'support': 10182} weighted_avg {'precision': 0.9864739603124705, 'recall': 0.986446670595168, 'f1-score': 0.9864469763974709, 'support': 10182}
 
time = 38.15 secondes

Val loss 0.5367001939115473 accuracy 0.9302120208740234 macro_avg {'precision': 0.9299250910655275, 'recall': 0.930438750313835, 'f1-score': 0.9295936366181158, 'support': 1132} weighted_avg {'precision': 0.9316283456122801, 'recall': 0.9302120141342756, 'f1-score': 0.9303210201818433, 'support': 1132}
 
----------
Epoch 20/40
time = 1407.62 secondes

Train loss 0.05199332548564631 accuracy 0.9893930554389954 macro_avg {'precision': 0.9894058246096169, 'recall': 0.9893625041640689, 'f1-score': 0.9893631262528786, 'support': 10182} weighted_avg {'precision': 0.9894353161853985, 'recall': 0.9893930465527401, 'f1-score': 0.989392496142461, 'support': 10182}
 
time = 37.57 secondes

Val loss 0.5609121798465116 accuracy 0.9302120208740234 macro_avg {'precision': 0.929860041796536, 'recall': 0.9322216516412107, 'f1-score': 0.929684093862323, 'support': 1132} weighted_avg {'precision': 0.9319056423952493, 'recall': 0.9302120141342756, 'f1-score': 0.9296209296506105, 'support': 1132}
 
----------
Epoch 21/40
time = 1407.41 secondes

Train loss 0.05415894210468714 accuracy 0.9899823665618896 macro_avg {'precision': 0.9901824564279418, 'recall': 0.9901918358048414, 'f1-score': 0.9901681897439228, 'support': 10182} weighted_avg {'precision': 0.9899922013017849, 'recall': 0.9899823217442546, 'f1-score': 0.9899678487259478, 'support': 10182}
 
time = 37.57 secondes

Val loss 0.6091317243614393 accuracy 0.916961133480072 macro_avg {'precision': 0.9247314459155496, 'recall': 0.9212012494464877, 'f1-score': 0.9199231109070386, 'support': 1132} weighted_avg {'precision': 0.9253211129471347, 'recall': 0.9169611307420494, 'f1-score': 0.9178572755133306, 'support': 1132}
 
----------
Epoch 22/40
time = 1408.07 secondes

Train loss 0.05144619845889234 accuracy 0.9904733896255493 macro_avg {'precision': 0.9903576289867706, 'recall': 0.990334549792306, 'f1-score': 0.9903154344024825, 'support': 10182} weighted_avg {'precision': 0.990516451797931, 'recall': 0.9904733844038499, 'f1-score': 0.9904667925879389, 'support': 10182}
 
time = 37.46 secondes

Val loss 0.6539902405636664 accuracy 0.9213780760765076 macro_avg {'precision': 0.9277193234004443, 'recall': 0.9218003860650053, 'f1-score': 0.9211402207016712, 'support': 1132} weighted_avg {'precision': 0.9246335576006464, 'recall': 0.9213780918727915, 'f1-score': 0.9195588113151788, 'support': 1132}
 
----------
Epoch 23/40
time = 1405.97 secondes

Train loss 0.053009115097980036 accuracy 0.9902769923210144 macro_avg {'precision': 0.9902561372336965, 'recall': 0.9902551121845056, 'f1-score': 0.9902456079663986, 'support': 10182} weighted_avg {'precision': 0.9902941652685113, 'recall': 0.9902769593400118, 'f1-score': 0.9902758245896067, 'support': 10182}
 
time = 37.38 secondes

Val loss 0.6232526465185363 accuracy 0.9240282773971558 macro_avg {'precision': 0.9268710136726103, 'recall': 0.9258429808877292, 'f1-score': 0.9241061796853668, 'support': 1132} weighted_avg {'precision': 0.9272464396838407, 'recall': 0.9240282685512368, 'f1-score': 0.9233570264313541, 'support': 1132}
 
----------
Epoch 24/40
time = 1409.10 secondes

Train loss 0.05513187618072014 accuracy 0.9907680749893188 macro_avg {'precision': 0.9903268882212565, 'recall': 0.9905277314930696, 'f1-score': 0.9903941959028563, 'support': 10182} weighted_avg {'precision': 0.9908341586067696, 'recall': 0.9907680219996071, 'f1-score': 0.9907707351859165, 'support': 10182}
 
time = 36.81 secondes

Val loss 0.6519463044293241 accuracy 0.9143109321594238 macro_avg {'precision': 0.917900410028546, 'recall': 0.9165896912596108, 'f1-score': 0.914624233520158, 'support': 1132} weighted_avg {'precision': 0.9207658494937556, 'recall': 0.9143109540636042, 'f1-score': 0.9150884247472401, 'support': 1132}
 
----------
Epoch 25/40
time = 1408.79 secondes

Train loss 0.052331396676833904 accuracy 0.9911609292030334 macro_avg {'precision': 0.9905244091743318, 'recall': 0.9909907966310803, 'f1-score': 0.9907266852536519, 'support': 10182} weighted_avg {'precision': 0.9912325361100235, 'recall': 0.9911608721272834, 'f1-score': 0.9911702986232844, 'support': 10182}
 
time = 40.74 secondes

Val loss 0.7152657072748669 accuracy 0.9037102460861206 macro_avg {'precision': 0.9071492219858099, 'recall': 0.9027226669322852, 'f1-score': 0.902704952276854, 'support': 1132} weighted_avg {'precision': 0.9087360176125796, 'recall': 0.9037102473498233, 'f1-score': 0.9044935265452106, 'support': 1132}
 
----------
Epoch 26/40
time = 1415.09 secondes

Train loss 0.039978432949414514 accuracy 0.9925358891487122 macro_avg {'precision': 0.9922782827691987, 'recall': 0.9920301886028989, 'f1-score': 0.9921481144285844, 'support': 10182} weighted_avg {'precision': 0.9925388385137933, 'recall': 0.9925358475741505, 'f1-score': 0.9925320454439677, 'support': 10182}
 
time = 37.26 secondes

Val loss 0.6738148277025329 accuracy 0.9187279343605042 macro_avg {'precision': 0.9218781849953223, 'recall': 0.9219164657296236, 'f1-score': 0.9203701517540501, 'support': 1132} weighted_avg {'precision': 0.9208112131884383, 'recall': 0.9187279151943463, 'f1-score': 0.9182330797976492, 'support': 1132}
 
----------
Epoch 27/40
time = 1423.91 secondes

Train loss 0.03770366667518126 accuracy 0.992634117603302 macro_avg {'precision': 0.9923945738089287, 'recall': 0.9925041847423545, 'f1-score': 0.9924254017622365, 'support': 10182} weighted_avg {'precision': 0.9926810562618081, 'recall': 0.9926340601060696, 'f1-score': 0.9926366888886975, 'support': 10182}
 
time = 42.90 secondes

Val loss 0.57171463038849 accuracy 0.9249116778373718 macro_avg {'precision': 0.9261077737600886, 'recall': 0.9266949252449509, 'f1-score': 0.9253650295298048, 'support': 1132} weighted_avg {'precision': 0.9269547128121214, 'recall': 0.9249116607773852, 'f1-score': 0.9249881133716747, 'support': 1132}
 
----------
Epoch 28/40
time = 1415.91 secondes

Train loss 0.03185992245059226 accuracy 0.9945001006126404 macro_avg {'precision': 0.9944722866754023, 'recall': 0.9944756904835549, 'f1-score': 0.9944598044891212, 'support': 10182} weighted_avg {'precision': 0.9945236534860822, 'recall': 0.9945000982125319, 'f1-score': 0.9944984027401397, 'support': 10182}
 
time = 40.34 secondes

Val loss 0.6007401038296452 accuracy 0.9249116778373718 macro_avg {'precision': 0.9278868737169239, 'recall': 0.9271972980126636, 'f1-score': 0.9269107691266589, 'support': 1132} weighted_avg {'precision': 0.9265356920970259, 'recall': 0.9249116607773852, 'f1-score': 0.9250944103817687, 'support': 1132}
 
----------
Epoch 29/40
time = 1408.44 secondes

Train loss 0.03642897476029633 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934510283833022, 'recall': 0.9938654465789062, 'f1-score': 0.9936407007077419, 'support': 10182} weighted_avg {'precision': 0.9940517740595779, 'recall': 0.9940090355529365, 'f1-score': 0.9940151791570347, 'support': 10182}
 
time = 37.77 secondes

Val loss 0.7130533025919134 accuracy 0.9178445339202881 macro_avg {'precision': 0.9234284867551474, 'recall': 0.9213608794009488, 'f1-score': 0.9196822568030839, 'support': 1132} weighted_avg {'precision': 0.9231643335378904, 'recall': 0.9178445229681979, 'f1-score': 0.917493655259149, 'support': 1132}
 
----------
Epoch 30/40
time = 1415.36 secondes

Train loss 0.030329900270524752 accuracy 0.9952858090400696 macro_avg {'precision': 0.9949495161442258, 'recall': 0.994706319019793, 'f1-score': 0.9948217805508845, 'support': 10182} weighted_avg {'precision': 0.9952920646034026, 'recall': 0.9952857984678845, 'f1-score': 0.9952832950487494, 'support': 10182}
 
time = 40.98 secondes

Val loss 0.5761175955082929 accuracy 0.9284452199935913 macro_avg {'precision': 0.9330230091880558, 'recall': 0.9287279301860544, 'f1-score': 0.9296514919877561, 'support': 1132} weighted_avg {'precision': 0.9303436668065724, 'recall': 0.9284452296819788, 'f1-score': 0.9281885334727354, 'support': 1132}
 
----------
Epoch 31/40
time = 1422.75 secondes

Train loss 0.021053200754194874 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960914974215612, 'recall': 0.9960647775283278, 'f1-score': 0.9960763276829763, 'support': 10182} weighted_avg {'precision': 0.9961752468074184, 'recall': 0.9961697112551562, 'f1-score': 0.9961706191757974, 'support': 10182}
 
time = 37.98 secondes

Val loss 0.7054938470315443 accuracy 0.9204947352409363 macro_avg {'precision': 0.926826774963595, 'recall': 0.922783926589787, 'f1-score': 0.9233649865022595, 'support': 1132} weighted_avg {'precision': 0.9252106701746141, 'recall': 0.9204946996466431, 'f1-score': 0.9211603167060798, 'support': 1132}
 
----------
Epoch 32/40
time = 1403.73 secondes

Train loss 0.022547656826565877 accuracy 0.9960715174674988 macro_avg {'precision': 0.9962272459705039, 'recall': 0.9961482691685715, 'f1-score': 0.9961810924968537, 'support': 10182} weighted_avg {'precision': 0.9960891625522915, 'recall': 0.9960714987232371, 'f1-score': 0.9960734705036454, 'support': 10182}
 
time = 36.57 secondes

Val loss 0.8069392129798384 accuracy 0.9187279343605042 macro_avg {'precision': 0.921406117434714, 'recall': 0.9225851711964218, 'f1-score': 0.9197061481559612, 'support': 1132} weighted_avg {'precision': 0.9218560676836637, 'recall': 0.9187279151943463, 'f1-score': 0.9180879953740924, 'support': 1132}
 
----------
Epoch 33/40
time = 1407.51 secondes

Train loss 0.01885050387213389 accuracy 0.9959732890129089 macro_avg {'precision': 0.996059527323782, 'recall': 0.9961046280409949, 'f1-score': 0.9960799066462076, 'support': 10182} weighted_avg {'precision': 0.995977898874605, 'recall': 0.995973286191318, 'f1-score': 0.9959734113813857, 'support': 10182}
 
time = 41.08 secondes

Val loss 0.6694604474134752 accuracy 0.9213780760765076 macro_avg {'precision': 0.9240132359987877, 'recall': 0.9244686196722057, 'f1-score': 0.923428614791869, 'support': 1132} weighted_avg {'precision': 0.9224422338309252, 'recall': 0.9213780918727915, 'f1-score': 0.9210897590358823, 'support': 1132}
 
----------
Epoch 34/40
time = 1413.15 secondes

Train loss 0.013819132621288555 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977532515825753, 'recall': 0.9977317064561705, 'f1-score': 0.9977403869371674, 'support': 10182} weighted_avg {'precision': 0.9976470271188237, 'recall': 0.9976428992339422, 'f1-score': 0.9976427674321803, 'support': 10182}
 
time = 37.49 secondes

Val loss 0.698508399996953 accuracy 0.916077733039856 macro_avg {'precision': 0.9201007590234583, 'recall': 0.9209162278311489, 'f1-score': 0.9183184364850959, 'support': 1132} weighted_avg {'precision': 0.9206234119657956, 'recall': 0.916077738515901, 'f1-score': 0.9159934403752039, 'support': 1132}
 
----------
Epoch 35/40
time = 1401.28 secondes

Train loss 0.01927510648502379 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972089791826455, 'recall': 0.9973400064803257, 'f1-score': 0.9972726324697458, 'support': 10182} weighted_avg {'precision': 0.9972514019920963, 'recall': 0.9972500491062659, 'f1-score': 0.9972490084322179, 'support': 10182}
 
time = 37.09 secondes

Val loss 0.7358649390135071 accuracy 0.9196113348007202 macro_avg {'precision': 0.9229123590838061, 'recall': 0.9235574660761877, 'f1-score': 0.9215881629751166, 'support': 1132} weighted_avg {'precision': 0.9225218893069677, 'recall': 0.9196113074204947, 'f1-score': 0.9193028773496301, 'support': 1132}
 
----------
Epoch 36/40
time = 1407.22 secondes

Train loss 0.014573513909678211 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974443582658254, 'recall': 0.9975566295060512, 'f1-score': 0.9974981713331197, 'support': 10182} weighted_avg {'precision': 0.9975518929682365, 'recall': 0.9975446867020232, 'f1-score': 0.9975460535863608, 'support': 10182}
 
time = 37.79 secondes

Val loss 0.6050498466229072 accuracy 0.9178445339202881 macro_avg {'precision': 0.9219023339725855, 'recall': 0.9217445060119225, 'f1-score': 0.920431044930995, 'support': 1132} weighted_avg {'precision': 0.9210921463508137, 'recall': 0.9178445229681979, 'f1-score': 0.9179757513657782, 'support': 1132}
 
----------
Epoch 37/40
time = 1411.02 secondes

Train loss 0.01277389375972344 accuracy 0.9978393316268921 macro_avg {'precision': 0.9977050856305242, 'recall': 0.9977006963179841, 'f1-score': 0.9977010523523505, 'support': 10182} weighted_avg {'precision': 0.9978411591755649, 'recall': 0.9978393242977804, 'f1-score': 0.9978384615599097, 'support': 10182}
 
time = 41.99 secondes

Val loss 0.6600217325010074 accuracy 0.9249116778373718 macro_avg {'precision': 0.9281208839825424, 'recall': 0.92661069549078, 'f1-score': 0.9262471112945454, 'support': 1132} weighted_avg {'precision': 0.927570296354773, 'recall': 0.9249116607773852, 'f1-score': 0.9250490797300792, 'support': 1132}
 
----------
Epoch 38/40
time = 1411.10 secondes

Train loss 0.006551882621292012 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986285546638236, 'recall': 0.9986591294615197, 'f1-score': 0.9986425045287074, 'support': 10182} weighted_avg {'precision': 0.9986275109217599, 'recall': 0.998625024553133, 'f1-score': 0.9986249345178381, 'support': 10182}
 
time = 37.39 secondes

Val loss 0.6634192922066292 accuracy 0.9240282773971558 macro_avg {'precision': 0.9264560484365862, 'recall': 0.9261359332858168, 'f1-score': 0.9249877584017179, 'support': 1132} weighted_avg {'precision': 0.9261633960110086, 'recall': 0.9240282685512368, 'f1-score': 0.9237635256859261, 'support': 1132}
 
----------
Epoch 39/40
time = 1408.93 secondes

Train loss 0.004548948203072152 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991494349028116, 'recall': 0.9990992493049669, 'f1-score': 0.9991235702110647, 'support': 10182} weighted_avg {'precision': 0.9991173754004641, 'recall': 0.9991160872127284, 'f1-score': 0.9991159671309826, 'support': 10182}
 
time = 41.45 secondes

Val loss 0.6325059754914728 accuracy 0.9337455630302429 macro_avg {'precision': 0.9373568380850757, 'recall': 0.935263470761446, 'f1-score': 0.9350815154845542, 'support': 1132} weighted_avg {'precision': 0.9357091297845037, 'recall': 0.9337455830388692, 'f1-score': 0.9334192575741498, 'support': 1132}
 
----------
Epoch 40/40
time = 1417.08 secondes

Train loss 0.003169068324110538 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995282445532044, 'recall': 0.9995294591887074, 'f1-score': 0.9995280480518616, 'support': 10182} weighted_avg {'precision': 0.9995102304510135, 'recall': 0.9995089373404047, 'f1-score': 0.9995087486691167, 'support': 10182}
 
time = 32.16 secondes

Val loss 0.6614473465879073 accuracy 0.9249116778373718 macro_avg {'precision': 0.9287197704696514, 'recall': 0.9278920904285499, 'f1-score': 0.9269808829663921, 'support': 1132} weighted_avg {'precision': 0.9275277471280706, 'recall': 0.9249116607773852, 'f1-score': 0.9248887113480301, 'support': 1132}
 
----------
best_accuracy 0.9337455630302429 best_epoch 39 macro_avg {'precision': 0.9373568380850757, 'recall': 0.935263470761446, 'f1-score': 0.9350815154845542, 'support': 1132} weighted_avg {'precision': 0.9357091297845037, 'recall': 0.9337455830388692, 'f1-score': 0.9334192575741498, 'support': 1132}

average train time 1313.0982891619205

average val time 36.95630005002022
 
time = 210.49 secondes

test_accuracy 0.8613913655281067 macro_avg {'precision': 0.860704708232951, 'recall': 0.8535895104301169, 'f1-score': 0.8551791836858758, 'support': 7532} weighted_avg {'precision': 0.8646702708359337, 'recall': 0.8613913967073819, 'f1-score': 0.8612093207951979, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_2
----------
Epoch 1/40
time = 1909.33 secondes

Train loss 1.001104614540958 accuracy 0.7303084135055542 macro_avg {'precision': 0.7268182303772096, 'recall': 0.717091745702702, 'f1-score': 0.7135565798057553, 'support': 10182} weighted_avg {'precision': 0.734279158696775, 'recall': 0.7303083873502259, 'f1-score': 0.7251663471642821, 'support': 10182}
 
time = 41.04 secondes

Val loss 0.5004134648282763 accuracy 0.8489399552345276 macro_avg {'precision': 0.8484632083993807, 'recall': 0.8443336476700545, 'f1-score': 0.8332444586018694, 'support': 1132} weighted_avg {'precision': 0.8508454430556123, 'recall': 0.848939929328622, 'f1-score': 0.8383638162128532, 'support': 1132}
 
----------
Epoch 2/40
time = 1909.31 secondes

Train loss 0.35199462669189535 accuracy 0.900019645690918 macro_avg {'precision': 0.8942297927958236, 'recall': 0.8928018822476605, 'f1-score': 0.892882558411171, 'support': 10182} weighted_avg {'precision': 0.8991646131627186, 'recall': 0.9000196425063838, 'f1-score': 0.8991028381262853, 'support': 10182}
 
time = 38.53 secondes

Val loss 0.46088602286304386 accuracy 0.879858672618866 macro_avg {'precision': 0.8875062529057969, 'recall': 0.8822480999464245, 'f1-score': 0.8795967697034286, 'support': 1132} weighted_avg {'precision': 0.889120811512215, 'recall': 0.8798586572438163, 'f1-score': 0.8787755001185383, 'support': 1132}
 
----------
Epoch 3/40
time = 1908.75 secondes

Train loss 0.21830159423615508 accuracy 0.9377332925796509 macro_avg {'precision': 0.9348357908777258, 'recall': 0.9346115524525966, 'f1-score': 0.9346213899426671, 'support': 10182} weighted_avg {'precision': 0.9379128048724401, 'recall': 0.9377332547633078, 'f1-score': 0.9377234295003632, 'support': 10182}
 
time = 40.30 secondes

Val loss 0.40330390266837995 accuracy 0.9125441908836365 macro_avg {'precision': 0.9151314506570856, 'recall': 0.9132859449544026, 'f1-score': 0.9115277587624699, 'support': 1132} weighted_avg {'precision': 0.918239450917028, 'recall': 0.9125441696113075, 'f1-score': 0.9129926859358247, 'support': 1132}
 
----------
Epoch 4/40
time = 1910.55 secondes

Train loss 0.167170140167824 accuracy 0.9550186991691589 macro_avg {'precision': 0.9536289632681811, 'recall': 0.9533919455459738, 'f1-score': 0.9534677008940127, 'support': 10182} weighted_avg {'precision': 0.9550982768604888, 'recall': 0.9550186603810646, 'f1-score': 0.9550166191368876, 'support': 10182}
 
time = 39.53 secondes

Val loss 0.4390325243748777 accuracy 0.9134275913238525 macro_avg {'precision': 0.9169355119636023, 'recall': 0.9097197947556129, 'f1-score': 0.9110208669977735, 'support': 1132} weighted_avg {'precision': 0.9173543857790867, 'recall': 0.9134275618374559, 'f1-score': 0.913372395541853, 'support': 1132}
 
----------
Epoch 5/40
time = 1909.60 secondes

Train loss 0.13766327793318836 accuracy 0.9642506837844849 macro_avg {'precision': 0.963118858128422, 'recall': 0.9631424419101673, 'f1-score': 0.9631092218764822, 'support': 10182} weighted_avg {'precision': 0.9642493126222794, 'recall': 0.9642506383814575, 'f1-score': 0.9642282693279672, 'support': 10182}
 
time = 39.07 secondes

Val loss 0.4958603046039237 accuracy 0.9063604474067688 macro_avg {'precision': 0.9147731704836743, 'recall': 0.9001813440838987, 'f1-score': 0.9041274600929144, 'support': 1132} weighted_avg {'precision': 0.910536636433018, 'recall': 0.9063604240282686, 'f1-score': 0.9055773918772159, 'support': 1132}
 
----------
Epoch 6/40
time = 1909.55 secondes

Train loss 0.1278144653248374 accuracy 0.9690631031990051 macro_avg {'precision': 0.9686596155967532, 'recall': 0.9680645374398276, 'f1-score': 0.9683305985009312, 'support': 10182} weighted_avg {'precision': 0.9690691788868356, 'recall': 0.9690630524454921, 'f1-score': 0.9690384658343896, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.5983240878460339 accuracy 0.8957597017288208 macro_avg {'precision': 0.8988604543821859, 'recall': 0.893485503886828, 'f1-score': 0.8906676904446608, 'support': 1132} weighted_avg {'precision': 0.901278459917364, 'recall': 0.8957597173144877, 'f1-score': 0.8933252110511339, 'support': 1132}
 
----------
Epoch 7/40
time = 1909.55 secondes

Train loss 0.11343008143990155 accuracy 0.9741701483726501 macro_avg {'precision': 0.9734581454190623, 'recall': 0.9733428234755808, 'f1-score': 0.9733609823657987, 'support': 10182} weighted_avg {'precision': 0.9741800836047303, 'recall': 0.9741701041052838, 'f1-score': 0.9741361739617854, 'support': 10182}
 
time = 40.32 secondes

Val loss 0.7245520907593563 accuracy 0.8842756152153015 macro_avg {'precision': 0.8921837603679006, 'recall': 0.8824649986375734, 'f1-score': 0.8830002249698236, 'support': 1132} weighted_avg {'precision': 0.8927516897604317, 'recall': 0.8842756183745583, 'f1-score': 0.8841824872471611, 'support': 1132}
 
----------
Epoch 8/40
time = 1909.75 secondes

Train loss 0.11420395336982142 accuracy 0.9743665456771851 macro_avg {'precision': 0.9736746085123285, 'recall': 0.9735967049059632, 'f1-score': 0.9736070413765034, 'support': 10182} weighted_avg {'precision': 0.9743933178250752, 'recall': 0.974366529169122, 'f1-score': 0.9743509755131652, 'support': 10182}
 
time = 39.40 secondes

Val loss 0.8220701154516551 accuracy 0.8772084712982178 macro_avg {'precision': 0.8931567094223519, 'recall': 0.8796595857899442, 'f1-score': 0.8769076972731874, 'support': 1132} weighted_avg {'precision': 0.8964092997993786, 'recall': 0.877208480565371, 'f1-score': 0.8767397605845306, 'support': 1132}
 
----------
Epoch 9/40
time = 1908.64 secondes

Train loss 0.10956418195955406 accuracy 0.976527214050293 macro_avg {'precision': 0.9758390837401996, 'recall': 0.9752474093978613, 'f1-score': 0.975513415610919, 'support': 10182} weighted_avg {'precision': 0.9765352184736995, 'recall': 0.9765272048713416, 'f1-score': 0.9765060450163512, 'support': 10182}
 
time = 39.87 secondes

Val loss 0.6684241715450132 accuracy 0.9037102460861206 macro_avg {'precision': 0.9094810188055483, 'recall': 0.9069276435400001, 'f1-score': 0.9047205484351591, 'support': 1132} weighted_avg {'precision': 0.9131524080036927, 'recall': 0.9037102473498233, 'f1-score': 0.9048151870925867, 'support': 1132}
 
----------
Epoch 10/40
time = 1911.39 secondes

Train loss 0.11217753514205216 accuracy 0.976527214050293 macro_avg {'precision': 0.9759240042393355, 'recall': 0.9760177083631083, 'f1-score': 0.9759556171993735, 'support': 10182} weighted_avg {'precision': 0.9765537290318279, 'recall': 0.9765272048713416, 'f1-score': 0.9765254081639174, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.6058615799966632 accuracy 0.9196113348007202 macro_avg {'precision': 0.9254867841946485, 'recall': 0.9206464038480459, 'f1-score': 0.9213484843391189, 'support': 1132} weighted_avg {'precision': 0.9235494414918549, 'recall': 0.9196113074204947, 'f1-score': 0.9199250448184835, 'support': 1132}
 
----------
Epoch 11/40
time = 1909.38 secondes

Train loss 0.105935125544674 accuracy 0.9794735908508301 macro_avg {'precision': 0.9792262505708834, 'recall': 0.9789824731222689, 'f1-score': 0.9790758557165041, 'support': 10182} weighted_avg {'precision': 0.9795077261628403, 'recall': 0.9794735808289138, 'f1-score': 0.9794614471096068, 'support': 10182}
 
time = 39.80 secondes

Val loss 0.6887336041459413 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131388260501497, 'recall': 0.9030057634729145, 'f1-score': 0.9030767659571618, 'support': 1132} weighted_avg {'precision': 0.9124237577930264, 'recall': 0.9028268551236749, 'f1-score': 0.9027173087032963, 'support': 1132}
 
----------
Epoch 12/40
time = 1910.59 secondes

Train loss 0.10126284972074741 accuracy 0.9801610708236694 macro_avg {'precision': 0.9799271984653691, 'recall': 0.9796845580350422, 'f1-score': 0.9797675962891758, 'support': 10182} weighted_avg {'precision': 0.9802152144509437, 'recall': 0.9801610685523473, 'f1-score': 0.9801493808749597, 'support': 10182}
 
time = 39.41 secondes

Val loss 0.6459896137787671 accuracy 0.9143109321594238 macro_avg {'precision': 0.9157103822305702, 'recall': 0.9144947352945921, 'f1-score': 0.9127582917258609, 'support': 1132} weighted_avg {'precision': 0.9173351169190597, 'recall': 0.9143109540636042, 'f1-score': 0.9136932618714839, 'support': 1132}
 
----------
Epoch 13/40
time = 1909.05 secondes

Train loss 0.0875982368280223 accuracy 0.9819289445877075 macro_avg {'precision': 0.9818301701954004, 'recall': 0.9819811273114001, 'f1-score': 0.9818792144705011, 'support': 10182} weighted_avg {'precision': 0.9819602100045404, 'recall': 0.9819288941268906, 'f1-score': 0.9819178206400212, 'support': 10182}
 
time = 39.81 secondes

Val loss 0.7624087328401568 accuracy 0.8931095600128174 macro_avg {'precision': 0.9040608183235574, 'recall': 0.8969271258193945, 'f1-score': 0.8937118050777937, 'support': 1132} weighted_avg {'precision': 0.904697506071807, 'recall': 0.8931095406360424, 'f1-score': 0.891664838614371, 'support': 1132}
 
----------
Epoch 14/40
time = 1909.42 secondes

Train loss 0.09257202683793551 accuracy 0.9830092787742615 macro_avg {'precision': 0.9826512779654568, 'recall': 0.9821824873724999, 'f1-score': 0.9823760297986149, 'support': 10182} weighted_avg {'precision': 0.9831013007333228, 'recall': 0.9830092319780004, 'f1-score': 0.9830146041423804, 'support': 10182}
 
time = 39.56 secondes

Val loss 0.7581579574864623 accuracy 0.9001767039299011 macro_avg {'precision': 0.9065109577950599, 'recall': 0.9011436394494112, 'f1-score': 0.8998883673521407, 'support': 1132} weighted_avg {'precision': 0.90729463050907, 'recall': 0.9001766784452296, 'f1-score': 0.8996065480741485, 'support': 1132}
 
----------
Epoch 15/40
time = 1909.09 secondes

Train loss 0.09834036898601499 accuracy 0.9809467792510986 macro_avg {'precision': 0.9805949913703363, 'recall': 0.9807113900831637, 'f1-score': 0.9806040141181048, 'support': 10182} weighted_avg {'precision': 0.9810396061804113, 'recall': 0.9809467688076998, 'f1-score': 0.980947042952623, 'support': 10182}
 
time = 39.67 secondes

Val loss 0.932810813280066 accuracy 0.8833922147750854 macro_avg {'precision': 0.8968407366237179, 'recall': 0.8830862564001631, 'f1-score': 0.8831612496497632, 'support': 1132} weighted_avg {'precision': 0.8982580178210453, 'recall': 0.8833922261484098, 'f1-score': 0.8838959884376227, 'support': 1132}
 
----------
Epoch 16/40
time = 1909.64 secondes

Train loss 0.0835622027550289 accuracy 0.9841877818107605 macro_avg {'precision': 0.9838873889832682, 'recall': 0.9837288215154943, 'f1-score': 0.9837867423909172, 'support': 10182} weighted_avg {'precision': 0.9842345343148707, 'recall': 0.9841877823610292, 'f1-score': 0.9841896439313582, 'support': 10182}
 
time = 39.52 secondes

Val loss 0.6462081183413368 accuracy 0.9107773900032043 macro_avg {'precision': 0.9161806451353067, 'recall': 0.9120046104897254, 'f1-score': 0.9116412449479506, 'support': 1132} weighted_avg {'precision': 0.9178876153029559, 'recall': 0.9107773851590106, 'f1-score': 0.911765415774978, 'support': 1132}
 
----------
Epoch 17/40
time = 1908.91 secondes

Train loss 0.07318664751887073 accuracy 0.9860538244247437 macro_avg {'precision': 0.985656983038357, 'recall': 0.9858153253990105, 'f1-score': 0.9857076845423199, 'support': 10182} weighted_avg {'precision': 0.9861020002815191, 'recall': 0.9860538204674917, 'f1-score': 0.9860500233098616, 'support': 10182}
 
time = 39.45 secondes

Val loss 0.640288737626102 accuracy 0.9231448769569397 macro_avg {'precision': 0.9228961684572434, 'recall': 0.9251849298570347, 'f1-score': 0.9228934584917503, 'support': 1132} weighted_avg {'precision': 0.9253714681891915, 'recall': 0.9231448763250883, 'f1-score': 0.9232018798073667, 'support': 1132}
 
----------
Epoch 18/40
time = 1910.39 secondes

Train loss 0.05692877924826645 accuracy 0.9883127212524414 macro_avg {'precision': 0.9883374009978058, 'recall': 0.9883091933112956, 'f1-score': 0.9883133878042475, 'support': 10182} weighted_avg {'precision': 0.9883234521472538, 'recall': 0.9883127087016303, 'f1-score': 0.9883078571003645, 'support': 10182}
 
time = 38.51 secondes

Val loss 0.6313100691155521 accuracy 0.916077733039856 macro_avg {'precision': 0.9205280164673922, 'recall': 0.9160253060002838, 'f1-score': 0.9165933958882494, 'support': 1132} weighted_avg {'precision': 0.919403407416757, 'recall': 0.916077738515901, 'f1-score': 0.9160528710049072, 'support': 1132}
 
----------
Epoch 19/40
time = 1908.76 secondes

Train loss 0.06651908281616571 accuracy 0.9885091781616211 macro_avg {'precision': 0.9881430190383107, 'recall': 0.9881787716350449, 'f1-score': 0.9881475363711234, 'support': 10182} weighted_avg {'precision': 0.988511897330776, 'recall': 0.9885091337654685, 'f1-score': 0.9884969271959496, 'support': 10182}
 
time = 40.14 secondes

Val loss 0.6519750257813401 accuracy 0.9134275913238525 macro_avg {'precision': 0.9199459769938481, 'recall': 0.9123775681870023, 'f1-score': 0.9137288528138295, 'support': 1132} weighted_avg {'precision': 0.916339805233741, 'recall': 0.9134275618374559, 'f1-score': 0.912840242865839, 'support': 1132}
 
----------
Epoch 20/40
time = 1909.28 secondes

Train loss 0.07116249481564131 accuracy 0.9881163239479065 macro_avg {'precision': 0.9880998091944931, 'recall': 0.9880022143227833, 'f1-score': 0.9880066392047937, 'support': 10182} weighted_avg {'precision': 0.9881852468684843, 'recall': 0.9881162836377921, 'f1-score': 0.9881049122374974, 'support': 10182}
 
time = 39.41 secondes

Val loss 0.6846689393715794 accuracy 0.9178445339202881 macro_avg {'precision': 0.9201664317654707, 'recall': 0.9197884864604056, 'f1-score': 0.9183650364055739, 'support': 1132} weighted_avg {'precision': 0.9208512496792637, 'recall': 0.9178445229681979, 'f1-score': 0.9177736248355403, 'support': 1132}
 
----------
Epoch 21/40
time = 1909.19 secondes

Train loss 0.05300863722974897 accuracy 0.9896877408027649 macro_avg {'precision': 0.9892952563526238, 'recall': 0.989350198877851, 'f1-score': 0.9893142377391084, 'support': 10182} weighted_avg {'precision': 0.9897083355542613, 'recall': 0.9896876841484974, 'f1-score': 0.9896905033431957, 'support': 10182}
 
time = 39.95 secondes

Val loss 0.8383926647221018 accuracy 0.898409903049469 macro_avg {'precision': 0.9063466726303553, 'recall': 0.8973646742841833, 'f1-score': 0.8988896934755406, 'support': 1132} weighted_avg {'precision': 0.9047223856129665, 'recall': 0.8984098939929329, 'f1-score': 0.8985842153642164, 'support': 1132}
 
----------
Epoch 22/40
time = 1911.28 secondes

Train loss 0.06965116375790764 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881676215096729, 'recall': 0.9868940967378398, 'f1-score': 0.9874301032100075, 'support': 10182} weighted_avg {'precision': 0.9886586506897446, 'recall': 0.9886073462973876, 'f1-score': 0.9885604977738306, 'support': 10182}
 
time = 39.38 secondes

Val loss 0.7193793235450178 accuracy 0.9125441908836365 macro_avg {'precision': 0.917491309835829, 'recall': 0.9119979607776211, 'f1-score': 0.9125201084867245, 'support': 1132} weighted_avg {'precision': 0.9177202387991072, 'recall': 0.9125441696113075, 'f1-score': 0.9129082479173948, 'support': 1132}
 
----------
Epoch 23/40
time = 1909.06 secondes

Train loss 0.048035009136118086 accuracy 0.9913573265075684 macro_avg {'precision': 0.9910465163522794, 'recall': 0.9910981373106011, 'f1-score': 0.9910643791955552, 'support': 10182} weighted_avg {'precision': 0.9913764394660936, 'recall': 0.9913572971911215, 'f1-score': 0.9913587306563644, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6402899378576171 accuracy 0.9213780760765076 macro_avg {'precision': 0.9274366491134497, 'recall': 0.9228166963586885, 'f1-score': 0.9236106246242672, 'support': 1132} weighted_avg {'precision': 0.9264131540301072, 'recall': 0.9213780918727915, 'f1-score': 0.9223859455862737, 'support': 1132}
 
----------
Epoch 24/40
time = 1909.22 secondes

Train loss 0.06083538519074004 accuracy 0.98978590965271 macro_avg {'precision': 0.9895304503712101, 'recall': 0.9895495686066548, 'f1-score': 0.9895263908042669, 'support': 10182} weighted_avg {'precision': 0.9898053456074727, 'recall': 0.9897858966804164, 'f1-score': 0.9897818585744753, 'support': 10182}
 
time = 39.34 secondes

Val loss 0.7233179955579595 accuracy 0.9090105891227722 macro_avg {'precision': 0.9161046582926714, 'recall': 0.9113504069028912, 'f1-score': 0.9105935742200995, 'support': 1132} weighted_avg {'precision': 0.9154776799805039, 'recall': 0.9090106007067138, 'f1-score': 0.9091087522825461, 'support': 1132}
 
----------
Epoch 25/40
time = 1909.07 secondes

Train loss 0.039563348141596046 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918336956256942, 'recall': 0.9916336169762061, 'f1-score': 0.9917221318965993, 'support': 10182} weighted_avg {'precision': 0.9921727133196265, 'recall': 0.9921429974464742, 'f1-score': 0.9921466006224027, 'support': 10182}
 
time = 40.17 secondes

Val loss 0.6303446873247031 accuracy 0.9231448769569397 macro_avg {'precision': 0.9314075403017965, 'recall': 0.9250527042591619, 'f1-score': 0.9258693500818433, 'support': 1132} weighted_avg {'precision': 0.9290963559400797, 'recall': 0.9231448763250883, 'f1-score': 0.923600842088214, 'support': 1132}
 
----------
Epoch 26/40
time = 1909.96 secondes

Train loss 0.04797554284569275 accuracy 0.9912590980529785 macro_avg {'precision': 0.9912095678789395, 'recall': 0.9908239963475902, 'f1-score': 0.9910094540964381, 'support': 10182} weighted_avg {'precision': 0.9912563747527677, 'recall': 0.9912590846592025, 'f1-score': 0.9912513256659231, 'support': 10182}
 
time = 39.19 secondes

Val loss 0.6050276190492273 accuracy 0.9275618195533752 macro_avg {'precision': 0.9302510342889931, 'recall': 0.9293476528646624, 'f1-score': 0.9286156491381921, 'support': 1132} weighted_avg {'precision': 0.9319015773406718, 'recall': 0.9275618374558304, 'f1-score': 0.92846789641746, 'support': 1132}
 
----------
Epoch 27/40
time = 1909.34 secondes

Train loss 0.037623642903953064 accuracy 0.992634117603302 macro_avg {'precision': 0.9925807778727632, 'recall': 0.992564290038837, 'f1-score': 0.9925655340195417, 'support': 10182} weighted_avg {'precision': 0.9926542708047015, 'recall': 0.9926340601060696, 'f1-score': 0.992637112821043, 'support': 10182}
 
time = 39.79 secondes

Val loss 0.6339351251003215 accuracy 0.9293286204338074 macro_avg {'precision': 0.9353044113446541, 'recall': 0.9299563894916206, 'f1-score': 0.9299468461676466, 'support': 1132} weighted_avg {'precision': 0.936027873800648, 'recall': 0.9293286219081273, 'f1-score': 0.9300308334653564, 'support': 1132}
 
----------
Epoch 28/40
time = 1909.05 secondes

Train loss 0.032646341550333795 accuracy 0.993714451789856 macro_avg {'precision': 0.9937246911993736, 'recall': 0.9936458791319266, 'f1-score': 0.9936804513640489, 'support': 10182} weighted_avg {'precision': 0.9937221453883613, 'recall': 0.9937143979571793, 'f1-score': 0.993713431200899, 'support': 10182}
 
time = 38.29 secondes

Val loss 0.6690042207819843 accuracy 0.9222614765167236 macro_avg {'precision': 0.9258793598045172, 'recall': 0.9233637652495338, 'f1-score': 0.9232805283307789, 'support': 1132} weighted_avg {'precision': 0.9260187243716778, 'recall': 0.9222614840989399, 'f1-score': 0.9227162617450433, 'support': 1132}
 
----------
Epoch 29/40
time = 1908.64 secondes

Train loss 0.03491280625829897 accuracy 0.9943037033081055 macro_avg {'precision': 0.9943444936358545, 'recall': 0.994083901376692, 'f1-score': 0.9942009611100051, 'support': 10182} weighted_avg {'precision': 0.9943269559885646, 'recall': 0.9943036731486937, 'f1-score': 0.9943033000109757, 'support': 10182}
 
time = 40.38 secondes

Val loss 0.6949095411685153 accuracy 0.916077733039856 macro_avg {'precision': 0.9215707163863709, 'recall': 0.9180254059301447, 'f1-score': 0.9174566541015358, 'support': 1132} weighted_avg {'precision': 0.9222765311077341, 'recall': 0.916077738515901, 'f1-score': 0.9167632515041262, 'support': 1132}
 
----------
Epoch 30/40
time = 1909.09 secondes

Train loss 0.03229863670169447 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945541448522427, 'recall': 0.9940212389337522, 'f1-score': 0.9942669956451022, 'support': 10182} weighted_avg {'precision': 0.9946226466479359, 'recall': 0.994598310744451, 'f1-score': 0.9945931329603148, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6782469018012499 accuracy 0.9213780760765076 macro_avg {'precision': 0.9234129538994523, 'recall': 0.9223355896450613, 'f1-score': 0.9216596726909889, 'support': 1132} weighted_avg {'precision': 0.9244205081136757, 'recall': 0.9213780918727915, 'f1-score': 0.9216312969535241, 'support': 1132}
 
----------
Epoch 31/40
time = 1909.36 secondes

Train loss 0.02550504969776325 accuracy 0.9956786632537842 macro_avg {'precision': 0.9955803882293403, 'recall': 0.9956658400852305, 'f1-score': 0.9956199562977284, 'support': 10182} weighted_avg {'precision': 0.9956904691661012, 'recall': 0.9956786485955608, 'f1-score': 0.9956814668256424, 'support': 10182}
 
time = 40.02 secondes

Val loss 0.6430131894406477 accuracy 0.926678478717804 macro_avg {'precision': 0.9304651124722747, 'recall': 0.9282103145398658, 'f1-score': 0.9280789830433541, 'support': 1132} weighted_avg {'precision': 0.9292600535211959, 'recall': 0.926678445229682, 'f1-score': 0.9266675770889872, 'support': 1132}
 
----------
Epoch 32/40
time = 1908.88 secondes

Train loss 0.02821248961966774 accuracy 0.9949911832809448 macro_avg {'precision': 0.9948742212770648, 'recall': 0.9949433663675104, 'f1-score': 0.9948982510687484, 'support': 10182} weighted_avg {'precision': 0.9950094143897416, 'recall': 0.9949911608721272, 'f1-score': 0.9949894876168847, 'support': 10182}
 
time = 39.02 secondes

Val loss 0.6624094739029677 accuracy 0.9257950782775879 macro_avg {'precision': 0.93184871590975, 'recall': 0.9276566091978131, 'f1-score': 0.9279351175860615, 'support': 1132} weighted_avg {'precision': 0.9318658488026749, 'recall': 0.9257950530035336, 'f1-score': 0.9269023287375748, 'support': 1132}
 
----------
Epoch 33/40
time = 1909.52 secondes

Train loss 0.02004615105625978 accuracy 0.9965626001358032 macro_avg {'precision': 0.9964150881822272, 'recall': 0.996552136791377, 'f1-score': 0.9964700264955505, 'support': 10182} weighted_avg {'precision': 0.9965832191212305, 'recall': 0.9965625613828325, 'f1-score': 0.9965594361405176, 'support': 10182}
 
time = 39.80 secondes

Val loss 0.639866872846385 accuracy 0.9196113348007202 macro_avg {'precision': 0.9255752284528205, 'recall': 0.9216602065323081, 'f1-score': 0.9212465496441752, 'support': 1132} weighted_avg {'precision': 0.9269286127556876, 'recall': 0.9196113074204947, 'f1-score': 0.9208447448387884, 'support': 1132}
 
----------
Epoch 34/40
time = 1908.36 secondes

Train loss 0.020469085694647938 accuracy 0.9966608285903931 macro_avg {'precision': 0.9965687393142485, 'recall': 0.9964580640730734, 'f1-score': 0.9965097461461795, 'support': 10182} weighted_avg {'precision': 0.9966667251905952, 'recall': 0.9966607739147515, 'f1-score': 0.996660534634597, 'support': 10182}
 
time = 39.09 secondes

Val loss 0.5968756691197509 accuracy 0.9284452199935913 macro_avg {'precision': 0.9312284460228968, 'recall': 0.9301803714595648, 'f1-score': 0.9295810463108707, 'support': 1132} weighted_avg {'precision': 0.931915592810522, 'recall': 0.9284452296819788, 'f1-score': 0.9289514922368795, 'support': 1132}
 
----------
Epoch 35/40
time = 1908.24 secondes

Train loss 0.012203871144432627 accuracy 0.9972500801086426 macro_avg {'precision': 0.997226065579515, 'recall': 0.9971572445096024, 'f1-score': 0.9971888107012928, 'support': 10182} weighted_avg {'precision': 0.9972555869419738, 'recall': 0.9972500491062659, 'f1-score': 0.9972499666092575, 'support': 10182}
 
time = 39.23 secondes

Val loss 0.6195066794899362 accuracy 0.926678478717804 macro_avg {'precision': 0.9298107259966082, 'recall': 0.9283921311554708, 'f1-score': 0.9273330151144362, 'support': 1132} weighted_avg {'precision': 0.9315746896475453, 'recall': 0.926678445229682, 'f1-score': 0.9272636676997998, 'support': 1132}
 
----------
Epoch 36/40
time = 1909.27 secondes

Train loss 0.01824775704706702 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971618373279526, 'recall': 0.9971895549285748, 'f1-score': 0.9971737261492954, 'support': 10182} weighted_avg {'precision': 0.9971580950120631, 'recall': 0.9971518365743469, 'f1-score': 0.9971529804756388, 'support': 10182}
 
time = 39.34 secondes

Val loss 0.6467199377327144 accuracy 0.9284452199935913 macro_avg {'precision': 0.9348181807533835, 'recall': 0.9294793210424042, 'f1-score': 0.9303337756119173, 'support': 1132} weighted_avg {'precision': 0.9337467155385072, 'recall': 0.9284452296819788, 'f1-score': 0.9292228966674563, 'support': 1132}
 
----------
Epoch 37/40
time = 1907.79 secondes

Train loss 0.009721664404243891 accuracy 0.9981340169906616 macro_avg {'precision': 0.998184276211121, 'recall': 0.9981634617425795, 'f1-score': 0.9981703566774864, 'support': 10182} weighted_avg {'precision': 0.9981384889128613, 'recall': 0.9981339618935376, 'f1-score': 0.9981326522019919, 'support': 10182}
 
time = 39.40 secondes

Val loss 0.6048776923446856 accuracy 0.9310954213142395 macro_avg {'precision': 0.9323433091836245, 'recall': 0.930029615673749, 'f1-score': 0.9298989428218887, 'support': 1132} weighted_avg {'precision': 0.9327771368455564, 'recall': 0.931095406360424, 'f1-score': 0.9307076772049082, 'support': 1132}
 
----------
Epoch 38/40
time = 1908.64 secondes

Train loss 0.006326359854966901 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990525285964097, 'recall': 0.9990099778142989, 'f1-score': 0.9990306543694972, 'support': 10182} weighted_avg {'precision': 0.9990186296345368, 'recall': 0.9990178746808093, 'f1-score': 0.9990176702493204, 'support': 10182}
 
time = 39.42 secondes

Val loss 0.6266892918643657 accuracy 0.9319788217544556 macro_avg {'precision': 0.9348972837256839, 'recall': 0.9332731825797754, 'f1-score': 0.9326439593721213, 'support': 1132} weighted_avg {'precision': 0.9354200621783917, 'recall': 0.9319787985865724, 'f1-score': 0.932156609484244, 'support': 1132}
 
----------
Epoch 39/40
time = 1909.80 secondes

Train loss 0.008169731699238082 accuracy 0.9986250400543213 macro_avg {'precision': 0.998660362144226, 'recall': 0.9985589346768678, 'f1-score': 0.9986085531921413, 'support': 10182} weighted_avg {'precision': 0.9986265462565532, 'recall': 0.998625024553133, 'f1-score': 0.9986248310917379, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.5921028292556566 accuracy 0.9319788217544556 macro_avg {'precision': 0.9350589491445861, 'recall': 0.9346573637579306, 'f1-score': 0.9340231011814026, 'support': 1132} weighted_avg {'precision': 0.9346340096577599, 'recall': 0.9319787985865724, 'f1-score': 0.9324318427169855, 'support': 1132}
 
----------
Epoch 40/40
time = 1907.59 secondes

Train loss 0.0033951027634054414 accuracy 0.9993125200271606 macro_avg {'precision': 0.9993473731774174, 'recall': 0.9992919811524137, 'f1-score': 0.9993191707889171, 'support': 10182} weighted_avg {'precision': 0.9993132492051352, 'recall': 0.9993125122765665, 'f1-score': 0.9993123929650052, 'support': 10182}
 
time = 39.52 secondes

Val loss 0.6252623127515569 accuracy 0.9319788217544556 macro_avg {'precision': 0.9336285320386436, 'recall': 0.9341665349908821, 'f1-score': 0.9330379804243488, 'support': 1132} weighted_avg {'precision': 0.933727039172477, 'recall': 0.9319787985865724, 'f1-score': 0.9319696077182962, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 38 macro_avg {'precision': 0.9348972837256839, 'recall': 0.9332731825797754, 'f1-score': 0.9326439593721213, 'support': 1132} weighted_avg {'precision': 0.9354200621783917, 'recall': 0.9319787985865724, 'f1-score': 0.932156609484244, 'support': 1132}

average train time 1909.307525497675

average val time 39.54058667421341
 
time = 258.98 secondes

test_accuracy 0.8663037419319153 macro_avg {'precision': 0.8656628464963416, 'recall': 0.8591149054203816, 'f1-score': 0.8598638394301966, 'support': 7532} weighted_avg {'precision': 0.8694824551205013, 'recall': 0.8663037705788635, 'f1-score': 0.865669260681477, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.05 GiB already allocated; 453.62 MiB free; 76.73 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 1.49 GiB free; 75.69 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_3
----------
Epoch 1/40
time = 35.94 secondes

Train loss 0.6427987506895354 accuracy 0.6375969052314758 macro_avg {'precision': 0.5829439252336448, 'recall': 0.5507777579116753, 'f1-score': 0.5364861294583884, 'support': 516} weighted_avg {'precision': 0.6057695790770122, 'recall': 0.6375968992248062, 'f1-score': 0.5960617697356968, 'support': 516}
 
time = 1.54 secondes

Val loss 0.627983033657074 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 2/40
time = 34.33 secondes

Train loss 0.41521984474225476 accuracy 0.8488371968269348 macro_avg {'precision': 0.8460152217653749, 'recall': 0.8214488890333697, 'f1-score': 0.8309134906231095, 'support': 516} weighted_avg {'precision': 0.8480808002718027, 'recall': 0.8488372093023255, 'f1-score': 0.8460633004591135, 'support': 516}
 
time = 1.51 secondes

Val loss 0.35225366055965424 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 3/40
time = 34.56 secondes

Train loss 0.3211212113048091 accuracy 0.8701550364494324 macro_avg {'precision': 0.8588149822408783, 'recall': 0.8612470133120946, 'f1-score': 0.8599955453864377, 'support': 516} weighted_avg {'precision': 0.8706553353708141, 'recall': 0.8701550387596899, 'f1-score': 0.8703743084008393, 'support': 516}
 
time = 1.53 secondes

Val loss 0.44073089584708214 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 4/40
time = 34.40 secondes

Train loss 0.23170202936638484 accuracy 0.8972868323326111 macro_avg {'precision': 0.8891984359726295, 'recall': 0.8882938088194658, 'f1-score': 0.8887419804968939, 'support': 516} weighted_avg {'precision': 0.897174483014693, 'recall': 0.8972868217054264, 'f1-score': 0.8972270675711009, 'support': 516}
 
time = 1.52 secondes

Val loss 0.8356140479445457 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 5/40
time = 34.98 secondes

Train loss 0.1612522087313912 accuracy 0.9515503644943237 macro_avg {'precision': 0.9462867290926703, 'recall': 0.9493116395494368, 'f1-score': 0.947759531860611, 'support': 516} weighted_avg {'precision': 0.951782607825027, 'recall': 0.9515503875968992, 'f1-score': 0.9516322046271788, 'support': 516}
 
time = 1.51 secondes

Val loss 0.40065275877714157 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 6/40
time = 34.42 secondes

Train loss 0.18590289204748292 accuracy 0.9399224519729614 macro_avg {'precision': 0.9494526053215078, 'recall': 0.9217284592753929, 'f1-score': 0.933079809731792, 'support': 516} weighted_avg {'precision': 0.9422543196428265, 'recall': 0.939922480620155, 'f1-score': 0.9389686537690499, 'support': 516}
 
time = 1.49 secondes

Val loss 1.0198391675949097 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 7/40
time = 34.44 secondes

Train loss 0.2496655656476364 accuracy 0.9263566136360168 macro_avg {'precision': 0.9229652840768533, 'recall': 0.9168603611657429, 'f1-score': 0.919755107386066, 'support': 516} weighted_avg {'precision': 0.926092331609331, 'recall': 0.9263565891472868, 'f1-score': 0.9260889615083184, 'support': 516}
 
time = 1.50 secondes

Val loss 1.0073904395103455 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 8/40
time = 34.44 secondes

Train loss 0.09712644319656785 accuracy 0.9709302186965942 macro_avg {'precision': 0.9654383044118588, 'recall': 0.972587487606261, 'f1-score': 0.9687942233027322, 'support': 516} weighted_avg {'precision': 0.9715309121991389, 'recall': 0.9709302325581395, 'f1-score': 0.9710409885936052, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0301872491836548 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 9/40
time = 34.59 secondes

Train loss 0.16457785826500956 accuracy 0.9554263353347778 macro_avg {'precision': 0.9532477737035097, 'recall': 0.9500430733221723, 'f1-score': 0.9516048134208155, 'support': 516} weighted_avg {'precision': 0.9553380356613511, 'recall': 0.9554263565891473, 'f1-score': 0.9553472901787681, 'support': 516}
 
time = 1.53 secondes

Val loss 1.7084228694438934 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 34.74 secondes

Train loss 0.06565111438447441 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.51 secondes

Val loss 0.7497517317533493 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 11/40
time = 34.47 secondes

Train loss 0.13306954025756568 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 1.51 secondes

Val loss 1.056972086429596 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 12/40
time = 34.43 secondes

Train loss 0.11943735280356398 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9265792965888977 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 13/40
time = 34.77 secondes

Train loss 0.652985708362945 accuracy 0.8740310072898865 macro_avg {'precision': 0.8621881115459883, 'recall': 0.8850592461355915, 'f1-score': 0.8685896305699543, 'support': 516} weighted_avg {'precision': 0.8869188653878244, 'recall': 0.874031007751938, 'f1-score': 0.8759484454255895, 'support': 516}
 
time = 1.52 secondes

Val loss 0.9831929951906204 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 14/40
time = 34.96 secondes

Train loss 0.27060735391128354 accuracy 0.9379844665527344 macro_avg {'precision': 0.9270919120503458, 'recall': 0.9467516213448629, 'f1-score': 0.9345624019149374, 'support': 516} weighted_avg {'precision': 0.943546666714849, 'recall': 0.937984496124031, 'f1-score': 0.9386805152852027, 'support': 516}
 
time = 1.50 secondes

Val loss 0.9303063675761223 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 15/40
time = 34.22 secondes

Train loss 0.5785835078797501 accuracy 0.9031007885932922 macro_avg {'precision': 0.9340369393139842, 'recall': 0.8663101604278075, 'f1-score': 0.8875287717095626, 'support': 516} weighted_avg {'precision': 0.9158843140864371, 'recall': 0.9031007751937985, 'f1-score': 0.8990455659531119, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4871693551540375 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 16/40
time = 34.41 secondes

Train loss 0.4743832769436818 accuracy 0.9011628031730652 macro_avg {'precision': 0.8915895061728395, 'recall': 0.8959494823074297, 'f1-score': 0.8936671421125151, 'support': 516} weighted_avg {'precision': 0.9018880395253135, 'recall': 0.9011627906976745, 'f1-score': 0.901436354514651, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3473591208457947 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 17/40
time = 34.57 secondes

Train loss 0.023122451233741067 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.53 secondes

Val loss 1.086848497390747 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 18/40
time = 34.74 secondes

Train loss 0.06081560684039935 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.51 secondes

Val loss 2.2231622636318207 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 19/40
time = 34.52 secondes

Train loss 0.04740368137197837 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.51 secondes

Val loss 1.3459680527448654 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 20/40
time = 34.35 secondes

Train loss 0.30731005633909564 accuracy 0.9457364082336426 macro_avg {'precision': 0.9607843137254901, 'recall': 0.9251336898395721, 'f1-score': 0.9391294089890292, 'support': 516} weighted_avg {'precision': 0.9499924000607995, 'recall': 0.9457364341085271, 'f1-score': 0.9446482182064923, 'support': 516}
 
time = 1.51 secondes

Val loss 0.821805733256042 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 21/40
time = 34.03 secondes

Train loss 0.009266755949338954 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4930856823921204 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 22/40
time = 35.02 secondes

Train loss 0.13188876525876395 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.51 secondes

Val loss 1.2625202387571335 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 23/40
time = 34.26 secondes

Train loss 0.10236564248087675 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.51 secondes

Val loss 1.284340888261795 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 24/40
time = 35.03 secondes

Train loss 0.03834887223417878 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.51 secondes

Val loss 1.3452790081501007 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 25/40
time = 34.24 secondes

Train loss 0.03126708064607528 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.51 secondes

Val loss 2.0385454893112183 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 34.22 secondes

Train loss 0.12682165308224008 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 1.50 secondes

Val loss 1.06238953769207 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 34.21 secondes

Train loss 0.030288236914643538 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8955617845058441 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 28/40
time = 34.28 secondes

Train loss 0.013736556415096857 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5125191807746887 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 29/40
time = 34.34 secondes

Train loss 0.033706825374710286 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8462360799312592 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 30/40
time = 34.89 secondes

Train loss 0.1642352013234014 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.51 secondes

Val loss 1.1116810161620378 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 31/40
time = 34.17 secondes

Train loss 0.014838638520097558 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4958850145339966 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 32/40
time = 34.36 secondes

Train loss 0.005273106050784311 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 2.0199357867240906 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 33/40
time = 34.36 secondes

Train loss 6.159410380253878e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4170300886034966 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 34/40
time = 34.65 secondes

Train loss 0.03047764519192931 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.52 secondes

Val loss 1.0500876915175468 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 35/40
time = 34.45 secondes

Train loss 0.0029360620650219394 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4636386930942535 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 36/40
time = 34.35 secondes

Train loss 0.052121528063170525 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.49 secondes

Val loss 2.4860389828681946 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 37/40
time = 34.19 secondes

Train loss 4.471662726824764e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5338240563869476 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 38/40
time = 35.09 secondes

Train loss 0.018431730405692095 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.54 secondes

Val loss 1.2899591773748398 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 39/40
time = 34.20 secondes

Train loss 8.354880838217495e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5789024084806442 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 40/40
time = 34.26 secondes

Train loss 5.249976201219287e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6116719096899033 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 34 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}

average train time 34.52156611680984

average val time 1.510578691959381
 
time = 1.84 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_3
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 20.66 secondes

Train loss 0.6150850518183275 accuracy 0.6879844665527344 macro_avg {'precision': 0.8030864197530865, 'recall': 0.5718267964826163, 'f1-score': 0.5302592519295468, 'support': 516} weighted_avg {'precision': 0.7672432768685998, 'recall': 0.687984496124031, 'f1-score': 0.605165555192479, 'support': 516}
 
time = 1.14 secondes

Val loss 0.5449104681611061 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 20.35 secondes

Train loss 0.49243062553983746 accuracy 0.7926356792449951 macro_avg {'precision': 0.780236451140406, 'recall': 0.7612193813695691, 'f1-score': 0.7683739779415775, 'support': 516} weighted_avg {'precision': 0.7894066985568322, 'recall': 0.7926356589147286, 'f1-score': 0.7890036707450953, 'support': 516}
 
time = 1.15 secondes

Val loss 0.4986915737390518 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 20.33 secondes

Train loss 0.29663675526777905 accuracy 0.8817829489707947 macro_avg {'precision': 0.8736757254721327, 'recall': 0.8692115143929913, 'f1-score': 0.8713411568504825, 'support': 516} weighted_avg {'precision': 0.8812495759822038, 'recall': 0.8817829457364341, 'f1-score': 0.8814277828491568, 'support': 516}
 
time = 1.14 secondes

Val loss 0.41714432276785374 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 4/40
time = 21.13 secondes

Train loss 0.24324111595298303 accuracy 0.9205426573753357 macro_avg {'precision': 0.913661131292164, 'recall': 0.9146091705541017, 'f1-score': 0.914130898021309, 'support': 516} weighted_avg {'precision': 0.9206409428641541, 'recall': 0.9205426356589147, 'f1-score': 0.9205881089754935, 'support': 516}
 
time = 1.14 secondes

Val loss 0.5154814347624779 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 5/40
time = 20.37 secondes

Train loss 0.2689566743193251 accuracy 0.8972868323326111 macro_avg {'precision': 0.8850925925925925, 'recall': 0.905604408107537, 'f1-score': 0.8921128105188826, 'support': 516} weighted_avg {'precision': 0.9057066465690496, 'recall': 0.8972868217054264, 'f1-score': 0.8986146652842738, 'support': 516}
 
time = 1.15 secondes

Val loss 0.9954583942890167 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 6/40
time = 20.41 secondes

Train loss 0.19110875559801405 accuracy 0.9399224519729614 macro_avg {'precision': 0.9407085561497326, 'recall': 0.9286526989906214, 'f1-score': 0.9341313666629606, 'support': 516} weighted_avg {'precision': 0.9400279297765618, 'recall': 0.939922480620155, 'f1-score': 0.9395061260219253, 'support': 516}
 
time = 1.14 secondes

Val loss 0.846051536500454 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 7/40
time = 20.35 secondes

Train loss 0.16133773791123973 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.14 secondes

Val loss 0.49940283223986626 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 20.36 secondes

Train loss 0.10577763073767225 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7077684327960014 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 9/40
time = 20.36 secondes

Train loss 0.10156771396710114 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 1.14 secondes

Val loss 0.8040197193622589 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 10/40
time = 21.21 secondes

Train loss 0.17812027470349814 accuracy 0.9437984228134155 macro_avg {'precision': 0.9365275020810655, 'recall': 0.9432326121938137, 'f1-score': 0.9396688317186157, 'support': 516} weighted_avg {'precision': 0.9445937094986431, 'recall': 0.9437984496124031, 'f1-score': 0.9440125779476365, 'support': 516}
 
time = 1.14 secondes

Val loss 0.6945641711354256 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 11/40
time = 20.36 secondes

Train loss 0.10064303960340719 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 1.15 secondes

Val loss 2.1196420192718506 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 12/40
time = 20.40 secondes

Train loss 0.2668800059014536 accuracy 0.9457364082336426 macro_avg {'precision': 0.9588662409238037, 'recall': 0.9262877297921103, 'f1-score': 0.9393022786852188, 'support': 516} weighted_avg {'precision': 0.9492557637703538, 'recall': 0.9457364341085271, 'f1-score': 0.9447406719596818, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2297129780054092 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 13/40
time = 20.39 secondes

Train loss 0.10754935715389861 accuracy 0.9748061895370483 macro_avg {'precision': 0.9688137755102041, 'recall': 0.9779350811891487, 'f1-score': 0.9730133123061389, 'support': 516} weighted_avg {'precision': 0.9756760698465433, 'recall': 0.9748062015503876, 'f1-score': 0.9749275248827052, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2132937163114548 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 14/40
time = 20.39 secondes

Train loss 0.14855017428018266 accuracy 0.9651162624359131 macro_avg {'precision': 0.9565306347282772, 'recall': 0.9714903369471579, 'f1-score': 0.9629043853342919, 'support': 516} weighted_avg {'precision': 0.9676139210600191, 'recall': 0.9651162790697675, 'f1-score': 0.9653971544647485, 'support': 516}
 
time = 1.09 secondes

Val loss 1.4484840482473373 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 15/40
time = 20.88 secondes

Train loss 0.057867132794027304 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 1.13 secondes

Val loss 1.1476810947060585 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 16/40
time = 20.58 secondes

Train loss 0.09303454872728749 accuracy 0.9825581312179565 macro_avg {'precision': 0.9816715542521994, 'recall': 0.9805519886871576, 'f1-score': 0.9811071287636235, 'support': 516} weighted_avg {'precision': 0.982545825850402, 'recall': 0.9825581395348837, 'f1-score': 0.9825479926064133, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0252512507140636 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 17/40
time = 20.38 secondes

Train loss 0.0669932525206329 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.15 secondes

Val loss 0.91978891970939 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 18/40
time = 20.34 secondes

Train loss 0.09030602267012 accuracy 0.9806201457977295 macro_avg {'precision': 0.9812927681780141, 'recall': 0.9767241519431757, 'f1-score': 0.978933616395852, 'support': 516} weighted_avg {'precision': 0.98065602773952, 'recall': 0.9806201550387597, 'f1-score': 0.9805739485005979, 'support': 516}
 
time = 1.15 secondes

Val loss 1.1071563363075256 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 20.33 secondes

Train loss 0.10587729399258299 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.15 secondes

Val loss 1.7372808754444122 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 20/40
time = 20.34 secondes

Train loss 0.73957175303561 accuracy 0.8527131676673889 macro_avg {'precision': 0.8501780910443499, 'recall': 0.8787282804804708, 'f1-score': 0.8494471744471744, 'support': 516} weighted_avg {'precision': 0.8861763299975266, 'recall': 0.8527131782945736, 'f1-score': 0.8555494447936308, 'support': 516}
 
time = 1.09 secondes

Val loss 1.7515232563018799 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 21/40
time = 20.35 secondes

Train loss 0.033175966924649074 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.13 secondes

Val loss 1.1205361570464447 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 22/40
time = 20.34 secondes

Train loss 0.21441098638002365 accuracy 0.9573643207550049 macro_avg {'precision': 0.9473684210526316, 'recall': 0.9665653495440729, 'f1-score': 0.9549266247379455, 'support': 516} weighted_avg {'precision': 0.9618523051815586, 'recall': 0.9573643410852714, 'f1-score': 0.9578112557489479, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1600159681402147 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 23/40
time = 20.37 secondes

Train loss 0.0640839045006556 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.14 secondes

Val loss 2.094721406698227 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 21.02 secondes

Train loss 0.14658576784087485 accuracy 0.9728682041168213 macro_avg {'precision': 0.9696616669093734, 'recall': 0.9717991645400907, 'f1-score': 0.9707122470160872, 'support': 516} weighted_avg {'precision': 0.9729611605367241, 'recall': 0.9728682170542635, 'f1-score': 0.9728990166262376, 'support': 516}
 
time = 1.15 secondes

Val loss 1.0376194594573462 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 25/40
time = 20.33 secondes

Train loss 0.11592590948743181 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 1.05 secondes

Val loss 1.4812840670347214 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 20.34 secondes

Train loss 0.060767630633728746 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.15 secondes

Val loss 1.3490205744747072 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 27/40
time = 20.59 secondes

Train loss 0.03772304567092127 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1152153313159943 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 28/40
time = 20.80 secondes

Train loss 0.0146385838505177 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.418574720621109 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 29/40
time = 20.41 secondes

Train loss 0.033739897641653166 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9189156889915466 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 30/40
time = 20.39 secondes

Train loss 0.000292741288307518 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.13 secondes

Val loss 1.183428969066881 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 31/40
time = 20.35 secondes

Train loss 0.09065089437397987 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.17 secondes

Val loss 1.2033831626176834 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 32/40
time = 20.41 secondes

Train loss 0.1884422080053782 accuracy 0.9709302186965942 macro_avg {'precision': 0.9628712871287128, 'recall': 0.9772036474164134, 'f1-score': 0.9690557196943952, 'support': 516} weighted_avg {'precision': 0.9730888786553075, 'recall': 0.9709302325581395, 'f1-score': 0.9711516317152747, 'support': 516}
 
time = 1.15 secondes

Val loss 1.8796826303005219 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 33/40
time = 20.52 secondes

Train loss 0.19469474034540876 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.16 secondes

Val loss 1.5309618711471558 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 34/40
time = 20.45 secondes

Train loss 0.0022319404551209036 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4264078810811043 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 35/40
time = 20.36 secondes

Train loss 0.0004439156797492284 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 2.5808774828910828 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 36/40
time = 20.40 secondes

Train loss 0.05661277513067806 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.14 secondes

Val loss 1.3911480009555817 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 37/40
time = 20.35 secondes

Train loss 0.002033620828032409 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0580894348677248 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 38/40
time = 20.97 secondes

Train loss 0.009768449010373319 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.13 secondes

Val loss 1.14921984821558 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 39/40
time = 20.35 secondes

Train loss 0.00024115803446902922 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7932339906692505 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 40/40
time = 20.38 secondes

Train loss 0.00019269286889484096 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9437332153320312 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 3 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}

average train time 20.484560865163804

average val time 1.1382619917392731
 
time = 1.27 secondes

test_accuracy 0.8307692408561707 macro_avg {'precision': 0.8387949260042283, 'recall': 0.8123781676413255, 'f1-score': 0.819853867472915, 'support': 65} weighted_avg {'precision': 0.834590990404944, 'recall': 0.8307692307692308, 'f1-score': 0.8273581797391321, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_3
----------
Epoch 1/40
time = 96.55 secondes

Train loss 0.6236782959013274 accuracy 0.6492248177528381 macro_avg {'precision': 0.6137733574442434, 'recall': 0.5368154998943485, 'f1-score': 0.492101127322758, 'support': 516} weighted_avg {'precision': 0.6254263799524323, 'recall': 0.6492248062015504, 'f1-score': 0.5698417628655751, 'support': 516}
 
time = 3.19 secondes

Val loss 0.5558886229991913 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 96.38 secondes

Train loss 0.42858401347290387 accuracy 0.817829430103302 macro_avg {'precision': 0.8046597670116493, 'recall': 0.7971327796108773, 'f1-score': 0.8005198394419951, 'support': 516} weighted_avg {'precision': 0.8162035696664779, 'recall': 0.8178294573643411, 'f1-score': 0.8166906667115551, 'support': 516}
 
time = 3.18 secondes

Val loss 0.5284586399793625 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 3/40
time = 97.40 secondes

Train loss 0.2707735714361523 accuracy 0.8972868323326111 macro_avg {'precision': 0.8976806239737274, 'recall': 0.8779074492466232, 'f1-score': 0.8862088335032351, 'support': 516} weighted_avg {'precision': 0.8973699577398455, 'recall': 0.8972868217054264, 'f1-score': 0.8959794814828075, 'support': 516}
 
time = 3.19 secondes

Val loss 0.3035033792257309 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 4/40
time = 96.87 secondes

Train loss 0.17210246289544034 accuracy 0.9379844665527344 macro_avg {'precision': 0.9404607425133554, 'recall': 0.9248248622466395, 'f1-score': 0.9317460317460317, 'support': 516} weighted_avg {'precision': 0.938392348470508, 'recall': 0.937984496124031, 'f1-score': 0.9374246339362619, 'support': 516}
 
time = 3.17 secondes

Val loss 0.4491608738899231 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 5/40
time = 96.89 secondes

Train loss 0.2384218110448935 accuracy 0.9263566136360168 macro_avg {'precision': 0.9176611550443325, 'recall': 0.9249386408335094, 'f1-score': 0.9210310108739428, 'support': 516} weighted_avg {'precision': 0.9274607712555984, 'recall': 0.9263565891472868, 'f1-score': 0.9266745341188296, 'support': 516}
 
time = 3.20 secondes

Val loss 1.5974602401256561 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 6/40
time = 98.15 secondes

Train loss 0.36979316790221317 accuracy 0.9089147448539734 macro_avg {'precision': 0.9302665679378008, 'recall': 0.8777936706597532, 'f1-score': 0.8958099730631919, 'support': 516} weighted_avg {'precision': 0.9167310269811065, 'recall': 0.9089147286821705, 'f1-score': 0.9059786905380277, 'support': 516}
 
time = 3.15 secondes

Val loss 0.5389043539762497 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 7/40
time = 96.82 secondes

Train loss 0.4002409873911264 accuracy 0.9031007885932922 macro_avg {'precision': 0.8909961418677079, 'recall': 0.9101636786242544, 'f1-score': 0.8979430379746836, 'support': 516} weighted_avg {'precision': 0.9100945633377618, 'recall': 0.9031007751937985, 'f1-score': 0.9042568197429104, 'support': 516}
 
time = 3.18 secondes

Val loss 0.7757201343774796 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 8/40
time = 96.59 secondes

Train loss 0.16939899839714848 accuracy 0.9593023061752319 macro_avg {'precision': 0.954617371649984, 'recall': 0.9576987468101361, 'f1-score': 0.9561180067629134, 'support': 516} weighted_avg {'precision': 0.9595090147254282, 'recall': 0.9593023255813954, 'f1-score': 0.9593710518868303, 'support': 516}
 
time = 3.17 secondes

Val loss 0.8188567534089088 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 9/40
time = 97.47 secondes

Train loss 0.0562212597014326 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 3.18 secondes

Val loss 0.7544961422681808 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 10/40
time = 97.10 secondes

Train loss 0.19417538091356895 accuracy 0.9534883499145508 macro_avg {'precision': 0.9516565746073943, 'recall': 0.9473692765307284, 'f1-score': 0.949440679350045, 'support': 516} weighted_avg {'precision': 0.953390676227123, 'recall': 0.9534883720930233, 'f1-score': 0.9533774764014349, 'support': 516}
 
time = 3.02 secondes

Val loss 1.07413699477911 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 11/40
time = 97.32 secondes

Train loss 0.09315239075768852 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 3.17 secondes

Val loss 1.1828903183341026 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 12/40
time = 97.01 secondes

Train loss 0.19093583229308328 accuracy 0.9554263353347778 macro_avg {'precision': 0.9461726998491704, 'recall': 0.961583472847553, 'f1-score': 0.9526475176654124, 'support': 516} weighted_avg {'precision': 0.9583395448221028, 'recall': 0.9554263565891473, 'f1-score': 0.9558042786827752, 'support': 516}
 
time = 3.17 secondes

Val loss 0.6163436425849795 accuracy 0.890625 macro_avg {'precision': 0.8880742913000977, 'recall': 0.9018218623481782, 'f1-score': 0.8893007165801828, 'support': 64} weighted_avg {'precision': 0.9033785434995112, 'recall': 0.890625, 'f1-score': 0.8915709167284409, 'support': 64}
 
----------
Epoch 13/40
time = 96.55 secondes

Train loss 0.059764649429725425 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 3.02 secondes

Val loss 1.5128589570522308 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 14/40
time = 97.12 secondes

Train loss 0.03146369578352085 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 3.18 secondes

Val loss 1.2298294007778168 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 15/40
time = 96.69 secondes

Train loss 0.07049027545673942 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 2.71 secondes

Val loss 1.0816927403211594 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 16/40
time = 96.84 secondes

Train loss 0.16310615005028067 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 3.17 secondes

Val loss 2.073997139930725 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 17/40
time = 96.60 secondes

Train loss 0.08555275164315279 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 3.17 secondes

Val loss 2.4976694881916046 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 18/40
time = 96.57 secondes

Train loss 0.2658490116565107 accuracy 0.9534883499145508 macro_avg {'precision': 0.9487888937430222, 'recall': 0.9508313963883426, 'f1-score': 0.9497924234561494, 'support': 516} weighted_avg {'precision': 0.9536245888567914, 'recall': 0.9534883720930233, 'f1-score': 0.9535411713592644, 'support': 516}
 
time = 3.24 secondes

Val loss 1.3208747394382954 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 19/40
time = 96.63 secondes

Train loss 0.13803066529340646 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 3.17 secondes

Val loss 1.4083380922675133 accuracy 0.78125 macro_avg {'precision': 0.825, 'recall': 0.8157894736842105, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8578125000000001, 'recall': 0.78125, 'f1-score': 0.7797531769305963, 'support': 64}
 
----------
Epoch 20/40
time = 96.72 secondes

Train loss 0.39133616332070564 accuracy 0.9244186282157898 macro_avg {'precision': 0.9130133612462287, 'recall': 0.9361133234725225, 'f1-score': 0.9207513733829523, 'support': 516} weighted_avg {'precision': 0.9332576682899868, 'recall': 0.9244186046511628, 'f1-score': 0.9254427863566991, 'support': 516}
 
time = 3.17 secondes

Val loss 1.3415073156356812 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 21/40
time = 96.79 secondes

Train loss 0.0224448609276971 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.17 secondes

Val loss 2.3013035655021667 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 22/40
time = 96.88 secondes

Train loss 0.08892402659473715 accuracy 0.9825581312179565 macro_avg {'precision': 0.9840264525893269, 'recall': 0.9782439087820816, 'f1-score': 0.9810175477320384, 'support': 516} weighted_avg {'precision': 0.9826547390779392, 'recall': 0.9825581395348837, 'f1-score': 0.9825057384531543, 'support': 516}
 
time = 3.23 secondes

Val loss 1.5832591354846954 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 23/40
time = 96.73 secondes

Train loss 0.14849973116581555 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 3.16 secondes

Val loss 1.5667136758565903 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 96.72 secondes

Train loss 0.0190266961872112 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.16 secondes

Val loss 1.343783363699913 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 25/40
time = 95.97 secondes

Train loss 0.002718364582643985 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.19 secondes

Val loss 0.9181021526455879 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 26/40
time = 97.24 secondes

Train loss 0.035302754492449545 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 3.18 secondes

Val loss 0.9958551079034805 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 27/40
time = 97.25 secondes

Train loss 0.0006871041197992974 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.17 secondes

Val loss 1.6797093003988266 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 96.77 secondes

Train loss 0.04140402851749748 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 3.17 secondes

Val loss 1.074525997042656 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 29/40
time = 96.49 secondes

Train loss 0.05204006498697157 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 3.17 secondes

Val loss 1.2177249491214752 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 30/40
time = 97.47 secondes

Train loss 0.0013258650913926292 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.14 secondes

Val loss 1.4259391874074936 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 31/40
time = 96.61 secondes

Train loss 0.06411416474535751 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 3.19 secondes

Val loss 1.2266603112220764 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 32/40
time = 96.59 secondes

Train loss 0.10607053857088569 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 3.17 secondes

Val loss 2.388211637735367 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 33/40
time = 96.55 secondes

Train loss 0.0174677814312886 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 3.18 secondes

Val loss 1.2151733189821243 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 34/40
time = 96.87 secondes

Train loss 9.973473788704723e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.18 secondes

Val loss 1.784604474902153 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 35/40
time = 96.83 secondes

Train loss 0.027095445907351943 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.15 secondes

Val loss 1.1196045577526093 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 36/40
time = 96.39 secondes

Train loss 0.018131293015330535 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 3.16 secondes

Val loss 1.6919010430574417 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 37/40
time = 96.46 secondes

Train loss 8.518239734588529e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.18 secondes

Val loss 1.5547788068652153 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 38/40
time = 96.68 secondes

Train loss 0.010307095052584455 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.16 secondes

Val loss 1.909068688750267 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 39/40
time = 97.30 secondes

Train loss 0.034877498759835195 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 3.16 secondes

Val loss 1.73294897377491 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 40/40
time = 96.59 secondes

Train loss 0.015398807317868694 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.16 secondes

Val loss 1.4566323161125183 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 12 macro_avg {'precision': 0.8880742913000977, 'recall': 0.9018218623481782, 'f1-score': 0.8893007165801828, 'support': 64} weighted_avg {'precision': 0.9033785434995112, 'recall': 0.890625, 'f1-score': 0.8915709167284409, 'support': 64}

average train time 96.83639701604844

average val time 3.1556310951709747
 
time = 3.89 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 75.73 GiB already allocated; 43.62 MiB free; 77.14 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 74.19 GiB already allocated; 265.62 MiB free; 76.92 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 451.62 MiB free; 76.74 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_3
----------
Epoch 1/40
time = 33.75 secondes

Train loss 0.625626108863137 accuracy 0.6395348906517029 macro_avg {'precision': 0.5836008170411439, 'recall': 0.5419111551777385, 'f1-score': 0.5168733891752577, 'support': 516} weighted_avg {'precision': 0.6046130854764076, 'recall': 0.6395348837209303, 'f1-score': 0.5838654361963558, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6982296705245972 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 2/40
time = 30.11 secondes

Train loss 0.382159088371378 accuracy 0.8585271239280701 macro_avg {'precision': 0.8535509031198687, 'recall': 0.8359719129431269, 'f1-score': 0.8432687706742672, 'support': 516} weighted_avg {'precision': 0.8574765946207407, 'recall': 0.8585271317829457, 'f1-score': 0.8567264556272631, 'support': 516}
 
time = 1.50 secondes

Val loss 0.5236067175865173 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 3/40
time = 30.82 secondes

Train loss 0.22959419272162698 accuracy 0.9127907156944275 macro_avg {'precision': 0.9085317460317461, 'recall': 0.9016059034832502, 'f1-score': 0.9048575116264777, 'support': 516} weighted_avg {'precision': 0.9124084840654608, 'recall': 0.9127906976744186, 'f1-score': 0.9124179976587435, 'support': 516}
 
time = 1.50 secondes

Val loss 0.6560925841331482 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 4/40
time = 30.23 secondes

Train loss 0.1929583439575226 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 1.49 secondes

Val loss 1.476532205939293 accuracy 0.671875 macro_avg {'precision': 0.7020512820512821, 'recall': 0.6993927125506073, 'f1-score': 0.6717948717948719, 'support': 64} weighted_avg {'precision': 0.7279166666666667, 'recall': 0.671875, 'f1-score': 0.6708333333333334, 'support': 64}
 
----------
Epoch 5/40
time = 30.52 secondes

Train loss 0.46417306394626695 accuracy 0.8449612259864807 macro_avg {'precision': 0.8347582620868956, 'recall': 0.8264876550233247, 'f1-score': 0.8302296505889322, 'support': 516} weighted_avg {'precision': 0.8437016133689439, 'recall': 0.8449612403100775, 'f1-score': 0.8439920567757917, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0404720455408096 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 6/40
time = 30.37 secondes

Train loss 0.10133519100032351 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8569167256355286 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 7/40
time = 30.11 secondes

Train loss 0.1767650766255842 accuracy 0.9593023061752319 macro_avg {'precision': 0.9622660427807486, 'recall': 0.9496204671423696, 'f1-score': 0.9553793129007152, 'support': 516} weighted_avg {'precision': 0.9596998974008207, 'recall': 0.9593023255813954, 'f1-score': 0.9590202789180785, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2650444135069847 accuracy 0.734375 macro_avg {'precision': 0.7246153846153847, 'recall': 0.7216599190283401, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7329807692307693, 'recall': 0.734375, 'f1-score': 0.733495670995671, 'support': 64}
 
----------
Epoch 8/40
time = 30.15 secondes

Train loss 0.22144800371747944 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4288799464702606 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 9/40
time = 30.11 secondes

Train loss 0.2841227783047185 accuracy 0.9399224519729614 macro_avg {'precision': 0.9307594936708861, 'recall': 0.9425011784210784, 'f1-score': 0.9359173126614988, 'support': 516} weighted_avg {'precision': 0.9419762535570602, 'recall': 0.939922480620155, 'f1-score': 0.940326102197384, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7079083919525146 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 30.25 secondes

Train loss 0.09328660189974912 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2738700211048126 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 11/40
time = 30.21 secondes

Train loss 0.2572881527113636 accuracy 0.9476743936538696 macro_avg {'precision': 0.9394415856680007, 'recall': 0.9497342457292395, 'f1-score': 0.9440695317047713, 'support': 516} weighted_avg {'precision': 0.9491837713097037, 'recall': 0.9476744186046512, 'f1-score': 0.9479771190313585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7568990588188171 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 12/40
time = 30.21 secondes

Train loss 0.13148416147283348 accuracy 0.9670542478561401 macro_avg {'precision': 0.9682539682539683, 'recall': 0.9603156543081449, 'f1-score': 0.9640572821700026, 'support': 516} weighted_avg {'precision': 0.9671619293712317, 'recall': 0.9670542635658915, 'f1-score': 0.9669134657821921, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4331865012645721 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 13/40
time = 31.07 secondes

Train loss 0.06832721539654868 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.50 secondes

Val loss 2.0870121717453003 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 14/40
time = 30.13 secondes

Train loss 0.2175860096868939 accuracy 0.9515503644943237 macro_avg {'precision': 0.9578884733083985, 'recall': 0.9377712400240561, 'f1-score': 0.9464674758792405, 'support': 516} weighted_avg {'precision': 0.9527747905184388, 'recall': 0.9515503875968992, 'f1-score': 0.9510069316270866, 'support': 516}
 
time = 1.49 secondes

Val loss 2.169286787509918 accuracy 0.703125 macro_avg {'precision': 0.749204665959703, 'recall': 0.7378542510121457, 'f1-score': 0.7024712503058479, 'support': 64} weighted_avg {'precision': 0.7799244432661717, 'recall': 0.703125, 'f1-score': 0.699856251529239, 'support': 64}
 
----------
Epoch 15/40
time = 30.19 secondes

Train loss 0.21709761677652062 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4831441193819046 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 16/40
time = 30.26 secondes

Train loss 0.13878011181209746 accuracy 0.963178277015686 macro_avg {'precision': 0.9587826929286407, 'recall': 0.9618923004404857, 'f1-score': 0.9602972442140645, 'support': 516} weighted_avg {'precision': 0.9633722181756288, 'recall': 0.9631782945736435, 'f1-score': 0.9632404755166558, 'support': 516}
 
time = 1.50 secondes

Val loss 2.1992675960063934 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 17/40
time = 30.21 secondes

Train loss 0.05020497808635065 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7382535636425018 accuracy 0.703125 macro_avg {'precision': 0.7277526395173455, 'recall': 0.652834008097166, 'f1-score': 0.6496686833765485, 'support': 64} weighted_avg {'precision': 0.7199754901960784, 'recall': 0.703125, 'f1-score': 0.6753277153558052, 'support': 64}
 
----------
Epoch 18/40
time = 30.29 secondes

Train loss 0.03965134958994123 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.52 secondes

Val loss 1.7827331721782684 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 19/40
time = 30.81 secondes

Train loss 0.05649112775581395 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.48 secondes

Val loss 2.0047809779644012 accuracy 0.6875 macro_avg {'precision': 0.725, 'recall': 0.7186234817813766, 'f1-score': 0.6871945259042034, 'support': 64} weighted_avg {'precision': 0.753125, 'recall': 0.6875, 'f1-score': 0.6853616813294232, 'support': 64}
 
----------
Epoch 20/40
time = 30.12 secondes

Train loss 0.27739180960413773 accuracy 0.9379844665527344 macro_avg {'precision': 0.9268991877687529, 'recall': 0.9502137412024771, 'f1-score': 0.9349183325975909, 'support': 516} weighted_avg {'precision': 0.9460956973596003, 'recall': 0.937984496124031, 'f1-score': 0.938805789925756, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6751444041728973 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 21/40
time = 30.14 secondes

Train loss 0.004300137421303203 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.49 secondes

Val loss 2.6756025552749634 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 22/40
time = 30.88 secondes

Train loss 0.0826095301034167 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 1.51 secondes

Val loss 1.989063024520874 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 23/40
time = 30.20 secondes

Train loss 0.0790824400403036 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.47 secondes

Val loss 1.8668419420719147 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 24/40
time = 30.91 secondes

Train loss 0.10543825667793333 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.50 secondes

Val loss 1.3192211389541626 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 25/40
time = 30.17 secondes

Train loss 0.018286236006105988 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 1.9932116270065308 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 26/40
time = 29.96 secondes

Train loss 0.03347690192067327 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.50 secondes

Val loss 1.918234795331955 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 27/40
time = 30.13 secondes

Train loss 0.00031919298139242034 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7011758089065552 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 28/40
time = 30.22 secondes

Train loss 0.06988515751816687 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.50 secondes

Val loss 2.487298548221588 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 29/40
time = 30.23 secondes

Train loss 0.09455356779212845 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 1.51 secondes

Val loss 2.217032015323639 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 30/40
time = 30.18 secondes

Train loss 0.01788237905522251 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4192169606685638 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 31/40
time = 30.62 secondes

Train loss 0.02329803276855576 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.50 secondes

Val loss 2.1601904332637787 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 32/40
time = 30.21 secondes

Train loss 0.00585778816027662 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 1.462239220738411 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 33/40
time = 30.19 secondes

Train loss 0.009014906732883184 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 2.9580326080322266 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 34/40
time = 30.10 secondes

Train loss 0.0012350406097649477 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7926853597164154 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 35/40
time = 30.04 secondes

Train loss 0.006170519318347391 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8376981914043427 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 36/40
time = 30.57 secondes

Train loss 0.0058649302861312844 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 2.7295517325401306 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 37/40
time = 30.44 secondes

Train loss 3.225793212054255e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8883630335330963 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 38/40
time = 30.31 secondes

Train loss 0.014937608432030009 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.52 secondes

Val loss 1.9225796461105347 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 39/40
time = 29.87 secondes

Train loss 2.621215775654877e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.34 secondes

Val loss 1.7789057940244675 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 40/40
time = 30.11 secondes

Train loss 2.75427998227921e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.824532225728035 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 30 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}

average train time 30.38502171039581

average val time 1.4982064723968507
 
time = 1.76 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9655172413793103, 'recall': 0.9736842105263157, 'f1-score': 0.9686293436293436, 'support': 65} weighted_avg {'precision': 0.9713527851458886, 'recall': 0.9692307692307692, 'f1-score': 0.9693644193644194, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_3
----------
Epoch 1/40
time = 42.43 secondes

Train loss 0.6262132480288997 accuracy 0.6317829489707947 macro_avg {'precision': 0.5560253699788583, 'recall': 0.5185215285340442, 'f1-score': 0.468502656402472, 'support': 516} weighted_avg {'precision': 0.5810429880197322, 'recall': 0.6317829457364341, 'f1-score': 0.5495718909668866, 'support': 516}
 
time = 1.87 secondes

Val loss 0.5721607729792595 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 2/40
time = 39.31 secondes

Train loss 0.45744808063362585 accuracy 0.7926356792449951 macro_avg {'precision': 0.7816102114419066, 'recall': 0.7589113014644929, 'f1-score': 0.7670527181823935, 'support': 516} weighted_avg {'precision': 0.7894382791476103, 'recall': 0.7926356589147286, 'f1-score': 0.7882970315390695, 'support': 516}
 
time = 1.68 secondes

Val loss 0.4254829064011574 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 39.37 secondes

Train loss 0.3971727020812757 accuracy 0.8430232405662537 macro_avg {'precision': 0.8323083571571039, 'recall': 0.8249678981844188, 'f1-score': 0.828321455710501, 'support': 516} weighted_avg {'precision': 0.8418178297150579, 'recall': 0.8430232558139535, 'f1-score': 0.842146989582622, 'support': 516}
 
time = 1.62 secondes

Val loss 0.468410886824131 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 4/40
time = 39.56 secondes

Train loss 0.21912724493692318 accuracy 0.9166666865348816 macro_avg {'precision': 0.9159608792095181, 'recall': 0.9023373372559855, 'f1-score': 0.9084014845333587, 'support': 516} weighted_avg {'precision': 0.9165574376554412, 'recall': 0.9166666666666666, 'f1-score': 0.9159734578425828, 'support': 516}
 
time = 1.64 secondes

Val loss 0.45259037241339684 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 5/40
time = 39.38 secondes

Train loss 0.1473745360236728 accuracy 0.9534883499145508 macro_avg {'precision': 0.9472080078281653, 'recall': 0.9531394762934187, 'f1-score': 0.9500161446561188, 'support': 516} weighted_avg {'precision': 0.954068098025164, 'recall': 0.9534883720930233, 'f1-score': 0.9536415585975925, 'support': 516}
 
time = 1.64 secondes

Val loss 0.7436205148696899 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 6/40
time = 39.35 secondes

Train loss 0.16911207980504542 accuracy 0.9515503644943237 macro_avg {'precision': 0.9536430481283422, 'recall': 0.9412333598816702, 'f1-score': 0.9468801344056134, 'support': 516} weighted_avg {'precision': 0.9518311103511171, 'recall': 0.9515503875968992, 'f1-score': 0.9512146177596172, 'support': 516}
 
time = 1.68 secondes

Val loss 2.345307797193527 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 7/40
time = 39.72 secondes

Train loss 0.3738545427719752 accuracy 0.9147287011146545 macro_avg {'precision': 0.9182265840811215, 'recall': 0.8962014206069275, 'f1-score': 0.9054047297635117, 'support': 516} weighted_avg {'precision': 0.9154974518212192, 'recall': 0.9147286821705426, 'f1-score': 0.9135775769351066, 'support': 516}
 
time = 1.68 secondes

Val loss 0.8066237270832062 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 8/40
time = 39.38 secondes

Train loss 0.19839317968933645 accuracy 0.9399224519729614 macro_avg {'precision': 0.9419741883444243, 'recall': 0.9274986590380834, 'f1-score': 0.9339638609426538, 'support': 516} weighted_avg {'precision': 0.9402400068155776, 'recall': 0.939922480620155, 'f1-score': 0.9394227254213968, 'support': 516}
 
time = 1.69 secondes

Val loss 0.652794860303402 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 9/40
time = 39.24 secondes

Train loss 0.11072983908481106 accuracy 0.9651162624359131 macro_avg {'precision': 0.9667456857251795, 'recall': 0.9576418575167012, 'f1-score': 0.9618963225520603, 'support': 516} weighted_avg {'precision': 0.9652812822753787, 'recall': 0.9651162790697675, 'f1-score': 0.9649445480554899, 'support': 516}
 
time = 1.69 secondes

Val loss 1.0907388105988503 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 10/40
time = 39.37 secondes

Train loss 0.049423836669919896 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 1.52 secondes

Val loss 1.8846968710422516 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 11/40
time = 39.13 secondes

Train loss 0.22207301261721912 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7672073543071747 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 12/40
time = 39.08 secondes

Train loss 0.12697766198217517 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 1.61 secondes

Val loss 2.076639622449875 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 13/40
time = 39.23 secondes

Train loss 0.44278978018943843 accuracy 0.9089147448539734 macro_avg {'precision': 0.8971276399236501, 'recall': 0.919339108951124, 'f1-score': 0.9044952448461221, 'support': 516} weighted_avg {'precision': 0.9180497224700238, 'recall': 0.9089147286821705, 'f1-score': 0.9101489989426886, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6228834688663483 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 39.45 secondes

Train loss 0.30832243647124746 accuracy 0.9302325248718262 macro_avg {'precision': 0.9253531477096433, 'recall': 0.9233619947011686, 'f1-score': 0.9243401759530792, 'support': 516} weighted_avg {'precision': 0.9300988756620037, 'recall': 0.9302325581395349, 'f1-score': 0.9301507194980564, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2950659543275833 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 15/40
time = 40.06 secondes

Train loss 0.5129475955433339 accuracy 0.9166666865348816 macro_avg {'precision': 0.9353551912568305, 'recall': 0.8884888578255287, 'f1-score': 0.9052665286168691, 'support': 516} weighted_avg {'precision': 0.9230692167577413, 'recall': 0.9166666666666666, 'f1-score': 0.914310213550228, 'support': 516}
 
time = 1.67 secondes

Val loss 1.1610345430672169 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 16/40
time = 39.51 secondes

Train loss 0.1982389162395989 accuracy 0.9476743936538696 macro_avg {'precision': 0.950645291389393, 'recall': 0.9358857662987825, 'f1-score': 0.9424846530790857, 'support': 516} weighted_avg {'precision': 0.9481341965356231, 'recall': 0.9476744186046512, 'f1-score': 0.9472391479476683, 'support': 516}
 
time = 1.69 secondes

Val loss 1.497447431087494 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 17/40
time = 39.44 secondes

Train loss 0.1796050021595985 accuracy 0.9593023061752319 macro_avg {'precision': 0.9555007784120395, 'recall': 0.956544706857598, 'f1-score': 0.9560182648401826, 'support': 516} weighted_avg {'precision': 0.9593566333981004, 'recall': 0.9593023255813954, 'f1-score': 0.959325616792326, 'support': 516}
 
time = 1.69 secondes

Val loss 1.0516498237848282 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 18/40
time = 39.41 secondes

Train loss 0.10314677721445067 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.69 secondes

Val loss 1.883267730474472 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 19/40
time = 39.35 secondes

Train loss 0.014325863092601525 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6531489789485931 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 20/40
time = 39.41 secondes

Train loss 0.09135981864484634 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4012673795223236 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 21/40
time = 39.25 secondes

Train loss 0.041637909964871746 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8053558021783829 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 22/40
time = 39.34 secondes

Train loss 0.14084317500920873 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8922217190265656 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 23/40
time = 39.27 secondes

Train loss 0.056769452976533845 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4171417728066444 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 24/40
time = 39.33 secondes

Train loss 0.09201531931246405 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4038533121347427 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 25/40
time = 39.27 secondes

Train loss 0.1617579068754849 accuracy 0.9748061895370483 macro_avg {'precision': 0.9712786567646109, 'recall': 0.9744729613315346, 'f1-score': 0.9728349565675176, 'support': 516} weighted_avg {'precision': 0.9749618285262307, 'recall': 0.9748062015503876, 'f1-score': 0.9748487464061328, 'support': 516}
 
time = 1.69 secondes

Val loss 2.6036927103996277 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 26/40
time = 39.92 secondes

Train loss 0.14603611460882926 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1673257146030664 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 27/40
time = 39.43 secondes

Train loss 0.058479749631784 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.66 secondes

Val loss 1.480094313621521 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 28/40
time = 39.10 secondes

Train loss 0.03546970267427352 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.66 secondes

Val loss 1.211783453822136 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 29/40
time = 39.94 secondes

Train loss 0.029163341590681353 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.69 secondes

Val loss 1.212589979171753 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 30/40
time = 39.15 secondes

Train loss 0.0854684688926103 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1489645950496197 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 31/40
time = 39.39 secondes

Train loss 0.002054126547150328 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.491396278142929 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 32/40
time = 39.39 secondes

Train loss 0.007782544322474154 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.72 secondes

Val loss 1.385601282119751 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 33/40
time = 39.82 secondes

Train loss 0.04436210980114111 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.70 secondes

Val loss 1.7520918399095535 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 34/40
time = 39.50 secondes

Train loss 0.005973262763291132 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.74 secondes

Val loss 1.2969504296779633 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 35/40
time = 39.34 secondes

Train loss 0.008765572931610443 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4453338533639908 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 39.73 secondes

Train loss 0.0016910390353807475 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7241961658000946 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 37/40
time = 39.59 secondes

Train loss 2.5416877234061815e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.71 secondes

Val loss 1.9218558967113495 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 38/40
time = 39.66 secondes

Train loss 5.992705182782657e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.70 secondes

Val loss 1.9247906506061554 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 39/40
time = 39.28 secondes

Train loss 0.006033159507668725 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7615353465080261 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 40/40
time = 38.57 secondes

Train loss 2.162405957223558e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6307250559329987 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 30 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}

average train time 39.486334425210956

average val time 1.684338140487671
 
time = 1.96 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_3
----------
Epoch 1/40
time = 51.84 secondes

Train loss 0.6486877943530227 accuracy 0.6143410801887512 macro_avg {'precision': 0.4509419152276295, 'recall': 0.4898411976008972, 'f1-score': 0.41137422827563674, 'support': 516} weighted_avg {'precision': 0.5009476957151376, 'recall': 0.6143410852713178, 'f1-score': 0.5064940094419297, 'support': 516}
 
time = 2.20 secondes

Val loss 0.5979201197624207 accuracy 0.625 macro_avg {'precision': 0.8064516129032258, 'recall': 0.5384615384615384, 'f1-score': 0.45142857142857146, 'support': 64} weighted_avg {'precision': 0.7701612903225806, 'recall': 0.625, 'f1-score': 0.5092857142857142, 'support': 64}
 
----------
Epoch 2/40
time = 49.31 secondes

Train loss 0.4691522992921598 accuracy 0.786821722984314 macro_avg {'precision': 0.7716863052708763, 'recall': 0.758968190757928, 'f1-score': 0.7641446712319659, 'support': 516} weighted_avg {'precision': 0.7837606132600796, 'recall': 0.7868217054263565, 'f1-score': 0.7842705390794876, 'support': 516}
 
time = 2.02 secondes

Val loss 0.39991746842861176 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 3/40
time = 49.81 secondes

Train loss 0.31748748356194206 accuracy 0.8779069781303406 macro_avg {'precision': 0.867637519460301, 'recall': 0.8684800806202558, 'f1-score': 0.868054794520548, 'support': 516} weighted_avg {'precision': 0.878053683276813, 'recall': 0.877906976744186, 'f1-score': 0.8779768503769778, 'support': 516}
 
time = 2.03 secondes

Val loss 0.3959294334053993 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 49.14 secondes

Train loss 0.25548440771120967 accuracy 0.9186046719551086 macro_avg {'precision': 0.9099600571071079, 'recall': 0.915397493620272, 'f1-score': 0.912528253148208, 'support': 516} weighted_avg {'precision': 0.9194026136910076, 'recall': 0.9186046511627907, 'f1-score': 0.9188727275457869, 'support': 516}
 
time = 1.96 secondes

Val loss 0.5732985287904739 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 5/40
time = 49.82 secondes

Train loss 0.2367099921473048 accuracy 0.9166666865348816 macro_avg {'precision': 0.911874054089623, 'recall': 0.9069534970661379, 'f1-score': 0.9093060613864057, 'support': 516} weighted_avg {'precision': 0.9163513632076506, 'recall': 0.9166666666666666, 'f1-score': 0.9164163059428482, 'support': 516}
 
time = 2.01 secondes

Val loss 0.46788015216588974 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 6/40
time = 49.29 secondes

Train loss 0.20905013297769157 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 2.02 secondes

Val loss 0.6150469854474068 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 7/40
time = 49.28 secondes

Train loss 0.21290303792127155 accuracy 0.9205426573753357 macro_avg {'precision': 0.9152370350969093, 'recall': 0.9123010906490255, 'f1-score': 0.9137303195762363, 'support': 516} weighted_avg {'precision': 0.9203275437442389, 'recall': 0.9205426356589147, 'f1-score': 0.9204016911882387, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4583413898944855 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 8/40
time = 49.70 secondes

Train loss 0.10660008495236098 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 2.00 secondes

Val loss 2.035320967435837 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 9/40
time = 49.51 secondes

Train loss 0.2722540305553456 accuracy 0.9263566136360168 macro_avg {'precision': 0.927417044439576, 'recall': 0.9122442013555906, 'f1-score': 0.9189484126984127, 'support': 516} weighted_avg {'precision': 0.926531252371899, 'recall': 0.9263565891472868, 'f1-score': 0.9256917527993109, 'support': 516}
 
time = 2.03 secondes

Val loss 0.7877931296825409 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 10/40
time = 49.32 secondes

Train loss 0.10951718830267165 accuracy 0.9709302186965942 macro_avg {'precision': 0.9654383044118588, 'recall': 0.972587487606261, 'f1-score': 0.9687942233027322, 'support': 516} weighted_avg {'precision': 0.9715309121991389, 'recall': 0.9709302325581395, 'f1-score': 0.9710409885936052, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1239083036780357 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 11/40
time = 49.38 secondes

Train loss 0.3974452090827099 accuracy 0.8972868323326111 macro_avg {'precision': 0.8858544303797469, 'recall': 0.8963720884872324, 'f1-score': 0.8904392764857881, 'support': 516} weighted_avg {'precision': 0.8998492542439407, 'recall': 0.8972868217054264, 'f1-score': 0.897976884401979, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1260405629873276 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 12/40
time = 49.93 secondes

Train loss 0.07728660404664521 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 2.04 secondes

Val loss 2.0661981403827667 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 13/40
time = 49.40 secondes

Train loss 0.3645772796907378 accuracy 0.8914728760719299 macro_avg {'precision': 0.8814659685863875, 'recall': 0.8848885782552867, 'f1-score': 0.8831124702684335, 'support': 516} weighted_avg {'precision': 0.8920702950606761, 'recall': 0.8914728682170543, 'f1-score': 0.8917151985923766, 'support': 516}
 
time = 2.04 secondes

Val loss 1.3463889509439468 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 14/40
time = 49.81 secondes

Train loss 0.3945751283846965 accuracy 0.9186046719551086 macro_avg {'precision': 0.9175534143276078, 'recall': 0.9050111340474294, 'f1-score': 0.9106456666941536, 'support': 516} weighted_avg {'precision': 0.9184526651143305, 'recall': 0.9186046511627907, 'f1-score': 0.917984470554845, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1533467867666332 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 15/40
time = 49.13 secondes

Train loss 0.25747944358700997 accuracy 0.9341084957122803 macro_avg {'precision': 0.9403599677435959, 'recall': 0.9171691887586756, 'f1-score': 0.9269036548172591, 'support': 516} weighted_avg {'precision': 0.9354824701233901, 'recall': 0.9341085271317829, 'f1-score': 0.9332190367225826, 'support': 516}
 
time = 2.03 secondes

Val loss 1.3853503987193108 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 16/40
time = 49.44 secondes

Train loss 0.022861844025266528 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1197438091039658 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 17/40
time = 49.82 secondes

Train loss 0.04687935988179313 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8437841534614563 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 18/40
time = 49.33 secondes

Train loss 0.10288021465010277 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.01 secondes

Val loss 0.7980420787353069 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 19/40
time = 48.99 secondes

Train loss 0.10282200488290982 accuracy 0.9825581312179565 macro_avg {'precision': 0.9840264525893269, 'recall': 0.9782439087820816, 'f1-score': 0.9810175477320384, 'support': 516} weighted_avg {'precision': 0.9826547390779392, 'recall': 0.9825581395348837, 'f1-score': 0.9825057384531543, 'support': 516}
 
time = 2.02 secondes

Val loss 2.40987628698349 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 20/40
time = 49.44 secondes

Train loss 0.3520119644893963 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 2.04 secondes

Val loss 1.120570670813322 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 21/40
time = 49.33 secondes

Train loss 0.22011452283428903 accuracy 0.963178277015686 macro_avg {'precision': 0.9542797888386123, 'recall': 0.9699705801082522, 'f1-score': 0.9608827319844713, 'support': 516} weighted_avg {'precision': 0.9659796760087458, 'recall': 0.9631782945736435, 'f1-score': 0.9634904910857709, 'support': 516}
 
time = 2.04 secondes

Val loss 1.5293855369091034 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 22/40
time = 49.87 secondes

Train loss 0.08344018792316395 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.03 secondes

Val loss 1.5211723297834396 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 23/40
time = 49.11 secondes

Train loss 0.07256370858301649 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.04 secondes

Val loss 2.6433530747890472 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 24/40
time = 49.44 secondes

Train loss 0.23891332999075088 accuracy 0.961240291595459 macro_avg {'precision': 0.9637518124093796, 'recall': 0.9522942639338134, 'f1-score': 0.957557412647233, 'support': 516} weighted_avg {'precision': 0.9615503720937983, 'recall': 0.9612403100775194, 'f1-score': 0.9609980141939479, 'support': 516}
 
time = 2.03 secondes

Val loss 2.18736831843853 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 25/40
time = 49.14 secondes

Train loss 0.21482251915288295 accuracy 0.9651162624359131 macro_avg {'precision': 0.9740634005763689, 'recall': 0.9518716577540107, 'f1-score': 0.9614054916561399, 'support': 516} weighted_avg {'precision': 0.9669258092621138, 'recall': 0.9651162790697675, 'f1-score': 0.9646988154857342, 'support': 516}
 
time = 2.03 secondes

Val loss 1.7550849658018706 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 26/40
time = 49.84 secondes

Train loss 0.0743913915759935 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.04 secondes

Val loss 1.7952998988330364 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 27/40
time = 49.26 secondes

Train loss 0.2868609506071648 accuracy 0.9651162624359131 macro_avg {'precision': 0.9560975609756097, 'recall': 0.9726443768996961, 'f1-score': 0.9629783163265306, 'support': 516} weighted_avg {'precision': 0.9681792399319343, 'recall': 0.9651162790697675, 'f1-score': 0.9654266285002373, 'support': 516}
 
time = 2.02 secondes

Val loss 2.4015322029590607 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 28/40
time = 49.68 secondes

Train loss 0.2844589106922892 accuracy 0.9554263353347778 macro_avg {'precision': 0.9470886075949367, 'recall': 0.9592753929424769, 'f1-score': 0.9524547803617571, 'support': 516} weighted_avg {'precision': 0.9572951623981946, 'recall': 0.9554263565891473, 'f1-score': 0.9557258177593495, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8804422970861197 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 29/40
time = 49.20 secondes

Train loss 0.01602347217119655 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4475029289787926 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 30/40
time = 49.55 secondes

Train loss 0.013532362230872615 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.02 secondes

Val loss 1.7765202969312668 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 31/40
time = 49.20 secondes

Train loss 0.03948413165882371 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.02 secondes

Val loss 1.6477696597576141 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 32/40
time = 50.01 secondes

Train loss 0.0541186015561283 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.03 secondes

Val loss 1.772340603172779 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 49.78 secondes

Train loss 0.1882956041396083 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8007608056650497 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 34/40
time = 49.46 secondes

Train loss 0.03387061659326939 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.03 secondes

Val loss 1.2410447392612696 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 35/40
time = 49.28 secondes

Train loss 0.00021999320564315315 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.914048746228218 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 36/40
time = 49.29 secondes

Train loss 0.08668372912176313 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 2.02 secondes

Val loss 2.357335388660431 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 37/40
time = 49.71 secondes

Train loss 0.006075638539738121 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.02 secondes

Val loss 2.060155540704727 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 38/40
time = 49.65 secondes

Train loss 1.9690951899754122e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.8338401913642883 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 49.32 secondes

Train loss 0.018500097940197906 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.6090283244848251 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 40/40
time = 49.02 secondes

Train loss 0.014089168152278227 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4111582329496741 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 18 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 49.5204231441021

average val time 2.030049794912338
 
time = 2.28 secondes

test_accuracy 0.9846153855323792 macro_avg {'precision': 0.9871794871794872, 'recall': 0.9814814814814814, 'f1-score': 0.9840725312423425, 'support': 65} weighted_avg {'precision': 0.9850098619329388, 'recall': 0.9846153846153847, 'f1-score': 0.9845701468342976, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_3
----------
Epoch 1/40
time = 99.99 secondes

Train loss 0.6238068595077052 accuracy 0.5968992114067078 macro_avg {'precision': 0.5209113682452582, 'recall': 0.5142467044845017, 'f1-score': 0.49910394265232977, 'support': 516} weighted_avg {'precision': 0.5552753033779141, 'recall': 0.5968992248062015, 'f1-score': 0.5600115306604428, 'support': 516}
 
time = 2.64 secondes

Val loss 0.7094335407018661 accuracy 0.6875 macro_avg {'precision': 0.7678571428571428, 'recall': 0.6214574898785425, 'f1-score': 0.5994993742177722, 'support': 64} weighted_avg {'precision': 0.7477678571428572, 'recall': 0.6875, 'f1-score': 0.6346996245306633, 'support': 64}
 
----------
Epoch 2/40
time = 100.02 secondes

Train loss 0.3807537506024043 accuracy 0.854651153087616 macro_avg {'precision': 0.8458556149732621, 'recall': 0.8363945191229296, 'f1-score': 0.8406404032168402, 'support': 516} weighted_avg {'precision': 0.8534712722298221, 'recall': 0.8546511627906976, 'f1-score': 0.8536438532788516, 'support': 516}
 
time = 2.45 secondes

Val loss 0.4683801904320717 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 3/40
time = 99.91 secondes

Train loss 0.2442454183191964 accuracy 0.9127907156944275 macro_avg {'precision': 0.905293201868189, 'recall': 0.9062220632934024, 'f1-score': 0.9057534246575343, 'support': 516} weighted_avg {'precision': 0.9128978047573648, 'recall': 0.9127906976744186, 'f1-score': 0.912840607412127, 'support': 516}
 
time = 2.47 secondes

Val loss 0.578301414847374 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 4/40
time = 99.74 secondes

Train loss 0.14131592116741973 accuracy 0.9534883499145508 macro_avg {'precision': 0.9496773564358045, 'recall': 0.9496773564358045, 'f1-score': 0.9496773564358045, 'support': 516} weighted_avg {'precision': 0.9534883720930233, 'recall': 0.9534883720930233, 'f1-score': 0.9534883720930233, 'support': 516}
 
time = 2.34 secondes

Val loss 0.7308817803859711 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 5/40
time = 99.88 secondes

Train loss 0.327707010014406 accuracy 0.9244186282157898 macro_avg {'precision': 0.9246319822544868, 'recall': 0.9107244445166849, 'f1-score': 0.9169222766697904, 'support': 516} weighted_avg {'precision': 0.9244516273754867, 'recall': 0.9244186046511628, 'f1-score': 0.9237898803688541, 'support': 516}
 
time = 2.44 secondes

Val loss 1.256316602230072 accuracy 0.703125 macro_avg {'precision': 0.7003910068426198, 'recall': 0.7074898785425101, 'f1-score': 0.6995305164319249, 'support': 64} weighted_avg {'precision': 0.7167949657869013, 'recall': 0.703125, 'f1-score': 0.7056924882629108, 'support': 64}
 
----------
Epoch 6/40
time = 99.75 secondes

Train loss 0.25199151482207305 accuracy 0.9244186282157898 macro_avg {'precision': 0.9153380102040816, 'recall': 0.9234188839946036, 'f1-score': 0.9190399369184163, 'support': 516} weighted_avg {'precision': 0.9257367554579972, 'recall': 0.9244186046511628, 'f1-score': 0.9247825746481155, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2854207456111908 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 7/40
time = 99.79 secondes

Train loss 0.1330003262652705 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5949057340621948 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 8/40
time = 100.32 secondes

Train loss 0.3521739606988955 accuracy 0.9127907156944275 macro_avg {'precision': 0.9076297953543462, 'recall': 0.9027599434357882, 'f1-score': 0.9050877386601921, 'support': 516} weighted_avg {'precision': 0.9124511646270455, 'recall': 0.9127906976744186, 'f1-score': 0.9125286922657715, 'support': 516}
 
time = 2.45 secondes

Val loss 1.657418131828308 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 9/40
time = 99.89 secondes

Train loss 0.13981471535887316 accuracy 0.963178277015686 macro_avg {'precision': 0.9665775401069518, 'recall': 0.9538140207727192, 'f1-score': 0.9596289021482662, 'support': 516} weighted_avg {'precision': 0.9636342909256727, 'recall': 0.9631782945736435, 'f1-score': 0.9629231094973091, 'support': 516}
 
time = 2.45 secondes

Val loss 1.8971561938524246 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 10/40
time = 99.90 secondes

Train loss 0.3259087157520381 accuracy 0.9205426573753357 macro_avg {'precision': 0.9094425305355465, 'recall': 0.9249955301269444, 'f1-score': 0.9157557729754269, 'support': 516} weighted_avg {'precision': 0.9245984433001454, 'recall': 0.9205426356589147, 'f1-score': 0.9212820697319739, 'support': 516}
 
time = 2.43 secondes

Val loss 1.4745250046253204 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 11/40
time = 99.82 secondes

Train loss 0.16115679025207294 accuracy 0.9689922332763672 macro_avg {'precision': 0.9630002396357537, 'recall': 0.9710677307673553, 'f1-score': 0.9667498993153444, 'support': 516} weighted_avg {'precision': 0.9697531380209059, 'recall': 0.9689922480620154, 'f1-score': 0.9691261196289811, 'support': 516}
 
time = 2.46 secondes

Val loss 2.06557434797287 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 12/40
time = 99.73 secondes

Train loss 0.1176640877908512 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 2.45 secondes

Val loss 1.3568861335515976 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 13/40
time = 99.83 secondes

Train loss 0.15563670639698324 accuracy 0.9728682041168213 macro_avg {'precision': 0.9651741293532339, 'recall': 0.9787234042553192, 'f1-score': 0.9710891976692066, 'support': 516} weighted_avg {'precision': 0.9747579929808323, 'recall': 0.9728682170542635, 'f1-score': 0.9730627972995041, 'support': 516}
 
time = 2.44 secondes

Val loss 2.0606918931007385 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 99.84 secondes

Train loss 0.22614133693709984 accuracy 0.9573643207550049 macro_avg {'precision': 0.9538709100661541, 'recall': 0.9538709100661541, 'f1-score': 0.9538709100661541, 'support': 516} weighted_avg {'precision': 0.9573643410852714, 'recall': 0.9573643410852714, 'f1-score': 0.9573643410852714, 'support': 516}
 
time = 2.44 secondes

Val loss 1.6951093971729279 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 15/40
time = 99.84 secondes

Train loss 0.37929273710478534 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.46 secondes

Val loss 1.56599660217762 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 16/40
time = 99.96 secondes

Train loss 0.16085558425490462 accuracy 0.9573643207550049 macro_avg {'precision': 0.9480040781115207, 'recall': 0.9642572696389968, 'f1-score': 0.9547512755102041, 'support': 516} weighted_avg {'precision': 0.9605432983216394, 'recall': 0.9573643410852714, 'f1-score': 0.9577436570558456, 'support': 516}
 
time = 2.45 secondes

Val loss 1.3545139729976654 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 17/40
time = 99.87 secondes

Train loss 0.8331401848179556 accuracy 0.8682170510292053 macro_avg {'precision': 0.9143576826196473, 'recall': 0.8181818181818181, 'f1-score': 0.8420569329660239, 'support': 516} weighted_avg {'precision': 0.8907894479917208, 'recall': 0.8682170542635659, 'f1-score': 0.8597461578434095, 'support': 516}
 
time = 2.46 secondes

Val loss 1.2562291473150253 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 18/40
time = 99.96 secondes

Train loss 0.3037922615392635 accuracy 0.9496123790740967 macro_avg {'precision': 0.9484950935928094, 'recall': 0.9420216829478407, 'f1-score': 0.9450955997904662, 'support': 516} weighted_avg {'precision': 0.9495253400222323, 'recall': 0.9496124031007752, 'f1-score': 0.9494292894530599, 'support': 516}
 
time = 2.45 secondes

Val loss 2.1254621744155884 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 19/40
time = 100.27 secondes

Train loss 0.06767933745096812 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.45 secondes

Val loss 2.254811465740204 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 20/40
time = 100.00 secondes

Train loss 0.17478690463273475 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 2.45 secondes

Val loss 2.140621393918991 accuracy 0.6875 macro_avg {'precision': 0.6875, 'recall': 0.6943319838056681, 'f1-score': 0.6847290640394088, 'support': 64} weighted_avg {'precision': 0.705078125, 'recall': 0.6875, 'f1-score': 0.6902709359605911, 'support': 64}
 
----------
Epoch 21/40
time = 99.83 secondes

Train loss 0.192142576244695 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.45 secondes

Val loss 1.449165627360344 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 22/40
time = 99.86 secondes

Train loss 0.03130004748902249 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.45 secondes

Val loss 1.414448767900467 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 23/40
time = 100.02 secondes

Train loss 0.12439228223515922 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 2.45 secondes

Val loss 1.4911992996931076 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 24/40
time = 99.83 secondes

Train loss 0.06391137393956976 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.44 secondes

Val loss 1.579172044992447 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 25/40
time = 99.98 secondes

Train loss 0.037284239662271415 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.44 secondes

Val loss 1.5421727299690247 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 26/40
time = 99.91 secondes

Train loss 0.07884744906473454 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1913505867123604 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 99.93 secondes

Train loss 0.05063684487443728 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.44 secondes

Val loss 1.2180385813117027 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 28/40
time = 100.23 secondes

Train loss 0.04535529875967327 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.44 secondes

Val loss 1.4883593916893005 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 29/40
time = 100.04 secondes

Train loss 0.12517923017863228 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6501441895961761 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 30/40
time = 100.00 secondes

Train loss 0.004819680489273389 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.31 secondes

Val loss 1.775810718536377 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 31/40
time = 99.74 secondes

Train loss 0.009513069953148564 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.45 secondes

Val loss 1.9464571177959442 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 32/40
time = 99.90 secondes

Train loss 0.07895299011827527 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.45 secondes

Val loss 2.6631231009960175 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 33/40
time = 99.95 secondes

Train loss 0.050980795502916655 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.45 secondes

Val loss 1.9978840053081512 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 34/40
time = 99.83 secondes

Train loss 0.012836514831592054 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.29 secondes

Val loss 1.896503061056137 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 35/40
time = 99.67 secondes

Train loss 0.026611772760037584 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.44 secondes

Val loss 1.8002724051475525 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 36/40
time = 99.83 secondes

Train loss 0.037592361842502156 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 2.35 secondes

Val loss 1.459074206650257 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 37/40
time = 99.62 secondes

Train loss 5.995733072543799e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.48 secondes

Val loss 1.5881338119506836 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 99.81 secondes

Train loss 0.00016996820274719292 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.29 secondes

Val loss 1.7582922279834747 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 39/40
time = 99.92 secondes

Train loss 9.83381805505787e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.43 secondes

Val loss 1.659583866596222 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 40/40
time = 100.08 secondes

Train loss 5.534277900578948e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.35 secondes

Val loss 1.6444981396198273 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 27 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 99.90668396949768

average val time 2.4340863645076753
 
time = 2.69 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 73.79 GiB already allocated; 109.62 MiB free; 77.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 261.62 MiB free; 76.92 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_3
----------
Epoch 1/40
time = 638.00 secondes

Train loss 1.3663246573608374 accuracy 0.6325869560241699 macro_avg {'precision': 0.6219244107976625, 'recall': 0.6170472686856687, 'f1-score': 0.6078706013437868, 'support': 10182} weighted_avg {'precision': 0.6337523389772152, 'recall': 0.6325869180907484, 'f1-score': 0.6227423153518827, 'support': 10182}
 
time = 23.36 secondes

Val loss 0.762900624476688 accuracy 0.7623674869537354 macro_avg {'precision': 0.7427393243214512, 'recall': 0.7587799968988177, 'f1-score': 0.7424239627907878, 'support': 1132} weighted_avg {'precision': 0.7545673406816037, 'recall': 0.7623674911660777, 'f1-score': 0.7492858166334991, 'support': 1132}
 
----------
Epoch 2/40
time = 637.45 secondes

Train loss 0.563592788785275 accuracy 0.8302887678146362 macro_avg {'precision': 0.8191227035486349, 'recall': 0.819320992482292, 'f1-score': 0.8165775216180098, 'support': 10182} weighted_avg {'precision': 0.8268271887479978, 'recall': 0.8302887448438421, 'f1-score': 0.8266648263252249, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.6512423467258333 accuracy 0.814487636089325 macro_avg {'precision': 0.8238572083724485, 'recall': 0.8126163380777243, 'f1-score': 0.811000466084437, 'support': 1132} weighted_avg {'precision': 0.8250007614819014, 'recall': 0.8144876325088339, 'f1-score': 0.8130356318910162, 'support': 1132}
 
----------
Epoch 3/40
time = 638.02 secondes

Train loss 0.32695392700967785 accuracy 0.9046356678009033 macro_avg {'precision': 0.8995273967667863, 'recall': 0.8990992892075672, 'f1-score': 0.8991204360775125, 'support': 10182} weighted_avg {'precision': 0.9045908271970372, 'recall': 0.9046356315065802, 'f1-score': 0.9044374404272355, 'support': 10182}
 
time = 23.43 secondes

Val loss 0.5586402537957044 accuracy 0.8595406413078308 macro_avg {'precision': 0.869598836863771, 'recall': 0.8596240134848164, 'f1-score': 0.8601706097605486, 'support': 1132} weighted_avg {'precision': 0.8706505069738429, 'recall': 0.8595406360424028, 'f1-score': 0.8608130451510376, 'support': 1132}
 
----------
Epoch 4/40
time = 637.11 secondes

Train loss 0.21398477004387736 accuracy 0.9407778978347778 macro_avg {'precision': 0.9380647868845735, 'recall': 0.9379500651731524, 'f1-score': 0.937867777514807, 'support': 10182} weighted_avg {'precision': 0.9413900272552947, 'recall': 0.940777843252799, 'f1-score': 0.9409557104050408, 'support': 10182}
 
time = 23.59 secondes

Val loss 0.6368536510124383 accuracy 0.8613074421882629 macro_avg {'precision': 0.8677580979001668, 'recall': 0.8658578441706956, 'f1-score': 0.8639135776581528, 'support': 1132} weighted_avg {'precision': 0.8689118496275623, 'recall': 0.8613074204946997, 'f1-score': 0.8621068013154227, 'support': 1132}
 
----------
Epoch 5/40
time = 636.63 secondes

Train loss 0.18426567417192252 accuracy 0.9564918875694275 macro_avg {'precision': 0.9552623781662699, 'recall': 0.9551406340235579, 'f1-score': 0.9550926857185222, 'support': 10182} weighted_avg {'precision': 0.9567063612106648, 'recall': 0.9564918483598507, 'f1-score': 0.9564883829032563, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.6597389964334351 accuracy 0.8595406413078308 macro_avg {'precision': 0.8672029314374579, 'recall': 0.8580462902489551, 'f1-score': 0.8576391454776757, 'support': 1132} weighted_avg {'precision': 0.8688844325163659, 'recall': 0.8595406360424028, 'f1-score': 0.8598571598976217, 'support': 1132}
 
----------
Epoch 6/40
time = 637.02 secondes

Train loss 0.16554490965206228 accuracy 0.9592418074607849 macro_avg {'precision': 0.9579309787524076, 'recall': 0.9575988977724945, 'f1-score': 0.9576898593147767, 'support': 10182} weighted_avg {'precision': 0.9593158898115484, 'recall': 0.9592417992535848, 'f1-score': 0.959210357212899, 'support': 10182}
 
time = 23.47 secondes

Val loss 0.7595683354654835 accuracy 0.851590096950531 macro_avg {'precision': 0.8586378264383854, 'recall': 0.854059343087305, 'f1-score': 0.853223658741577, 'support': 1132} weighted_avg {'precision': 0.8607404500018647, 'recall': 0.8515901060070671, 'f1-score': 0.8530441476303228, 'support': 1132}
 
----------
Epoch 7/40
time = 637.28 secondes

Train loss 0.13791962522160617 accuracy 0.9673934578895569 macro_avg {'precision': 0.9672271292786141, 'recall': 0.9672014033027503, 'f1-score': 0.9671962191372184, 'support': 10182} weighted_avg {'precision': 0.9674322851394486, 'recall': 0.9673934394028678, 'f1-score': 0.9673950345087149, 'support': 10182}
 
time = 23.71 secondes

Val loss 0.8368696063465084 accuracy 0.8586572408676147 macro_avg {'precision': 0.8664758942302789, 'recall': 0.85985926163818, 'f1-score': 0.859494706189105, 'support': 1132} weighted_avg {'precision': 0.8650061825320098, 'recall': 0.8586572438162544, 'f1-score': 0.8579610785275957, 'support': 1132}
 
----------
Epoch 8/40
time = 637.01 secondes

Train loss 0.13647122770193137 accuracy 0.9705362915992737 macro_avg {'precision': 0.9692980920410171, 'recall': 0.96958233909078, 'f1-score': 0.9693717382302708, 'support': 10182} weighted_avg {'precision': 0.9706296495104269, 'recall': 0.9705362404242781, 'f1-score': 0.970514473554642, 'support': 10182}
 
time = 23.42 secondes

Val loss 0.9310339822878235 accuracy 0.8524734973907471 macro_avg {'precision': 0.8605339598944765, 'recall': 0.8543177950749812, 'f1-score': 0.8542081170396892, 'support': 1132} weighted_avg {'precision': 0.8640416383134301, 'recall': 0.8524734982332155, 'f1-score': 0.8549982809805515, 'support': 1132}
 
----------
Epoch 9/40
time = 637.81 secondes

Train loss 0.1209269448156886 accuracy 0.9720094799995422 macro_avg {'precision': 0.9704399378770114, 'recall': 0.9705719035623815, 'f1-score': 0.9704507646867497, 'support': 10182} weighted_avg {'precision': 0.972159297509647, 'recall': 0.9720094284030643, 'f1-score': 0.9720303270470257, 'support': 10182}
 
time = 23.25 secondes

Val loss 0.8848030001698161 accuracy 0.8630741834640503 macro_avg {'precision': 0.8778548724966374, 'recall': 0.8670558069132488, 'f1-score': 0.8677762548458647, 'support': 1132} weighted_avg {'precision': 0.8776602017475639, 'recall': 0.8630742049469965, 'f1-score': 0.8652301323760689, 'support': 1132}
 
----------
Epoch 10/40
time = 637.36 secondes

Train loss 0.10729890415294013 accuracy 0.9780986309051514 macro_avg {'precision': 0.9779193309665043, 'recall': 0.9777973624573111, 'f1-score': 0.977827104067179, 'support': 10182} weighted_avg {'precision': 0.9781544695816492, 'recall': 0.9780986053820467, 'f1-score': 0.9780962318092582, 'support': 10182}
 
time = 23.47 secondes

Val loss 0.8722038868540885 accuracy 0.8683745861053467 macro_avg {'precision': 0.8788568575968252, 'recall': 0.8671364271546309, 'f1-score': 0.869171585900081, 'support': 1132} weighted_avg {'precision': 0.8792356518142838, 'recall': 0.8683745583038869, 'f1-score': 0.8701031408361998, 'support': 1132}
 
----------
Epoch 11/40
time = 636.30 secondes

Train loss 0.10940588439480851 accuracy 0.9786878824234009 macro_avg {'precision': 0.9780814467987001, 'recall': 0.9779639099711377, 'f1-score': 0.9780055610294751, 'support': 10182} weighted_avg {'precision': 0.9787088878596661, 'recall': 0.9786878805735612, 'f1-score': 0.978680910770696, 'support': 10182}
 
time = 23.66 secondes

Val loss 0.9348058769246563 accuracy 0.8657243847846985 macro_avg {'precision': 0.8769338370149541, 'recall': 0.8700992332595524, 'f1-score': 0.8686234488996428, 'support': 1132} weighted_avg {'precision': 0.8796644890862196, 'recall': 0.8657243816254417, 'f1-score': 0.867618342157461, 'support': 1132}
 
----------
Epoch 12/40
time = 636.71 secondes

Train loss 0.09386073000375178 accuracy 0.9812414646148682 macro_avg {'precision': 0.9811612543498638, 'recall': 0.9812501416462138, 'f1-score': 0.9811917594943853, 'support': 10182} weighted_avg {'precision': 0.9812658795116844, 'recall': 0.981241406403457, 'f1-score': 0.9812392852116406, 'support': 10182}
 
time = 23.43 secondes

Val loss 1.0074244355083966 accuracy 0.8586572408676147 macro_avg {'precision': 0.872185240022789, 'recall': 0.8631492566248147, 'f1-score': 0.8632551564976607, 'support': 1132} weighted_avg {'precision': 0.8718726443984014, 'recall': 0.8586572438162544, 'f1-score': 0.8604772716864025, 'support': 1132}
 
----------
Epoch 13/40
time = 636.91 secondes

Train loss 0.10075636638830646 accuracy 0.9798664450645447 macro_avg {'precision': 0.9796750542320316, 'recall': 0.9796406875009149, 'f1-score': 0.9796403203920201, 'support': 10182} weighted_avg {'precision': 0.9798598223214958, 'recall': 0.9798664309565901, 'f1-score': 0.9798452240629429, 'support': 10182}
 
time = 23.61 secondes

Val loss 0.9302929794265393 accuracy 0.8763250708580017 macro_avg {'precision': 0.880630908503187, 'recall': 0.8734750806257987, 'f1-score': 0.8730069429766327, 'support': 1132} weighted_avg {'precision': 0.8811918202774581, 'recall': 0.8763250883392226, 'f1-score': 0.875442169641582, 'support': 1132}
 
----------
Epoch 14/40
time = 637.45 secondes

Train loss 0.10318995838618147 accuracy 0.9803575277328491 macro_avg {'precision': 0.9796778873852764, 'recall': 0.9795366863229077, 'f1-score': 0.9795621021809863, 'support': 10182} weighted_avg {'precision': 0.9804508050672154, 'recall': 0.9803574936161854, 'f1-score': 0.9803575462071188, 'support': 10182}
 
time = 23.57 secondes

Val loss 1.121814567818713 accuracy 0.8507066965103149 macro_avg {'precision': 0.8740645708422266, 'recall': 0.8606368873439371, 'f1-score': 0.857934320144252, 'support': 1132} weighted_avg {'precision': 0.8774266120280462, 'recall': 0.8507067137809188, 'f1-score': 0.8536186015748248, 'support': 1132}
 
----------
Epoch 15/40
time = 637.10 secondes

Train loss 0.0883775396230552 accuracy 0.983598530292511 macro_avg {'precision': 0.982806449057534, 'recall': 0.9830085166616079, 'f1-score': 0.9828939162936084, 'support': 10182} weighted_avg {'precision': 0.983628112619103, 'recall': 0.9835985071695148, 'f1-score': 0.9836002151163471, 'support': 10182}
 
time = 23.51 secondes

Val loss 0.9732307663907191 accuracy 0.8763250708580017 macro_avg {'precision': 0.8844522107499359, 'recall': 0.8794653722317586, 'f1-score': 0.8776232744891471, 'support': 1132} weighted_avg {'precision': 0.8869701546612044, 'recall': 0.8763250883392226, 'f1-score': 0.8776974238198063, 'support': 1132}
 
----------
Epoch 16/40
time = 636.83 secondes

Train loss 0.08620290426213277 accuracy 0.9842860102653503 macro_avg {'precision': 0.984054022815589, 'recall': 0.9838713323347607, 'f1-score': 0.983941529924793, 'support': 10182} weighted_avg {'precision': 0.9843368334369751, 'recall': 0.9842859948929483, 'f1-score': 0.9842902872901395, 'support': 10182}
 
time = 23.24 secondes

Val loss 1.1640953554437352 accuracy 0.8586572408676147 macro_avg {'precision': 0.8691509147580023, 'recall': 0.863157342370779, 'f1-score': 0.8599031157789083, 'support': 1132} weighted_avg {'precision': 0.8737715133486278, 'recall': 0.8586572438162544, 'f1-score': 0.859912336786686, 'support': 1132}
 
----------
Epoch 17/40
time = 637.15 secondes

Train loss 0.07094283069677565 accuracy 0.9865449070930481 macro_avg {'precision': 0.9864809166308401, 'recall': 0.9866936679070053, 'f1-score': 0.9865656091330773, 'support': 10182} weighted_avg {'precision': 0.9865981182459334, 'recall': 0.986544883127087, 'f1-score': 0.9865507009642781, 'support': 10182}
 
time = 23.46 secondes

Val loss 0.9409400241871276 accuracy 0.8674911856651306 macro_avg {'precision': 0.8724135832588222, 'recall': 0.8696738516627557, 'f1-score': 0.8658776450801906, 'support': 1132} weighted_avg {'precision': 0.8790047542537752, 'recall': 0.8674911660777385, 'f1-score': 0.8681226063699965, 'support': 1132}
 
----------
Epoch 18/40
time = 634.68 secondes

Train loss 0.09432760256091209 accuracy 0.9838931560516357 macro_avg {'precision': 0.9836639744262078, 'recall': 0.9835474946622924, 'f1-score': 0.9835846796426482, 'support': 10182} weighted_avg {'precision': 0.9839555212654151, 'recall': 0.983893144765272, 'f1-score': 0.9839029133631051, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.985599982247255 accuracy 0.8825088143348694 macro_avg {'precision': 0.8863868348623433, 'recall': 0.8855250270101495, 'f1-score': 0.8846196301908273, 'support': 1132} weighted_avg {'precision': 0.8867605620850304, 'recall': 0.8825088339222615, 'f1-score': 0.8833853263591473, 'support': 1132}
 
----------
Epoch 19/40
time = 636.14 secondes

Train loss 0.09220760208645258 accuracy 0.9841877818107605 macro_avg {'precision': 0.9838936151302727, 'recall': 0.9839993909340867, 'f1-score': 0.9839129192058993, 'support': 10182} weighted_avg {'precision': 0.98426122683466, 'recall': 0.9841877823610292, 'f1-score': 0.9841920362757236, 'support': 10182}
 
time = 23.31 secondes

Val loss 0.9537898464209128 accuracy 0.8851590156555176 macro_avg {'precision': 0.8935605359786635, 'recall': 0.8852478650174366, 'f1-score': 0.8861237132687846, 'support': 1132} weighted_avg {'precision': 0.8923998461183206, 'recall': 0.8851590106007067, 'f1-score': 0.885389934020102, 'support': 1132}
 
----------
Epoch 20/40
time = 637.62 secondes

Train loss 0.06259232405638007 accuracy 0.9890984296798706 macro_avg {'precision': 0.9891644355460324, 'recall': 0.989134886309029, 'f1-score': 0.9891365059928772, 'support': 10182} weighted_avg {'precision': 0.9891159145124775, 'recall': 0.9890984089569829, 'f1-score': 0.9890949718707163, 'support': 10182}
 
time = 23.34 secondes

Val loss 0.981840782632197 accuracy 0.8719081282615662 macro_avg {'precision': 0.878350288226644, 'recall': 0.8771534704426633, 'f1-score': 0.873694322949307, 'support': 1132} weighted_avg {'precision': 0.8823075709949886, 'recall': 0.8719081272084805, 'f1-score': 0.8727384917388045, 'support': 1132}
 
----------
Epoch 21/40
time = 636.59 secondes

Train loss 0.06055157946901653 accuracy 0.9879198670387268 macro_avg {'precision': 0.9882452157003503, 'recall': 0.9881061799432102, 'f1-score': 0.9881709455063078, 'support': 10182} weighted_avg {'precision': 0.9879392524132122, 'recall': 0.987919858573954, 'f1-score': 0.987925100222785, 'support': 10182}
 
time = 23.51 secondes

Val loss 0.939514422498895 accuracy 0.8816254734992981 macro_avg {'precision': 0.8805130721241923, 'recall': 0.8835582157830564, 'f1-score': 0.8806356197318607, 'support': 1132} weighted_avg {'precision': 0.8862793862258675, 'recall': 0.8816254416961131, 'f1-score': 0.8826892088436007, 'support': 1132}
 
----------
Epoch 22/40
time = 636.48 secondes

Train loss 0.07209791640583477 accuracy 0.9886073470115662 macro_avg {'precision': 0.9883832269159434, 'recall': 0.9886824295490086, 'f1-score': 0.9884867928848549, 'support': 10182} weighted_avg {'precision': 0.9886884466481543, 'recall': 0.9886073462973876, 'f1-score': 0.988601821041708, 'support': 10182}
 
time = 23.45 secondes

Val loss 0.9167201660473464 accuracy 0.8851590156555176 macro_avg {'precision': 0.8907347827453174, 'recall': 0.8878301572688752, 'f1-score': 0.8868574865345744, 'support': 1132} weighted_avg {'precision': 0.8911218696269461, 'recall': 0.8851590106007067, 'f1-score': 0.8854039579675784, 'support': 1132}
 
----------
Epoch 23/40
time = 633.17 secondes

Train loss 0.05123979084694823 accuracy 0.9911609292030334 macro_avg {'precision': 0.9911650652528914, 'recall': 0.9911712478978151, 'f1-score': 0.9911607753490974, 'support': 10182} weighted_avg {'precision': 0.9911760671309302, 'recall': 0.9911608721272834, 'f1-score': 0.9911611958937704, 'support': 10182}
 
time = 22.97 secondes

Val loss 1.0210471871771365 accuracy 0.879858672618866 macro_avg {'precision': 0.883209608817418, 'recall': 0.8833397276911061, 'f1-score': 0.8807813786691568, 'support': 1132} weighted_avg {'precision': 0.8865573843863019, 'recall': 0.8798586572438163, 'f1-score': 0.8807622136574644, 'support': 1132}
 
----------
Epoch 24/40
