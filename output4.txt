[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_1
----------
Epoch 1/40
time = 51.01 secondes

Train loss 0.6484671542138765 accuracy 0.5988371968269348 macro_avg {'precision': 0.5110780423280423, 'recall': 0.5065341417031028, 'f1-score': 0.48207592457002096, 'support': 516} weighted_avg {'precision': 0.5468878173577786, 'recall': 0.5988372093023255, 'f1-score': 0.5497498120475199, 'support': 516}
 
time = 1.55 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.5683221146464348 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 44.12 secondes

Train loss 0.4316922918413625 accuracy 0.7926356792449951 macro_avg {'precision': 0.7960464015151515, 'recall': 0.743908782081498, 'f1-score': 0.757253338140314, 'support': 516} weighted_avg {'precision': 0.7941244751291989, 'recall': 0.7926356589147286, 'f1-score': 0.7827573460081663, 'support': 516}
 
time = 1.46 secondes

Val loss 0.449489651247859 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 3/40
time = 43.89 secondes

Train loss 0.2424559767047564 accuracy 0.9089147448539734 macro_avg {'precision': 0.9004681950274459, 'recall': 0.903182549615591, 'f1-score': 0.9017879198979488, 'support': 516} weighted_avg {'precision': 0.9092873698728202, 'recall': 0.9089147286821705, 'f1-score': 0.909068544699096, 'support': 516}
 
time = 1.55 secondes

Val loss 0.4411683026701212 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 44.17 secondes

Train loss 0.1529593360469197 accuracy 0.9457364082336426 macro_avg {'precision': 0.9422062545929616, 'recall': 0.9401362092225671, 'f1-score': 0.9411534701857283, 'support': 516} weighted_avg {'precision': 0.9456397168615254, 'recall': 0.9457364341085271, 'f1-score': 0.9456727818318217, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5802359767258167 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 45.27 secondes

Train loss 0.12945584704478583 accuracy 0.9554263353347778 macro_avg {'precision': 0.9496527777777778, 'recall': 0.9546592331323245, 'f1-score': 0.9520459660507421, 'support': 516} weighted_avg {'precision': 0.9558637489233419, 'recall': 0.9554263565891473, 'f1-score': 0.9555497285066072, 'support': 516}
 
time = 1.55 secondes

Val loss 0.7515546977519989 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 6/40
time = 44.18 secondes

Train loss 0.21710896671213437 accuracy 0.9379844665527344 macro_avg {'precision': 0.9294591283038685, 'recall': 0.9386733416770964, 'f1-score': 0.933641975308642, 'support': 516} weighted_avg {'precision': 0.939382097406025, 'recall': 0.937984496124031, 'f1-score': 0.9383134749736817, 'support': 516}
 
time = 1.55 secondes

Val loss 0.5084730144590139 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 7/40
time = 44.01 secondes

Train loss 0.10898110413020759 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9283211827278137 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 8/40
time = 44.55 secondes

Train loss 0.11305292753968388 accuracy 0.9709302186965942 macro_avg {'precision': 0.9634177215189874, 'recall': 0.9760496074638754, 'f1-score': 0.9689922480620154, 'support': 516} weighted_avg {'precision': 0.9726140712393289, 'recall': 0.9709302325581395, 'f1-score': 0.9711255333213148, 'support': 516}
 
time = 1.58 secondes

Val loss 0.7843436300754547 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 9/40
time = 44.00 secondes

Train loss 0.05085022477997524 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8264092803001404 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 44.06 secondes

Train loss 0.158899184715031 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9702771045267582 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 11/40
time = 44.35 secondes

Train loss 0.25782609717377153 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 1.57 secondes

Val loss 1.470630556344986 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 12/40
time = 43.90 secondes

Train loss 0.1689814520950401 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.55 secondes

Val loss 1.090615674853325 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 13/40
time = 43.92 secondes

Train loss 0.09597611122157876 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 1.59 secondes

Val loss 1.825234591960907 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 45.56 secondes

Train loss 0.2778898612613733 accuracy 0.9496123790740967 macro_avg {'precision': 0.9508524573771311, 'recall': 0.9397136030427644, 'f1-score': 0.9448246364414028, 'support': 516} weighted_avg {'precision': 0.9497654962213129, 'recall': 0.9496124031007752, 'f1-score': 0.9492974184521322, 'support': 516}
 
time = 1.56 secondes

Val loss 1.219543695449829 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 15/40
time = 44.01 secondes

Train loss 0.34743856010380003 accuracy 0.9282945990562439 macro_avg {'precision': 0.9255952380952381, 'recall': 0.9183801180046487, 'f1-score': 0.9217717317817705, 'support': 516} weighted_avg {'precision': 0.9280523255813954, 'recall': 0.9282945736434108, 'f1-score': 0.9279881314083002, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2637725472450256 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 43.99 secondes

Train loss 0.11533800290657603 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.45 secondes

Val loss 0.7785346657037735 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 17/40
time = 44.31 secondes

Train loss 0.0562764307198284 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5886543691158295 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 18/40
time = 43.99 secondes

Train loss 0.047533505874911716 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.55 secondes

Val loss 2.50537246465683 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 19/40
time = 44.07 secondes

Train loss 0.19089577305765654 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 1.58 secondes

Val loss 1.4012825787067413 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 20/40
time = 44.89 secondes

Train loss 0.11779450446413124 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.55 secondes

Val loss 1.0541197881102562 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 21/40
time = 44.36 secondes

Train loss 0.3096776276105436 accuracy 0.9418604373931885 macro_avg {'precision': 0.9308755760368663, 'recall': 0.9544072948328268, 'f1-score': 0.9389859368102416, 'support': 516} weighted_avg {'precision': 0.9498981888329225, 'recall': 0.9418604651162791, 'f1-score': 0.9426304280553963, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2989709228277206 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 22/40
time = 44.08 secondes

Train loss 0.037103814627643616 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4808869734406471 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 23/40
time = 43.88 secondes

Train loss 0.10719815791217667 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.57 secondes

Val loss 1.588595598936081 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 45.78 secondes

Train loss 0.0005445388616697693 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.1775003522634506 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 25/40
time = 43.48 secondes

Train loss 0.03956041625122342 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.4926774203777313 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 26/40
time = 44.06 secondes

Train loss 0.039494372762750245 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.47 secondes

Val loss 0.9543888717889786 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 27/40
time = 44.02 secondes

Train loss 0.20654129833300514 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1127036213874817 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 28/40
time = 44.38 secondes

Train loss 0.08597790196566193 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.56 secondes

Val loss 0.9251856654882431 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 29/40
time = 43.94 secondes

Train loss 0.05596733741527494 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.55 secondes

Val loss 1.495246946811676 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 30/40
time = 44.32 secondes

Train loss 0.0015362289687442226 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2893417179584503 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 31/40
time = 43.91 secondes

Train loss 0.032513707035060645 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5993940383195877 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 32/40
time = 45.50 secondes

Train loss 0.0002029587110772616 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0544578731060028 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 43.52 secondes

Train loss 0.029213577178201045 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.55 secondes

Val loss 1.403256580233574 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 34/40
time = 44.14 secondes

Train loss 0.009672270263598131 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1019640415906906 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 35/40
time = 44.15 secondes

Train loss 0.06142923340093782 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.55 secondes

Val loss 1.8624211996793747 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 36/40
time = 44.10 secondes

Train loss 0.08137650245396688 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.55 secondes

Val loss 1.3643712997436523 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 43.92 secondes

Train loss 0.00014526665957722193 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.829428106546402 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 38/40
time = 45.52 secondes

Train loss 0.017648513299002043 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4478777945041656 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 39/40
time = 43.93 secondes

Train loss 7.32476613793e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.1653912216424942 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 40/40
time = 43.80 secondes

Train loss 6.468607578867567e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0635102614760399 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 26 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}

average train time 44.42560328841209

average val time 1.5440983295440673
 
time = 1.87 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.975, 'recall': 0.962962962962963, 'f1-score': 0.9679487179487178, 'support': 65} weighted_avg {'precision': 0.9707692307692308, 'recall': 0.9692307692307692, 'f1-score': 0.969033530571992, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 38.10 secondes

Train loss 0.6118795040881995 accuracy 0.6705426573753357 macro_avg {'precision': 0.8036640898019697, 'recall': 0.5466085854070836, 'f1-score': 0.4844730717694351, 'support': 516} weighted_avg {'precision': 0.7641175490314387, 'recall': 0.6705426356589147, 'f1-score': 0.5697049365188096, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5209976881742477 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 37.85 secondes

Train loss 0.48955667289820587 accuracy 0.7965116500854492 macro_avg {'precision': 0.781183155080214, 'recall': 0.7734912146676852, 'f1-score': 0.7768965645035764, 'support': 516} weighted_avg {'precision': 0.7944553693570452, 'recall': 0.7965116279069767, 'f1-score': 0.7951013945903923, 'support': 516}
 
time = 1.08 secondes

Val loss 0.595069408416748 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 3/40
time = 37.81 secondes

Train loss 0.30316798772775766 accuracy 0.8895348906517029 macro_avg {'precision': 0.880791788856305, 'recall': 0.8799067015587667, 'f1-score': 0.8803451488362822, 'support': 516} weighted_avg {'precision': 0.8894134518478103, 'recall': 0.8895348837209303, 'f1-score': 0.889470619840618, 'support': 516}
 
time = 1.19 secondes

Val loss 0.5372880846261978 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 4/40
time = 37.85 secondes

Train loss 0.20889812222484386 accuracy 0.9224806427955627 macro_avg {'precision': 0.9218768328445748, 'recall': 0.9092046876777791, 'f1-score': 0.914900634946813, 'support': 516} weighted_avg {'precision': 0.9223933256041282, 'recall': 0.9224806201550387, 'f1-score': 0.9218899719569951, 'support': 516}
 
time = 1.20 secondes

Val loss 0.4207959845662117 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 5/40
time = 37.82 secondes

Train loss 0.18637056183069944 accuracy 0.9302325248718262 macro_avg {'precision': 0.9262541229754344, 'recall': 0.9222079547486306, 'f1-score': 0.9241610190250674, 'support': 516} weighted_avg {'precision': 0.930020374930783, 'recall': 0.9302325581395349, 'f1-score': 0.9300662146021522, 'support': 516}
 
time = 1.21 secondes

Val loss 0.6602529734373093 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 6/40
time = 37.79 secondes

Train loss 0.14330859389156103 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.21 secondes

Val loss 1.461461827158928 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 7/40
time = 37.87 secondes

Train loss 0.18790496054641675 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4476582985371351 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 8/40
time = 37.69 secondes

Train loss 0.09559408770733033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.26 secondes

Val loss 0.5406880658119917 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 9/40
time = 37.75 secondes

Train loss 0.1151893291142628 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4370921105146408 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 10/40
time = 37.75 secondes

Train loss 0.07336072456867744 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 1.21 secondes

Val loss 0.702195331454277 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 11/40
time = 37.78 secondes

Train loss 0.3720530061594521 accuracy 0.9224806427955627 macro_avg {'precision': 0.9147160692710431, 'recall': 0.9184370072980836, 'f1-score': 0.9165089073345956, 'support': 516} weighted_avg {'precision': 0.9229441754316953, 'recall': 0.9224806201550387, 'f1-score': 0.9226537132802691, 'support': 516}
 
time = 1.20 secondes

Val loss 0.8342920988798141 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 12/40
time = 37.75 secondes

Train loss 0.07604224078717049 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.20 secondes

Val loss 1.607848584651947 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 37.72 secondes

Train loss 0.06278472877756665 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.12 secondes

Val loss 1.1636684089899063 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 37.88 secondes

Train loss 0.0886974026860006 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0803441554307938 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 15/40
time = 37.73 secondes

Train loss 0.18989273916249108 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1421115472912788 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 16/40
time = 37.75 secondes

Train loss 0.134410434301103 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 1.20 secondes

Val loss 0.840247965825256 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 17/40
time = 37.81 secondes

Train loss 0.2334456879268118 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.15 secondes

Val loss 1.9791456758975983 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 18/40
time = 37.81 secondes

Train loss 0.3454848953829655 accuracy 0.9321705102920532 macro_avg {'precision': 0.9218514328808447, 'recall': 0.9364221510654552, 'f1-score': 0.9279418747082364, 'support': 516} weighted_avg {'precision': 0.9354191512621743, 'recall': 0.9321705426356589, 'f1-score': 0.9327456414737882, 'support': 516}
 
time = 1.21 secondes

Val loss 1.0730529874563217 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 37.80 secondes

Train loss 0.5731687560927998 accuracy 0.893410861492157 macro_avg {'precision': 0.8810267995296157, 'recall': 0.9002568145246493, 'f1-score': 0.887839829902265, 'support': 516} weighted_avg {'precision': 0.901010158075819, 'recall': 0.8934108527131783, 'f1-score': 0.8947188319818274, 'support': 516}
 
time = 1.20 secondes

Val loss 1.6587252020835876 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 20/40
time = 37.78 secondes

Train loss 0.01211984952290853 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.20 secondes

Val loss 1.930421382188797 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 21/40
time = 37.77 secondes

Train loss 0.045483751377270724 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.21 secondes

Val loss 1.6416117027401924 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 22/40
time = 37.76 secondes

Train loss 0.29783655986389157 accuracy 0.9476743936538696 macro_avg {'precision': 0.9601904164051056, 'recall': 0.9289615265835541, 'f1-score': 0.9415523121908653, 'support': 516} weighted_avg {'precision': 0.9509337930318529, 'recall': 0.9476744186046512, 'f1-score': 0.9467579356085755, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1994608283857815 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 23/40
time = 37.74 secondes

Train loss 0.14321513218932191 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.13 secondes

Val loss 2.326024055480957 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 24/40
time = 37.84 secondes

Train loss 0.13996493708779753 accuracy 0.9689922332763672 macro_avg {'precision': 0.9723513824308785, 'recall': 0.9606813711945126, 'f1-score': 0.9660459301177864, 'support': 516} weighted_avg {'precision': 0.9694069560087888, 'recall': 0.9689922480620154, 'f1-score': 0.9687984113551584, 'support': 516}
 
time = 1.21 secondes

Val loss 1.151353769004345 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 25/40
time = 37.77 secondes

Train loss 0.07647180854110047 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 1.20 secondes

Val loss 1.5654735565185547 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 26/40
time = 37.81 secondes

Train loss 0.06018229337959466 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.54 secondes

Val loss 2.059539884328842 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 27/40
time = 37.69 secondes

Train loss 0.007575753189898519 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 1.2836417332291603 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 28/40
time = 37.66 secondes

Train loss 0.013093511755648775 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.21 secondes

Val loss 1.4585321545600891 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 37.74 secondes

Train loss 0.002264237272108651 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.11 secondes

Val loss 0.7938464358448982 accuracy 0.890625 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}
 
----------
Epoch 30/40
time = 37.75 secondes

Train loss 0.03174836540512677 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.20 secondes

Val loss 2.0029105246067047 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 31/40
time = 37.73 secondes

Train loss 0.0012360489841243675 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.2074059695005417 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 32/40
time = 37.75 secondes

Train loss 0.02636931425667805 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.21 secondes

Val loss 1.9673902988433838 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 33/40
time = 37.83 secondes

Train loss 0.007728801291677607 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.21 secondes

Val loss 1.282075360417366 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 34/40
time = 37.73 secondes

Train loss 0.07562345547392563 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.21 secondes

Val loss 1.3651388138532639 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 35/40
time = 37.86 secondes

Train loss 0.030789600984655517 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4954889714717865 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 37.92 secondes

Train loss 0.007754079878698879 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 2.5611753165721893 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 37/40
time = 37.74 secondes

Train loss 0.028849033851160624 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4328311383724213 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 38/40
time = 37.83 secondes

Train loss 0.0003410180462665404 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4899351298809052 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 37.80 secondes

Train loss 9.842868486444014e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4465883821249008 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 40/40
time = 37.73 secondes

Train loss 9.114195045461229e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4567785859107971 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 29 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}

average train time 37.78849007487297

average val time 1.206836348772049
 
time = 1.33 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_1
----------
Epoch 1/40
time = 110.88 secondes

Train loss 0.6208415446859418 accuracy 0.6744186282157898 macro_avg {'precision': 0.6623230428108478, 'recall': 0.5773450579458088, 'f1-score': 0.558974358974359, 'support': 516} weighted_avg {'precision': 0.6667727054567667, 'recall': 0.6744186046511628, 'f1-score': 0.6210693699065791, 'support': 516}
 
time = 3.19 secondes

Val loss 0.574383407831192 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 2/40
time = 109.91 secondes

Train loss 0.3958620198748328 accuracy 0.8449612259864807 macro_avg {'precision': 0.8415011809990377, 'recall': 0.81725533540302, 'f1-score': 0.8265779391006252, 'support': 516} weighted_avg {'precision': 0.8440338017318607, 'recall': 0.8449612403100775, 'f1-score': 0.8421162055990907, 'support': 516}
 
time = 3.28 secondes

Val loss 0.4010474197566509 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 3/40
time = 109.93 secondes

Train loss 0.3053324529618928 accuracy 0.8759689927101135 macro_avg {'precision': 0.8691565421728913, 'recall': 0.8600360840661216, 'f1-score': 0.8641837204711456, 'support': 516} weighted_avg {'precision': 0.8751279490289051, 'recall': 0.875968992248062, 'f1-score': 0.8751936454206333, 'support': 516}
 
time = 3.27 secondes

Val loss 0.38428428024053574 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 4/40
time = 109.08 secondes

Train loss 0.2765027183023366 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 3.26 secondes

Val loss 0.7334373593330383 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 110.76 secondes

Train loss 0.22509805762180776 accuracy 0.9147287011146545 macro_avg {'precision': 0.9085000408263249, 'recall': 0.9065877801797702, 'f1-score': 0.9075268817204302, 'support': 516} weighted_avg {'precision': 0.9145580344624819, 'recall': 0.9147286821705426, 'f1-score': 0.9146286571642912, 'support': 516}
 
time = 3.25 secondes

Val loss 0.7033235356211662 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 6/40
time = 110.85 secondes

Train loss 0.15903478742323138 accuracy 0.9418604373931885 macro_avg {'precision': 0.944808641871282, 'recall': 0.9290184158769891, 'f1-score': 0.9360119047619048, 'support': 516} weighted_avg {'precision': 0.9423460471700442, 'recall': 0.9418604651162791, 'f1-score': 0.9413355943152454, 'support': 516}
 
time = 3.25 secondes

Val loss 0.49331944435834885 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 7/40
time = 110.33 secondes

Train loss 0.12874467689261743 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 3.25 secondes

Val loss 0.8076917231082916 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 8/40
time = 108.78 secondes

Train loss 0.33719487134790554 accuracy 0.9031007885932922 macro_avg {'precision': 0.8929307452671938, 'recall': 0.8997773190514117, 'f1-score': 0.896093435360451, 'support': 516} weighted_avg {'precision': 0.9043922075654308, 'recall': 0.9031007751937985, 'f1-score': 0.9035191238405655, 'support': 516}
 
time = 3.32 secondes

Val loss 0.5185783058404922 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 9/40
time = 111.68 secondes

Train loss 0.11759842450335396 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 3.27 secondes

Val loss 1.3767000436782837 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 110.36 secondes

Train loss 0.14430443289915496 accuracy 0.9651162624359131 macro_avg {'precision': 0.9724383422323926, 'recall': 0.9530256977065488, 'f1-score': 0.9615072194685277, 'support': 516} weighted_avg {'precision': 0.9664628653985261, 'recall': 0.9651162790697675, 'f1-score': 0.9647508046797686, 'support': 516}
 
time = 3.27 secondes

Val loss 1.8720239400863647 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 11/40
time = 110.00 secondes

Train loss 0.12741439464452647 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 3.22 secondes

Val loss 0.9112781442236155 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 12/40
time = 109.55 secondes

Train loss 0.22378833774674797 accuracy 0.9515503644943237 macro_avg {'precision': 0.9511904761904761, 'recall': 0.9435414397867464, 'f1-score': 0.9471430620147098, 'support': 516} weighted_avg {'precision': 0.9515180878552972, 'recall': 0.9515503875968992, 'f1-score': 0.9513433320326352, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4541483521461487 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 13/40
time = 111.18 secondes

Train loss 0.08695977868399385 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 3.38 secondes

Val loss 1.3499275147914886 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 14/40
time = 109.51 secondes

Train loss 0.04540810167831792 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.28 secondes

Val loss 1.129255250096321 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 109.35 secondes

Train loss 0.10000095951854195 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 3.24 secondes

Val loss 1.1267386078834534 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 16/40
time = 109.07 secondes

Train loss 0.1841409852671804 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 3.25 secondes

Val loss 1.2525547221302986 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 17/40
time = 111.61 secondes

Train loss 0.14371543455865432 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 3.25 secondes

Val loss 1.8017287254333496 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 110.01 secondes

Train loss 0.026182726556505782 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 3.17 secondes

Val loss 2.1328561305999756 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 19/40
time = 109.64 secondes

Train loss 0.05814073682422256 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 3.28 secondes

Val loss 1.7090198695659637 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 20/40
time = 111.29 secondes

Train loss 0.3225959445028848 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 3.34 secondes

Val loss 1.4081890285015106 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 21/40
time = 109.58 secondes

Train loss 0.18450812213510895 accuracy 0.9670542478561401 macro_avg {'precision': 0.9620949074074074, 'recall': 0.9672398940233733, 'f1-score': 0.9645557140375051, 'support': 516} weighted_avg {'precision': 0.9674299723657767, 'recall': 0.9670542635658915, 'f1-score': 0.9671454515048837, 'support': 516}
 
time = 3.34 secondes

Val loss 1.443152278661728 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 22/40
time = 109.29 secondes

Train loss 0.1166973254073651 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 3.29 secondes

Val loss 1.3189547210931778 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 23/40
time = 110.10 secondes

Train loss 0.03705972561764418 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.70 secondes

Val loss 0.9670058307237923 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 24/40
time = 108.54 secondes

Train loss 0.025352893767624417 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 3.23 secondes

Val loss 1.124589666724205 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 25/40
time = 111.11 secondes

Train loss 0.003198813354670578 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.26 secondes

Val loss 2.3936354517936707 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 26/40
time = 110.60 secondes

Train loss 0.4131214476651759 accuracy 0.9321705102920532 macro_avg {'precision': 0.9477564102564102, 'recall': 0.9087251922045414, 'f1-score': 0.9235804626640205, 'support': 516} weighted_avg {'precision': 0.9369074239713775, 'recall': 0.9321705426356589, 'f1-score': 0.9306312797505676, 'support': 516}
 
time = 3.22 secondes

Val loss 1.064063373953104 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 27/40
time = 110.08 secondes

Train loss 0.051691933078638445 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 2.3253433406352997 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 28/40
time = 109.66 secondes

Train loss 0.07212349785241355 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 3.28 secondes

Val loss 1.338636502623558 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 29/40
time = 109.71 secondes

Train loss 0.01786365759581906 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.81 secondes

Val loss 2.1446223855018616 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 30/40
time = 110.43 secondes

Train loss 0.03289659313811695 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 3.14 secondes

Val loss 2.208230972290039 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 31/40
time = 109.60 secondes

Train loss 0.12458896116379148 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 3.41 secondes

Val loss 1.610340178012848 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 32/40
time = 110.46 secondes

Train loss 0.08795193974087438 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 3.23 secondes

Val loss 1.4975502341985703 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 33/40
time = 110.99 secondes

Train loss 0.011843261595596701 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.22 secondes

Val loss 1.7452628016471863 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 109.94 secondes

Train loss 0.05261105974116645 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 1.709677278995514 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 35/40
time = 111.28 secondes

Train loss 0.00017651771265787608 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.22 secondes

Val loss 1.3155423551797867 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 36/40
time = 110.01 secondes

Train loss 0.08733464148870994 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 3.22 secondes

Val loss 1.668299823999405 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 37/40
time = 110.29 secondes

Train loss 0.0001407871130857419 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.26 secondes

Val loss 2.0013616383075714 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 38/40
time = 111.20 secondes

Train loss 0.05291752666292296 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 3.27 secondes

Val loss 2.1024787425994873 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 39/40
time = 109.91 secondes

Train loss 0.00010726286101006818 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.24 secondes

Val loss 1.9849089980125427 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 40/40
time = 110.32 secondes

Train loss 0.00011339108084829411 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.27 secondes

Val loss 1.9019729495048523 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 23 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 110.17144976854324

average val time 3.2268829464912416
 
time = 3.95 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9366471734892787, 'recall': 0.9366471734892787, 'f1-score': 0.9366471734892787, 'support': 65} weighted_avg {'precision': 0.9384615384615385, 'recall': 0.9384615384615385, 'f1-score': 0.9384615384615385, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 75.91 GiB already allocated; 15.62 MiB free; 77.17 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 74.19 GiB already allocated; 333.62 MiB free; 76.86 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 835.62 MiB free; 76.37 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_1
----------
Epoch 1/40
time = 34.11 secondes

Train loss 0.6567783157030741 accuracy 0.5968992114067078 macro_avg {'precision': 0.506608419822477, 'recall': 0.503860344911659, 'f1-score': 0.4783318751822689, 'support': 516} weighted_avg {'precision': 0.5432406892730166, 'recall': 0.5968992248062015, 'f1-score': 0.5467731908188479, 'support': 516}
 
time = 1.72 secondes

Val loss 0.6483345180749893 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 30.15 secondes

Train loss 0.4736546386371959 accuracy 0.7674418687820435 macro_avg {'precision': 0.7691305157326382, 'recall': 0.7114575036978041, 'f1-score': 0.7233491198284336, 'support': 516} weighted_avg {'precision': 0.768242408147497, 'recall': 0.7674418604651163, 'f1-score': 0.7537431449275062, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4845489114522934 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 3/40
time = 30.09 secondes

Train loss 0.4114030446067001 accuracy 0.8217054009437561 macro_avg {'precision': 0.8068540362118344, 'recall': 0.8082505729564553, 'f1-score': 0.8075376232485729, 'support': 516} weighted_avg {'precision': 0.8221359014332488, 'recall': 0.8217054263565892, 'f1-score': 0.8219078235438464, 'support': 516}
 
time = 1.51 secondes

Val loss 0.4701610952615738 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 4/40
time = 30.33 secondes

Train loss 0.23988865823908287 accuracy 0.9089147448539734 macro_avg {'precision': 0.9011092371562014, 'recall': 0.9020285096630528, 'f1-score': 0.9015646879756469, 'support': 516} weighted_avg {'precision': 0.90902623570397, 'recall': 0.9089147286821705, 'f1-score': 0.9089668566304437, 'support': 516}
 
time = 1.54 secondes

Val loss 0.5063801445066929 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 5/40
time = 30.12 secondes

Train loss 0.19853529572543321 accuracy 0.9341084957122803 macro_avg {'precision': 0.9374523264683448, 'recall': 0.9194772686637518, 'f1-score': 0.9272914145516635, 'support': 516} weighted_avg {'precision': 0.9347234787339092, 'recall': 0.9341085271317829, 'f1-score': 0.9334181866173404, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6985029019415379 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 6/40
time = 29.68 secondes

Train loss 0.13120987192219633 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.53 secondes

Val loss 0.89257001131773 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 7/40
time = 30.08 secondes

Train loss 0.25928406263913284 accuracy 0.9244186282157898 macro_avg {'precision': 0.912962962962963, 'recall': 0.9349592835199845, 'f1-score': 0.9206113134006872, 'support': 516} weighted_avg {'precision': 0.9323284524834912, 'recall': 0.9244186046511628, 'f1-score': 0.9253956970959751, 'support': 516}
 
time = 1.52 secondes

Val loss 1.392895758152008 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 8/40
time = 30.36 secondes

Train loss 0.16238292923310038 accuracy 0.9476743936538696 macro_avg {'precision': 0.9520348837209303, 'recall': 0.9347317263462445, 'f1-score': 0.9423361078114459, 'support': 516} weighted_avg {'precision': 0.9484349648458626, 'recall': 0.9476744186046512, 'f1-score': 0.9471643889110329, 'support': 516}
 
time = 1.16 secondes

Val loss 1.112002745270729 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 9/40
time = 29.99 secondes

Train loss 0.17208194819095574 accuracy 0.9515503644943237 macro_avg {'precision': 0.9523801608935576, 'recall': 0.9423873998342083, 'f1-score': 0.9470127949723769, 'support': 516} weighted_avg {'precision': 0.9516437370927733, 'recall': 0.9515503875968992, 'f1-score': 0.951279935056365, 'support': 516}
 
time = 1.54 secondes

Val loss 1.9113911390304565 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 10/40
time = 30.00 secondes

Train loss 0.12845719239681563 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.44 secondes

Val loss 1.2405556738376617 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 11/40
time = 30.26 secondes

Train loss 0.12190856214235254 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.56 secondes

Val loss 1.4983333051204681 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 12/40
time = 30.20 secondes

Train loss 0.3027792275860327 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6353834420442581 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 13/40
time = 30.58 secondes

Train loss 0.13359660844787757 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.51 secondes

Val loss 1.317705549299717 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 14/40
time = 30.22 secondes

Train loss 0.35118401451803616 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6398965418338776 accuracy 0.75 macro_avg {'precision': 0.7658730158730158, 'recall': 0.771255060728745, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.7896825396825398, 'recall': 0.75, 'f1-score': 0.7512218963831867, 'support': 64}
 
----------
Epoch 15/40
time = 30.09 secondes

Train loss 0.2099811704432465 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0730313323438168 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 16/40
time = 29.83 secondes

Train loss 0.1772331207202197 accuracy 0.9496123790740967 macro_avg {'precision': 0.9395900755124056, 'recall': 0.9570242023308356, 'f1-score': 0.9466289005935427, 'support': 516} weighted_avg {'precision': 0.9535427276452338, 'recall': 0.9496124031007752, 'f1-score': 0.9501015018724527, 'support': 516}
 
time = 1.52 secondes

Val loss 0.8848967030644417 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 30.43 secondes

Train loss 0.12311049633894017 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.54 secondes

Val loss 1.6023304760456085 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 18/40
time = 30.37 secondes

Train loss 0.1917411569946015 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6791450828313828 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 19/40
time = 30.56 secondes

Train loss 0.12897297652649065 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.25 secondes

Val loss 2.6572521924972534 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 20/40
time = 30.00 secondes

Train loss 0.060254706360865384 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5116469860076904 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 21/40
time = 30.25 secondes

Train loss 0.06364064671145046 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.53 secondes

Val loss 2.110848158597946 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 30.22 secondes

Train loss 0.12491783101281864 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.52 secondes

Val loss 1.531773641705513 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 23/40
time = 30.21 secondes

Train loss 0.012602947508143685 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 2.040704756975174 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 30.00 secondes

Train loss 0.05516036900812513 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.7398687303066254 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 25/40
time = 29.99 secondes

Train loss 0.06968361505344299 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4831435531377792 accuracy 0.65625 macro_avg {'precision': 0.6916666666666667, 'recall': 0.6862348178137652, 'f1-score': 0.6559139784946237, 'support': 64} weighted_avg {'precision': 0.7182291666666667, 'recall': 0.65625, 'f1-score': 0.6538978494623656, 'support': 64}
 
----------
Epoch 26/40
time = 30.16 secondes

Train loss 0.26840145522785885 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 1.51 secondes

Val loss 2.416386902332306 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 27/40
time = 30.61 secondes

Train loss 0.1729861014719063 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.53 secondes

Val loss 1.3513858765363693 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 28/40
time = 30.34 secondes

Train loss 0.09652199355729284 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.52 secondes

Val loss 1.4449278712272644 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 29/40
time = 30.13 secondes

Train loss 0.06417314555338552 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6720838844776154 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 30/40
time = 30.15 secondes

Train loss 0.027461881629609376 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1987587958574295 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 31/40
time = 30.22 secondes

Train loss 0.019796533098115382 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.50 secondes

Val loss 1.758107453584671 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 32/40
time = 30.60 secondes

Train loss 0.0010739933647776277 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.749803751707077 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 33/40
time = 30.48 secondes

Train loss 0.0030313041213296606 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.52 secondes

Val loss 1.9742971658706665 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 34/40
time = 30.12 secondes

Train loss 0.04233543748920387 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6585697829723358 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 30.02 secondes

Train loss 0.03061917360294804 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9593395292758942 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 36/40
time = 30.42 secondes

Train loss 0.00010399735522999738 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5130765438079834 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 29.91 secondes

Train loss 0.025205528952056105 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 1.288802832365036 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 38/40
time = 30.42 secondes

Train loss 0.0004712519331598852 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5494403094053268 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 39/40
time = 29.81 secondes

Train loss 0.011907795049685801 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5029142796993256 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 40/40
time = 29.96 secondes

Train loss 6.596711186416955e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.487855225801468 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 16 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 30.286575692892075

average val time 1.5072179853916168
 
time = 1.77 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_1
----------
Epoch 1/40
time = 42.42 secondes

Train loss 0.6250356182907567 accuracy 0.6705426573753357 macro_avg {'precision': 0.6828752642706131, 'recall': 0.5604570648375404, 'f1-score': 0.5244497452022119, 'support': 516} weighted_avg {'precision': 0.6788026287755872, 'recall': 0.6705426356589147, 'f1-score': 0.5969853761282671, 'support': 516}
 
time = 1.89 secondes

Val loss 0.6419084966182709 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 2/40
time = 39.83 secondes

Train loss 0.42234978328148526 accuracy 0.815891444683075 macro_avg {'precision': 0.8018849206349206, 'recall': 0.7967670627245096, 'f1-score': 0.7991436356558972, 'support': 516} weighted_avg {'precision': 0.8146344745908699, 'recall': 0.8158914728682171, 'f1-score': 0.8151046617240141, 'support': 516}
 
time = 1.70 secondes

Val loss 0.5241179391741753 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 3/40
time = 39.82 secondes

Train loss 0.23846285417675972 accuracy 0.9050387740135193 macro_avg {'precision': 0.897605083088954, 'recall': 0.8966809160801652, 'f1-score': 0.8971388121575057, 'support': 516} weighted_avg {'precision': 0.9049355141815757, 'recall': 0.9050387596899225, 'f1-score': 0.9049835153015839, 'support': 516}
 
time = 1.70 secondes

Val loss 0.6524151861667633 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 40.28 secondes

Train loss 0.2745478278533979 accuracy 0.9069767594337463 macro_avg {'precision': 0.9153321706040907, 'recall': 0.883198153536076, 'f1-score': 0.8956504154097642, 'support': 516} weighted_avg {'precision': 0.9093398950921601, 'recall': 0.9069767441860465, 'f1-score': 0.9051112312111295, 'support': 516}
 
time = 1.73 secondes

Val loss 1.2008797079324722 accuracy 0.703125 macro_avg {'precision': 0.7232232232232232, 'recall': 0.7257085020242915, 'f1-score': 0.703052503052503, 'support': 64} weighted_avg {'precision': 0.7473410910910911, 'recall': 0.703125, 'f1-score': 0.7039224664224664, 'support': 64}
 
----------
Epoch 5/40
time = 40.08 secondes

Train loss 0.28934638497109216 accuracy 0.8798449635505676 macro_avg {'precision': 0.8689971808296415, 'recall': 0.8723079173642379, 'f1-score': 0.8705888063686229, 'support': 516} weighted_avg {'precision': 0.880492589921544, 'recall': 0.8798449612403101, 'f1-score': 0.8801132555844169, 'support': 516}
 
time = 1.70 secondes

Val loss 0.7955436855554581 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 39.92 secondes

Train loss 0.2750699918233846 accuracy 0.9418604373931885 macro_avg {'precision': 0.9309719704364803, 'recall': 0.9520992149277505, 'f1-score': 0.9387658227848101, 'support': 516} weighted_avg {'precision': 0.9481515953757185, 'recall': 0.9418604651162791, 'f1-score': 0.9425540918457462, 'support': 516}
 
time = 1.73 secondes

Val loss 1.878673255443573 accuracy 0.6875 macro_avg {'precision': 0.7678571428571428, 'recall': 0.6214574898785425, 'f1-score': 0.5994993742177722, 'support': 64} weighted_avg {'precision': 0.7477678571428572, 'recall': 0.6875, 'f1-score': 0.6346996245306633, 'support': 64}
 
----------
Epoch 7/40
time = 39.94 secondes

Train loss 0.28978963807193475 accuracy 0.9186046719551086 macro_avg {'precision': 0.9366415676313163, 'recall': 0.8911626546169725, 'f1-score': 0.9076104564909707, 'support': 516} weighted_avg {'precision': 0.9246731464232292, 'recall': 0.9186046511627907, 'f1-score': 0.9163811061729844, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1333815194666386 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 8/40
time = 39.81 secondes

Train loss 0.21337093538463567 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.72 secondes

Val loss 1.1721819788217545 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 9/40
time = 39.85 secondes

Train loss 0.0754368415981651 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.76 secondes

Val loss 2.0241373777389526 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 39.76 secondes

Train loss 0.08350599995262173 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.70 secondes

Val loss 2.0022046864032745 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 11/40
time = 39.74 secondes

Train loss 0.6093260882449668 accuracy 0.8798449635505676 macro_avg {'precision': 0.8726522222038029, 'recall': 0.8653836776490094, 'f1-score': 0.8687539999015408, 'support': 516} weighted_avg {'precision': 0.8791165826037017, 'recall': 0.8798449612403101, 'f1-score': 0.8792534433022423, 'support': 516}
 
time = 1.70 secondes

Val loss 2.404471606016159 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 12/40
time = 39.98 secondes

Train loss 0.3092179125083159 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.70 secondes

Val loss 1.633028268814087 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 13/40
time = 40.14 secondes

Train loss 0.13167497588526175 accuracy 0.9573643207550049 macro_avg {'precision': 0.9521224325412807, 'recall': 0.9561789899712303, 'f1-score': 0.9540798990340276, 'support': 516} weighted_avg {'precision': 0.9576772908490916, 'recall': 0.9573643410852714, 'f1-score': 0.957459542304148, 'support': 516}
 
time = 1.75 secondes

Val loss 1.672478049993515 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 14/40
time = 39.49 secondes

Train loss 0.4766141516663607 accuracy 0.9263566136360168 macro_avg {'precision': 0.9438772754280775, 'recall': 0.9007038018302098, 'f1-score': 0.9166609996599795, 'support': 516} weighted_avg {'precision': 0.9320299542286858, 'recall': 0.9263565891472868, 'f1-score': 0.9244835775417842, 'support': 516}
 
time = 1.69 secondes

Val loss 2.2375268042087555 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 15/40
time = 40.06 secondes

Train loss 0.05417639433069395 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.70 secondes

Val loss 2.018381655216217 accuracy 0.65625 macro_avg {'precision': 0.735632183908046, 'recall': 0.5829959514170041, 'f1-score': 0.5416666666666667, 'support': 64} weighted_avg {'precision': 0.7173132183908046, 'recall': 0.65625, 'f1-score': 0.5846354166666667, 'support': 64}
 
----------
Epoch 16/40
time = 40.26 secondes

Train loss 0.22395754638493987 accuracy 0.9670542478561401 macro_avg {'precision': 0.9613081897931741, 'recall': 0.9683939339759114, 'f1-score': 0.96463345307643, 'support': 516} weighted_avg {'precision': 0.9676827403847825, 'recall': 0.9670542635658915, 'f1-score': 0.9671797870727524, 'support': 516}
 
time = 1.74 secondes

Val loss 1.5666281580924988 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 17/40
time = 39.89 secondes

Train loss 0.11491544869810848 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.70 secondes

Val loss 1.9758648425340652 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 18/40
time = 40.18 secondes

Train loss 0.08700183632985996 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.70 secondes

Val loss 2.046614795923233 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 19/40
time = 39.76 secondes

Train loss 0.1932369931115924 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.71 secondes

Val loss 3.070172905921936 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 20/40
time = 39.60 secondes

Train loss 0.0617340229288278 accuracy 0.9844961166381836 macro_avg {'precision': 0.982185330809184, 'recall': 0.9843798254311396, 'f1-score': 0.9832641411520499, 'support': 516} weighted_avg {'precision': 0.9845631035446839, 'recall': 0.9844961240310077, 'f1-score': 0.9845137237864214, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9089334458112717 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 21/40
time = 39.93 secondes

Train loss 0.15142547276197796 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.68 secondes

Val loss 2.0300595462322235 accuracy 0.734375 macro_avg {'precision': 0.7292358803986712, 'recall': 0.7095141700404858, 'f1-score': 0.7142106645652745, 'support': 64} weighted_avg {'precision': 0.7320390365448506, 'recall': 0.734375, 'f1-score': 0.7284443131074336, 'support': 64}
 
----------
Epoch 22/40
time = 40.49 secondes

Train loss 0.025180068211105237 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.48 secondes

Val loss 2.083932340145111 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 23/40
time = 40.11 secondes

Train loss 0.10263278931729887 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.73 secondes

Val loss 2.140805721282959 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 24/40
time = 40.12 secondes

Train loss 0.09598735824847333 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.71 secondes

Val loss 1.9200657904148102 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 25/40
time = 39.90 secondes

Train loss 0.03630040398605739 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.71 secondes

Val loss 2.409125506877899 accuracy 0.6875 macro_avg {'precision': 0.7115384615384616, 'recall': 0.6336032388663968, 'f1-score': 0.6257309941520468, 'support': 64} weighted_avg {'precision': 0.7043269230769231, 'recall': 0.6875, 'f1-score': 0.6542397660818713, 'support': 64}
 
----------
Epoch 26/40
time = 40.28 secondes

Train loss 0.11398647684109164 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.70 secondes

Val loss 1.6969991028308868 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 27/40
time = 39.74 secondes

Train loss 0.03631438125398056 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.66 secondes

Val loss 2.0768578946590424 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 28/40
time = 40.67 secondes

Train loss 0.021378272981427002 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.70 secondes

Val loss 1.80338816344738 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 29/40
time = 42.45 secondes

Train loss 0.1305558308681198 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.80 secondes

Val loss 2.1289318799972534 accuracy 0.71875 macro_avg {'precision': 0.7198067632850241, 'recall': 0.6842105263157895, 'f1-score': 0.6883116883116883, 'support': 64} weighted_avg {'precision': 0.7193538647342995, 'recall': 0.71875, 'f1-score': 0.7065746753246753, 'support': 64}
 
----------
Epoch 30/40
time = 44.53 secondes

Train loss 0.03969892109528177 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.48625186085701 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 31/40
time = 44.24 secondes

Train loss 0.04418978331175987 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.05 secondes

Val loss 3.244371175765991 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 32/40
time = 47.47 secondes

Train loss 0.16101114878675257 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.06 secondes

Val loss 2.9142743349075317 accuracy 0.703125 macro_avg {'precision': 0.7040050062578223, 'recall': 0.6649797570850202, 'f1-score': 0.6673050615595076, 'support': 64} weighted_avg {'precision': 0.7036530037546934, 'recall': 0.703125, 'f1-score': 0.6877735978112176, 'support': 64}
 
----------
Epoch 33/40
time = 47.88 secondes

Train loss 2.1954282078006532e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9673337638378143 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 34/40
time = 46.76 secondes

Train loss 0.03560937149769884 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.08 secondes

Val loss 1.7495750486850739 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 35/40
time = 47.76 secondes

Train loss 0.006746183475942499 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.98 secondes

Val loss 2.435919463634491 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 36/40
time = 48.03 secondes

Train loss 3.4828258514718264e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9676964730024338 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 37/40
time = 45.91 secondes

Train loss 0.016310500819958124 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.06 secondes

Val loss 2.0135097205638885 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 38/40
time = 47.30 secondes

Train loss 0.00013055886004374108 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 2.496764689683914 accuracy 0.71875 macro_avg {'precision': 0.7136363636363636, 'recall': 0.6902834008097165, 'f1-score': 0.6945917285259808, 'support': 64} weighted_avg {'precision': 0.7161931818181818, 'recall': 0.71875, 'f1-score': 0.7106972428419936, 'support': 64}
 
----------
Epoch 39/40
time = 47.50 secondes

Train loss 3.786359433654456e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.07 secondes

Val loss 2.6430184841156006 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 40/40
time = 46.40 secondes

Train loss 4.828717950052427e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 2.6777721643447876 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 3 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}

average train time 41.95685896277428

average val time 1.7974827766418457
 
time = 2.38 secondes

test_accuracy 0.9230769276618958 macro_avg {'precision': 0.9303861788617886, 'recall': 0.9127680311890838, 'f1-score': 0.9193348225366097, 'support': 65} weighted_avg {'precision': 0.9256566604127581, 'recall': 0.9230769230769231, 'f1-score': 0.9222750443897131, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_1
----------
Epoch 1/40
time = 61.82 secondes

Train loss 0.6339394504373724 accuracy 0.6782945990562439 macro_avg {'precision': 0.7138382541720154, 'recall': 0.5676901321457016, 'f1-score': 0.5327310814349306, 'support': 516} weighted_avg {'precision': 0.7022087550128867, 'recall': 0.6782945736434108, 'f1-score': 0.6045019699543897, 'support': 516}
 
time = 2.62 secondes

Val loss 0.4559163898229599 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 58.22 secondes

Train loss 0.4738170120752219 accuracy 0.786821722984314 macro_avg {'precision': 0.7700048074532102, 'recall': 0.7647383905206182, 'f1-score': 0.7671441933737015, 'support': 516} weighted_avg {'precision': 0.7851187284164176, 'recall': 0.7868217054263565, 'f1-score': 0.7857722381168817, 'support': 516}
 
time = 2.35 secondes

Val loss 0.38838502764701843 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 58.31 secondes

Train loss 0.3877472387570323 accuracy 0.8527131676673889 macro_avg {'precision': 0.8473997563612031, 'recall': 0.8291045625213335, 'f1-score': 0.8366081695915204, 'support': 516} weighted_avg {'precision': 0.8515453932542725, 'recall': 0.8527131782945736, 'f1-score': 0.8507249056151844, 'support': 516}
 
time = 2.36 secondes

Val loss 0.3989737406373024 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 58.86 secondes

Train loss 0.26272348845095345 accuracy 0.9069767594337463 macro_avg {'precision': 0.8986942381437795, 'recall': 0.9005087528241471, 'f1-score': 0.8995848469122989, 'support': 516} weighted_avg {'precision': 0.9072168168249528, 'recall': 0.9069767441860465, 'f1-score': 0.9070823427185286, 'support': 516}
 
time = 2.38 secondes

Val loss 0.4658821187913418 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 58.26 secondes

Train loss 0.23204717748431544 accuracy 0.9166666865348816 macro_avg {'precision': 0.9184121047262837, 'recall': 0.9000292573509094, 'f1-score': 0.9079240585122939, 'support': 516} weighted_avg {'precision': 0.9170038535645473, 'recall': 0.9166666666666666, 'f1-score': 0.915731922398589, 'support': 516}
 
time = 2.45 secondes

Val loss 0.4648912623524666 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 6/40
time = 59.51 secondes

Train loss 0.18294251295314592 accuracy 0.9437984228134155 macro_avg {'precision': 0.9396383186705768, 'recall': 0.9386164523836614, 'f1-score': 0.9391229704605646, 'support': 516} weighted_avg {'precision': 0.9437406700159889, 'recall': 0.9437984496124031, 'f1-score': 0.9437657539539986, 'support': 516}
 
time = 2.45 secondes

Val loss 0.5831400752067566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 7/40
time = 58.56 secondes

Train loss 0.11872421393601337 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 2.36 secondes

Val loss 0.7752330601215363 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 8/40
time = 58.48 secondes

Train loss 0.1414358509566889 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 2.45 secondes

Val loss 1.2355355620384216 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 9/40
time = 59.07 secondes

Train loss 0.33448161012986954 accuracy 0.9127907156944275 macro_avg {'precision': 0.9153325123152709, 'recall': 0.8946816637680217, 'f1-score': 0.9033848586348223, 'support': 516} weighted_avg {'precision': 0.9133273029874875, 'recall': 0.9127906976744186, 'f1-score': 0.9116806918250254, 'support': 516}
 
time = 2.40 secondes

Val loss 0.9954286515712738 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.31 secondes

Train loss 0.1268364178778773 accuracy 0.9689922332763672 macro_avg {'precision': 0.9630002396357537, 'recall': 0.9710677307673553, 'f1-score': 0.9667498993153444, 'support': 516} weighted_avg {'precision': 0.9697531380209059, 'recall': 0.9689922480620154, 'f1-score': 0.9691261196289811, 'support': 516}
 
time = 2.40 secondes

Val loss 1.954167127609253 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 58.91 secondes

Train loss 0.36159477563694853 accuracy 0.9360464811325073 macro_avg {'precision': 0.9484901685393259, 'recall': 0.9152268257399672, 'f1-score': 0.928361976482467, 'support': 516} weighted_avg {'precision': 0.9394748660830938, 'recall': 0.936046511627907, 'f1-score': 0.9348188048295232, 'support': 516}
 
time = 2.48 secondes

Val loss 1.4643760919570923 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 58.41 secondes

Train loss 0.21275364523965187 accuracy 0.9437984228134155 macro_avg {'precision': 0.9387649195640893, 'recall': 0.9397704923361995, 'f1-score': 0.9392633181126333, 'support': 516} weighted_avg {'precision': 0.9438703571845218, 'recall': 0.9437984496124031, 'f1-score': 0.943830613665593, 'support': 516}
 
time = 2.41 secondes

Val loss 1.2357655763626099 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 13/40
time = 58.06 secondes

Train loss 0.1287964549688199 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 2.42 secondes

Val loss 1.1264150738716125 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 14/40
time = 58.88 secondes

Train loss 0.10440204414286806 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 2.41 secondes

Val loss 1.4035854237154126 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 15/40
time = 58.88 secondes

Train loss 0.48789847710445017 accuracy 0.9108527302742004 macro_avg {'precision': 0.8991163131399716, 'recall': 0.9162427059798774, 'f1-score': 0.9057556699066133, 'support': 516} weighted_avg {'precision': 0.9161221172771334, 'recall': 0.9108527131782945, 'f1-score': 0.9117871711114361, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3586439620703459 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 16/40
time = 58.00 secondes

Train loss 0.0835169197272273 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.26 secondes

Val loss 1.465189978480339 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 17/40
time = 58.59 secondes

Train loss 0.20039999671897737 accuracy 0.9515503644943237 macro_avg {'precision': 0.9490243583027763, 'recall': 0.9458495196918226, 'f1-score': 0.9473965363269734, 'support': 516} weighted_avg {'precision': 0.9514479810038943, 'recall': 0.9515503875968992, 'f1-score': 0.9514644458464872, 'support': 516}
 
time = 2.42 secondes

Val loss 1.5267489701509476 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 59.03 secondes

Train loss 0.15735966191101453 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 2.16 secondes

Val loss 1.1849833708256483 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 19/40
time = 58.74 secondes

Train loss 0.16154145083507473 accuracy 0.9689922332763672 macro_avg {'precision': 0.9697699348561062, 'recall': 0.9629894510995888, 'f1-score': 0.966212676794133, 'support': 516} weighted_avg {'precision': 0.9690528470329837, 'recall': 0.9689922480620154, 'f1-score': 0.9688795627403446, 'support': 516}
 
time = 2.42 secondes

Val loss 1.720089614391327 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 20/40
time = 58.46 secondes

Train loss 0.004716151664483318 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.42 secondes

Val loss 2.0340465307235718 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 21/40
time = 58.66 secondes

Train loss 0.2387493375894282 accuracy 0.9534883499145508 macro_avg {'precision': 0.9593185863208746, 'recall': 0.9404450368155, 'f1-score': 0.9486762926247037, 'support': 516} weighted_avg {'precision': 0.9545605953992947, 'recall': 0.9534883720930233, 'f1-score': 0.953001072906358, 'support': 516}
 
time = 2.41 secondes

Val loss 1.6022708751261234 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 22/40
time = 58.13 secondes

Train loss 0.05865256421163918 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.14 secondes

Val loss 1.5636188238859177 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 23/40
time = 58.35 secondes

Train loss 0.07743679428963471 accuracy 0.9767441749572754 macro_avg {'precision': 0.9795766125690035, 'recall': 0.97022251840775, 'f1-score': 0.9745975483680402, 'support': 516} weighted_avg {'precision': 0.9770310140487893, 'recall': 0.9767441860465116, 'f1-score': 0.9766296987036599, 'support': 516}
 
time = 2.38 secondes

Val loss 1.8072308003902435 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 24/40
time = 58.15 secondes

Train loss 0.02226735371346656 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.2751631364226341 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 25/40
time = 58.87 secondes

Train loss 0.12391318097202615 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2276369780302048 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 26/40
time = 59.12 secondes

Train loss 0.32974892150455026 accuracy 0.9496123790740967 macro_avg {'precision': 0.9521407624633431, 'recall': 0.9385595630902264, 'f1-score': 0.9446854127154284, 'support': 516} weighted_avg {'precision': 0.9499779490327127, 'recall': 0.9496124031007752, 'f1-score': 0.9492284817720469, 'support': 516}
 
time = 2.35 secondes

Val loss 1.8140016496181488 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 27/40
time = 57.89 secondes

Train loss 0.1245776131483691 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3423852026462555 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 28/40
time = 59.42 secondes

Train loss 0.048813668804624205 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.25 secondes

Val loss 1.7185466327355243 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 29/40
time = 58.82 secondes

Train loss 0.12386098914584816 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.41 secondes

Val loss 1.7375836186110973 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 30/40
time = 57.85 secondes

Train loss 0.28565631554837717 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 2.42 secondes

Val loss 1.2771421447396278 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 59.25 secondes

Train loss 0.03930170394530499 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.38 secondes

Val loss 1.3815643042325974 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 32/40
time = 58.58 secondes

Train loss 0.04664655021770159 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.36 secondes

Val loss 1.896320316940546 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 33/40
time = 58.45 secondes

Train loss 0.05259972890042153 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.42 secondes

Val loss 1.584839090704918 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 34/40
time = 58.90 secondes

Train loss 0.0065927045802571665 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.40 secondes

Val loss 1.713086411356926 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 35/40
time = 58.26 secondes

Train loss 6.341708991165046e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.37 secondes

Val loss 1.5881700813770294 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 59.00 secondes

Train loss 0.03260832701617443 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6551595330238342 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 37/40
time = 58.72 secondes

Train loss 4.282978018939806e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.42 secondes

Val loss 1.847426414489746 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 38/40
time = 58.59 secondes

Train loss 0.001748274674327783 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.44 secondes

Val loss 1.9580502212047577 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 39/40
time = 58.92 secondes

Train loss 2.799836141948066e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.43 secondes

Val loss 1.7082684509950923 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 40/40
time = 58.69 secondes

Train loss 2.625838103333742e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.23 secondes

Val loss 1.714829411037499 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 5 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 58.70047608613968

average val time 2.3862047672271727
 
time = 2.68 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9049707602339181, 'recall': 0.9049707602339181, 'f1-score': 0.9049707602339181, 'support': 65} weighted_avg {'precision': 0.9076923076923077, 'recall': 0.9076923076923077, 'f1-score': 0.9076923076923077, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_1
----------
Epoch 1/40
time = 106.88 secondes

Train loss 0.6526508042306611 accuracy 0.6279069781303406 macro_avg {'precision': 0.4541854185418542, 'recall': 0.4958633356630853, 'f1-score': 0.40004360148245044, 'support': 516} weighted_avg {'precision': 0.5041215749481925, 'recall': 0.627906976744186, 'f1-score': 0.5017939137062444, 'support': 516}
 
time = 3.11 secondes

Val loss 0.6721367835998535 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 106.89 secondes

Train loss 0.43885405948667816 accuracy 0.8062015771865845 macro_avg {'precision': 0.8098145330585675, 'recall': 0.7614713196690668, 'f1-score': 0.7750575434191254, 'support': 516} weighted_avg {'precision': 0.8076945184334525, 'recall': 0.8062015503875969, 'f1-score': 0.7980911319062242, 'support': 516}
 
time = 2.88 secondes

Val loss 0.4404994025826454 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 3/40
time = 106.60 secondes

Train loss 0.40031165674780356 accuracy 0.8217054009437561 macro_avg {'precision': 0.8062950527505053, 'recall': 0.8128667327666076, 'f1-score': 0.8092206790123456, 'support': 516} weighted_avg {'precision': 0.8242317171116847, 'recall': 0.8217054263565892, 'f1-score': 0.8226512405493349, 'support': 516}
 
time = 2.92 secondes

Val loss 0.391114741563797 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 4/40
time = 105.75 secondes

Train loss 0.28435496082811645 accuracy 0.8798449635505676 macro_avg {'precision': 0.8699998374591615, 'recall': 0.8699998374591615, 'f1-score': 0.8699998374591615, 'support': 516} weighted_avg {'precision': 0.8798449612403101, 'recall': 0.8798449612403101, 'f1-score': 0.8798449612403101, 'support': 516}
 
time = 2.95 secondes

Val loss 0.4086569473147392 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 5/40
time = 106.16 secondes

Train loss 0.20852691790258343 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 2.94 secondes

Val loss 0.5047884732484818 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 6/40
time = 106.52 secondes

Train loss 0.16236198668819712 accuracy 0.9476743936538696 macro_avg {'precision': 0.949331550802139, 'recall': 0.9370398062513207, 'f1-score': 0.9426305451580625, 'support': 516} weighted_avg {'precision': 0.9478967168262654, 'recall': 0.9476744186046512, 'f1-score': 0.9473117871803867, 'support': 516}
 
time = 2.58 secondes

Val loss 0.8151003122329712 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 105.54 secondes

Train loss 0.08078327928458086 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 2.92 secondes

Val loss 0.6999615952372551 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 8/40
time = 106.53 secondes

Train loss 0.11735291272458254 accuracy 0.9709302186965942 macro_avg {'precision': 0.9725198412698413, 'recall': 0.9645092079384945, 'f1-score': 0.9682858372088259, 'support': 516} weighted_avg {'precision': 0.9710728897502153, 'recall': 0.9709302325581395, 'f1-score': 0.9708059992195812, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2831183820962906 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 9/40
time = 106.23 secondes

Train loss 0.0728111248145896 accuracy 0.9864341020584106 macro_avg {'precision': 0.9870350969093766, 'recall': 0.9835915023649693, 'f1-score': 0.9852710301715525, 'support': 516} weighted_avg {'precision': 0.9864584729210066, 'recall': 0.9864341085271318, 'f1-score': 0.9864100448370163, 'support': 516}
 
time = 2.91 secondes

Val loss 0.9561516046524048 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 10/40
time = 105.93 secondes

Train loss 0.2727364226893494 accuracy 0.9379844665527344 macro_avg {'precision': 0.9270919120503458, 'recall': 0.9467516213448629, 'f1-score': 0.9345624019149374, 'support': 516} weighted_avg {'precision': 0.943546666714849, 'recall': 0.937984496124031, 'f1-score': 0.9386805152852027, 'support': 516}
 
time = 2.96 secondes

Val loss 1.4376361966133118 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 106.26 secondes

Train loss 0.12369245507447472 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 2.72 secondes

Val loss 1.1686341911554337 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 12/40
time = 106.88 secondes

Train loss 0.2239398792400166 accuracy 0.9573643207550049 macro_avg {'precision': 0.9570050300981281, 'recall': 0.9504087902085399, 'f1-score': 0.953542430591933, 'support': 516} weighted_avg {'precision': 0.9573363428265328, 'recall': 0.9573643410852714, 'f1-score': 0.9572093987679738, 'support': 516}
 
time = 2.86 secondes

Val loss 1.1280450572958216 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 13/40
time = 106.33 secondes

Train loss 0.3481568852316052 accuracy 0.9263566136360168 macro_avg {'precision': 0.9149700229644129, 'recall': 0.9376330803114283, 'f1-score': 0.9227155199596393, 'support': 516} weighted_avg {'precision': 0.9346882229396336, 'recall': 0.9263565891472868, 'f1-score': 0.9273318755368353, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4471633285284042 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 106.67 secondes

Train loss 0.48193736072007043 accuracy 0.9050387740135193 macro_avg {'precision': 0.8969252724442138, 'recall': 0.8978349560327032, 'f1-score': 0.8973759512937596, 'support': 516} weighted_avg {'precision': 0.9051546666505755, 'recall': 0.9050387596899225, 'f1-score': 0.9050931058487606, 'support': 516}
 
time = 2.98 secondes

Val loss 0.9556056782603264 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 107.11 secondes

Train loss 0.10950636746587628 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 2.92 secondes

Val loss 0.8155350387096405 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 16/40
time = 106.23 secondes

Train loss 0.06793631725612971 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 2.93 secondes

Val loss 1.228388026356697 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 106.23 secondes

Train loss 0.05855598292758011 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 2.83 secondes

Val loss 1.8716845214366913 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 18/40
time = 107.01 secondes

Train loss 0.14278572121486033 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 2.84 secondes

Val loss 1.782495766878128 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 19/40
time = 106.10 secondes

Train loss 0.07426900208740721 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 2.93 secondes

Val loss 2.292722076177597 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 20/40
time = 106.35 secondes

Train loss 0.41266337134275644 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.85 secondes

Val loss 1.568615734577179 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 21/40
time = 106.13 secondes

Train loss 0.17685734642763043 accuracy 0.9689922332763672 macro_avg {'precision': 0.9752439373767674, 'recall': 0.9583732912894365, 'f1-score': 0.9658730158730159, 'support': 516} weighted_avg {'precision': 0.9700219380667982, 'recall': 0.9689922480620154, 'f1-score': 0.968712316968131, 'support': 516}
 
time = 2.93 secondes

Val loss 1.8788590763724642 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 22/40
time = 106.25 secondes

Train loss 0.12393657735017106 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 2.94 secondes

Val loss 1.6335791498422623 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 23/40
time = 105.71 secondes

Train loss 0.11917145702450811 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 2.95 secondes

Val loss 2.4499506056308746 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 106.71 secondes

Train loss 0.19166216588818122 accuracy 0.9670542478561401 macro_avg {'precision': 0.9629480142072974, 'recall': 0.9660858540708352, 'f1-score': 0.9644764816652156, 'support': 516} weighted_avg {'precision': 0.9672354216258294, 'recall': 0.9670542635658915, 'f1-score': 0.9671098991464816, 'support': 516}
 
time = 2.69 secondes

Val loss 1.499965339899063 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 25/40
time = 107.58 secondes

Train loss 0.10124347070990497 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2261934950947762 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 26/40
time = 106.31 secondes

Train loss 0.06265152328353107 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.82 secondes

Val loss 1.6787316799163818 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 27/40
time = 105.84 secondes

Train loss 0.1743168470257484 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 2.94 secondes

Val loss 1.4443295896053314 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 28/40
time = 106.49 secondes

Train loss 0.023845222142523253 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.92 secondes

Val loss 2.4346551597118378 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 29/40
time = 106.91 secondes

Train loss 0.39005585973350343 accuracy 0.9418604373931885 macro_avg {'precision': 0.958217270194986, 'recall': 0.9197860962566845, 'f1-score': 0.934593023255814, 'support': 516} weighted_avg {'precision': 0.9467189220703505, 'recall': 0.9418604651162791, 'f1-score': 0.9405928880475933, 'support': 516}
 
time = 2.92 secondes

Val loss 1.48084257543087 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 30/40
time = 106.69 secondes

Train loss 0.1493743916686402 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.86 secondes

Val loss 1.705119117628783 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 106.46 secondes

Train loss 0.0026505435958053126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.80 secondes

Val loss 1.864279255270958 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 32/40
time = 106.03 secondes

Train loss 0.11904445267789539 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.91 secondes

Val loss 1.48716489225626 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 33/40
time = 106.60 secondes

Train loss 0.0001673200391506367 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.95 secondes

Val loss 2.412769377231598 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 34/40
time = 106.07 secondes

Train loss 0.022556991701783387 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.98 secondes

Val loss 1.9907635897397995 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 35/40
time = 105.99 secondes

Train loss 0.0002379695541810978 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.75 secondes

Val loss 2.076480969786644 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 36/40
time = 106.13 secondes

Train loss 0.020897628651613504 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.87 secondes

Val loss 2.1474937796592712 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 106.13 secondes

Train loss 6.45406376641018e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.761106714606285 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 38/40
time = 105.97 secondes

Train loss 3.172502009406206e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.92 secondes

Val loss 1.883382573723793 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 39/40
time = 106.09 secondes

Train loss 0.0002561505991087126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.94 secondes

Val loss 1.8005222529172897 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 40/40
time = 107.34 secondes

Train loss 2.7276694240616493e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.7226413786411285 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 15 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 106.39002574682236

average val time 2.8956131041049957
 
time = 3.26 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 69.25 GiB already allocated; 718.62 MiB free; 74.20 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 70.56 GiB already allocated; 1.80 GiB free; 73.10 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_1
----------
Epoch 1/40
time = 755.49 secondes

Train loss 1.372331961638512 accuracy 0.6310155391693115 macro_avg {'precision': 0.6227990152221288, 'recall': 0.6155942767044172, 'f1-score': 0.6085424596125351, 'support': 10182} weighted_avg {'precision': 0.6352206755249442, 'recall': 0.6310155175800433, 'f1-score': 0.6229050349104075, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.7946031366435575 accuracy 0.7667844295501709 macro_avg {'precision': 0.7464748114842101, 'recall': 0.7624202961575086, 'f1-score': 0.7477227027896178, 'support': 1132} weighted_avg {'precision': 0.7591497875513612, 'recall': 0.7667844522968198, 'f1-score': 0.7563077766068933, 'support': 1132}
 
----------
Epoch 2/40
time = 754.78 secondes

Train loss 0.5510137719007171 accuracy 0.8354940414428711 macro_avg {'precision': 0.822608970862451, 'recall': 0.8234619063329716, 'f1-score': 0.8207997313937538, 'support': 10182} weighted_avg {'precision': 0.8317195020277058, 'recall': 0.8354940090355529, 'f1-score': 0.8319458919253531, 'support': 10182}
 
time = 23.78 secondes

Val loss 0.6106695998722399 accuracy 0.8162544369697571 macro_avg {'precision': 0.8211281532337369, 'recall': 0.8109693318799313, 'f1-score': 0.8100367090302376, 'support': 1132} weighted_avg {'precision': 0.8237026913105493, 'recall': 0.8162544169611308, 'f1-score': 0.8143292364742848, 'support': 1132}
 
----------
Epoch 3/40
time = 754.66 secondes

Train loss 0.31115727099989143 accuracy 0.9104301929473877 macro_avg {'precision': 0.904979919710013, 'recall': 0.9038584653721854, 'f1-score': 0.9040340139091496, 'support': 10182} weighted_avg {'precision': 0.910529177052902, 'recall': 0.9104301708898055, 'f1-score': 0.9101392321502128, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.6279412276754287 accuracy 0.8365724682807922 macro_avg {'precision': 0.8530049729151175, 'recall': 0.8441911531931096, 'f1-score': 0.8391021139442414, 'support': 1132} weighted_avg {'precision': 0.8585270263452727, 'recall': 0.8365724381625441, 'f1-score': 0.8375765214643205, 'support': 1132}
 
----------
Epoch 4/40
time = 754.37 secondes

Train loss 0.21366391299596552 accuracy 0.9412689208984375 macro_avg {'precision': 0.9377447098015473, 'recall': 0.9374400275467858, 'f1-score': 0.9374969290738285, 'support': 10182} weighted_avg {'precision': 0.940974003326342, 'recall': 0.9412689059123944, 'f1-score': 0.9410440233637504, 'support': 10182}
 
time = 24.28 secondes

Val loss 0.6924298346488619 accuracy 0.843639612197876 macro_avg {'precision': 0.8682274146955926, 'recall': 0.8342303827464101, 'f1-score': 0.8407482412610522, 'support': 1132} weighted_avg {'precision': 0.8709878243092795, 'recall': 0.8436395759717314, 'f1-score': 0.84865035955994, 'support': 1132}
 
----------
Epoch 5/40
time = 752.90 secondes

Train loss 0.16139613372109995 accuracy 0.9572775959968567 macro_avg {'precision': 0.9546306415889925, 'recall': 0.9544967785595271, 'f1-score': 0.9545189898105397, 'support': 10182} weighted_avg {'precision': 0.9574269291066994, 'recall': 0.9572775486152033, 'f1-score': 0.9573085003398356, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.7453474432662864 accuracy 0.8683745861053467 macro_avg {'precision': 0.8653046063444083, 'recall': 0.8638709351951821, 'f1-score': 0.8621702824770379, 'support': 1132} weighted_avg {'precision': 0.8708572071679808, 'recall': 0.8683745583038869, 'f1-score': 0.8670814269455164, 'support': 1132}
 
----------
Epoch 6/40
time = 751.19 secondes

Train loss 0.1632520506621574 accuracy 0.9606168270111084 macro_avg {'precision': 0.9593769843422366, 'recall': 0.959295033199024, 'f1-score': 0.9592826166285946, 'support': 10182} weighted_avg {'precision': 0.9607009086743692, 'recall': 0.9606167747004518, 'f1-score': 0.9606035512368668, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.8076046266770122 accuracy 0.8586572408676147 macro_avg {'precision': 0.8733611505879111, 'recall': 0.8603918737860127, 'f1-score': 0.8611976506316774, 'support': 1132} weighted_avg {'precision': 0.8745645268805701, 'recall': 0.8586572438162544, 'f1-score': 0.8610883425250137, 'support': 1132}
 
----------
Epoch 7/40
time = 752.98 secondes

Train loss 0.1319472046252457 accuracy 0.9680809378623962 macro_avg {'precision': 0.9667779673844444, 'recall': 0.9664714537450386, 'f1-score': 0.9665962629174363, 'support': 10182} weighted_avg {'precision': 0.9680453594040704, 'recall': 0.9680809271263013, 'f1-score': 0.9680377537003787, 'support': 10182}
 
time = 24.23 secondes

Val loss 0.7400198687330334 accuracy 0.8763250708580017 macro_avg {'precision': 0.882719054172991, 'recall': 0.8795807675518855, 'f1-score': 0.8765283658987331, 'support': 1132} weighted_avg {'precision': 0.8845500008690171, 'recall': 0.8763250883392226, 'f1-score': 0.8756405291375831, 'support': 1132}
 
----------
Epoch 8/40
time = 753.98 secondes

Train loss 0.11714227561021276 accuracy 0.9732862114906311 macro_avg {'precision': 0.9730610650496192, 'recall': 0.9731039324220108, 'f1-score': 0.9730458775072742, 'support': 10182} weighted_avg {'precision': 0.9733179267287682, 'recall': 0.9732861913180122, 'f1-score': 0.9732642852113152, 'support': 10182}
 
time = 24.06 secondes

Val loss 0.8056871728515778 accuracy 0.8745583295822144 macro_avg {'precision': 0.8798159382358636, 'recall': 0.8699355610932809, 'f1-score': 0.8694207096865416, 'support': 1132} weighted_avg {'precision': 0.8786456874570715, 'recall': 0.8745583038869258, 'f1-score': 0.8720014860472374, 'support': 1132}
 
----------
Epoch 9/40
time = 751.96 secondes

Train loss 0.11801415112559842 accuracy 0.9736790657043457 macro_avg {'precision': 0.972644628486076, 'recall': 0.9725788801775138, 'f1-score': 0.972562795589426, 'support': 10182} weighted_avg {'precision': 0.9738008963208308, 'recall': 0.9736790414456885, 'f1-score': 0.9736979908628413, 'support': 10182}
 
time = 24.35 secondes

Val loss 1.0753419020801003 accuracy 0.8533568978309631 macro_avg {'precision': 0.8679677448365062, 'recall': 0.8564901278422747, 'f1-score': 0.8529149614998224, 'support': 1132} weighted_avg {'precision': 0.8700975756978135, 'recall': 0.8533568904593639, 'f1-score': 0.8523570552222254, 'support': 1132}
 
----------
Epoch 10/40
time = 749.13 secondes

Train loss 0.10305417418138897 accuracy 0.9778040051460266 macro_avg {'precision': 0.9776383737383597, 'recall': 0.9776333215872335, 'f1-score': 0.977607878384223, 'support': 10182} weighted_avg {'precision': 0.9779062634343646, 'recall': 0.9778039677862895, 'f1-score': 0.9778262756359387, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.9331279173257685 accuracy 0.8683745861053467 macro_avg {'precision': 0.8768015519988897, 'recall': 0.8702840547955544, 'f1-score': 0.8702798287425673, 'support': 1132} weighted_avg {'precision': 0.8767348440272853, 'recall': 0.8683745583038869, 'f1-score': 0.8691743120305949, 'support': 1132}
 
----------
Epoch 11/40
time = 753.27 secondes

Train loss 0.11408827397798271 accuracy 0.976527214050293 macro_avg {'precision': 0.9760512242354531, 'recall': 0.9752069771980449, 'f1-score': 0.9755615259145831, 'support': 10182} weighted_avg {'precision': 0.9766349309311828, 'recall': 0.9765272048713416, 'f1-score': 0.976516826796692, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.8731713990548061 accuracy 0.8816254734992981 macro_avg {'precision': 0.8852490276105718, 'recall': 0.8813630113595456, 'f1-score': 0.8800319787214775, 'support': 1132} weighted_avg {'precision': 0.8892986528284939, 'recall': 0.8816254416961131, 'f1-score': 0.8827693127374225, 'support': 1132}
 
----------
Epoch 12/40
time = 745.70 secondes

Train loss 0.09350815200219639 accuracy 0.9817324876785278 macro_avg {'precision': 0.9811533373948553, 'recall': 0.9812864309053259, 'f1-score': 0.9811952368034825, 'support': 10182} weighted_avg {'precision': 0.9817763636396301, 'recall': 0.9817324690630524, 'f1-score': 0.9817327587328296, 'support': 10182}
 
time = 24.12 secondes

Val loss 0.6727751348406227 accuracy 0.898409903049469 macro_avg {'precision': 0.899681050613302, 'recall': 0.901665548309509, 'f1-score': 0.8990898194638367, 'support': 1132} weighted_avg {'precision': 0.9026512091959225, 'recall': 0.8984098939929329, 'f1-score': 0.8989089010985141, 'support': 1132}
 
----------
Epoch 13/40
time = 753.68 secondes

Train loss 0.08819657378679974 accuracy 0.9833039045333862 macro_avg {'precision': 0.9827605320841689, 'recall': 0.9826348888497225, 'f1-score': 0.9826756627843956, 'support': 10182} weighted_avg {'precision': 0.9833198066214602, 'recall': 0.9833038695737576, 'f1-score': 0.9832906199431807, 'support': 10182}
 
time = 25.46 secondes

Val loss 0.773803951294968 accuracy 0.8886925578117371 macro_avg {'precision': 0.8938634676689954, 'recall': 0.8931172197065278, 'f1-score': 0.8905624794033737, 'support': 1132} weighted_avg {'precision': 0.8958193315622673, 'recall': 0.8886925795053003, 'f1-score': 0.8892571244970706, 'support': 1132}
 
----------
Epoch 14/40
time = 752.32 secondes

Train loss 0.0932274632471103 accuracy 0.980553925037384 macro_avg {'precision': 0.9804310136897358, 'recall': 0.98020414388562, 'f1-score': 0.9802714302140234, 'support': 10182} weighted_avg {'precision': 0.980597048195714, 'recall': 0.9805539186800236, 'f1-score': 0.9805301347474901, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.7728160917353127 accuracy 0.8904593586921692 macro_avg {'precision': 0.8942876348892301, 'recall': 0.8898960402382146, 'f1-score': 0.890230523091845, 'support': 1132} weighted_avg {'precision': 0.8965893111519456, 'recall': 0.8904593639575972, 'f1-score': 0.8915145460515232, 'support': 1132}
 
----------
Epoch 15/40
time = 753.87 secondes

Train loss 0.0719670745086744 accuracy 0.9861520528793335 macro_avg {'precision': 0.9858527859212373, 'recall': 0.9852419916401732, 'f1-score': 0.9855118632423577, 'support': 10182} weighted_avg {'precision': 0.9861667119229981, 'recall': 0.9861520329994107, 'f1-score': 0.9861296046393095, 'support': 10182}
 
time = 24.21 secondes

Val loss 0.9237031098707287 accuracy 0.8860424160957336 macro_avg {'precision': 0.8955202697406713, 'recall': 0.8906077846906573, 'f1-score': 0.8892029419574626, 'support': 1132} weighted_avg {'precision': 0.8953263719726176, 'recall': 0.8860424028268551, 'f1-score': 0.8864554977098054, 'support': 1132}
 
----------
Epoch 16/40
time = 751.91 secondes

Train loss 0.09111707174977444 accuracy 0.9833039045333862 macro_avg {'precision': 0.9832043072807435, 'recall': 0.9829076347767767, 'f1-score': 0.9829997136447165, 'support': 10182} weighted_avg {'precision': 0.9833759323360373, 'recall': 0.9833038695737576, 'f1-score': 0.9832827748837946, 'support': 10182}
 
time = 24.17 secondes

Val loss 0.9377645152257378 accuracy 0.8789752721786499 macro_avg {'precision': 0.8930652443457742, 'recall': 0.8828843825303483, 'f1-score': 0.8838259068861909, 'support': 1132} weighted_avg {'precision': 0.8905908069390202, 'recall': 0.8789752650176679, 'f1-score': 0.8801836820631088, 'support': 1132}
 
----------
Epoch 17/40
time = 753.83 secondes

Train loss 0.08425878126803256 accuracy 0.9853663444519043 macro_avg {'precision': 0.9846060863228274, 'recall': 0.9844686300106302, 'f1-score': 0.9844948491595954, 'support': 10182} weighted_avg {'precision': 0.9854143644602418, 'recall': 0.9853663327440582, 'f1-score': 0.9853520739409795, 'support': 10182}
 
time = 24.16 secondes

Val loss 0.9657834803055919 accuracy 0.8772084712982178 macro_avg {'precision': 0.8925533149624533, 'recall': 0.8767410997234475, 'f1-score': 0.8793459031255132, 'support': 1132} weighted_avg {'precision': 0.8887904444433735, 'recall': 0.877208480565371, 'f1-score': 0.8775853051960477, 'support': 1132}
 
----------
Epoch 18/40
time = 752.53 secondes

Train loss 0.07976119425824882 accuracy 0.9853663444519043 macro_avg {'precision': 0.9844619872694128, 'recall': 0.9844023646004441, 'f1-score': 0.984414797763027, 'support': 10182} weighted_avg {'precision': 0.9853762106376384, 'recall': 0.9853663327440582, 'f1-score': 0.9853535442115765, 'support': 10182}
 
time = 23.92 secondes

Val loss 0.992117074271705 accuracy 0.870141327381134 macro_avg {'precision': 0.8812779685143189, 'recall': 0.8709005611704322, 'f1-score': 0.8700869466852816, 'support': 1132} weighted_avg {'precision': 0.8864467610957574, 'recall': 0.8701413427561837, 'f1-score': 0.8729543336143502, 'support': 1132}
 
----------
Epoch 19/40
time = 754.19 secondes

Train loss 0.07153822533315518 accuracy 0.9869377613067627 macro_avg {'precision': 0.9863034044808192, 'recall': 0.9863121378785034, 'f1-score': 0.9862765358079466, 'support': 10182} weighted_avg {'precision': 0.9870431902998108, 'recall': 0.9869377332547633, 'f1-score': 0.9869595653434582, 'support': 10182}
 
time = 24.15 secondes

Val loss 1.0845947651230259 accuracy 0.8630741834640503 macro_avg {'precision': 0.8914171758759473, 'recall': 0.8651150588094595, 'f1-score': 0.8684040236646009, 'support': 1132} weighted_avg {'precision': 0.8907204520585983, 'recall': 0.8630742049469965, 'f1-score': 0.8667269863309442, 'support': 1132}
 
----------
Epoch 20/40
time = 753.25 secondes

Train loss 0.05953320252072964 accuracy 0.9890002012252808 macro_avg {'precision': 0.9884552427468485, 'recall': 0.9880638701675956, 'f1-score': 0.988238361198521, 'support': 10182} weighted_avg {'precision': 0.9890085218145828, 'recall': 0.9890001964250639, 'f1-score': 0.9889867107018898, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8541200280906452 accuracy 0.8895759582519531 macro_avg {'precision': 0.9003426887178707, 'recall': 0.8931741703920248, 'f1-score': 0.8920724608782201, 'support': 1132} weighted_avg {'precision': 0.8998147142118282, 'recall': 0.8895759717314488, 'f1-score': 0.8898306106926647, 'support': 1132}
 
----------
Epoch 21/40
time = 750.66 secondes

Train loss 0.0641876879211967 accuracy 0.9891966581344604 macro_avg {'precision': 0.988963734983898, 'recall': 0.988961383182707, 'f1-score': 0.9889300115687074, 'support': 10182} weighted_avg {'precision': 0.9892470618587771, 'recall': 0.989196621488902, 'f1-score': 0.989188623316835, 'support': 10182}
 
time = 23.99 secondes

Val loss 0.9540071966604929 accuracy 0.8869258165359497 macro_avg {'precision': 0.8987006263142356, 'recall': 0.8883460023219281, 'f1-score': 0.8890146844100295, 'support': 1132} weighted_avg {'precision': 0.8978512785134412, 'recall': 0.8869257950530035, 'f1-score': 0.8875584304481257, 'support': 1132}
 
----------
Epoch 22/40
time = 753.34 secondes

Train loss 0.06019574741347833 accuracy 0.9892948865890503 macro_avg {'precision': 0.9890623680386547, 'recall': 0.9889867640602665, 'f1-score': 0.9890062111654334, 'support': 10182} weighted_avg {'precision': 0.9893163025733535, 'recall': 0.9892948340208211, 'f1-score': 0.9892872415353429, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8117108292869271 accuracy 0.8948763608932495 macro_avg {'precision': 0.9094741174817651, 'recall': 0.8977009907009121, 'f1-score': 0.9007949655864523, 'support': 1132} weighted_avg {'precision': 0.9066520601007092, 'recall': 0.8948763250883393, 'f1-score': 0.897736830091526, 'support': 1132}
 
----------
Epoch 23/40
time = 751.85 secondes

Train loss 0.046891239848781234 accuracy 0.9912590980529785 macro_avg {'precision': 0.9910942812121457, 'recall': 0.9910986806467094, 'f1-score': 0.9910815748197365, 'support': 10182} weighted_avg {'precision': 0.9912890290931287, 'recall': 0.9912590846592025, 'f1-score': 0.9912597869873107, 'support': 10182}
 
time = 24.30 secondes

Val loss 0.861574079609262 accuracy 0.8904593586921692 macro_avg {'precision': 0.8974093724344812, 'recall': 0.8940962135174175, 'f1-score': 0.8937967626774256, 'support': 1132} weighted_avg {'precision': 0.8954076185669162, 'recall': 0.8904593639575972, 'f1-score': 0.8909618234218524, 'support': 1132}
 
----------
Epoch 24/40
time = 753.34 secondes

Train loss 0.049776418264081024 accuracy 0.9920448064804077 macro_avg {'precision': 0.9918456049048275, 'recall': 0.9919515415120166, 'f1-score': 0.9918861996140059, 'support': 10182} weighted_avg {'precision': 0.9920642555785829, 'recall': 0.9920447849145551, 'f1-score': 0.9920429598966232, 'support': 10182}
 
time = 24.06 secondes

Val loss 1.080848942467128 accuracy 0.8683745861053467 macro_avg {'precision': 0.8831733072203105, 'recall': 0.8774287583732457, 'f1-score': 0.8701177522078671, 'support': 1132} weighted_avg {'precision': 0.8852145054137567, 'recall': 0.8683745583038869, 'f1-score': 0.8652123310618849, 'support': 1132}
 
----------
Epoch 25/40
time = 752.36 secondes

Train loss 0.04876870376791824 accuracy 0.9916519522666931 macro_avg {'precision': 0.9913750579598197, 'recall': 0.9914745311552249, 'f1-score': 0.9914163293884884, 'support': 10182} weighted_avg {'precision': 0.9916604006652592, 'recall': 0.9916519347868789, 'f1-score': 0.9916476377050246, 'support': 10182}
 
time = 23.90 secondes

Val loss 0.8584901109039288 accuracy 0.9010601043701172 macro_avg {'precision': 0.906664111515259, 'recall': 0.9039321342098422, 'f1-score': 0.9025330574532333, 'support': 1132} weighted_avg {'precision': 0.907080063437981, 'recall': 0.901060070671378, 'f1-score': 0.9013085333087916, 'support': 1132}
 
----------
Epoch 26/40
time = 752.67 secondes

Train loss 0.06092188786274371 accuracy 0.9907680749893188 macro_avg {'precision': 0.9902960777763882, 'recall': 0.9901684877515627, 'f1-score': 0.9902061139446289, 'support': 10182} weighted_avg {'precision': 0.9908022183772769, 'recall': 0.9907680219996071, 'f1-score': 0.9907594011698361, 'support': 10182}
 
time = 23.82 secondes

Val loss 0.8058353072652531 accuracy 0.8922261595726013 macro_avg {'precision': 0.9007005797570399, 'recall': 0.8977463799964355, 'f1-score': 0.8949957781346468, 'support': 1132} weighted_avg {'precision': 0.9039005456709617, 'recall': 0.892226148409894, 'f1-score': 0.8937555336541271, 'support': 1132}
 
----------
Epoch 27/40
time = 752.86 secondes

Train loss 0.051702512698568535 accuracy 0.9913573265075684 macro_avg {'precision': 0.9907966184798582, 'recall': 0.990612683320145, 'f1-score': 0.9906936862196385, 'support': 10182} weighted_avg {'precision': 0.9913793385484096, 'recall': 0.9913572971911215, 'f1-score': 0.9913591786920781, 'support': 10182}
 
time = 25.31 secondes

Val loss 0.8526200375970188 accuracy 0.8939929604530334 macro_avg {'precision': 0.9022921238290584, 'recall': 0.8971818502208588, 'f1-score': 0.8971399674248456, 'support': 1132} weighted_avg {'precision': 0.9011302072928531, 'recall': 0.8939929328621908, 'f1-score': 0.8949328188899834, 'support': 1132}
 
----------
Epoch 28/40
time = 751.36 secondes

Train loss 0.03535121138044459 accuracy 0.9940090775489807 macro_avg {'precision': 0.9939766947761284, 'recall': 0.9936788171249026, 'f1-score': 0.993813496075914, 'support': 10182} weighted_avg {'precision': 0.9940224143819081, 'recall': 0.9940090355529365, 'f1-score': 0.9940036751855822, 'support': 10182}
 
time = 24.41 secondes

Val loss 1.1391332672197088 accuracy 0.8736749291419983 macro_avg {'precision': 0.8927321653928899, 'recall': 0.8676111026509574, 'f1-score': 0.8737096387857376, 'support': 1132} weighted_avg {'precision': 0.8863971339958189, 'recall': 0.8736749116607774, 'f1-score': 0.8735081407763031, 'support': 1132}
 
----------
Epoch 29/40
time = 754.37 secondes

Train loss 0.03715499011462212 accuracy 0.9939108490943909 macro_avg {'precision': 0.993902243134484, 'recall': 0.9938488303088301, 'f1-score': 0.9938670676472212, 'support': 10182} weighted_avg {'precision': 0.9939322691752885, 'recall': 0.9939108230210175, 'f1-score': 0.9939128252095553, 'support': 10182}
 
time = 23.95 secondes

Val loss 1.067693534377687 accuracy 0.8683745861053467 macro_avg {'precision': 0.8850390007258714, 'recall': 0.8708386806164906, 'f1-score': 0.8728853808123708, 'support': 1132} weighted_avg {'precision': 0.882983007776834, 'recall': 0.8683745583038869, 'f1-score': 0.8701166865905084, 'support': 1132}
 
----------
Epoch 30/40
time = 754.63 secondes

Train loss 0.03644347898339869 accuracy 0.9939108490943909 macro_avg {'precision': 0.993760722179388, 'recall': 0.9939054746857945, 'f1-score': 0.9938271576707992, 'support': 10182} weighted_avg {'precision': 0.9939266251779809, 'recall': 0.9939108230210175, 'f1-score': 0.9939134313789806, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.8739052489636122 accuracy 0.8957597017288208 macro_avg {'precision': 0.9001009851411821, 'recall': 0.8968236109848619, 'f1-score': 0.897262923002286, 'support': 1132} weighted_avg {'precision': 0.899072132739794, 'recall': 0.8957597173144877, 'f1-score': 0.8961455170153119, 'support': 1132}
 
----------
Epoch 31/40
time = 753.45 secondes

Train loss 0.025959832525053975 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953250005870793, 'recall': 0.9954097565633775, 'f1-score': 0.9953618758032269, 'support': 10182} weighted_avg {'precision': 0.9953871187961189, 'recall': 0.9953840109998036, 'f1-score': 0.9953801139582318, 'support': 10182}
 
time = 24.75 secondes

Val loss 0.8779223775988138 accuracy 0.8966431021690369 macro_avg {'precision': 0.9043230630068578, 'recall': 0.8988354828975277, 'f1-score': 0.9004111605597072, 'support': 1132} weighted_avg {'precision': 0.901194346969186, 'recall': 0.8966431095406361, 'f1-score': 0.8977860509808875, 'support': 1132}
 
----------
Epoch 32/40
time = 758.62 secondes

Train loss 0.0277228288420189 accuracy 0.9955804944038391 macro_avg {'precision': 0.995286567472126, 'recall': 0.9954263545153028, 'f1-score': 0.9953509225906689, 'support': 10182} weighted_avg {'precision': 0.9955943473834448, 'recall': 0.9955804360636418, 'f1-score': 0.9955822926445846, 'support': 10182}
 
time = 24.68 secondes

Val loss 0.9034856507832572 accuracy 0.9001767039299011 macro_avg {'precision': 0.9048637021085796, 'recall': 0.9033264056112049, 'f1-score': 0.9022439062009578, 'support': 1132} weighted_avg {'precision': 0.9033795517018438, 'recall': 0.9001766784452296, 'f1-score': 0.8999772359278706, 'support': 1132}
 
----------
Epoch 33/40
time = 757.29 secondes

Train loss 0.02274574027798915 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963307586288079, 'recall': 0.9961586202089784, 'f1-score': 0.9962361309740665, 'support': 10182} weighted_avg {'precision': 0.9962866130673353, 'recall': 0.9962679237870752, 'f1-score': 0.9962688876045266, 'support': 10182}
 
time = 24.38 secondes

Val loss 0.9153745993161734 accuracy 0.8904593586921692 macro_avg {'precision': 0.894230099447137, 'recall': 0.8954176026269571, 'f1-score': 0.8924236178395379, 'support': 1132} weighted_avg {'precision': 0.8976734824924806, 'recall': 0.8904593639575972, 'f1-score': 0.8918156718475612, 'support': 1132}
 
----------
Epoch 34/40
time = 755.53 secondes

Train loss 0.0196310529865408 accuracy 0.9962679743766785 macro_avg {'precision': 0.996221252384412, 'recall': 0.9962593320220797, 'f1-score': 0.9962367319673626, 'support': 10182} weighted_avg {'precision': 0.9962773393346889, 'recall': 0.9962679237870752, 'f1-score': 0.9962690892243178, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.952540274721658 accuracy 0.898409903049469 macro_avg {'precision': 0.9057842277530691, 'recall': 0.9010000842328447, 'f1-score': 0.901156343135351, 'support': 1132} weighted_avg {'precision': 0.904929523636246, 'recall': 0.8984098939929329, 'f1-score': 0.8993834992448966, 'support': 1132}
 
----------
Epoch 35/40
time = 755.48 secondes

Train loss 0.015508589382747863 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975190877969418, 'recall': 0.9974545048840687, 'f1-score': 0.9974853024850476, 'support': 10182} weighted_avg {'precision': 0.9975486329986448, 'recall': 0.9975446867020232, 'f1-score': 0.9975452542278265, 'support': 10182}
 
time = 24.48 secondes

Val loss 0.9013555614728317 accuracy 0.9028268456459045 macro_avg {'precision': 0.9084692932448064, 'recall': 0.9043041288912319, 'f1-score': 0.9047638500189679, 'support': 1132} weighted_avg {'precision': 0.9074167596953874, 'recall': 0.9028268551236749, 'f1-score': 0.9034216790751081, 'support': 1132}
 
----------
Epoch 36/40
time = 756.23 secondes

Train loss 0.01311352847341578 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977195787365696, 'recall': 0.99773183359121, 'f1-score': 0.9977242089918377, 'support': 10182} weighted_avg {'precision': 0.9976432963101047, 'recall': 0.9976428992339422, 'f1-score': 0.997641534596836, 'support': 10182}
 
time = 24.03 secondes

Val loss 0.8549421874387764 accuracy 0.9010601043701172 macro_avg {'precision': 0.9080053111380012, 'recall': 0.9036995578189959, 'f1-score': 0.9039883277153746, 'support': 1132} weighted_avg {'precision': 0.9081317789132044, 'recall': 0.901060070671378, 'f1-score': 0.9026620832775903, 'support': 1132}
 
----------
Epoch 37/40
time = 749.67 secondes

Train loss 0.011699782797074235 accuracy 0.997741162776947 macro_avg {'precision': 0.9977984990264328, 'recall': 0.9977821899592556, 'f1-score': 0.9977869008189482, 'support': 10182} weighted_avg {'precision': 0.997749217959591, 'recall': 0.9977411117658613, 'f1-score': 0.9977416244722362, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.9261157800301076 accuracy 0.9019434452056885 macro_avg {'precision': 0.9059935992413385, 'recall': 0.9047054121594371, 'f1-score': 0.9044833680821153, 'support': 1132} weighted_avg {'precision': 0.9048351628181854, 'recall': 0.9019434628975265, 'f1-score': 0.9025225154597547, 'support': 1132}
 
----------
Epoch 38/40
time = 751.72 secondes

Train loss 0.008788656654223171 accuracy 0.9983304142951965 macro_avg {'precision': 0.9984002265102557, 'recall': 0.9983954854416333, 'f1-score': 0.9983962324272045, 'support': 10182} weighted_avg {'precision': 0.9983341028334072, 'recall': 0.9983303869573757, 'f1-score': 0.9983305700738241, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.934349763100637 accuracy 0.8992933034896851 macro_avg {'precision': 0.9036948669274061, 'recall': 0.9017666057022637, 'f1-score': 0.9013226556836932, 'support': 1132} weighted_avg {'precision': 0.9038802477116822, 'recall': 0.8992932862190812, 'f1-score': 0.9001004984642382, 'support': 1132}
 
----------
Epoch 39/40
time = 752.52 secondes

Train loss 0.0065723362446275715 accuracy 0.998919665813446 macro_avg {'precision': 0.9989627855156149, 'recall': 0.9989661221551002, 'f1-score': 0.9989641871717895, 'support': 10182} weighted_avg {'precision': 0.9989200438405521, 'recall': 0.9989196621488902, 'f1-score': 0.9989195755867342, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.9459367514915664 accuracy 0.9028268456459045 macro_avg {'precision': 0.9070013583830117, 'recall': 0.9055171140746486, 'f1-score': 0.9054042451182214, 'support': 1132} weighted_avg {'precision': 0.9054935666872914, 'recall': 0.9028268551236749, 'f1-score': 0.9032424345292964, 'support': 1132}
 
----------
Epoch 40/40
time = 752.91 secondes

Train loss 0.002053271436787704 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996224065117731, 'recall': 0.9996220883649922, 'f1-score': 0.9996218870502203, 'support': 10182} weighted_avg {'precision': 0.9996078915605738, 'recall': 0.9996071498723237, 'f1-score': 0.9996071478785676, 'support': 10182}
 
time = 24.53 secondes

Val loss 0.9393784564454749 accuracy 0.9045936465263367 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}
 
----------
best_accuracy 0.9045936465263367 best_epoch 40 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}

average train time 753.1714322268963

average val time 24.193848645687105
 
time = 155.53 secondes

test_accuracy 0.8394848704338074 macro_avg {'precision': 0.8360665862079324, 'recall': 0.8314777131359555, 'f1-score': 0.8318660812130627, 'support': 7532} weighted_avg {'precision': 0.8416371158070496, 'recall': 0.8394848645778014, 'f1-score': 0.8387477349344281, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 476.60 secondes

Train loss 1.4331473210355739 accuracy 0.6079356074333191 macro_avg {'precision': 0.595532368398952, 'recall': 0.5917237987707078, 'f1-score': 0.5790491296094726, 'support': 10182} weighted_avg {'precision': 0.6042763200476227, 'recall': 0.6079355725790611, 'f1-score': 0.593853690526893, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.7841680335326934 accuracy 0.7667844295501709 macro_avg {'precision': 0.739943149202323, 'recall': 0.7618544356319451, 'f1-score': 0.7458947088746772, 'support': 1132} weighted_avg {'precision': 0.75182844061862, 'recall': 0.7667844522968198, 'f1-score': 0.7541985476968371, 'support': 1132}
 
----------
Epoch 2/40
time = 476.04 secondes

Train loss 0.583929990013269 accuracy 0.8282263278961182 macro_avg {'precision': 0.8161602902699846, 'recall': 0.8165633833367003, 'f1-score': 0.8128140616937282, 'support': 10182} weighted_avg {'precision': 0.8244776185406745, 'recall': 0.8282262816735415, 'f1-score': 0.8237937923967038, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.5993993981203563 accuracy 0.8250883221626282 macro_avg {'precision': 0.8195563635230922, 'recall': 0.8193174818530942, 'f1-score': 0.8152797294673576, 'support': 1132} weighted_avg {'precision': 0.8230771856693206, 'recall': 0.8250883392226148, 'f1-score': 0.8202999495405455, 'support': 1132}
 
----------
Epoch 3/40
time = 476.00 secondes

Train loss 0.340324222538591 accuracy 0.9025731682777405 macro_avg {'precision': 0.8967596834557, 'recall': 0.8958669568700433, 'f1-score': 0.8958695376090751, 'support': 10182} weighted_avg {'precision': 0.9024620646147935, 'recall': 0.9025731683362798, 'f1-score': 0.9021430590220308, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.5815014537476318 accuracy 0.8560070991516113 macro_avg {'precision': 0.8634590795475925, 'recall': 0.8556529482332225, 'f1-score': 0.8552210975889697, 'support': 1132} weighted_avg {'precision': 0.8646713003522922, 'recall': 0.8560070671378092, 'f1-score': 0.8560157507643367, 'support': 1132}
 
----------
Epoch 4/40
time = 476.22 secondes

Train loss 0.23231736694578098 accuracy 0.9345904588699341 macro_avg {'precision': 0.9319368347980402, 'recall': 0.9317686101997366, 'f1-score': 0.9317570155734156, 'support': 10182} weighted_avg {'precision': 0.9348861108546099, 'recall': 0.9345904537418974, 'f1-score': 0.9346498251221417, 'support': 10182}
 
time = 18.96 secondes

Val loss 0.6259556379641446 accuracy 0.8551236987113953 macro_avg {'precision': 0.8609540977768008, 'recall': 0.8556226015645432, 'f1-score': 0.8544318344221775, 'support': 1132} weighted_avg {'precision': 0.8625570425443255, 'recall': 0.8551236749116607, 'f1-score': 0.8548984432087424, 'support': 1132}
 
----------
Epoch 5/40
time = 475.88 secondes

Train loss 0.1748830053386581 accuracy 0.9533490538597107 macro_avg {'precision': 0.9516033261806103, 'recall': 0.9514170434662741, 'f1-score': 0.9514570429770532, 'support': 10182} weighted_avg {'precision': 0.9534326157275188, 'recall': 0.9533490473384404, 'f1-score': 0.953336799730088, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.7272236547465633 accuracy 0.8630741834640503 macro_avg {'precision': 0.8708896460916961, 'recall': 0.8644282370593244, 'f1-score': 0.8641041655066886, 'support': 1132} weighted_avg {'precision': 0.8726354679099134, 'recall': 0.8630742049469965, 'f1-score': 0.8642412809883327, 'support': 1132}
 
----------
Epoch 6/40
time = 476.16 secondes

Train loss 0.1584024625383332 accuracy 0.9604203701019287 macro_avg {'precision': 0.9592065042520094, 'recall': 0.9592835233329247, 'f1-score': 0.9592294929828862, 'support': 10182} weighted_avg {'precision': 0.9604347813263789, 'recall': 0.9604203496366136, 'f1-score': 0.9604123345468925, 'support': 10182}
 
time = 18.86 secondes

Val loss 0.758953261697455 accuracy 0.8577738404273987 macro_avg {'precision': 0.8614111064327519, 'recall': 0.8589454743813493, 'f1-score': 0.8549817886692553, 'support': 1132} weighted_avg {'precision': 0.8660030040975224, 'recall': 0.857773851590106, 'f1-score': 0.856284031270566, 'support': 1132}
 
----------
Epoch 7/40
time = 475.84 secondes

Train loss 0.14216014674765656 accuracy 0.9653310179710388 macro_avg {'precision': 0.9645655522809855, 'recall': 0.9641619498612242, 'f1-score': 0.9642924550541008, 'support': 10182} weighted_avg {'precision': 0.9655337846443575, 'recall': 0.9653309762325673, 'f1-score': 0.9653611515450293, 'support': 10182}
 
time = 18.85 secondes

Val loss 0.7416990194010588 accuracy 0.8780918717384338 macro_avg {'precision': 0.8811785459790918, 'recall': 0.8804205108422221, 'f1-score': 0.8781174879349164, 'support': 1132} weighted_avg {'precision': 0.8849644983260769, 'recall': 0.8780918727915195, 'f1-score': 0.8787998994126525, 'support': 1132}
 
----------
Epoch 8/40
time = 476.10 secondes

Train loss 0.12067588076754429 accuracy 0.9725005030632019 macro_avg {'precision': 0.9722001082472236, 'recall': 0.9721257796000968, 'f1-score': 0.9721351711975579, 'support': 10182} weighted_avg {'precision': 0.9725739050575131, 'recall': 0.9725004910626596, 'f1-score': 0.9725087613223514, 'support': 10182}
 
time = 18.82 secondes

Val loss 0.7339283946235861 accuracy 0.8745583295822144 macro_avg {'precision': 0.8826095081904173, 'recall': 0.874568146580154, 'f1-score': 0.8769547797901808, 'support': 1132} weighted_avg {'precision': 0.8811637837674384, 'recall': 0.8745583038869258, 'f1-score': 0.8761188850333996, 'support': 1132}
 
----------
Epoch 9/40
time = 476.04 secondes

Train loss 0.10903065326039532 accuracy 0.9746611714363098 macro_avg {'precision': 0.9741865901387794, 'recall': 0.9742351137255751, 'f1-score': 0.9741962233526994, 'support': 10182} weighted_avg {'precision': 0.974724442373857, 'recall': 0.9746611667648792, 'f1-score': 0.9746785518769862, 'support': 10182}
 
time = 18.88 secondes

Val loss 0.8223847077159674 accuracy 0.8772084712982178 macro_avg {'precision': 0.8826345561067571, 'recall': 0.8770441957968472, 'f1-score': 0.8769333427693777, 'support': 1132} weighted_avg {'precision': 0.8831914359483808, 'recall': 0.877208480565371, 'f1-score': 0.8773411367960622, 'support': 1132}
 
----------
Epoch 10/40
time = 475.82 secondes

Train loss 0.11789070985461728 accuracy 0.9738755226135254 macro_avg {'precision': 0.9731961377927348, 'recall': 0.973200740770074, 'f1-score': 0.9731627640154048, 'support': 10182} weighted_avg {'precision': 0.9739487252486413, 'recall': 0.9738754665095266, 'f1-score': 0.9738776717658235, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.8175750739454755 accuracy 0.8825088143348694 macro_avg {'precision': 0.8913923704669908, 'recall': 0.883866773636696, 'f1-score': 0.8847052732973243, 'support': 1132} weighted_avg {'precision': 0.8909649461121127, 'recall': 0.8825088339222615, 'f1-score': 0.8837968176779287, 'support': 1132}
 
----------
Epoch 11/40
time = 475.91 secondes

Train loss 0.09919397233814671 accuracy 0.9790807366371155 macro_avg {'precision': 0.9790703489237936, 'recall': 0.9788592044062174, 'f1-score': 0.9789447022959307, 'support': 10182} weighted_avg {'precision': 0.9791428167988073, 'recall': 0.9790807307012375, 'f1-score': 0.9790913360341983, 'support': 10182}
 
time = 18.77 secondes

Val loss 0.8908824549281222 accuracy 0.8754417300224304 macro_avg {'precision': 0.8821615968382085, 'recall': 0.8794177991914369, 'f1-score': 0.8789325370424491, 'support': 1132} weighted_avg {'precision': 0.8815647475126456, 'recall': 0.8754416961130742, 'f1-score': 0.8765026701389428, 'support': 1132}
 
----------
Epoch 12/40
time = 475.88 secondes

Train loss 0.09129590717917549 accuracy 0.9806521534919739 macro_avg {'precision': 0.9800866581385748, 'recall': 0.9802607772683853, 'f1-score': 0.9801439160742735, 'support': 10182} weighted_avg {'precision': 0.9807138847737596, 'recall': 0.9806521312119426, 'f1-score': 0.9806558565390472, 'support': 10182}
 
time = 18.48 secondes

Val loss 0.9937783832445374 accuracy 0.8630741834640503 macro_avg {'precision': 0.8733898391893451, 'recall': 0.8670089084551453, 'f1-score': 0.8648809298645034, 'support': 1132} weighted_avg {'precision': 0.8755908746722945, 'recall': 0.8630742049469965, 'f1-score': 0.8639046796658957, 'support': 1132}
 
----------
Epoch 13/40
time = 476.11 secondes

Train loss 0.08980626681439609 accuracy 0.980455756187439 macro_avg {'precision': 0.9795998189242281, 'recall': 0.979604220809508, 'f1-score': 0.9795927062112714, 'support': 10182} weighted_avg {'precision': 0.9804728958930987, 'recall': 0.9804557061481045, 'f1-score': 0.9804549758499381, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.8969723584669852 accuracy 0.8895759582519531 macro_avg {'precision': 0.8922436621638152, 'recall': 0.8912214320652373, 'f1-score': 0.8895649057737479, 'support': 1132} weighted_avg {'precision': 0.8935681143745808, 'recall': 0.8895759717314488, 'f1-score': 0.8893378676623295, 'support': 1132}
 
----------
Epoch 14/40
time = 475.84 secondes

Train loss 0.10348619175381762 accuracy 0.9797682762145996 macro_avg {'precision': 0.9789901199294879, 'recall': 0.9787463913066874, 'f1-score': 0.9788377776155285, 'support': 10182} weighted_avg {'precision': 0.9798523975319084, 'recall': 0.979768218424671, 'f1-score': 0.979779436900201, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9059342153333079 accuracy 0.8754417300224304 macro_avg {'precision': 0.8778813571448472, 'recall': 0.877441965291202, 'f1-score': 0.8741509322557416, 'support': 1132} weighted_avg {'precision': 0.8851415609220239, 'recall': 0.8754416961130742, 'f1-score': 0.8771474591746815, 'support': 1132}
 
----------
Epoch 15/40
time = 476.03 secondes

Train loss 0.08314088314661176 accuracy 0.9836967587471008 macro_avg {'precision': 0.9832150597916243, 'recall': 0.9831992157949017, 'f1-score': 0.983199031298537, 'support': 10182} weighted_avg {'precision': 0.9837254619249084, 'recall': 0.9836967197014339, 'f1-score': 0.9837026716596627, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.9432870343968627 accuracy 0.8780918717384338 macro_avg {'precision': 0.8845226477766779, 'recall': 0.8791886345536408, 'f1-score': 0.8780385805480032, 'support': 1132} weighted_avg {'precision': 0.8873804611747138, 'recall': 0.8780918727915195, 'f1-score': 0.8791053029753878, 'support': 1132}
 
----------
Epoch 16/40
time = 476.35 secondes

Train loss 0.0940445225161075 accuracy 0.982518196105957 macro_avg {'precision': 0.9817548134222344, 'recall': 0.9816643902481731, 'f1-score': 0.9816593986344646, 'support': 10182} weighted_avg {'precision': 0.9826808035717151, 'recall': 0.9825181693184051, 'f1-score': 0.9825537198533938, 'support': 10182}
 
time = 18.84 secondes

Val loss 0.9672756871394239 accuracy 0.8789752721786499 macro_avg {'precision': 0.8884270418708559, 'recall': 0.8825164724944143, 'f1-score': 0.88057735833649, 'support': 1132} weighted_avg {'precision': 0.8906840871781373, 'recall': 0.8789752650176679, 'f1-score': 0.8797962694336531, 'support': 1132}
 
----------
Epoch 17/40
time = 476.65 secondes

Train loss 0.0818525345824826 accuracy 0.9848753213882446 macro_avg {'precision': 0.9849107728893282, 'recall': 0.9847533387775153, 'f1-score': 0.9848087326962881, 'support': 10182} weighted_avg {'precision': 0.9849143428672977, 'recall': 0.9848752700844627, 'f1-score': 0.9848711988006121, 'support': 10182}
 
time = 16.81 secondes

Val loss 0.8446089303164831 accuracy 0.8939929604530334 macro_avg {'precision': 0.9006322439249818, 'recall': 0.8984693505945536, 'f1-score': 0.895063622639484, 'support': 1132} weighted_avg {'precision': 0.901506280142878, 'recall': 0.8939929328621908, 'f1-score': 0.8927643861731265, 'support': 1132}
 
----------
Epoch 18/40
time = 476.49 secondes

Train loss 0.08235502529404037 accuracy 0.9848753213882446 macro_avg {'precision': 0.9843885036380129, 'recall': 0.9848336893572034, 'f1-score': 0.9845820441279723, 'support': 10182} weighted_avg {'precision': 0.9848976904712462, 'recall': 0.9848752700844627, 'f1-score': 0.9848594575484368, 'support': 10182}
 
time = 16.90 secondes

Val loss 0.8545968070694714 accuracy 0.8904593586921692 macro_avg {'precision': 0.8956289533222371, 'recall': 0.8935548211794837, 'f1-score': 0.8913272082898652, 'support': 1132} weighted_avg {'precision': 0.8996540634020332, 'recall': 0.8904593639575972, 'f1-score': 0.8916909484994318, 'support': 1132}
 
----------
Epoch 19/40
time = 476.27 secondes

Train loss 0.06282364381961082 accuracy 0.9881163239479065 macro_avg {'precision': 0.9875385327508319, 'recall': 0.9876985328735055, 'f1-score': 0.987598871641884, 'support': 10182} weighted_avg {'precision': 0.9881654007767301, 'recall': 0.9881162836377921, 'f1-score': 0.988122278611521, 'support': 10182}
 
time = 16.82 secondes

Val loss 0.8057548724572767 accuracy 0.8922261595726013 macro_avg {'precision': 0.8977223620467759, 'recall': 0.8933680720438512, 'f1-score': 0.8928635548307208, 'support': 1132} weighted_avg {'precision': 0.8974182953616768, 'recall': 0.892226148409894, 'f1-score': 0.892260650990808, 'support': 1132}
 
----------
Epoch 20/40
time = 476.61 secondes

Train loss 0.052562987162582 accuracy 0.98978590965271 macro_avg {'precision': 0.9891761708337553, 'recall': 0.9892604113527611, 'f1-score': 0.9892034050464359, 'support': 10182} weighted_avg {'precision': 0.9898173625653797, 'recall': 0.9897858966804164, 'f1-score': 0.9897878889952575, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.9763796942340929 accuracy 0.8745583295822144 macro_avg {'precision': 0.8959231728469849, 'recall': 0.8823246687327038, 'f1-score': 0.8784921639339665, 'support': 1132} weighted_avg {'precision': 0.9024436496660545, 'recall': 0.8745583038869258, 'f1-score': 0.8774899066285587, 'support': 1132}
 
----------
Epoch 21/40
time = 476.40 secondes

Train loss 0.07425018755057125 accuracy 0.9866431355476379 macro_avg {'precision': 0.9865689620766265, 'recall': 0.986778149810112, 'f1-score': 0.986658241498629, 'support': 10182} weighted_avg {'precision': 0.9866694270713218, 'recall': 0.9866430956590061, 'f1-score': 0.9866419029432296, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.8224266537015891 accuracy 0.8913427591323853 macro_avg {'precision': 0.8970380007732738, 'recall': 0.8939182246500144, 'f1-score': 0.8925762853483103, 'support': 1132} weighted_avg {'precision': 0.8982436703140954, 'recall': 0.8913427561837456, 'f1-score': 0.8918994657342718, 'support': 1132}
 
----------
Epoch 22/40
time = 476.26 secondes

Train loss 0.05776682668380844 accuracy 0.9899823665618896 macro_avg {'precision': 0.9898832208283483, 'recall': 0.9898323684349215, 'f1-score': 0.9898448652004305, 'support': 10182} weighted_avg {'precision': 0.9899877544583315, 'recall': 0.9899823217442546, 'f1-score': 0.9899717822955614, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8461720995633378 accuracy 0.8939929604530334 macro_avg {'precision': 0.9015471875027007, 'recall': 0.8932644188617118, 'f1-score': 0.8927044858621975, 'support': 1132} weighted_avg {'precision': 0.9017710974474212, 'recall': 0.8939929328621908, 'f1-score': 0.8937859038335254, 'support': 1132}
 
----------
Epoch 23/40
time = 476.22 secondes

Train loss 0.04697093484487074 accuracy 0.9911609292030334 macro_avg {'precision': 0.9910013300213396, 'recall': 0.9910493216952705, 'f1-score': 0.9910115989662931, 'support': 10182} weighted_avg {'precision': 0.9911955383611514, 'recall': 0.9911608721272834, 'f1-score': 0.9911641665669635, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.7270659135557112 accuracy 0.9028268456459045 macro_avg {'precision': 0.9062091506547768, 'recall': 0.904765264201895, 'f1-score': 0.904517030128479, 'support': 1132} weighted_avg {'precision': 0.9059847331977929, 'recall': 0.9028268551236749, 'f1-score': 0.9034375725753206, 'support': 1132}
 
----------
Epoch 24/40
time = 476.30 secondes

Train loss 0.05323730014505181 accuracy 0.9914555549621582 macro_avg {'precision': 0.9911679139192643, 'recall': 0.9910527066005498, 'f1-score': 0.9910947134898889, 'support': 10182} weighted_avg {'precision': 0.9914771992689536, 'recall': 0.9914555097230406, 'f1-score': 0.9914527204680895, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8383258971479732 accuracy 0.8957597017288208 macro_avg {'precision': 0.9025643848897058, 'recall': 0.8990701955651718, 'f1-score': 0.8976995556023345, 'support': 1132} weighted_avg {'precision': 0.9017608386305206, 'recall': 0.8957597173144877, 'f1-score': 0.8956881652653363, 'support': 1132}
 
----------
Epoch 25/40
time = 476.33 secondes

Train loss 0.049769247696713995 accuracy 0.9921430349349976 macro_avg {'precision': 0.9922156831705223, 'recall': 0.9922917962845117, 'f1-score': 0.9922432922975473, 'support': 10182} weighted_avg {'precision': 0.9921478885978211, 'recall': 0.9921429974464742, 'f1-score': 0.9921349017016393, 'support': 10182}
 
time = 16.90 secondes

Val loss 1.2118418849469736 accuracy 0.8639575839042664 macro_avg {'precision': 0.8784330995646729, 'recall': 0.8666925028105087, 'f1-score': 0.8664674732898282, 'support': 1132} weighted_avg {'precision': 0.881337250102642, 'recall': 0.8639575971731449, 'f1-score': 0.8664615583449901, 'support': 1132}
 
----------
Epoch 26/40
time = 476.35 secondes

Train loss 0.04962862467934944 accuracy 0.991750180721283 macro_avg {'precision': 0.9908647049469523, 'recall': 0.9911753156672493, 'f1-score': 0.9909945533362012, 'support': 10182} weighted_avg {'precision': 0.9917978212614529, 'recall': 0.9917501473187978, 'f1-score': 0.991754284990792, 'support': 10182}
 
time = 17.10 secondes

Val loss 0.9946132900272652 accuracy 0.8780918717384338 macro_avg {'precision': 0.886844770451769, 'recall': 0.880248149772868, 'f1-score': 0.8784473175089064, 'support': 1132} weighted_avg {'precision': 0.890620579613345, 'recall': 0.8780918727915195, 'f1-score': 0.8802463425347955, 'support': 1132}
 
----------
Epoch 27/40
time = 476.24 secondes

Train loss 0.037443653197178337 accuracy 0.9928305149078369 macro_avg {'precision': 0.9923604881152501, 'recall': 0.9925993536713094, 'f1-score': 0.9924711511501763, 'support': 10182} weighted_avg {'precision': 0.992858005407245, 'recall': 0.9928304851699077, 'f1-score': 0.992835871514283, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8570922745954742 accuracy 0.8966431021690369 macro_avg {'precision': 0.8997127327141022, 'recall': 0.9016370238578795, 'f1-score': 0.8988682934835366, 'support': 1132} weighted_avg {'precision': 0.9010992175565485, 'recall': 0.8966431095406361, 'f1-score': 0.896947512131109, 'support': 1132}
 
----------
Epoch 28/40
time = 476.34 secondes

Train loss 0.043723354749204725 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919919339144008, 'recall': 0.9920220277396986, 'f1-score': 0.9920011773727777, 'support': 10182} weighted_avg {'precision': 0.9920538260037121, 'recall': 0.9920447849145551, 'f1-score': 0.9920434542402128, 'support': 10182}
 
time = 16.76 secondes

Val loss 0.8313640775060622 accuracy 0.898409903049469 macro_avg {'precision': 0.9061009294875714, 'recall': 0.9015306506607855, 'f1-score': 0.9021619417995221, 'support': 1132} weighted_avg {'precision': 0.9025417665778662, 'recall': 0.8984098939929329, 'f1-score': 0.8987797359314919, 'support': 1132}
 
----------
Epoch 29/40
time = 476.24 secondes

Train loss 0.031085909932283513 accuracy 0.9941073060035706 macro_avg {'precision': 0.9940725275169824, 'recall': 0.9941480105977402, 'f1-score': 0.9941061328427813, 'support': 10182} weighted_avg {'precision': 0.994114057034208, 'recall': 0.9941072480848556, 'f1-score': 0.9941066487754239, 'support': 10182}
 
time = 16.17 secondes

Val loss 0.992737110735132 accuracy 0.8886925578117371 macro_avg {'precision': 0.9009585520205844, 'recall': 0.8863641622063806, 'f1-score': 0.8886403409719144, 'support': 1132} weighted_avg {'precision': 0.8995411403023295, 'recall': 0.8886925795053003, 'f1-score': 0.8899843997219234, 'support': 1132}
 
----------
Epoch 30/40
time = 476.58 secondes

Train loss 0.03888092267498481 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934250948877779, 'recall': 0.9934886079499444, 'f1-score': 0.9934468610963197, 'support': 10182} weighted_avg {'precision': 0.9940202929890849, 'recall': 0.9940090355529365, 'f1-score': 0.9940050584084523, 'support': 10182}
 
time = 16.68 secondes

Val loss 0.886118140636337 accuracy 0.8922261595726013 macro_avg {'precision': 0.9006095908515904, 'recall': 0.8950692334630697, 'f1-score': 0.8936173151022802, 'support': 1132} weighted_avg {'precision': 0.8996652193836726, 'recall': 0.892226148409894, 'f1-score': 0.8920199450739377, 'support': 1132}
 
----------
Epoch 31/40
time = 476.22 secondes

Train loss 0.028713607613170544 accuracy 0.994892954826355 macro_avg {'precision': 0.9946646465126282, 'recall': 0.9946425407239985, 'f1-score': 0.9946491755579986, 'support': 10182} weighted_avg {'precision': 0.9949013888135394, 'recall': 0.9948929483402082, 'f1-score': 0.994892985163133, 'support': 10182}
 
time = 16.89 secondes

Val loss 0.8772494216123883 accuracy 0.9081271886825562 macro_avg {'precision': 0.9166574954576159, 'recall': 0.9118808200266096, 'f1-score': 0.9125847218581361, 'support': 1132} weighted_avg {'precision': 0.9127131316103466, 'recall': 0.9081272084805654, 'f1-score': 0.9087118330973951, 'support': 1132}
 
----------
Epoch 32/40
time = 476.12 secondes

Train loss 0.038586022712079684 accuracy 0.9936162233352661 macro_avg {'precision': 0.9937714285862491, 'recall': 0.9936985801093063, 'f1-score': 0.993728398576048, 'support': 10182} weighted_avg {'precision': 0.9936375960701547, 'recall': 0.9936161854252603, 'f1-score': 0.9936201772640636, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8376955747209368 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126703005774628, 'recall': 0.91050410830889, 'f1-score': 0.9106161324321006, 'support': 1132} weighted_avg {'precision': 0.9103768495176995, 'recall': 0.9081272084805654, 'f1-score': 0.9082280056250128, 'support': 1132}
 
----------
Epoch 33/40
time = 477.06 secondes

Train loss 0.022106994634426086 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960348085684627, 'recall': 0.9959239975075697, 'f1-score': 0.9959766413322289, 'support': 10182} weighted_avg {'precision': 0.9960763174345807, 'recall': 0.9960714987232371, 'f1-score': 0.9960714828076999, 'support': 10182}
 
time = 16.86 secondes

Val loss 0.8938071656801595 accuracy 0.9054770469665527 macro_avg {'precision': 0.9089023322543677, 'recall': 0.907206830352122, 'f1-score': 0.9062887458539539, 'support': 1132} weighted_avg {'precision': 0.9098721753018832, 'recall': 0.9054770318021201, 'f1-score': 0.9059075922778872, 'support': 1132}
 
----------
Epoch 34/40
time = 476.11 secondes

Train loss 0.02002061514667016 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963586041890611, 'recall': 0.9963882587223306, 'f1-score': 0.9963660536643802, 'support': 10182} weighted_avg {'precision': 0.9962904601872715, 'recall': 0.9962679237870752, 'f1-score': 0.9962715798892713, 'support': 10182}
 
time = 16.54 secondes

Val loss 0.9732385666069296 accuracy 0.8939929604530334 macro_avg {'precision': 0.9024351907424117, 'recall': 0.8994889048217717, 'f1-score': 0.8971986517749485, 'support': 1132} weighted_avg {'precision': 0.9046193260034942, 'recall': 0.8939929328621908, 'f1-score': 0.8956300749622467, 'support': 1132}
 
----------
Epoch 35/40
time = 476.38 secondes

Train loss 0.015641405498072445 accuracy 0.9970536828041077 macro_avg {'precision': 0.997186663684358, 'recall': 0.997134246896984, 'f1-score': 0.9971470633025602, 'support': 10182} weighted_avg {'precision': 0.9970814979283738, 'recall': 0.9970536240424278, 'f1-score': 0.9970537399642208, 'support': 10182}
 
time = 16.93 secondes

Val loss 0.8120080086814148 accuracy 0.9116607904434204 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}
 
----------
Epoch 36/40
time = 476.52 secondes

Train loss 0.015949043090050786 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975256556069297, 'recall': 0.9973727067699185, 'f1-score': 0.9974413372715596, 'support': 10182} weighted_avg {'precision': 0.9975572648351069, 'recall': 0.9975446867020232, 'f1-score': 0.9975438718809831, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9054440364443636 accuracy 0.9054770469665527 macro_avg {'precision': 0.9098100446437348, 'recall': 0.908338583070797, 'f1-score': 0.9079247398369761, 'support': 1132} weighted_avg {'precision': 0.909363568992873, 'recall': 0.9054770318021201, 'f1-score': 0.9062233633137983, 'support': 1132}
 
----------
Epoch 37/40
time = 476.33 secondes

Train loss 0.0065117422103141975 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986604452327945, 'recall': 0.9986403734244002, 'f1-score': 0.9986495940363275, 'support': 10182} weighted_avg {'precision': 0.9987247312286821, 'recall': 0.9987232370850521, 'f1-score': 0.9987231987033319, 'support': 10182}
 
time = 16.92 secondes

Val loss 0.9217688095203697 accuracy 0.9010601043701172 macro_avg {'precision': 0.9029670784735023, 'recall': 0.9040157579397295, 'f1-score': 0.9018182850077678, 'support': 1132} weighted_avg {'precision': 0.9056168332215249, 'recall': 0.901060070671378, 'f1-score': 0.9017167851383562, 'support': 1132}
 
----------
Epoch 38/40
time = 476.60 secondes

Train loss 0.009076425064661034 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986561952378381, 'recall': 0.9987010040805717, 'f1-score': 0.9986767750580696, 'support': 10182} weighted_avg {'precision': 0.9987254040347094, 'recall': 0.9987232370850521, 'f1-score': 0.9987224450350004, 'support': 10182}
 
time = 17.19 secondes

Val loss 1.1009912460943616 accuracy 0.8904593586921692 macro_avg {'precision': 0.8930635853249503, 'recall': 0.8951290034856629, 'f1-score': 0.8915758679621119, 'support': 1132} weighted_avg {'precision': 0.8973040338994697, 'recall': 0.8904593639575972, 'f1-score': 0.8914447556334754, 'support': 1132}
 
----------
Epoch 39/40
time = 476.36 secondes

Train loss 0.004712479369310978 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992373015787427, 'recall': 0.9992411211620341, 'f1-score': 0.9992389826265702, 'support': 10182} weighted_avg {'precision': 0.9993127050759184, 'recall': 0.9993125122765665, 'f1-score': 0.9993123996889289, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.9440119815970601 accuracy 0.8992933034896851 macro_avg {'precision': 0.9043786351635557, 'recall': 0.9034703667960795, 'f1-score': 0.901970580444825, 'support': 1132} weighted_avg {'precision': 0.904949066983656, 'recall': 0.8992932862190812, 'f1-score': 0.8999977322225842, 'support': 1132}
 
----------
Epoch 40/40
time = 476.27 secondes

Train loss 0.0029121377023918088 accuracy 0.9994107484817505 macro_avg {'precision': 0.999418394131815, 'recall': 0.9993780990979012, 'f1-score': 0.9993977770860285, 'support': 10182} weighted_avg {'precision': 0.9994115870018708, 'recall': 0.9994107248084856, 'f1-score': 0.9994106819482753, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9745304558480609 accuracy 0.9001767039299011 macro_avg {'precision': 0.9058208282388479, 'recall': 0.9037579696344862, 'f1-score': 0.902814940267515, 'support': 1132} weighted_avg {'precision': 0.9059259916519704, 'recall': 0.9001766784452296, 'f1-score': 0.900934748385834, 'support': 1132}
 
----------
best_accuracy 0.9116607904434204 best_epoch 35 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}

average train time 476.2516987025738

average val time 17.631594270467758
 
time = 107.53 secondes

test_accuracy 0.8348379731178284 macro_avg {'precision': 0.8316073449511627, 'recall': 0.8290983707098822, 'f1-score': 0.8284636763392512, 'support': 7532} weighted_avg {'precision': 0.8375247937439214, 'recall': 0.8348380244291025, 'f1-score': 0.8343998913511087, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_1
----------
Epoch 1/40
time = 1922.63 secondes

Train loss 1.3563601410650945 accuracy 0.6342565417289734 macro_avg {'precision': 0.6311249056630124, 'recall': 0.6183001475305336, 'f1-score': 0.6069341533632095, 'support': 10182} weighted_avg {'precision': 0.6394093685392014, 'recall': 0.6342565311333727, 'f1-score': 0.6219575282769404, 'support': 10182}
 
time = 52.82 secondes

Val loss 0.7800213056550899 accuracy 0.7614840865135193 macro_avg {'precision': 0.7543278013263962, 'recall': 0.7587375685957276, 'f1-score': 0.7454669955773282, 'support': 1132} weighted_avg {'precision': 0.7669285197252486, 'recall': 0.7614840989399293, 'f1-score': 0.7520640590829529, 'support': 1132}
 
----------
Epoch 2/40
time = 1917.88 secondes

Train loss 0.5498222497231919 accuracy 0.8326458930969238 macro_avg {'precision': 0.8194822777281006, 'recall': 0.8198686414206552, 'f1-score': 0.8160250599070608, 'support': 10182} weighted_avg {'precision': 0.8289016402609096, 'recall': 0.8326458456098998, 'f1-score': 0.8281176786290024, 'support': 10182}
 
time = 53.45 secondes

Val loss 0.6661390110220707 accuracy 0.7959364056587219 macro_avg {'precision': 0.8078255781927763, 'recall': 0.79421757987355, 'f1-score': 0.7926226676191326, 'support': 1132} weighted_avg {'precision': 0.8157289939906799, 'recall': 0.7959363957597173, 'f1-score': 0.7967029108383243, 'support': 1132}
 
----------
Epoch 3/40
time = 1921.35 secondes

Train loss 0.32057227810707345 accuracy 0.9056177735328674 macro_avg {'precision': 0.9001688138780143, 'recall': 0.8995811872248136, 'f1-score': 0.8996746042331776, 'support': 10182} weighted_avg {'precision': 0.9056635843204324, 'recall': 0.905617756825771, 'f1-score': 0.9054525271801049, 'support': 10182}
 
time = 53.00 secondes

Val loss 0.5940035742930543 accuracy 0.851590096950531 macro_avg {'precision': 0.8549678790264492, 'recall': 0.8489949452380243, 'f1-score': 0.8491355095612892, 'support': 1132} weighted_avg {'precision': 0.8529812738975073, 'recall': 0.8515901060070671, 'f1-score': 0.8495391534753041, 'support': 1132}
 
----------
Epoch 4/40
time = 1923.23 secondes

Train loss 0.22492251191449059 accuracy 0.9388136267662048 macro_avg {'precision': 0.9351679169472039, 'recall': 0.9348968995233135, 'f1-score': 0.9349479551161674, 'support': 10182} weighted_avg {'precision': 0.9390748474958273, 'recall': 0.9388135926144175, 'f1-score': 0.9388596497932974, 'support': 10182}
 
time = 52.26 secondes

Val loss 0.6839744140931838 accuracy 0.8454063534736633 macro_avg {'precision': 0.8578191346968701, 'recall': 0.8419427275782103, 'f1-score': 0.8434235817190616, 'support': 1132} weighted_avg {'precision': 0.8564730236320933, 'recall': 0.8454063604240283, 'f1-score': 0.8446783177814201, 'support': 1132}
 
----------
Epoch 5/40
time = 1922.14 secondes

Train loss 0.16780832892881772 accuracy 0.9569829106330872 macro_avg {'precision': 0.9544422617033348, 'recall': 0.9543776813274839, 'f1-score': 0.9543436729105828, 'support': 10182} weighted_avg {'precision': 0.957082899244578, 'recall': 0.9569829110194461, 'f1-score': 0.956971829480186, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.7324177780267324 accuracy 0.862190842628479 macro_avg {'precision': 0.8700550486432188, 'recall': 0.862658951325076, 'f1-score': 0.8618377666814778, 'support': 1132} weighted_avg {'precision': 0.873109662625358, 'recall': 0.8621908127208481, 'f1-score': 0.8630627353570113, 'support': 1132}
 
----------
Epoch 6/40
time = 1923.40 secondes

Train loss 0.15209646134844176 accuracy 0.9624828696250916 macro_avg {'precision': 0.960568671406927, 'recall': 0.9608502644411872, 'f1-score': 0.9606605022504654, 'support': 10182} weighted_avg {'precision': 0.9625860675937754, 'recall': 0.9624828128069142, 'f1-score': 0.9624869699524449, 'support': 10182}
 
time = 53.30 secondes

Val loss 0.7910824491098051 accuracy 0.8630741834640503 macro_avg {'precision': 0.8739048415669337, 'recall': 0.8649658670323206, 'f1-score': 0.8652424836198026, 'support': 1132} weighted_avg {'precision': 0.8734628770828299, 'recall': 0.8630742049469965, 'f1-score': 0.864391520109176, 'support': 1132}
 
----------
Epoch 7/40
time = 1919.33 secondes

Train loss 0.13056213132912087 accuracy 0.9688666462898254 macro_avg {'precision': 0.9679842675373426, 'recall': 0.9678890453720749, 'f1-score': 0.9679058774256072, 'support': 10182} weighted_avg {'precision': 0.9688315105119321, 'recall': 0.9688666273816539, 'f1-score': 0.9688183985908866, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.8152730234924861 accuracy 0.8586572408676147 macro_avg {'precision': 0.8618898470234162, 'recall': 0.8578494890896333, 'f1-score': 0.8564586708214851, 'support': 1132} weighted_avg {'precision': 0.8626374034537093, 'recall': 0.8586572438162544, 'f1-score': 0.8569071639887107, 'support': 1132}
 
----------
Epoch 8/40
time = 1921.80 secondes

Train loss 0.11953015721076295 accuracy 0.9719112515449524 macro_avg {'precision': 0.9708811688815364, 'recall': 0.970867716324298, 'f1-score': 0.9708578367637344, 'support': 10182} weighted_avg {'precision': 0.9719537730489218, 'recall': 0.9719112158711452, 'f1-score': 0.9719167378769186, 'support': 10182}
 
time = 47.72 secondes

Val loss 0.723524037891225 accuracy 0.870141327381134 macro_avg {'precision': 0.8746950269223799, 'recall': 0.8721629700856346, 'f1-score': 0.8711095389842092, 'support': 1132} weighted_avg {'precision': 0.8719913764890239, 'recall': 0.8701413427561837, 'f1-score': 0.86854589786337, 'support': 1132}
 
----------
Epoch 9/40
time = 1918.96 secondes

Train loss 0.13171000592310048 accuracy 0.972304105758667 macro_avg {'precision': 0.9717382670856548, 'recall': 0.9712567131204042, 'f1-score': 0.9714287478747371, 'support': 10182} weighted_avg {'precision': 0.9723688042388928, 'recall': 0.9723040659988215, 'f1-score': 0.9722685409838638, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.9472246942312037 accuracy 0.8613074421882629 macro_avg {'precision': 0.8645305687267678, 'recall': 0.8658064686955044, 'f1-score': 0.8625773274148827, 'support': 1132} weighted_avg {'precision': 0.8679684289177609, 'recall': 0.8613074204946997, 'f1-score': 0.8621420085395792, 'support': 1132}
 
----------
Epoch 10/40
time = 1923.81 secondes

Train loss 0.11088613241697476 accuracy 0.9764290452003479 macro_avg {'precision': 0.9752179625554758, 'recall': 0.9757292537258643, 'f1-score': 0.9754248844175107, 'support': 10182} weighted_avg {'precision': 0.9765642114085306, 'recall': 0.9764289923394225, 'f1-score': 0.9764529073533446, 'support': 10182}
 
time = 53.15 secondes

Val loss 0.9061960216282053 accuracy 0.8630741834640503 macro_avg {'precision': 0.8696380771859384, 'recall': 0.8629405265607378, 'f1-score': 0.8641900206670261, 'support': 1132} weighted_avg {'precision': 0.8670442748293664, 'recall': 0.8630742049469965, 'f1-score': 0.8629459112608805, 'support': 1132}
 
----------
Epoch 11/40
time = 1926.41 secondes

Train loss 0.12593862606340242 accuracy 0.9740719199180603 macro_avg {'precision': 0.97320767702232, 'recall': 0.9730492711817892, 'f1-score': 0.9730752685218379, 'support': 10182} weighted_avg {'precision': 0.9741435792867559, 'recall': 0.9740718915733647, 'f1-score': 0.9740558624456227, 'support': 10182}
 
time = 52.65 secondes

Val loss 0.988449477814638 accuracy 0.8586572408676147 macro_avg {'precision': 0.8704122690058755, 'recall': 0.862907702325314, 'f1-score': 0.8612213325199256, 'support': 1132} weighted_avg {'precision': 0.8731343707645367, 'recall': 0.8586572438162544, 'f1-score': 0.8603554732585362, 'support': 1132}
 
----------
Epoch 12/40
time = 1925.91 secondes

Train loss 0.09780363976829587 accuracy 0.9790807366371155 macro_avg {'precision': 0.9789912996390843, 'recall': 0.9786940928669632, 'f1-score': 0.9788103392987646, 'support': 10182} weighted_avg {'precision': 0.9791057645519969, 'recall': 0.9790807307012375, 'f1-score': 0.9790608398837547, 'support': 10182}
 
time = 53.57 secondes

Val loss 0.9447666060695552 accuracy 0.8692579865455627 macro_avg {'precision': 0.8822035510822925, 'recall': 0.870140490982644, 'f1-score': 0.8715210373253462, 'support': 1132} weighted_avg {'precision': 0.8796936638294879, 'recall': 0.8692579505300353, 'f1-score': 0.8696165541610031, 'support': 1132}
 
----------
Epoch 13/40
time = 1925.57 secondes

Train loss 0.09539037328187867 accuracy 0.9821253418922424 macro_avg {'precision': 0.9819608823115014, 'recall': 0.9816884186048762, 'f1-score': 0.9817998872982969, 'support': 10182} weighted_avg {'precision': 0.9821601583233321, 'recall': 0.9821253191907288, 'f1-score': 0.9821184038666043, 'support': 10182}
 
time = 45.94 secondes

Val loss 1.0016799879794889 accuracy 0.8586572408676147 macro_avg {'precision': 0.8684059091195225, 'recall': 0.8608938541306881, 'f1-score': 0.860962575838778, 'support': 1132} weighted_avg {'precision': 0.8701210110355243, 'recall': 0.8586572438162544, 'f1-score': 0.8611124521960787, 'support': 1132}
 
----------
Epoch 14/40
time = 1926.82 secondes

Train loss 0.11129338205935016 accuracy 0.9789825677871704 macro_avg {'precision': 0.9784174033921422, 'recall': 0.9785844470958601, 'f1-score': 0.9784459855069632, 'support': 10182} weighted_avg {'precision': 0.9790609670846595, 'recall': 0.9789825181693184, 'f1-score': 0.9789691467485602, 'support': 10182}
 
time = 52.47 secondes

Val loss 0.9710275931283832 accuracy 0.8780918717384338 macro_avg {'precision': 0.8846317515333902, 'recall': 0.8787632844145318, 'f1-score': 0.8792075248447777, 'support': 1132} weighted_avg {'precision': 0.8832890099271713, 'recall': 0.8780918727915195, 'f1-score': 0.8782152057655278, 'support': 1132}
 
----------
Epoch 15/40
time = 1924.49 secondes

Train loss 0.08928665776178807 accuracy 0.98448246717453 macro_avg {'precision': 0.9839703015806924, 'recall': 0.9836706278261932, 'f1-score': 0.9837949825103255, 'support': 10182} weighted_avg {'precision': 0.9844939578968811, 'recall': 0.9844824199567865, 'f1-score': 0.9844649200208041, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.8860850506654816 accuracy 0.8736749291419983 macro_avg {'precision': 0.8755093733853874, 'recall': 0.8773560619391303, 'f1-score': 0.8736251287469301, 'support': 1132} weighted_avg {'precision': 0.8807208340134238, 'recall': 0.8736749116607774, 'f1-score': 0.8747173575783868, 'support': 1132}
 
----------
Epoch 16/40
time = 1923.23 secondes

Train loss 0.07685961915589277 accuracy 0.9863485097885132 macro_avg {'precision': 0.9863689821094754, 'recall': 0.9864582943156721, 'f1-score': 0.9864041617136952, 'support': 10182} weighted_avg {'precision': 0.9863482048486378, 'recall': 0.9863484580632489, 'f1-score': 0.9863388154446698, 'support': 10182}
 
time = 53.15 secondes

Val loss 1.0277355745044114 accuracy 0.862190842628479 macro_avg {'precision': 0.8685718206044944, 'recall': 0.8659779453270373, 'f1-score': 0.8640419867507088, 'support': 1132} weighted_avg {'precision': 0.869050366035999, 'recall': 0.8621908127208481, 'f1-score': 0.8622182386974463, 'support': 1132}
 
----------
Epoch 17/40
time = 1923.90 secondes

Train loss 0.07368812286173693 accuracy 0.9861520528793335 macro_avg {'precision': 0.9862564145756009, 'recall': 0.9860893933386711, 'f1-score': 0.9861586219834747, 'support': 10182} weighted_avg {'precision': 0.9861647238005923, 'recall': 0.9861520329994107, 'f1-score': 0.9861442141611498, 'support': 10182}
 
time = 52.52 secondes

Val loss 0.8700165179774123 accuracy 0.8869258165359497 macro_avg {'precision': 0.8931426906995149, 'recall': 0.8876121128460899, 'f1-score': 0.8884694447619121, 'support': 1132} weighted_avg {'precision': 0.8935023600343338, 'recall': 0.8869257950530035, 'f1-score': 0.8884043120449301, 'support': 1132}
 
----------
Epoch 18/40
time = 1924.82 secondes

Train loss 0.07652928455529173 accuracy 0.9865449070930481 macro_avg {'precision': 0.9863488721926548, 'recall': 0.9857695342716145, 'f1-score': 0.9860421402531097, 'support': 10182} weighted_avg {'precision': 0.9865619322924669, 'recall': 0.986544883127087, 'f1-score': 0.986538407053708, 'support': 10182}
 
time = 52.99 secondes

Val loss 0.9044486876418503 accuracy 0.8842756152153015 macro_avg {'precision': 0.8937313516046311, 'recall': 0.8858495780447873, 'f1-score': 0.8869339654307481, 'support': 1132} weighted_avg {'precision': 0.8935036054082099, 'recall': 0.8842756183745583, 'f1-score': 0.886007217329685, 'support': 1132}
 
----------
Epoch 19/40
time = 1926.83 secondes

Train loss 0.058053445491742496 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893489618120093, 'recall': 0.9892613929212845, 'f1-score': 0.9892885189261232, 'support': 10182} weighted_avg {'precision': 0.9894263616148029, 'recall': 0.9893930465527401, 'f1-score': 0.9893926587968289, 'support': 10182}
 
time = 53.42 secondes

Val loss 0.9706725447357084 accuracy 0.8772084712982178 macro_avg {'precision': 0.8814805948713327, 'recall': 0.879018767882501, 'f1-score': 0.877464054413893, 'support': 1132} weighted_avg {'precision': 0.8824810592201481, 'recall': 0.877208480565371, 'f1-score': 0.8771666246351415, 'support': 1132}
 
----------
Epoch 20/40
time = 1924.45 secondes

Train loss 0.06300680484962916 accuracy 0.9882145524024963 macro_avg {'precision': 0.9877677264913267, 'recall': 0.9880019096493753, 'f1-score': 0.9878743323204955, 'support': 10182} weighted_avg {'precision': 0.9882439270756346, 'recall': 0.9882144961697112, 'f1-score': 0.9882203170945527, 'support': 10182}
 
time = 53.21 secondes

Val loss 0.9521126986446816 accuracy 0.8780918717384338 macro_avg {'precision': 0.8798887704165328, 'recall': 0.8782878167631981, 'f1-score': 0.8777599651068119, 'support': 1132} weighted_avg {'precision': 0.8809338736239282, 'recall': 0.8780918727915195, 'f1-score': 0.878421345252993, 'support': 1132}
 
----------
Epoch 21/40
time = 1923.15 secondes

Train loss 0.07824257556795877 accuracy 0.9857591986656189 macro_avg {'precision': 0.985840597304418, 'recall': 0.984086487438633, 'f1-score': 0.9848382511506582, 'support': 10182} weighted_avg {'precision': 0.9859228773977913, 'recall': 0.9857591828717345, 'f1-score': 0.9857402985938656, 'support': 10182}
 
time = 52.70 secondes

Val loss 0.9927527360153068 accuracy 0.8772084712982178 macro_avg {'precision': 0.8835282917005148, 'recall': 0.8820352740659377, 'f1-score': 0.8804827005671392, 'support': 1132} weighted_avg {'precision': 0.8848160537524499, 'recall': 0.877208480565371, 'f1-score': 0.8787463172878207, 'support': 1132}
 
----------
Epoch 22/40
