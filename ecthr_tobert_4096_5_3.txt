[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/lib64/python3.6/site-packages/h5py/__init__.py:39: UserWarning: h5py is running against HDF5 1.10.8 when it was built against 1.10.7, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
ECtHR_ToBERT_256_50_5
----------
Epoch 1/40
time = 1156.02 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.2001404967763134 micro_f1_score 0.7313287247126681 
 
time = 57.52 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.16889469056832987 micro_f1_score 0.7538160469667319
 
----------
Epoch 2/40
time = 1145.30 secondes

Train loss 0.1371012013455903 micro_f1_score 0.8201526469632996 
 
time = 57.91 secondes

Val loss 0.16247995271057378 micro_f1_score 0.7663335895465028
 
----------
Epoch 3/40
time = 1146.91 secondes

Train loss 0.11861063042269633 micro_f1_score 0.8513302034428795 
 
time = 57.03 secondes

Val loss 0.15989352457347464 micro_f1_score 0.7829722538958572
 
----------
Epoch 4/40
time = 1145.85 secondes

Train loss 0.10521007830881186 micro_f1_score 0.8723327882582859 
 
time = 57.37 secondes

Val loss 0.16396029470641105 micro_f1_score 0.7879472693032015
 
----------
Epoch 5/40
time = 1144.41 secondes

Train loss 0.09427191351229945 micro_f1_score 0.8872299872935198 
 
time = 57.91 secondes

Val loss 0.1666264686672414 micro_f1_score 0.7877428998505231
 
----------
Epoch 6/40
time = 1151.91 secondes

Train loss 0.08359505664347461 micro_f1_score 0.902443839077737 
 
time = 58.39 secondes

Val loss 0.1754034823570095 micro_f1_score 0.7864834756776828
 
----------
Epoch 7/40
time = 1145.78 secondes

Train loss 0.07438017401995288 micro_f1_score 0.9142362341087102 
 
time = 57.08 secondes

Val loss 0.18429521965931672 micro_f1_score 0.7925219941348974
 
----------
Epoch 8/40
time = 1132.09 secondes

Train loss 0.0664629488770204 micro_f1_score 0.9256995062308958 
 
time = 57.46 secondes

Val loss 0.19097534609866923 micro_f1_score 0.7905454545454546
 
----------
Epoch 9/40
