[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
20newsgroups_BERT_head_none_1
----------
Epoch 1/40
time = 258.50 secondes

Train loss 1.263328872702934 accuracy 0.685523509979248 macro_avg {'precision': 0.7017603057498867, 'recall': 0.6702080576926586, 'f1-score': 0.667996388290267, 'support': 10182} weighted_avg {'precision': 0.7087122297631298, 'recall': 0.6855234727951287, 'f1-score': 0.6820836786233148, 'support': 10182}
 
time = 7.06 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.6117357586471128 accuracy 0.833922266960144 macro_avg {'precision': 0.8075526964716172, 'recall': 0.8275260930245845, 'f1-score': 0.812253921534946, 'support': 1132} weighted_avg {'precision': 0.8194172862521273, 'recall': 0.833922261484099, 'f1-score': 0.8212743361832183, 'support': 1132}
 
----------
Epoch 2/40
time = 252.18 secondes

Train loss 0.4386543285399909 accuracy 0.8714398145675659 macro_avg {'precision': 0.8621184933017579, 'recall': 0.8607868295548933, 'f1-score': 0.8595815488949154, 'support': 10182} weighted_avg {'precision': 0.8692875820976627, 'recall': 0.8714397957179336, 'f1-score': 0.8689765431889259, 'support': 10182}
 
time = 6.83 secondes

Val loss 0.5073278901022924 accuracy 0.8586572408676147 macro_avg {'precision': 0.8635517005739002, 'recall': 0.8604647720820278, 'f1-score': 0.8552555924202144, 'support': 1132} weighted_avg {'precision': 0.8703695371925328, 'recall': 0.8586572438162544, 'f1-score': 0.8571153378430973, 'support': 1132}
 
----------
Epoch 3/40
time = 252.06 secondes

Train loss 0.2747196465338839 accuracy 0.9231978058815002 macro_avg {'precision': 0.9193732634797367, 'recall': 0.918767342020445, 'f1-score': 0.9189110828427663, 'support': 10182} weighted_avg {'precision': 0.923690461162655, 'recall': 0.923197800039285, 'f1-score': 0.9232952996646852, 'support': 10182}
 
time = 6.93 secondes

Val loss 0.5090569610720579 accuracy 0.880742073059082 macro_avg {'precision': 0.8893712226455669, 'recall': 0.8793429707831271, 'f1-score': 0.8799391074588396, 'support': 1132} weighted_avg {'precision': 0.8904874636616423, 'recall': 0.8807420494699647, 'f1-score': 0.8813505408516, 'support': 1132}
 
----------
Epoch 4/40
time = 252.85 secondes

Train loss 0.21090531920183747 accuracy 0.9459831118583679 macro_avg {'precision': 0.9435849257774725, 'recall': 0.9435759317062413, 'f1-score': 0.9434588148368256, 'support': 10182} weighted_avg {'precision': 0.9463029497747899, 'recall': 0.94598310744451, 'f1-score': 0.9460345031700066, 'support': 10182}
 
time = 6.95 secondes

Val loss 0.4997026262555639 accuracy 0.8939929604530334 macro_avg {'precision': 0.9033339572333656, 'recall': 0.8945774671959376, 'f1-score': 0.8955135800083459, 'support': 1132} weighted_avg {'precision': 0.9037972275295929, 'recall': 0.8939929328621908, 'f1-score': 0.8951663511566404, 'support': 1132}
 
----------
Epoch 5/40
time = 252.31 secondes

Train loss 0.19058163257336225 accuracy 0.95403653383255 macro_avg {'precision': 0.9522270658610079, 'recall': 0.9520007755577243, 'f1-score': 0.951991120178459, 'support': 10182} weighted_avg {'precision': 0.954318674658952, 'recall': 0.9540365350618739, 'f1-score': 0.9540604003536982, 'support': 10182}
 
time = 6.96 secondes

Val loss 0.510394016975983 accuracy 0.9028268456459045 macro_avg {'precision': 0.9071931730603511, 'recall': 0.9054110283893445, 'f1-score': 0.9041423732568423, 'support': 1132} weighted_avg {'precision': 0.9081880551184167, 'recall': 0.9028268551236749, 'f1-score': 0.9034682535358717, 'support': 1132}
 
----------
Epoch 6/40
time = 246.78 secondes

Train loss 0.16011137826621513 accuracy 0.9650363922119141 macro_avg {'precision': 0.9637307387385095, 'recall': 0.9638135604312433, 'f1-score': 0.9637224922030729, 'support': 10182} weighted_avg {'precision': 0.9651717078029977, 'recall': 0.96503633863681, 'f1-score': 0.9650578870618314, 'support': 10182}
 
time = 7.39 secondes

Val loss 0.5422729771382595 accuracy 0.9072438478469849 macro_avg {'precision': 0.9066473013312075, 'recall': 0.9054301498489938, 'f1-score': 0.9038594044827255, 'support': 1132} weighted_avg {'precision': 0.9100829581345792, 'recall': 0.907243816254417, 'f1-score': 0.9062308585935381, 'support': 1132}
 
----------
Epoch 7/40
time = 247.23 secondes

Train loss 0.14136511692484868 accuracy 0.9677863121032715 macro_avg {'precision': 0.9666989657427691, 'recall': 0.9665305230879839, 'f1-score': 0.9665724238679578, 'support': 10182} weighted_avg {'precision': 0.9677096164036312, 'recall': 0.9677862895305441, 'f1-score': 0.9677054079219324, 'support': 10182}
 
time = 6.72 secondes

Val loss 0.5490426182177928 accuracy 0.9063604474067688 macro_avg {'precision': 0.9133825308758444, 'recall': 0.9069435465244563, 'f1-score': 0.908165678433537, 'support': 1132} weighted_avg {'precision': 0.911229278242275, 'recall': 0.9063604240282686, 'f1-score': 0.9067468741201858, 'support': 1132}
 
----------
Epoch 8/40
time = 249.23 secondes

Train loss 0.1312545144240488 accuracy 0.9706344604492188 macro_avg {'precision': 0.9698953391326416, 'recall': 0.9701152270397738, 'f1-score': 0.9699462544438354, 'support': 10182} weighted_avg {'precision': 0.9706868058674415, 'recall': 0.9706344529561972, 'f1-score': 0.9706031148004546, 'support': 10182}
 
time = 6.79 secondes

Val loss 0.5877536177355632 accuracy 0.9178445339202881 macro_avg {'precision': 0.9268556014349253, 'recall': 0.9201675312063686, 'f1-score': 0.9206652638897882, 'support': 1132} weighted_avg {'precision': 0.9236928605226554, 'recall': 0.9178445229681979, 'f1-score': 0.9177331551364551, 'support': 1132}
 
----------
Epoch 9/40
time = 251.14 secondes

Train loss 0.1352744771490108 accuracy 0.9727951288223267 macro_avg {'precision': 0.9720780321387641, 'recall': 0.9720669462662729, 'f1-score': 0.9720418560346934, 'support': 10182} weighted_avg {'precision': 0.9728624516582113, 'recall': 0.9727951286584168, 'f1-score': 0.9727975317540679, 'support': 10182}
 
time = 6.88 secondes

Val loss 0.686660295657725 accuracy 0.8939929604530334 macro_avg {'precision': 0.9041602299420557, 'recall': 0.8962010044007845, 'f1-score': 0.895436250905812, 'support': 1132} weighted_avg {'precision': 0.901040849613466, 'recall': 0.8939929328621908, 'f1-score': 0.8922004240154964, 'support': 1132}
 
----------
Epoch 10/40
time = 251.29 secondes

Train loss 0.11525016964648158 accuracy 0.9760361909866333 macro_avg {'precision': 0.9748788870881258, 'recall': 0.9749513767834449, 'f1-score': 0.9748890720067012, 'support': 10182} weighted_avg {'precision': 0.9761174646622938, 'recall': 0.9760361422117462, 'f1-score': 0.9760524808549316, 'support': 10182}
 
time = 6.84 secondes

Val loss 0.7236972280452519 accuracy 0.8966431021690369 macro_avg {'precision': 0.9099562615528054, 'recall': 0.8971425652168501, 'f1-score': 0.9003812447732956, 'support': 1132} weighted_avg {'precision': 0.9065957347566731, 'recall': 0.8966431095406361, 'f1-score': 0.8980597728537396, 'support': 1132}
 
----------
Epoch 11/40
time = 251.73 secondes

Train loss 0.1337054156254373 accuracy 0.9744647741317749 macro_avg {'precision': 0.9735616431791406, 'recall': 0.9739405306619331, 'f1-score': 0.9737143635900004, 'support': 10182} weighted_avg {'precision': 0.974611701580378, 'recall': 0.974464741701041, 'f1-score': 0.9745064836709532, 'support': 10182}
 
time = 6.83 secondes

Val loss 0.6323745941065259 accuracy 0.9028268456459045 macro_avg {'precision': 0.9074312181979008, 'recall': 0.9007558814537223, 'f1-score': 0.9022479186062313, 'support': 1132} weighted_avg {'precision': 0.906429542585187, 'recall': 0.9028268551236749, 'f1-score': 0.902965433199013, 'support': 1132}
 
----------
Epoch 12/40
time = 251.14 secondes

Train loss 0.1023584950173296 accuracy 0.9795718193054199 macro_avg {'precision': 0.9791806644828369, 'recall': 0.9792535803811093, 'f1-score': 0.9792109710840297, 'support': 10182} weighted_avg {'precision': 0.9795779350193294, 'recall': 0.9795717933608329, 'f1-score': 0.9795693261126037, 'support': 10182}
 
time = 6.80 secondes

Val loss 0.6259938772061912 accuracy 0.9098939895629883 macro_avg {'precision': 0.9116068331010696, 'recall': 0.9121441645616958, 'f1-score': 0.9105564600009524, 'support': 1132} weighted_avg {'precision': 0.912659833756713, 'recall': 0.9098939929328622, 'f1-score': 0.9099748433918968, 'support': 1132}
 
----------
Epoch 13/40
time = 245.44 secondes

Train loss 0.1143082028901456 accuracy 0.9795718193054199 macro_avg {'precision': 0.9788124794785078, 'recall': 0.9790612730906897, 'f1-score': 0.978923249852539, 'support': 10182} weighted_avg {'precision': 0.9796261844106392, 'recall': 0.9795717933608329, 'f1-score': 0.9795876445999897, 'support': 10182}
 
time = 7.30 secondes

Val loss 0.7350068436005042 accuracy 0.8975265026092529 macro_avg {'precision': 0.9031281616681062, 'recall': 0.8971438544241377, 'f1-score': 0.8973649467259305, 'support': 1132} weighted_avg {'precision': 0.9000257003802029, 'recall': 0.8975265017667845, 'f1-score': 0.8963510036049379, 'support': 1132}
 
----------
Epoch 14/40
time = 248.85 secondes

Train loss 0.09813594200239087 accuracy 0.9813396334648132 macro_avg {'precision': 0.9806750650991777, 'recall': 0.9806106065210359, 'f1-score': 0.9806311500821968, 'support': 10182} weighted_avg {'precision': 0.9813607731786027, 'recall': 0.9813396189353761, 'f1-score': 0.9813382730965525, 'support': 10182}
 
time = 6.80 secondes

Val loss 0.7900260927474936 accuracy 0.898409903049469 macro_avg {'precision': 0.9048306313345928, 'recall': 0.9017453435070666, 'f1-score': 0.9003239498520962, 'support': 1132} weighted_avg {'precision': 0.9055264004353124, 'recall': 0.8984098939929329, 'f1-score': 0.8986787569339165, 'support': 1132}
 
----------
Epoch 15/40
time = 250.01 secondes

Train loss 0.11145889990820675 accuracy 0.9810450077056885 macro_avg {'precision': 0.980894516797268, 'recall': 0.9808296852544393, 'f1-score': 0.9808352043332249, 'support': 10182} weighted_avg {'precision': 0.9811005546971419, 'recall': 0.9810449813396189, 'f1-score': 0.9810459068878794, 'support': 10182}
 
time = 6.77 secondes

Val loss 0.7992025906837817 accuracy 0.9019434452056885 macro_avg {'precision': 0.9093172952966857, 'recall': 0.9030223193896859, 'f1-score': 0.9035790606790689, 'support': 1132} weighted_avg {'precision': 0.9078222526005729, 'recall': 0.9019434628975265, 'f1-score': 0.9023580713473868, 'support': 1132}
 
----------
Epoch 16/40
time = 249.77 secondes

Train loss 0.10440658425416628 accuracy 0.9808486104011536 macro_avg {'precision': 0.9798691219181386, 'recall': 0.9805059468632722, 'f1-score': 0.9801569037178097, 'support': 10182} weighted_avg {'precision': 0.9809187896595828, 'recall': 0.9808485562757808, 'f1-score': 0.9808582739697133, 'support': 10182}
 
time = 6.79 secondes

Val loss 0.7389955461098202 accuracy 0.8966431021690369 macro_avg {'precision': 0.9004655686083567, 'recall': 0.89773659470398, 'f1-score': 0.8971095925515616, 'support': 1132} weighted_avg {'precision': 0.9001583855840201, 'recall': 0.8966431095406361, 'f1-score': 0.8963617143793174, 'support': 1132}
 
----------
Epoch 17/40
time = 250.26 secondes

Train loss 0.08996801337670317 accuracy 0.9835003018379211 macro_avg {'precision': 0.9827848409089995, 'recall': 0.9826141169980962, 'f1-score': 0.9826890944494661, 'support': 10182} weighted_avg {'precision': 0.9834945721338348, 'recall': 0.9835002946375958, 'f1-score': 0.9834877082740924, 'support': 10182}
 
time = 6.88 secondes

Val loss 0.7066374074040115 accuracy 0.9107773900032043 macro_avg {'precision': 0.9157765213493677, 'recall': 0.9121100209334342, 'f1-score': 0.9125784332273875, 'support': 1132} weighted_avg {'precision': 0.9149100477845946, 'recall': 0.9107773851590106, 'f1-score': 0.9114034122834308, 'support': 1132}
 
----------
Epoch 18/40
time = 251.19 secondes

Train loss 0.08427978739800292 accuracy 0.9847770929336548 macro_avg {'precision': 0.9840003552191281, 'recall': 0.9839402070881164, 'f1-score': 0.9839576700590289, 'support': 10182} weighted_avg {'precision': 0.9847721191319977, 'recall': 0.9847770575525437, 'f1-score': 0.9847620563857246, 'support': 10182}
 
time = 7.22 secondes

Val loss 0.7500843799791486 accuracy 0.9081271886825562 macro_avg {'precision': 0.9134074902375465, 'recall': 0.9086413873873209, 'f1-score': 0.9089767630833373, 'support': 1132} weighted_avg {'precision': 0.9123747227306244, 'recall': 0.9081272084805654, 'f1-score': 0.9081996201140228, 'support': 1132}
 
----------
Epoch 19/40
time = 246.90 secondes

Train loss 0.08497951238823132 accuracy 0.985660970211029 macro_avg {'precision': 0.9851157347255859, 'recall': 0.9855665362914987, 'f1-score': 0.9853144724140614, 'support': 10182} weighted_avg {'precision': 0.9857341883142794, 'recall': 0.9856609703398154, 'f1-score': 0.985673944304285, 'support': 10182}
 
time = 6.79 secondes

Val loss 0.9273361888188216 accuracy 0.8869258165359497 macro_avg {'precision': 0.9029879610891067, 'recall': 0.8876237693884473, 'f1-score': 0.8899935215952063, 'support': 1132} weighted_avg {'precision': 0.8998368909422045, 'recall': 0.8869257950530035, 'f1-score': 0.8871632983298824, 'support': 1132}
 
----------
Epoch 20/40
time = 248.47 secondes

Train loss 0.07809646750437176 accuracy 0.9861520528793335 macro_avg {'precision': 0.9857269621544287, 'recall': 0.9855661646444037, 'f1-score': 0.9856295237175337, 'support': 10182} weighted_avg {'precision': 0.9861890783569941, 'recall': 0.9861520329994107, 'f1-score': 0.9861535198723276, 'support': 10182}
 
time = 7.38 secondes

Val loss 0.722247730458625 accuracy 0.9098939895629883 macro_avg {'precision': 0.917144096142812, 'recall': 0.915599447844837, 'f1-score': 0.9141903104108376, 'support': 1132} weighted_avg {'precision': 0.9160711872919659, 'recall': 0.9098939929328622, 'f1-score': 0.9106350857672734, 'support': 1132}
 
----------
Epoch 21/40
time = 248.72 secondes

Train loss 0.07467404359860146 accuracy 0.9870359897613525 macro_avg {'precision': 0.9867682507514768, 'recall': 0.9867150314448005, 'f1-score': 0.9867284640192432, 'support': 10182} weighted_avg {'precision': 0.9870710931957791, 'recall': 0.9870359457866824, 'f1-score': 0.9870405346671776, 'support': 10182}
 
time = 6.91 secondes

Val loss 0.7180338702928053 accuracy 0.9125441908836365 macro_avg {'precision': 0.9133334821298226, 'recall': 0.9152948596754227, 'f1-score': 0.9122003456428095, 'support': 1132} weighted_avg {'precision': 0.9157521607057607, 'recall': 0.9125441696113075, 'f1-score': 0.9119149032628736, 'support': 1132}
 
----------
Epoch 22/40
time = 250.30 secondes

Train loss 0.06478929906290512 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888038722666298, 'recall': 0.9885614233615909, 'f1-score': 0.9886677656744904, 'support': 10182} weighted_avg {'precision': 0.9889299453532019, 'recall': 0.9889019838931448, 'f1-score': 0.9889017233531, 'support': 10182}
 
time = 6.94 secondes

Val loss 0.8039091905748265 accuracy 0.9028268456459045 macro_avg {'precision': 0.911379396586331, 'recall': 0.9086362511731993, 'f1-score': 0.9055278072243329, 'support': 1132} weighted_avg {'precision': 0.9131956714231526, 'recall': 0.9028268551236749, 'f1-score': 0.9031382706894061, 'support': 1132}
 
----------
Epoch 23/40
time = 249.90 secondes

Train loss 0.07572478385792442 accuracy 0.9877234697341919 macro_avg {'precision': 0.9876870603793177, 'recall': 0.9876794140325146, 'f1-score': 0.9876506652659159, 'support': 10182} weighted_avg {'precision': 0.9878244292235241, 'recall': 0.9877234335101159, 'f1-score': 0.9877411389883464, 'support': 10182}
 
time = 6.91 secondes

Val loss 0.6903284197234799 accuracy 0.9107773900032043 macro_avg {'precision': 0.917567114508938, 'recall': 0.914802882340692, 'f1-score': 0.9135820177675322, 'support': 1132} weighted_avg {'precision': 0.9186626031691789, 'recall': 0.9107773851590106, 'f1-score': 0.9121404095781659, 'support': 1132}
 
----------
Epoch 24/40
time = 252.31 secondes

Train loss 0.06450561216409154 accuracy 0.9891966581344604 macro_avg {'precision': 0.988899514584395, 'recall': 0.9891949256485072, 'f1-score': 0.9890315712521845, 'support': 10182} weighted_avg {'precision': 0.9892346122554989, 'recall': 0.989196621488902, 'f1-score': 0.9892015337458244, 'support': 10182}
 
time = 6.83 secondes

Val loss 0.7212912622716443 accuracy 0.9116607904434204 macro_avg {'precision': 0.9172984907645987, 'recall': 0.9153289361821961, 'f1-score': 0.9138724106621747, 'support': 1132} weighted_avg {'precision': 0.9176888191935005, 'recall': 0.911660777385159, 'f1-score': 0.9122275304787509, 'support': 1132}
 
----------
Epoch 25/40
time = 250.97 secondes

Train loss 0.06708124603503574 accuracy 0.9890984296798706 macro_avg {'precision': 0.9889837157255682, 'recall': 0.9889354149726742, 'f1-score': 0.988925971172832, 'support': 10182} weighted_avg {'precision': 0.98920047980825, 'recall': 0.9890984089569829, 'f1-score': 0.9891157084071291, 'support': 10182}
 
time = 6.71 secondes

Val loss 0.7821798086068823 accuracy 0.9063604474067688 macro_avg {'precision': 0.9102889156579049, 'recall': 0.9085779961111446, 'f1-score': 0.9078282137759193, 'support': 1132} weighted_avg {'precision': 0.9102464363658855, 'recall': 0.9063604240282686, 'f1-score': 0.9066999661641374, 'support': 1132}
 
----------
Epoch 26/40
time = 247.29 secondes

Train loss 0.059719651531013426 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901144190725599, 'recall': 0.9900555722755475, 'f1-score': 0.990072226071695, 'support': 10182} weighted_avg {'precision': 0.9903377133949278, 'recall': 0.9902769593400118, 'f1-score': 0.990294064327027, 'support': 10182}
 
time = 6.81 secondes

Val loss 0.8507461062439637 accuracy 0.9019434452056885 macro_avg {'precision': 0.9041006705851616, 'recall': 0.9048829951850109, 'f1-score': 0.9032091138935294, 'support': 1132} weighted_avg {'precision': 0.9048160141929199, 'recall': 0.9019434628975265, 'f1-score': 0.9022105042337575, 'support': 1132}
 
----------
Epoch 27/40
time = 250.74 secondes

Train loss 0.04990207875736095 accuracy 0.9921430349349976 macro_avg {'precision': 0.9919416580763132, 'recall': 0.9919873074531784, 'f1-score': 0.9919597821306508, 'support': 10182} weighted_avg {'precision': 0.9921558156616062, 'recall': 0.9921429974464742, 'f1-score': 0.9921447476180375, 'support': 10182}
 
time = 7.42 secondes

Val loss 0.8220755069544883 accuracy 0.9037102460861206 macro_avg {'precision': 0.9095335417009747, 'recall': 0.9025996732578687, 'f1-score': 0.9042176125895927, 'support': 1132} weighted_avg {'precision': 0.908281263608202, 'recall': 0.9037102473498233, 'f1-score': 0.9040629531112894, 'support': 1132}
 
----------
Epoch 28/40
time = 250.61 secondes

Train loss 0.0663954652151331 accuracy 0.9904733896255493 macro_avg {'precision': 0.9895774285515146, 'recall': 0.9897899501197422, 'f1-score': 0.9896488037435163, 'support': 10182} weighted_avg {'precision': 0.9905539313833231, 'recall': 0.9904733844038499, 'f1-score': 0.9904804049288549, 'support': 10182}
 
time = 6.83 secondes

Val loss 0.7162565783724397 accuracy 0.9196113348007202 macro_avg {'precision': 0.9187601788032358, 'recall': 0.9195260663498706, 'f1-score': 0.9180761907672581, 'support': 1132} weighted_avg {'precision': 0.9207281596723476, 'recall': 0.9196113074204947, 'f1-score': 0.9191473840995076, 'support': 1132}
 
----------
Epoch 29/40
time = 251.53 secondes

Train loss 0.04059086503027461 accuracy 0.9930269122123718 macro_avg {'precision': 0.9925670854723581, 'recall': 0.9927167346052114, 'f1-score': 0.9926272063115512, 'support': 10182} weighted_avg {'precision': 0.9930552120686112, 'recall': 0.9930269102337458, 'f1-score': 0.9930284269781219, 'support': 10182}
 
time = 6.82 secondes

Val loss 0.706465455843935 accuracy 0.9143109321594238 macro_avg {'precision': 0.9149697942909573, 'recall': 0.9184096142999966, 'f1-score': 0.9153793656351807, 'support': 1132} weighted_avg {'precision': 0.9169750514163649, 'recall': 0.9143109540636042, 'f1-score': 0.9143225132593404, 'support': 1132}
 
----------
Epoch 30/40
time = 250.42 secondes

Train loss 0.027977638044020134 accuracy 0.9954822659492493 macro_avg {'precision': 0.9953157136769123, 'recall': 0.9953131977244756, 'f1-score': 0.9953055224206404, 'support': 10182} weighted_avg {'precision': 0.9954962153528318, 'recall': 0.9954822235317227, 'f1-score': 0.9954802846682627, 'support': 10182}
 
time = 6.87 secondes

Val loss 0.7825092716469646 accuracy 0.9107773900032043 macro_avg {'precision': 0.9142359284768053, 'recall': 0.9155555931914995, 'f1-score': 0.9131304583068877, 'support': 1132} weighted_avg {'precision': 0.9153674513654004, 'recall': 0.9107773851590106, 'f1-score': 0.9112660298856434, 'support': 1132}
 
----------
Epoch 31/40
time = 250.78 secondes

Train loss 0.03686146650539209 accuracy 0.9929287433624268 macro_avg {'precision': 0.9921378042896339, 'recall': 0.9925293015835326, 'f1-score': 0.992303869580564, 'support': 10182} weighted_avg {'precision': 0.9929820066751044, 'recall': 0.9929286977018268, 'f1-score': 0.9929317500401419, 'support': 10182}
 
time = 6.88 secondes

Val loss 0.711872795763451 accuracy 0.9187279343605042 macro_avg {'precision': 0.9221666221275185, 'recall': 0.9205913315865557, 'f1-score': 0.9198334273980173, 'support': 1132} weighted_avg {'precision': 0.9221143154425232, 'recall': 0.9187279151943463, 'f1-score': 0.9187882723136276, 'support': 1132}
 
----------
Epoch 32/40
time = 247.37 secondes

Train loss 0.02746521234741116 accuracy 0.9953840374946594 macro_avg {'precision': 0.995133299226025, 'recall': 0.9951308959815763, 'f1-score': 0.9951267083315397, 'support': 10182} weighted_avg {'precision': 0.9953967623224463, 'recall': 0.9953840109998036, 'f1-score': 0.9953852907654042, 'support': 10182}
 
time = 7.18 secondes

Val loss 0.8069455720996955 accuracy 0.9116607904434204 macro_avg {'precision': 0.9125715566774968, 'recall': 0.9158725743751722, 'f1-score': 0.9118011144847182, 'support': 1132} weighted_avg {'precision': 0.9169377210144425, 'recall': 0.911660777385159, 'f1-score': 0.9120646533457887, 'support': 1132}
 
----------
Epoch 33/40
time = 250.42 secondes

Train loss 0.027775616851617734 accuracy 0.9950894117355347 macro_avg {'precision': 0.9948285478293164, 'recall': 0.9949035795623227, 'f1-score': 0.994862261179686, 'support': 10182} weighted_avg {'precision': 0.9951005618570411, 'recall': 0.9950893734040464, 'f1-score': 0.9950914503264409, 'support': 10182}
 
time = 6.87 secondes

Val loss 0.7558389602166078 accuracy 0.916961133480072 macro_avg {'precision': 0.9195302686767495, 'recall': 0.9210061981316884, 'f1-score': 0.9184899689463981, 'support': 1132} weighted_avg {'precision': 0.9227016441153024, 'recall': 0.9169611307420494, 'f1-score': 0.9181124505052021, 'support': 1132}
 
----------
Epoch 34/40
time = 250.11 secondes

Train loss 0.02778516562054051 accuracy 0.995776891708374 macro_avg {'precision': 0.9954843399652635, 'recall': 0.9954829575525096, 'f1-score': 0.9954769365467702, 'support': 10182} weighted_avg {'precision': 0.9957837646517178, 'recall': 0.9957768611274799, 'f1-score': 0.9957737896030247, 'support': 10182}
 
time = 7.83 secondes

Val loss 0.7847715615677425 accuracy 0.9187279343605042 macro_avg {'precision': 0.9217913016109309, 'recall': 0.9210838076803286, 'f1-score': 0.9200446178342337, 'support': 1132} weighted_avg {'precision': 0.9217469247550432, 'recall': 0.9187279151943463, 'f1-score': 0.918759825244848, 'support': 1132}
 
----------
Epoch 35/40
time = 249.76 secondes

Train loss 0.022826091056206962 accuracy 0.9963661432266235 macro_avg {'precision': 0.996458026696995, 'recall': 0.9963377716028416, 'f1-score': 0.9963933626950847, 'support': 10182} weighted_avg {'precision': 0.9963763650850772, 'recall': 0.9963661363189943, 'f1-score': 0.9963666003610481, 'support': 10182}
 
time = 6.78 secondes

Val loss 0.7679374363633799 accuracy 0.9204947352409363 macro_avg {'precision': 0.9225280347503185, 'recall': 0.9239871218910434, 'f1-score': 0.9214151904214702, 'support': 1132} weighted_avg {'precision': 0.924327377343171, 'recall': 0.9204946996466431, 'f1-score': 0.9205313326889099, 'support': 1132}
 
----------
Epoch 36/40
time = 250.58 secondes

Train loss 0.018142695244357444 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967679585525511, 'recall': 0.9967271873267508, 'f1-score': 0.9967452793521613, 'support': 10182} weighted_avg {'precision': 0.9967638259998332, 'recall': 0.9967589864466706, 'f1-score': 0.9967590703654247, 'support': 10182}
 
time = 6.81 secondes

Val loss 0.761858034702809 accuracy 0.9196113348007202 macro_avg {'precision': 0.9186531367518572, 'recall': 0.9224562970109094, 'f1-score': 0.9192263589820884, 'support': 1132} weighted_avg {'precision': 0.9230442542043331, 'recall': 0.9196113074204947, 'f1-score': 0.920024124584787, 'support': 1132}
 
----------
Epoch 37/40
time = 250.13 secondes

Train loss 0.01815121970660012 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974447130194019, 'recall': 0.9974233089452775, 'f1-score': 0.9974319411371747, 'support': 10182} weighted_avg {'precision': 0.9973505900561392, 'recall': 0.997348261638185, 'f1-score': 0.9973472903722584, 'support': 10182}
 
time = 6.93 secondes

Val loss 0.7533902160066646 accuracy 0.9204947352409363 macro_avg {'precision': 0.9237860892229335, 'recall': 0.9238759178520809, 'f1-score': 0.9218351883973682, 'support': 1132} weighted_avg {'precision': 0.9253167733775467, 'recall': 0.9204946996466431, 'f1-score': 0.9207456977204976, 'support': 1132}
 
----------
Epoch 38/40
time = 249.76 secondes

Train loss 0.006924396099478414 accuracy 0.998919665813446 macro_avg {'precision': 0.9989388564492676, 'recall': 0.9989403128091618, 'f1-score': 0.9989384844270817, 'support': 10182} weighted_avg {'precision': 0.9989217262292749, 'recall': 0.9989196621488902, 'f1-score': 0.998919568440116, 'support': 10182}
 
time = 6.88 secondes

Val loss 0.7545767329339328 accuracy 0.9222614765167236 macro_avg {'precision': 0.9254649541538227, 'recall': 0.925174469276584, 'f1-score': 0.9238377104629576, 'support': 1132} weighted_avg {'precision': 0.9264974009742808, 'recall': 0.9222614840989399, 'f1-score': 0.9227863833075717, 'support': 1132}
 
----------
Epoch 39/40
time = 246.40 secondes

Train loss 0.005710802699696776 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991570206615412, 'recall': 0.9991604609937763, 'f1-score': 0.9991580357507196, 'support': 10182} weighted_avg {'precision': 0.9991179346647294, 'recall': 0.9991160872127284, 'f1-score': 0.9991162741392261, 'support': 10182}
 
time = 6.85 secondes

Val loss 0.7573551383191213 accuracy 0.9204947352409363 macro_avg {'precision': 0.9237733347868342, 'recall': 0.92323656511568, 'f1-score': 0.9218597605883163, 'support': 1132} weighted_avg {'precision': 0.9243948136286163, 'recall': 0.9204946996466431, 'f1-score': 0.9206883332255212, 'support': 1132}
 
----------
Epoch 40/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.22 GiB already allocated; 23.31 MiB free; 7.31 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 7.27 GiB already allocated; 9.31 MiB free; 7.33 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.20 GiB total capacity; 7.25 GiB already allocated; 9.31 MiB free; 7.33 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_1
----------
Epoch 1/40
time = 273.25 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.28389799778794383 micro_f1_score 0.5707319317293095 
 
time = 16.11 secondes

Val loss 0.24259695337444057 micro_f1_score 0.6246081504702194
 
----------
Epoch 2/40
time = 266.65 secondes

Train loss 0.19055049112318334 micro_f1_score 0.7310235827475774 
 
time = 16.04 secondes

Val loss 0.21256732134545436 micro_f1_score 0.6953062848050915
 
----------
Epoch 3/40
time = 265.86 secondes

Train loss 0.16382512214954373 micro_f1_score 0.7802617006439969 
 
time = 15.92 secondes

Val loss 0.20495709654737693 micro_f1_score 0.703601108033241
 
----------
Epoch 4/40
time = 267.53 secondes

Train loss 0.14471984456318457 micro_f1_score 0.8151103150696083 
 
time = 16.10 secondes

Val loss 0.20336082174641187 micro_f1_score 0.7178890182382616
 
----------
Epoch 5/40
time = 267.52 secondes

Train loss 0.12902657210088528 micro_f1_score 0.8370079695780573 
 
time = 16.66 secondes

Val loss 0.21033402391877332 micro_f1_score 0.7180076628352492
 
----------
Epoch 6/40
time = 284.46 secondes

Train loss 0.11577172859294994 micro_f1_score 0.8588523471067743 
 
time = 17.36 secondes

Val loss 0.21822297084526937 micro_f1_score 0.716585548483714
 
----------
Epoch 7/40
time = 289.15 secondes

Train loss 0.10529829611380895 micro_f1_score 0.873863817572955 
 
time = 17.25 secondes

Val loss 0.22856411447779076 micro_f1_score 0.7255709472107825
 
----------
Epoch 8/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.88 GiB already allocated; 14.31 MiB free; 13.98 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.88 GiB already allocated; 18.31 MiB free; 13.98 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 22.31 MiB free; 13.97 GiB reserved in total by PyTorch)
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 26.31 MiB free; 13.97 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 26.31 MiB free; 13.97 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.20 GiB total capacity; 13.73 GiB already allocated; 64.31 MiB free; 13.85 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_none_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 7.97 GiB already allocated; 22.31 MiB free; 8.08 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.99 GiB already allocated; 36.31 MiB free; 8.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.99 GiB already allocated; 36.31 MiB free; 8.07 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.80 GiB already allocated; 56.31 MiB free; 8.05 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.80 GiB already allocated; 56.31 MiB free; 8.05 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.80 GiB already allocated; 8.31 MiB free; 8.05 GiB reserved in total by PyTorch)
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_2
----------
Epoch 1/40
time = 15.04 secondes

Train loss 0.6476433385502208 accuracy 0.6298449635505676 macro_avg {'precision': 0.3173828125, 'recall': 0.4939209726443769, 'f1-score': 0.3864447086801427, 'support': 516} weighted_avg {'precision': 0.40472459423449614, 'recall': 0.6298449612403101, 'f1-score': 0.49279189595258505, 'support': 516}
 
time = 0.62 secondes

Val loss 0.587630145251751 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 13.92 secondes

Train loss 0.5186942183610165 accuracy 0.7441860437393188 macro_avg {'precision': 0.7569944044764189, 'recall': 0.6724477024852494, 'f1-score': 0.6807589193648175, 'support': 516} weighted_avg {'precision': 0.7512749490330217, 'recall': 0.7441860465116279, 'f1-score': 0.7199182761250221, 'support': 516}
 
time = 0.52 secondes

Val loss 0.4255586713552475 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 3/40
time = 13.91 secondes

Train loss 0.4147833816029809 accuracy 0.8217054009437561 macro_avg {'precision': 0.8073089700996677, 'recall': 0.8232530923394503, 'f1-score': 0.8125562662876096, 'support': 516} weighted_avg {'precision': 0.831079862989003, 'recall': 0.8217054263565892, 'f1-score': 0.8239525884787946, 'support': 516}
 
time = 0.54 secondes

Val loss 0.6312367022037506 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 4/40
time = 13.80 secondes

Train loss 0.28887884905844025 accuracy 0.8895348906517029 macro_avg {'precision': 0.8801894135962636, 'recall': 0.8810607415113048, 'f1-score': 0.88062100456621, 'support': 516} weighted_avg {'precision': 0.889668390436997, 'recall': 0.8895348837209303, 'f1-score': 0.8895981027220274, 'support': 516}
 
time = 0.55 secondes

Val loss 0.4662577398121357 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 5/40
time = 13.84 secondes

Train loss 0.21287819810888983 accuracy 0.9263566136360168 macro_avg {'precision': 0.9220203810367744, 'recall': 0.9180144011182809, 'f1-score': 0.9199477423042377, 'support': 516} weighted_avg {'precision': 0.926125324714726, 'recall': 0.9263565891472868, 'f1-score': 0.9261810043022717, 'support': 516}
 
time = 0.59 secondes

Val loss 0.6282428726553917 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 6/40
time = 14.15 secondes

Train loss 0.2319162144523227 accuracy 0.9205426573753357 macro_avg {'precision': 0.9129641588634162, 'recall': 0.9157632105066398, 'f1-score': 0.9143256322514022, 'support': 516} weighted_avg {'precision': 0.920876980223422, 'recall': 0.9205426356589147, 'f1-score': 0.9206768155885733, 'support': 516}
 
time = 0.47 secondes

Val loss 1.0182067453861237 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 7/40
time = 14.06 secondes

Train loss 0.15328160323428386 accuracy 0.9593023061752319 macro_avg {'precision': 0.954617371649984, 'recall': 0.9576987468101361, 'f1-score': 0.9561180067629134, 'support': 516} weighted_avg {'precision': 0.9595090147254282, 'recall': 0.9593023255813954, 'f1-score': 0.9593710518868303, 'support': 516}
 
time = 0.51 secondes

Val loss 0.9893745183944702 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 8/40
time = 13.91 secondes

Train loss 0.27690975507721305 accuracy 0.9244186282157898 macro_avg {'precision': 0.9194604504976427, 'recall': 0.9164946442793752, 'f1-score': 0.9179385966700785, 'support': 516} weighted_avg {'precision': 0.9242175984016957, 'recall': 0.9244186046511628, 'f1-score': 0.9242845355205198, 'support': 516}
 
time = 0.51 secondes

Val loss 0.920039176940918 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 9/40
time = 13.73 secondes

Train loss 0.10456791872892415 accuracy 0.9767441749572754 macro_avg {'precision': 0.9748386782179023, 'recall': 0.9748386782179023, 'f1-score': 0.9748386782179023, 'support': 516} weighted_avg {'precision': 0.9767441860465116, 'recall': 0.9767441860465116, 'f1-score': 0.9767441860465116, 'support': 516}
 
time = 0.50 secondes

Val loss 0.7835583165287971 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 10/40
time = 13.70 secondes

Train loss 0.10831143510894793 accuracy 0.9670542478561401 macro_avg {'precision': 0.9659180199057098, 'recall': 0.9626237342132211, 'f1-score': 0.9642296447023418, 'support': 516} weighted_avg {'precision': 0.967008199633722, 'recall': 0.9670542635658915, 'f1-score': 0.9669958231756111, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6634585186839104 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 11/40
time = 13.86 secondes

Train loss 0.2891405942271266 accuracy 0.9244186282157898 macro_avg {'precision': 0.9132653061224489, 'recall': 0.9384214033775986, 'f1-score': 0.9210225778726644, 'support': 516} weighted_avg {'precision': 0.9352620893318567, 'recall': 0.9244186046511628, 'f1-score': 0.9255294545319801, 'support': 516}
 
time = 0.51 secondes

Val loss 0.7938093915581703 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 12/40
time = 13.87 secondes

Train loss 0.10593118560570998 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 0.52 secondes

Val loss 0.8705193996429443 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 13/40
time = 14.98 secondes

Train loss 0.09973334489658361 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 0.50 secondes

Val loss 0.8677250370383263 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 14/40
time = 15.60 secondes

Train loss 0.09058691665995866 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 0.55 secondes

Val loss 0.9958115145564079 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 15/40
time = 17.51 secondes

Train loss 0.029737331631953235 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.52 secondes

Val loss 2.022353708744049 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 16/40
time = 14.12 secondes

Train loss 0.10609421359064679 accuracy 0.9767441749572754 macro_avg {'precision': 0.9795766125690035, 'recall': 0.97022251840775, 'f1-score': 0.9745975483680402, 'support': 516} weighted_avg {'precision': 0.9770310140487893, 'recall': 0.9767441860465116, 'f1-score': 0.9766296987036599, 'support': 516}
 
time = 0.55 secondes

Val loss 1.6483793258666992 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 17/40
time = 13.94 secondes

Train loss 0.25651657947155676 accuracy 0.9554263353347778 macro_avg {'precision': 0.9513168137000518, 'recall': 0.9523511532272484, 'f1-score': 0.9518295281582952, 'support': 516} weighted_avg {'precision': 0.9554850643447058, 'recall': 0.9554263565891473, 'f1-score': 0.9554518660106426, 'support': 516}
 
time = 0.52 secondes

Val loss 0.8511447384953499 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 18/40
time = 13.91 secondes

Train loss 0.11250432711059341 accuracy 0.9728682041168213 macro_avg {'precision': 0.9651741293532339, 'recall': 0.9787234042553192, 'f1-score': 0.9710891976692066, 'support': 516} weighted_avg {'precision': 0.9747579929808323, 'recall': 0.9728682170542635, 'f1-score': 0.9730627972995041, 'support': 516}
 
time = 0.52 secondes

Val loss 0.9753586500883102 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 19/40
time = 13.65 secondes

Train loss 0.08776816274356944 accuracy 0.9767441749572754 macro_avg {'precision': 0.9712437095614666, 'recall': 0.9794548380280546, 'f1-score': 0.9750624244865083, 'support': 516} weighted_avg {'precision': 0.9774426592509617, 'recall': 0.9767441860465116, 'f1-score': 0.9768445897217357, 'support': 516}
 
time = 0.49 secondes

Val loss 1.3663984388113022 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 20/40
time = 14.02 secondes

Train loss 0.1869445880182673 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 0.51 secondes

Val loss 1.3605611696839333 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 21/40
time = 14.02 secondes

Train loss 0.14400232905719543 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 0.46 secondes

Val loss 1.0464647347689606 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 22/40
time = 13.68 secondes

Train loss 0.0692966641094465 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 0.53 secondes

Val loss 1.5832359790802002 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 23/40
time = 14.18 secondes

Train loss 0.014413366079238724 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.49 secondes

Val loss 2.013337254524231 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 14.18 secondes

Train loss 0.19280662303561147 accuracy 0.9670542478561401 macro_avg {'precision': 0.9588036829160623, 'recall': 0.9730100937860637, 'f1-score': 0.9649298156536479, 'support': 516} weighted_avg {'precision': 0.9692642405256673, 'recall': 0.9670542635658915, 'f1-score': 0.9673051826106447, 'support': 516}
 
time = 0.56 secondes

Val loss 0.9940875247120857 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 25/40
time = 13.93 secondes

Train loss 0.12986603245901113 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 0.49 secondes

Val loss 1.2156233936548233 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 26/40
time = 14.19 secondes

Train loss 0.08301010889364548 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 0.50 secondes

Val loss 2.1881823241710663 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 27/40
time = 14.15 secondes

Train loss 0.05612168423778547 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 0.53 secondes

Val loss 1.5383962392807007 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 28/40
time = 13.89 secondes

Train loss 0.0816590417283199 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 0.51 secondes

Val loss 1.5511074215173721 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 29/40
time = 14.15 secondes

Train loss 0.1197377638827399 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 0.51 secondes

Val loss 1.53982312977314 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 30/40
time = 13.60 secondes

Train loss 0.03865092342223789 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.50 secondes

Val loss 1.503997951745987 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 14.11 secondes

Train loss 0.011734715745577969 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.54 secondes

Val loss 1.2756416220217943 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 32/40
time = 13.79 secondes

Train loss 0.02563137937139607 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.59 secondes

Val loss 0.8337275348603725 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 33/40
time = 14.99 secondes

Train loss 0.020293894474338176 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.49 secondes

Val loss 1.114693347364664 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 34/40
time = 13.79 secondes

Train loss 0.00018303495060977048 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.51 secondes

Val loss 1.6443877816200256 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 35/40
time = 17.06 secondes

Train loss 9.946444366836327e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.52 secondes

Val loss 2.4162987172603607 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 36/40
time = 15.49 secondes

Train loss 0.08495292953419707 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 0.52 secondes

Val loss 1.7154805958271027 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 13.85 secondes

Train loss 7.737779301488914e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.52 secondes

Val loss 1.8546954691410065 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 38/40
time = 13.67 secondes

Train loss 0.01513695080520296 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.52 secondes

Val loss 1.9073406755924225 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 39/40
time = 14.14 secondes

Train loss 0.00010531761367791191 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.53 secondes

Val loss 1.6079570651054382 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 40/40
time = 14.15 secondes

Train loss 9.66943482512072e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.49 secondes

Val loss 1.6974487900733948 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 11 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}

average train time 14.263521575927735

average val time 0.5205475211143493
 
time = 0.61 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_2
----------
Epoch 1/40
time = 14.14 secondes

Train loss 0.6691592281514948 accuracy 0.6220930218696594 macro_avg {'precision': 0.46754032258064515, 'recall': 0.4947661850039823, 'f1-score': 0.4108036890645587, 'support': 516} weighted_avg {'precision': 0.5136463803450864, 'recall': 0.622093023255814, 'f1-score': 0.5079010529971096, 'support': 516}
 
time = 0.70 secondes

Val loss 0.653860792517662 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 13.70 secondes

Train loss 0.4737939369497877 accuracy 0.7984496355056763 macro_avg {'precision': 0.8062015503875969, 'recall': 0.7484680525982152, 'f1-score': 0.7628173396506612, 'support': 516} weighted_avg {'precision': 0.8019349798689981, 'recall': 0.7984496124031008, 'f1-score': 0.7881162533048933, 'support': 516}
 
time = 0.57 secondes

Val loss 0.4093651920557022 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 3/40
time = 13.64 secondes

Train loss 0.3621539922826218 accuracy 0.8740310072898865 macro_avg {'precision': 0.8723063683304647, 'recall': 0.8515920875119873, 'f1-score': 0.8600675047040515, 'support': 516} weighted_avg {'precision': 0.873637340057906, 'recall': 0.874031007751938, 'f1-score': 0.8722320288316581, 'support': 516}
 
time = 0.51 secondes

Val loss 0.4019826427102089 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 4/40
time = 13.64 secondes

Train loss 0.3022350105598117 accuracy 0.8972868323326111 macro_avg {'precision': 0.8914682539682539, 'recall': 0.8848316889618517, 'f1-score': 0.8879432914711847, 'support': 516} weighted_avg {'precision': 0.8967646425495263, 'recall': 0.8972868217054264, 'f1-score': 0.8968478639091868, 'support': 516}
 
time = 0.56 secondes

Val loss 0.5954950302839279 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 5/40
time = 13.59 secondes

Train loss 0.4527361079147368 accuracy 0.8410852551460266 macro_avg {'precision': 0.8271868332825358, 'recall': 0.8315264210132796, 'f1-score': 0.8292218275750726, 'support': 516} weighted_avg {'precision': 0.8423682040595489, 'recall': 0.8410852713178295, 'f1-score': 0.8416086585417745, 'support': 516}
 
time = 0.50 secondes

Val loss 0.6467646360397339 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 6/40
time = 14.14 secondes

Train loss 0.2614644691348076 accuracy 0.9186046719551086 macro_avg {'precision': 0.9154219783498831, 'recall': 0.9073192139525056, 'f1-score': 0.9110914192881407, 'support': 516} weighted_avg {'precision': 0.9182823551817367, 'recall': 0.9186046511627907, 'f1-score': 0.9182039454628095, 'support': 516}
 
time = 0.53 secondes

Val loss 0.31783175468444824 accuracy 0.90625 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}
 
----------
Epoch 7/40
time = 13.50 secondes

Train loss 0.18861457078971647 accuracy 0.9496123790740967 macro_avg {'precision': 0.9423915648214714, 'recall': 0.9500999626156073, 'f1-score': 0.9459685863874345, 'support': 516} weighted_avg {'precision': 0.9505293349457662, 'recall': 0.9496124031007752, 'f1-score': 0.9498299443970939, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6147453114390373 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 8/40
time = 13.52 secondes

Train loss 0.3113351749030478 accuracy 0.9224806427955627 macro_avg {'precision': 0.9353299150151695, 'recall': 0.8988183281049364, 'f1-score': 0.9127906976744187, 'support': 516} weighted_avg {'precision': 0.9262972423907212, 'recall': 0.9224806201550387, 'f1-score': 0.920790517396791, 'support': 516}
 
time = 0.59 secondes

Val loss 0.5317751541733742 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 9/40
time = 13.47 secondes

Train loss 0.21449302812812454 accuracy 0.9496123790740967 macro_avg {'precision': 0.9438099073701167, 'recall': 0.9477918827105309, 'f1-score': 0.945730789767487, 'support': 516} weighted_avg {'precision': 0.9499588207563369, 'recall': 0.9496124031007752, 'f1-score': 0.9497249136321749, 'support': 516}
 
time = 0.50 secondes

Val loss 0.507225401699543 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 10/40
time = 13.43 secondes

Train loss 0.19156890658831055 accuracy 0.9554263353347778 macro_avg {'precision': 0.9522482893450636, 'recall': 0.9511971132747102, 'f1-score': 0.9517182179514823, 'support': 516} weighted_avg {'precision': 0.9553822167663129, 'recall': 0.9554263565891473, 'f1-score': 0.955400425549723, 'support': 516}
 
time = 0.53 secondes

Val loss 0.962611734867096 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 11/40
time = 13.54 secondes

Train loss 0.21527723766242465 accuracy 0.9457364082336426 macro_avg {'precision': 0.9442401253401501, 'recall': 0.937828129317491, 'f1-score': 0.9408721843897327, 'support': 516} weighted_avg {'precision': 0.9456198386200823, 'recall': 0.9457364341085271, 'f1-score': 0.945539234795603, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6522274985909462 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 12/40
time = 13.62 secondes

Train loss 0.12952076114544814 accuracy 0.9728682041168213 macro_avg {'precision': 0.9696616669093734, 'recall': 0.9717991645400907, 'f1-score': 0.9707122470160872, 'support': 516} weighted_avg {'precision': 0.9729611605367241, 'recall': 0.9728682170542635, 'f1-score': 0.9728990166262376, 'support': 516}
 
time = 1.00 secondes

Val loss 0.9152942672371864 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 13/40
time = 13.85 secondes

Train loss 0.14495724106602598 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 0.50 secondes

Val loss 1.3900098204612732 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 14/40
time = 15.60 secondes

Train loss 0.11456804043810928 accuracy 0.9670542478561401 macro_avg {'precision': 0.9682539682539683, 'recall': 0.9603156543081449, 'f1-score': 0.9640572821700026, 'support': 516} weighted_avg {'precision': 0.9671619293712317, 'recall': 0.9670542635658915, 'f1-score': 0.9669134657821921, 'support': 516}
 
time = 0.53 secondes

Val loss 0.977115623652935 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 15/40
time = 14.97 secondes

Train loss 0.11285817593152662 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 0.54 secondes

Val loss 1.0534869655966759 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 16/40
time = 13.41 secondes

Train loss 0.12052273824387653 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 0.51 secondes

Val loss 0.7477524355053902 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 17/40
time = 13.56 secondes

Train loss 0.26204545226540754 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 0.49 secondes

Val loss 1.0265655145049095 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 18/40
time = 13.31 secondes

Train loss 0.29278874928555026 accuracy 0.9360464811325073 macro_avg {'precision': 0.9523504273504273, 'recall': 0.9129187458348911, 'f1-score': 0.9279472933689337, 'support': 516} weighted_avg {'precision': 0.9410016232690651, 'recall': 0.936046511627907, 'f1-score': 0.9345952066219638, 'support': 516}
 
time = 0.51 secondes

Val loss 1.1895519495010376 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 19/40
time = 13.43 secondes

Train loss 0.01880250264234333 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 0.56 secondes

Val loss 0.9776146560907364 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 20/40
time = 13.70 secondes

Train loss 0.14531070487679576 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 0.49 secondes

Val loss 1.1296423897147179 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 21/40
time = 13.49 secondes

Train loss 0.03368834678655152 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 0.50 secondes

Val loss 1.5432065725326538 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 22/40
time = 13.15 secondes

Train loss 0.10607513134582956 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 0.53 secondes

Val loss 1.1890716850757599 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 23/40
time = 13.67 secondes

Train loss 0.06914066233950893 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 0.50 secondes

Val loss 1.2520389184355736 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 24/40
time = 13.45 secondes

Train loss 0.10075194293202719 accuracy 0.9806201457977295 macro_avg {'precision': 0.9790322318482518, 'recall': 0.9790322318482518, 'f1-score': 0.9790322318482518, 'support': 516} weighted_avg {'precision': 0.9806201550387597, 'recall': 0.9806201550387597, 'f1-score': 0.9806201550387597, 'support': 516}
 
time = 0.54 secondes

Val loss 1.3524656221270561 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 25/40
time = 13.55 secondes

Train loss 0.20380238194731204 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 0.53 secondes

Val loss 1.3711987882852554 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 26/40
time = 13.31 secondes

Train loss 0.05738344468232809 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.46 secondes

Val loss 1.060402724891901 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 27/40
time = 14.00 secondes

Train loss 0.018285203801386877 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.52 secondes

Val loss 1.3051619082689285 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 28/40
time = 13.77 secondes

Train loss 0.10445855445119157 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 0.52 secondes

Val loss 1.94391331076622 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 29/40
time = 13.88 secondes

Train loss 0.03394483533779611 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 0.52 secondes

Val loss 1.7826145738363266 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 30/40
time = 13.91 secondes

Train loss 0.18935495036280234 accuracy 0.9670542478561401 macro_avg {'precision': 0.9583333333333333, 'recall': 0.9741641337386018, 'f1-score': 0.9650003391440005, 'support': 516} weighted_avg {'precision': 0.9697997416020671, 'recall': 0.9670542635658915, 'f1-score': 0.9673335972872688, 'support': 516}
 
time = 0.51 secondes

Val loss 1.6768475770950317 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 31/40
time = 13.60 secondes

Train loss 0.18464971098574373 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 0.50 secondes

Val loss 1.5795994699001312 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 32/40
time = 13.55 secondes

Train loss 0.032054056816074684 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.51 secondes

Val loss 1.1219100430607796 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 33/40
time = 14.40 secondes

Train loss 0.029341232800630456 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.55 secondes

Val loss 1.2771467491984367 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 34/40
time = 14.06 secondes

Train loss 0.03401556532216174 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.53 secondes

Val loss 1.6625613868236542 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 35/40
time = 13.46 secondes

Train loss 0.006611321078459944 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.49 secondes

Val loss 1.5047822445631027 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 36/40
time = 12.96 secondes

Train loss 0.05910298784962806 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 0.52 secondes

Val loss 1.7394249141216278 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 37/40
time = 13.55 secondes

Train loss 0.017799837793008366 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.54 secondes

Val loss 1.503453478217125 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 38/40
time = 16.69 secondes

Train loss 0.0003369870277255717 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.57 secondes

Val loss 1.0468443781137466 accuracy 0.875 macro_avg {'precision': 0.8705882352941177, 'recall': 0.8825910931174089, 'f1-score': 0.873015873015873, 'support': 64} weighted_avg {'precision': 0.8838235294117647, 'recall': 0.875, 'f1-score': 0.8759920634920635, 'support': 64}
 
----------
Epoch 39/40
time = 14.85 secondes

Train loss 0.013321720690300659 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.50 secondes

Val loss 1.2896412312984467 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 40/40
time = 13.58 secondes

Train loss 0.00015600688912496534 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.54 secondes

Val loss 1.4551233351230621 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 6 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}

average train time 13.81700142621994

average val time 0.5387065052986145
 
time = 0.57 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9523809523809523, 'recall': 0.9259259259259259, 'f1-score': 0.935, 'support': 65} weighted_avg {'precision': 0.9443223443223443, 'recall': 0.9384615384615385, 'f1-score': 0.9375384615384615, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_2
----------
Epoch 1/40
time = 14.43 secondes

Train loss 0.66092603856867 accuracy 0.6220930218696594 macro_avg {'precision': 0.4561579651941098, 'recall': 0.4936121450514442, 'f1-score': 0.40649423422892034, 'support': 516} weighted_avg {'precision': 0.5052470865373639, 'recall': 0.622093023255814, 'f1-score': 0.5049348388649939, 'support': 516}
 
time = 0.58 secondes

Val loss 0.691625565290451 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 13.34 secondes

Train loss 0.5477617148197058 accuracy 0.6647287011146545 macro_avg {'precision': 0.7967500000000001, 'recall': 0.538587195032752, 'f1-score': 0.4695490441923619, 'support': 516} weighted_avg {'precision': 0.758016472868217, 'recall': 0.6647286821705426, 'f1-score': 0.5580969949684055, 'support': 516}
 
time = 0.54 secondes

Val loss 0.5065917670726776 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 13.32 secondes

Train loss 0.38830435140566394 accuracy 0.8488371968269348 macro_avg {'precision': 0.837345542263575, 'recall': 0.8341433285112885, 'f1-score': 0.835682207887646, 'support': 516} weighted_avg {'precision': 0.8482243203935922, 'recall': 0.8488372093023255, 'f1-score': 0.8484767983046632, 'support': 516}
 
time = 0.50 secondes

Val loss 0.4881362318992615 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 4/40
time = 13.18 secondes

Train loss 0.3031536191701889 accuracy 0.8875969052314758 macro_avg {'precision': 0.8812061734330189, 'recall': 0.8737707849097085, 'f1-score': 0.8772214837788608, 'support': 516} weighted_avg {'precision': 0.8869497371193088, 'recall': 0.8875968992248062, 'f1-score': 0.8870435437343559, 'support': 516}
 
time = 0.52 secondes

Val loss 0.48362402617931366 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 5/40
time = 13.48 secondes

Train loss 0.33593089957580424 accuracy 0.8701550364494324 macro_avg {'precision': 0.8580553243260549, 'recall': 0.8635550932171708, 'f1-score': 0.860614197418871, 'support': 516} weighted_avg {'precision': 0.8714784450258688, 'recall': 0.8701550387596899, 'f1-score': 0.870649749051436, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6128000020980835 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 6/40
time = 13.47 secondes

Train loss 0.20143165583298964 accuracy 0.9457364082336426 macro_avg {'precision': 0.9389306854457082, 'recall': 0.9447523690327195, 'f1-score': 0.9416855020988053, 'support': 516} weighted_avg {'precision': 0.9463646570620181, 'recall': 0.9457364341085271, 'f1-score': 0.9459151516971914, 'support': 516}
 
time = 0.53 secondes

Val loss 1.2476155459880829 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 7/40
time = 13.57 secondes

Train loss 0.4397757951113762 accuracy 0.8740310072898865 macro_avg {'precision': 0.9029356060606061, 'recall': 0.8319734083188401, 'f1-score': 0.8525370745712189, 'support': 516} weighted_avg {'precision': 0.8866480943152455, 'recall': 0.874031007751938, 'f1-score': 0.8680301634629047, 'support': 516}
 
time = 0.52 secondes

Val loss 0.5385475903749466 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 8/40
time = 13.28 secondes

Train loss 0.17151175213582587 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 0.52 secondes

Val loss 0.8390664011240005 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 9/40
time = 13.54 secondes

Train loss 0.2863450708629733 accuracy 0.9379844665527344 macro_avg {'precision': 0.9285003553660269, 'recall': 0.9409814215821726, 'f1-score': 0.9339181661010438, 'support': 516} weighted_avg {'precision': 0.9403139342049442, 'recall': 0.937984496124031, 'f1-score': 0.9384292509702953, 'support': 516}
 
time = 0.51 secondes

Val loss 0.7605833858251572 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 10/40
time = 13.41 secondes

Train loss 0.20736030724859147 accuracy 0.9496123790740967 macro_avg {'precision': 0.9446143391097519, 'recall': 0.9466378427579929, 'f1-score': 0.945608458744162, 'support': 516} weighted_avg {'precision': 0.9497572745208048, 'recall': 0.9496124031007752, 'f1-score': 0.9496696023058697, 'support': 516}
 
time = 0.55 secondes

Val loss 1.0769395530223846 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 11/40
time = 13.30 secondes

Train loss 0.31045731691163825 accuracy 0.9379844665527344 macro_avg {'precision': 0.9337797011513024, 'recall': 0.9317491019618679, 'f1-score': 0.9327468230694037, 'support': 516} weighted_avg {'precision': 0.9378692962617645, 'recall': 0.937984496124031, 'f1-score': 0.937911750664939, 'support': 516}
 
time = 0.49 secondes

Val loss 1.3525629788637161 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 12/40
time = 12.94 secondes

Train loss 0.29455891224047676 accuracy 0.9321705102920532 macro_avg {'precision': 0.9421950198786357, 'recall': 0.9121873120621556, 'f1-score': 0.9242344787659366, 'support': 516} weighted_avg {'precision': 0.9347810835843507, 'recall': 0.9321705426356589, 'f1-score': 0.9309825091222274, 'support': 516}
 
time = 0.50 secondes

Val loss 0.9173505753278732 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 13/40
time = 13.76 secondes

Train loss 0.13199367951319524 accuracy 0.9670542478561401 macro_avg {'precision': 0.9659180199057098, 'recall': 0.9626237342132211, 'f1-score': 0.9642296447023418, 'support': 516} weighted_avg {'precision': 0.967008199633722, 'recall': 0.9670542635658915, 'f1-score': 0.9669958231756111, 'support': 516}
 
time = 0.51 secondes

Val loss 0.8657416999340057 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 14/40
time = 13.55 secondes

Train loss 0.1525376720890177 accuracy 0.961240291595459 macro_avg {'precision': 0.9554853302106225, 'recall': 0.961526583554118, 'f1-score': 0.9583467872134324, 'support': 516} weighted_avg {'precision': 0.9617715389883098, 'recall': 0.9612403100775194, 'f1-score': 0.9613679654979937, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6200868561863899 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 15/40
time = 13.55 secondes

Train loss 0.07960893896013273 accuracy 0.9825581312179565 macro_avg {'precision': 0.9816715542521994, 'recall': 0.9805519886871576, 'f1-score': 0.9811071287636235, 'support': 516} weighted_avg {'precision': 0.982545825850402, 'recall': 0.9825581395348837, 'f1-score': 0.9825479926064133, 'support': 516}
 
time = 0.52 secondes

Val loss 0.6127921566367149 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 16/40
time = 16.04 secondes

Train loss 0.07586814537926605 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 0.65 secondes

Val loss 0.903137743473053 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 17/40
time = 14.76 secondes

Train loss 0.24415185487349378 accuracy 0.9457364082336426 macro_avg {'precision': 0.9389306854457082, 'recall': 0.9447523690327195, 'f1-score': 0.9416855020988053, 'support': 516} weighted_avg {'precision': 0.9463646570620181, 'recall': 0.9457364341085271, 'f1-score': 0.9459151516971914, 'support': 516}
 
time = 0.54 secondes

Val loss 0.8520849943161011 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 18/40
time = 13.24 secondes

Train loss 0.03562424265934775 accuracy 0.9864341020584106 macro_avg {'precision': 0.9870350969093766, 'recall': 0.9835915023649693, 'f1-score': 0.9852710301715525, 'support': 516} weighted_avg {'precision': 0.9864584729210066, 'recall': 0.9864341085271318, 'f1-score': 0.9864100448370163, 'support': 516}
 
time = 0.56 secondes

Val loss 1.2706108689308167 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 19/40
time = 13.24 secondes

Train loss 0.22447703474476424 accuracy 0.9496123790740967 macro_avg {'precision': 0.9633802816901409, 'recall': 0.9304812834224598, 'f1-score': 0.9436378302077031, 'support': 516} weighted_avg {'precision': 0.9533027623102959, 'recall': 0.9496124031007752, 'f1-score': 0.9486877668197046, 'support': 516}
 
time = 0.52 secondes

Val loss 0.8426170647144318 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 20/40
time = 13.20 secondes

Train loss 0.07092301762190112 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 0.57 secondes

Val loss 1.0390484482049942 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 21/40
time = 13.12 secondes

Train loss 0.0504416465321838 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 0.46 secondes

Val loss 0.9251817613840103 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 22/40
time = 13.23 secondes

Train loss 0.2893706424387567 accuracy 0.9496123790740967 macro_avg {'precision': 0.9391189495765675, 'recall': 0.9593322822359118, 'f1-score': 0.9468319515558866, 'support': 516} weighted_avg {'precision': 0.9549707623471791, 'recall': 0.9496124031007752, 'f1-score': 0.9501779186692271, 'support': 516}
 
time = 0.52 secondes

Val loss 1.0573585331439972 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 23/40
time = 13.18 secondes

Train loss 0.07310590060837002 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 0.49 secondes

Val loss 1.303001031279564 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 24/40
time = 13.34 secondes

Train loss 0.06170430997824014 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 0.54 secondes

Val loss 0.9942512437701225 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 25/40
time = 12.98 secondes

Train loss 0.0008604865940993257 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.49 secondes

Val loss 1.0609540343284607 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 26/40
time = 13.27 secondes

Train loss 0.019813818796661286 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.51 secondes

Val loss 1.146338626742363 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 27/40
time = 13.42 secondes

Train loss 0.1431552643586077 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 0.52 secondes

Val loss 1.5674091279506683 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 28/40
time = 14.13 secondes

Train loss 0.32674938669206866 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 0.51 secondes

Val loss 2.1940599977970123 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 29/40
time = 13.45 secondes

Train loss 0.09784803934003734 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 0.54 secondes

Val loss 1.3344156444072723 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 30/40
time = 13.12 secondes

Train loss 0.23805982006822227 accuracy 0.9670542478561401 macro_avg {'precision': 0.9583333333333333, 'recall': 0.9741641337386018, 'f1-score': 0.9650003391440005, 'support': 516} weighted_avg {'precision': 0.9697997416020671, 'recall': 0.9670542635658915, 'f1-score': 0.9673335972872688, 'support': 516}
 
time = 0.55 secondes

Val loss 1.6953555345535278 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 31/40
time = 13.13 secondes

Train loss 0.12168372087476062 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 0.52 secondes

Val loss 2.198421150445938 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 32/40
time = 13.32 secondes

Train loss 0.151123974892526 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 0.54 secondes

Val loss 1.620317168533802 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 33/40
time = 13.43 secondes

Train loss 0.04401198395344457 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.50 secondes

Val loss 1.4823862463235855 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 34/40
time = 13.42 secondes

Train loss 0.08104049735288066 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 0.95 secondes

Val loss 1.9429218173027039 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 35/40
time = 13.73 secondes

Train loss 9.917388943546085e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.57 secondes

Val loss 1.4550185203552246 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 36/40
time = 13.07 secondes

Train loss 0.011878155841700253 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.51 secondes

Val loss 1.3312679082155228 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 37/40
time = 14.46 secondes

Train loss 0.0294140221506523 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.52 secondes

Val loss 1.6607601046562195 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 38/40
time = 16.18 secondes

Train loss 0.08846560570633631 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 0.49 secondes

Val loss 1.1538966298103333 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 39/40
time = 13.14 secondes

Train loss 7.158964327765827e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.50 secondes

Val loss 1.5835530359327095 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 40/40
time = 13.09 secondes

Train loss 7.010351824150844e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.52 secondes

Val loss 1.656118940032684 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 38 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}

average train time 13.570213985443115

average val time 0.5348111271858216
 
time = 0.57 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_none_3
----------
Epoch 1/40
time = 260.06 secondes

Train loss 1.2659949144257856 accuracy 0.6750147342681885 macro_avg {'precision': 0.7002265204177923, 'recall': 0.6599512011420079, 'f1-score': 0.6543357267689671, 'support': 10182} weighted_avg {'precision': 0.7060168109112518, 'recall': 0.6750147318797879, 'f1-score': 0.6685154539631127, 'support': 10182}
 
time = 8.33 secondes

Val loss 0.6111042325345564 accuracy 0.8268551230430603 macro_avg {'precision': 0.8022611692689219, 'recall': 0.8169783975845227, 'f1-score': 0.8056533077669679, 'support': 1132} weighted_avg {'precision': 0.8102926300328851, 'recall': 0.8268551236749117, 'f1-score': 0.8143868668299515, 'support': 1132}
 
----------
Epoch 2/40
time = 262.80 secondes

Train loss 0.4404214831270874 accuracy 0.8731094598770142 macro_avg {'precision': 0.8637576161635362, 'recall': 0.8629171941029294, 'f1-score': 0.8615394774532726, 'support': 10182} weighted_avg {'precision': 0.8708501356009204, 'recall': 0.8731094087605579, 'f1-score': 0.8705766983588372, 'support': 10182}
 
time = 8.04 secondes

Val loss 0.4460246190428734 accuracy 0.880742073059082 macro_avg {'precision': 0.8819954505374955, 'recall': 0.8820368388783241, 'f1-score': 0.8776946480757658, 'support': 1132} weighted_avg {'precision': 0.8908772587860853, 'recall': 0.8807420494699647, 'f1-score': 0.881080506438127, 'support': 1132}
 
----------
Epoch 3/40
time = 253.61 secondes

Train loss 0.2697056949919373 accuracy 0.9232960343360901 macro_avg {'precision': 0.919712523543591, 'recall': 0.919012377029885, 'f1-score': 0.9190856528558452, 'support': 10182} weighted_avg {'precision': 0.9243486740203457, 'recall': 0.9232960125712041, 'f1-score': 0.9235725635937505, 'support': 10182}
 
time = 8.97 secondes

Val loss 0.442075703227499 accuracy 0.8931095600128174 macro_avg {'precision': 0.8973455956493408, 'recall': 0.891535300639655, 'f1-score': 0.8906848590762436, 'support': 1132} weighted_avg {'precision': 0.895872644891384, 'recall': 0.8931095406360424, 'f1-score': 0.8906225923139864, 'support': 1132}
 
----------
Epoch 4/40
time = 257.98 secondes

Train loss 0.20826978061905238 accuracy 0.9464741945266724 macro_avg {'precision': 0.9443840659684962, 'recall': 0.943777001799387, 'f1-score': 0.944007735446673, 'support': 10182} weighted_avg {'precision': 0.9465879464325556, 'recall': 0.9464741701041053, 'f1-score': 0.9464602105946966, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.4944038733899016 accuracy 0.9010601043701172 macro_avg {'precision': 0.9061795863704853, 'recall': 0.9020401047973593, 'f1-score': 0.901862563952631, 'support': 1132} weighted_avg {'precision': 0.9051698309207161, 'recall': 0.901060070671378, 'f1-score': 0.9008476413875525, 'support': 1132}
 
----------
Epoch 5/40
time = 259.19 secondes

Train loss 0.16901055899349274 accuracy 0.9575722217559814 macro_avg {'precision': 0.9556582993346773, 'recall': 0.955060710081135, 'f1-score': 0.9552626632764006, 'support': 10182} weighted_avg {'precision': 0.957489962983447, 'recall': 0.9575721862109605, 'f1-score': 0.9574355728397209, 'support': 10182}
 
time = 8.07 secondes

Val loss 0.5002034631538087 accuracy 0.9116607904434204 macro_avg {'precision': 0.9131141746285065, 'recall': 0.9126078156821759, 'f1-score': 0.9110088369391294, 'support': 1132} weighted_avg {'precision': 0.9154308359417052, 'recall': 0.911660777385159, 'f1-score': 0.9116983073618856, 'support': 1132}
 
----------
Epoch 6/40
time = 257.37 secondes

Train loss 0.16113441723340016 accuracy 0.963268518447876 macro_avg {'precision': 0.9621009007378646, 'recall': 0.9618554527694775, 'f1-score': 0.9619204859440634, 'support': 10182} weighted_avg {'precision': 0.9633443202877362, 'recall': 0.9632685130622668, 'f1-score': 0.9632480415792145, 'support': 10182}
 
time = 8.17 secondes

Val loss 0.512567001717939 accuracy 0.9028268456459045 macro_avg {'precision': 0.9118905905131548, 'recall': 0.8982870888848156, 'f1-score': 0.8997223661820977, 'support': 1132} weighted_avg {'precision': 0.912248844950755, 'recall': 0.9028268551236749, 'f1-score': 0.9032427426921459, 'support': 1132}
 
----------
Epoch 7/40
time = 256.35 secondes

Train loss 0.14859936248402886 accuracy 0.967197060585022 macro_avg {'precision': 0.9660522272589536, 'recall': 0.9658570289403077, 'f1-score': 0.9659166913539536, 'support': 10182} weighted_avg {'precision': 0.9671438749005491, 'recall': 0.9671970143390297, 'f1-score': 0.9671316933914456, 'support': 10182}
 
time = 7.81 secondes

Val loss 0.6269365223173813 accuracy 0.8904593586921692 macro_avg {'precision': 0.8944260689318669, 'recall': 0.8873388498481116, 'f1-score': 0.8860327813883362, 'support': 1132} weighted_avg {'precision': 0.894900065737936, 'recall': 0.8904593639575972, 'f1-score': 0.887426521017309, 'support': 1132}
 
----------
Epoch 8/40
time = 257.92 secondes

Train loss 0.12891849342690126 accuracy 0.9722058773040771 macro_avg {'precision': 0.971663068165473, 'recall': 0.971203149364784, 'f1-score': 0.971407104287966, 'support': 10182} weighted_avg {'precision': 0.9722032013319628, 'recall': 0.9722058534669024, 'f1-score': 0.972180926707567, 'support': 10182}
 
time = 7.75 secondes

Val loss 0.6418736745409903 accuracy 0.898409903049469 macro_avg {'precision': 0.9046195423720718, 'recall': 0.8983652623145618, 'f1-score': 0.8981536972086644, 'support': 1132} weighted_avg {'precision': 0.9057715992766118, 'recall': 0.8984098939929329, 'f1-score': 0.8988538265923242, 'support': 1132}
 
----------
Epoch 9/40
time = 256.96 secondes

Train loss 0.1333552235606316 accuracy 0.9740719199180603 macro_avg {'precision': 0.9726692490339259, 'recall': 0.9732349855835194, 'f1-score': 0.9728651090580269, 'support': 10182} weighted_avg {'precision': 0.9743065640779935, 'recall': 0.9740718915733647, 'f1-score': 0.9741186176666925, 'support': 10182}
 
time = 7.73 secondes

Val loss 0.6705639833427841 accuracy 0.8939929604530334 macro_avg {'precision': 0.9035744493002339, 'recall': 0.9017497328407111, 'f1-score': 0.8968590243743018, 'support': 1132} weighted_avg {'precision': 0.9065523279432738, 'recall': 0.8939929328621908, 'f1-score': 0.8937755854848933, 'support': 1132}
 
----------
Epoch 10/40
time = 253.62 secondes

Train loss 0.13018236681017123 accuracy 0.9728933572769165 macro_avg {'precision': 0.9716192881440641, 'recall': 0.971732744364247, 'f1-score': 0.9716191358413024, 'support': 10182} weighted_avg {'precision': 0.9730590970630868, 'recall': 0.9728933411903359, 'f1-score': 0.9729214510533107, 'support': 10182}
 
time = 8.06 secondes

Val loss 0.6268086266881396 accuracy 0.9125441908836365 macro_avg {'precision': 0.9180278883778727, 'recall': 0.9162070291011888, 'f1-score': 0.9145971273366825, 'support': 1132} weighted_avg {'precision': 0.918805268901962, 'recall': 0.9125441696113075, 'f1-score': 0.9130691268368488, 'support': 1132}
 
----------
Epoch 11/40
time = 258.67 secondes

Train loss 0.10755945441929066 accuracy 0.9787861108779907 macro_avg {'precision': 0.9778794355552984, 'recall': 0.9780785111491624, 'f1-score': 0.9779402616515268, 'support': 10182} weighted_avg {'precision': 0.9788607006339489, 'recall': 0.9787860931054803, 'f1-score': 0.9787907224234692, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.6888472869423297 accuracy 0.9045936465263367 macro_avg {'precision': 0.9102879988193704, 'recall': 0.9073346451399014, 'f1-score': 0.9063333069905019, 'support': 1132} weighted_avg {'precision': 0.9092877360446516, 'recall': 0.9045936395759717, 'f1-score': 0.9043193453556815, 'support': 1132}
 
----------
Epoch 12/40
time = 256.85 secondes

Train loss 0.11656957026550475 accuracy 0.9768218994140625 macro_avg {'precision': 0.9761904611407273, 'recall': 0.9763157973034036, 'f1-score': 0.9761563535075704, 'support': 10182} weighted_avg {'precision': 0.9770093879820909, 'recall': 0.9768218424670988, 'f1-score': 0.9768216841671626, 'support': 10182}
 
time = 8.46 secondes

Val loss 0.760490786573197 accuracy 0.8992933034896851 macro_avg {'precision': 0.9047567971564927, 'recall': 0.9024595195729226, 'f1-score': 0.8999874185018868, 'support': 1132} weighted_avg {'precision': 0.9057515897983727, 'recall': 0.8992932862190812, 'f1-score': 0.8987814649698487, 'support': 1132}
 
----------
Epoch 13/40
time = 258.11 secondes

Train loss 0.10340852985710759 accuracy 0.9809467792510986 macro_avg {'precision': 0.9805338283230285, 'recall': 0.9805118114290284, 'f1-score': 0.9805014688255648, 'support': 10182} weighted_avg {'precision': 0.9809844696101133, 'recall': 0.9809467688076998, 'f1-score': 0.9809437065349105, 'support': 10182}
 
time = 7.61 secondes

Val loss 0.6450443269441423 accuracy 0.9063604474067688 macro_avg {'precision': 0.9122029839528938, 'recall': 0.908793651169626, 'f1-score': 0.9089243496695119, 'support': 1132} weighted_avg {'precision': 0.911332891147861, 'recall': 0.9063604240282686, 'f1-score': 0.9071459914930755, 'support': 1132}
 
----------
Epoch 14/40
time = 258.66 secondes

Train loss 0.11028491746858303 accuracy 0.9792771935462952 macro_avg {'precision': 0.977809286963567, 'recall': 0.978411662191062, 'f1-score': 0.9780441286876732, 'support': 10182} weighted_avg {'precision': 0.9794864981049174, 'recall': 0.9792771557650756, 'f1-score': 0.9793220858998637, 'support': 10182}
 
time = 8.10 secondes

Val loss 0.647263699179412 accuracy 0.9143109321594238 macro_avg {'precision': 0.9163212261203517, 'recall': 0.916918715640396, 'f1-score': 0.914934733298385, 'support': 1132} weighted_avg {'precision': 0.9178337823357162, 'recall': 0.9143109540636042, 'f1-score': 0.9143234780961169, 'support': 1132}
 
----------
Epoch 15/40
time = 260.20 secondes

Train loss 0.09386888758270794 accuracy 0.9828128218650818 macro_avg {'precision': 0.9824537237408544, 'recall': 0.9824889631891777, 'f1-score': 0.9824546913507332, 'support': 10182} weighted_avg {'precision': 0.9827993133335863, 'recall': 0.9828128069141623, 'f1-score': 0.982788945666153, 'support': 10182}
 
time = 8.07 secondes

Val loss 0.6382111621642252 accuracy 0.9196113348007202 macro_avg {'precision': 0.9251191885265315, 'recall': 0.9220303230055492, 'f1-score': 0.9221125441324999, 'support': 1132} weighted_avg {'precision': 0.923713957475294, 'recall': 0.9196113074204947, 'f1-score': 0.920146533842659, 'support': 1132}
 
----------
Epoch 16/40
time = 258.64 secondes

Train loss 0.09053628340232284 accuracy 0.9821253418922424 macro_avg {'precision': 0.9820765139067156, 'recall': 0.9813309973894612, 'f1-score': 0.9816537571532109, 'support': 10182} weighted_avg {'precision': 0.9821907627815353, 'recall': 0.9821253191907288, 'f1-score': 0.9821120783811385, 'support': 10182}
 
time = 7.38 secondes

Val loss 0.6301010642414888 accuracy 0.9178445339202881 macro_avg {'precision': 0.9221307424013687, 'recall': 0.9204161022129849, 'f1-score': 0.9199195584122236, 'support': 1132} weighted_avg {'precision': 0.921152565603949, 'recall': 0.9178445229681979, 'f1-score': 0.9180501169764747, 'support': 1132}
 
----------
Epoch 17/40
time = 259.18 secondes

Train loss 0.07713236728980503 accuracy 0.9851699471473694 macro_avg {'precision': 0.9846678497989634, 'recall': 0.9847574906490604, 'f1-score': 0.9846838783889783, 'support': 10182} weighted_avg {'precision': 0.9852570165504981, 'recall': 0.98516990768022, 'f1-score': 0.9851841668133543, 'support': 10182}
 
time = 8.14 secondes

Val loss 0.7765525391146633 accuracy 0.8939929604530334 macro_avg {'precision': 0.8965243522793391, 'recall': 0.896657250324078, 'f1-score': 0.8928356723271076, 'support': 1132} weighted_avg {'precision': 0.9036972545684324, 'recall': 0.8939929328621908, 'f1-score': 0.8954748953062336, 'support': 1132}
 
----------
Epoch 18/40
time = 254.78 secondes

Train loss 0.0970058263304695 accuracy 0.9832056760787964 macro_avg {'precision': 0.9825664064508359, 'recall': 0.9826081908471751, 'f1-score': 0.9825645545443733, 'support': 10182} weighted_avg {'precision': 0.9832467645196878, 'recall': 0.9832056570418385, 'f1-score': 0.9832029782298302, 'support': 10182}
 
time = 8.45 secondes

Val loss 0.7377340256634725 accuracy 0.9107773900032043 macro_avg {'precision': 0.9177187605442988, 'recall': 0.9116138240557723, 'f1-score': 0.9129934563112512, 'support': 1132} weighted_avg {'precision': 0.9135149492939426, 'recall': 0.9107773851590106, 'f1-score': 0.9105268369804648, 'support': 1132}
 
----------
Epoch 19/40
time = 261.27 secondes

Train loss 0.08271535767692668 accuracy 0.9859556555747986 macro_avg {'precision': 0.9853241372674578, 'recall': 0.9853688981334852, 'f1-score': 0.9853380878526078, 'support': 10182} weighted_avg {'precision': 0.9859771675299287, 'recall': 0.9859556079355726, 'f1-score': 0.9859579000754191, 'support': 10182}
 
time = 8.50 secondes

Val loss 0.6806028150650222 accuracy 0.916961133480072 macro_avg {'precision': 0.9177326044654903, 'recall': 0.9200951230118655, 'f1-score': 0.9174059782387085, 'support': 1132} weighted_avg {'precision': 0.9197390255715125, 'recall': 0.9169611307420494, 'f1-score': 0.9169801824035861, 'support': 1132}
 
----------
Epoch 20/40
time = 254.65 secondes

Train loss 0.07442292542208415 accuracy 0.9869377613067627 macro_avg {'precision': 0.9866306939361082, 'recall': 0.9868322468593357, 'f1-score': 0.9866932197576854, 'support': 10182} weighted_avg {'precision': 0.9869944916591744, 'recall': 0.9869377332547633, 'f1-score': 0.9869278792099139, 'support': 10182}
 
time = 7.96 secondes

Val loss 0.7822625789693787 accuracy 0.9098939895629883 macro_avg {'precision': 0.9132379211649283, 'recall': 0.9152431494685477, 'f1-score': 0.9122660583103054, 'support': 1132} weighted_avg {'precision': 0.9136617725409046, 'recall': 0.9098939929328622, 'f1-score': 0.9097870798127459, 'support': 1132}
 
----------
Epoch 21/40
time = 258.98 secondes

Train loss 0.09461846194062959 accuracy 0.9848753213882446 macro_avg {'precision': 0.9847680968017467, 'recall': 0.9843498823761647, 'f1-score': 0.9845293836864331, 'support': 10182} weighted_avg {'precision': 0.9849735125593946, 'recall': 0.9848752700844627, 'f1-score': 0.984894845775657, 'support': 10182}
 
time = 8.36 secondes

Val loss 0.8240042549160778 accuracy 0.9054770469665527 macro_avg {'precision': 0.9143788416889089, 'recall': 0.9090744623313846, 'f1-score': 0.9077709195469426, 'support': 1132} weighted_avg {'precision': 0.9148698793360819, 'recall': 0.9054770318021201, 'f1-score': 0.9061163373614001, 'support': 1132}
 
----------
Epoch 22/40
time = 257.15 secondes

Train loss 0.060434679856241146 accuracy 0.9891966581344604 macro_avg {'precision': 0.9890151742423179, 'recall': 0.9889710882373739, 'f1-score': 0.9889837246212348, 'support': 10182} weighted_avg {'precision': 0.9892040410736542, 'recall': 0.989196621488902, 'f1-score': 0.9891911514105662, 'support': 10182}
 
time = 7.50 secondes

Val loss 0.7329772176160756 accuracy 0.9081271886825562 macro_avg {'precision': 0.9161079154412366, 'recall': 0.9116647254873067, 'f1-score': 0.9107431546940568, 'support': 1132} weighted_avg {'precision': 0.9158922635353538, 'recall': 0.9081272084805654, 'f1-score': 0.9088842988045038, 'support': 1132}
 
----------
Epoch 23/40
time = 259.90 secondes

Train loss 0.061806725486122004 accuracy 0.9885091781616211 macro_avg {'precision': 0.9879214767136129, 'recall': 0.9881094133837592, 'f1-score': 0.98800531893667, 'support': 10182} weighted_avg {'precision': 0.988547941809696, 'recall': 0.9885091337654685, 'f1-score': 0.988519294737762, 'support': 10182}
 
time = 8.26 secondes

Val loss 0.5935228968359502 accuracy 0.9240282773971558 macro_avg {'precision': 0.9267889174959896, 'recall': 0.9238547221867307, 'f1-score': 0.9236568815730953, 'support': 1132} weighted_avg {'precision': 0.9263643048609568, 'recall': 0.9240282685512368, 'f1-score': 0.9236635773547192, 'support': 1132}
 
----------
Epoch 24/40
time = 258.34 secondes

Train loss 0.04858694981630776 accuracy 0.9912590980529785 macro_avg {'precision': 0.9911130107101096, 'recall': 0.9909007643623442, 'f1-score': 0.9909940759127751, 'support': 10182} weighted_avg {'precision': 0.9912769909077824, 'recall': 0.9912590846592025, 'f1-score': 0.9912552374335404, 'support': 10182}
 
time = 8.19 secondes

Val loss 0.6813963599038096 accuracy 0.9204947352409363 macro_avg {'precision': 0.9231559977422592, 'recall': 0.9223631069721112, 'f1-score': 0.9209270551767391, 'support': 1132} weighted_avg {'precision': 0.9238092118287814, 'recall': 0.9204946996466431, 'f1-score': 0.9202747466533902, 'support': 1132}
 
----------
Epoch 25/40
time = 258.21 secondes

Train loss 0.06904527577132843 accuracy 0.9891966581344604 macro_avg {'precision': 0.9891703182005586, 'recall': 0.9891349206718388, 'f1-score': 0.9891382400996827, 'support': 10182} weighted_avg {'precision': 0.9891966753077074, 'recall': 0.989196621488902, 'f1-score': 0.9891820058302261, 'support': 10182}
 
time = 7.98 secondes

Val loss 0.6970557481437655 accuracy 0.9151943325996399 macro_avg {'precision': 0.9203740314030233, 'recall': 0.9192685792553705, 'f1-score': 0.9176450327884418, 'support': 1132} weighted_avg {'precision': 0.9192350025751939, 'recall': 0.9151943462897526, 'f1-score': 0.9148553040203846, 'support': 1132}
 
----------
Epoch 26/40
time = 259.56 secondes

Train loss 0.04173661090419982 accuracy 0.9925358891487122 macro_avg {'precision': 0.9927135425732084, 'recall': 0.9926633763385077, 'f1-score': 0.9926847222129991, 'support': 10182} weighted_avg {'precision': 0.9925519456937855, 'recall': 0.9925358475741505, 'f1-score': 0.992540101590665, 'support': 10182}
 
time = 8.00 secondes

Val loss 0.7148791115547974 accuracy 0.9143109321594238 macro_avg {'precision': 0.9189477058393966, 'recall': 0.9181570998488384, 'f1-score': 0.9158203417063604, 'support': 1132} weighted_avg {'precision': 0.919506611847223, 'recall': 0.9143109540636042, 'f1-score': 0.9140594233352397, 'support': 1132}
 
----------
Epoch 27/40
time = 257.65 secondes

Train loss 0.04015692311531179 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934616227539486, 'recall': 0.9934106615147374, 'f1-score': 0.9934291791562242, 'support': 10182} weighted_avg {'precision': 0.9935315492655328, 'recall': 0.9935179728933412, 'f1-score': 0.9935181657137633, 'support': 10182}
 
time = 8.04 secondes

Val loss 0.7415357438107427 accuracy 0.9107773900032043 macro_avg {'precision': 0.9172518241826682, 'recall': 0.9126465447191873, 'f1-score': 0.9134647380025204, 'support': 1132} weighted_avg {'precision': 0.9134202435013411, 'recall': 0.9107773851590106, 'f1-score': 0.9105282496272132, 'support': 1132}
 
----------
Epoch 28/40
time = 255.53 secondes

Train loss 0.04828687373960883 accuracy 0.9920448064804077 macro_avg {'precision': 0.9916411285548549, 'recall': 0.9915832042342989, 'f1-score': 0.9916043234087928, 'support': 10182} weighted_avg {'precision': 0.9920569373724618, 'recall': 0.9920447849145551, 'f1-score': 0.9920428016241328, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.7874130110441244 accuracy 0.9098939895629883 macro_avg {'precision': 0.9189959711442667, 'recall': 0.9138985574556309, 'f1-score': 0.9140357899419549, 'support': 1132} weighted_avg {'precision': 0.915813142223606, 'recall': 0.9098939929328622, 'f1-score': 0.9102349436688547, 'support': 1132}
 
----------
Epoch 29/40
time = 259.11 secondes

Train loss 0.0478906546146502 accuracy 0.9928305149078369 macro_avg {'precision': 0.9924638592612949, 'recall': 0.9924965782885057, 'f1-score': 0.9924692695840319, 'support': 10182} weighted_avg {'precision': 0.9928560249708613, 'recall': 0.9928304851699077, 'f1-score': 0.9928331317569971, 'support': 10182}
 
time = 7.80 secondes

Val loss 0.7166468380233249 accuracy 0.916077733039856 macro_avg {'precision': 0.9194062191189843, 'recall': 0.918401807099406, 'f1-score': 0.9177972270543107, 'support': 1132} weighted_avg {'precision': 0.9194164259941883, 'recall': 0.916077738515901, 'f1-score': 0.9165864426856346, 'support': 1132}
 
----------
Epoch 30/40
time = 256.91 secondes

Train loss 0.04758378635633163 accuracy 0.9925358891487122 macro_avg {'precision': 0.9915262217729393, 'recall': 0.9921879108683924, 'f1-score': 0.9918056707554614, 'support': 10182} weighted_avg {'precision': 0.9926604205934594, 'recall': 0.9925358475741505, 'f1-score': 0.992558214995881, 'support': 10182}
 
time = 8.07 secondes

Val loss 0.7198880964491072 accuracy 0.916961133480072 macro_avg {'precision': 0.9193857858018347, 'recall': 0.9149477352602144, 'f1-score': 0.9163454784306804, 'support': 1132} weighted_avg {'precision': 0.9192752947527959, 'recall': 0.9169611307420494, 'f1-score': 0.9173247348180524, 'support': 1132}
 
----------
Epoch 31/40
time = 257.75 secondes

Train loss 0.029092128475706684 accuracy 0.9955804944038391 macro_avg {'precision': 0.9954854913132332, 'recall': 0.9950923963379831, 'f1-score': 0.9952753439707577, 'support': 10182} weighted_avg {'precision': 0.9955982538617156, 'recall': 0.9955804360636418, 'f1-score': 0.9955775966644003, 'support': 10182}
 
time = 7.91 secondes

Val loss 0.7233551261836599 accuracy 0.9204947352409363 macro_avg {'precision': 0.921851882936671, 'recall': 0.9233354377652964, 'f1-score': 0.9213262140581848, 'support': 1132} weighted_avg {'precision': 0.9236417080199384, 'recall': 0.9204946996466431, 'f1-score': 0.9207625252633836, 'support': 1132}
 
----------
Epoch 32/40
time = 259.22 secondes

Train loss 0.03217315968328221 accuracy 0.995776891708374 macro_avg {'precision': 0.9958031758650057, 'recall': 0.9956934840456284, 'f1-score': 0.9957435011581636, 'support': 10182} weighted_avg {'precision': 0.9957839857277595, 'recall': 0.9957768611274799, 'f1-score': 0.9957755354842287, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.748638830044078 accuracy 0.9213780760765076 macro_avg {'precision': 0.9262508152780418, 'recall': 0.9240649873781654, 'f1-score': 0.9228116111078334, 'support': 1132} weighted_avg {'precision': 0.9256943907041386, 'recall': 0.9213780918727915, 'f1-score': 0.9209103028189312, 'support': 1132}
 
----------
Epoch 33/40
time = 257.25 secondes

Train loss 0.035063582293482644 accuracy 0.9942054748535156 macro_avg {'precision': 0.9941177289862088, 'recall': 0.9939497912657543, 'f1-score': 0.9940219074861656, 'support': 10182} weighted_avg {'precision': 0.9942278105332507, 'recall': 0.9942054606167747, 'f1-score': 0.9942047307776893, 'support': 10182}
 
time = 8.14 secondes

Val loss 0.6715922836542951 accuracy 0.9151943325996399 macro_avg {'precision': 0.9165654120775798, 'recall': 0.9180484137468768, 'f1-score': 0.916348290739941, 'support': 1132} weighted_avg {'precision': 0.9176674548096718, 'recall': 0.9151943462897526, 'f1-score': 0.9154264513830117, 'support': 1132}
 
----------
Epoch 34/40
time = 257.80 secondes

Train loss 0.01977979856443995 accuracy 0.9966608285903931 macro_avg {'precision': 0.9965266980066986, 'recall': 0.9966684333497954, 'f1-score': 0.9965946139720903, 'support': 10182} weighted_avg {'precision': 0.9966682178429987, 'recall': 0.9966607739147515, 'f1-score': 0.9966617042145769, 'support': 10182}
 
time = 8.13 secondes

Val loss 0.6521902180762661 accuracy 0.9302120208740234 macro_avg {'precision': 0.9342238276477394, 'recall': 0.9318988030940879, 'f1-score': 0.9318550288024889, 'support': 1132} weighted_avg {'precision': 0.932326548647029, 'recall': 0.9302120141342756, 'f1-score': 0.9300206851516104, 'support': 1132}
 
----------
Epoch 35/40
time = 258.63 secondes

Train loss 0.026343784945860895 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961394784720508, 'recall': 0.9961028067582642, 'f1-score': 0.9961151357110423, 'support': 10182} weighted_avg {'precision': 0.9960852043575419, 'recall': 0.9960714987232371, 'f1-score': 0.9960721530613005, 'support': 10182}
 
time = 7.89 secondes

Val loss 0.7359033634809902 accuracy 0.916961133480072 macro_avg {'precision': 0.9190642285693718, 'recall': 0.9187761801731759, 'f1-score': 0.918094717183086, 'support': 1132} weighted_avg {'precision': 0.9184585896070031, 'recall': 0.9169611307420494, 'f1-score': 0.9168978132081572, 'support': 1132}
 
----------
Epoch 36/40
time = 259.61 secondes

Train loss 0.016156696034581437 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974496135306323, 'recall': 0.9974923035688865, 'f1-score': 0.9974692843829276, 'support': 10182} weighted_avg {'precision': 0.9975472124549031, 'recall': 0.9975446867020232, 'f1-score': 0.9975442503754889, 'support': 10182}
 
time = 7.78 secondes

Val loss 0.6914482877834327 accuracy 0.9134275913238525 macro_avg {'precision': 0.9202275530889137, 'recall': 0.9163603681423703, 'f1-score': 0.9165098635847911, 'support': 1132} weighted_avg {'precision': 0.9199132680002009, 'recall': 0.9134275618374559, 'f1-score': 0.9147941988647518, 'support': 1132}
 
----------
Epoch 37/40
time = 252.63 secondes

Train loss 0.008723127517111937 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981983656226271, 'recall': 0.9981226478949358, 'f1-score': 0.9981587878505052, 'support': 10182} weighted_avg {'precision': 0.9981369444305759, 'recall': 0.9981339618935376, 'f1-score': 0.9981337378781618, 'support': 10182}
 
time = 7.72 secondes

Val loss 0.7117294711627271 accuracy 0.9249116778373718 macro_avg {'precision': 0.9293170082105426, 'recall': 0.9284092606939621, 'f1-score': 0.9280443311794377, 'support': 1132} weighted_avg {'precision': 0.9275085437093282, 'recall': 0.9249116607773852, 'f1-score': 0.9253488940373712, 'support': 1132}
 
----------
Epoch 38/40
time = 259.45 secondes

Train loss 0.011702215526769453 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982868917490881, 'recall': 0.998242461512431, 'f1-score': 0.9982639111682156, 'support': 10182} weighted_avg {'precision': 0.9982342046032886, 'recall': 0.9982321744254566, 'f1-score': 0.9982324290378973, 'support': 10182}
 
time = 8.34 secondes

Val loss 0.7140264481668952 accuracy 0.9196113348007202 macro_avg {'precision': 0.9255713626547161, 'recall': 0.9225185449255102, 'f1-score': 0.9216710629159796, 'support': 1132} weighted_avg {'precision': 0.9245432593049874, 'recall': 0.9196113074204947, 'f1-score': 0.9196130694282669, 'support': 1132}
 
----------
Epoch 39/40
time = 256.45 secondes

Train loss 0.005198198101863406 accuracy 0.998821496963501 macro_avg {'precision': 0.9988587322145819, 'recall': 0.9988677255495666, 'f1-score': 0.9988624141757676, 'support': 10182} weighted_avg {'precision': 0.9988227773460361, 'recall': 0.9988214496169712, 'f1-score': 0.9988212736073121, 'support': 10182}
 
time = 8.02 secondes

Val loss 0.6751455920032602 accuracy 0.9275618195533752 macro_avg {'precision': 0.9301828203605697, 'recall': 0.9290072203002963, 'f1-score': 0.9283667050843448, 'support': 1132} weighted_avg {'precision': 0.9295727150814486, 'recall': 0.9275618374558304, 'f1-score': 0.927364900803912, 'support': 1132}
 
----------
Epoch 40/40
time = 256.65 secondes

Train loss 0.003639413204677272 accuracy 0.9992143511772156 macro_avg {'precision': 0.9991889197049965, 'recall': 0.9992384898039223, 'f1-score': 0.9992128240456098, 'support': 10182} weighted_avg {'precision': 0.9992157071750573, 'recall': 0.9992142997446474, 'f1-score': 0.9992141357357731, 'support': 10182}
 
time = 7.89 secondes

Val loss 0.703526263823041 accuracy 0.9275618195533752 macro_avg {'precision': 0.9313864790608044, 'recall': 0.9298281171197266, 'f1-score': 0.9289100671029343, 'support': 1132} weighted_avg {'precision': 0.9303912177809286, 'recall': 0.9275618374558304, 'f1-score': 0.9271764811524723, 'support': 1132}
 
----------
best_accuracy 0.9302120208740234 best_epoch 34 macro_avg {'precision': 0.9342238276477394, 'recall': 0.9318988030940879, 'f1-score': 0.9318550288024889, 'support': 1132} weighted_avg {'precision': 0.932326548647029, 'recall': 0.9302120141342756, 'f1-score': 0.9300206851516104, 'support': 1132}

average train time 257.8399275004864

average val time 8.034403455257415
 
time = 52.78 secondes

test_accuracy 0.8538236618041992 macro_avg {'precision': 0.8509924087261025, 'recall': 0.8465682943628098, 'f1-score': 0.8475709385549285, 'support': 7532} weighted_avg {'precision': 0.8582965764754048, 'recall': 0.8538236856080722, 'f1-score': 0.8548521146286505, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_3
----------
Epoch 1/40
time = 263.89 secondes

Train loss 1.2933818680618772 accuracy 0.6702023148536682 macro_avg {'precision': 0.6793476662413932, 'recall': 0.6547285400856796, 'f1-score': 0.647946530891119, 'support': 10182} weighted_avg {'precision': 0.6847574921217217, 'recall': 0.6702023178157533, 'f1-score': 0.661686975430907, 'support': 10182}
 
time = 8.26 secondes

Val loss 0.6372512994517743 accuracy 0.8321554660797119 macro_avg {'precision': 0.800833254345051, 'recall': 0.8176214385648406, 'f1-score': 0.8036822352330368, 'support': 1132} weighted_avg {'precision': 0.8103431092600338, 'recall': 0.8321554770318021, 'f1-score': 0.8162393875084422, 'support': 1132}
 
----------
Epoch 2/40
time = 255.12 secondes

Train loss 0.4695152107515084 accuracy 0.8635827898979187 macro_avg {'precision': 0.8532059437285188, 'recall': 0.8521427675949237, 'f1-score': 0.8499622817518713, 'support': 10182} weighted_avg {'precision': 0.8605407083301327, 'recall': 0.8635827931644078, 'f1-score': 0.8600861680545347, 'support': 10182}
 
time = 8.03 secondes

Val loss 0.45183628482717864 accuracy 0.8772084712982178 macro_avg {'precision': 0.8775728823004986, 'recall': 0.8751285326371491, 'f1-score': 0.8738112306693567, 'support': 1132} weighted_avg {'precision': 0.8838681416791037, 'recall': 0.877208480565371, 'f1-score': 0.8780279747357639, 'support': 1132}
 
----------
Epoch 3/40
time = 255.02 secondes

Train loss 0.2734684380125167 accuracy 0.9261441826820374 macro_avg {'precision': 0.9216666273430791, 'recall': 0.9205814729527351, 'f1-score': 0.9209140293720248, 'support': 10182} weighted_avg {'precision': 0.9259958770535526, 'recall': 0.9261441759968572, 'f1-score': 0.9258822044748084, 'support': 10182}
 
time = 8.32 secondes

Val loss 0.5175911753084248 accuracy 0.8727915287017822 macro_avg {'precision': 0.8707314384152636, 'recall': 0.8737937118066077, 'f1-score': 0.867115964999462, 'support': 1132} weighted_avg {'precision': 0.8804522911141522, 'recall': 0.872791519434629, 'f1-score': 0.8708470252380478, 'support': 1132}
 
----------
Epoch 4/40
time = 263.09 secondes

Train loss 0.20358406458988645 accuracy 0.945786714553833 macro_avg {'precision': 0.9432068404733611, 'recall': 0.942884376949445, 'f1-score': 0.9429260903154557, 'support': 10182} weighted_avg {'precision': 0.9461327754270993, 'recall': 0.9457866823806718, 'f1-score': 0.9458526407405753, 'support': 10182}
 
time = 7.46 secondes

Val loss 0.5158248927057262 accuracy 0.8886925578117371 macro_avg {'precision': 0.8958870517781847, 'recall': 0.8910791179766505, 'f1-score': 0.8897337641970944, 'support': 1132} weighted_avg {'precision': 0.8992533938209165, 'recall': 0.8886925795053003, 'f1-score': 0.8898195747625824, 'support': 1132}
 
----------
Epoch 5/40
time = 251.60 secondes

Train loss 0.17589894120487878 accuracy 0.9576704502105713 macro_avg {'precision': 0.9552027422610655, 'recall': 0.9551873657061332, 'f1-score': 0.9551219226703411, 'support': 10182} weighted_avg {'precision': 0.9578787030457253, 'recall': 0.9576703987428796, 'f1-score': 0.9577091421425679, 'support': 10182}
 
time = 7.45 secondes

Val loss 0.5192412898849539 accuracy 0.9019434452056885 macro_avg {'precision': 0.9030970353667701, 'recall': 0.903448955865327, 'f1-score': 0.9016896517209319, 'support': 1132} weighted_avg {'precision': 0.9041863395548484, 'recall': 0.9019434628975265, 'f1-score': 0.9013585651008623, 'support': 1132}
 
----------
Epoch 6/40
time = 251.37 secondes

Train loss 0.15396301500759493 accuracy 0.9654292464256287 macro_avg {'precision': 0.9644342683809495, 'recall': 0.9641561859528631, 'f1-score': 0.9642514472821748, 'support': 10182} weighted_avg {'precision': 0.9654989455927063, 'recall': 0.9654291887644864, 'f1-score': 0.9654223692527295, 'support': 10182}
 
time = 7.55 secondes

Val loss 0.5834938504169105 accuracy 0.8966431021690369 macro_avg {'precision': 0.9015890013380498, 'recall': 0.898520993900847, 'f1-score': 0.8959459402423267, 'support': 1132} weighted_avg {'precision': 0.9020870949921642, 'recall': 0.8966431095406361, 'f1-score': 0.8950919592680741, 'support': 1132}
 
----------
Epoch 7/40
time = 251.74 secondes

Train loss 0.15037396456653346 accuracy 0.9656256437301636 macro_avg {'precision': 0.9649187330423828, 'recall': 0.9649863410578078, 'f1-score': 0.9648865127721814, 'support': 10182} weighted_avg {'precision': 0.9656851621789014, 'recall': 0.9656256138283245, 'f1-score': 0.9655881789438698, 'support': 10182}
 
time = 7.48 secondes

Val loss 0.6322576866581918 accuracy 0.8939929604530334 macro_avg {'precision': 0.8975119546937634, 'recall': 0.8966216940826632, 'f1-score': 0.8935225943553938, 'support': 1132} weighted_avg {'precision': 0.9003341212512675, 'recall': 0.8939929328621908, 'f1-score': 0.8934898218916532, 'support': 1132}
 
----------
Epoch 8/40
time = 250.80 secondes

Train loss 0.13956931294661176 accuracy 0.9694559574127197 macro_avg {'precision': 0.968657575683252, 'recall': 0.9689616312052189, 'f1-score': 0.9687642954849093, 'support': 10182} weighted_avg {'precision': 0.9696463548244085, 'recall': 0.9694559025731684, 'f1-score': 0.9695098348690172, 'support': 10182}
 
time = 7.46 secondes

Val loss 0.5518116949570471 accuracy 0.9001767039299011 macro_avg {'precision': 0.9050344865291822, 'recall': 0.9036064277044951, 'f1-score': 0.9016635008438841, 'support': 1132} weighted_avg {'precision': 0.9073964581964429, 'recall': 0.9001766784452296, 'f1-score': 0.901058686979021, 'support': 1132}
 
----------
Epoch 9/40
time = 246.08 secondes

Train loss 0.1420352717733056 accuracy 0.9710273146629333 macro_avg {'precision': 0.9705051258571181, 'recall': 0.9704388289398128, 'f1-score': 0.9704257860105354, 'support': 10182} weighted_avg {'precision': 0.9710360741974731, 'recall': 0.9710273030838735, 'f1-score': 0.9709843296286866, 'support': 10182}
 
time = 7.48 secondes

Val loss 0.7953844499425031 accuracy 0.8833922147750854 macro_avg {'precision': 0.8917703806020716, 'recall': 0.8849607883922008, 'f1-score': 0.8832545945309714, 'support': 1132} weighted_avg {'precision': 0.8954424605802199, 'recall': 0.8833922261484098, 'f1-score': 0.8846710682680551, 'support': 1132}
 
----------
Epoch 10/40
time = 249.40 secondes

Train loss 0.14615075436786798 accuracy 0.9718130230903625 macro_avg {'precision': 0.9710564342393002, 'recall': 0.9711828989297313, 'f1-score': 0.9710961664319664, 'support': 10182} weighted_avg {'precision': 0.9718325154547176, 'recall': 0.971813003339226, 'f1-score': 0.9717990530186408, 'support': 10182}
 
time = 7.54 secondes

Val loss 0.698992137655347 accuracy 0.8931095600128174 macro_avg {'precision': 0.9071228073767683, 'recall': 0.8892846618215096, 'f1-score': 0.8932915575485305, 'support': 1132} weighted_avg {'precision': 0.9056167645185086, 'recall': 0.8931095406360424, 'f1-score': 0.894520666916714, 'support': 1132}
 
----------
Epoch 11/40
time = 248.66 secondes

Train loss 0.12319033759004828 accuracy 0.9755451083183289 macro_avg {'precision': 0.9746528567165589, 'recall': 0.9748269563999357, 'f1-score': 0.9747091268711813, 'support': 10182} weighted_avg {'precision': 0.9756983766830148, 'recall': 0.9755450795521509, 'f1-score': 0.9755941518440655, 'support': 10182}
 
time = 7.57 secondes

Val loss 0.6628867494898297 accuracy 0.9037102460861206 macro_avg {'precision': 0.9096504345123974, 'recall': 0.9045033083375115, 'f1-score': 0.9040468857843502, 'support': 1132} weighted_avg {'precision': 0.9099112772992249, 'recall': 0.9037102473498233, 'f1-score': 0.9039330523481328, 'support': 1132}
 
----------
Epoch 12/40
time = 250.63 secondes

Train loss 0.11524965221594487 accuracy 0.9776075482368469 macro_avg {'precision': 0.9774138684983908, 'recall': 0.9772508436676187, 'f1-score': 0.9773107534030532, 'support': 10182} weighted_avg {'precision': 0.9776138146290644, 'recall': 0.9776075427224514, 'f1-score': 0.977590486030243, 'support': 10182}
 
time = 7.52 secondes

Val loss 0.7456020498094903 accuracy 0.8975265026092529 macro_avg {'precision': 0.9090635970117444, 'recall': 0.9047536920623841, 'f1-score': 0.9019099011232055, 'support': 1132} weighted_avg {'precision': 0.9085830710482807, 'recall': 0.8975265017667845, 'f1-score': 0.8973266976480416, 'support': 1132}
 
----------
Epoch 13/40
time = 250.16 secondes

Train loss 0.10504090216392677 accuracy 0.9790807366371155 macro_avg {'precision': 0.9792756765854433, 'recall': 0.978930078804853, 'f1-score': 0.9790756386412726, 'support': 10182} weighted_avg {'precision': 0.9791536008426072, 'recall': 0.9790807307012375, 'f1-score': 0.979091311531254, 'support': 10182}
 
time = 7.53 secondes

Val loss 0.6768322723395434 accuracy 0.9010601043701172 macro_avg {'precision': 0.9054718162725204, 'recall': 0.9055508756541665, 'f1-score': 0.9025122843123514, 'support': 1132} weighted_avg {'precision': 0.9075891672865216, 'recall': 0.901060070671378, 'f1-score': 0.901060553396821, 'support': 1132}
 
----------
Epoch 14/40
time = 250.59 secondes

Train loss 0.09778590153576001 accuracy 0.9813396334648132 macro_avg {'precision': 0.9809494550642587, 'recall': 0.9808989093822381, 'f1-score': 0.9808968611429882, 'support': 10182} weighted_avg {'precision': 0.9814042267977306, 'recall': 0.9813396189353761, 'f1-score': 0.981343903406339, 'support': 10182}
 
time = 7.72 secondes

Val loss 0.6744836222636186 accuracy 0.9072438478469849 macro_avg {'precision': 0.9119796702096508, 'recall': 0.9101199836092879, 'f1-score': 0.9097447468395974, 'support': 1132} weighted_avg {'precision': 0.9102295278140772, 'recall': 0.907243816254417, 'f1-score': 0.9073438854697123, 'support': 1132}
 
----------
Epoch 15/40
time = 249.83 secondes

Train loss 0.09410676541229694 accuracy 0.982518196105957 macro_avg {'precision': 0.9825139627994975, 'recall': 0.9823675572238312, 'f1-score': 0.9824108290361657, 'support': 10182} weighted_avg {'precision': 0.9825944826934416, 'recall': 0.9825181693184051, 'f1-score': 0.9825256442470833, 'support': 10182}
 
time = 7.51 secondes

Val loss 0.7564833011135088 accuracy 0.8948763608932495 macro_avg {'precision': 0.9106782049246837, 'recall': 0.8960229562702402, 'f1-score': 0.8993734985932734, 'support': 1132} weighted_avg {'precision': 0.9078952491826929, 'recall': 0.8948763250883393, 'f1-score': 0.8972581699909383, 'support': 1132}
 
----------
Epoch 16/40
time = 245.92 secondes

Train loss 0.08464193077832154 accuracy 0.9851699471473694 macro_avg {'precision': 0.9845884215230185, 'recall': 0.9849112062422366, 'f1-score': 0.9847348965615377, 'support': 10182} weighted_avg {'precision': 0.9852315123290156, 'recall': 0.98516990768022, 'f1-score': 0.9851866871940606, 'support': 10182}
 
time = 7.64 secondes

Val loss 0.7418476681931692 accuracy 0.8975265026092529 macro_avg {'precision': 0.9037442488638019, 'recall': 0.8995707568602282, 'f1-score': 0.8985637718644585, 'support': 1132} weighted_avg {'precision': 0.9057691444979914, 'recall': 0.8975265017667845, 'f1-score': 0.898577217705142, 'support': 1132}
 
----------
Epoch 17/40
time = 251.63 secondes

Train loss 0.07757251700043281 accuracy 0.9872323870658875 macro_avg {'precision': 0.9872067677966013, 'recall': 0.9871905664158496, 'f1-score': 0.9871855339887885, 'support': 10182} weighted_avg {'precision': 0.9872579468789795, 'recall': 0.9872323708505205, 'f1-score': 0.9872318082857974, 'support': 10182}
 
time = 7.63 secondes

Val loss 0.8633734342710994 accuracy 0.8886925578117371 macro_avg {'precision': 0.9024784282285161, 'recall': 0.8929550397899211, 'f1-score': 0.8915291440921213, 'support': 1132} weighted_avg {'precision': 0.9014238113675468, 'recall': 0.8886925795053003, 'f1-score': 0.88854062409612, 'support': 1132}
 
----------
Epoch 18/40
time = 250.88 secondes

Train loss 0.08821614822512831 accuracy 0.9854645729064941 macro_avg {'precision': 0.9854629505121645, 'recall': 0.9853694097241433, 'f1-score': 0.985393520706786, 'support': 10182} weighted_avg {'precision': 0.9855002644849216, 'recall': 0.9854645452759773, 'f1-score': 0.9854597661234872, 'support': 10182}
 
time = 7.45 secondes

Val loss 0.767090678145854 accuracy 0.9037102460861206 macro_avg {'precision': 0.9075967916693004, 'recall': 0.9041330631152255, 'f1-score': 0.9036335822890423, 'support': 1132} weighted_avg {'precision': 0.9089261397007169, 'recall': 0.9037102473498233, 'f1-score': 0.9042647557898065, 'support': 1132}
 
----------
Epoch 19/40
time = 250.52 secondes

Train loss 0.0749602993071239 accuracy 0.9871341586112976 macro_avg {'precision': 0.9867713304152204, 'recall': 0.9868045074229436, 'f1-score': 0.9867829184610992, 'support': 10182} weighted_avg {'precision': 0.9871419578645863, 'recall': 0.9871341583186014, 'f1-score': 0.9871330546572985, 'support': 10182}
 
time = 7.54 secondes

Val loss 0.7201525954318333 accuracy 0.9116607904434204 macro_avg {'precision': 0.912924243421142, 'recall': 0.9154248979506463, 'f1-score': 0.9121713146397162, 'support': 1132} weighted_avg {'precision': 0.9169472610206952, 'recall': 0.911660777385159, 'f1-score': 0.9123674614262748, 'support': 1132}
 
----------
Epoch 20/40
time = 250.95 secondes

Train loss 0.07304274305559895 accuracy 0.9862502813339233 macro_avg {'precision': 0.9858324959473436, 'recall': 0.9855196522628991, 'f1-score': 0.9856434042541306, 'support': 10182} weighted_avg {'precision': 0.9862952617536104, 'recall': 0.9862502455313298, 'f1-score': 0.9862454321896688, 'support': 10182}
 
time = 7.54 secondes

Val loss 0.6510961162650705 accuracy 0.9134275913238525 macro_avg {'precision': 0.9194728596714026, 'recall': 0.914742598979165, 'f1-score': 0.9154500069715406, 'support': 1132} weighted_avg {'precision': 0.9177170107588458, 'recall': 0.9134275618374559, 'f1-score': 0.9139905434659994, 'support': 1132}
 
----------
Epoch 21/40
time = 247.42 secondes

Train loss 0.04931806545881465 accuracy 0.9908662438392639 macro_avg {'precision': 0.9906321096149684, 'recall': 0.990338351014082, 'f1-score': 0.9904740471778434, 'support': 10182} weighted_avg {'precision': 0.9908986386082571, 'recall': 0.9908662345315262, 'f1-score': 0.9908714130607594, 'support': 10182}
 
time = 7.58 secondes

Val loss 0.6512622777973122 accuracy 0.9178445339202881 macro_avg {'precision': 0.9183271284155019, 'recall': 0.9197255471058714, 'f1-score': 0.9175653918122093, 'support': 1132} weighted_avg {'precision': 0.9198176632988154, 'recall': 0.9178445229681979, 'f1-score': 0.9174240314357665, 'support': 1132}
 
----------
Epoch 22/40
time = 251.18 secondes

Train loss 0.06185626791848564 accuracy 0.9894912838935852 macro_avg {'precision': 0.9892839832574907, 'recall': 0.9892079994310169, 'f1-score': 0.9892280633827506, 'support': 10182} weighted_avg {'precision': 0.9895229649510419, 'recall': 0.9894912590846592, 'f1-score': 0.9894895552466825, 'support': 10182}
 
time = 7.45 secondes

Val loss 0.9198172395647394 accuracy 0.8948763608932495 macro_avg {'precision': 0.8988377394758675, 'recall': 0.8978792418001864, 'f1-score': 0.8948077171763835, 'support': 1132} weighted_avg {'precision': 0.90303226312028, 'recall': 0.8948763250883393, 'f1-score': 0.8953553531749149, 'support': 1132}
 
----------
Epoch 23/40
time = 249.76 secondes

Train loss 0.0684844266757561 accuracy 0.9885091781616211 macro_avg {'precision': 0.9882295388010103, 'recall': 0.9880199647331013, 'f1-score': 0.9881116642338152, 'support': 10182} weighted_avg {'precision': 0.9885354240053417, 'recall': 0.9885091337654685, 'f1-score': 0.9885093499464294, 'support': 10182}
 
time = 7.97 secondes

Val loss 0.5879700042815259 accuracy 0.9222614765167236 macro_avg {'precision': 0.9230125119715338, 'recall': 0.9252477797371481, 'f1-score': 0.9231693583336208, 'support': 1132} weighted_avg {'precision': 0.9240001625055927, 'recall': 0.9222614840989399, 'f1-score': 0.9221778055281982, 'support': 1132}
 
----------
Epoch 24/40
time = 249.73 secondes

Train loss 0.05548748996264707 accuracy 0.989589512348175 macro_avg {'precision': 0.9891571628510221, 'recall': 0.9893746042697155, 'f1-score': 0.9892582630473413, 'support': 10182} weighted_avg {'precision': 0.9895958757372689, 'recall': 0.9895894716165783, 'f1-score': 0.9895863476284956, 'support': 10182}
 
time = 7.43 secondes

Val loss 0.6771918676164769 accuracy 0.916961133480072 macro_avg {'precision': 0.9222384886376258, 'recall': 0.9160740873462195, 'f1-score': 0.916005631423849, 'support': 1132} weighted_avg {'precision': 0.9223043651897798, 'recall': 0.9169611307420494, 'f1-score': 0.9166900437279795, 'support': 1132}
 
----------
Epoch 25/40
time = 249.03 secondes

Train loss 0.05784273576875929 accuracy 0.9902769923210144 macro_avg {'precision': 0.9899516092929179, 'recall': 0.9898133096852874, 'f1-score': 0.9898699014552896, 'support': 10182} weighted_avg {'precision': 0.9902857549730646, 'recall': 0.9902769593400118, 'f1-score': 0.9902698012421605, 'support': 10182}
 
time = 7.55 secondes

Val loss 0.7653577935316848 accuracy 0.9107773900032043 macro_avg {'precision': 0.9133594067421527, 'recall': 0.9104702258536109, 'f1-score': 0.9086868428397304, 'support': 1132} weighted_avg {'precision': 0.9179557222749614, 'recall': 0.9107773851590106, 'f1-score': 0.9111667236463763, 'support': 1132}
 
----------
Epoch 26/40
time = 248.91 secondes

Train loss 0.049355619158339484 accuracy 0.9911609292030334 macro_avg {'precision': 0.9903022602769426, 'recall': 0.9905557332068466, 'f1-score': 0.9904189937742137, 'support': 10182} weighted_avg {'precision': 0.9911836566417381, 'recall': 0.9911608721272834, 'f1-score': 0.9911627009296773, 'support': 10182}
 
time = 7.56 secondes

Val loss 0.7509257535229422 accuracy 0.9134275913238525 macro_avg {'precision': 0.9177213704165771, 'recall': 0.9162310409261328, 'f1-score': 0.9143295956462694, 'support': 1132} weighted_avg {'precision': 0.9198178417942727, 'recall': 0.9134275618374559, 'f1-score': 0.913783770756973, 'support': 1132}
 
----------
Epoch 27/40
time = 250.80 secondes

Train loss 0.04763909723584831 accuracy 0.9925358891487122 macro_avg {'precision': 0.9925756637770753, 'recall': 0.9923579175626104, 'f1-score': 0.9924567142899186, 'support': 10182} weighted_avg {'precision': 0.9925511601437584, 'recall': 0.9925358475741505, 'f1-score': 0.9925341380294973, 'support': 10182}
 
time = 7.65 secondes

Val loss 0.7442153213282516 accuracy 0.9090105891227722 macro_avg {'precision': 0.9107293068420657, 'recall': 0.9114169365453341, 'f1-score': 0.908914335907346, 'support': 1132} weighted_avg {'precision': 0.9144346011754888, 'recall': 0.9090106007067138, 'f1-score': 0.9094820518986411, 'support': 1132}
 
----------
Epoch 28/40
time = 250.61 secondes

Train loss 0.04341833915329589 accuracy 0.9923394322395325 macro_avg {'precision': 0.992186630085183, 'recall': 0.9920652900728955, 'f1-score': 0.9921153443584085, 'support': 10182} weighted_avg {'precision': 0.992348098708752, 'recall': 0.9923394225103123, 'f1-score': 0.9923335868347564, 'support': 10182}
 
time = 7.60 secondes

Val loss 0.8233127260648705 accuracy 0.9063604474067688 macro_avg {'precision': 0.9105011778096228, 'recall': 0.9104630135537775, 'f1-score': 0.9081266346772244, 'support': 1132} weighted_avg {'precision': 0.9122167664878298, 'recall': 0.9063604240282686, 'f1-score': 0.9067453100441463, 'support': 1132}
 
----------
Epoch 29/40
time = 231.99 secondes

Train loss 0.03164692058268757 accuracy 0.9945983290672302 macro_avg {'precision': 0.9943607395867204, 'recall': 0.9943117867598751, 'f1-score': 0.9943334145933683, 'support': 10182} weighted_avg {'precision': 0.9946001632297667, 'recall': 0.994598310744451, 'f1-score': 0.994596382524077, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.8184553787322726 accuracy 0.9054770469665527 macro_avg {'precision': 0.9089870904440979, 'recall': 0.9079508769808798, 'f1-score': 0.9053448183237727, 'support': 1132} weighted_avg {'precision': 0.9120763956302298, 'recall': 0.9054770318021201, 'f1-score': 0.9055152525001994, 'support': 1132}
 
----------
Epoch 30/40
time = 235.53 secondes

Train loss 0.04078527410700881 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934885301407835, 'recall': 0.9931112493001919, 'f1-score': 0.9932848593399568, 'support': 10182} weighted_avg {'precision': 0.9935419035795993, 'recall': 0.9935179728933412, 'f1-score': 0.9935163831201508, 'support': 10182}
 
time = 7.50 secondes

Val loss 0.7299323415374064 accuracy 0.9204947352409363 macro_avg {'precision': 0.9224676596523682, 'recall': 0.9214477790992334, 'f1-score': 0.9207694264686312, 'support': 1132} weighted_avg {'precision': 0.9234101244409744, 'recall': 0.9204946996466431, 'f1-score': 0.9208852117159143, 'support': 1132}
 
----------
Epoch 31/40
time = 239.62 secondes

Train loss 0.04065912271953479 accuracy 0.9939108490943909 macro_avg {'precision': 0.9934487712655127, 'recall': 0.9934403806713563, 'f1-score': 0.9934302068403824, 'support': 10182} weighted_avg {'precision': 0.9939422246138608, 'recall': 0.9939108230210175, 'f1-score': 0.993913613088154, 'support': 10182}
 
time = 8.98 secondes

Val loss 0.7225938459255111 accuracy 0.9134275913238525 macro_avg {'precision': 0.9155444646658204, 'recall': 0.9173234742643153, 'f1-score': 0.9145047051209418, 'support': 1132} weighted_avg {'precision': 0.9192736171123214, 'recall': 0.9134275618374559, 'f1-score': 0.9145155397182575, 'support': 1132}
 
----------
Epoch 32/40
time = 243.95 secondes

Train loss 0.024334000629299152 accuracy 0.9959732890129089 macro_avg {'precision': 0.9958844861967668, 'recall': 0.9957330727928545, 'f1-score': 0.9958022812999896, 'support': 10182} weighted_avg {'precision': 0.9959861844413658, 'recall': 0.995973286191318, 'f1-score': 0.995973399286367, 'support': 10182}
 
time = 7.75 secondes

Val loss 0.8112249086536368 accuracy 0.9151943325996399 macro_avg {'precision': 0.9160958464402533, 'recall': 0.915641423490178, 'f1-score': 0.9141508468799703, 'support': 1132} weighted_avg {'precision': 0.9178816053694021, 'recall': 0.9151943462897526, 'f1-score': 0.914829991458043, 'support': 1132}
 
----------
Epoch 33/40
time = 238.56 secondes

Train loss 0.023219449777292428 accuracy 0.9961697459220886 macro_avg {'precision': 0.9959123927790656, 'recall': 0.9959907527556566, 'f1-score': 0.9959472796693737, 'support': 10182} weighted_avg {'precision': 0.996180779171071, 'recall': 0.9961697112551562, 'f1-score': 0.9961708651206371, 'support': 10182}
 
time = 8.60 secondes

Val loss 0.8471177238917194 accuracy 0.9151943325996399 macro_avg {'precision': 0.9180126726049409, 'recall': 0.915914130619454, 'f1-score': 0.9154451111654491, 'support': 1132} weighted_avg {'precision': 0.9190097932007517, 'recall': 0.9151943462897526, 'f1-score': 0.9155774378968202, 'support': 1132}
 
----------
Epoch 34/40
time = 241.59 secondes

Train loss 0.024595098940571887 accuracy 0.9962679743766785 macro_avg {'precision': 0.9961292773096888, 'recall': 0.9962716970921697, 'f1-score': 0.996188093170755, 'support': 10182} weighted_avg {'precision': 0.9963031142105565, 'recall': 0.9962679237870752, 'f1-score': 0.9962742065816577, 'support': 10182}
 
time = 7.34 secondes

Val loss 0.8434233873387558 accuracy 0.9098939895629883 macro_avg {'precision': 0.9130208646841711, 'recall': 0.9142756235898446, 'f1-score': 0.9116943064960902, 'support': 1132} weighted_avg {'precision': 0.9156909002138974, 'recall': 0.9098939929328622, 'f1-score': 0.9108601448540581, 'support': 1132}
 
----------
Epoch 35/40
time = 235.62 secondes

Train loss 0.0221274888231557 accuracy 0.9962679743766785 macro_avg {'precision': 0.996097895093631, 'recall': 0.9960294909554562, 'f1-score': 0.9960611596578606, 'support': 10182} weighted_avg {'precision': 0.9962739778793932, 'recall': 0.9962679237870752, 'f1-score': 0.9962683941645966, 'support': 10182}
 
time = 8.44 secondes

Val loss 0.7670079157940589 accuracy 0.9072438478469849 macro_avg {'precision': 0.9088673539566547, 'recall': 0.9110398100630499, 'f1-score': 0.9081728921821345, 'support': 1132} weighted_avg {'precision': 0.9106470519477585, 'recall': 0.907243816254417, 'f1-score': 0.907082453063825, 'support': 1132}
 
----------
Epoch 36/40
time = 237.74 secondes

Train loss 0.016822402570962975 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971135598131807, 'recall': 0.9972271194314424, 'f1-score': 0.9971682310545367, 'support': 10182} weighted_avg {'precision': 0.9971555229894922, 'recall': 0.9971518365743469, 'f1-score': 0.9971516802665646, 'support': 10182}
 
time = 6.82 secondes

Val loss 0.7304370666109169 accuracy 0.9151943325996399 macro_avg {'precision': 0.9199972827888437, 'recall': 0.9182209617686263, 'f1-score': 0.9176611260025249, 'support': 1132} weighted_avg {'precision': 0.9194532985556424, 'recall': 0.9151943462897526, 'f1-score': 0.9158462706036417, 'support': 1132}
 
----------
Epoch 37/40
time = 238.92 secondes

Train loss 0.016227430155679595 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972203636820556, 'recall': 0.9972951421905467, 'f1-score': 0.9972546698197583, 'support': 10182} weighted_avg {'precision': 0.9972586253033464, 'recall': 0.9972500491062659, 'f1-score': 0.9972513363240176, 'support': 10182}
 
time = 8.35 secondes

Val loss 0.7300265778398631 accuracy 0.9196113348007202 macro_avg {'precision': 0.9233446325025474, 'recall': 0.9221261357948137, 'f1-score': 0.921310334434447, 'support': 1132} weighted_avg {'precision': 0.9232212358187568, 'recall': 0.9196113074204947, 'f1-score': 0.9199481738339504, 'support': 1132}
 
----------
Epoch 38/40
time = 237.01 secondes

Train loss 0.00855777984936448 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986431813264962, 'recall': 0.9986643017597316, 'f1-score': 0.9986525571493224, 'support': 10182} weighted_avg {'precision': 0.9987260936192531, 'recall': 0.9987232370850521, 'f1-score': 0.9987235012525196, 'support': 10182}
 
time = 7.71 secondes

Val loss 0.7083946339373373 accuracy 0.926678478717804 macro_avg {'precision': 0.9293524685391443, 'recall': 0.9287067027493894, 'f1-score': 0.9282138811236195, 'support': 1132} weighted_avg {'precision': 0.9282518258893887, 'recall': 0.926678445229682, 'f1-score': 0.9266374775030949, 'support': 1132}
 
----------
Epoch 39/40
time = 251.53 secondes

Train loss 0.006481712652855481 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986717554073815, 'recall': 0.9986823385626163, 'f1-score': 0.99867568468106, 'support': 10182} weighted_avg {'precision': 0.998627302358648, 'recall': 0.998625024553133, 'f1-score': 0.9986247625910754, 'support': 10182}
 
time = 8.71 secondes

Val loss 0.6911079319842698 accuracy 0.9240282773971558 macro_avg {'precision': 0.9289585443869784, 'recall': 0.9257470498095209, 'f1-score': 0.925796746813471, 'support': 1132} weighted_avg {'precision': 0.9269272569816379, 'recall': 0.9240282685512368, 'f1-score': 0.923912595326016, 'support': 1132}
 
----------
Epoch 40/40
time = 261.83 secondes

Train loss 0.004349512841537681 accuracy 0.9992143511772156 macro_avg {'precision': 0.9992439350626349, 'recall': 0.9992417150618248, 'f1-score': 0.9992419306848037, 'support': 10182} weighted_avg {'precision': 0.9992161363419745, 'recall': 0.9992142997446474, 'f1-score': 0.9992142904738939, 'support': 10182}
 
time = 8.50 secondes

Val loss 0.6886081310667194 accuracy 0.9240282773971558 macro_avg {'precision': 0.9285199280757764, 'recall': 0.9258165462086302, 'f1-score': 0.9257885014502387, 'support': 1132} weighted_avg {'precision': 0.9263775094507749, 'recall': 0.9240282685512368, 'f1-score': 0.9238485950325349, 'support': 1132}
 
----------
best_accuracy 0.926678478717804 best_epoch 38 macro_avg {'precision': 0.9293524685391443, 'recall': 0.9287067027493894, 'f1-score': 0.9282138811236195, 'support': 1132} weighted_avg {'precision': 0.9282518258893887, 'recall': 0.926678445229682, 'f1-score': 0.9266374775030949, 'support': 1132}

average train time 248.22995885014535

average val time 7.718346428871155
 
time = 55.95 secondes

test_accuracy 0.8597981929779053 macro_avg {'precision': 0.8585163959250469, 'recall': 0.8531406421064135, 'f1-score': 0.8535854423923166, 'support': 7532} weighted_avg {'precision': 0.8650461036865225, 'recall': 0.859798194370685, 'f1-score': 0.8602866808745823, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_3
----------
Epoch 1/40
time = 268.67 secondes

Train loss 1.3282672125887085 accuracy 0.6553722620010376 macro_avg {'precision': 0.6730168694660861, 'recall': 0.6398655463377486, 'f1-score': 0.632320721737051, 'support': 10182} weighted_avg {'precision': 0.6802654906122951, 'recall': 0.6553722254959733, 'f1-score': 0.6468489206255907, 'support': 10182}
 
time = 8.78 secondes

Val loss 0.7281081393151216 accuracy 0.7906360626220703 macro_avg {'precision': 0.7674223137760211, 'recall': 0.7825877030899322, 'f1-score': 0.7697298927802771, 'support': 1132} weighted_avg {'precision': 0.7787582328728226, 'recall': 0.7906360424028268, 'f1-score': 0.7798473337518159, 'support': 1132}
 
----------
Epoch 2/40
time = 259.56 secondes

Train loss 0.5129971885629688 accuracy 0.850913405418396 macro_avg {'precision': 0.8402248526107957, 'recall': 0.8382267120844012, 'f1-score': 0.8352622778805356, 'support': 10182} weighted_avg {'precision': 0.8482045821090687, 'recall': 0.8509133765468474, 'f1-score': 0.8466985341302774, 'support': 10182}
 
time = 9.18 secondes

Val loss 0.5769959716519839 accuracy 0.8401060104370117 macro_avg {'precision': 0.8394547269865453, 'recall': 0.8390375103429927, 'f1-score': 0.8355476210245701, 'support': 1132} weighted_avg {'precision': 0.8475267986472135, 'recall': 0.8401060070671378, 'f1-score': 0.8400336319352012, 'support': 1132}
 
----------
Epoch 3/40
time = 259.11 secondes

Train loss 0.3289058654038367 accuracy 0.9050285220146179 macro_avg {'precision': 0.8983917912963875, 'recall': 0.8967292601005994, 'f1-score': 0.8967985979226085, 'support': 10182} weighted_avg {'precision': 0.9041154081331669, 'recall': 0.9050284816342565, 'f1-score': 0.9039685387409961, 'support': 10182}
 
time = 8.53 secondes

Val loss 0.5855983660202211 accuracy 0.8507066965103149 macro_avg {'precision': 0.8521171133633274, 'recall': 0.8450301045861444, 'f1-score': 0.8452110192514715, 'support': 1132} weighted_avg {'precision': 0.856380864208063, 'recall': 0.8507067137809188, 'f1-score': 0.8504774347238911, 'support': 1132}
 
----------
Epoch 4/40
time = 256.32 secondes

Train loss 0.2442510571371723 accuracy 0.9309566020965576 macro_avg {'precision': 0.9263993765472431, 'recall': 0.9248665756881366, 'f1-score': 0.9252820245887522, 'support': 10182} weighted_avg {'precision': 0.9305393788637675, 'recall': 0.9309565900608918, 'f1-score': 0.9304720942602037, 'support': 10182}
 
time = 8.73 secondes

Val loss 0.6431055623500175 accuracy 0.8630741834640503 macro_avg {'precision': 0.8675538123053357, 'recall': 0.8542750537213888, 'f1-score': 0.8573488935590532, 'support': 1132} weighted_avg {'precision': 0.8672769534805091, 'recall': 0.8630742049469965, 'f1-score': 0.8617345414423622, 'support': 1132}
 
----------
Epoch 5/40
time = 257.73 secondes

Train loss 0.19602858361947456 accuracy 0.947750985622406 macro_avg {'precision': 0.9443177374891933, 'recall': 0.9441391724966035, 'f1-score': 0.9441748370036779, 'support': 10182} weighted_avg {'precision': 0.9476732109113573, 'recall': 0.9477509330190532, 'f1-score': 0.9476594999807741, 'support': 10182}
 
time = 9.11 secondes

Val loss 0.626088501301817 accuracy 0.8719081282615662 macro_avg {'precision': 0.8719024119138495, 'recall': 0.8653528423231907, 'f1-score': 0.8651651423299975, 'support': 1132} weighted_avg {'precision': 0.8740592607196783, 'recall': 0.8719081272084805, 'f1-score': 0.8699834544311515, 'support': 1132}
 
----------
Epoch 6/40
time = 256.92 secondes

Train loss 0.16889864459905768 accuracy 0.9573757648468018 macro_avg {'precision': 0.9546562093861001, 'recall': 0.9542559495086451, 'f1-score': 0.9544208265952581, 'support': 10182} weighted_avg {'precision': 0.957324379055042, 'recall': 0.9573757611471224, 'f1-score': 0.9573192039352472, 'support': 10182}
 
time = 8.72 secondes

Val loss 0.7608531304818749 accuracy 0.8524734973907471 macro_avg {'precision': 0.8576183936561763, 'recall': 0.8481535369590054, 'f1-score': 0.8484429892123062, 'support': 1132} weighted_avg {'precision': 0.8603030469956501, 'recall': 0.8524734982332155, 'f1-score': 0.8516917895143983, 'support': 1132}
 
----------
Epoch 7/40
time = 259.10 secondes

Train loss 0.14458469956768955 accuracy 0.9653310179710388 macro_avg {'precision': 0.9631463466663763, 'recall': 0.9627415175563516, 'f1-score': 0.9629240120579811, 'support': 10182} weighted_avg {'precision': 0.9653182041787226, 'recall': 0.9653309762325673, 'f1-score': 0.9653057025246757, 'support': 10182}
 
time = 8.10 secondes

Val loss 0.7880780989022165 accuracy 0.8666077852249146 macro_avg {'precision': 0.8646473186047011, 'recall': 0.8636569068756634, 'f1-score': 0.8622725299022973, 'support': 1132} weighted_avg {'precision': 0.8692215711154221, 'recall': 0.8666077738515902, 'f1-score': 0.8661072976400468, 'support': 1132}
 
----------
Epoch 8/40
time = 259.79 secondes

Train loss 0.14132063151494376 accuracy 0.9678845405578613 macro_avg {'precision': 0.9661377383305425, 'recall': 0.9661471449287629, 'f1-score': 0.9661180188082474, 'support': 10182} weighted_avg {'precision': 0.9678816038749474, 'recall': 0.9678845020624631, 'f1-score': 0.9678585243691701, 'support': 10182}
 
time = 8.82 secondes

Val loss 0.7643163395212622 accuracy 0.8710247278213501 macro_avg {'precision': 0.8752603438179294, 'recall': 0.8640934105210796, 'f1-score': 0.8648208755266639, 'support': 1132} weighted_avg {'precision': 0.8757553564746385, 'recall': 0.8710247349823321, 'f1-score': 0.869037289177366, 'support': 1132}
 
----------
Epoch 9/40
time = 259.50 secondes

Train loss 0.13399412477334335 accuracy 0.9697505831718445 macro_avg {'precision': 0.9684101233088904, 'recall': 0.9682622859786967, 'f1-score': 0.9683103808160233, 'support': 10182} weighted_avg {'precision': 0.9697757288109954, 'recall': 0.9697505401689256, 'f1-score': 0.9697389097392421, 'support': 10182}
 
time = 8.99 secondes

Val loss 0.8193599907275532 accuracy 0.8692579865455627 macro_avg {'precision': 0.8668632031174222, 'recall': 0.8646294888741257, 'f1-score': 0.8629845726315095, 'support': 1132} weighted_avg {'precision': 0.8734482336410241, 'recall': 0.8692579505300353, 'f1-score': 0.8686544874610507, 'support': 1132}
 
----------
Epoch 10/40
time = 258.47 secondes

Train loss 0.12410386943043973 accuracy 0.9715183973312378 macro_avg {'precision': 0.9699788021089016, 'recall': 0.9696860487644393, 'f1-score': 0.9698026563499736, 'support': 10182} weighted_avg {'precision': 0.9714676355412457, 'recall': 0.9715183657434688, 'f1-score': 0.9714654254934826, 'support': 10182}
 
time = 8.41 secondes

Val loss 0.9378761623422025 accuracy 0.8577738404273987 macro_avg {'precision': 0.8606019153811821, 'recall': 0.8530725553918594, 'f1-score': 0.854306990745569, 'support': 1132} weighted_avg {'precision': 0.862943152511369, 'recall': 0.857773851590106, 'f1-score': 0.8578257655662705, 'support': 1132}
 
----------
Epoch 11/40
time = 259.81 secondes

Train loss 0.13352596513295378 accuracy 0.972304105758667 macro_avg {'precision': 0.9708905657848271, 'recall': 0.9705491644699802, 'f1-score': 0.9706842067241528, 'support': 10182} weighted_avg {'precision': 0.972344491570311, 'recall': 0.9723040659988215, 'f1-score': 0.972291613078659, 'support': 10182}
 
time = 8.39 secondes

Val loss 0.9193884178190197 accuracy 0.8586572408676147 macro_avg {'precision': 0.8651311700429634, 'recall': 0.8580721975808565, 'f1-score': 0.8562259103501922, 'support': 1132} weighted_avg {'precision': 0.8683070403118519, 'recall': 0.8586572438162544, 'f1-score': 0.8581964663911876, 'support': 1132}
 
----------
Epoch 12/40
time = 255.96 secondes

Train loss 0.10786243604357318 accuracy 0.9766254425048828 macro_avg {'precision': 0.9754926399864061, 'recall': 0.9752678300042199, 'f1-score': 0.9753615797990088, 'support': 10182} weighted_avg {'precision': 0.9766337574838467, 'recall': 0.9766254174032607, 'f1-score': 0.9766112944354148, 'support': 10182}
 
time = 8.24 secondes

Val loss 0.931797513146565 accuracy 0.8736749291419983 macro_avg {'precision': 0.8748552661654232, 'recall': 0.871245193554741, 'f1-score': 0.8711655246071768, 'support': 1132} weighted_avg {'precision': 0.8784046647391718, 'recall': 0.8736749116607774, 'f1-score': 0.8740888164634539, 'support': 1132}
 
----------
Epoch 13/40
time = 261.90 secondes

Train loss 0.09895297220896318 accuracy 0.978295087814331 macro_avg {'precision': 0.9771806330435538, 'recall': 0.9767413501043064, 'f1-score': 0.9769345462283304, 'support': 10182} weighted_avg {'precision': 0.9782893912514119, 'recall': 0.978295030445885, 'f1-score': 0.978269698163067, 'support': 10182}
 
time = 8.45 secondes

Val loss 0.916107052437056 accuracy 0.870141327381134 macro_avg {'precision': 0.8737372611051738, 'recall': 0.8689251083425263, 'f1-score': 0.8679934658312151, 'support': 1132} weighted_avg {'precision': 0.8776499573440255, 'recall': 0.8701413427561837, 'f1-score': 0.8707845798508163, 'support': 1132}
 
----------
Epoch 14/40
time = 254.09 secondes

Train loss 0.09086943936164694 accuracy 0.9810450077056885 macro_avg {'precision': 0.9802694715380831, 'recall': 0.9801473300774953, 'f1-score': 0.9801766056596101, 'support': 10182} weighted_avg {'precision': 0.9811036526441651, 'recall': 0.9810449813396189, 'f1-score': 0.9810425212331124, 'support': 10182}
 
time = 8.86 secondes

Val loss 1.0270354358928646 accuracy 0.8595406413078308 macro_avg {'precision': 0.863860460779925, 'recall': 0.86096593844247, 'f1-score': 0.8593620779228814, 'support': 1132} weighted_avg {'precision': 0.8669967179071353, 'recall': 0.8595406360424028, 'f1-score': 0.8600212225815885, 'support': 1132}
 
----------
Epoch 15/40
time = 260.29 secondes

Train loss 0.10441951215938991 accuracy 0.9798664450645447 macro_avg {'precision': 0.979350768592696, 'recall': 0.9789328031292133, 'f1-score': 0.9791241989672421, 'support': 10182} weighted_avg {'precision': 0.9798676371639146, 'recall': 0.9798664309565901, 'f1-score': 0.9798502664969461, 'support': 10182}
 
time = 8.81 secondes

Val loss 0.9532930628174398 accuracy 0.8745583295822144 macro_avg {'precision': 0.8764666200062582, 'recall': 0.8691343600102608, 'f1-score': 0.870189274395119, 'support': 1132} weighted_avg {'precision': 0.8790859028361772, 'recall': 0.8745583038869258, 'f1-score': 0.8743878247336258, 'support': 1132}
 
----------
Epoch 16/40
time = 259.86 secondes

Train loss 0.10335602275366541 accuracy 0.9806521534919739 macro_avg {'precision': 0.979911940898018, 'recall': 0.9792614162533878, 'f1-score': 0.9795327674972567, 'support': 10182} weighted_avg {'precision': 0.9806750687029815, 'recall': 0.9806521312119426, 'f1-score': 0.9806209353254588, 'support': 10182}
 
time = 9.00 secondes

Val loss 0.9194757736609382 accuracy 0.8754417300224304 macro_avg {'precision': 0.8788363697429995, 'recall': 0.8735051119437365, 'f1-score': 0.8734516712508624, 'support': 1132} weighted_avg {'precision': 0.8809550266614634, 'recall': 0.8754416961130742, 'f1-score': 0.875801983529068, 'support': 1132}
 
----------
Epoch 17/40
time = 260.81 secondes

Train loss 0.0788474444411897 accuracy 0.9848753213882446 macro_avg {'precision': 0.9839896913612526, 'recall': 0.9839017078110425, 'f1-score': 0.9839365835840927, 'support': 10182} weighted_avg {'precision': 0.9849008019751447, 'recall': 0.9848752700844627, 'f1-score': 0.9848790925857498, 'support': 10182}
 
time = 8.04 secondes

Val loss 0.9982951390700461 accuracy 0.8692579865455627 macro_avg {'precision': 0.875136045082051, 'recall': 0.8685384433493318, 'f1-score': 0.869465652839381, 'support': 1132} weighted_avg {'precision': 0.87709620578714, 'recall': 0.8692579505300353, 'f1-score': 0.870759208188435, 'support': 1132}
 
----------
Epoch 18/40
time = 274.72 secondes

Train loss 0.08008425271178664 accuracy 0.9847770929336548 macro_avg {'precision': 0.9847184748153598, 'recall': 0.9841711919708841, 'f1-score': 0.9844073744443153, 'support': 10182} weighted_avg {'precision': 0.9848261904881639, 'recall': 0.9847770575525437, 'f1-score': 0.9847672299773933, 'support': 10182}
 
time = 8.35 secondes

Val loss 0.9775710560067419 accuracy 0.880742073059082 macro_avg {'precision': 0.8911134018026564, 'recall': 0.873403915765522, 'f1-score': 0.8777206801183064, 'support': 1132} weighted_avg {'precision': 0.8887363932410647, 'recall': 0.8807420494699647, 'f1-score': 0.8807594356511127, 'support': 1132}
 
----------
Epoch 19/40
time = 268.68 secondes

Train loss 0.07551175762668126 accuracy 0.9859556555747986 macro_avg {'precision': 0.9854392799985254, 'recall': 0.9850468668338571, 'f1-score': 0.9852221569179436, 'support': 10182} weighted_avg {'precision': 0.985985698073105, 'recall': 0.9859556079355726, 'f1-score': 0.9859539446287612, 'support': 10182}
 
time = 9.89 secondes

Val loss 0.975781066174714 accuracy 0.8816254734992981 macro_avg {'precision': 0.8861019303694558, 'recall': 0.8772773172412351, 'f1-score': 0.8800860041280119, 'support': 1132} weighted_avg {'precision': 0.8864207529977516, 'recall': 0.8816254416961131, 'f1-score': 0.8823108415906136, 'support': 1132}
 
----------
Epoch 20/40
time = 273.51 secondes

Train loss 0.08261115943725479 accuracy 0.9837949872016907 macro_avg {'precision': 0.9826765679796579, 'recall': 0.9830274118112519, 'f1-score': 0.9828031246844204, 'support': 10182} weighted_avg {'precision': 0.9838992712512933, 'recall': 0.983794932233353, 'f1-score': 0.9838009698876711, 'support': 10182}
 
time = 9.35 secondes

Val loss 0.9555259621837406 accuracy 0.8674911856651306 macro_avg {'precision': 0.8683340414454663, 'recall': 0.8669601945334767, 'f1-score': 0.8650488247030369, 'support': 1132} weighted_avg {'precision': 0.8722711203084167, 'recall': 0.8674911660777385, 'f1-score': 0.8671327840290327, 'support': 1132}
 
----------
Epoch 21/40
time = 267.98 secondes

Train loss 0.07363640635093058 accuracy 0.9858574271202087 macro_avg {'precision': 0.9854758437314167, 'recall': 0.9855508799380692, 'f1-score': 0.9855008867606919, 'support': 10182} weighted_avg {'precision': 0.9858544598521122, 'recall': 0.9858573954036535, 'f1-score': 0.9858431705547152, 'support': 10182}
 
time = 8.84 secondes

Val loss 1.0376111763302183 accuracy 0.8816254734992981 macro_avg {'precision': 0.885143320491539, 'recall': 0.8765855357709113, 'f1-score': 0.877797618640774, 'support': 1132} weighted_avg {'precision': 0.8861746377446549, 'recall': 0.8816254416961131, 'f1-score': 0.8807768007271833, 'support': 1132}
 
----------
Epoch 22/40
time = 268.86 secondes

Train loss 0.0741137618214548 accuracy 0.9858574271202087 macro_avg {'precision': 0.985294662387844, 'recall': 0.985428066137691, 'f1-score': 0.9853414997596845, 'support': 10182} weighted_avg {'precision': 0.9858889425441253, 'recall': 0.9858573954036535, 'f1-score': 0.9858542381245605, 'support': 10182}
 
time = 9.48 secondes

Val loss 1.036297616040134 accuracy 0.879858672618866 macro_avg {'precision': 0.8770843545321908, 'recall': 0.876724459103228, 'f1-score': 0.8751886002481586, 'support': 1132} weighted_avg {'precision': 0.8811207295027432, 'recall': 0.8798586572438163, 'f1-score': 0.8789252271367263, 'support': 1132}
 
----------
Epoch 23/40
time = 271.25 secondes

Train loss 0.06451356851665674 accuracy 0.9891966581344604 macro_avg {'precision': 0.9890108245714917, 'recall': 0.988693242557957, 'f1-score': 0.9888328972272428, 'support': 10182} weighted_avg {'precision': 0.9892322497906961, 'recall': 0.989196621488902, 'f1-score': 0.9891961735227695, 'support': 10182}
 
time = 8.38 secondes

Val loss 1.027961758907776 accuracy 0.8692579865455627 macro_avg {'precision': 0.8763056333505205, 'recall': 0.8711187067607244, 'f1-score': 0.8668869353024782, 'support': 1132} weighted_avg {'precision': 0.8776098091283054, 'recall': 0.8692579505300353, 'f1-score': 0.8653022393324272, 'support': 1132}
 
----------
Epoch 24/40
time = 288.70 secondes

Train loss 0.05947486812088138 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888671462109588, 'recall': 0.9885870060007246, 'f1-score': 0.9887000434916505, 'support': 10182} weighted_avg {'precision': 0.988931627274128, 'recall': 0.9889019838931448, 'f1-score': 0.9888898254988379, 'support': 10182}
 
time = 9.07 secondes

Val loss 1.0933700953022016 accuracy 0.8648409843444824 macro_avg {'precision': 0.8761203989738261, 'recall': 0.8630318606343609, 'f1-score': 0.8641919350368179, 'support': 1132} weighted_avg {'precision': 0.8773924282936446, 'recall': 0.8648409893992933, 'f1-score': 0.8649056810711842, 'support': 1132}
 
----------
Epoch 25/40
time = 290.39 secondes

Train loss 0.062415781008357714 accuracy 0.9894912838935852 macro_avg {'precision': 0.9894848104543721, 'recall': 0.9890114194792364, 'f1-score': 0.989229379549655, 'support': 10182} weighted_avg {'precision': 0.989515340553105, 'recall': 0.9894912590846592, 'f1-score': 0.9894872445380166, 'support': 10182}
 
time = 9.36 secondes

Val loss 1.0423202379389411 accuracy 0.8772084712982178 macro_avg {'precision': 0.8822258481862569, 'recall': 0.8764380835222495, 'f1-score': 0.877091505012895, 'support': 1132} weighted_avg {'precision': 0.884174149831988, 'recall': 0.877208480565371, 'f1-score': 0.8781880648538453, 'support': 1132}
 
----------
Epoch 26/40
time = 279.86 secondes

Train loss 0.05333828034471504 accuracy 0.9896877408027649 macro_avg {'precision': 0.9893746234098726, 'recall': 0.9892998011462419, 'f1-score': 0.9893311941347932, 'support': 10182} weighted_avg {'precision': 0.9896957441083624, 'recall': 0.9896876841484974, 'f1-score': 0.9896857181969656, 'support': 10182}
 
time = 9.87 secondes

Val loss 0.9985673664009418 accuracy 0.880742073059082 macro_avg {'precision': 0.8817100243354963, 'recall': 0.8764439202434169, 'f1-score': 0.8767298713562586, 'support': 1132} weighted_avg {'precision': 0.8835973724848152, 'recall': 0.8807420494699647, 'f1-score': 0.8798879487790219, 'support': 1132}
 
----------
Epoch 27/40
time = 287.71 secondes

Train loss 0.04438217871661272 accuracy 0.9916519522666931 macro_avg {'precision': 0.9911381102568537, 'recall': 0.9908877232275441, 'f1-score': 0.9910000007046541, 'support': 10182} weighted_avg {'precision': 0.9916511467428829, 'recall': 0.9916519347868789, 'f1-score': 0.9916401690648169, 'support': 10182}
 
time = 9.45 secondes

Val loss 1.0892821297554331 accuracy 0.8780918717384338 macro_avg {'precision': 0.880551646859489, 'recall': 0.8746678993547953, 'f1-score': 0.8760515477081714, 'support': 1132} weighted_avg {'precision': 0.8816801554753213, 'recall': 0.8780918727915195, 'f1-score': 0.8784581705584386, 'support': 1132}
 
----------
Epoch 28/40
time = 268.99 secondes

Train loss 0.057804592691418875 accuracy 0.9894912838935852 macro_avg {'precision': 0.9893008957140929, 'recall': 0.989219334592384, 'f1-score': 0.9892443499922441, 'support': 10182} weighted_avg {'precision': 0.9895162510741142, 'recall': 0.9894912590846592, 'f1-score': 0.9894888923303377, 'support': 10182}
 
time = 9.70 secondes

Val loss 0.8286262966030848 accuracy 0.8922261595726013 macro_avg {'precision': 0.8920626083757293, 'recall': 0.8898431108750622, 'f1-score': 0.8901885067296572, 'support': 1132} weighted_avg {'precision': 0.8941981752858044, 'recall': 0.892226148409894, 'f1-score': 0.8925095782788942, 'support': 1132}
 
----------
Epoch 29/40
time = 278.14 secondes

Train loss 0.042693288530286304 accuracy 0.9934197664260864 macro_avg {'precision': 0.9931593834422193, 'recall': 0.9930046708654269, 'f1-score': 0.9930777237697157, 'support': 10182} weighted_avg {'precision': 0.9934262676083435, 'recall': 0.9934197603614221, 'f1-score': 0.9934189044757675, 'support': 10182}
 
time = 9.46 secondes

Val loss 1.0865190400549642 accuracy 0.8710247278213501 macro_avg {'precision': 0.8696396989809463, 'recall': 0.8664882396267138, 'f1-score': 0.8647998514708123, 'support': 1132} weighted_avg {'precision': 0.8780360348767766, 'recall': 0.8710247349823321, 'f1-score': 0.8717313737357469, 'support': 1132}
 
----------
Epoch 30/40
time = 268.30 secondes

Train loss 0.03833233322727311 accuracy 0.993714451789856 macro_avg {'precision': 0.9935142135167083, 'recall': 0.9933602365837686, 'f1-score': 0.9934316979637879, 'support': 10182} weighted_avg {'precision': 0.9937233176190068, 'recall': 0.9937143979571793, 'f1-score': 0.9937134892828171, 'support': 10182}
 
time = 10.22 secondes

Val loss 1.0084480343389708 accuracy 0.8904593586921692 macro_avg {'precision': 0.8921687433008703, 'recall': 0.8868925041181461, 'f1-score': 0.886532333503949, 'support': 1132} weighted_avg {'precision': 0.8954961131855683, 'recall': 0.8904593639575972, 'f1-score': 0.8902245529586917, 'support': 1132}
 
----------
Epoch 31/40
time = 267.13 secondes

Train loss 0.034793197356508127 accuracy 0.9943037033081055 macro_avg {'precision': 0.9941862220608637, 'recall': 0.9940264222129344, 'f1-score': 0.9940909968773903, 'support': 10182} weighted_avg {'precision': 0.9943239850337378, 'recall': 0.9943036731486937, 'f1-score': 0.9943015612405861, 'support': 10182}
 
time = 10.12 secondes

Val loss 1.112138490133462 accuracy 0.8692579865455627 macro_avg {'precision': 0.8744222069876215, 'recall': 0.8682416107720817, 'f1-score': 0.8663995409458665, 'support': 1132} weighted_avg {'precision': 0.8791424232061928, 'recall': 0.8692579505300353, 'f1-score': 0.8690766087570917, 'support': 1132}
 
----------
Epoch 32/40
time = 269.02 secondes

Train loss 0.03443612277483133 accuracy 0.9947947859764099 macro_avg {'precision': 0.9947926806775689, 'recall': 0.9946978720813601, 'f1-score': 0.9947425829359066, 'support': 10182} weighted_avg {'precision': 0.9948013964126058, 'recall': 0.9947947358082891, 'f1-score': 0.9947953949214657, 'support': 10182}
 
time = 9.68 secondes

Val loss 1.0686080368367084 accuracy 0.8860424160957336 macro_avg {'precision': 0.8933248870840593, 'recall': 0.8856388811209998, 'f1-score': 0.8866430361022761, 'support': 1132} weighted_avg {'precision': 0.8966822985320374, 'recall': 0.8860424028268551, 'f1-score': 0.8887957230178406, 'support': 1132}
 
----------
Epoch 33/40
time = 269.58 secondes

Train loss 0.03594233766428088 accuracy 0.9940090775489807 macro_avg {'precision': 0.9939388624259393, 'recall': 0.9934965244365553, 'f1-score': 0.993689101341797, 'support': 10182} weighted_avg {'precision': 0.9940562450374862, 'recall': 0.9940090355529365, 'f1-score': 0.9940064188525498, 'support': 10182}
 
time = 8.86 secondes

Val loss 0.9829691144938332 accuracy 0.8878092169761658 macro_avg {'precision': 0.8891798794476568, 'recall': 0.8861222764860702, 'f1-score': 0.8858277227351079, 'support': 1132} weighted_avg {'precision': 0.8920031689670415, 'recall': 0.8878091872791519, 'f1-score': 0.888066605472493, 'support': 1132}
 
----------
Epoch 34/40
time = 269.54 secondes

Train loss 0.02380185796292084 accuracy 0.995776891708374 macro_avg {'precision': 0.9954563564060889, 'recall': 0.995517643503596, 'f1-score': 0.9954810330723625, 'support': 10182} weighted_avg {'precision': 0.9957888195095518, 'recall': 0.9957768611274799, 'f1-score': 0.9957776132746164, 'support': 10182}
 
time = 9.30 secondes

Val loss 0.9783166758719181 accuracy 0.8895759582519531 macro_avg {'precision': 0.8884482521926402, 'recall': 0.8882273604403123, 'f1-score': 0.887342238321024, 'support': 1132} weighted_avg {'precision': 0.8929571334902512, 'recall': 0.8895759717314488, 'f1-score': 0.8902293657718362, 'support': 1132}
 
----------
Epoch 35/40
time = 272.75 secondes

Train loss 0.0161695620952733 accuracy 0.9969554543495178 macro_avg {'precision': 0.9967278444708914, 'recall': 0.9967310246021258, 'f1-score': 0.9967264394412926, 'support': 10182} weighted_avg {'precision': 0.9969640356332456, 'recall': 0.9969554115105087, 'f1-score': 0.99695665043701, 'support': 10182}
 
time = 10.26 secondes

Val loss 1.0780180258629577 accuracy 0.8825088143348694 macro_avg {'precision': 0.8839500930196775, 'recall': 0.8790855591313231, 'f1-score': 0.880174215399024, 'support': 1132} weighted_avg {'precision': 0.8859021145710149, 'recall': 0.8825088339222615, 'f1-score': 0.8829076005606363, 'support': 1132}
 
----------
Epoch 36/40
time = 271.14 secondes

Train loss 0.015228186850056244 accuracy 0.9971518516540527 macro_avg {'precision': 0.9968535448087319, 'recall': 0.9969667162412597, 'f1-score': 0.996907082720573, 'support': 10182} weighted_avg {'precision': 0.9971580967098492, 'recall': 0.9971518365743469, 'f1-score': 0.99715201821696, 'support': 10182}
 
time = 9.14 secondes

Val loss 1.0432412275899174 accuracy 0.8842756152153015 macro_avg {'precision': 0.8909089927244175, 'recall': 0.8820056973011134, 'f1-score': 0.8832067471466705, 'support': 1132} weighted_avg {'precision': 0.894209559948558, 'recall': 0.8842756183745583, 'f1-score': 0.8864421059701602, 'support': 1132}
 
----------
Epoch 37/40
time = 269.65 secondes

Train loss 0.009700974534582367 accuracy 0.997741162776947 macro_avg {'precision': 0.9975083745076679, 'recall': 0.9976170979059311, 'f1-score': 0.9975607259869189, 'support': 10182} weighted_avg {'precision': 0.9977473727818119, 'recall': 0.9977411117658613, 'f1-score': 0.9977423386955673, 'support': 10182}
 
time = 8.26 secondes

Val loss 0.9923456868218893 accuracy 0.8895759582519531 macro_avg {'precision': 0.8916788010241298, 'recall': 0.888738713127226, 'f1-score': 0.8893389452876029, 'support': 1132} weighted_avg {'precision': 0.8934869966237, 'recall': 0.8895759717314488, 'f1-score': 0.8905849219208095, 'support': 1132}
 
----------
Epoch 38/40
time = 269.41 secondes

Train loss 0.013814652013327586 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972670824504778, 'recall': 0.9972124277736413, 'f1-score': 0.997235465715295, 'support': 10182} weighted_avg {'precision': 0.9973566167726301, 'recall': 0.997348261638185, 'f1-score': 0.9973482441873547, 'support': 10182}
 
time = 10.13 secondes

Val loss 1.0458336785831448 accuracy 0.8913427591323853 macro_avg {'precision': 0.894252425882365, 'recall': 0.8898935282825999, 'f1-score': 0.8903412963890007, 'support': 1132} weighted_avg {'precision': 0.8943383088268357, 'recall': 0.8913427561837456, 'f1-score': 0.891197114974505, 'support': 1132}
 
----------
Epoch 39/40
time = 268.90 secondes

Train loss 0.006351115320463789 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986386830652456, 'recall': 0.9986042862309311, 'f1-score': 0.9986205941413784, 'support': 10182} weighted_avg {'precision': 0.9986262964636551, 'recall': 0.998625024553133, 'f1-score': 0.9986248411005522, 'support': 10182}
 
time = 9.09 secondes

Val loss 1.030388564605666 accuracy 0.8939929604530334 macro_avg {'precision': 0.8939138733813274, 'recall': 0.8916673865286396, 'f1-score': 0.8909608902771475, 'support': 1132} weighted_avg {'precision': 0.8953648293167662, 'recall': 0.8939929328621908, 'f1-score': 0.89280225748849, 'support': 1132}
 
----------
Epoch 40/40
time = 267.63 secondes

Train loss 0.004886388643355996 accuracy 0.998821496963501 macro_avg {'precision': 0.998842322450923, 'recall': 0.9987585434893745, 'f1-score': 0.9987990879072773, 'support': 10182} weighted_avg {'precision': 0.9988233476440929, 'recall': 0.9988214496169712, 'f1-score': 0.9988211739315606, 'support': 10182}
 
time = 9.51 secondes

Val loss 1.024214681317203 accuracy 0.898409903049469 macro_avg {'precision': 0.8988242943699383, 'recall': 0.895355925123396, 'f1-score': 0.8956236569223973, 'support': 1132} weighted_avg {'precision': 0.9000084920113728, 'recall': 0.8984098939929329, 'f1-score': 0.8978917047450165, 'support': 1132}
 
----------
best_accuracy 0.898409903049469 best_epoch 40 macro_avg {'precision': 0.8988242943699383, 'recall': 0.895355925123396, 'f1-score': 0.8956236569223973, 'support': 1132} weighted_avg {'precision': 0.9000084920113728, 'recall': 0.8984098939929329, 'f1-score': 0.8978917047450165, 'support': 1132}

average train time 267.24365961551666

average val time 9.073118710517884
 
time = 54.84 secondes

test_accuracy 0.840945303440094 macro_avg {'precision': 0.8353044018867128, 'recall': 0.8288933810686923, 'f1-score': 0.8289482615553523, 'support': 7532} weighted_avg {'precision': 0.842067083156098, 'recall': 0.8409453000531067, 'f1-score': 0.8388305295095079, 'support': 7532}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_3
----------
Epoch 1/40
time = 319.96 secondes

Train loss 0.27615595984834806 micro_f1_score 0.5973618090452262 
 
time = 22.00 secondes

Val loss 0.2571531783361904 micro_f1_score 0.5832687838884587
 
----------
Epoch 2/40
time = 289.69 secondes

Train loss 0.18214049025161846 micro_f1_score 0.7477309461643665 
 
time = 18.75 secondes

Val loss 0.20561386950191904 micro_f1_score 0.6935286935286935
 
----------
Epoch 3/40
time = 290.71 secondes

Train loss 0.15619713379456115 micro_f1_score 0.7920209287115761 
 
time = 22.17 secondes

Val loss 0.2010176297826845 micro_f1_score 0.7102877414268821
 
----------
Epoch 4/40
time = 298.05 secondes

Train loss 0.13907163915064957 micro_f1_score 0.8210406411456004 
 
time = 17.96 secondes

Val loss 0.20378457510569056 micro_f1_score 0.7155607295304618
 
----------
Epoch 5/40
time = 292.40 secondes

Train loss 0.12477858615116225 micro_f1_score 0.8436537526341386 
 
time = 20.27 secondes

Val loss 0.20524945183367024 micro_f1_score 0.7241379310344828
 
----------
Epoch 6/40
time = 292.58 secondes

Train loss 0.11272624593043515 micro_f1_score 0.8637151029287355 
 
time = 18.94 secondes

Val loss 0.21861435839387236 micro_f1_score 0.7217194570135748
 
----------
Epoch 7/40
time = 289.39 secondes

Train loss 0.10282169884188218 micro_f1_score 0.8762622215098574 
 
time = 18.66 secondes

Val loss 0.22751868552848942 micro_f1_score 0.7177802117561153
 
----------
Epoch 8/40
time = 292.11 secondes

Train loss 0.09119598091588364 micro_f1_score 0.8940980485483103 
 
time = 20.78 secondes

Val loss 0.2417668620826768 micro_f1_score 0.7261992619926199
 
----------
Epoch 9/40
time = 286.68 secondes

Train loss 0.08133177531480386 micro_f1_score 0.9082938388625592 
 
time = 17.91 secondes

Val loss 0.2548159336457487 micro_f1_score 0.7342888643880927
 
----------
Epoch 10/40
time = 283.44 secondes

Train loss 0.07263106039792366 micro_f1_score 0.9185900455330507 
 
time = 17.25 secondes

Val loss 0.27528746939096294 micro_f1_score 0.7312223858615613
 
----------
Epoch 11/40
time = 287.77 secondes

Train loss 0.06182332940919845 micro_f1_score 0.9327763897564022 
 
time = 16.80 secondes

Val loss 0.2790841319766201 micro_f1_score 0.7435804701627486
 
----------
Epoch 12/40
time = 277.74 secondes

Train loss 0.055554568648615195 micro_f1_score 0.9401742648202894 
 
time = 21.00 secondes

Val loss 0.30324923760089717 micro_f1_score 0.7356154406409323
 
----------
Epoch 13/40
time = 290.43 secondes

Train loss 0.047134798520815195 micro_f1_score 0.9490961173692565 
 
time = 22.17 secondes

Val loss 0.3301053736053529 micro_f1_score 0.7348567283278927
 
----------
Epoch 14/40
time = 283.97 secondes

Train loss 0.042648177159329254 micro_f1_score 0.9547789148484263 
 
time = 18.82 secondes

Val loss 0.3516197731016112 micro_f1_score 0.7334538878842676
 
----------
Epoch 15/40
time = 288.32 secondes

Train loss 0.037431356300146795 micro_f1_score 0.9599876766665383 
 
time = 17.71 secondes

Val loss 0.38386223623987104 micro_f1_score 0.7232549982462294
 
----------
Epoch 16/40
time = 278.32 secondes

Train loss 0.03323935210979585 micro_f1_score 0.9647963105303612 
 
time = 18.86 secondes

Val loss 0.3996722173006808 micro_f1_score 0.7289261979713186
 
----------
Epoch 17/40
time = 290.27 secondes

Train loss 0.028714586159598234 micro_f1_score 0.9706265817930823 
 
time = 17.09 secondes

Val loss 0.40655768345125387 micro_f1_score 0.728051391862955
 
----------
Epoch 18/40
time = 274.91 secondes

Train loss 0.02501945486832368 micro_f1_score 0.9728735632183908 
 
time = 16.26 secondes

Val loss 0.4143751703324865 micro_f1_score 0.7210884353741496
 
----------
Epoch 19/40
time = 260.97 secondes

Train loss 0.023011471305529142 micro_f1_score 0.9759644825474587 
 
time = 16.19 secondes

Val loss 0.4271211984460471 micro_f1_score 0.7274026438013578
 
----------
Epoch 20/40
time = 262.80 secondes

Train loss 0.021631944622961922 micro_f1_score 0.9776333397056012 
 
time = 16.00 secondes

Val loss 0.43828258858840974 micro_f1_score 0.7317939609236236
 
----------
Epoch 21/40
time = 266.08 secondes

Train loss 0.01744340148115707 micro_f1_score 0.9813555436692901 
 
time = 17.32 secondes

Val loss 0.46036211022588075 micro_f1_score 0.7304964539007092
 
----------
Epoch 22/40
time = 264.13 secondes

Train loss 0.0176793438774693 micro_f1_score 0.9796884544899206 
 
time = 16.40 secondes

Val loss 0.4848847191353313 micro_f1_score 0.7242477876106195
 
----------
Epoch 23/40
time = 260.56 secondes

Train loss 0.015846387524619754 micro_f1_score 0.9838192642344681 
 
time = 16.06 secondes

Val loss 0.49271931963377313 micro_f1_score 0.7259206798866856
 
----------
Epoch 24/40
time = 263.28 secondes

Train loss 0.013778723007907591 micro_f1_score 0.9852543341588874 
 
time = 16.31 secondes

Val loss 0.49928065963455887 micro_f1_score 0.7321814254859611
 
----------
Epoch 25/40
time = 265.22 secondes

Train loss 0.011980020521134048 micro_f1_score 0.9875762195121951 
 
time = 15.96 secondes

Val loss 0.5124024064814459 micro_f1_score 0.7277936962750716
 
----------
Epoch 26/40
time = 268.75 secondes

Train loss 0.012464025963355026 micro_f1_score 0.9868882451593229 
 
time = 15.98 secondes

Val loss 0.542937565655982 micro_f1_score 0.7241620111731845
 
----------
Epoch 27/40
time = 266.68 secondes

Train loss 0.010560229026547555 micro_f1_score 0.9887683228631259 
 
time = 16.15 secondes

Val loss 0.5370004515423149 micro_f1_score 0.7237609329446063
 
----------
Epoch 28/40
time = 269.67 secondes

Train loss 0.009929597727062395 micro_f1_score 0.9897119341563786 
 
time = 16.64 secondes

Val loss 0.5680794472821423 micro_f1_score 0.7238624522403613
 
----------
Epoch 29/40
time = 261.87 secondes

Train loss 0.00862721505240319 micro_f1_score 0.9910568177493626 
 
time = 18.16 secondes

Val loss 0.5909259542822838 micro_f1_score 0.7240760674560459
 
----------
Epoch 30/40
time = 268.22 secondes

Train loss 0.00786627698006349 micro_f1_score 0.991892200525294 
 
time = 15.86 secondes

Val loss 0.5610802779432202 micro_f1_score 0.7288256227758008
 
----------
Epoch 31/40
time = 262.04 secondes

Train loss 0.007530388874350522 micro_f1_score 0.9919695528068505 
 
time = 15.74 secondes

Val loss 0.5737703656319713 micro_f1_score 0.7252669039145907
 
----------
Epoch 32/40
time = 264.18 secondes

Train loss 0.005940373309992235 micro_f1_score 0.9938421772844762 
 
time = 16.25 secondes

Val loss 0.6120084670723461 micro_f1_score 0.7243125904486252
 
----------
Epoch 33/40
time = 254.77 secondes

Train loss 0.005374986252013719 micro_f1_score 0.9946414319917912 
 
time = 16.41 secondes

Val loss 0.6082874284904511 micro_f1_score 0.728710025152713
 
----------
Epoch 34/40
time = 263.84 secondes

Train loss 0.0054021742810086305 micro_f1_score 0.9938762314099882 
 
time = 15.79 secondes

Val loss 0.6071082290078773 micro_f1_score 0.7264116575591986
 
----------
Epoch 35/40
time = 261.82 secondes

Train loss 0.004828440932560789 micro_f1_score 0.9947910725827915 
 
time = 15.82 secondes

Val loss 0.5980116066629769 micro_f1_score 0.7333570665717336
 
----------
Epoch 36/40
time = 262.69 secondes

Train loss 0.003984199239017995 micro_f1_score 0.9957469431153642 
 
time = 16.48 secondes

Val loss 0.6194874365798763 micro_f1_score 0.7212643678160919
 
----------
Epoch 37/40
time = 260.36 secondes

Train loss 0.002545627001876841 micro_f1_score 0.9968840249278006 
 
time = 16.59 secondes

Val loss 0.6333290045378638 micro_f1_score 0.7275960170697012
 
----------
Epoch 38/40
time = 259.74 secondes

Train loss 0.0024381367209145113 micro_f1_score 0.9973797136672616 
 
time = 16.25 secondes

Val loss 0.6303299941488953 micro_f1_score 0.7284436493738821
 
----------
Epoch 39/40
time = 262.78 secondes

Train loss 0.0023147244064877486 micro_f1_score 0.9975687585473333 
 
time = 15.84 secondes

Val loss 0.6312772861269654 micro_f1_score 0.7292263610315186
 
----------
Epoch 40/40
time = 260.23 secondes

Train loss 0.0015398866081816343 micro_f1_score 0.9984804740920831 
 
time = 15.74 secondes

Val loss 0.640485622110914 micro_f1_score 0.724937566892615
 
----------
best_f1_socre 0.7435804701627486 best_epoch 11

average train time 274.93581340909003

average val time 17.532555669546127
 
time = 17.87 secondes

test_f1_score 0.7197452229299363

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_3
----------
Epoch 1/40
time = 279.87 secondes

Train loss 0.27703949915798937 micro_f1_score 0.5866799927312375 
 
time = 19.30 secondes

Val loss 0.2356565997737353 micro_f1_score 0.6270987895353378
 
----------
Epoch 2/40
time = 265.80 secondes

Train loss 0.17824740110821016 micro_f1_score 0.7548878370034988 
 
time = 16.11 secondes

Val loss 0.1938814788323934 micro_f1_score 0.7098283931357254
 
----------
Epoch 3/40
time = 261.45 secondes

Train loss 0.14975674024170582 micro_f1_score 0.8025884732052578 
 
time = 16.06 secondes

Val loss 0.19116111514998263 micro_f1_score 0.7215931276844981
 
----------
Epoch 4/40
time = 277.69 secondes

Train loss 0.1299264086494306 micro_f1_score 0.8348321824313474 
 
time = 16.11 secondes

Val loss 0.1911967021764302 micro_f1_score 0.7385444743935311
 
----------
Epoch 5/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 7.02 GiB already allocated; 122.31 MiB free; 7.12 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 6.99 GiB already allocated; 170.31 MiB free; 7.07 GiB reserved in total by PyTorch)
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 6.99 GiB already allocated; 170.31 MiB free; 7.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 6.99 GiB already allocated; 170.31 MiB free; 7.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 6.99 GiB already allocated; 170.31 MiB free; 7.07 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_none_4
----------
Epoch 1/40
time = 275.41 secondes

Train loss 1.2604872979913813 accuracy 0.6802200078964233 macro_avg {'precision': 0.6920430013151114, 'recall': 0.6650882452181803, 'f1-score': 0.6574640510163511, 'support': 10182} weighted_avg {'precision': 0.6969198775074917, 'recall': 0.6802199960714987, 'f1-score': 0.671667090057951, 'support': 10182}
 
time = 8.64 secondes

Val loss 0.6413290349530502 accuracy 0.8268551230430603 macro_avg {'precision': 0.8308895786621837, 'recall': 0.8226127341858849, 'f1-score': 0.8119564729206672, 'support': 1132} weighted_avg {'precision': 0.8367802337159359, 'recall': 0.8268551236749117, 'f1-score': 0.8197033539662887, 'support': 1132}
 
----------
Epoch 2/40
time = 264.40 secondes

Train loss 0.44310131765539457 accuracy 0.8744844198226929 macro_avg {'precision': 0.8653897565649201, 'recall': 0.8642832832057559, 'f1-score': 0.8634152665501202, 'support': 10182} weighted_avg {'precision': 0.8724835606444724, 'recall': 0.8744843842074249, 'f1-score': 0.8723844717226285, 'support': 10182}
 
time = 9.10 secondes

Val loss 0.45290038519552056 accuracy 0.8816254734992981 macro_avg {'precision': 0.8860915846963294, 'recall': 0.8780090379850636, 'f1-score': 0.8774299719608092, 'support': 1132} weighted_avg {'precision': 0.890630062402571, 'recall': 0.8816254416961131, 'f1-score': 0.8815115580444227, 'support': 1132}
 
----------
Epoch 3/40
time = 277.41 secondes

Train loss 0.26786400053030235 accuracy 0.9225103259086609 macro_avg {'precision': 0.9178101885070804, 'recall': 0.9172043229391255, 'f1-score': 0.9173329370632997, 'support': 10182} weighted_avg {'precision': 0.9224680899856548, 'recall': 0.9225103123158515, 'f1-score': 0.9223182716440185, 'support': 10182}
 
time = 9.56 secondes

Val loss 0.4724947532743845 accuracy 0.8842756152153015 macro_avg {'precision': 0.892535400029203, 'recall': 0.883987327898583, 'f1-score': 0.8826591379178597, 'support': 1132} weighted_avg {'precision': 0.8935173656369766, 'recall': 0.8842756183745583, 'f1-score': 0.883167476262324, 'support': 1132}
 
----------
Epoch 4/40
time = 287.46 secondes

Train loss 0.20175112969625092 accuracy 0.9451974630355835 macro_avg {'precision': 0.942482049186169, 'recall': 0.9419379315122132, 'f1-score': 0.9420773314650768, 'support': 10182} weighted_avg {'precision': 0.9455734128948542, 'recall': 0.9451974071891573, 'f1-score': 0.945261407137198, 'support': 10182}
 
time = 11.04 secondes

Val loss 0.4839527816052588 accuracy 0.9028268456459045 macro_avg {'precision': 0.9062385069056896, 'recall': 0.9041684846413978, 'f1-score': 0.903103517595228, 'support': 1132} weighted_avg {'precision': 0.9048216610200919, 'recall': 0.9028268551236749, 'f1-score': 0.9015491576743688, 'support': 1132}
 
----------
Epoch 5/40
time = 285.58 secondes

Train loss 0.1826463286546344 accuracy 0.9558044075965881 macro_avg {'precision': 0.9542164262860553, 'recall': 0.9536994145951715, 'f1-score': 0.9538881446712694, 'support': 10182} weighted_avg {'precision': 0.955717034248655, 'recall': 0.9558043606364172, 'f1-score': 0.9556923955431808, 'support': 10182}
 
time = 9.96 secondes

Val loss 0.4918918562528323 accuracy 0.9116607904434204 macro_avg {'precision': 0.9137894763642039, 'recall': 0.9101146469889194, 'f1-score': 0.9093699887968535, 'support': 1132} weighted_avg {'precision': 0.9149767855068972, 'recall': 0.911660777385159, 'f1-score': 0.91093092850487, 'support': 1132}
 
----------
Epoch 6/40
time = 281.27 secondes

Train loss 0.15977422853517295 accuracy 0.9629738926887512 macro_avg {'precision': 0.9618770074138103, 'recall': 0.9617130415244789, 'f1-score': 0.9617234351133686, 'support': 10182} weighted_avg {'precision': 0.9630767307891989, 'recall': 0.9629738754665095, 'f1-score': 0.9629563131021173, 'support': 10182}
 
time = 9.60 secondes

Val loss 0.5261461377958767 accuracy 0.9107773900032043 macro_avg {'precision': 0.9172678175662627, 'recall': 0.9107328163031412, 'f1-score': 0.9114635764979095, 'support': 1132} weighted_avg {'precision': 0.9175263180679907, 'recall': 0.9107773851590106, 'f1-score': 0.9114961017873128, 'support': 1132}
 
----------
Epoch 7/40
time = 285.41 secondes

Train loss 0.14754113529085472 accuracy 0.9674916863441467 macro_avg {'precision': 0.9665168699687265, 'recall': 0.9665415329143603, 'f1-score': 0.9664954320756577, 'support': 10182} weighted_avg {'precision': 0.9675269887461974, 'recall': 0.9674916519347869, 'f1-score': 0.9674787730100352, 'support': 10182}
 
time = 10.38 secondes

Val loss 0.46145478147573926 accuracy 0.9125441908836365 macro_avg {'precision': 0.9167821530513425, 'recall': 0.912793502983021, 'f1-score': 0.9124489604761832, 'support': 1132} weighted_avg {'precision': 0.9161844803219796, 'recall': 0.9125441696113075, 'f1-score': 0.912223933674039, 'support': 1132}
 
----------
Epoch 8/40
time = 286.44 secondes

Train loss 0.14671232483118188 accuracy 0.9700452089309692 macro_avg {'precision': 0.9694248704612487, 'recall': 0.9693757884089171, 'f1-score': 0.9693636405833868, 'support': 10182} weighted_avg {'precision': 0.970149197870649, 'recall': 0.9700451777646828, 'f1-score': 0.9700625657048179, 'support': 10182}
 
time = 11.40 secondes

Val loss 0.6021041392699592 accuracy 0.9019434452056885 macro_avg {'precision': 0.9084029628848496, 'recall': 0.905747560530199, 'f1-score': 0.9030375601968741, 'support': 1132} weighted_avg {'precision': 0.9096359831629166, 'recall': 0.9019434628975265, 'f1-score': 0.9014801337232369, 'support': 1132}
 
----------
Epoch 9/40
time = 286.13 secondes

Train loss 0.12656163797609463 accuracy 0.9735808372497559 macro_avg {'precision': 0.9730107810605219, 'recall': 0.9732490686211897, 'f1-score': 0.9730783660101799, 'support': 10182} weighted_avg {'precision': 0.9737413130385426, 'recall': 0.9735808289137694, 'f1-score': 0.9736169723638223, 'support': 10182}
 
time = 8.99 secondes

Val loss 0.6237937843440999 accuracy 0.9028268456459045 macro_avg {'precision': 0.9089007612851617, 'recall': 0.9067952813311339, 'f1-score': 0.9049390569294257, 'support': 1132} weighted_avg {'precision': 0.9085608459303127, 'recall': 0.9028268551236749, 'f1-score': 0.9026662400999437, 'support': 1132}
 
----------
Epoch 10/40
time = 288.32 secondes

Train loss 0.13670904041000925 accuracy 0.9725987315177917 macro_avg {'precision': 0.9713372979154764, 'recall': 0.9714537947226433, 'f1-score': 0.9713737481438642, 'support': 10182} weighted_avg {'precision': 0.9726389718461783, 'recall': 0.9725987035945787, 'f1-score': 0.9725967433859782, 'support': 10182}
 
time = 10.53 secondes

Val loss 0.6004710526125256 accuracy 0.9107773900032043 macro_avg {'precision': 0.9205080395742892, 'recall': 0.9095527768095797, 'f1-score': 0.9116496912639102, 'support': 1132} weighted_avg {'precision': 0.9182679207816733, 'recall': 0.9107773851590106, 'f1-score': 0.9112513632120084, 'support': 1132}
 
----------
Epoch 11/40
time = 283.75 secondes

Train loss 0.12305213026767739 accuracy 0.9769200682640076 macro_avg {'precision': 0.975953007085454, 'recall': 0.9763778966608884, 'f1-score': 0.9761215489469279, 'support': 10182} weighted_avg {'precision': 0.976965150279897, 'recall': 0.9769200549990179, 'f1-score': 0.9768997468061076, 'support': 10182}
 
time = 9.69 secondes

Val loss 0.6362852146424777 accuracy 0.9116607904434204 macro_avg {'precision': 0.9212656416457546, 'recall': 0.9129071138675708, 'f1-score': 0.914446416225184, 'support': 1132} weighted_avg {'precision': 0.9185032516911154, 'recall': 0.911660777385159, 'f1-score': 0.9124550299275741, 'support': 1132}
 
----------
Epoch 12/40
time = 282.83 secondes

Train loss 0.11186760125693272 accuracy 0.9786878824234009 macro_avg {'precision': 0.9775156403492377, 'recall': 0.9770127188123311, 'f1-score': 0.977231551157628, 'support': 10182} weighted_avg {'precision': 0.9786953638187493, 'recall': 0.9786878805735612, 'f1-score': 0.9786600935171711, 'support': 10182}
 
time = 10.35 secondes

Val loss 0.62961409682376 accuracy 0.9116607904434204 macro_avg {'precision': 0.919303578903038, 'recall': 0.9071305528119327, 'f1-score': 0.9104304529271019, 'support': 1132} weighted_avg {'precision': 0.9155140443170086, 'recall': 0.911660777385159, 'f1-score': 0.9109691240375762, 'support': 1132}
 
----------
Epoch 13/40
time = 283.71 secondes

Train loss 0.10436662120724118 accuracy 0.9807503819465637 macro_avg {'precision': 0.9806776186576867, 'recall': 0.9803463923876397, 'f1-score': 0.980491574794554, 'support': 10182} weighted_avg {'precision': 0.9808381055985831, 'recall': 0.9807503437438617, 'f1-score': 0.9807743503744977, 'support': 10182}
 
time = 9.71 secondes

Val loss 0.700476229942812 accuracy 0.9045936465263367 macro_avg {'precision': 0.9078344589387838, 'recall': 0.906243622670833, 'f1-score': 0.9049069186777248, 'support': 1132} weighted_avg {'precision': 0.9100023001640188, 'recall': 0.9045936395759717, 'f1-score': 0.9051762374040904, 'support': 1132}
 
----------
Epoch 14/40
time = 284.39 secondes

Train loss 0.08253977796206016 accuracy 0.9828128218650818 macro_avg {'precision': 0.9825920341739007, 'recall': 0.9820417013731539, 'f1-score': 0.9822830142592345, 'support': 10182} weighted_avg {'precision': 0.9828441702119943, 'recall': 0.9828128069141623, 'f1-score': 0.98279668988684, 'support': 10182}
 
time = 10.10 secondes

Val loss 0.6693192473692658 accuracy 0.9134275913238525 macro_avg {'precision': 0.9147902397428247, 'recall': 0.9135297633315348, 'f1-score': 0.9123889230367335, 'support': 1132} weighted_avg {'precision': 0.9162573731326737, 'recall': 0.9134275618374559, 'f1-score': 0.9130176056840483, 'support': 1132}
 
----------
Epoch 15/40
time = 285.46 secondes

Train loss 0.09904570441008283 accuracy 0.9827145934104919 macro_avg {'precision': 0.9825683764767413, 'recall': 0.9821228744716436, 'f1-score': 0.9823132901744694, 'support': 10182} weighted_avg {'precision': 0.9827778955502009, 'recall': 0.9827145943822432, 'f1-score': 0.9827172839247157, 'support': 10182}
 
time = 9.46 secondes

Val loss 0.6964537488109298 accuracy 0.9187279343605042 macro_avg {'precision': 0.9199228843400841, 'recall': 0.9201224176006495, 'f1-score': 0.9183352833988483, 'support': 1132} weighted_avg {'precision': 0.9201188623289472, 'recall': 0.9187279151943463, 'f1-score': 0.9177069648795411, 'support': 1132}
 
----------
Epoch 16/40
time = 282.75 secondes

Train loss 0.07977469544645287 accuracy 0.9849734902381897 macro_avg {'precision': 0.9845238182019382, 'recall': 0.9846458149553277, 'f1-score': 0.9845699121241935, 'support': 10182} weighted_avg {'precision': 0.9849701972966354, 'recall': 0.9849734826163818, 'f1-score': 0.9849568698895396, 'support': 10182}
 
time = 9.28 secondes

Val loss 0.7005075536308397 accuracy 0.9054770469665527 macro_avg {'precision': 0.9137280527971473, 'recall': 0.9111581660254788, 'f1-score': 0.9091191297021555, 'support': 1132} weighted_avg {'precision': 0.9146033643000708, 'recall': 0.9054770318021201, 'f1-score': 0.9064868812618554, 'support': 1132}
 
----------
Epoch 17/40
time = 287.22 secondes

Train loss 0.09223545199403396 accuracy 0.9834021329879761 macro_avg {'precision': 0.9834714583539037, 'recall': 0.9834605224871915, 'f1-score': 0.9834395450339917, 'support': 10182} weighted_avg {'precision': 0.9833966533600388, 'recall': 0.9834020821056767, 'f1-score': 0.9833725869300038, 'support': 10182}
 
time = 10.59 secondes

Val loss 0.6445393324167629 accuracy 0.9187279343605042 macro_avg {'precision': 0.9236889888424203, 'recall': 0.9193048107493021, 'f1-score': 0.9201455454543277, 'support': 1132} weighted_avg {'precision': 0.9233428412294729, 'recall': 0.9187279151943463, 'f1-score': 0.9196015037217313, 'support': 1132}
 
----------
Epoch 18/40
time = 286.71 secondes

Train loss 0.09088752444929372 accuracy 0.9853663444519043 macro_avg {'precision': 0.9852531616376806, 'recall': 0.9848949713362926, 'f1-score': 0.9850515563237853, 'support': 10182} weighted_avg {'precision': 0.9853984653625706, 'recall': 0.9853663327440582, 'f1-score': 0.9853606804934287, 'support': 10182}
 
time = 8.74 secondes

Val loss 0.5878088827483506 accuracy 0.9143109321594238 macro_avg {'precision': 0.9174118616307902, 'recall': 0.9153170627201627, 'f1-score': 0.9149826391671093, 'support': 1132} weighted_avg {'precision': 0.9174532467743866, 'recall': 0.9143109540636042, 'f1-score': 0.9144748075061779, 'support': 1132}
 
----------
Epoch 19/40
time = 284.14 secondes

Train loss 0.07720848730261974 accuracy 0.9852681756019592 macro_avg {'precision': 0.9846033824870508, 'recall': 0.9847971247239915, 'f1-score': 0.9846719798507545, 'support': 10182} weighted_avg {'precision': 0.9853249109944523, 'recall': 0.985268120212139, 'f1-score': 0.9852680835321139, 'support': 10182}
 
time = 10.56 secondes

Val loss 0.7159055777285149 accuracy 0.9072438478469849 macro_avg {'precision': 0.9168902049912744, 'recall': 0.9063876097850277, 'f1-score': 0.9092797306771796, 'support': 1132} weighted_avg {'precision': 0.9142029587384326, 'recall': 0.907243816254417, 'f1-score': 0.9081488846015011, 'support': 1132}
 
----------
Epoch 20/40
time = 285.48 secondes

Train loss 0.07221308644306138 accuracy 0.9869377613067627 macro_avg {'precision': 0.9861850377216375, 'recall': 0.9860054374925795, 'f1-score': 0.9860785175374851, 'support': 10182} weighted_avg {'precision': 0.9869486925366862, 'recall': 0.9869377332547633, 'f1-score': 0.9869266939568343, 'support': 10182}
 
time = 9.92 secondes

Val loss 0.6092867289668172 accuracy 0.9187279343605042 macro_avg {'precision': 0.9225531292590035, 'recall': 0.92135852804621, 'f1-score': 0.9210903005239226, 'support': 1132} weighted_avg {'precision': 0.9194034446478807, 'recall': 0.9187279151943463, 'f1-score': 0.9181146976742391, 'support': 1132}
 
----------
Epoch 21/40
time = 283.88 secondes

Train loss 0.06606402549752582 accuracy 0.9880180954933167 macro_avg {'precision': 0.987928389213943, 'recall': 0.9879335177893047, 'f1-score': 0.9879158695564014, 'support': 10182} weighted_avg {'precision': 0.9880295625368849, 'recall': 0.9880180711058731, 'f1-score': 0.9880082429204783, 'support': 10182}
 
time = 10.11 secondes

Val loss 0.7768703142187597 accuracy 0.9028268456459045 macro_avg {'precision': 0.9170056870784455, 'recall': 0.9065440716027642, 'f1-score': 0.9089452532849835, 'support': 1132} weighted_avg {'precision': 0.913851752983292, 'recall': 0.9028268551236749, 'f1-score': 0.9051245454948695, 'support': 1132}
 
----------
Epoch 22/40
time = 279.58 secondes

Train loss 0.07430018060681669 accuracy 0.9878216981887817 macro_avg {'precision': 0.9877200400602568, 'recall': 0.9876133714154959, 'f1-score': 0.9876574870344266, 'support': 10182} weighted_avg {'precision': 0.9878467163297566, 'recall': 0.9878216460420349, 'f1-score': 0.9878248334725253, 'support': 10182}
 
time = 10.12 secondes

Val loss 0.6866945809902768 accuracy 0.9134275913238525 macro_avg {'precision': 0.9174202106903744, 'recall': 0.9164199964549251, 'f1-score': 0.9157977704439709, 'support': 1132} weighted_avg {'precision': 0.9156379478103593, 'recall': 0.9134275618374559, 'f1-score': 0.9133663719752673, 'support': 1132}
 
----------
Epoch 23/40
time = 281.69 secondes

Train loss 0.052234022135140334 accuracy 0.990669846534729 macro_avg {'precision': 0.9905698119604208, 'recall': 0.9905857858785387, 'f1-score': 0.9905690160273718, 'support': 10182} weighted_avg {'precision': 0.9906923883835194, 'recall': 0.9906698094676881, 'f1-score': 0.9906722419431951, 'support': 10182}
 
time = 9.52 secondes

Val loss 0.8445677358210214 accuracy 0.8966431021690369 macro_avg {'precision': 0.9028779513241858, 'recall': 0.9010415456926573, 'f1-score': 0.8974350110183842, 'support': 1132} weighted_avg {'precision': 0.9051905767645255, 'recall': 0.8966431095406361, 'f1-score': 0.8961370926008054, 'support': 1132}
 
----------
Epoch 24/40
time = 283.46 secondes

Train loss 0.05930969379002976 accuracy 0.9907680749893188 macro_avg {'precision': 0.9907897137288166, 'recall': 0.990446723013241, 'f1-score': 0.9905992580565168, 'support': 10182} weighted_avg {'precision': 0.9907997912417952, 'recall': 0.9907680219996071, 'f1-score': 0.9907657113527162, 'support': 10182}
 
time = 9.74 secondes

Val loss 0.7833137580844931 accuracy 0.9010601043701172 macro_avg {'precision': 0.9128689947536296, 'recall': 0.90316356509361, 'f1-score': 0.9052636086554007, 'support': 1132} weighted_avg {'precision': 0.9099067346186742, 'recall': 0.901060070671378, 'f1-score': 0.9024696949267503, 'support': 1132}
 
----------
Epoch 25/40
time = 282.81 secondes

Train loss 0.0506032037440975 accuracy 0.9914555549621582 macro_avg {'precision': 0.9911240586663652, 'recall': 0.9910949116105947, 'f1-score': 0.9910991067135837, 'support': 10182} weighted_avg {'precision': 0.9914774453542299, 'recall': 0.9914555097230406, 'f1-score': 0.991456939059827, 'support': 10182}
 
time = 10.63 secondes

Val loss 0.778575630373101 accuracy 0.9081271886825562 macro_avg {'precision': 0.9124305772722316, 'recall': 0.9123665912865139, 'f1-score': 0.910651706366535, 'support': 1132} weighted_avg {'precision': 0.9123301880897895, 'recall': 0.9081272084805654, 'f1-score': 0.908333151501604, 'support': 1132}
 
----------
Epoch 26/40
time = 317.23 secondes

Train loss 0.054660003804222965 accuracy 0.991750180721283 macro_avg {'precision': 0.9918860415483304, 'recall': 0.991763056893262, 'f1-score': 0.9918066326114996, 'support': 10182} weighted_avg {'precision': 0.9917600002281453, 'recall': 0.9917501473187978, 'f1-score': 0.9917366532535673, 'support': 10182}
 
time = 12.62 secondes

Val loss 0.7120972469449658 accuracy 0.9090105891227722 macro_avg {'precision': 0.9163707146413376, 'recall': 0.9133901829699965, 'f1-score': 0.9124421318092903, 'support': 1132} weighted_avg {'precision': 0.9162197267300882, 'recall': 0.9090106007067138, 'f1-score': 0.9101336698957447, 'support': 1132}
 
----------
Epoch 27/40
time = 350.05 secondes

Train loss 0.05422083457442411 accuracy 0.9918484091758728 macro_avg {'precision': 0.9917938034794569, 'recall': 0.9918753542244115, 'f1-score': 0.9918289939734273, 'support': 10182} weighted_avg {'precision': 0.9918633416857277, 'recall': 0.991848359850717, 'f1-score': 0.9918502836827413, 'support': 10182}
 
time = 12.16 secondes

Val loss 0.7454162086991423 accuracy 0.9151943325996399 macro_avg {'precision': 0.918709713992591, 'recall': 0.9171741634068917, 'f1-score': 0.9160957227244471, 'support': 1132} weighted_avg {'precision': 0.9205026267946727, 'recall': 0.9151943462897526, 'f1-score': 0.9160708617717901, 'support': 1132}
 
----------
Epoch 28/40
time = 346.05 secondes

Train loss 0.0445795326695831 accuracy 0.9932233691215515 macro_avg {'precision': 0.9931660853614627, 'recall': 0.9932233046880616, 'f1-score': 0.9931853094785694, 'support': 10182} weighted_avg {'precision': 0.9932392511046193, 'recall': 0.993223335297584, 'f1-score': 0.993221995408001, 'support': 10182}
 
time = 12.63 secondes

Val loss 0.719827883507426 accuracy 0.9196113348007202 macro_avg {'precision': 0.9251887599216108, 'recall': 0.9214910547022171, 'f1-score': 0.9222013222799254, 'support': 1132} weighted_avg {'precision': 0.924089485779484, 'recall': 0.9196113074204947, 'f1-score': 0.9206257033835814, 'support': 1132}
 
----------
Epoch 29/40
time = 343.40 secondes

Train loss 0.03940998190125329 accuracy 0.9935179948806763 macro_avg {'precision': 0.993507016540128, 'recall': 0.9936065961972812, 'f1-score': 0.9935520327072982, 'support': 10182} weighted_avg {'precision': 0.9935263584335751, 'recall': 0.9935179728933412, 'f1-score': 0.9935175174755769, 'support': 10182}
 
time = 12.52 secondes

Val loss 0.7485794893353312 accuracy 0.9107773900032043 macro_avg {'precision': 0.9172736788115504, 'recall': 0.9144696654338078, 'f1-score': 0.9144648312415133, 'support': 1132} weighted_avg {'precision': 0.916399095378128, 'recall': 0.9107773851590106, 'f1-score': 0.9120942822766177, 'support': 1132}
 
----------
Epoch 30/40
time = 354.46 secondes

Train loss 0.032947584445615886 accuracy 0.9944019317626953 macro_avg {'precision': 0.9945061235401663, 'recall': 0.9944110763582177, 'f1-score': 0.9944547923583222, 'support': 10182} weighted_avg {'precision': 0.9944097366085616, 'recall': 0.9944018856806128, 'f1-score': 0.9944019701301118, 'support': 10182}
 
time = 12.40 secondes

Val loss 0.7794945197307807 accuracy 0.9081271886825562 macro_avg {'precision': 0.9163338053083935, 'recall': 0.9108807595888155, 'f1-score': 0.910241099507141, 'support': 1132} weighted_avg {'precision': 0.9177646685597638, 'recall': 0.9081272084805654, 'f1-score': 0.9092769865419938, 'support': 1132}
 
----------
Epoch 31/40
time = 346.45 secondes

Train loss 0.042909568233549904 accuracy 0.9930269122123718 macro_avg {'precision': 0.9930664439931167, 'recall': 0.9929208059628362, 'f1-score': 0.9929864491979851, 'support': 10182} weighted_avg {'precision': 0.9930351329113906, 'recall': 0.9930269102337458, 'f1-score': 0.9930238316108321, 'support': 10182}
 
time = 12.36 secondes

Val loss 0.7256551008244393 accuracy 0.9116607904434204 macro_avg {'precision': 0.9157191181604443, 'recall': 0.9159215525195294, 'f1-score': 0.9140742134627194, 'support': 1132} weighted_avg {'precision': 0.916865580782912, 'recall': 0.911660777385159, 'f1-score': 0.9126147101950578, 'support': 1132}
 
----------
Epoch 32/40
time = 343.27 secondes

Train loss 0.022814801080483227 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960273896372053, 'recall': 0.9959434763573816, 'f1-score': 0.9959824941196314, 'support': 10182} weighted_avg {'precision': 0.9960746254547898, 'recall': 0.9960714987232371, 'f1-score': 0.9960704512615535, 'support': 10182}
 
time = 11.19 secondes

Val loss 0.6800086994172347 accuracy 0.9178445339202881 macro_avg {'precision': 0.9192913601723243, 'recall': 0.9199713610520741, 'f1-score': 0.9185899827046755, 'support': 1132} weighted_avg {'precision': 0.9198751489139034, 'recall': 0.9178445229681979, 'f1-score': 0.9177691431455477, 'support': 1132}
 
----------
Epoch 33/40
time = 364.23 secondes

Train loss 0.026100907172678354 accuracy 0.9952858090400696 macro_avg {'precision': 0.995295711151892, 'recall': 0.9953108703254087, 'f1-score': 0.9952990653074438, 'support': 10182} weighted_avg {'precision': 0.995298419117835, 'recall': 0.9952857984678845, 'f1-score': 0.9952878193137482, 'support': 10182}
 
time = 12.67 secondes

Val loss 0.7533221264088176 accuracy 0.9213780760765076 macro_avg {'precision': 0.9275459129582405, 'recall': 0.9239581892523118, 'f1-score': 0.9240235707917229, 'support': 1132} weighted_avg {'precision': 0.9262618591021242, 'recall': 0.9213780918727915, 'f1-score': 0.9220356745972874, 'support': 1132}
 
----------
Epoch 34/40
time = 370.86 secondes

Train loss 0.03552256614891793 accuracy 0.9943037033081055 macro_avg {'precision': 0.9942480801514646, 'recall': 0.9942389957429972, 'f1-score': 0.9942409065211649, 'support': 10182} weighted_avg {'precision': 0.9943026537201299, 'recall': 0.9943036731486937, 'f1-score': 0.9943004647127087, 'support': 10182}
 
time = 12.23 secondes

Val loss 0.6884498365142859 accuracy 0.9240282773971558 macro_avg {'precision': 0.9278184482121791, 'recall': 0.9263989299887199, 'f1-score': 0.925673985050684, 'support': 1132} weighted_avg {'precision': 0.926179292405289, 'recall': 0.9240282685512368, 'f1-score': 0.9235902033011251, 'support': 1132}
 
----------
Epoch 35/40
time = 361.30 secondes

Train loss 0.020240058937591614 accuracy 0.996857225894928 macro_avg {'precision': 0.9968640520061847, 'recall': 0.9968228125177842, 'f1-score': 0.9968426185143601, 'support': 10182} weighted_avg {'precision': 0.9968556173756232, 'recall': 0.9968571989785897, 'f1-score': 0.9968556242070379, 'support': 10182}
 
time = 12.40 secondes

Val loss 0.7645216820613275 accuracy 0.9107773900032043 macro_avg {'precision': 0.9161919689348357, 'recall': 0.913880186345405, 'f1-score': 0.9133062929002502, 'support': 1132} weighted_avg {'precision': 0.9170136530240472, 'recall': 0.9107773851590106, 'f1-score': 0.912124278083109, 'support': 1132}
 
----------
Epoch 36/40
time = 369.52 secondes

Train loss 0.011951036948906205 accuracy 0.997741162776947 macro_avg {'precision': 0.9977018096181409, 'recall': 0.9976216023935262, 'f1-score': 0.9976595253329222, 'support': 10182} weighted_avg {'precision': 0.9977448708653769, 'recall': 0.9977411117658613, 'f1-score': 0.997740969416722, 'support': 10182}
 
time = 13.08 secondes

Val loss 0.6863526072560694 accuracy 0.9231448769569397 macro_avg {'precision': 0.9250663609793122, 'recall': 0.9239764417359654, 'f1-score': 0.9233050020741554, 'support': 1132} weighted_avg {'precision': 0.9258982575768234, 'recall': 0.9231448763250883, 'f1-score': 0.923246629922079, 'support': 1132}
 
----------
Epoch 37/40
time = 376.66 secondes

Train loss 0.01647494298738041 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974094344433133, 'recall': 0.9975519331264705, 'f1-score': 0.9974778876531255, 'support': 10182} weighted_avg {'precision': 0.9975490890206511, 'recall': 0.9975446867020232, 'f1-score': 0.9975442680718347, 'support': 10182}
 
time = 12.84 secondes

Val loss 0.7511817212021079 accuracy 0.9178445339202881 macro_avg {'precision': 0.9215034241474409, 'recall': 0.9200233187807791, 'f1-score': 0.9191290145201221, 'support': 1132} weighted_avg {'precision': 0.9218660580472375, 'recall': 0.9178445229681979, 'f1-score': 0.9180667539272986, 'support': 1132}
 
----------
Epoch 38/40
time = 363.12 secondes

Train loss 0.010812753748963348 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984284970144136, 'recall': 0.9983097194995445, 'f1-score': 0.998367060212559, 'support': 10182} weighted_avg {'precision': 0.9984307792104165, 'recall': 0.9984285994892949, 'f1-score': 0.9984279503510631, 'support': 10182}
 
time = 12.65 secondes

Val loss 0.6750672591621789 accuracy 0.926678478717804 macro_avg {'precision': 0.9284196624637223, 'recall': 0.9272176256650541, 'f1-score': 0.9269718257305047, 'support': 1132} weighted_avg {'precision': 0.9279309203809197, 'recall': 0.926678445229682, 'f1-score': 0.9264516653924046, 'support': 1132}
 
----------
Epoch 39/40
time = 372.56 secondes

Train loss 0.006518788655197071 accuracy 0.9986250400543213 macro_avg {'precision': 0.9985066912974052, 'recall': 0.9986250763654411, 'f1-score': 0.9985645983164074, 'support': 10182} weighted_avg {'precision': 0.9986276071700516, 'recall': 0.998625024553133, 'f1-score': 0.9986252208724021, 'support': 10182}
 
time = 13.10 secondes

Val loss 0.6712739321623636 accuracy 0.926678478717804 macro_avg {'precision': 0.930189407342685, 'recall': 0.9280595296295866, 'f1-score': 0.9280741338278956, 'support': 1132} weighted_avg {'precision': 0.9290070650006007, 'recall': 0.926678445229682, 'f1-score': 0.9267950078313214, 'support': 1132}
 
----------
Epoch 40/40
time = 376.96 secondes

Train loss 0.0021455779348842647 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995178850144327, 'recall': 0.9995051502877322, 'f1-score': 0.9995109501196889, 'support': 10182} weighted_avg {'precision': 0.9995098843350727, 'recall': 0.9995089373404047, 'f1-score': 0.9995088390273971, 'support': 10182}
 
time = 12.53 secondes

Val loss 0.7321521080792363 accuracy 0.9213780760765076 macro_avg {'precision': 0.9239501353908173, 'recall': 0.9219749128509669, 'f1-score': 0.9219417016003991, 'support': 1132} weighted_avg {'precision': 0.924342321413471, 'recall': 0.9213780918727915, 'f1-score': 0.9218197643925833, 'support': 1132}
 
----------
best_accuracy 0.926678478717804 best_epoch 38 macro_avg {'precision': 0.9284196624637223, 'recall': 0.9272176256650541, 'f1-score': 0.9269718257305047, 'support': 1132} weighted_avg {'precision': 0.9279309203809197, 'recall': 0.926678445229682, 'f1-score': 0.9264516653924046, 'support': 1132}

average train time 310.79494245648385

average val time 10.877465111017226
 
time = 82.67 secondes

test_accuracy 0.859134316444397 macro_avg {'precision': 0.855312131349008, 'recall': 0.8512236381724148, 'f1-score': 0.852116526298561, 'support': 7532} weighted_avg {'precision': 0.8616147124484694, 'recall': 0.8591343600637281, 'f1-score': 0.8592795482654122, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_4
----------
Epoch 1/40
time = 367.99 secondes

Train loss 1.2841919452139123 accuracy 0.6692202091217041 macro_avg {'precision': 0.6658649654024891, 'recall': 0.6535774923417811, 'f1-score': 0.6503669731567866, 'support': 10182} weighted_avg {'precision': 0.6782305721325913, 'recall': 0.6692201924965626, 'f1-score': 0.6648027874471873, 'support': 10182}
 
time = 13.89 secondes

Val loss 0.6429241851601802 accuracy 0.8189045786857605 macro_avg {'precision': 0.7953347917676872, 'recall': 0.8079676947775871, 'f1-score': 0.795739632325253, 'support': 1132} weighted_avg {'precision': 0.8042975450551514, 'recall': 0.818904593639576, 'f1-score': 0.8062067360807378, 'support': 1132}
 
----------
Epoch 2/40
time = 369.72 secondes

Train loss 0.45212696464600705 accuracy 0.8678059577941895 macro_avg {'precision': 0.859304235622148, 'recall': 0.8567380473751495, 'f1-score': 0.8548869365725235, 'support': 10182} weighted_avg {'precision': 0.8657303951883851, 'recall': 0.8678059320369279, 'f1-score': 0.8645230137998563, 'support': 10182}
 
time = 13.68 secondes

Val loss 0.4859054303190238 accuracy 0.8568904399871826 macro_avg {'precision': 0.8652575014237642, 'recall': 0.8594989633589709, 'f1-score': 0.8551243398954188, 'support': 1132} weighted_avg {'precision': 0.8701684074930846, 'recall': 0.8568904593639576, 'f1-score': 0.855669428807145, 'support': 1132}
 
----------
Epoch 3/40
time = 372.01 secondes

Train loss 0.27676114580759215 accuracy 0.9216264486312866 macro_avg {'precision': 0.916988988607037, 'recall': 0.9156473528686291, 'f1-score': 0.9159255593216938, 'support': 10182} weighted_avg {'precision': 0.9211798734730158, 'recall': 0.9216263995285798, 'f1-score': 0.921073988439503, 'support': 10182}
 
time = 13.62 secondes

Val loss 0.430495418988588 accuracy 0.8904593586921692 macro_avg {'precision': 0.888943575492714, 'recall': 0.8868634610502092, 'f1-score': 0.8852445929050378, 'support': 1132} weighted_avg {'precision': 0.8923328385299402, 'recall': 0.8904593639575972, 'f1-score': 0.88883325689836, 'support': 1132}
 
----------
Epoch 4/40
time = 362.19 secondes

Train loss 0.20640244834005153 accuracy 0.9464741945266724 macro_avg {'precision': 0.9436539224980081, 'recall': 0.9428736993234812, 'f1-score': 0.9431753296786198, 'support': 10182} weighted_avg {'precision': 0.9466545145312338, 'recall': 0.9464741701041053, 'f1-score': 0.9464806142029784, 'support': 10182}
 
time = 13.44 secondes

Val loss 0.5562998771562543 accuracy 0.8878092169761658 macro_avg {'precision': 0.8962551099579137, 'recall': 0.8894126767296854, 'f1-score': 0.8870284100310739, 'support': 1132} weighted_avg {'precision': 0.8945209083927435, 'recall': 0.8878091872791519, 'f1-score': 0.8848936680009379, 'support': 1132}
 
----------
Epoch 5/40
time = 367.54 secondes

Train loss 0.17501602998899596 accuracy 0.9564918875694275 macro_avg {'precision': 0.9544947543049732, 'recall': 0.9544405293029771, 'f1-score': 0.9543781303219582, 'support': 10182} weighted_avg {'precision': 0.9564060706750641, 'recall': 0.9564918483598507, 'f1-score': 0.9563617306578881, 'support': 10182}
 
time = 14.02 secondes

Val loss 0.5139690759939365 accuracy 0.9028268456459045 macro_avg {'precision': 0.9074295857135294, 'recall': 0.9030410982376896, 'f1-score': 0.9030791653996484, 'support': 1132} weighted_avg {'precision': 0.9095894950765118, 'recall': 0.9028268551236749, 'f1-score': 0.9038645349223831, 'support': 1132}
 
----------
Epoch 6/40
time = 383.52 secondes

Train loss 0.15796679334966846 accuracy 0.9627774953842163 macro_avg {'precision': 0.9617386152703299, 'recall': 0.9618945280888778, 'f1-score': 0.9617178891096045, 'support': 10182} weighted_avg {'precision': 0.9630799591795252, 'recall': 0.9627774504026714, 'f1-score': 0.9628421864188216, 'support': 10182}
 
time = 13.13 secondes

Val loss 0.5379626963240042 accuracy 0.9054770469665527 macro_avg {'precision': 0.9153096201128228, 'recall': 0.9021366670648782, 'f1-score': 0.9048699880743154, 'support': 1132} weighted_avg {'precision': 0.9124983726192709, 'recall': 0.9054770318021201, 'f1-score': 0.905771417593813, 'support': 1132}
 
----------
Epoch 7/40
time = 370.88 secondes

Train loss 0.15811446689385802 accuracy 0.964152455329895 macro_avg {'precision': 0.9635188371351278, 'recall': 0.9635720216945375, 'f1-score': 0.9634762403628125, 'support': 10182} weighted_avg {'precision': 0.9643001131126713, 'recall': 0.9641524258495384, 'f1-score': 0.9641557114489462, 'support': 10182}
 
time = 13.08 secondes

Val loss 0.6183588244127516 accuracy 0.8939929604530334 macro_avg {'precision': 0.898901535258507, 'recall': 0.8928028104327448, 'f1-score': 0.8920183503165495, 'support': 1132} weighted_avg {'precision': 0.8994905505819709, 'recall': 0.8939929328621908, 'f1-score': 0.893300314191315, 'support': 1132}
 
----------
Epoch 8/40
time = 357.85 secondes

Train loss 0.1414388546949414 accuracy 0.9697505831718445 macro_avg {'precision': 0.968705781411653, 'recall': 0.9687393481745381, 'f1-score': 0.9686691340419655, 'support': 10182} weighted_avg {'precision': 0.9698292918350567, 'recall': 0.9697505401689256, 'f1-score': 0.9697419654386152, 'support': 10182}
 
time = 13.24 secondes

Val loss 0.6617020628797087 accuracy 0.9010601043701172 macro_avg {'precision': 0.9114612361794234, 'recall': 0.9034781751601078, 'f1-score': 0.903587796042113, 'support': 1132} weighted_avg {'precision': 0.9114600767262356, 'recall': 0.901060070671378, 'f1-score': 0.9023713073090328, 'support': 1132}
 
----------
Epoch 9/40
time = 373.19 secondes

Train loss 0.12528776761340496 accuracy 0.9742683172225952 macro_avg {'precision': 0.9734960574323646, 'recall': 0.9739440459846829, 'f1-score': 0.9736709088630846, 'support': 10182} weighted_avg {'precision': 0.9743873609483417, 'recall': 0.9742683166372029, 'f1-score': 0.9742821590467152, 'support': 10182}
 
time = 13.16 secondes

Val loss 0.6075330729183125 accuracy 0.9028268456459045 macro_avg {'precision': 0.9114889138387594, 'recall': 0.9003370696811495, 'f1-score': 0.8996933515863299, 'support': 1132} weighted_avg {'precision': 0.9123859539876089, 'recall': 0.9028268551236749, 'f1-score': 0.902171004900099, 'support': 1132}
 
----------
Epoch 10/40
time = 373.84 secondes

Train loss 0.1225815700953099 accuracy 0.9750540256500244 macro_avg {'precision': 0.9743954672320034, 'recall': 0.9745101712052582, 'f1-score': 0.9744254023171786, 'support': 10182} weighted_avg {'precision': 0.9750776972450843, 'recall': 0.9750540168925554, 'f1-score': 0.9750376774315104, 'support': 10182}
 
time = 13.73 secondes

Val loss 0.5761421655860572 accuracy 0.9143109321594238 macro_avg {'precision': 0.9165539581529896, 'recall': 0.9150183382893363, 'f1-score': 0.9143324449994944, 'support': 1132} weighted_avg {'precision': 0.9172689457303081, 'recall': 0.9143109540636042, 'f1-score': 0.9143054979032127, 'support': 1132}
 
----------
Epoch 11/40
time = 369.71 secondes

Train loss 0.10949819472747609 accuracy 0.979375422000885 macro_avg {'precision': 0.9789822118971637, 'recall': 0.9786906843647796, 'f1-score': 0.9788040795134799, 'support': 10182} weighted_avg {'precision': 0.9794230291741571, 'recall': 0.9793753682969947, 'f1-score': 0.9793676196972365, 'support': 10182}
 
time = 13.55 secondes

Val loss 0.6487680260427329 accuracy 0.9098939895629883 macro_avg {'precision': 0.9115942989846418, 'recall': 0.9104545597269207, 'f1-score': 0.9086043544157125, 'support': 1132} weighted_avg {'precision': 0.9163895810456709, 'recall': 0.9098939929328622, 'f1-score': 0.9109632926465833, 'support': 1132}
 
----------
Epoch 12/40
time = 355.92 secondes

Train loss 0.10648687302702936 accuracy 0.9799646735191345 macro_avg {'precision': 0.9792991068182456, 'recall': 0.9789400318366657, 'f1-score': 0.9790893566277891, 'support': 10182} weighted_avg {'precision': 0.980018551180173, 'recall': 0.9799646434885091, 'f1-score': 0.979964778840872, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.6153704887743823 accuracy 0.9098939895629883 macro_avg {'precision': 0.9173909038337037, 'recall': 0.9094976571625416, 'f1-score': 0.9115144535617146, 'support': 1132} weighted_avg {'precision': 0.9147143470508686, 'recall': 0.9098939929328622, 'f1-score': 0.9102692012968738, 'support': 1132}
 
----------
Epoch 13/40
time = 379.21 secondes

Train loss 0.108259206158692 accuracy 0.9789825677871704 macro_avg {'precision': 0.9783089903780222, 'recall': 0.978332703204245, 'f1-score': 0.9783067877251874, 'support': 10182} weighted_avg {'precision': 0.9790116361968576, 'recall': 0.9789825181693184, 'f1-score': 0.9789827719520882, 'support': 10182}
 
time = 13.52 secondes

Val loss 0.9681128301369978 accuracy 0.8816254734992981 macro_avg {'precision': 0.8989255014094633, 'recall': 0.8882416347216694, 'f1-score': 0.8821077837506579, 'support': 1132} weighted_avg {'precision': 0.9024338666173791, 'recall': 0.8816254416961131, 'f1-score': 0.8796226961706355, 'support': 1132}
 
----------
Epoch 14/40
time = 370.36 secondes

Train loss 0.09742024087285776 accuracy 0.9820271134376526 macro_avg {'precision': 0.9818447736498668, 'recall': 0.9818243697441501, 'f1-score': 0.9818185706979567, 'support': 10182} weighted_avg {'precision': 0.9820666801841248, 'recall': 0.9820271066588097, 'f1-score': 0.9820310749193554, 'support': 10182}
 
time = 14.47 secondes

Val loss 0.6881311259396017 accuracy 0.9134275913238525 macro_avg {'precision': 0.9189587542195745, 'recall': 0.9169922561907156, 'f1-score': 0.915780114803073, 'support': 1132} weighted_avg {'precision': 0.918185877826595, 'recall': 0.9134275618374559, 'f1-score': 0.9136984306398795, 'support': 1132}
 
----------
Epoch 15/40
time = 366.73 secondes

Train loss 0.09109751371622882 accuracy 0.9831074476242065 macro_avg {'precision': 0.9824472294912112, 'recall': 0.9822386968850922, 'f1-score': 0.982323765723819, 'support': 10182} weighted_avg {'precision': 0.9831180153716846, 'recall': 0.9831074445099195, 'f1-score': 0.9830942141229604, 'support': 10182}
 
time = 13.34 secondes

Val loss 0.8786550208427747 accuracy 0.8913427591323853 macro_avg {'precision': 0.9087122967761398, 'recall': 0.8948879975019459, 'f1-score': 0.8958203337854023, 'support': 1132} weighted_avg {'precision': 0.9073896518490634, 'recall': 0.8913427561837456, 'f1-score': 0.8930026257558589, 'support': 1132}
 
----------
Epoch 16/40
time = 365.61 secondes

Train loss 0.09403015204092016 accuracy 0.9830092787742615 macro_avg {'precision': 0.9828362062687541, 'recall': 0.9827824559997639, 'f1-score': 0.9827722249458033, 'support': 10182} weighted_avg {'precision': 0.9830744146251573, 'recall': 0.9830092319780004, 'f1-score': 0.9830037163974544, 'support': 10182}
 
time = 13.89 secondes

Val loss 0.7104402581155201 accuracy 0.9063604474067688 macro_avg {'precision': 0.9128322410189549, 'recall': 0.9044661243875689, 'f1-score': 0.9069350914436498, 'support': 1132} weighted_avg {'precision': 0.9104761850800588, 'recall': 0.9063604240282686, 'f1-score': 0.9066064386508311, 'support': 1132}
 
----------
Epoch 17/40
time = 380.01 secondes

Train loss 0.08205288284814319 accuracy 0.9847770929336548 macro_avg {'precision': 0.9847668202776718, 'recall': 0.9844215210043605, 'f1-score': 0.9845775767936956, 'support': 10182} weighted_avg {'precision': 0.9848048514969151, 'recall': 0.9847770575525437, 'f1-score': 0.9847746882785595, 'support': 10182}
 
time = 13.32 secondes

Val loss 0.6824999926671218 accuracy 0.9116607904434204 macro_avg {'precision': 0.9175420152791871, 'recall': 0.9169963976392216, 'f1-score': 0.9151332770395879, 'support': 1132} weighted_avg {'precision': 0.9168427046881004, 'recall': 0.911660777385159, 'f1-score': 0.9119178637741828, 'support': 1132}
 
----------
Epoch 18/40
time = 363.81 secondes

Train loss 0.07666182444383417 accuracy 0.9860538244247437 macro_avg {'precision': 0.9855580447080792, 'recall': 0.9856295252865795, 'f1-score': 0.9855871687788161, 'support': 10182} weighted_avg {'precision': 0.9860526163375738, 'recall': 0.9860538204674917, 'f1-score': 0.9860467180172179, 'support': 10182}
 
time = 13.14 secondes

Val loss 0.6184874747551463 accuracy 0.9204947352409363 macro_avg {'precision': 0.92329409546203, 'recall': 0.9221388230455834, 'f1-score': 0.9213959628517573, 'support': 1132} weighted_avg {'precision': 0.9241733248180577, 'recall': 0.9204946996466431, 'f1-score': 0.9209086327877174, 'support': 1132}
 
----------
Epoch 19/40
time = 359.58 secondes

Train loss 0.0724896734212008 accuracy 0.9873306155204773 macro_avg {'precision': 0.9871324288743036, 'recall': 0.9866570398276805, 'f1-score': 0.9868693422714504, 'support': 10182} weighted_avg {'precision': 0.9873619237097231, 'recall': 0.9873305833824396, 'f1-score': 0.9873241937164814, 'support': 10182}
 
time = 12.86 secondes

Val loss 0.7631199292577868 accuracy 0.9063604474067688 macro_avg {'precision': 0.9119137370202048, 'recall': 0.9099917173696674, 'f1-score': 0.9077372318116723, 'support': 1132} weighted_avg {'precision': 0.912733380289306, 'recall': 0.9063604240282686, 'f1-score': 0.906747456749489, 'support': 1132}
 
----------
Epoch 20/40
time = 366.16 secondes

Train loss 0.07109205039114172 accuracy 0.9880180954933167 macro_avg {'precision': 0.988152169931005, 'recall': 0.9879753361575242, 'f1-score': 0.9880434853741402, 'support': 10182} weighted_avg {'precision': 0.9880512096305044, 'recall': 0.9880180711058731, 'f1-score': 0.9880154126928758, 'support': 10182}
 
time = 14.22 secondes

Val loss 0.7518485135568509 accuracy 0.9134275913238525 macro_avg {'precision': 0.9183770919482617, 'recall': 0.9180977278338881, 'f1-score': 0.9154805907508747, 'support': 1132} weighted_avg {'precision': 0.9194224156181484, 'recall': 0.9134275618374559, 'f1-score': 0.9133772912264556, 'support': 1132}
 
----------
Epoch 21/40
time = 379.65 secondes

Train loss 0.07107285087569015 accuracy 0.9882145524024963 macro_avg {'precision': 0.9880298744221255, 'recall': 0.9882641790012782, 'f1-score': 0.9881192168830782, 'support': 10182} weighted_avg {'precision': 0.9882924815942532, 'recall': 0.9882144961697112, 'f1-score': 0.9882257934952391, 'support': 10182}
 
time = 13.59 secondes

Val loss 0.7124641915706632 accuracy 0.9134275913238525 macro_avg {'precision': 0.9207861974890426, 'recall': 0.915867913605149, 'f1-score': 0.9152511780260124, 'support': 1132} weighted_avg {'precision': 0.919584294488615, 'recall': 0.9134275618374559, 'f1-score': 0.9134975393673378, 'support': 1132}
 
----------
Epoch 22/40
time = 364.71 secondes

Train loss 0.07994181095754681 accuracy 0.9877234697341919 macro_avg {'precision': 0.9869527804429318, 'recall': 0.9874091732457387, 'f1-score': 0.9871609635738151, 'support': 10182} weighted_avg {'precision': 0.9877682436782211, 'recall': 0.9877234335101159, 'f1-score': 0.9877288444379776, 'support': 10182}
 
time = 12.68 secondes

Val loss 0.728782227670923 accuracy 0.9098939895629883 macro_avg {'precision': 0.9177837119885653, 'recall': 0.9105081768225552, 'f1-score': 0.9119609985421592, 'support': 1132} weighted_avg {'precision': 0.9147698567269799, 'recall': 0.9098939929328622, 'f1-score': 0.9103341646328188, 'support': 1132}
 
----------
Epoch 23/40
time = 359.54 secondes

Train loss 0.06847990110519267 accuracy 0.9886073470115662 macro_avg {'precision': 0.9886052590804176, 'recall': 0.9885192567402867, 'f1-score': 0.9885367991044436, 'support': 10182} weighted_avg {'precision': 0.9886741458846557, 'recall': 0.9886073462973876, 'f1-score': 0.9886151171373686, 'support': 10182}
 
time = 13.57 secondes

Val loss 0.7409686426596034 accuracy 0.9125441908836365 macro_avg {'precision': 0.9124643096039724, 'recall': 0.9134852975833356, 'f1-score': 0.9122072616892869, 'support': 1132} weighted_avg {'precision': 0.9136621491645839, 'recall': 0.9125441696113075, 'f1-score': 0.9122850914499587, 'support': 1132}
 
----------
Epoch 24/40
time = 376.32 secondes

Train loss 0.05647826784200275 accuracy 0.9915537238121033 macro_avg {'precision': 0.9913191404017283, 'recall': 0.9915450322367739, 'f1-score': 0.9914228984882248, 'support': 10182} weighted_avg {'precision': 0.9915683419510791, 'recall': 0.9915537222549597, 'f1-score': 0.9915525707011857, 'support': 10182}
 
time = 11.64 secondes

Val loss 0.7917738192924626 accuracy 0.9072438478469849 macro_avg {'precision': 0.9161352144713015, 'recall': 0.9061005719844779, 'f1-score': 0.9082757615882562, 'support': 1132} weighted_avg {'precision': 0.9124247941878042, 'recall': 0.907243816254417, 'f1-score': 0.9072550027212406, 'support': 1132}
 
----------
Epoch 25/40
time = 374.11 secondes

Train loss 0.056906699803803806 accuracy 0.9907680749893188 macro_avg {'precision': 0.9907815624645512, 'recall': 0.9905066705170933, 'f1-score': 0.9906119733123822, 'support': 10182} weighted_avg {'precision': 0.9908278868500137, 'recall': 0.9907680219996071, 'f1-score': 0.9907681124973311, 'support': 10182}
 
time = 14.69 secondes

Val loss 0.8540124534921348 accuracy 0.9063604474067688 macro_avg {'precision': 0.9084726377917697, 'recall': 0.9096700750591771, 'f1-score': 0.9069341303228869, 'support': 1132} weighted_avg {'precision': 0.9105271203884312, 'recall': 0.9063604240282686, 'f1-score': 0.9062260993226929, 'support': 1132}
 
----------
Epoch 26/40
time = 364.17 secondes

Train loss 0.04885409096307138 accuracy 0.9916519522666931 macro_avg {'precision': 0.9914127196217242, 'recall': 0.9913781053211302, 'f1-score': 0.9913798453937593, 'support': 10182} weighted_avg {'precision': 0.9916685453845674, 'recall': 0.9916519347868789, 'f1-score': 0.9916447019347644, 'support': 10182}
 
time = 13.43 secondes

Val loss 0.7807016375259017 accuracy 0.9037102460861206 macro_avg {'precision': 0.9111130922483598, 'recall': 0.9049625243153281, 'f1-score': 0.9062456435854196, 'support': 1132} weighted_avg {'precision': 0.9109679206606495, 'recall': 0.9037102473498233, 'f1-score': 0.905337665481161, 'support': 1132}
 
----------
Epoch 27/40
time = 360.61 secondes

Train loss 0.05114827630113923 accuracy 0.991750180721283 macro_avg {'precision': 0.9917501105414053, 'recall': 0.9915916096068486, 'f1-score': 0.9916575333738411, 'support': 10182} weighted_avg {'precision': 0.9917808224964457, 'recall': 0.9917501473187978, 'f1-score': 0.9917526331829468, 'support': 10182}
 
time = 13.21 secondes

Val loss 0.6836880961578368 accuracy 0.9125441908836365 macro_avg {'precision': 0.9171532583776904, 'recall': 0.91560146048304, 'f1-score': 0.9148131257058842, 'support': 1132} weighted_avg {'precision': 0.9159950815002025, 'recall': 0.9125441696113075, 'f1-score': 0.9125891957555108, 'support': 1132}
 
----------
Epoch 28/40
time = 379.92 secondes

Train loss 0.037830462550464204 accuracy 0.993714451789856 macro_avg {'precision': 0.9936483394865692, 'recall': 0.9934198939384308, 'f1-score': 0.9935289570083821, 'support': 10182} weighted_avg {'precision': 0.993724835130619, 'recall': 0.9937143979571793, 'f1-score': 0.9937147519010369, 'support': 10182}
 
time = 14.54 secondes

Val loss 0.7100528396372348 accuracy 0.9178445339202881 macro_avg {'precision': 0.9219274009562511, 'recall': 0.9202013315381443, 'f1-score': 0.9188966778978237, 'support': 1132} weighted_avg {'precision': 0.9232172184897007, 'recall': 0.9178445229681979, 'f1-score': 0.9182845167613268, 'support': 1132}
 
----------
Epoch 29/40
time = 377.48 secondes

Train loss 0.03492467954791015 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934223234846066, 'recall': 0.9934451646000433, 'f1-score': 0.993428294081353, 'support': 10182} weighted_avg {'precision': 0.9935278580068987, 'recall': 0.9935179728933412, 'f1-score': 0.9935175437495042, 'support': 10182}
 
time = 13.71 secondes

Val loss 0.7300807536159201 accuracy 0.9222614765167236 macro_avg {'precision': 0.9278805068608851, 'recall': 0.9237342133447909, 'f1-score': 0.9239570182676478, 'support': 1132} weighted_avg {'precision': 0.926650047223229, 'recall': 0.9222614840989399, 'f1-score': 0.9226331302455456, 'support': 1132}
 
----------
Epoch 30/40
time = 359.88 secondes

Train loss 0.04034471791764729 accuracy 0.9941073060035706 macro_avg {'precision': 0.9939754143409381, 'recall': 0.9938683501604622, 'f1-score': 0.9939161770944123, 'support': 10182} weighted_avg {'precision': 0.9941143300229704, 'recall': 0.9941072480848556, 'f1-score': 0.9941054745353282, 'support': 10182}
 
time = 13.82 secondes

Val loss 0.6651354670782023 accuracy 0.916077733039856 macro_avg {'precision': 0.9211931673859732, 'recall': 0.9192173223891874, 'f1-score': 0.9178394610289471, 'support': 1132} weighted_avg {'precision': 0.921178387864145, 'recall': 0.916077738515901, 'f1-score': 0.9163167926499095, 'support': 1132}
 
----------
Epoch 31/40
time = 363.58 secondes

Train loss 0.03181207367895387 accuracy 0.9949911832809448 macro_avg {'precision': 0.994843011207541, 'recall': 0.994880575322413, 'f1-score': 0.9948519750768361, 'support': 10182} weighted_avg {'precision': 0.9950127334225418, 'recall': 0.9949911608721272, 'f1-score': 0.9949923943098364, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.6607130083582273 accuracy 0.9240282773971558 macro_avg {'precision': 0.9315039525520061, 'recall': 0.9257937833603325, 'f1-score': 0.9277469224745497, 'support': 1132} weighted_avg {'precision': 0.9275746487322201, 'recall': 0.9240282685512368, 'f1-score': 0.9248491595914108, 'support': 1132}
 
----------
Epoch 32/40
time = 380.61 secondes

Train loss 0.03601369011277934 accuracy 0.9943037033081055 macro_avg {'precision': 0.9942634697453998, 'recall': 0.994214759424243, 'f1-score': 0.9942328068732806, 'support': 10182} weighted_avg {'precision': 0.994321592278031, 'recall': 0.9943036731486937, 'f1-score': 0.99430617263498, 'support': 10182}
 
time = 13.44 secondes

Val loss 0.6297870680621561 accuracy 0.9302120208740234 macro_avg {'precision': 0.9317920183143761, 'recall': 0.9331512996305223, 'f1-score': 0.9317215094464176, 'support': 1132} weighted_avg {'precision': 0.9328472107564397, 'recall': 0.9302120141342756, 'f1-score': 0.9307429030943404, 'support': 1132}
 
----------
Epoch 33/40
time = 364.33 secondes

Train loss 0.02955431570869681 accuracy 0.9955804944038391 macro_avg {'precision': 0.9956435571656981, 'recall': 0.995732493810964, 'f1-score': 0.9956796457551025, 'support': 10182} weighted_avg {'precision': 0.9955979374103949, 'recall': 0.9955804360636418, 'f1-score': 0.9955806437169513, 'support': 10182}
 
time = 13.55 secondes

Val loss 0.7234739808659405 accuracy 0.9213780760765076 macro_avg {'precision': 0.924812858070293, 'recall': 0.9267124187293108, 'f1-score': 0.924158901586957, 'support': 1132} weighted_avg {'precision': 0.9258519591779596, 'recall': 0.9213780918727915, 'f1-score': 0.9220036554373474, 'support': 1132}
 
----------
Epoch 34/40
time = 361.71 secondes

Train loss 0.027717010216155625 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953834730892709, 'recall': 0.9954621853850968, 'f1-score': 0.9954203279332472, 'support': 10182} weighted_avg {'precision': 0.9953869587097132, 'recall': 0.9953840109998036, 'f1-score': 0.9953830014575913, 'support': 10182}
 
time = 12.96 secondes

Val loss 0.7413824872055044 accuracy 0.9187279343605042 macro_avg {'precision': 0.9223671626645146, 'recall': 0.9211686678704348, 'f1-score': 0.9206683901277846, 'support': 1132} weighted_avg {'precision': 0.9224125378681876, 'recall': 0.9187279151943463, 'f1-score': 0.9194377732823009, 'support': 1132}
 
----------
Epoch 35/40
time = 343.42 secondes

Train loss 0.01800073803552183 accuracy 0.9969554543495178 macro_avg {'precision': 0.9969796367234469, 'recall': 0.9969888408880726, 'f1-score': 0.9969828841944045, 'support': 10182} weighted_avg {'precision': 0.9969585200009604, 'recall': 0.9969554115105087, 'f1-score': 0.9969555715189231, 'support': 10182}
 
time = 12.70 secondes

Val loss 0.6924649910447123 accuracy 0.9204947352409363 macro_avg {'precision': 0.9249369344763935, 'recall': 0.9237396832463205, 'f1-score': 0.9230607549348212, 'support': 1132} weighted_avg {'precision': 0.9243687916619878, 'recall': 0.9204946996466431, 'f1-score': 0.9210903677725107, 'support': 1132}
 
----------
Epoch 36/40
time = 341.66 secondes

Train loss 0.01450604344875728 accuracy 0.9971518516540527 macro_avg {'precision': 0.9969483376301902, 'recall': 0.9971461768375356, 'f1-score': 0.9970395977031297, 'support': 10182} weighted_avg {'precision': 0.9971670236624088, 'recall': 0.9971518365743469, 'f1-score': 0.9971531049438608, 'support': 10182}
 
time = 12.28 secondes

Val loss 0.8427214711995168 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116709863753014, 'recall': 0.9094425670797669, 'f1-score': 0.9078994203246028, 'support': 1132} weighted_avg {'precision': 0.9138143299186932, 'recall': 0.9054770318021201, 'f1-score': 0.9071248961724436, 'support': 1132}
 
----------
Epoch 37/40
time = 337.77 secondes

Train loss 0.013066565504402036 accuracy 0.9978393316268921 macro_avg {'precision': 0.9977520656642312, 'recall': 0.9977432407651478, 'f1-score': 0.9977454146003417, 'support': 10182} weighted_avg {'precision': 0.9978419540585411, 'recall': 0.9978393242977804, 'f1-score': 0.9978386396728598, 'support': 10182}
 
time = 13.41 secondes

Val loss 0.7050829364641328 accuracy 0.9240282773971558 macro_avg {'precision': 0.9290780219313712, 'recall': 0.9258720898357963, 'f1-score': 0.926121624484986, 'support': 1132} weighted_avg {'precision': 0.9282926088658453, 'recall': 0.9240282685512368, 'f1-score': 0.9247018145044117, 'support': 1132}
 
----------
Epoch 38/40
time = 339.48 secondes

Train loss 0.005834899347208699 accuracy 0.998821496963501 macro_avg {'precision': 0.998817602778175, 'recall': 0.9987919357393746, 'f1-score': 0.9988038093048051, 'support': 10182} weighted_avg {'precision': 0.9988230603534484, 'recall': 0.9988214496169712, 'f1-score': 0.9988213523443854, 'support': 10182}
 
time = 13.18 secondes

Val loss 0.7303958396125484 accuracy 0.9204947352409363 macro_avg {'precision': 0.9272463826819608, 'recall': 0.9239290673456841, 'f1-score': 0.9239400988523891, 'support': 1132} weighted_avg {'precision': 0.9242762966946466, 'recall': 0.9204946996466431, 'f1-score': 0.9206293305387716, 'support': 1132}
 
----------
Epoch 39/40
time = 340.40 secondes

Train loss 0.003787100426836198 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992663126189196, 'recall': 0.9992918066281513, 'f1-score': 0.9992785304964338, 'support': 10182} weighted_avg {'precision': 0.9993135306193038, 'recall': 0.9993125122765665, 'f1-score': 0.9993125237035289, 'support': 10182}
 
time = 12.78 secondes

Val loss 0.7214112642460593 accuracy 0.9275618195533752 macro_avg {'precision': 0.9326164776835798, 'recall': 0.9304926460775695, 'f1-score': 0.930718868084746, 'support': 1132} weighted_avg {'precision': 0.9289495852941277, 'recall': 0.9275618374558304, 'f1-score': 0.9274252880985959, 'support': 1132}
 
----------
Epoch 40/40
time = 338.91 secondes

Train loss 0.004873640195590589 accuracy 0.9993125200271606 macro_avg {'precision': 0.999342962970457, 'recall': 0.9993430588720493, 'f1-score': 0.9993423912338054, 'support': 10182} weighted_avg {'precision': 0.9993143566920385, 'recall': 0.9993125122765665, 'f1-score': 0.9993127883626438, 'support': 10182}
 
time = 14.19 secondes

Val loss 0.7701758467984022 accuracy 0.9213780760765076 macro_avg {'precision': 0.9309702635761358, 'recall': 0.9249866253830241, 'f1-score': 0.9258445059203524, 'support': 1132} weighted_avg {'precision': 0.927377927365354, 'recall': 0.9213780918727915, 'f1-score': 0.9221512715163646, 'support': 1132}
 
----------
best_accuracy 0.9302120208740234 best_epoch 32 macro_avg {'precision': 0.9317920183143761, 'recall': 0.9331512996305223, 'f1-score': 0.9317215094464176, 'support': 1132} weighted_avg {'precision': 0.9328472107564397, 'recall': 0.9302120141342756, 'f1-score': 0.9307429030943404, 'support': 1132}

average train time 364.60238720178603

average val time 13.470827841758728
 
time = 85.62 secondes

test_accuracy 0.8481146693229675 macro_avg {'precision': 0.8470635800640662, 'recall': 0.8422944346227009, 'f1-score': 0.8428172397033356, 'support': 7532} weighted_avg {'precision': 0.8543969945756184, 'recall': 0.8481147105682422, 'f1-score': 0.8494337108726496, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_4
----------
Epoch 1/40
time = 339.66 secondes

Train loss 1.3188187476230004 accuracy 0.6580239534378052 macro_avg {'precision': 0.6622722260821183, 'recall': 0.6423267469375646, 'f1-score': 0.6388774015157753, 'support': 10182} weighted_avg {'precision': 0.6762180734425175, 'recall': 0.6580239638577883, 'f1-score': 0.6535665916145013, 'support': 10182}
 
time = 14.00 secondes

Val loss 0.7635616022096553 accuracy 0.7641342878341675 macro_avg {'precision': 0.74122040619138, 'recall': 0.7575365112651106, 'f1-score': 0.7405692990456905, 'support': 1132} weighted_avg {'precision': 0.7442997088231881, 'recall': 0.7641342756183745, 'f1-score': 0.7455057082178735, 'support': 1132}
 
----------
Epoch 2/40
time = 337.49 secondes

Train loss 0.5413684647828575 accuracy 0.8401100039482117 macro_avg {'precision': 0.827148301229502, 'recall': 0.8260857834604766, 'f1-score': 0.82131941200704, 'support': 10182} weighted_avg {'precision': 0.836219745865757, 'recall': 0.8401099980357494, 'f1-score': 0.8343127034259388, 'support': 10182}
 
time = 12.36 secondes

Val loss 0.6609304406693284 accuracy 0.815371036529541 macro_avg {'precision': 0.8098845563745064, 'recall': 0.8067520046157636, 'f1-score': 0.7984205719897427, 'support': 1132} weighted_avg {'precision': 0.8223058888012136, 'recall': 0.8153710247349824, 'f1-score': 0.8095907863191414, 'support': 1132}
 
----------
Epoch 3/40
time = 331.00 secondes

Train loss 0.3553274156528655 accuracy 0.8943233489990234 macro_avg {'precision': 0.8864576626626087, 'recall': 0.8852071193224866, 'f1-score': 0.8852330409979036, 'support': 10182} weighted_avg {'precision': 0.8934901850355148, 'recall': 0.8943233156550776, 'f1-score': 0.8934123231013653, 'support': 10182}
 
time = 13.55 secondes

Val loss 0.6333362204350637 accuracy 0.8321554660797119 macro_avg {'precision': 0.8320828161819028, 'recall': 0.8316809281246993, 'f1-score': 0.828090212130892, 'support': 1132} weighted_avg {'precision': 0.8410488088110635, 'recall': 0.8321554770318021, 'f1-score': 0.8323424900039934, 'support': 1132}
 
----------
Epoch 4/40
time = 331.56 secondes

Train loss 0.274153716383382 accuracy 0.9236888885498047 macro_avg {'precision': 0.9184347086768845, 'recall': 0.9173108835094897, 'f1-score': 0.9176255269658782, 'support': 10182} weighted_avg {'precision': 0.9235437391781579, 'recall': 0.9236888626988804, 'f1-score': 0.9233966324705073, 'support': 10182}
 
time = 12.29 secondes

Val loss 0.6292120650620527 accuracy 0.8595406413078308 macro_avg {'precision': 0.8599657886728872, 'recall': 0.8537402168501759, 'f1-score': 0.85408240559681, 'support': 1132} weighted_avg {'precision': 0.8615242376117036, 'recall': 0.8595406360424028, 'f1-score': 0.8576197097450232, 'support': 1132}
 
----------
Epoch 5/40
time = 337.39 secondes

Train loss 0.2125142806968425 accuracy 0.9421528577804565 macro_avg {'precision': 0.938006036964949, 'recall': 0.9370307373228759, 'f1-score': 0.9373263155575821, 'support': 10182} weighted_avg {'precision': 0.942278890114558, 'recall': 0.942152818699666, 'f1-score': 0.9420321564384322, 'support': 10182}
 
time = 13.47 secondes

Val loss 0.632150923187228 accuracy 0.8736749291419983 macro_avg {'precision': 0.8805836193916086, 'recall': 0.8659514895965346, 'f1-score': 0.867890314244913, 'support': 1132} weighted_avg {'precision': 0.8784185236790706, 'recall': 0.8736749116607774, 'f1-score': 0.871591255568741, 'support': 1132}
 
----------
Epoch 6/40
time = 324.07 secondes

Train loss 0.19479633780273797 accuracy 0.9527598023414612 macro_avg {'precision': 0.950146587164134, 'recall': 0.9498156640244672, 'f1-score': 0.9499364951021507, 'support': 10182} weighted_avg {'precision': 0.9528565879192944, 'recall': 0.952759772146926, 'f1-score': 0.9527644747827536, 'support': 10182}
 
time = 13.06 secondes

Val loss 0.7328805993278315 accuracy 0.8657243847846985 macro_avg {'precision': 0.8673465650301194, 'recall': 0.8591881699612811, 'f1-score': 0.8570653274170376, 'support': 1132} weighted_avg {'precision': 0.8679686838144561, 'recall': 0.8657243816254417, 'f1-score': 0.8619287588533826, 'support': 1132}
 
----------
Epoch 7/40
time = 333.60 secondes

Train loss 0.17135925411727 accuracy 0.9583579301834106 macro_avg {'precision': 0.955291503794184, 'recall': 0.9547168289621137, 'f1-score': 0.9549386964026821, 'support': 10182} weighted_avg {'precision': 0.9581773097619043, 'recall': 0.9583578864663131, 'f1-score': 0.9582158525340823, 'support': 10182}
 
time = 12.84 secondes

Val loss 0.8617296639524898 accuracy 0.8454063534736633 macro_avg {'precision': 0.8506252850395348, 'recall': 0.8493265720210312, 'f1-score': 0.842515254262808, 'support': 1132} weighted_avg {'precision': 0.8610920239655149, 'recall': 0.8454063604240283, 'f1-score': 0.8451316985564598, 'support': 1132}
 
----------
Epoch 8/40
time = 333.41 secondes

Train loss 0.15289660930946788 accuracy 0.9655274152755737 macro_avg {'precision': 0.9630449395527728, 'recall': 0.962770875821356, 'f1-score': 0.962871131864836, 'support': 10182} weighted_avg {'precision': 0.9655462490065503, 'recall': 0.9655274012964055, 'f1-score': 0.9655039802449245, 'support': 10182}
 
time = 13.37 secondes

Val loss 0.7547876344203398 accuracy 0.870141327381134 macro_avg {'precision': 0.8749419399082192, 'recall': 0.8658266839493092, 'f1-score': 0.8646861658094182, 'support': 1132} weighted_avg {'precision': 0.8731882118814077, 'recall': 0.8701413427561837, 'f1-score': 0.8668446079324521, 'support': 1132}
 
----------
Epoch 9/40
time = 332.13 secondes

Train loss 0.14982136226856052 accuracy 0.9663131237030029 macro_avg {'precision': 0.9642914228527169, 'recall': 0.9643553307635686, 'f1-score': 0.9642917362616832, 'support': 10182} weighted_avg {'precision': 0.9664425926143273, 'recall': 0.966313101551758, 'f1-score': 0.9663457908949593, 'support': 10182}
 
time = 14.51 secondes

Val loss 1.023657621351779 accuracy 0.8392226099967957 macro_avg {'precision': 0.8585304587032097, 'recall': 0.8331877938894914, 'f1-score': 0.8350584980143086, 'support': 1132} weighted_avg {'precision': 0.854976739258672, 'recall': 0.8392226148409894, 'f1-score': 0.8358937371227995, 'support': 1132}
 
----------
Epoch 10/40
time = 336.90 secondes

Train loss 0.14310047401616413 accuracy 0.9702416062355042 macro_avg {'precision': 0.9689194459998773, 'recall': 0.9680213226848172, 'f1-score': 0.9683971673630977, 'support': 10182} weighted_avg {'precision': 0.9702791329917757, 'recall': 0.9702416028285209, 'f1-score': 0.9701977284187772, 'support': 10182}
 
time = 13.77 secondes

Val loss 0.8458951337223637 accuracy 0.8727915287017822 macro_avg {'precision': 0.8789962296607244, 'recall': 0.8733599717004596, 'f1-score': 0.8737093024518107, 'support': 1132} weighted_avg {'precision': 0.8802720074138237, 'recall': 0.872791519434629, 'f1-score': 0.8738906557908421, 'support': 1132}
 
----------
Epoch 11/40
time = 334.95 secondes

Train loss 0.13537248278207042 accuracy 0.9734826683998108 macro_avg {'precision': 0.9718592955507914, 'recall': 0.9721426893885375, 'f1-score': 0.9719635946848397, 'support': 10182} weighted_avg {'precision': 0.9735764172785631, 'recall': 0.9734826163818503, 'f1-score': 0.9734947091333598, 'support': 10182}
 
time = 12.77 secondes

Val loss 0.9292668052252159 accuracy 0.8692579865455627 macro_avg {'precision': 0.8742609787487311, 'recall': 0.8682511322461327, 'f1-score': 0.8685106967864789, 'support': 1132} weighted_avg {'precision': 0.8761317867238058, 'recall': 0.8692579505300353, 'f1-score': 0.8698244543328109, 'support': 1132}
 
----------
Epoch 12/40
time = 331.85 secondes

Train loss 0.12447832517882003 accuracy 0.9761343598365784 macro_avg {'precision': 0.9752667795691776, 'recall': 0.9754357533181459, 'f1-score': 0.9753221171261053, 'support': 10182} weighted_avg {'precision': 0.9762429855276108, 'recall': 0.9761343547436653, 'f1-score': 0.9761611731233084, 'support': 10182}
 
time = 13.33 secondes

Val loss 0.8070173674336024 accuracy 0.8816254734992981 macro_avg {'precision': 0.8861051439250762, 'recall': 0.879978288780268, 'f1-score': 0.8810895658045999, 'support': 1132} weighted_avg {'precision': 0.885662034294811, 'recall': 0.8816254416961131, 'f1-score': 0.8816629814796115, 'support': 1132}
 
----------
Epoch 13/40
time = 334.93 secondes

Train loss 0.11090420216244823 accuracy 0.9781968593597412 macro_avg {'precision': 0.9775970109040916, 'recall': 0.9773366419239814, 'f1-score': 0.9774482920173047, 'support': 10182} weighted_avg {'precision': 0.9782498448743487, 'recall': 0.9781968179139658, 'f1-score': 0.9782051042010417, 'support': 10182}
 
time = 12.75 secondes

Val loss 0.9458135663319386 accuracy 0.8674911856651306 macro_avg {'precision': 0.8725951490191592, 'recall': 0.8638773618830811, 'f1-score': 0.8650481621048657, 'support': 1132} weighted_avg {'precision': 0.8740275801191232, 'recall': 0.8674911660777385, 'f1-score': 0.867372739351266, 'support': 1132}
 
----------
Epoch 14/40
time = 330.47 secondes

Train loss 0.09970658668328324 accuracy 0.9801610708236694 macro_avg {'precision': 0.9797216140822798, 'recall': 0.9794803544536279, 'f1-score': 0.9795868545736844, 'support': 10182} weighted_avg {'precision': 0.9801900373329033, 'recall': 0.9801610685523473, 'f1-score': 0.9801615574725563, 'support': 10182}
 
time = 12.02 secondes

Val loss 0.9065545936165096 accuracy 0.8692579865455627 macro_avg {'precision': 0.8698865831811526, 'recall': 0.8661014872364984, 'f1-score': 0.8657846566341123, 'support': 1132} weighted_avg {'precision': 0.8717534884048448, 'recall': 0.8692579505300353, 'f1-score': 0.8684314349776279, 'support': 1132}
 
----------
Epoch 15/40
time = 333.97 secondes

Train loss 0.12406885097693968 accuracy 0.9772146940231323 macro_avg {'precision': 0.9765184392521853, 'recall': 0.9757459995929152, 'f1-score': 0.9760632645153576, 'support': 10182} weighted_avg {'precision': 0.9773907362977957, 'recall': 0.9772146925947751, 'f1-score': 0.9772392903695424, 'support': 10182}
 
time = 12.60 secondes

Val loss 0.8511490140659128 accuracy 0.879858672618866 macro_avg {'precision': 0.8872759748394387, 'recall': 0.8744889049856907, 'f1-score': 0.8778952486238516, 'support': 1132} weighted_avg {'precision': 0.8851834221191308, 'recall': 0.8798586572438163, 'f1-score': 0.8798006393479522, 'support': 1132}
 
----------
Epoch 16/40
time = 330.42 secondes

Train loss 0.09835360516134095 accuracy 0.9808486104011536 macro_avg {'precision': 0.9807013115258931, 'recall': 0.9801579906783487, 'f1-score': 0.9803956797768366, 'support': 10182} weighted_avg {'precision': 0.980928895951354, 'recall': 0.9808485562757808, 'f1-score': 0.9808578980544198, 'support': 10182}
 
time = 12.76 secondes

Val loss 0.8963943457150583 accuracy 0.8754417300224304 macro_avg {'precision': 0.8777006763708464, 'recall': 0.8723843151279723, 'f1-score': 0.8722572700776764, 'support': 1132} weighted_avg {'precision': 0.8800249451079406, 'recall': 0.8754416961130742, 'f1-score': 0.8748406291414393, 'support': 1132}
 
----------
Epoch 17/40
time = 329.00 secondes

Train loss 0.08920944338165764 accuracy 0.9821253418922424 macro_avg {'precision': 0.981562288210663, 'recall': 0.981683478981957, 'f1-score': 0.9816139825775606, 'support': 10182} weighted_avg {'precision': 0.9821448468250156, 'recall': 0.9821253191907288, 'f1-score': 0.982126144681347, 'support': 10182}
 
time = 13.60 secondes

Val loss 0.9271768851686945 accuracy 0.8710247278213501 macro_avg {'precision': 0.8748621544858235, 'recall': 0.8688329025789597, 'f1-score': 0.8685334356959515, 'support': 1132} weighted_avg {'precision': 0.8796557594077141, 'recall': 0.8710247349823321, 'f1-score': 0.8719158191612786, 'support': 1132}
 
----------
Epoch 18/40
time = 333.49 secondes

Train loss 0.10488726551271636 accuracy 0.9814378619194031 macro_avg {'precision': 0.9806349100031229, 'recall': 0.9810268079196437, 'f1-score': 0.9807910249634508, 'support': 10182} weighted_avg {'precision': 0.9815163080009663, 'recall': 0.9814378314672952, 'f1-score': 0.9814386400939155, 'support': 10182}
 
time = 12.97 secondes

Val loss 0.8802848569185941 accuracy 0.8789752721786499 macro_avg {'precision': 0.8867781435199319, 'recall': 0.8728179661208809, 'f1-score': 0.87583965250091, 'support': 1132} weighted_avg {'precision': 0.8855040619275488, 'recall': 0.8789752650176679, 'f1-score': 0.8786054785918632, 'support': 1132}
 
----------
Epoch 19/40
time = 336.00 secondes

Train loss 0.08139354095332026 accuracy 0.98448246717453 macro_avg {'precision': 0.9838383022830378, 'recall': 0.983963494810539, 'f1-score': 0.9838899518778625, 'support': 10182} weighted_avg {'precision': 0.9845210509693758, 'recall': 0.9844824199567865, 'f1-score': 0.9844910260358182, 'support': 10182}
 
time = 12.45 secondes

Val loss 1.0890194665672155 accuracy 0.8657243847846985 macro_avg {'precision': 0.875938802415741, 'recall': 0.8652461661027756, 'f1-score': 0.8655516648775567, 'support': 1132} weighted_avg {'precision': 0.8812480142212875, 'recall': 0.8657243816254417, 'f1-score': 0.868317804342015, 'support': 1132}
 
----------
Epoch 20/40
time = 333.24 secondes

Train loss 0.08855659066808139 accuracy 0.9858574271202087 macro_avg {'precision': 0.9850047269537651, 'recall': 0.9851777159709186, 'f1-score': 0.9850731833499331, 'support': 10182} weighted_avg {'precision': 0.9859153573907543, 'recall': 0.9858573954036535, 'f1-score': 0.9858683834358382, 'support': 10182}
 
time = 13.13 secondes

Val loss 1.2882119325132266 accuracy 0.8365724682807922 macro_avg {'precision': 0.8534827475710299, 'recall': 0.842668796451807, 'f1-score': 0.8360833860416109, 'support': 1132} weighted_avg {'precision': 0.8639384675425926, 'recall': 0.8365724381625441, 'f1-score': 0.8374116261439554, 'support': 1132}
 
----------
Epoch 21/40
time = 332.59 secondes

Train loss 0.07982037768442822 accuracy 0.9858574271202087 macro_avg {'precision': 0.9846964850670133, 'recall': 0.9851492137391302, 'f1-score': 0.9848668149345876, 'support': 10182} weighted_avg {'precision': 0.9859745151742878, 'recall': 0.9858573954036535, 'f1-score': 0.9858657155586334, 'support': 10182}
 
time = 12.66 secondes

Val loss 1.0431076787158224 accuracy 0.870141327381134 macro_avg {'precision': 0.8760574541537975, 'recall': 0.8668616537770669, 'f1-score': 0.868102206486361, 'support': 1132} weighted_avg {'precision': 0.878268658973398, 'recall': 0.8701413427561837, 'f1-score': 0.8713152594607194, 'support': 1132}
 
----------
Epoch 22/40
time = 335.23 secondes

Train loss 0.07439737718914116 accuracy 0.9871341586112976 macro_avg {'precision': 0.9866706175245167, 'recall': 0.9865571907460513, 'f1-score': 0.9865974980304806, 'support': 10182} weighted_avg {'precision': 0.9871734679948088, 'recall': 0.9871341583186014, 'f1-score': 0.9871396128880008, 'support': 10182}
 
time = 12.74 secondes

Val loss 1.0043255940439797 accuracy 0.8727915287017822 macro_avg {'precision': 0.8740697932322462, 'recall': 0.8700566478769712, 'f1-score': 0.8695084742453906, 'support': 1132} weighted_avg {'precision': 0.8770274538232986, 'recall': 0.872791519434629, 'f1-score': 0.8724231987801973, 'support': 1132}
 
----------
Epoch 23/40
time = 329.90 secondes

Train loss 0.07628853159621368 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860767996122302, 'recall': 0.9859373820503782, 'f1-score': 0.98598722663805, 'support': 10182} weighted_avg {'precision': 0.9863827880720611, 'recall': 0.9863484580632489, 'f1-score': 0.9863453522818955, 'support': 10182}
 
time = 12.94 secondes

Val loss 0.9839521160384708 accuracy 0.8780918717384338 macro_avg {'precision': 0.8778535127102387, 'recall': 0.8768270322988256, 'f1-score': 0.8758718709930384, 'support': 1132} weighted_avg {'precision': 0.8801145064751886, 'recall': 0.8780918727915195, 'f1-score': 0.877581749874739, 'support': 1132}
 
----------
Epoch 24/40
time = 331.30 secondes

Train loss 0.07184549604840194 accuracy 0.9879198670387268 macro_avg {'precision': 0.9871491102316801, 'recall': 0.9868991087188123, 'f1-score': 0.9870131310586763, 'support': 10182} weighted_avg {'precision': 0.9879162806065185, 'recall': 0.987919858573954, 'f1-score': 0.9879096620955207, 'support': 10182}
 
time = 13.39 secondes

Val loss 1.1247576623339317 accuracy 0.8666077852249146 macro_avg {'precision': 0.8712631163967318, 'recall': 0.8662341568266194, 'f1-score': 0.8664101675050583, 'support': 1132} weighted_avg {'precision': 0.8739325003251336, 'recall': 0.8666077738515902, 'f1-score': 0.8677844005029112, 'support': 1132}
 
----------
Epoch 25/40
time = 331.02 secondes

Train loss 0.07484260986280984 accuracy 0.9869377613067627 macro_avg {'precision': 0.9859119192434932, 'recall': 0.9854280616957469, 'f1-score': 0.9856394314357901, 'support': 10182} weighted_avg {'precision': 0.9869510466727942, 'recall': 0.9869377332547633, 'f1-score': 0.9869203381243773, 'support': 10182}
 
time = 13.14 secondes

Val loss 1.0158131069442853 accuracy 0.880742073059082 macro_avg {'precision': 0.8839375749044172, 'recall': 0.8773281269947641, 'f1-score': 0.8769673543492618, 'support': 1132} weighted_avg {'precision': 0.8851031292000436, 'recall': 0.8807420494699647, 'f1-score': 0.8795681002314223, 'support': 1132}
 
----------
Epoch 26/40
time = 340.80 secondes

Train loss 0.046612817781377325 accuracy 0.9919465780258179 macro_avg {'precision': 0.9913636153600857, 'recall': 0.9911141902540017, 'f1-score': 0.9912296231468591, 'support': 10182} weighted_avg {'precision': 0.9919552966003448, 'recall': 0.9919465723826361, 'f1-score': 0.9919424025588944, 'support': 10182}
 
time = 13.05 secondes

Val loss 0.9572359329420732 accuracy 0.8886925578117371 macro_avg {'precision': 0.8901286961809657, 'recall': 0.8863156220419339, 'f1-score': 0.8873946629647692, 'support': 1132} weighted_avg {'precision': 0.8919407138581329, 'recall': 0.8886925795053003, 'f1-score': 0.8894490870462648, 'support': 1132}
 
----------
Epoch 27/40
time = 334.19 secondes

Train loss 0.05096403832125978 accuracy 0.9910627007484436 macro_avg {'precision': 0.9908493427641044, 'recall': 0.9907620414934323, 'f1-score': 0.9907914781202924, 'support': 10182} weighted_avg {'precision': 0.9910973819198716, 'recall': 0.9910626595953643, 'f1-score': 0.9910657813751469, 'support': 10182}
 
time = 13.14 secondes

Val loss 1.0672493460095236 accuracy 0.8674911856651306 macro_avg {'precision': 0.873350382927736, 'recall': 0.8685212199560803, 'f1-score': 0.8661814393062075, 'support': 1132} weighted_avg {'precision': 0.8742053056857069, 'recall': 0.8674911660777385, 'f1-score': 0.8658484316770308, 'support': 1132}
 
----------
Epoch 28/40
time = 334.45 secondes

Train loss 0.04459245488525346 accuracy 0.9924376606941223 macro_avg {'precision': 0.9922067158791604, 'recall': 0.9921922947807653, 'f1-score': 0.9921930085397973, 'support': 10182} weighted_avg {'precision': 0.9924441341840694, 'recall': 0.9924376350422314, 'f1-score': 0.9924343050153871, 'support': 10182}
 
time = 13.00 secondes

Val loss 1.0741434310524787 accuracy 0.8719081282615662 macro_avg {'precision': 0.8742513260937275, 'recall': 0.8676622504963746, 'f1-score': 0.8679386965567379, 'support': 1132} weighted_avg {'precision': 0.8772015933193811, 'recall': 0.8719081272084805, 'f1-score': 0.8721551941203499, 'support': 1132}
 
----------
Epoch 29/40
time = 332.21 secondes

Train loss 0.06100952997127492 accuracy 0.9900805354118347 macro_avg {'precision': 0.9899366762878412, 'recall': 0.9900404112055652, 'f1-score': 0.9899447753108817, 'support': 10182} weighted_avg {'precision': 0.9901542827394595, 'recall': 0.9900805342761736, 'f1-score': 0.9900732523237774, 'support': 10182}
 
time = 11.56 secondes

Val loss 1.1557425374776358 accuracy 0.8683745861053467 macro_avg {'precision': 0.8805261825846487, 'recall': 0.8725480579332855, 'f1-score': 0.870783867530441, 'support': 1132} weighted_avg {'precision': 0.887312866592711, 'recall': 0.8683745583038869, 'f1-score': 0.8726315806247167, 'support': 1132}
 
----------
Epoch 30/40
time = 333.42 secondes

Train loss 0.041770610234414265 accuracy 0.9929287433624268 macro_avg {'precision': 0.992684469204667, 'recall': 0.992734346937078, 'f1-score': 0.9927008305808543, 'support': 10182} weighted_avg {'precision': 0.992944997054916, 'recall': 0.9929286977018268, 'f1-score': 0.9929283040914041, 'support': 10182}
 
time = 13.57 secondes

Val loss 1.0035736660829058 accuracy 0.8939929604530334 macro_avg {'precision': 0.8965686195812712, 'recall': 0.8931678681479804, 'f1-score': 0.8940841409955944, 'support': 1132} weighted_avg {'precision': 0.8962285597630401, 'recall': 0.8939929328621908, 'f1-score': 0.89428539518251, 'support': 1132}
 
----------
Epoch 31/40
time = 336.18 secondes

Train loss 0.03545568226195606 accuracy 0.9939108490943909 macro_avg {'precision': 0.9937187031089962, 'recall': 0.9937975618583479, 'f1-score': 0.9937511446478023, 'support': 10182} weighted_avg {'precision': 0.9939221798134821, 'recall': 0.9939108230210175, 'f1-score': 0.9939093190013023, 'support': 10182}
 
time = 12.66 secondes

Val loss 1.0071542676237764 accuracy 0.8842756152153015 macro_avg {'precision': 0.8863268022008954, 'recall': 0.8852562186361885, 'f1-score': 0.8845995944218629, 'support': 1132} weighted_avg {'precision': 0.8876504896188037, 'recall': 0.8842756183745583, 'f1-score': 0.8847394722640972, 'support': 1132}
 
----------
Epoch 32/40
time = 336.62 secondes

Train loss 0.024708321983540612 accuracy 0.9954822659492493 macro_avg {'precision': 0.9952978933302269, 'recall': 0.9951485626310156, 'f1-score': 0.9952172757567792, 'support': 10182} weighted_avg {'precision': 0.9954895921122222, 'recall': 0.9954822235317227, 'f1-score': 0.9954807074764135, 'support': 10182}
 
time = 13.19 secondes

Val loss 1.173345203650941 accuracy 0.879858672618866 macro_avg {'precision': 0.8854282049105157, 'recall': 0.8798079829905794, 'f1-score': 0.8796728119986051, 'support': 1132} weighted_avg {'precision': 0.8870399401459816, 'recall': 0.8798586572438163, 'f1-score': 0.8802789290204417, 'support': 1132}
 
----------
Epoch 33/40
time = 329.38 secondes

Train loss 0.029683094824319984 accuracy 0.9947947859764099 macro_avg {'precision': 0.9945674454120967, 'recall': 0.9945527808894792, 'f1-score': 0.994553506367024, 'support': 10182} weighted_avg {'precision': 0.994811309848744, 'recall': 0.9947947358082891, 'f1-score': 0.9947963110277482, 'support': 10182}
 
time = 12.10 secondes

Val loss 1.0043334654310712 accuracy 0.8878092169761658 macro_avg {'precision': 0.888231555395552, 'recall': 0.8885461732050668, 'f1-score': 0.8874501669195786, 'support': 1132} weighted_avg {'precision': 0.8891365475817865, 'recall': 0.8878091872791519, 'f1-score': 0.8874729222378966, 'support': 1132}
 
----------
Epoch 34/40
time = 331.43 secondes

Train loss 0.02141412172059234 accuracy 0.9964643716812134 macro_avg {'precision': 0.9963602584341895, 'recall': 0.9961200754560998, 'f1-score': 0.9962340930124794, 'support': 10182} weighted_avg {'precision': 0.9964733638561522, 'recall': 0.9964643488509134, 'f1-score': 0.9964638286053108, 'support': 10182}
 
time = 12.43 secondes

Val loss 1.0953186896394853 accuracy 0.880742073059082 macro_avg {'precision': 0.8792649647385369, 'recall': 0.8806035839575707, 'f1-score': 0.8785288056075944, 'support': 1132} weighted_avg {'precision': 0.8832933962070199, 'recall': 0.8807420494699647, 'f1-score': 0.8806159606091619, 'support': 1132}
 
----------
Epoch 35/40
time = 329.53 secondes

Train loss 0.023405108581674102 accuracy 0.9964643716812134 macro_avg {'precision': 0.996417623640356, 'recall': 0.9962956408211004, 'f1-score': 0.9963504277695249, 'support': 10182} weighted_avg {'precision': 0.9964783932462606, 'recall': 0.9964643488509134, 'f1-score': 0.9964651935098909, 'support': 10182}
 
time = 13.47 secondes

Val loss 1.2204993128910335 accuracy 0.8763250708580017 macro_avg {'precision': 0.8837608649249441, 'recall': 0.8776955657005472, 'f1-score': 0.8784129308300443, 'support': 1132} weighted_avg {'precision': 0.8844252788451941, 'recall': 0.8763250883392226, 'f1-score': 0.8779638643158906, 'support': 1132}
 
----------
Epoch 36/40
time = 333.37 secondes

Train loss 0.023791978947117046 accuracy 0.9959732890129089 macro_avg {'precision': 0.9956072391411205, 'recall': 0.9957944007454674, 'f1-score': 0.9956974767093936, 'support': 10182} weighted_avg {'precision': 0.995983149625425, 'recall': 0.995973286191318, 'f1-score': 0.9959750368209915, 'support': 10182}
 
time = 13.59 secondes

Val loss 1.1389838456972272 accuracy 0.8851590156555176 macro_avg {'precision': 0.8873200699735596, 'recall': 0.8838992120267873, 'f1-score': 0.8839124215152252, 'support': 1132} weighted_avg {'precision': 0.8891946135168054, 'recall': 0.8851590106007067, 'f1-score': 0.8854633498977331, 'support': 1132}
 
----------
Epoch 37/40
time = 334.90 secondes

Train loss 0.00995891442376956 accuracy 0.9980357885360718 macro_avg {'precision': 0.9978806335215742, 'recall': 0.9978450255271044, 'f1-score': 0.9978606370822257, 'support': 10182} weighted_avg {'precision': 0.9980390770304257, 'recall': 0.9980357493616185, 'f1-score': 0.9980353840658628, 'support': 10182}
 
time = 13.31 secondes

Val loss 1.1804133917602755 accuracy 0.8860424160957336 macro_avg {'precision': 0.8851131065255791, 'recall': 0.8879175268395942, 'f1-score': 0.8849512111931439, 'support': 1132} weighted_avg {'precision': 0.8887044394853684, 'recall': 0.8860424028268551, 'f1-score': 0.8857148350348543, 'support': 1132}
 
----------
Epoch 38/40
time = 332.23 secondes

Train loss 0.01750983247761531 accuracy 0.9970536828041077 macro_avg {'precision': 0.9969773543545669, 'recall': 0.9969499675843073, 'f1-score': 0.9969606115686129, 'support': 10182} weighted_avg {'precision': 0.9970593295239119, 'recall': 0.9970536240424278, 'f1-score': 0.9970534221592197, 'support': 10182}
 
time = 12.49 secondes

Val loss 1.103777549795268 accuracy 0.8886925578117371 macro_avg {'precision': 0.8905227981574091, 'recall': 0.8887527483976863, 'f1-score': 0.8885369819420686, 'support': 1132} weighted_avg {'precision': 0.8921651099404755, 'recall': 0.8886925795053003, 'f1-score': 0.8892990329026379, 'support': 1132}
 
----------
Epoch 39/40
time = 323.46 secondes

Train loss 0.008292839090115325 accuracy 0.9985268115997314 macro_avg {'precision': 0.998447514716535, 'recall': 0.9983362812517509, 'f1-score': 0.9983907475437837, 'support': 10182} weighted_avg {'precision': 0.9985276812360937, 'recall': 0.998526812021214, 'f1-score': 0.9985263178326634, 'support': 10182}
 
time = 13.15 secondes

Val loss 1.1089131998694837 accuracy 0.8878092169761658 macro_avg {'precision': 0.8893558165564766, 'recall': 0.8878263983292494, 'f1-score': 0.8870482362397396, 'support': 1132} weighted_avg {'precision': 0.8915414747539375, 'recall': 0.8878091872791519, 'f1-score': 0.8881365619815087, 'support': 1132}
 
----------
Epoch 40/40
time = 328.17 secondes

Train loss 0.005323385365122496 accuracy 0.998919665813446 macro_avg {'precision': 0.9988759431978508, 'recall': 0.9987995393022112, 'f1-score': 0.9988367426638277, 'support': 10182} weighted_avg {'precision': 0.9989198765424272, 'recall': 0.9989196621488902, 'f1-score': 0.9989189101843652, 'support': 10182}
 
time = 13.56 secondes

Val loss 1.138992484068118 accuracy 0.8869258165359497 macro_avg {'precision': 0.8885870417377306, 'recall': 0.8874022975431369, 'f1-score': 0.8863671069475482, 'support': 1132} weighted_avg {'precision': 0.8910469636948277, 'recall': 0.8869257950530035, 'f1-score': 0.8872780989569596, 'support': 1132}
 
----------
best_accuracy 0.8939929604530334 best_epoch 30 macro_avg {'precision': 0.8965686195812712, 'recall': 0.8931678681479804, 'f1-score': 0.8940841409955944, 'support': 1132} weighted_avg {'precision': 0.8962285597630401, 'recall': 0.8939929328621908, 'f1-score': 0.89428539518251, 'support': 1132}

average train time 332.896680867672

average val time 13.018411338329315
 
time = 82.40 secondes

test_accuracy 0.8289962410926819 macro_avg {'precision': 0.8236943081599859, 'recall': 0.8168167085548182, 'f1-score': 0.8171971107953157, 'support': 7532} weighted_avg {'precision': 0.8318117279562787, 'recall': 0.828996282527881, 'f1-score': 0.8275673330115512, 'support': 7532}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_4
----------
Epoch 1/40
time = 402.63 secondes

Train loss 0.27835542363626464 micro_f1_score 0.5899596921949432 
 
time = 27.87 secondes

Val loss 0.2452615577666486 micro_f1_score 0.6069612827532265
 
----------
Epoch 2/40
time = 393.59 secondes

Train loss 0.18318196979796028 micro_f1_score 0.7457018861625773 
 
time = 27.45 secondes

Val loss 0.2141163867028033 micro_f1_score 0.6908366533864542
 
----------
Epoch 3/40
time = 395.53 secondes

Train loss 0.15687331441487815 micro_f1_score 0.7930231608185939 
 
time = 29.32 secondes

Val loss 0.2009841516369679 micro_f1_score 0.7049960348929423
 
----------
Epoch 4/40
time = 396.10 secondes

Train loss 0.13895548376682643 micro_f1_score 0.8216555320189017 
 
time = 25.78 secondes

Val loss 0.21139927660344077 micro_f1_score 0.7038327526132405
 
----------
Epoch 5/40
time = 401.36 secondes

Train loss 0.12304564714599568 micro_f1_score 0.847875262562611 
 
time = 28.96 secondes

Val loss 0.2207662028367402 micro_f1_score 0.7104567761419402
 
----------
Epoch 6/40
time = 401.22 secondes

Train loss 0.11188750495412597 micro_f1_score 0.8651125401929259 
 
time = 26.73 secondes

Val loss 0.2208931072325003 micro_f1_score 0.7271369914147069
 
----------
Epoch 7/40
time = 400.80 secondes

Train loss 0.09971701890767158 micro_f1_score 0.8828361780188226 
 
time = 29.29 secondes

Val loss 0.22936875214342212 micro_f1_score 0.7301943198804185
 
----------
Epoch 8/40
time = 392.04 secondes

Train loss 0.09061704847777077 micro_f1_score 0.8954678942773235 
 
time = 27.48 secondes

Val loss 0.24165012919511952 micro_f1_score 0.7270029673590506
 
----------
Epoch 9/40
time = 394.59 secondes

Train loss 0.07852533420900236 micro_f1_score 0.9114890936294197 
 
time = 25.31 secondes

Val loss 0.2640031077822701 micro_f1_score 0.7235142118863049
 
----------
Epoch 10/40
time = 394.00 secondes

Train loss 0.06919512414407018 micro_f1_score 0.9243822333437599 
 
time = 28.42 secondes

Val loss 0.27538306424852277 micro_f1_score 0.7272058823529411
 
----------
Epoch 11/40
time = 392.09 secondes

Train loss 0.060622835930789244 micro_f1_score 0.9348960361342574 
 
time = 29.31 secondes

Val loss 0.2918878589741519 micro_f1_score 0.7295231161266836
 
----------
Epoch 12/40
time = 391.25 secondes

Train loss 0.05298558682673149 micro_f1_score 0.9422659640421575 
 
time = 26.28 secondes

Val loss 0.3167036274661783 micro_f1_score 0.725567976920303
 
----------
Epoch 13/40
time = 397.14 secondes

Train loss 0.045497214808841946 micro_f1_score 0.951384330231301 
 
time = 27.14 secondes

Val loss 0.33608502418291375 micro_f1_score 0.7245960502692997
 
----------
Epoch 14/40
time = 403.63 secondes

Train loss 0.040948392009270286 micro_f1_score 0.9558189655172414 
 
time = 27.16 secondes

Val loss 0.36017381375441787 micro_f1_score 0.7255652173913044
 
----------
Epoch 15/40
time = 398.87 secondes

Train loss 0.03486999354497236 micro_f1_score 0.9633781190019194 
 
time = 29.58 secondes

Val loss 0.38669658562199016 micro_f1_score 0.7162258756254467
 
----------
Epoch 16/40
time = 392.53 secondes

Train loss 0.03137144503573812 micro_f1_score 0.9667625071880392 
 
time = 26.83 secondes

Val loss 0.39432866016372303 micro_f1_score 0.7259515570934256
 
----------
Epoch 17/40
time = 395.06 secondes

Train loss 0.028552226293181816 micro_f1_score 0.9687511981902533 
 
time = 23.60 secondes

Val loss 0.40279645265125835 micro_f1_score 0.7318611987381702
 
----------
Epoch 18/40
time = 393.34 secondes

Train loss 0.02524837861430143 micro_f1_score 0.9738691931540342 
 
time = 26.18 secondes

Val loss 0.42645922498624833 micro_f1_score 0.725359522974395
 
----------
Epoch 19/40
time = 393.53 secondes

Train loss 0.02175406551361923 micro_f1_score 0.9768366332849171 
 
time = 29.73 secondes

Val loss 0.4435547753924229 micro_f1_score 0.728425501937302
 
----------
Epoch 20/40
time = 395.77 secondes

Train loss 0.020986137626223846 micro_f1_score 0.9757959838130869 
 
time = 26.91 secondes

Val loss 0.44824328676598973 micro_f1_score 0.7300140252454417
 
----------
Epoch 21/40
time = 430.08 secondes

Train loss 0.01754872239423446 micro_f1_score 0.9811565456209949 
 
time = 33.80 secondes

Val loss 0.47657344771213217 micro_f1_score 0.7179665738161559
 
----------
Epoch 22/40
time = 504.36 secondes

Train loss 0.01653669870611666 micro_f1_score 0.9823275697545707 
 
time = 31.70 secondes

Val loss 0.47863402327553173 micro_f1_score 0.7304714989444054
 
----------
Epoch 23/40
time = 501.18 secondes

Train loss 0.015012372872395744 micro_f1_score 0.9834527985359157 
 
time = 33.35 secondes

Val loss 0.4997277384410139 micro_f1_score 0.7179115300942713
 
----------
Epoch 24/40
time = 494.52 secondes

Train loss 0.014764815085511949 micro_f1_score 0.9847560975609756 
 
time = 32.60 secondes

Val loss 0.5142381545461592 micro_f1_score 0.7189072609633357
 
----------
Epoch 25/40
time = 505.39 secondes

Train loss 0.01230050232554424 micro_f1_score 0.9867468961840201 
 
time = 35.74 secondes

Val loss 0.5360125901757694 micro_f1_score 0.7207207207207208
 
----------
Epoch 26/40
time = 498.94 secondes

Train loss 0.010706651241317715 micro_f1_score 0.9878188047202132 
 
time = 37.15 secondes

Val loss 0.524683514823679 micro_f1_score 0.7324046920821116
 
----------
Epoch 27/40
time = 502.55 secondes

Train loss 0.010022510651492872 micro_f1_score 0.9893021662161648 
 
time = 33.27 secondes

Val loss 0.5376862062782538 micro_f1_score 0.7276736493936052
 
----------
Epoch 28/40
time = 501.72 secondes

Train loss 0.009202559803285309 micro_f1_score 0.9907516650808754 
 
time = 33.21 secondes

Val loss 0.5565266611634708 micro_f1_score 0.7260022066936374
 
----------
Epoch 29/40
time = 493.95 secondes

Train loss 0.008924861117222528 micro_f1_score 0.9906684441058846 
 
time = 33.71 secondes

Val loss 0.5788479391180101 micro_f1_score 0.7208480565371024
 
----------
Epoch 30/40
time = 508.47 secondes

Train loss 0.008393572201948536 micro_f1_score 0.991783323189288 
 
time = 32.08 secondes

Val loss 0.5946134087003645 micro_f1_score 0.7213687150837989
 
----------
Epoch 31/40
time = 510.23 secondes

Train loss 0.007774334758984083 micro_f1_score 0.9917575113001861 
 
time = 33.84 secondes

Val loss 0.5896715306844867 micro_f1_score 0.728898426323319
 
----------
Epoch 32/40
time = 505.14 secondes

Train loss 0.006482164221697449 micro_f1_score 0.9936523623094758 
 
time = 31.14 secondes

Val loss 0.5965164626230959 micro_f1_score 0.7286596440247004
 
----------
Epoch 33/40
time = 499.00 secondes

Train loss 0.005477061932412595 micro_f1_score 0.9941039978698315 
 
time = 32.61 secondes

Val loss 0.6177075014251178 micro_f1_score 0.7314449623520975
 
----------
Epoch 34/40
time = 500.15 secondes

Train loss 0.005220168121847671 micro_f1_score 0.9945263798084233 
 
time = 33.51 secondes

Val loss 0.621953552863637 micro_f1_score 0.7250883392226147
 
----------
Epoch 35/40
time = 506.80 secondes

Train loss 0.004017218703959336 micro_f1_score 0.9961633428300095 
 
time = 32.97 secondes

Val loss 0.6172113819200484 micro_f1_score 0.7278761061946902
 
----------
Epoch 36/40
time = 500.74 secondes

Train loss 0.003395507193164195 micro_f1_score 0.9968830773909076 
 
time = 31.26 secondes

Val loss 0.6174697016106278 micro_f1_score 0.7296229802513465
 
----------
Epoch 37/40
time = 500.18 secondes

Train loss 0.00287494616146465 micro_f1_score 0.9973789173789174 
 
time = 29.48 secondes

Val loss 0.6338280102268594 micro_f1_score 0.7288440763413756
 
----------
Epoch 38/40
time = 446.88 secondes

Train loss 0.0026567595532346663 micro_f1_score 0.9976064739181641 
 
time = 30.64 secondes

Val loss 0.6229785343662637 micro_f1_score 0.7378223495702005
 
----------
Epoch 39/40
time = 431.67 secondes

Train loss 0.001776002561366506 micro_f1_score 0.9980629723878612 
 
time = 29.96 secondes

Val loss 0.6354399704542316 micro_f1_score 0.7322522522522523
 
----------
Epoch 40/40
time = 431.07 secondes

Train loss 0.0013591761616832325 micro_f1_score 0.9985942783328902 
 
time = 28.92 secondes

Val loss 0.6483188872454596 micro_f1_score 0.7317248829672308
 
----------
best_f1_socre 0.7378223495702005 best_epoch 38

average train time 442.45264917612076

average val time 30.006023645401
 
time = 33.22 secondes

test_f1_score 0.7142371729527693

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_4
----------
Epoch 1/40
time = 451.37 secondes

Train loss 0.28617023861891516 micro_f1_score 0.5670743005373355 
 
time = 31.66 secondes

Val loss 0.24933514414263552 micro_f1_score 0.5820408163265306
 
----------
Epoch 2/40
time = 439.35 secondes

Train loss 0.1909882326652338 micro_f1_score 0.7283557394002069 
 
time = 30.72 secondes

Val loss 0.20707672455760298 micro_f1_score 0.6865079365079364
 
----------
Epoch 3/40
time = 432.04 secondes

Train loss 0.16451445591409464 micro_f1_score 0.7782300740861352 
 
time = 29.00 secondes

Val loss 0.1956548069099911 micro_f1_score 0.7207920792079209
 
----------
Epoch 4/40
time = 436.70 secondes

Train loss 0.1442924208670586 micro_f1_score 0.8098733564572074 
 
time = 29.53 secondes

Val loss 0.18974341488763935 micro_f1_score 0.732943469785575
 
----------
Epoch 5/40
time = 443.40 secondes

Train loss 0.1268449169961182 micro_f1_score 0.8389915427472042 
 
time = 29.01 secondes

Val loss 0.19753405561701196 micro_f1_score 0.7235521235521236
 
----------
Epoch 6/40
time = 437.76 secondes

Train loss 0.1141021536931664 micro_f1_score 0.8588727345150368 
 
time = 28.61 secondes

Val loss 0.19246133062683168 micro_f1_score 0.7468690702087286
 
----------
Epoch 7/40
time = 431.07 secondes

Train loss 0.10278181340041999 micro_f1_score 0.87896676042946 
 
time = 30.61 secondes

Val loss 0.20653372111379123 micro_f1_score 0.7434750186428039
 
----------
Epoch 8/40
time = 433.18 secondes

Train loss 0.09184434771336414 micro_f1_score 0.8936856176771252 
 
time = 29.02 secondes

Val loss 0.22254196713205243 micro_f1_score 0.7352941176470589
 
----------
Epoch 9/40
time = 440.77 secondes

Train loss 0.08130516148012903 micro_f1_score 0.9074851827138203 
 
time = 30.90 secondes

Val loss 0.22257078115324505 micro_f1_score 0.7417664670658682
 
----------
Epoch 10/40
time = 427.44 secondes

Train loss 0.07423653498224847 micro_f1_score 0.9168686947681238 
 
time = 29.37 secondes

Val loss 0.24128516525274418 micro_f1_score 0.7363038714390066
 
----------
Epoch 11/40
time = 421.51 secondes

Train loss 0.06510829981835979 micro_f1_score 0.9290879402845812 
 
time = 28.57 secondes

Val loss 0.2503926210471841 micro_f1_score 0.7435137138621201
 
----------
Epoch 12/40
time = 427.23 secondes

Train loss 0.05860014844241107 micro_f1_score 0.9370243826681162 
 
time = 27.53 secondes

Val loss 0.277898730557473 micro_f1_score 0.7345635202271115
 
----------
Epoch 13/40
time = 432.04 secondes

Train loss 0.05174838063718231 micro_f1_score 0.9460128393533918 
 
time = 29.56 secondes

Val loss 0.28897548576847454 micro_f1_score 0.7431734317343174
 
----------
Epoch 14/40
time = 426.57 secondes

Train loss 0.04476571661264946 micro_f1_score 0.9534075104311543 
 
time = 27.86 secondes

Val loss 0.3057216284949271 micro_f1_score 0.7428987618353969
 
----------
Epoch 15/40
time = 433.29 secondes

Train loss 0.040589861024112384 micro_f1_score 0.9592230016187466 
 
time = 27.49 secondes

Val loss 0.30885175169735657 micro_f1_score 0.7485754985754985
 
----------
Epoch 16/40
time = 422.72 secondes

Train loss 0.03607431903359824 micro_f1_score 0.9619853789919199 
 
time = 28.38 secondes

Val loss 0.34673318437865525 micro_f1_score 0.7361702127659575
 
----------
Epoch 17/40
time = 421.40 secondes

Train loss 0.03205655095270239 micro_f1_score 0.9669840294840295 
 
time = 29.79 secondes

Val loss 0.3643936033620209 micro_f1_score 0.7308228730822873
 
----------
Epoch 18/40
time = 423.04 secondes

Train loss 0.02857699996638657 micro_f1_score 0.9694390122320642 
 
time = 29.49 secondes

Val loss 0.35009989459983637 micro_f1_score 0.7528735632183908
 
----------
Epoch 19/40
time = 428.31 secondes

Train loss 0.02485226334758556 micro_f1_score 0.9739196940726578 
 
time = 28.88 secondes

Val loss 0.3667810471331487 micro_f1_score 0.7449243263196752
 
----------
Epoch 20/40
time = 427.99 secondes

Train loss 0.022786922170098887 micro_f1_score 0.9757459831675593 
 
time = 29.80 secondes

Val loss 0.3858060752514933 micro_f1_score 0.74765003615329
 
----------
Epoch 21/40
time = 426.57 secondes

Train loss 0.02093471247269688 micro_f1_score 0.9780509218612817 
 
time = 28.60 secondes

Val loss 0.402369458655842 micro_f1_score 0.7536023054755042
 
----------
Epoch 22/40
time = 422.42 secondes

Train loss 0.019518308968258066 micro_f1_score 0.9787428920352631 
 
time = 28.68 secondes

Val loss 0.4122204506983522 micro_f1_score 0.7433881343817011
 
----------
Epoch 23/40
time = 434.44 secondes

Train loss 0.0175576055379425 micro_f1_score 0.9812831166850913 
 
time = 29.82 secondes

Val loss 0.42084259051279943 micro_f1_score 0.7470414201183432
 
----------
Epoch 24/40
time = 426.28 secondes

Train loss 0.01571873488803478 micro_f1_score 0.9822796387332801 
 
time = 30.01 secondes

Val loss 0.4285277603346793 micro_f1_score 0.7449664429530202
 
----------
Epoch 25/40
time = 431.83 secondes

Train loss 0.013936012714544336 micro_f1_score 0.9853680841335163 
 
time = 28.96 secondes

Val loss 0.45205920226261265 micro_f1_score 0.7357475797776979
 
----------
Epoch 26/40
time = 425.50 secondes

Train loss 0.012964249218746953 micro_f1_score 0.9863650213284582 
 
time = 30.05 secondes

Val loss 0.46468169865061026 micro_f1_score 0.7394160583941607
 
----------
Epoch 27/40
time = 427.34 secondes

Train loss 0.01115150497118504 micro_f1_score 0.9877765507787213 
 
time = 29.52 secondes

Val loss 0.4681125970893219 micro_f1_score 0.7447973713033954
 
----------
Epoch 28/40
time = 432.56 secondes

Train loss 0.012435556342104253 micro_f1_score 0.9874537619646875 
 
time = 30.49 secondes

Val loss 0.4776750034728988 micro_f1_score 0.7424023154848046
 
----------
Epoch 29/40
time = 435.17 secondes

Train loss 0.009497811039840895 micro_f1_score 0.9899596866205218 
 
time = 30.07 secondes

Val loss 0.489494866645727 micro_f1_score 0.740444120859119
 
----------
Epoch 30/40
time = 448.64 secondes

Train loss 0.008922273720672164 micro_f1_score 0.9910925009516559 
 
time = 29.08 secondes

Val loss 0.5033300702200562 micro_f1_score 0.7415485278080697
 
----------
Epoch 31/40
time = 432.52 secondes

Train loss 0.007713117782960736 micro_f1_score 0.992118789263278 
 
time = 30.09 secondes

Val loss 0.5081678795032814 micro_f1_score 0.7444364680545585
 
----------
Epoch 32/40
time = 438.63 secondes

Train loss 0.007719554577567111 micro_f1_score 0.9928883818216391 
 
time = 28.73 secondes

Val loss 0.5072529726341123 micro_f1_score 0.7524394651246837
 
----------
Epoch 33/40
time = 423.07 secondes

Train loss 0.005785431725149744 micro_f1_score 0.9941057915351561 
 
time = 29.72 secondes

Val loss 0.5329373704849697 micro_f1_score 0.742429640185251
 
----------
Epoch 34/40
time = 431.25 secondes

Train loss 0.005350025254370554 micro_f1_score 0.994979079497908 
 
time = 29.39 secondes

Val loss 0.5145497620105743 micro_f1_score 0.7505391804457225
 
----------
Epoch 35/40
time = 423.29 secondes

Train loss 0.0053946307836028875 micro_f1_score 0.9943313677002092 
 
time = 28.91 secondes

Val loss 0.5489238671592025 micro_f1_score 0.7469287469287468
 
----------
Epoch 36/40
time = 433.50 secondes

Train loss 0.0045624109499340605 micro_f1_score 0.9959295469243352 
 
time = 30.43 secondes

Val loss 0.5407925734265906 micro_f1_score 0.7500878734622145
 
----------
Epoch 37/40
time = 425.45 secondes

Train loss 0.004425058707943003 micro_f1_score 0.9964645504656909 
 
time = 29.22 secondes

Val loss 0.5383047720447915 micro_f1_score 0.7543424317617867
 
----------
Epoch 38/40
time = 428.33 secondes

Train loss 0.0030004428642666776 micro_f1_score 0.9973767250883929 
 
time = 29.01 secondes

Val loss 0.5369992339220203 micro_f1_score 0.7582769668921324
 
----------
Epoch 39/40
time = 424.19 secondes

Train loss 0.0027933124213787935 micro_f1_score 0.9970357984342936 
 
time = 30.73 secondes

Val loss 0.5379604717991391 micro_f1_score 0.7576840600428878
 
----------
Epoch 40/40
time = 420.66 secondes

Train loss 0.0022051112397568906 micro_f1_score 0.9980232646544515 
 
time = 28.07 secondes

Val loss 0.5489527778547318 micro_f1_score 0.752566371681416
 
----------
best_f1_socre 0.7582769668921324 best_epoch 38

average train time 430.7203875362873

average val time 29.383452171087264
 
time = 31.47 secondes

test_f1_score 0.7387074357192495

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_4
----------
Epoch 1/40
time = 429.87 secondes

Train loss 0.2955692355025996 micro_f1_score 0.5424494985167396 
 
time = 29.86 secondes

Val loss 0.2598283872252605 micro_f1_score 0.5054945054945054
 
----------
Epoch 2/40
time = 413.43 secondes

Train loss 0.20186503805421493 micro_f1_score 0.7121769656980925 
 
time = 29.39 secondes

Val loss 0.21941414780792642 micro_f1_score 0.6756329113924051
 
----------
Epoch 3/40
time = 415.46 secondes

Train loss 0.17281729358810563 micro_f1_score 0.763831544178365 
 
time = 29.71 secondes

Val loss 0.21560389096619653 micro_f1_score 0.685192536720921
 
----------
Epoch 4/40
time = 421.32 secondes

Train loss 0.15401634584340426 micro_f1_score 0.7933057139341235 
 
time = 28.89 secondes

Val loss 0.2016155146917359 micro_f1_score 0.7160493827160495
 
----------
Epoch 5/40
time = 420.40 secondes

Train loss 0.13883409356815857 micro_f1_score 0.8217424764064969 
 
time = 28.08 secondes

Val loss 0.20235004349321614 micro_f1_score 0.7207619047619048
 
----------
Epoch 6/40
time = 428.25 secondes

Train loss 0.12607904731354735 micro_f1_score 0.8410380205190102 
 
time = 28.95 secondes

Val loss 0.2084699861827444 micro_f1_score 0.7242955064737243
 
----------
Epoch 7/40
time = 426.61 secondes

Train loss 0.11380435222306767 micro_f1_score 0.8603691987346335 
 
time = 30.43 secondes

Val loss 0.21493977601410913 micro_f1_score 0.7339380196523054
 
----------
Epoch 8/40
time = 419.79 secondes

Train loss 0.10378934638994235 micro_f1_score 0.873734767594173 
 
time = 27.94 secondes

Val loss 0.21475137098402272 micro_f1_score 0.7385303991048117
 
----------
Epoch 9/40
time = 424.02 secondes

Train loss 0.09502150597352836 micro_f1_score 0.8858584266120131 
 
time = 26.88 secondes

Val loss 0.23553363013951506 micro_f1_score 0.7327844311377245
 
----------
Epoch 10/40
time = 414.16 secondes

Train loss 0.08503593021231863 micro_f1_score 0.9022320025149323 
 
time = 29.08 secondes

Val loss 0.25223877525231875 micro_f1_score 0.7326732673267327
 
----------
Epoch 11/40
time = 421.82 secondes

Train loss 0.07568187591963792 micro_f1_score 0.9144914491449145 
 
time = 29.11 secondes

Val loss 0.27435968413216166 micro_f1_score 0.7252827435242613
 
----------
Epoch 12/40
time = 418.11 secondes

Train loss 0.06888321170180634 micro_f1_score 0.9233764211182058 
 
time = 26.68 secondes

Val loss 0.27653343132773384 micro_f1_score 0.7297396406307297
 
----------
Epoch 13/40
time = 423.19 secondes

Train loss 0.06015386259778999 micro_f1_score 0.9359128445702323 
 
time = 29.34 secondes

Val loss 0.2880691131118868 micro_f1_score 0.7327021121631464
 
----------
Epoch 14/40
time = 414.97 secondes

Train loss 0.05525409397543282 micro_f1_score 0.9417907561400116 
 
time = 28.03 secondes

Val loss 0.30168967327622115 micro_f1_score 0.7345003646973013
 
----------
Epoch 15/40
time = 424.14 secondes

Train loss 0.04911473225466571 micro_f1_score 0.9488318208148291 
 
time = 28.91 secondes

Val loss 0.3137567746834677 micro_f1_score 0.7376509330406147
 
----------
Epoch 16/40
time = 423.01 secondes

Train loss 0.04320152428374534 micro_f1_score 0.9558307294680399 
 
time = 30.16 secondes

Val loss 0.3300062002705746 micro_f1_score 0.742133815551537
 
----------
Epoch 17/40
time = 420.63 secondes

Train loss 0.03846156321453384 micro_f1_score 0.9617044228694716 
 
time = 28.94 secondes

Val loss 0.3410935699939728 micro_f1_score 0.7460608281421767
 
----------
Epoch 18/40
time = 408.89 secondes

Train loss 0.035217401440997886 micro_f1_score 0.9639573796976574 
 
time = 27.51 secondes

Val loss 0.34966778767402057 micro_f1_score 0.7420058139534884
 
----------
Epoch 19/40
time = 417.80 secondes

Train loss 0.03216989442867621 micro_f1_score 0.9672710510141365 
 
time = 29.03 secondes

Val loss 0.35024095851866927 micro_f1_score 0.744983582634075
 
----------
Epoch 20/40
time = 410.25 secondes

Train loss 0.027753066647114015 micro_f1_score 0.9725460122699386 
 
time = 30.43 secondes

Val loss 0.36382528260105945 micro_f1_score 0.7481857764876633
 
----------
Epoch 21/40
time = 412.57 secondes

Train loss 0.025518193468871013 micro_f1_score 0.9745022970903523 
 
time = 29.09 secondes

Val loss 0.38372289914576735 micro_f1_score 0.7488721804511278
 
----------
Epoch 22/40
time = 420.41 secondes

Train loss 0.02354349637837233 micro_f1_score 0.976031193852976 
 
time = 27.08 secondes

Val loss 0.4100163671814027 micro_f1_score 0.7394522575869726
 
----------
Epoch 23/40
time = 420.97 secondes

Train loss 0.021577765012363408 micro_f1_score 0.9778015921616656 
 
time = 30.38 secondes

Val loss 0.4130425183255164 micro_f1_score 0.7442028985507247
 
----------
Epoch 24/40
time = 420.88 secondes

Train loss 0.01901061708689143 micro_f1_score 0.9805194805194806 
 
time = 29.60 secondes

Val loss 0.4247868195420406 micro_f1_score 0.7390983000739098
 
----------
Epoch 25/40
time = 414.13 secondes

Train loss 0.018342819290292273 micro_f1_score 0.9811234237676729 
 
time = 28.35 secondes

Val loss 0.42015409103182494 micro_f1_score 0.7459499263622975
 
----------
Epoch 26/40
time = 417.20 secondes

Train loss 0.013829867471953925 micro_f1_score 0.9851953601953602 
 
time = 29.70 secondes

Val loss 0.458361843936756 micro_f1_score 0.7383827296011709
 
----------
Epoch 27/40
time = 417.03 secondes

Train loss 0.01402717307324024 micro_f1_score 0.9853736573474519 
 
time = 30.12 secondes

Val loss 0.4553523823374607 micro_f1_score 0.7453874538745389
 
----------
Epoch 28/40
time = 426.50 secondes

Train loss 0.014126265348291322 micro_f1_score 0.9859230152977531 
 
time = 30.25 secondes

Val loss 0.4678021539918712 micro_f1_score 0.7456268221574344
 
----------
Epoch 29/40
time = 426.80 secondes

Train loss 0.01215965507713541 micro_f1_score 0.9881976699916242 
 
time = 30.42 secondes

Val loss 0.47760578672416876 micro_f1_score 0.748020158387329
 
----------
Epoch 30/40
time = 416.13 secondes

Train loss 0.010397875697297193 micro_f1_score 0.9896083133493205 
 
time = 29.15 secondes

Val loss 0.48074615465813 micro_f1_score 0.74697912852435
 
----------
Epoch 31/40
time = 429.51 secondes

Train loss 0.009515238465069529 micro_f1_score 0.9903688758612814 
 
time = 29.55 secondes

Val loss 0.4773140520345969 micro_f1_score 0.7529923830250272
 
----------
Epoch 32/40
time = 418.99 secondes

Train loss 0.009611085057442143 micro_f1_score 0.9903297037995888 
 
time = 29.14 secondes

Val loss 0.48535064864354055 micro_f1_score 0.7584208620065194
 
----------
Epoch 33/40
time = 419.63 secondes

Train loss 0.006828403427166736 micro_f1_score 0.9933794992770717 
 
time = 29.16 secondes

Val loss 0.5018377233235563 micro_f1_score 0.750910415149308
 
----------
Epoch 34/40
time = 413.51 secondes

Train loss 0.006574498302441432 micro_f1_score 0.993036264698048 
 
time = 32.35 secondes

Val loss 0.5180848780714098 micro_f1_score 0.7540628385698809
 
----------
Epoch 35/40
time = 429.19 secondes

Train loss 0.006311179186744633 micro_f1_score 0.9934233035544573 
 
time = 29.90 secondes

Val loss 0.5361142866924161 micro_f1_score 0.7463116228859301
 
----------
Epoch 36/40
time = 428.98 secondes

Train loss 0.005770554313861433 micro_f1_score 0.9946747812856599 
 
time = 31.30 secondes

Val loss 0.5173003119034846 micro_f1_score 0.7480860371855633
 
----------
Epoch 37/40
time = 417.87 secondes

Train loss 0.004366291903822564 micro_f1_score 0.9958184444613396 
 
time = 29.61 secondes

Val loss 0.5286654295002828 micro_f1_score 0.748750892219843
 
----------
Epoch 38/40
time = 424.65 secondes

Train loss 0.005442017508913351 micro_f1_score 0.9952880376956984 
 
time = 28.42 secondes

Val loss 0.5227997913712361 micro_f1_score 0.7502694933524973
 
----------
Epoch 39/40
time = 421.69 secondes

Train loss 0.004529454481326776 micro_f1_score 0.9962000303997568 
 
time = 29.05 secondes

Val loss 0.5195823841896213 micro_f1_score 0.7549909255898367
 
----------
Epoch 40/40
time = 421.17 secondes

Train loss 0.003644038253439355 micro_f1_score 0.9966173843639542 
 
time = 29.27 secondes

Val loss 0.5377817205229743 micro_f1_score 0.7499097798628652
 
----------
best_f1_socre 0.7584208620065194 best_epoch 32

average train time 420.34816501140597

average val time 29.230967491865158
 
time = 33.93 secondes

test_f1_score 0.727079646017699

----------
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_4
----------
Epoch 1/40
time = 19.92 secondes

Train loss 0.6594922985091354 accuracy 0.5949612259864807 macro_avg {'precision': 0.49117867867867865, 'recall': 0.4954163483575248, 'f1-score': 0.4613375156712801, 'support': 516} weighted_avg {'precision': 0.5307946027422772, 'recall': 0.5949612403100775, 'f1-score': 0.5351685230592537, 'support': 516}
 
time = 0.88 secondes

Val loss 0.7331648766994476 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.56 secondes

Train loss 0.5431913056156852 accuracy 0.7209302186965942 macro_avg {'precision': 0.7957799250640899, 'recall': 0.6218975017473141, 'f1-score': 0.6113400983366462, 'support': 516} weighted_avg {'precision': 0.769600968571861, 'recall': 0.7209302325581395, 'f1-score': 0.6681349854149384, 'support': 516}
 
time = 0.78 secondes

Val loss 0.5420894771814346 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 3/40
time = 18.62 secondes

Train loss 0.48683525350960816 accuracy 0.7829457521438599 macro_avg {'precision': 0.7652403608993842, 'recall': 0.7709311964631114, 'f1-score': 0.7677469135802468, 'support': 516} weighted_avg {'precision': 0.7858482570135716, 'recall': 0.7829457364341085, 'f1-score': 0.7840971624078857, 'support': 516}
 
time = 0.84 secondes

Val loss 0.5104697868227959 accuracy 0.703125 macro_avg {'precision': 0.6931931931931932, 'recall': 0.6953441295546559, 'f1-score': 0.6940880503144654, 'support': 64} weighted_avg {'precision': 0.7051113613613613, 'recall': 0.703125, 'f1-score': 0.7039465408805032, 'support': 64}
 
----------
Epoch 4/40
time = 18.07 secondes

Train loss 0.40545294478987204 accuracy 0.8430232405662537 macro_avg {'precision': 0.8307687270822419, 'recall': 0.828430018042033, 'f1-score': 0.8295647776993935, 'support': 516} weighted_avg {'precision': 0.8425264505951002, 'recall': 0.8430232558139535, 'f1-score': 0.8427448045426177, 'support': 516}
 
time = 0.86 secondes

Val loss 0.6562319695949554 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 5/40
time = 18.95 secondes

Train loss 0.2724484374577349 accuracy 0.9031007885932922 macro_avg {'precision': 0.8929307452671938, 'recall': 0.8997773190514117, 'f1-score': 0.896093435360451, 'support': 516} weighted_avg {'precision': 0.9043922075654308, 'recall': 0.9031007751937985, 'f1-score': 0.9035191238405655, 'support': 516}
 
time = 0.86 secondes

Val loss 0.9024647921323776 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 6/40
time = 22.33 secondes

Train loss 0.297390606593002 accuracy 0.9031007885932922 macro_avg {'precision': 0.9062937062937063, 'recall': 0.8824667197633406, 'f1-score': 0.8922125668449198, 'support': 516} weighted_avg {'precision': 0.9038560922281853, 'recall': 0.9031007751937985, 'f1-score': 0.901640161878705, 'support': 516}
 
time = 0.85 secondes

Val loss 0.6939963959157467 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 7/40
time = 18.70 secondes

Train loss 0.5152211338846069 accuracy 0.8488371968269348 macro_avg {'precision': 0.8390580470976451, 'recall': 0.8306812086536742, 'f1-score': 0.8344739093242087, 'support': 516} weighted_avg {'precision': 0.847629905326439, 'recall': 0.8488372093023255, 'f1-score': 0.8478922553563969, 'support': 516}
 
time = 0.82 secondes

Val loss 0.5016710758209229 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 8/40
time = 17.55 secondes

Train loss 0.4005796029091333 accuracy 0.8837209343910217 macro_avg {'precision': 0.8714081453807481, 'recall': 0.8926580303301205, 'f1-score': 0.8781850517005304, 'support': 516} weighted_avg {'precision': 0.8938237280596844, 'recall': 0.8837209302325582, 'f1-score': 0.8853313676236935, 'support': 516}
 
time = 0.77 secondes

Val loss 0.8584813922643661 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 9/40
time = 17.54 secondes

Train loss 0.3016271667950081 accuracy 0.9108527302742004 macro_avg {'precision': 0.9059454110662158, 'recall': 0.9000861466443444, 'f1-score': 0.9028614457831324, 'support': 516} weighted_avg {'precision': 0.91047032600073, 'recall': 0.9108527131782945, 'f1-score': 0.9105287428784906, 'support': 516}
 
time = 0.85 secondes

Val loss 1.2177935540676117 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 10/40
time = 18.38 secondes

Train loss 0.1845140213598356 accuracy 0.9496123790740967 macro_avg {'precision': 0.9438099073701167, 'recall': 0.9477918827105309, 'f1-score': 0.945730789767487, 'support': 516} weighted_avg {'precision': 0.9499588207563369, 'recall': 0.9496124031007752, 'f1-score': 0.9497249136321749, 'support': 516}
 
time = 0.75 secondes

Val loss 1.2070897817611694 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 11/40
time = 17.89 secondes

Train loss 0.23270674425205498 accuracy 0.9399224519729614 macro_avg {'precision': 0.9345809548521017, 'recall': 0.9355769387058499, 'f1-score': 0.9350745814307458, 'support': 516} weighted_avg {'precision': 0.9399987881311272, 'recall': 0.939922480620155, 'f1-score': 0.9399568628839098, 'support': 516}
 
time = 1.06 secondes

Val loss 0.6730942502617836 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 12/40
time = 18.29 secondes

Train loss 0.2356757477179847 accuracy 0.9379844665527344 macro_avg {'precision': 0.9404607425133554, 'recall': 0.9248248622466395, 'f1-score': 0.9317460317460317, 'support': 516} weighted_avg {'precision': 0.938392348470508, 'recall': 0.937984496124031, 'f1-score': 0.9374246339362619, 'support': 516}
 
time = 0.83 secondes

Val loss 0.927270233631134 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 13/40
time = 18.24 secondes

Train loss 0.13515460612534574 accuracy 0.9689922332763672 macro_avg {'precision': 0.9697699348561062, 'recall': 0.9629894510995888, 'f1-score': 0.966212676794133, 'support': 516} weighted_avg {'precision': 0.9690528470329837, 'recall': 0.9689922480620154, 'f1-score': 0.9688795627403446, 'support': 516}
 
time = 0.80 secondes

Val loss 1.0219964757561684 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 14/40
time = 18.49 secondes

Train loss 0.12030804136090657 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 0.85 secondes

Val loss 0.5937637165188789 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 15/40
time = 18.24 secondes

Train loss 0.13329235611793896 accuracy 0.9651162624359131 macro_avg {'precision': 0.9570244018005212, 'recall': 0.9703362969946199, 'f1-score': 0.9628289684318372, 'support': 516} weighted_avg {'precision': 0.9671037576973015, 'recall': 0.9651162790697675, 'f1-score': 0.965366453670791, 'support': 516}
 
time = 0.69 secondes

Val loss 0.809077225625515 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 16/40
time = 16.30 secondes

Train loss 0.13255151571832935 accuracy 0.9651162624359131 macro_avg {'precision': 0.9581974125996531, 'recall': 0.9680282170895438, 'f1-score': 0.9626736111111112, 'support': 516} weighted_avg {'precision': 0.9662505194747043, 'recall': 0.9651162790697675, 'f1-score': 0.9653013296726961, 'support': 516}
 
time = 0.68 secondes

Val loss 0.8773432143498212 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 17/40
time = 18.03 secondes

Train loss 0.13051369359229945 accuracy 0.9709302186965942 macro_avg {'precision': 0.9671133354859541, 'recall': 0.9702794077011849, 'f1-score': 0.9686557191163666, 'support': 516} weighted_avg {'precision': 0.9710986250760301, 'recall': 0.9709302325581395, 'f1-score': 0.9709793227763074, 'support': 516}
 
time = 0.73 secondes

Val loss 1.1861388683319092 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 18/40
time = 18.17 secondes

Train loss 0.17317839133179266 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 0.81 secondes

Val loss 0.9771309047937393 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 19/40
time = 19.36 secondes

Train loss 0.0864134001841938 accuracy 0.9806201457977295 macro_avg {'precision': 0.9812927681780141, 'recall': 0.9767241519431757, 'f1-score': 0.978933616395852, 'support': 516} weighted_avg {'precision': 0.98065602773952, 'recall': 0.9806201550387597, 'f1-score': 0.9805739485005979, 'support': 516}
 
time = 0.80 secondes

Val loss 0.9995373114943504 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 20/40
time = 20.99 secondes

Train loss 0.1914557677439668 accuracy 0.963178277015686 macro_avg {'precision': 0.9652449970081777, 'recall': 0.9549680607252573, 'f1-score': 0.9597297241790064, 'support': 516} weighted_avg {'precision': 0.9634107985975287, 'recall': 0.9631782945736435, 'f1-score': 0.9629727506428373, 'support': 516}
 
time = 0.81 secondes

Val loss 1.4863064587116241 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 21/40
time = 17.75 secondes

Train loss 0.09483556818943753 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 0.88 secondes

Val loss 1.5360179990530014 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 22/40
time = 17.56 secondes

Train loss 0.0849077221408317 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 0.85 secondes

Val loss 1.0327720940113068 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 23/40
time = 18.13 secondes

Train loss 0.16882375672205605 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 0.68 secondes

Val loss 1.3221311643719673 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 24/40
time = 17.36 secondes

Train loss 0.2687422239105217 accuracy 0.9437984228134155 macro_avg {'precision': 0.9336830566865018, 'recall': 0.9501568519090422, 'f1-score': 0.9404126199094482, 'support': 516} weighted_avg {'precision': 0.9474944585660978, 'recall': 0.9437984496124031, 'f1-score': 0.9443214639567619, 'support': 516}
 
time = 1.06 secondes

Val loss 1.7933257520198822 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 25/40
time = 17.92 secondes

Train loss 0.05810379267804268 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 0.76 secondes

Val loss 1.6138144135475159 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 26/40
time = 17.54 secondes

Train loss 0.08060139318430712 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 0.83 secondes

Val loss 1.5890449583530426 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 27/40
time = 17.92 secondes

Train loss 0.538594637252214 accuracy 0.9282945990562439 macro_avg {'precision': 0.9494535519125683, 'recall': 0.9010695187165776, 'f1-score': 0.9184851525307943, 'support': 516} weighted_avg {'precision': 0.9355434828652518, 'recall': 0.9282945736434108, 'f1-score': 0.9262669279385684, 'support': 516}
 
time = 0.76 secondes

Val loss 2.1069127917289734 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 28/40
time = 18.34 secondes

Train loss 0.017902273443090082 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.76 secondes

Val loss 1.6276587545871735 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 29/40
time = 17.86 secondes

Train loss 0.04820951250748652 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 0.79 secondes

Val loss 1.2458678781986237 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 30/40
time = 18.30 secondes

Train loss 0.09709647766166282 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 0.96 secondes

Val loss 1.0818251222372055 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 31/40
time = 22.90 secondes

Train loss 0.08308310393388665 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.83 secondes

Val loss 1.5542031824588776 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 32/40
time = 19.46 secondes

Train loss 0.02010130974954474 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 0.75 secondes

Val loss 1.133429005742073 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 33/40
time = 17.58 secondes

Train loss 0.053330344194722726 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 0.96 secondes

Val loss 2.1922474205493927 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 34/40
time = 18.00 secondes

Train loss 0.0038082646170743938 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.77 secondes

Val loss 1.1697599589824677 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 35/40
time = 17.96 secondes

Train loss 0.06892036828591672 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 0.95 secondes

Val loss 1.0471445098519325 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 36/40
time = 17.89 secondes

Train loss 0.00029761303625436443 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.84 secondes

Val loss 1.9239063560962677 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 37/40
time = 18.19 secondes

Train loss 0.0002288514630036485 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.03 secondes

Val loss 1.6066608279943466 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 38/40
time = 18.05 secondes

Train loss 0.003248666536158205 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.93 secondes

Val loss 1.250099316239357 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 39/40
time = 17.34 secondes

Train loss 0.013655935743758384 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.85 secondes

Val loss 1.41804538667202 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 40/40
time = 18.02 secondes

Train loss 0.00012606408144523758 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.87 secondes

Val loss 1.580687254667282 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 14 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 18.39234214425087

average val time 0.8364347994327546
 
time = 0.93 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_4
----------
Epoch 1/40
time = 20.02 secondes

Train loss 0.6429315995086323 accuracy 0.6375969052314758 macro_avg {'precision': 0.3187984496124031, 'recall': 0.5, 'f1-score': 0.38934911242603554, 'support': 516} weighted_avg {'precision': 0.40652980590108767, 'recall': 0.6375968992248062, 'f1-score': 0.4964955735975415, 'support': 516}
 
time = 0.97 secondes

Val loss 0.5910139977931976 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.03 secondes

Train loss 0.5004895410754464 accuracy 0.748062014579773 macro_avg {'precision': 0.7983906753838417, 'recall': 0.6639468166376803, 'f1-score': 0.6691524621212122, 'support': 516} weighted_avg {'precision': 0.7786484938839656, 'recall': 0.748062015503876, 'f1-score': 0.7136173691860466, 'support': 516}
 
time = 0.79 secondes

Val loss 0.48216646909713745 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 17.70 secondes

Train loss 0.35810451028925 accuracy 0.8643410801887512 macro_avg {'precision': 0.8514552137867384, 'recall': 0.8589958227004535, 'f1-score': 0.8548418209876543, 'support': 516} weighted_avg {'precision': 0.8664535232196096, 'recall': 0.8643410852713178, 'f1-score': 0.8650607265049287, 'support': 516}
 
time = 0.83 secondes

Val loss 0.286414559930563 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 4/40
time = 16.84 secondes

Train loss 0.27938337928869506 accuracy 0.8992248177528381 macro_avg {'precision': 0.8916469339430064, 'recall': 0.8898135656583717, 'f1-score': 0.8907135874877812, 'support': 516} weighted_avg {'precision': 0.8990171932629601, 'recall': 0.8992248062015504, 'f1-score': 0.8991065948305259, 'support': 516}
 
time = 0.84 secondes

Val loss 0.5766307637095451 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 5/40
time = 17.54 secondes

Train loss 0.24076114515915062 accuracy 0.9186046719551086 macro_avg {'precision': 0.9119353737626579, 'recall': 0.9119353737626579, 'f1-score': 0.9119353737626579, 'support': 516} weighted_avg {'precision': 0.9186046511627907, 'recall': 0.9186046511627907, 'f1-score': 0.9186046511627907, 'support': 516}
 
time = 0.85 secondes

Val loss 0.5818718671798706 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 6/40
time = 17.94 secondes

Train loss 0.17982395845606472 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 0.89 secondes

Val loss 0.5408914759755135 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 7/40
time = 17.48 secondes

Train loss 0.277225876819681 accuracy 0.9263566136360168 macro_avg {'precision': 0.9300683798577836, 'recall': 0.9099361214505144, 'f1-score': 0.9185227046074065, 'support': 516} weighted_avg {'precision': 0.9271072883921064, 'recall': 0.9263565891472868, 'f1-score': 0.9254752771365503, 'support': 516}
 
time = 0.78 secondes

Val loss 0.5706870630383492 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 8/40
time = 17.55 secondes

Train loss 0.23076106291828732 accuracy 0.9418604373931885 macro_avg {'precision': 0.9347920242544796, 'recall': 0.9405588154023699, 'f1-score': 0.9375201808201485, 'support': 516} weighted_avg {'precision': 0.9425129365804452, 'recall': 0.9418604651162791, 'f1-score': 0.9420519482469907, 'support': 516}
 
time = 0.84 secondes

Val loss 0.780950665473938 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 9/40
time = 17.50 secondes

Train loss 0.2707743048032915 accuracy 0.9360464811325073 macro_avg {'precision': 0.928267272843696, 'recall': 0.9348455049331145, 'f1-score': 0.9313472912660112, 'support': 516} weighted_avg {'precision': 0.9368973658699301, 'recall': 0.936046511627907, 'f1-score': 0.9362901749059314, 'support': 516}
 
time = 0.79 secondes

Val loss 1.4493040144443512 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 20.12 secondes

Train loss 0.19729924750881214 accuracy 0.9476743936538696 macro_avg {'precision': 0.9458281239718365, 'recall': 0.9405019261089349, 'f1-score': 0.9430526431961153, 'support': 516} weighted_avg {'precision': 0.9475529518524923, 'recall': 0.9476744186046512, 'f1-score': 0.9475172153594628, 'support': 516}
 
time = 0.81 secondes

Val loss 0.5951731568202376 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 11/40
time = 18.93 secondes

Train loss 0.20281715926742463 accuracy 0.9534883499145508 macro_avg {'precision': 0.9487888937430222, 'recall': 0.9508313963883426, 'f1-score': 0.9497924234561494, 'support': 516} weighted_avg {'precision': 0.9536245888567914, 'recall': 0.9534883720930233, 'f1-score': 0.9535411713592644, 'support': 516}
 
time = 0.91 secondes

Val loss 0.43125671427696943 accuracy 0.921875 macro_avg {'precision': 0.9174174174174174, 'recall': 0.9220647773279352, 'f1-score': 0.919496855345912, 'support': 64} weighted_avg {'precision': 0.9227665165165164, 'recall': 0.921875, 'f1-score': 0.9220911949685534, 'support': 64}
 
----------
Epoch 12/40
time = 17.25 secondes

Train loss 0.10564586891312942 accuracy 0.9748061895370483 macro_avg {'precision': 0.9688137755102041, 'recall': 0.9779350811891487, 'f1-score': 0.9730133123061389, 'support': 516} weighted_avg {'precision': 0.9756760698465433, 'recall': 0.9748062015503876, 'f1-score': 0.9749275248827052, 'support': 516}
 
time = 0.81 secondes

Val loss 0.8337305337190628 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 13/40
time = 16.98 secondes

Train loss 0.2427238316670286 accuracy 0.9476743936538696 macro_avg {'precision': 0.9406576166997502, 'recall': 0.9474261658241634, 'f1-score': 0.9438296019449182, 'support': 516} weighted_avg {'precision': 0.9484418813129997, 'recall': 0.9476744186046512, 'f1-score': 0.9478737794684892, 'support': 516}
 
time = 0.80 secondes

Val loss 1.1933630555868149 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 17.15 secondes

Train loss 0.321283563428248 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 0.90 secondes

Val loss 0.8622913509607315 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 15/40
time = 17.45 secondes

Train loss 0.2658281240569936 accuracy 0.9418604373931885 macro_avg {'precision': 0.9335645974889805, 'recall': 0.9428668953074459, 'f1-score': 0.9377893518518519, 'support': 516} weighted_avg {'precision': 0.9432204434158361, 'recall': 0.9418604651162791, 'f1-score': 0.9421688827878265, 'support': 516}
 
time = 0.84 secondes

Val loss 0.6076380610466003 accuracy 0.875 macro_avg {'precision': 0.8690476190476191, 'recall': 0.8765182186234818, 'f1-score': 0.8718718718718719, 'support': 64} weighted_avg {'precision': 0.8779761904761905, 'recall': 0.875, 'f1-score': 0.8756256256256256, 'support': 64}
 
----------
Epoch 16/40
time = 17.56 secondes

Train loss 0.3079214388765677 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 0.82 secondes

Val loss 0.775558914989233 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 17/40
time = 18.35 secondes

Train loss 0.04250206715413228 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 0.97 secondes

Val loss 1.160603977739811 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 18/40
time = 17.07 secondes

Train loss 0.044924036761971584 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 0.97 secondes

Val loss 1.0778628885746002 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 19/40
time = 17.43 secondes

Train loss 0.4165256152945486 accuracy 0.9302325248718262 macro_avg {'precision': 0.91922135810358, 'recall': 0.9372104741316256, 'f1-score': 0.9262435677530018, 'support': 516} weighted_avg {'precision': 0.9351763622373106, 'recall': 0.9302325581395349, 'f1-score': 0.9309638730437326, 'support': 516}
 
time = 0.81 secondes

Val loss 1.490623578429222 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 20/40
time = 17.50 secondes

Train loss 0.12839392645841916 accuracy 0.9767441749572754 macro_avg {'precision': 0.9712437095614666, 'recall': 0.9794548380280546, 'f1-score': 0.9750624244865083, 'support': 516} weighted_avg {'precision': 0.9774426592509617, 'recall': 0.9767441860465116, 'f1-score': 0.9768445897217357, 'support': 516}
 
time = 0.89 secondes

Val loss 0.951908603310585 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 21/40
time = 18.04 secondes

Train loss 0.09824953936781226 accuracy 0.9786821603775024 macro_avg {'precision': 0.9797821938540501, 'recall': 0.9740503551517319, 'f1-score': 0.9767992250058248, 'support': 516} weighted_avg {'precision': 0.9787545404973339, 'recall': 0.9786821705426356, 'f1-score': 0.9786181247760776, 'support': 516}
 
time = 0.98 secondes

Val loss 1.39309823513031 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 22/40
time = 17.93 secondes

Train loss 0.19570759717008154 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 0.77 secondes

Val loss 1.0221359729766846 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 23/40
time = 18.01 secondes

Train loss 0.013074440873672509 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.77 secondes

Val loss 2.102681487798691 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 24/40
time = 20.75 secondes

Train loss 0.3710218666528817 accuracy 0.9418604373931885 macro_avg {'precision': 0.9461988304093567, 'recall': 0.9278643759244509, 'f1-score': 0.9358453657808795, 'support': 516} weighted_avg {'precision': 0.9426583254000634, 'recall': 0.9418604651162791, 'f1-score': 0.9412513411329473, 'support': 516}
 
time = 0.81 secondes

Val loss 0.98879424482584 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 25/40
time = 18.52 secondes

Train loss 0.04832330903578126 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 0.83 secondes

Val loss 1.058029480278492 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 26/40
time = 17.15 secondes

Train loss 0.023347795441760823 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.78 secondes

Val loss 0.9622327834367752 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 27/40
time = 17.08 secondes

Train loss 0.03579491145104508 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.90 secondes

Val loss 1.3313818573951721 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 28/40
time = 17.23 secondes

Train loss 0.11518084090714568 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 0.74 secondes

Val loss 2.3593786656856537 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 29/40
time = 16.85 secondes

Train loss 0.19864400203258617 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 0.82 secondes

Val loss 1.3903514593839645 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 30/40
time = 17.99 secondes

Train loss 0.08792966701642427 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 0.75 secondes

Val loss 1.1013551950454712 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 31/40
time = 17.19 secondes

Train loss 0.10928215317085921 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 0.85 secondes

Val loss 1.7058885991573334 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 32/40
time = 17.83 secondes

Train loss 0.0007347657568364715 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.92 secondes

Val loss 1.1596002280712128 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 33/40
time = 17.92 secondes

Train loss 0.014169620197428616 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.73 secondes

Val loss 1.0229313160780293 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 34/40
time = 17.48 secondes

Train loss 0.01483076124780134 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 0.77 secondes

Val loss 1.290966972708702 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 35/40
time = 17.37 secondes

Train loss 0.00013676652363783708 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.95 secondes

Val loss 1.4247786551713943 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 17.00 secondes

Train loss 0.047132662267055515 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.93 secondes

Val loss 1.3230224251747131 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 37/40
time = 17.82 secondes

Train loss 0.033158866905123985 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.85 secondes

Val loss 1.3859369605779648 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 38/40
time = 18.20 secondes

Train loss 0.0001265220220595824 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.92 secondes

Val loss 1.2117053419351578 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 39/40
time = 19.49 secondes

Train loss 0.0004897402823465227 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.93 secondes

Val loss 1.2405212223529816 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 40/40
time = 21.04 secondes

Train loss 0.00010190086829948775 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.96 secondes

Val loss 1.2237760201096535 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 11 macro_avg {'precision': 0.9174174174174174, 'recall': 0.9220647773279352, 'f1-score': 0.919496855345912, 'support': 64} weighted_avg {'precision': 0.9227665165165164, 'recall': 0.921875, 'f1-score': 0.9220911949685534, 'support': 64}

average train time 17.90622075200081

average val time 0.8513641059398651
 
time = 0.93 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9366471734892787, 'recall': 0.9366471734892787, 'f1-score': 0.9366471734892787, 'support': 65} weighted_avg {'precision': 0.9384615384615385, 'recall': 0.9384615384615385, 'f1-score': 0.9384615384615385, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_4
----------
Epoch 1/40
time = 18.98 secondes

Train loss 0.6405131365313674 accuracy 0.6375969052314758 macro_avg {'precision': 0.3187984496124031, 'recall': 0.5, 'f1-score': 0.38934911242603554, 'support': 516} weighted_avg {'precision': 0.40652980590108767, 'recall': 0.6375968992248062, 'f1-score': 0.4964955735975415, 'support': 516}
 
time = 1.10 secondes

Val loss 0.6971316039562225 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.13 secondes

Train loss 0.5217061512397997 accuracy 0.7403100728988647 macro_avg {'precision': 0.7792775830605683, 'recall': 0.6567137493295191, 'f1-score': 0.6606529378275977, 'support': 516} weighted_avg {'precision': 0.7638211981811025, 'recall': 0.7403100775193798, 'f1-score': 0.7058981931725299, 'support': 516}
 
time = 0.83 secondes

Val loss 0.47138382494449615 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 3/40
time = 18.16 secondes

Train loss 0.40630064859534754 accuracy 0.8430232405662537 macro_avg {'precision': 0.830253723110866, 'recall': 0.8503567771402565, 'f1-score': 0.8359699694278415, 'support': 516} weighted_avg {'precision': 0.8554380792752886, 'recall': 0.8430232558139535, 'f1-score': 0.8453304055664201, 'support': 516}
 
time = 0.90 secondes

Val loss 0.5912272706627846 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 4/40
time = 17.86 secondes

Train loss 0.29677944043369003 accuracy 0.893410861492157 macro_avg {'precision': 0.8889705882352941, 'recall': 0.878330055426426, 'f1-score': 0.8831362956923495, 'support': 516} weighted_avg {'precision': 0.8928152074783402, 'recall': 0.8934108527131783, 'f1-score': 0.892672159071158, 'support': 516}
 
time = 0.71 secondes

Val loss 0.43894657492637634 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 5/40
time = 17.36 secondes

Train loss 0.1837505982680754 accuracy 0.9496123790740967 macro_avg {'precision': 0.9446143391097519, 'recall': 0.9466378427579929, 'f1-score': 0.945608458744162, 'support': 516} weighted_avg {'precision': 0.9497572745208048, 'recall': 0.9496124031007752, 'f1-score': 0.9496696023058697, 'support': 516}
 
time = 0.72 secondes

Val loss 0.4962919279932976 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 6/40
time = 17.24 secondes

Train loss 0.12948571151178895 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 0.94 secondes

Val loss 0.6331232041120529 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 7/40
time = 17.96 secondes

Train loss 0.10905535306753308 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 0.75 secondes

Val loss 0.8630584180355072 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 8/40
time = 17.52 secondes

Train loss 0.41545974712988193 accuracy 0.9147287011146545 macro_avg {'precision': 0.9362867098058736, 'recall': 0.8846610210815468, 'f1-score': 0.9026131118851124, 'support': 516} weighted_avg {'precision': 0.9224973407778692, 'recall': 0.9147286821705426, 'f1-score': 0.9120659194704481, 'support': 516}
 
time = 0.84 secondes

Val loss 1.0057927370071411 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 17.27 secondes

Train loss 0.22355221724490437 accuracy 0.9515503644943237 macro_avg {'precision': 0.9471328489880644, 'recall': 0.9481575995968987, 'f1-score': 0.947640791476408, 'support': 516} weighted_avg {'precision': 0.9516134952913111, 'recall': 0.9515503875968992, 'f1-score': 0.9515781152289595, 'support': 516}
 
time = 0.76 secondes

Val loss 0.5467180385021493 accuracy 0.90625 macro_avg {'precision': 0.9177489177489178, 'recall': 0.8906882591093117, 'f1-score': 0.9, 'support': 64} weighted_avg {'precision': 0.9108495670995671, 'recall': 0.90625, 'f1-score': 0.9046875, 'support': 64}
 
----------
Epoch 10/40
time = 17.52 secondes

Train loss 0.14777055466688718 accuracy 0.963178277015686 macro_avg {'precision': 0.9564732142857143, 'recall': 0.9653544202980999, 'f1-score': 0.9605579179858952, 'support': 516} weighted_avg {'precision': 0.9641516126799556, 'recall': 0.9631782945736435, 'f1-score': 0.9633556132901075, 'support': 516}
 
time = 0.86 secondes

Val loss 0.9718265235424042 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 11/40
time = 17.46 secondes

Train loss 0.09896770449510466 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 0.86 secondes

Val loss 0.8714589327573776 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 12/40
time = 17.68 secondes

Train loss 0.09688208737608159 accuracy 0.9786821603775024 macro_avg {'precision': 0.9774682306940372, 'recall': 0.976358435056808, 'f1-score': 0.9769087129333176, 'support': 516} weighted_avg {'precision': 0.9786653102669607, 'recall': 0.9786821705426356, 'f1-score': 0.978669768741172, 'support': 516}
 
time = 0.91 secondes

Val loss 0.7470464408397675 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 13/40
time = 17.38 secondes

Train loss 0.14518707652336382 accuracy 0.9709302186965942 macro_avg {'precision': 0.9712936763834967, 'recall': 0.9656632478910326, 'f1-score': 0.9683625795533974, 'support': 516} weighted_avg {'precision': 0.9709541433361235, 'recall': 0.9709302325581395, 'f1-score': 0.970842897421924, 'support': 516}
 
time = 0.93 secondes

Val loss 1.7840120419859886 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 14/40
time = 19.54 secondes

Train loss 0.41643776380541647 accuracy 0.9224806427955627 macro_avg {'precision': 0.9243325705568268, 'recall': 0.9068966077727029, 'f1-score': 0.9144604877078395, 'support': 516} weighted_avg {'precision': 0.922821208734678, 'recall': 0.9224806201550387, 'f1-score': 0.92166845484393, 'support': 516}
 
time = 1.03 secondes

Val loss 1.555163487792015 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 15/40
time = 19.96 secondes

Train loss 0.14625093611451148 accuracy 0.9689922332763672 macro_avg {'precision': 0.9623028817847652, 'recall': 0.9722217707198935, 'f1-score': 0.966820987654321, 'support': 516} weighted_avg {'precision': 0.9700888654845156, 'recall': 0.9689922480620154, 'f1-score': 0.9691567374868407, 'support': 516}
 
time = 0.73 secondes

Val loss 1.2015368789434433 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 16/40
time = 17.18 secondes

Train loss 0.21450473526563268 accuracy 0.963178277015686 macro_avg {'precision': 0.9665775401069518, 'recall': 0.9538140207727192, 'f1-score': 0.9596289021482662, 'support': 516} weighted_avg {'precision': 0.9636342909256727, 'recall': 0.9631782945736435, 'f1-score': 0.9629231094973091, 'support': 516}
 
time = 0.79 secondes

Val loss 1.0707987695932388 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 17/40
time = 17.57 secondes

Train loss 0.12084177947095172 accuracy 0.9670542478561401 macro_avg {'precision': 0.9613081897931741, 'recall': 0.9683939339759114, 'f1-score': 0.96463345307643, 'support': 516} weighted_avg {'precision': 0.9676827403847825, 'recall': 0.9670542635658915, 'f1-score': 0.9671797870727524, 'support': 516}
 
time = 0.69 secondes

Val loss 0.8606060892343521 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 18/40
time = 17.70 secondes

Train loss 0.12662890505497204 accuracy 0.9728682041168213 macro_avg {'precision': 0.9696616669093734, 'recall': 0.9717991645400907, 'f1-score': 0.9707122470160872, 'support': 516} weighted_avg {'precision': 0.9729611605367241, 'recall': 0.9728682170542635, 'f1-score': 0.9728990166262376, 'support': 516}
 
time = 0.84 secondes

Val loss 1.121158391237259 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 19/40
time = 17.39 secondes

Train loss 0.10866494940516229 accuracy 0.9748061895370483 macro_avg {'precision': 0.9681246426529446, 'recall': 0.9790891211416868, 'f1-score': 0.9730705152652603, 'support': 516} weighted_avg {'precision': 0.9760311540149189, 'recall': 0.9748062015503876, 'f1-score': 0.9749519462002839, 'support': 516}
 
time = 0.99 secondes

Val loss 1.050327343866229 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 20/40
time = 18.30 secondes

Train loss 0.3828477883662069 accuracy 0.9360464811325073 macro_avg {'precision': 0.9523504273504273, 'recall': 0.9129187458348911, 'f1-score': 0.9279472933689337, 'support': 516} weighted_avg {'precision': 0.9410016232690651, 'recall': 0.936046511627907, 'f1-score': 0.9345952066219638, 'support': 516}
 
time = 0.87 secondes

Val loss 1.1526212692260742 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 21/40
time = 18.08 secondes

Train loss 0.09436343938542643 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 0.88 secondes

Val loss 1.3671832978725433 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 22/40
time = 17.08 secondes

Train loss 0.10681014854432733 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 0.89 secondes

Val loss 1.3753350228071213 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 23/40
time = 18.25 secondes

Train loss 0.010691550356568769 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.77 secondes

Val loss 1.5943878591060638 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 24/40
time = 17.64 secondes

Train loss 0.1338674869453605 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 0.88 secondes

Val loss 1.08195348829031 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 25/40
time = 17.41 secondes

Train loss 0.04614058170453504 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 0.82 secondes

Val loss 0.900909848511219 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 26/40
time = 17.48 secondes

Train loss 0.018576936217758692 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 0.91 secondes

Val loss 1.4372962266206741 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 27/40
time = 17.44 secondes

Train loss 0.214455269166854 accuracy 0.963178277015686 macro_avg {'precision': 0.9538834951456311, 'recall': 0.9711246200607903, 'f1-score': 0.960959992354466, 'support': 516} weighted_avg {'precision': 0.9665744712877248, 'recall': 0.9631782945736435, 'f1-score': 0.9635209591440854, 'support': 516}
 
time = 0.89 secondes

Val loss 1.0140428841114044 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 28/40
time = 17.72 secondes

Train loss 0.07035154198202884 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.85 secondes

Val loss 1.6753972470760345 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 29/40
time = 17.74 secondes

Train loss 0.09240154667570481 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 0.76 secondes

Val loss 1.424088329076767 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 30/40
time = 17.29 secondes

Train loss 0.04973838728399256 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 0.76 secondes

Val loss 0.985273327678442 accuracy 0.875 macro_avg {'precision': 0.8704453441295547, 'recall': 0.8704453441295547, 'f1-score': 0.8704453441295547, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 64}
 
----------
Epoch 31/40
time = 16.90 secondes

Train loss 0.014646736272190923 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.74 secondes

Val loss 1.3794859945774078 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 32/40
time = 18.84 secondes

Train loss 0.016857903089575386 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.97 secondes

Val loss 1.395496979355812 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 33/40
time = 19.75 secondes

Train loss 0.024634863311251993 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.79 secondes

Val loss 1.8457273095846176 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 34/40
time = 17.29 secondes

Train loss 0.08184786308662627 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.83 secondes

Val loss 1.1954856663942337 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 35/40
time = 17.02 secondes

Train loss 0.013888048201227899 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.80 secondes

Val loss 1.1534900963306427 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 36/40
time = 17.48 secondes

Train loss 0.028987747462286443 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.84 secondes

Val loss 1.1161609217524529 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 37/40
time = 17.12 secondes

Train loss 0.0004105206568386744 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.84 secondes

Val loss 1.1800639927387238 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 38/40
time = 17.17 secondes

Train loss 0.02897932965424843 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.85 secondes

Val loss 1.4845146834850311 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 39/40
time = 17.91 secondes

Train loss 0.030544138268327737 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 0.84 secondes

Val loss 1.2780179530382156 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 40/40
time = 16.92 secondes

Train loss 0.00025414991338920754 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.89 secondes

Val loss 1.2619796246290207 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 9 macro_avg {'precision': 0.9177489177489178, 'recall': 0.8906882591093117, 'f1-score': 0.9, 'support': 64} weighted_avg {'precision': 0.9108495670995671, 'recall': 0.90625, 'f1-score': 0.9046875, 'support': 64}

average train time 17.742318838834763

average val time 0.847194367647171
 
time = 0.88 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9425, 'recall': 0.9312865497076024, 'f1-score': 0.9358974358974359, 'support': 65} weighted_avg {'precision': 0.9395384615384614, 'recall': 0.9384615384615385, 'f1-score': 0.9380670611439843, 'support': 65}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_none_5
----------
Epoch 1/40
time = 347.20 secondes

Train loss 1.2721364546327427 accuracy 0.6711844801902771 macro_avg {'precision': 0.6848632316978167, 'recall': 0.6553902871344739, 'f1-score': 0.6486344467214755, 'support': 10182} weighted_avg {'precision': 0.6900082419097797, 'recall': 0.671184443134944, 'f1-score': 0.6630391395992722, 'support': 10182}
 
time = 14.19 secondes

Val loss 0.661695797888326 accuracy 0.8127208352088928 macro_avg {'precision': 0.7948561408305796, 'recall': 0.8055430475540895, 'f1-score': 0.7925358136255597, 'support': 1132} weighted_avg {'precision': 0.8068408888381894, 'recall': 0.8127208480565371, 'f1-score': 0.8013937554039341, 'support': 1132}
 
----------
Epoch 2/40
time = 338.62 secondes

Train loss 0.45224617418410545 accuracy 0.867314875125885 macro_avg {'precision': 0.8598573104812569, 'recall': 0.8562165273596575, 'f1-score': 0.8552566561164076, 'support': 10182} weighted_avg {'precision': 0.8662128474535955, 'recall': 0.8673148693773326, 'f1-score': 0.8646418628068838, 'support': 10182}
 
time = 13.56 secondes

Val loss 0.5218793742463622 accuracy 0.8560070991516113 macro_avg {'precision': 0.8563234449270907, 'recall': 0.8474007025868625, 'f1-score': 0.8438176458148012, 'support': 1132} weighted_avg {'precision': 0.8609520588565213, 'recall': 0.8560070671378092, 'f1-score': 0.8517286182848983, 'support': 1132}
 
----------
Epoch 3/40
time = 342.75 secondes

Train loss 0.2884764379457669 accuracy 0.9195639491081238 macro_avg {'precision': 0.9150801781657153, 'recall': 0.9141389018905235, 'f1-score': 0.9144265254165802, 'support': 10182} weighted_avg {'precision': 0.9193189176348073, 'recall': 0.9195639363582793, 'f1-score': 0.9192743280784678, 'support': 10182}
 
time = 12.92 secondes

Val loss 0.48929023827937707 accuracy 0.8825088143348694 macro_avg {'precision': 0.8896178624144031, 'recall': 0.8756903391207975, 'f1-score': 0.8739866051020904, 'support': 1132} weighted_avg {'precision': 0.8907890558515009, 'recall': 0.8825088339222615, 'f1-score': 0.8795342456981836, 'support': 1132}
 
----------
Epoch 4/40
time = 338.84 secondes

Train loss 0.21656721025950962 accuracy 0.9421528577804565 macro_avg {'precision': 0.9386869985263837, 'recall': 0.938369798448097, 'f1-score': 0.9384919800000995, 'support': 10182} weighted_avg {'precision': 0.9422507617460074, 'recall': 0.942152818699666, 'f1-score': 0.9421663677359873, 'support': 10182}
 
time = 12.84 secondes

Val loss 0.5480477415995908 accuracy 0.8825088143348694 macro_avg {'precision': 0.8929990831836596, 'recall': 0.886065919204062, 'f1-score': 0.884539141476435, 'support': 1132} weighted_avg {'precision': 0.894656889423437, 'recall': 0.8825088339222615, 'f1-score': 0.8830214433605335, 'support': 1132}
 
----------
Epoch 5/40
time = 336.19 secondes

Train loss 0.18811963098120016 accuracy 0.9533490538597107 macro_avg {'precision': 0.9513655313222001, 'recall': 0.9508068157163763, 'f1-score': 0.9509840543928789, 'support': 10182} weighted_avg {'precision': 0.9533179913182, 'recall': 0.9533490473384404, 'f1-score': 0.9532362622937173, 'support': 10182}
 
time = 12.85 secondes

Val loss 0.4701632431996855 accuracy 0.9045936465263367 macro_avg {'precision': 0.9102409068533994, 'recall': 0.9016268176153247, 'f1-score': 0.902564098461107, 'support': 1132} weighted_avg {'precision': 0.9097949888022195, 'recall': 0.9045936395759717, 'f1-score': 0.9039650886700525, 'support': 1132}
 
----------
Epoch 6/40
time = 330.46 secondes

Train loss 0.15927067279429694 accuracy 0.962090015411377 macro_avg {'precision': 0.9605048449794165, 'recall': 0.9603382537324047, 'f1-score': 0.9603449396748154, 'support': 10182} weighted_avg {'precision': 0.9622248304772552, 'recall': 0.9620899626792379, 'f1-score': 0.9620848298447559, 'support': 10182}
 
time = 11.04 secondes

Val loss 0.5444628858732217 accuracy 0.9063604474067688 macro_avg {'precision': 0.9142485481369865, 'recall': 0.907498771783078, 'f1-score': 0.9074559393253709, 'support': 1132} weighted_avg {'precision': 0.9152953953574084, 'recall': 0.9063604240282686, 'f1-score': 0.907183886388564, 'support': 1132}
 
----------
Epoch 7/40
time = 301.61 secondes

Train loss 0.143610249726256 accuracy 0.9668042063713074 macro_avg {'precision': 0.9657267817951883, 'recall': 0.96596286637889, 'f1-score': 0.9657906721109871, 'support': 10182} weighted_avg {'precision': 0.9669380765814111, 'recall': 0.9668041642113534, 'f1-score': 0.9668267220458746, 'support': 10182}
 
time = 10.54 secondes

Val loss 0.5297385001830547 accuracy 0.9090105891227722 macro_avg {'precision': 0.9107426627710197, 'recall': 0.9100555330963698, 'f1-score': 0.9083295976325936, 'support': 1132} weighted_avg {'precision': 0.9138794038781042, 'recall': 0.9090106007067138, 'f1-score': 0.9094238520426343, 'support': 1132}
 
----------
Epoch 8/40
time = 295.40 secondes

Train loss 0.13792104192954974 accuracy 0.9707326889038086 macro_avg {'precision': 0.9696586186909087, 'recall': 0.9694345847345524, 'f1-score': 0.9695110796397385, 'support': 10182} weighted_avg {'precision': 0.9708463297265976, 'recall': 0.9707326654881163, 'f1-score': 0.9707543746315649, 'support': 10182}
 
time = 10.69 secondes

Val loss 0.6382376148675333 accuracy 0.9054770469665527 macro_avg {'precision': 0.9087804505118896, 'recall': 0.899881455141361, 'f1-score': 0.8989616828672169, 'support': 1132} weighted_avg {'precision': 0.9095439153595054, 'recall': 0.9054770318021201, 'f1-score': 0.9033185212345552, 'support': 1132}
 
----------
Epoch 9/40
time = 294.94 secondes

Train loss 0.13538470605719619 accuracy 0.9709291458129883 macro_avg {'precision': 0.9693124866789924, 'recall': 0.9695870223487315, 'f1-score': 0.9693632309829263, 'support': 10182} weighted_avg {'precision': 0.9711669835810506, 'recall': 0.9709290905519544, 'f1-score': 0.9709792640150003, 'support': 10182}
 
time = 10.56 secondes

Val loss 0.6555957477777528 accuracy 0.8931095600128174 macro_avg {'precision': 0.9003325280567556, 'recall': 0.8945030956615024, 'f1-score': 0.8951871553182611, 'support': 1132} weighted_avg {'precision': 0.8976164643155243, 'recall': 0.8931095406360424, 'f1-score': 0.8929066927422095, 'support': 1132}
 
----------
Epoch 10/40
time = 286.91 secondes

Train loss 0.11588092284269588 accuracy 0.9769200682640076 macro_avg {'precision': 0.9762332252688501, 'recall': 0.9762792427285829, 'f1-score': 0.9762373869859495, 'support': 10182} weighted_avg {'precision': 0.9769731914683704, 'recall': 0.9769200549990179, 'f1-score': 0.9769288512167278, 'support': 10182}
 
time = 10.63 secondes

Val loss 0.5783744415228951 accuracy 0.9116607904434204 macro_avg {'precision': 0.9163341039385369, 'recall': 0.9117455194723867, 'f1-score': 0.9122092375060443, 'support': 1132} weighted_avg {'precision': 0.915485441889261, 'recall': 0.911660777385159, 'f1-score': 0.9119637035258654, 'support': 1132}
 
----------
Epoch 11/40
time = 285.82 secondes

Train loss 0.11739953934768577 accuracy 0.9759379625320435 macro_avg {'precision': 0.9753718483157403, 'recall': 0.9751145796009018, 'f1-score': 0.9752250874488068, 'support': 10182} weighted_avg {'precision': 0.9759583543848237, 'recall': 0.9759379296798272, 'f1-score': 0.9759303808966225, 'support': 10182}
 
time = 10.65 secondes

Val loss 0.743001087923685 accuracy 0.8895759582519531 macro_avg {'precision': 0.8999672031849159, 'recall': 0.8845691611944234, 'f1-score': 0.8840287363399051, 'support': 1132} weighted_avg {'precision': 0.8976525600693623, 'recall': 0.8895759717314488, 'f1-score': 0.887487627259391, 'support': 1132}
 
----------
Epoch 12/40
time = 284.04 secondes

Train loss 0.11099272862931507 accuracy 0.9780004024505615 macro_avg {'precision': 0.9771935004198596, 'recall': 0.9773445446427458, 'f1-score': 0.9772542680951186, 'support': 10182} weighted_avg {'precision': 0.9780567968166155, 'recall': 0.9780003928501276, 'f1-score': 0.9780138682503118, 'support': 10182}
 
time = 10.39 secondes

Val loss 0.7087542876422087 accuracy 0.9001767039299011 macro_avg {'precision': 0.9116687802434985, 'recall': 0.9013978115152291, 'f1-score': 0.9020408507071556, 'support': 1132} weighted_avg {'precision': 0.9118376850411865, 'recall': 0.9001766784452296, 'f1-score': 0.9013335008963546, 'support': 1132}
 
----------
Epoch 13/40
time = 286.22 secondes

Train loss 0.10640400951020777 accuracy 0.978295087814331 macro_avg {'precision': 0.9773363548854371, 'recall': 0.9772814369383231, 'f1-score': 0.9772871439714212, 'support': 10182} weighted_avg {'precision': 0.9783159078313959, 'recall': 0.978295030445885, 'f1-score': 0.9782835504221247, 'support': 10182}
 
time = 10.19 secondes

Val loss 0.7375103208338055 accuracy 0.8966431021690369 macro_avg {'precision': 0.9027483491254399, 'recall': 0.898917227923689, 'f1-score': 0.8965288880445195, 'support': 1132} weighted_avg {'precision': 0.9055569473195036, 'recall': 0.8966431095406361, 'f1-score': 0.8967735303653107, 'support': 1132}
 
----------
Epoch 14/40
time = 286.33 secondes

Train loss 0.11181185379317977 accuracy 0.9791789650917053 macro_avg {'precision': 0.9786567568412815, 'recall': 0.9784168665439055, 'f1-score': 0.9785226708815422, 'support': 10182} weighted_avg {'precision': 0.9791768466289975, 'recall': 0.9791789432331566, 'f1-score': 0.9791639383159918, 'support': 10182}
 
time = 10.02 secondes

Val loss 0.6298508841989555 accuracy 0.9028268456459045 macro_avg {'precision': 0.9075604505597294, 'recall': 0.9036734199303815, 'f1-score': 0.9031222846588364, 'support': 1132} weighted_avg {'precision': 0.90565191722144, 'recall': 0.9028268551236749, 'f1-score': 0.9017100432051057, 'support': 1132}
 
----------
Epoch 15/40
time = 287.65 secondes

Train loss 0.08821916764934132 accuracy 0.9834021329879761 macro_avg {'precision': 0.9827827545109937, 'recall': 0.9824887822575878, 'f1-score': 0.9826170065464543, 'support': 10182} weighted_avg {'precision': 0.9834212451680993, 'recall': 0.9834020821056767, 'f1-score': 0.9833929631652512, 'support': 10182}
 
time = 10.51 secondes

Val loss 0.5786217266966713 accuracy 0.9213780760765076 macro_avg {'precision': 0.9228018358109207, 'recall': 0.9216616453500034, 'f1-score': 0.9212623173194145, 'support': 1132} weighted_avg {'precision': 0.9238048715642907, 'recall': 0.9213780918727915, 'f1-score': 0.9215969697456315, 'support': 1132}
 
----------
Epoch 16/40
time = 283.83 secondes

Train loss 0.0974485126093132 accuracy 0.9828128218650818 macro_avg {'precision': 0.9827274850447785, 'recall': 0.9826934521899874, 'f1-score': 0.9827025733079064, 'support': 10182} weighted_avg {'precision': 0.9828136835624189, 'recall': 0.9828128069141623, 'f1-score': 0.9828052423047753, 'support': 10182}
 
time = 10.10 secondes

Val loss 0.5884887119361633 accuracy 0.9231448769569397 macro_avg {'precision': 0.9264912498878959, 'recall': 0.9274852749520136, 'f1-score': 0.9252464579984933, 'support': 1132} weighted_avg {'precision': 0.9262595889050822, 'recall': 0.9231448763250883, 'f1-score': 0.9228251338689999, 'support': 1132}
 
----------
Epoch 17/40
time = 287.54 secondes

Train loss 0.08055333276065446 accuracy 0.9839913845062256 macro_avg {'precision': 0.9839139472914147, 'recall': 0.9838723397458129, 'f1-score': 0.983863403987422, 'support': 10182} weighted_avg {'precision': 0.9840447683541613, 'recall': 0.9839913572971911, 'f1-score': 0.9839876479771122, 'support': 10182}
 
time = 10.89 secondes

Val loss 0.7539433759422383 accuracy 0.8966431021690369 macro_avg {'precision': 0.9076701486655864, 'recall': 0.8971349183109203, 'f1-score': 0.8992355242721064, 'support': 1132} weighted_avg {'precision': 0.9064248125243316, 'recall': 0.8966431095406361, 'f1-score': 0.8981974913694393, 'support': 1132}
 
----------
Epoch 18/40
time = 287.27 secondes

Train loss 0.06775766745819824 accuracy 0.9866431355476379 macro_avg {'precision': 0.9864791802538863, 'recall': 0.9863214075490344, 'f1-score': 0.986379012427293, 'support': 10182} weighted_avg {'precision': 0.986679827580343, 'recall': 0.9866430956590061, 'f1-score': 0.9866407309975209, 'support': 10182}
 
time = 10.69 secondes

Val loss 0.5868559440947958 accuracy 0.9213780760765076 macro_avg {'precision': 0.9247025036607509, 'recall': 0.9231725183718936, 'f1-score': 0.9222377602898704, 'support': 1132} weighted_avg {'precision': 0.9257692263244023, 'recall': 0.9213780918727915, 'f1-score': 0.9221694704089268, 'support': 1132}
 
----------
Epoch 19/40
time = 290.86 secondes

Train loss 0.07351604440340927 accuracy 0.9873306155204773 macro_avg {'precision': 0.9867865763016997, 'recall': 0.9871429732035395, 'f1-score': 0.9869504427200402, 'support': 10182} weighted_avg {'precision': 0.987365747549056, 'recall': 0.9873305833824396, 'f1-score': 0.9873352654255765, 'support': 10182}
 
time = 10.85 secondes

Val loss 0.7131554618342345 accuracy 0.9134275913238525 macro_avg {'precision': 0.9165199519639069, 'recall': 0.9156453440119223, 'f1-score': 0.9147848532769214, 'support': 1132} weighted_avg {'precision': 0.9167570009798488, 'recall': 0.9134275618374559, 'f1-score': 0.9137415801838762, 'support': 1132}
 
----------
Epoch 20/40
time = 289.53 secondes

Train loss 0.08965602372016612 accuracy 0.9858574271202087 macro_avg {'precision': 0.9853707348036547, 'recall': 0.9856402079628559, 'f1-score': 0.985478388520459, 'support': 10182} weighted_avg {'precision': 0.9859188560342892, 'recall': 0.9858573954036535, 'f1-score': 0.9858646638695788, 'support': 10182}
 
time = 10.71 secondes

Val loss 0.6489959905724595 accuracy 0.9125441908836365 macro_avg {'precision': 0.9192078436387175, 'recall': 0.914393795975012, 'f1-score': 0.9146912599827892, 'support': 1132} weighted_avg {'precision': 0.9204228572892402, 'recall': 0.9125441696113075, 'f1-score': 0.9142591728099223, 'support': 1132}
 
----------
Epoch 21/40
time = 290.14 secondes

Train loss 0.06181585937584676 accuracy 0.9900805354118347 macro_avg {'precision': 0.9897778468333159, 'recall': 0.9896136413157661, 'f1-score': 0.9896816745422591, 'support': 10182} weighted_avg {'precision': 0.9901038572202071, 'recall': 0.9900805342761736, 'f1-score': 0.9900792117194541, 'support': 10182}
 
time = 10.76 secondes

Val loss 0.5126628570728378 accuracy 0.9319788217544556 macro_avg {'precision': 0.9345630749504311, 'recall': 0.9330669402916871, 'f1-score': 0.9329814600342419, 'support': 1132} weighted_avg {'precision': 0.9343056533244939, 'recall': 0.9319787985865724, 'f1-score': 0.932274233731029, 'support': 1132}
 
----------
Epoch 22/40
time = 287.97 secondes

Train loss 0.06786035422738625 accuracy 0.9885091781616211 macro_avg {'precision': 0.9876886955179188, 'recall': 0.987596698340791, 'f1-score': 0.9876239179172531, 'support': 10182} weighted_avg {'precision': 0.9885515854442992, 'recall': 0.9885091337654685, 'f1-score': 0.9885115153349174, 'support': 10182}
 
time = 10.78 secondes

Val loss 0.8541228029545738 accuracy 0.8957597017288208 macro_avg {'precision': 0.9020434949020203, 'recall': 0.8963599371059509, 'f1-score': 0.8963681568761871, 'support': 1132} weighted_avg {'precision': 0.9046602665958003, 'recall': 0.8957597173144877, 'f1-score': 0.8971447185863729, 'support': 1132}
 
----------
Epoch 23/40
time = 290.90 secondes

Train loss 0.0681067963746864 accuracy 0.9875270128250122 macro_avg {'precision': 0.9872098459207386, 'recall': 0.9872519560632897, 'f1-score': 0.9872109203399957, 'support': 10182} weighted_avg {'precision': 0.9875741577585504, 'recall': 0.9875270084462777, 'f1-score': 0.987530057903275, 'support': 10182}
 
time = 10.03 secondes

Val loss 0.7252344444730651 accuracy 0.9125441908836365 macro_avg {'precision': 0.9136165007371069, 'recall': 0.9127536737005434, 'f1-score': 0.9124493573464152, 'support': 1132} weighted_avg {'precision': 0.9151229221730962, 'recall': 0.9125441696113075, 'f1-score': 0.9130949282063523, 'support': 1132}
 
----------
Epoch 24/40
time = 286.34 secondes

Train loss 0.05196854846586601 accuracy 0.9901787638664246 macro_avg {'precision': 0.9903035264040321, 'recall': 0.9901867279311334, 'f1-score': 0.9902392816811745, 'support': 10182} weighted_avg {'precision': 0.9901988313783211, 'recall': 0.9901787468080927, 'f1-score': 0.9901828747352756, 'support': 10182}
 
time = 10.68 secondes

Val loss 0.7284470235628222 accuracy 0.9151943325996399 macro_avg {'precision': 0.9202800531673244, 'recall': 0.9146928135415238, 'f1-score': 0.9154572099016585, 'support': 1132} weighted_avg {'precision': 0.9193513678954598, 'recall': 0.9151943462897526, 'f1-score': 0.9152643725449039, 'support': 1132}
 
----------
Epoch 25/40
time = 287.12 secondes

Train loss 0.07211131711951202 accuracy 0.9890002012252808 macro_avg {'precision': 0.9890006266740512, 'recall': 0.9888167894293863, 'f1-score': 0.988877463788832, 'support': 10182} weighted_avg {'precision': 0.9890933536388928, 'recall': 0.9890001964250639, 'f1-score': 0.989015749816255, 'support': 10182}
 
time = 11.37 secondes

Val loss 0.7509572013325556 accuracy 0.9098939895629883 macro_avg {'precision': 0.9209618316660355, 'recall': 0.9139032297376755, 'f1-score': 0.9144939806980178, 'support': 1132} weighted_avg {'precision': 0.9194496053834136, 'recall': 0.9098939929328622, 'f1-score': 0.9113351510006391, 'support': 1132}
 
----------
Epoch 26/40
time = 286.80 secondes

Train loss 0.053072047832228374 accuracy 0.9911609292030334 macro_avg {'precision': 0.9912122662835671, 'recall': 0.9911539825006722, 'f1-score': 0.9911738874198489, 'support': 10182} weighted_avg {'precision': 0.991199531197472, 'recall': 0.9911608721272834, 'f1-score': 0.991170616641011, 'support': 10182}
 
time = 10.35 secondes

Val loss 0.7266080331497045 accuracy 0.9072438478469849 macro_avg {'precision': 0.9113144704523372, 'recall': 0.911537919628145, 'f1-score': 0.9093989354976347, 'support': 1132} weighted_avg {'precision': 0.9123717936342528, 'recall': 0.907243816254417, 'f1-score': 0.9076789015048341, 'support': 1132}
 
----------
Epoch 27/40
time = 288.74 secondes

Train loss 0.04559905469086602 accuracy 0.9920448064804077 macro_avg {'precision': 0.9917926007092726, 'recall': 0.9919385008355068, 'f1-score': 0.9918560137389706, 'support': 10182} weighted_avg {'precision': 0.992054816142118, 'recall': 0.9920447849145551, 'f1-score': 0.9920414078969348, 'support': 10182}
 
time = 10.86 secondes

Val loss 0.8039793182502813 accuracy 0.9037102460861206 macro_avg {'precision': 0.9075285114971786, 'recall': 0.9081923615603053, 'f1-score': 0.9054985359446883, 'support': 1132} weighted_avg {'precision': 0.9100998771663377, 'recall': 0.9037102473498233, 'f1-score': 0.9048362234998079, 'support': 1132}
 
----------
Epoch 28/40
time = 288.17 secondes

Train loss 0.052227449681900864 accuracy 0.9910627007484436 macro_avg {'precision': 0.990158915126792, 'recall': 0.9904111631145922, 'f1-score': 0.990247115380879, 'support': 10182} weighted_avg {'precision': 0.9911516369778957, 'recall': 0.9910626595953643, 'f1-score': 0.9910754570439949, 'support': 10182}
 
time = 10.85 secondes

Val loss 0.6990935505648811 accuracy 0.9151943325996399 macro_avg {'precision': 0.9160840795936045, 'recall': 0.9183504222621537, 'f1-score': 0.916223624492633, 'support': 1132} weighted_avg {'precision': 0.9175605503009597, 'recall': 0.9151943462897526, 'f1-score': 0.9154500190168857, 'support': 1132}
 
----------
Epoch 29/40
time = 287.94 secondes

Train loss 0.042068644955103804 accuracy 0.9931251406669617 macro_avg {'precision': 0.9930147181952131, 'recall': 0.9927427916147427, 'f1-score': 0.9928678747930242, 'support': 10182} weighted_avg {'precision': 0.9931264151055411, 'recall': 0.9931251227656649, 'f1-score': 0.993116712430175, 'support': 10182}
 
time = 10.63 secondes

Val loss 0.8017758863709492 accuracy 0.9107773900032043 macro_avg {'precision': 0.9164760881134291, 'recall': 0.9131887846347352, 'f1-score': 0.9124844691538483, 'support': 1132} weighted_avg {'precision': 0.9159049944180119, 'recall': 0.9107773851590106, 'f1-score': 0.9110839866152278, 'support': 1132}
 
----------
Epoch 30/40
time = 289.92 secondes

Train loss 0.033375322245600254 accuracy 0.9945001006126404 macro_avg {'precision': 0.9938556304994842, 'recall': 0.9940978367027972, 'f1-score': 0.993963574487809, 'support': 10182} weighted_avg {'precision': 0.9945320514685022, 'recall': 0.9945000982125319, 'f1-score': 0.9945046337381266, 'support': 10182}
 
time = 10.57 secondes

Val loss 0.7585225259523648 accuracy 0.9151943325996399 macro_avg {'precision': 0.9194920589299921, 'recall': 0.9177672649990644, 'f1-score': 0.9168276831211755, 'support': 1132} weighted_avg {'precision': 0.9192121255262959, 'recall': 0.9151943462897526, 'f1-score': 0.915552760653627, 'support': 1132}
 
----------
Epoch 31/40
time = 285.93 secondes

Train loss 0.029342402751673626 accuracy 0.9951876401901245 macro_avg {'precision': 0.9950654126187224, 'recall': 0.9949923360776065, 'f1-score': 0.9950225738500752, 'support': 10182} weighted_avg {'precision': 0.995192793256935, 'recall': 0.9951875859359655, 'f1-score': 0.9951837795326175, 'support': 10182}
 
time = 10.31 secondes

Val loss 0.8031432703156869 accuracy 0.9098939895629883 macro_avg {'precision': 0.9166654964028496, 'recall': 0.9138477659919481, 'f1-score': 0.9130703354613761, 'support': 1132} weighted_avg {'precision': 0.9160778678303608, 'recall': 0.9098939929328622, 'f1-score': 0.9110550388359951, 'support': 1132}
 
----------
Epoch 32/40
time = 289.17 secondes

Train loss 0.02335774215889743 accuracy 0.9953840374946594 macro_avg {'precision': 0.9952509153230406, 'recall': 0.99521239039089, 'f1-score': 0.9952260766947612, 'support': 10182} weighted_avg {'precision': 0.9954074987871377, 'recall': 0.9953840109998036, 'f1-score': 0.9953899383287689, 'support': 10182}
 
time = 10.70 secondes

Val loss 0.7864459050725203 accuracy 0.9143109321594238 macro_avg {'precision': 0.9214454712995893, 'recall': 0.9183624583508507, 'f1-score': 0.9178769687457502, 'support': 1132} weighted_avg {'precision': 0.9206261699136611, 'recall': 0.9143109540636042, 'f1-score': 0.9154737819231904, 'support': 1132}
 
----------
Epoch 33/40
time = 291.89 secondes

Train loss 0.0299000187966626 accuracy 0.9950894117355347 macro_avg {'precision': 0.9948593156984646, 'recall': 0.9950005083398604, 'f1-score': 0.9949256202050197, 'support': 10182} weighted_avg {'precision': 0.9950985920679134, 'recall': 0.9950893734040464, 'f1-score': 0.995089889668025, 'support': 10182}
 
time = 10.17 secondes

Val loss 0.6546124735125975 accuracy 0.9231448769569397 macro_avg {'precision': 0.9278256745032545, 'recall': 0.9263243476563131, 'f1-score': 0.9261144613638846, 'support': 1132} weighted_avg {'precision': 0.925103336671026, 'recall': 0.9231448763250883, 'f1-score': 0.9231360045172355, 'support': 1132}
 
----------
Epoch 34/40
time = 287.48 secondes

Train loss 0.02840965274036953 accuracy 0.995776891708374 macro_avg {'precision': 0.9957866026163664, 'recall': 0.9954761974144661, 'f1-score': 0.9956233254006372, 'support': 10182} weighted_avg {'precision': 0.995783546815988, 'recall': 0.9957768611274799, 'f1-score': 0.9957735195008458, 'support': 10182}
 
time = 11.03 secondes

Val loss 0.8596536534315534 accuracy 0.9054770469665527 macro_avg {'precision': 0.913067291198764, 'recall': 0.9101778937165174, 'f1-score': 0.9090230530704542, 'support': 1132} weighted_avg {'precision': 0.912258357010816, 'recall': 0.9054770318021201, 'f1-score': 0.906072486460314, 'support': 1132}
 
----------
Epoch 35/40
time = 292.56 secondes

Train loss 0.02006050350790067 accuracy 0.996857225894928 macro_avg {'precision': 0.9968229856452977, 'recall': 0.9967250334543547, 'f1-score': 0.9967702370205116, 'support': 10182} weighted_avg {'precision': 0.9968673972757242, 'recall': 0.9968571989785897, 'f1-score': 0.9968587258749433, 'support': 10182}
 
time = 9.93 secondes

Val loss 0.7477587037211494 accuracy 0.9222614765167236 macro_avg {'precision': 0.9254545351286299, 'recall': 0.9249581827292939, 'f1-score': 0.9239240393190056, 'support': 1132} weighted_avg {'precision': 0.925254457221004, 'recall': 0.9222614840989399, 'f1-score': 0.922480230234233, 'support': 1132}
 
----------
Epoch 36/40
time = 288.40 secondes

Train loss 0.012190654528471274 accuracy 0.997741162776947 macro_avg {'precision': 0.9977462250916336, 'recall': 0.9977480999842688, 'f1-score': 0.9977457925930684, 'support': 10182} weighted_avg {'precision': 0.9977448927301136, 'recall': 0.9977411117658613, 'f1-score': 0.9977416536305692, 'support': 10182}
 
time = 10.79 secondes

Val loss 0.688491704772159 accuracy 0.926678478717804 macro_avg {'precision': 0.9304667922975052, 'recall': 0.9304526870331419, 'f1-score': 0.9292843829602923, 'support': 1132} weighted_avg {'precision': 0.9289365207572843, 'recall': 0.926678445229682, 'f1-score': 0.9265443723238558, 'support': 1132}
 
----------
Epoch 37/40
time = 285.32 secondes

Train loss 0.009237588685279591 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982583818350526, 'recall': 0.9983045172907936, 'f1-score': 0.9982809608830323, 'support': 10182} weighted_avg {'precision': 0.998232634709745, 'recall': 0.9982321744254566, 'f1-score': 0.998231921600223, 'support': 10182}
 
time = 10.63 secondes

Val loss 0.759465061470007 accuracy 0.926678478717804 macro_avg {'precision': 0.9299376932865296, 'recall': 0.9302776077311113, 'f1-score': 0.92896325029002, 'support': 1132} weighted_avg {'precision': 0.9292452111738367, 'recall': 0.926678445229682, 'f1-score': 0.9267514979155361, 'support': 1132}
 
----------
Epoch 38/40
time = 288.06 secondes

Train loss 0.011265509529775997 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981314648751157, 'recall': 0.9981935122744143, 'f1-score': 0.998160674269289, 'support': 10182} weighted_avg {'precision': 0.998137425506908, 'recall': 0.9981339618935376, 'f1-score': 0.9981338803364326, 'support': 10182}
 
time = 10.30 secondes

Val loss 0.6998869143159462 accuracy 0.9284452199935913 macro_avg {'precision': 0.9325843162468933, 'recall': 0.9315530442038737, 'f1-score': 0.9313716469052441, 'support': 1132} weighted_avg {'precision': 0.9297767300835718, 'recall': 0.9284452296819788, 'f1-score': 0.928423759395504, 'support': 1132}
 
----------
Epoch 39/40
time = 284.39 secondes

Train loss 0.008664043401864373 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985698284006377, 'recall': 0.9985668083280801, 'f1-score': 0.998565618952845, 'support': 10182} weighted_avg {'precision': 0.99853168646557, 'recall': 0.998526812021214, 'f1-score': 0.9985264635421823, 'support': 10182}
 
time = 10.98 secondes

Val loss 0.7115928440837284 accuracy 0.9302120208740234 macro_avg {'precision': 0.934203194646608, 'recall': 0.9328098430745634, 'f1-score': 0.932919390694855, 'support': 1132} weighted_avg {'precision': 0.9320007775753784, 'recall': 0.9302120141342756, 'f1-score': 0.930508729927146, 'support': 1132}
 
----------
Epoch 40/40
time = 288.89 secondes

Train loss 0.005808834563270336 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990287189857483, 'recall': 0.999053124544511, 'f1-score': 0.9990400815952603, 'support': 10182} weighted_avg {'precision': 0.9990194210174199, 'recall': 0.9990178746808093, 'f1-score': 0.9990177952033451, 'support': 10182}
 
time = 10.73 secondes

Val loss 0.7070219987739953 accuracy 0.9293286204338074 macro_avg {'precision': 0.932534013516414, 'recall': 0.9315900665026741, 'f1-score': 0.9314726215102033, 'support': 1132} weighted_avg {'precision': 0.9301347045333866, 'recall': 0.9293286219081273, 'f1-score': 0.9292067799840886, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 21 macro_avg {'precision': 0.9345630749504311, 'recall': 0.9330669402916871, 'f1-score': 0.9329814600342419, 'support': 1132} weighted_avg {'precision': 0.9343056533244939, 'recall': 0.9319787985865724, 'f1-score': 0.932274233731029, 'support': 1132}

average train time 296.20386611819265

average val time 10.931867557764054
 
time = 71.35 secondes

test_accuracy 0.8505045175552368 macro_avg {'precision': 0.8468598239845562, 'recall': 0.842269330612471, 'f1-score': 0.8428013088526919, 'support': 7532} weighted_avg {'precision': 0.8531934352008819, 'recall': 0.8505045140732873, 'f1-score': 0.8501627939847666, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_5
----------
Epoch 1/40
time = 299.23 secondes

Train loss 1.2987950530306698 accuracy 0.6677470207214355 macro_avg {'precision': 0.6863105197197248, 'recall': 0.6520341826994908, 'f1-score': 0.6510652431796798, 'support': 10182} weighted_avg {'precision': 0.6966613656110778, 'recall': 0.6677470045177765, 'f1-score': 0.6656752922935034, 'support': 10182}
 
time = 12.54 secondes

Val loss 0.6218979268426627 accuracy 0.8162544369697571 macro_avg {'precision': 0.78770965361544, 'recall': 0.8069886956437322, 'f1-score': 0.7922668095712926, 'support': 1132} weighted_avg {'precision': 0.8014560636120929, 'recall': 0.8162544169611308, 'f1-score': 0.8038079983306383, 'support': 1132}
 
----------
Epoch 2/40
time = 292.88 secondes

Train loss 0.451977139470435 accuracy 0.8691809177398682 macro_avg {'precision': 0.8624193832846896, 'recall': 0.8582841445161826, 'f1-score': 0.8572725998763756, 'support': 10182} weighted_avg {'precision': 0.8686843905236339, 'recall': 0.869180907483795, 'f1-score': 0.8665962821947422, 'support': 10182}
 
time = 11.86 secondes

Val loss 0.4880341161042452 accuracy 0.8604240417480469 macro_avg {'precision': 0.8628330441767382, 'recall': 0.8614378442268663, 'f1-score': 0.8575309183135602, 'support': 1132} weighted_avg {'precision': 0.8695184069802849, 'recall': 0.8604240282685512, 'f1-score': 0.8601009646384197, 'support': 1132}
 
----------
Epoch 3/40
time = 296.84 secondes

Train loss 0.2874159772048472 accuracy 0.91838538646698 macro_avg {'precision': 0.9141048284254027, 'recall': 0.9128306079109603, 'f1-score': 0.9131973838600157, 'support': 10182} weighted_avg {'precision': 0.9189602082215593, 'recall': 0.9183853859752504, 'f1-score': 0.9184113907106565, 'support': 10182}
 
time = 12.32 secondes

Val loss 0.4249928083375726 accuracy 0.8904593586921692 macro_avg {'precision': 0.8963915124477063, 'recall': 0.8918621624835067, 'f1-score': 0.8905225099161322, 'support': 1132} weighted_avg {'precision': 0.9019365125701635, 'recall': 0.8904593639575972, 'f1-score': 0.8924369204339284, 'support': 1132}
 
----------
Epoch 4/40
time = 285.45 secondes

Train loss 0.2172006043003144 accuracy 0.9432331919670105 macro_avg {'precision': 0.9407577161173718, 'recall': 0.9404009691003032, 'f1-score': 0.9404314394979897, 'support': 10182} weighted_avg {'precision': 0.9436220527302278, 'recall': 0.9432331565507759, 'f1-score': 0.9432936419025841, 'support': 10182}
 
time = 11.65 secondes

Val loss 0.4476754285434497 accuracy 0.9090105891227722 macro_avg {'precision': 0.9119785551171887, 'recall': 0.9105721878237285, 'f1-score': 0.9086672112608513, 'support': 1132} weighted_avg {'precision': 0.9140471088745126, 'recall': 0.9090106007067138, 'f1-score': 0.9088853458470234, 'support': 1132}
 
----------
Epoch 5/40
time = 290.04 secondes

Train loss 0.1907666335770571 accuracy 0.9555097222328186 macro_avg {'precision': 0.9536914875654879, 'recall': 0.9534670646952753, 'f1-score': 0.9534972937107892, 'support': 10182} weighted_avg {'precision': 0.9555654956457816, 'recall': 0.95550972304066, 'f1-score': 0.9554617493173115, 'support': 10182}
 
time = 11.72 secondes

Val loss 0.4946903100263485 accuracy 0.8975265026092529 macro_avg {'precision': 0.9013990902848118, 'recall': 0.8964731835997986, 'f1-score': 0.8970250509422971, 'support': 1132} weighted_avg {'precision': 0.9004184506493917, 'recall': 0.8975265017667845, 'f1-score': 0.8970832718617299, 'support': 1132}
 
----------
Epoch 6/40
time = 289.91 secondes

Train loss 0.16659352443713893 accuracy 0.9635632038116455 macro_avg {'precision': 0.9624187063871398, 'recall': 0.9620847249564086, 'f1-score': 0.962172890194738, 'support': 10182} weighted_avg {'precision': 0.9637041627368371, 'recall': 0.963563150658024, 'f1-score': 0.9635581558002507, 'support': 10182}
 
time = 11.43 secondes

Val loss 0.5875835583748584 accuracy 0.898409903049469 macro_avg {'precision': 0.9043591701554267, 'recall': 0.9017156999695682, 'f1-score': 0.9002243370992769, 'support': 1132} weighted_avg {'precision': 0.9039579825719112, 'recall': 0.8984098939929329, 'f1-score': 0.8980152333295169, 'support': 1132}
 
----------
Epoch 7/40
time = 283.40 secondes

Train loss 0.16004986856255193 accuracy 0.9638578295707703 macro_avg {'precision': 0.9623239433121755, 'recall': 0.9624586902698642, 'f1-score': 0.9623654934169232, 'support': 10182} weighted_avg {'precision': 0.9640349781013452, 'recall': 0.9638577882537812, 'f1-score': 0.9639207796331326, 'support': 10182}
 
time = 11.44 secondes

Val loss 0.5643067345852 accuracy 0.9063604474067688 macro_avg {'precision': 0.9114721708301092, 'recall': 0.9089061000029398, 'f1-score': 0.9072505268090065, 'support': 1132} weighted_avg {'precision': 0.9111971177836308, 'recall': 0.9063604240282686, 'f1-score': 0.9055623131482957, 'support': 1132}
 
----------
Epoch 8/40
time = 285.04 secondes

Train loss 0.1482223455645758 accuracy 0.9697505831718445 macro_avg {'precision': 0.9690298416277804, 'recall': 0.9688702840907893, 'f1-score': 0.9688877847749102, 'support': 10182} weighted_avg {'precision': 0.9699412830024465, 'recall': 0.9697505401689256, 'f1-score': 0.9697859139663177, 'support': 10182}
 
time = 11.64 secondes

Val loss 0.6298230767043465 accuracy 0.9037102460861206 macro_avg {'precision': 0.9098997721879323, 'recall': 0.906363383713102, 'f1-score': 0.9058297758818068, 'support': 1132} weighted_avg {'precision': 0.9109264857400458, 'recall': 0.9037102473498233, 'f1-score': 0.9049278309975441, 'support': 1132}
 
----------
Epoch 9/40
time = 292.69 secondes

Train loss 0.14443578978457117 accuracy 0.9713219404220581 macro_avg {'precision': 0.9702971545413321, 'recall': 0.970604779636246, 'f1-score': 0.9704012717413433, 'support': 10182} weighted_avg {'precision': 0.9713817619581332, 'recall': 0.9713219406796307, 'f1-score': 0.9713068257746074, 'support': 10182}
 
time = 11.84 secondes

Val loss 0.7657240872799327 accuracy 0.8913427591323853 macro_avg {'precision': 0.9036137217741688, 'recall': 0.8763409404287478, 'f1-score': 0.8685835130226307, 'support': 1132} weighted_avg {'precision': 0.9053083413123449, 'recall': 0.8913427561837456, 'f1-score': 0.8836684694012523, 'support': 1132}
 
----------
Epoch 10/40
time = 278.96 secondes

Train loss 0.14546009608344473 accuracy 0.9709291458129883 macro_avg {'precision': 0.9702211170859574, 'recall': 0.9696339823707433, 'f1-score': 0.9698903081241829, 'support': 10182} weighted_avg {'precision': 0.9709640138896625, 'recall': 0.9709290905519544, 'f1-score': 0.9709146858747729, 'support': 10182}
 
time = 12.15 secondes

Val loss 0.5700003367862632 accuracy 0.9125441908836365 macro_avg {'precision': 0.916502457792513, 'recall': 0.9142846073085937, 'f1-score': 0.9133302534013049, 'support': 1132} weighted_avg {'precision': 0.9175846010796619, 'recall': 0.9125441696113075, 'f1-score': 0.9129353315112987, 'support': 1132}
 
----------
Epoch 11/40
time = 277.68 secondes

Train loss 0.11844343916666358 accuracy 0.9768218994140625 macro_avg {'precision': 0.9760336383032515, 'recall': 0.9763572914822948, 'f1-score': 0.9761769183283754, 'support': 10182} weighted_avg {'precision': 0.9768545622194833, 'recall': 0.9768218424670988, 'f1-score': 0.9768216477026308, 'support': 10182}
 
time = 11.07 secondes

Val loss 0.624465119223189 accuracy 0.9098939895629883 macro_avg {'precision': 0.9137092298048184, 'recall': 0.912550052583312, 'f1-score': 0.910983533815003, 'support': 1132} weighted_avg {'precision': 0.9137938126355964, 'recall': 0.9098939929328622, 'f1-score': 0.9096233261627158, 'support': 1132}
 
----------
Epoch 12/40
time = 287.07 secondes

Train loss 0.11623928590309518 accuracy 0.9766254425048828 macro_avg {'precision': 0.9763905007614827, 'recall': 0.9763115179621751, 'f1-score': 0.9763286002163666, 'support': 10182} weighted_avg {'precision': 0.9767200827285669, 'recall': 0.9766254174032607, 'f1-score': 0.9766510499714953, 'support': 10182}
 
time = 11.84 secondes

Val loss 0.5956839096730798 accuracy 0.9178445339202881 macro_avg {'precision': 0.9218123494628034, 'recall': 0.9176296213069429, 'f1-score': 0.9181889889524129, 'support': 1132} weighted_avg {'precision': 0.9209713539325286, 'recall': 0.9178445229681979, 'f1-score': 0.9178903921856547, 'support': 1132}
 
----------
Epoch 13/40
time = 277.30 secondes

Train loss 0.10208126689692823 accuracy 0.9798664450645447 macro_avg {'precision': 0.9796685309188664, 'recall': 0.9796516296829564, 'f1-score': 0.9796353405995714, 'support': 10182} weighted_avg {'precision': 0.9799953599858767, 'recall': 0.9798664309565901, 'f1-score': 0.9799053798110281, 'support': 10182}
 
time = 11.45 secondes

Val loss 0.6032099330979793 accuracy 0.9151943325996399 macro_avg {'precision': 0.9211757728054112, 'recall': 0.9171076516807817, 'f1-score': 0.9158527519613016, 'support': 1132} weighted_avg {'precision': 0.9235225819072597, 'recall': 0.9151943462897526, 'f1-score': 0.9161709757764293, 'support': 1132}
 
----------
Epoch 14/40
time = 287.48 secondes

Train loss 0.08890614711794288 accuracy 0.9820271134376526 macro_avg {'precision': 0.9815120183450953, 'recall': 0.9814024695754014, 'f1-score': 0.9814470193055662, 'support': 10182} weighted_avg {'precision': 0.9820781777672679, 'recall': 0.9820271066588097, 'f1-score': 0.9820423047756821, 'support': 10182}
 
time = 11.31 secondes

Val loss 0.6550763915542965 accuracy 0.9072438478469849 macro_avg {'precision': 0.9100516297186806, 'recall': 0.9101005620144613, 'f1-score': 0.9078651747136789, 'support': 1132} weighted_avg {'precision': 0.9101686175826268, 'recall': 0.907243816254417, 'f1-score': 0.9063070028041331, 'support': 1132}
 
----------
Epoch 15/40
time = 288.94 secondes

Train loss 0.1083548903233674 accuracy 0.9802592992782593 macro_avg {'precision': 0.9797736318510708, 'recall': 0.9798707173789752, 'f1-score': 0.9797585049926267, 'support': 10182} weighted_avg {'precision': 0.9803600144651999, 'recall': 0.9802592810842663, 'f1-score': 0.9802523833055345, 'support': 10182}
 
time = 12.06 secondes

Val loss 0.5391685910478667 accuracy 0.9240282773971558 macro_avg {'precision': 0.925259099432054, 'recall': 0.925436438699116, 'f1-score': 0.9242570700165949, 'support': 1132} weighted_avg {'precision': 0.9265511263522002, 'recall': 0.9240282685512368, 'f1-score': 0.9242248374148954, 'support': 1132}
 
----------
Epoch 16/40
time = 296.01 secondes

Train loss 0.09090606189425925 accuracy 0.9843842387199402 macro_avg {'precision': 0.984509088165327, 'recall': 0.9845571315194095, 'f1-score': 0.9845074651615573, 'support': 10182} weighted_avg {'precision': 0.9844497750287216, 'recall': 0.9843842074248674, 'f1-score': 0.9843905438487595, 'support': 10182}
 
time = 11.45 secondes

Val loss 0.6059129974820395 accuracy 0.9125441908836365 macro_avg {'precision': 0.9162957311322144, 'recall': 0.9170011507065239, 'f1-score': 0.9149836931028241, 'support': 1132} weighted_avg {'precision': 0.9169114785262411, 'recall': 0.9125441696113075, 'f1-score': 0.9131323464297656, 'support': 1132}
 
----------
Epoch 17/40
time = 275.92 secondes

Train loss 0.0834225066012306 accuracy 0.9860538244247437 macro_avg {'precision': 0.9859156359101696, 'recall': 0.9858040715311575, 'f1-score': 0.9858501099376727, 'support': 10182} weighted_avg {'precision': 0.9860799761771382, 'recall': 0.9860538204674917, 'f1-score': 0.986057137716148, 'support': 10182}
 
time = 11.96 secondes

Val loss 0.6429009273540455 accuracy 0.9125441908836365 macro_avg {'precision': 0.9156414877290414, 'recall': 0.916671183605532, 'f1-score': 0.914645391172811, 'support': 1132} weighted_avg {'precision': 0.9161087238481239, 'recall': 0.9125441696113075, 'f1-score': 0.912829418645208, 'support': 1132}
 
----------
Epoch 18/40
time = 284.84 secondes

Train loss 0.0755628877073772 accuracy 0.9859556555747986 macro_avg {'precision': 0.9857357143840263, 'recall': 0.9854775839203151, 'f1-score': 0.9855734355432066, 'support': 10182} weighted_avg {'precision': 0.9860070273544018, 'recall': 0.9859556079355726, 'f1-score': 0.9859490935488763, 'support': 10182}
 
time = 11.12 secondes

Val loss 0.6390762426416983 accuracy 0.9134275913238525 macro_avg {'precision': 0.9188549424961296, 'recall': 0.9159271714487766, 'f1-score': 0.9156239622683005, 'support': 1132} weighted_avg {'precision': 0.9176867740956767, 'recall': 0.9134275618374559, 'f1-score': 0.9136059162139551, 'support': 1132}
 
----------
Epoch 19/40
time = 284.71 secondes

Train loss 0.07752837062237387 accuracy 0.9859556555747986 macro_avg {'precision': 0.9855438438724484, 'recall': 0.9850350680016227, 'f1-score': 0.9852528855064128, 'support': 10182} weighted_avg {'precision': 0.9859905700241918, 'recall': 0.9859556079355726, 'f1-score': 0.9859456077749154, 'support': 10182}
 
time = 11.83 secondes

Val loss 0.7384539871449126 accuracy 0.9072438478469849 macro_avg {'precision': 0.9168261815331208, 'recall': 0.9111217738508314, 'f1-score': 0.9103266642133558, 'support': 1132} weighted_avg {'precision': 0.9144462598871768, 'recall': 0.907243816254417, 'f1-score': 0.9067145972543986, 'support': 1132}
 
----------
Epoch 20/40
time = 291.37 secondes

Train loss 0.07229762039586571 accuracy 0.9872323870658875 macro_avg {'precision': 0.9869058105198381, 'recall': 0.986906022801301, 'f1-score': 0.9868921753246298, 'support': 10182} weighted_avg {'precision': 0.9872375136410174, 'recall': 0.9872323708505205, 'f1-score': 0.9872213712663098, 'support': 10182}
 
time = 11.81 secondes

Val loss 0.5754146888535666 accuracy 0.9231448769569397 macro_avg {'precision': 0.9295436741768285, 'recall': 0.9245754688459036, 'f1-score': 0.9251971032368511, 'support': 1132} weighted_avg {'precision': 0.9286604736508609, 'recall': 0.9231448763250883, 'f1-score': 0.9241002667482784, 'support': 1132}
 
----------
Epoch 21/40
time = 283.84 secondes

Train loss 0.07568544972562041 accuracy 0.9865449070930481 macro_avg {'precision': 0.9860525386748338, 'recall': 0.98619836145795, 'f1-score': 0.9861136864979644, 'support': 10182} weighted_avg {'precision': 0.9865734088062803, 'recall': 0.986544883127087, 'f1-score': 0.9865477794221967, 'support': 10182}
 
time = 11.40 secondes

Val loss 0.7411035788991541 accuracy 0.916961133480072 macro_avg {'precision': 0.9221020311960204, 'recall': 0.919127853652582, 'f1-score': 0.9191468970330614, 'support': 1132} weighted_avg {'precision': 0.9201916892053368, 'recall': 0.9169611307420494, 'f1-score': 0.9171218457169146, 'support': 1132}
 
----------
Epoch 22/40
time = 287.19 secondes

Train loss 0.06415800893076808 accuracy 0.9888038039207458 macro_avg {'precision': 0.9882307418826537, 'recall': 0.9881723492338498, 'f1-score': 0.9881890179914252, 'support': 10182} weighted_avg {'precision': 0.9888335121706888, 'recall': 0.9888037713612257, 'f1-score': 0.9888057719583009, 'support': 10182}
 
time = 11.57 secondes

Val loss 0.7264489943108728 accuracy 0.9081271886825562 macro_avg {'precision': 0.9161885189196566, 'recall': 0.9105488193354722, 'f1-score': 0.9110983236334628, 'support': 1132} weighted_avg {'precision': 0.9151019640094377, 'recall': 0.9081272084805654, 'f1-score': 0.9093470238548346, 'support': 1132}
 
----------
Epoch 23/40
time = 282.54 secondes

Train loss 0.07722167876754026 accuracy 0.9866431355476379 macro_avg {'precision': 0.986091519937839, 'recall': 0.9864578902551846, 'f1-score': 0.9862424962568268, 'support': 10182} weighted_avg {'precision': 0.9867220749340733, 'recall': 0.9866430956590061, 'f1-score': 0.986652223867434, 'support': 10182}
 
time = 12.01 secondes

Val loss 0.8123369364743859 accuracy 0.898409903049469 macro_avg {'precision': 0.9086096072543708, 'recall': 0.903343186922112, 'f1-score': 0.9017639196310299, 'support': 1132} weighted_avg {'precision': 0.9090759503374333, 'recall': 0.8984098939929329, 'f1-score': 0.8990945228807018, 'support': 1132}
 
----------
Epoch 24/40
time = 286.35 secondes

Train loss 0.07353293563464888 accuracy 0.9871341586112976 macro_avg {'precision': 0.9868444005783307, 'recall': 0.9869604087862397, 'f1-score': 0.9868632087090917, 'support': 10182} weighted_avg {'precision': 0.9872396155750927, 'recall': 0.9871341583186014, 'f1-score': 0.9871505852248439, 'support': 10182}
 
time = 12.29 secondes

Val loss 0.7378094337018154 accuracy 0.9063604474067688 macro_avg {'precision': 0.9130257762680548, 'recall': 0.9109077332091241, 'f1-score': 0.9089231237396855, 'support': 1132} weighted_avg {'precision': 0.9128184396327633, 'recall': 0.9063604240282686, 'f1-score': 0.906342399760496, 'support': 1132}
 
----------
Epoch 25/40
time = 279.50 secondes

Train loss 0.05734804680184112 accuracy 0.990669846534729 macro_avg {'precision': 0.9903701498357871, 'recall': 0.9905206388771083, 'f1-score': 0.9904290936354847, 'support': 10182} weighted_avg {'precision': 0.9907060966437138, 'recall': 0.9906698094676881, 'f1-score': 0.9906741989546641, 'support': 10182}
 
time = 11.38 secondes

Val loss 0.7702858946402967 accuracy 0.9081271886825562 macro_avg {'precision': 0.9143783495728792, 'recall': 0.9108669867791918, 'f1-score': 0.9093920815093538, 'support': 1132} weighted_avg {'precision': 0.9173164258545948, 'recall': 0.9081272084805654, 'f1-score': 0.9093397501482032, 'support': 1132}
 
----------
Epoch 26/40
time = 286.57 secondes

Train loss 0.06126972464122243 accuracy 0.9899823665618896 macro_avg {'precision': 0.9899706985440592, 'recall': 0.9898007436297768, 'f1-score': 0.9898710215660997, 'support': 10182} weighted_avg {'precision': 0.9900007312247645, 'recall': 0.9899823217442546, 'f1-score': 0.9899771519669998, 'support': 10182}
 
time = 11.54 secondes

Val loss 0.595014635269763 accuracy 0.9222614765167236 macro_avg {'precision': 0.9229835617279241, 'recall': 0.9257491461430292, 'f1-score': 0.923252015107803, 'support': 1132} weighted_avg {'precision': 0.9253510564917836, 'recall': 0.9222614840989399, 'f1-score': 0.9227020254444664, 'support': 1132}
 
----------
Epoch 27/40
time = 282.90 secondes

Train loss 0.052617431907935185 accuracy 0.9913573265075684 macro_avg {'precision': 0.9913494486851411, 'recall': 0.9912843081068436, 'f1-score': 0.9913052012903909, 'support': 10182} weighted_avg {'precision': 0.9913721964730543, 'recall': 0.9913572971911215, 'f1-score': 0.9913528603483278, 'support': 10182}
 
time = 12.23 secondes

Val loss 0.7628147406543525 accuracy 0.9116607904434204 macro_avg {'precision': 0.9146284641427354, 'recall': 0.9145671331725346, 'f1-score': 0.9125237191543848, 'support': 1132} weighted_avg {'precision': 0.9149601096342825, 'recall': 0.911660777385159, 'f1-score': 0.9111138826009296, 'support': 1132}
 
----------
Epoch 28/40
time = 284.27 secondes

Train loss 0.052125829839622516 accuracy 0.9913573265075684 macro_avg {'precision': 0.9913949281594927, 'recall': 0.9912516460719794, 'f1-score': 0.9913021720881783, 'support': 10182} weighted_avg {'precision': 0.991389796172412, 'recall': 0.9913572971911215, 'f1-score': 0.9913529096567001, 'support': 10182}
 
time = 11.41 secondes

Val loss 0.7957005423007322 accuracy 0.9001767039299011 macro_avg {'precision': 0.9084475949399705, 'recall': 0.9040968280005395, 'f1-score': 0.9034668395016257, 'support': 1132} weighted_avg {'precision': 0.908074071580042, 'recall': 0.9001766784452296, 'f1-score': 0.9012478841680427, 'support': 1132}
 
----------
Epoch 29/40
time = 283.51 secondes

Train loss 0.043031097393618344 accuracy 0.9936162233352661 macro_avg {'precision': 0.9935719466213504, 'recall': 0.9933581601056061, 'f1-score': 0.9934572979643608, 'support': 10182} weighted_avg {'precision': 0.99363855683518, 'recall': 0.9936161854252603, 'f1-score': 0.993619955857072, 'support': 10182}
 
time = 11.65 secondes

Val loss 0.7248099183237007 accuracy 0.9134275913238525 macro_avg {'precision': 0.9206651491741369, 'recall': 0.9140615003865232, 'f1-score': 0.914757864486843, 'support': 1132} weighted_avg {'precision': 0.9185463656762571, 'recall': 0.9134275618374559, 'f1-score': 0.9134063595744761, 'support': 1132}
 
----------
Epoch 30/40
time = 289.72 secondes

Train loss 0.04282284056240868 accuracy 0.9920448064804077 macro_avg {'precision': 0.9915788705371001, 'recall': 0.99153707983284, 'f1-score': 0.9915478218379405, 'support': 10182} weighted_avg {'precision': 0.9920747810070039, 'recall': 0.9920447849145551, 'f1-score': 0.9920495129900136, 'support': 10182}
 
time = 12.87 secondes

Val loss 0.6442108950031467 accuracy 0.9231448769569397 macro_avg {'precision': 0.9252164112248378, 'recall': 0.924957621724839, 'f1-score': 0.923772020474428, 'support': 1132} weighted_avg {'precision': 0.925959602878665, 'recall': 0.9231448763250883, 'f1-score': 0.9231901465674315, 'support': 1132}
 
----------
Epoch 31/40
time = 285.54 secondes

Train loss 0.036280290671306524 accuracy 0.9939108490943909 macro_avg {'precision': 0.9939232768549291, 'recall': 0.9935128341114272, 'f1-score': 0.9937062600740451, 'support': 10182} weighted_avg {'precision': 0.9939224781527108, 'recall': 0.9939108230210175, 'f1-score': 0.9939070684070098, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.6600883707653569 accuracy 0.9240282773971558 macro_avg {'precision': 0.9246245082745507, 'recall': 0.9245776094615392, 'f1-score': 0.9234825933541417, 'support': 1132} weighted_avg {'precision': 0.9262481088893539, 'recall': 0.9240282685512368, 'f1-score': 0.9239114532873933, 'support': 1132}
 
----------
Epoch 32/40
time = 285.41 secondes

Train loss 0.031359487746795055 accuracy 0.9949911832809448 macro_avg {'precision': 0.9948990531106929, 'recall': 0.9948281190446574, 'f1-score': 0.9948584935879159, 'support': 10182} weighted_avg {'precision': 0.9950056289334959, 'recall': 0.9949911608721272, 'f1-score': 0.994993292217349, 'support': 10182}
 
time = 11.57 secondes

Val loss 0.6849703435843661 accuracy 0.9196113348007202 macro_avg {'precision': 0.9209846856372552, 'recall': 0.9194585809417694, 'f1-score': 0.9194989698964374, 'support': 1132} weighted_avg {'precision': 0.9210133929940086, 'recall': 0.9196113074204947, 'f1-score': 0.9195814380624154, 'support': 1132}
 
----------
Epoch 33/40
time = 283.46 secondes

Train loss 0.022544264085349375 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961766631233038, 'recall': 0.996037722326393, 'f1-score': 0.9961019702415683, 'support': 10182} weighted_avg {'precision': 0.9961747246622858, 'recall': 0.9961697112551562, 'f1-score': 0.9961669918475502, 'support': 10182}
 
time = 11.43 secondes

Val loss 0.8006442910998782 accuracy 0.9125441908836365 macro_avg {'precision': 0.9139725200000888, 'recall': 0.9153736489968965, 'f1-score': 0.9120972924424142, 'support': 1132} weighted_avg {'precision': 0.9194706457504714, 'recall': 0.9125441696113075, 'f1-score': 0.9136649893713932, 'support': 1132}
 
----------
Epoch 34/40
time = 285.10 secondes

Train loss 0.022843080352472064 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960685790244538, 'recall': 0.9959698066215126, 'f1-score': 0.9960170245019595, 'support': 10182} weighted_avg {'precision': 0.996173787592106, 'recall': 0.9961697112551562, 'f1-score': 0.9961696847670595, 'support': 10182}
 
time = 11.99 secondes

Val loss 0.6976489142959419 accuracy 0.9249116778373718 macro_avg {'precision': 0.9253075234438727, 'recall': 0.9262706453527633, 'f1-score': 0.9244640932183307, 'support': 1132} weighted_avg {'precision': 0.9276184053565184, 'recall': 0.9249116607773852, 'f1-score': 0.9248693875127076, 'support': 1132}
 
----------
Epoch 35/40
time = 286.96 secondes

Train loss 0.022801093942786566 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963116221186447, 'recall': 0.9963989918514509, 'f1-score': 0.9963523197988321, 'support': 10182} weighted_avg {'precision': 0.9963719041866823, 'recall': 0.9963661363189943, 'f1-score': 0.9963661104756578, 'support': 10182}
 
time = 11.72 secondes

Val loss 0.6250464430051298 accuracy 0.9257950782775879 macro_avg {'precision': 0.929882237284866, 'recall': 0.9265824201271611, 'f1-score': 0.9268861188891627, 'support': 1132} weighted_avg {'precision': 0.9289455208040294, 'recall': 0.9257950530035336, 'f1-score': 0.9259611471686846, 'support': 1132}
 
----------
Epoch 36/40
time = 288.36 secondes

Train loss 0.017529683989341377 accuracy 0.9972500801086426 macro_avg {'precision': 0.9971353405542436, 'recall': 0.9970696591816995, 'f1-score': 0.9970997670976626, 'support': 10182} weighted_avg {'precision': 0.9972553903044453, 'recall': 0.9972500491062659, 'f1-score': 0.9972503577867166, 'support': 10182}
 
time = 11.65 secondes

Val loss 0.6162299155985751 accuracy 0.9302120208740234 macro_avg {'precision': 0.9330218482757026, 'recall': 0.9313307264001637, 'f1-score': 0.9311683288034525, 'support': 1132} weighted_avg {'precision': 0.9330948998319301, 'recall': 0.9302120141342756, 'f1-score': 0.930606988814101, 'support': 1132}
 
----------
Epoch 37/40
time = 292.39 secondes

Train loss 0.009542474496527209 accuracy 0.9982321858406067 macro_avg {'precision': 0.9981086043616264, 'recall': 0.9981694341035217, 'f1-score': 0.9981379225567428, 'support': 10182} weighted_avg {'precision': 0.9982338446685931, 'recall': 0.9982321744254566, 'f1-score': 0.9982319404451869, 'support': 10182}
 
time = 11.75 secondes

Val loss 0.6150235492009223 accuracy 0.9275618195533752 macro_avg {'precision': 0.927901654585132, 'recall': 0.9300797181215362, 'f1-score': 0.9278055725122816, 'support': 1132} weighted_avg {'precision': 0.9296100950245749, 'recall': 0.9275618374558304, 'f1-score': 0.927333650713036, 'support': 1132}
 
----------
Epoch 38/40
time = 284.70 secondes

Train loss 0.012207487478402328 accuracy 0.997741162776947 macro_avg {'precision': 0.9977473049379648, 'recall': 0.9977006286100201, 'f1-score': 0.997722471841968, 'support': 10182} weighted_avg {'precision': 0.9977423070323898, 'recall': 0.9977411117658613, 'f1-score': 0.9977401984683877, 'support': 10182}
 
time = 11.50 secondes

Val loss 0.6875913917342138 accuracy 0.9257950782775879 macro_avg {'precision': 0.9281124551285659, 'recall': 0.927672880723704, 'f1-score': 0.9266311059924698, 'support': 1132} weighted_avg {'precision': 0.9283429617334318, 'recall': 0.9257950530035336, 'f1-score': 0.9257407203306987, 'support': 1132}
 
----------
Epoch 39/40
time = 289.58 secondes

Train loss 0.007255477546428462 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990605810335375, 'recall': 0.9990578493203047, 'f1-score': 0.9990585915537261, 'support': 10182} weighted_avg {'precision': 0.9990189812315835, 'recall': 0.9990178746808093, 'f1-score': 0.9990177791026165, 'support': 10182}
 
time = 11.53 secondes

Val loss 0.6347495574886074 accuracy 0.9284452199935913 macro_avg {'precision': 0.9319789326370733, 'recall': 0.9310743054584665, 'f1-score': 0.93043786268922, 'support': 1132} weighted_avg {'precision': 0.9315795844701713, 'recall': 0.9284452296819788, 'f1-score': 0.9288293664167139, 'support': 1132}
 
----------
Epoch 40/40
time = 293.75 secondes

Train loss 0.003165654665932248 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994423477102693, 'recall': 0.9994349729289944, 'f1-score': 0.9994379621780644, 'support': 10182} weighted_avg {'precision': 0.9994132805867483, 'recall': 0.9994107248084856, 'f1-score': 0.9994112708767421, 'support': 10182}
 
time = 11.73 secondes

Val loss 0.6531690885904411 accuracy 0.9302120208740234 macro_avg {'precision': 0.933297678684279, 'recall': 0.9328318795223784, 'f1-score': 0.9320087442637522, 'support': 1132} weighted_avg {'precision': 0.9326933626251807, 'recall': 0.9302120141342756, 'f1-score': 0.9303462569198604, 'support': 1132}
 
----------
best_accuracy 0.9302120208740234 best_epoch 36 macro_avg {'precision': 0.9330218482757026, 'recall': 0.9313307264001637, 'f1-score': 0.9311683288034525, 'support': 1132} weighted_avg {'precision': 0.9330948998319301, 'recall': 0.9302120141342756, 'f1-score': 0.930606988814101, 'support': 1132}

average train time 286.68471801280975

average val time 11.727148681879044
 
time = 73.66 secondes

test_accuracy 0.8584704995155334 macro_avg {'precision': 0.864185978342125, 'recall': 0.8497517542681148, 'f1-score': 0.8512169842841162, 'support': 7532} weighted_avg {'precision': 0.868732740952198, 'recall': 0.8584705257567711, 'f1-score': 0.8584043215718986, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_5
----------
Epoch 1/40
time = 309.97 secondes

Train loss 1.3367781771969758 accuracy 0.6551758050918579 macro_avg {'precision': 0.6644811549185541, 'recall': 0.6392876952083305, 'f1-score': 0.6348604297077375, 'support': 10182} weighted_avg {'precision': 0.6741326951624098, 'recall': 0.6551758004321352, 'f1-score': 0.6498778040161458, 'support': 10182}
 
time = 14.10 secondes

Val loss 0.7411362077568618 accuracy 0.7773851752281189 macro_avg {'precision': 0.7612576410131061, 'recall': 0.7723676634269041, 'f1-score': 0.7594584815064498, 'support': 1132} weighted_avg {'precision': 0.769588467616886, 'recall': 0.7773851590106007, 'f1-score': 0.7659066654563123, 'support': 1132}
 
----------
Epoch 2/40
time = 300.74 secondes

Train loss 0.5034665226983126 accuracy 0.8536633253097534 macro_avg {'precision': 0.8443191951487743, 'recall': 0.8414864660697317, 'f1-score': 0.8390681107094758, 'support': 10182} weighted_avg {'precision': 0.8517135704152183, 'recall': 0.8536633274405814, 'f1-score': 0.8499200702294598, 'support': 10182}
 
time = 12.68 secondes

Val loss 0.6136806866967343 accuracy 0.8242049813270569 macro_avg {'precision': 0.8239962443915712, 'recall': 0.8222029929487562, 'f1-score': 0.8181766573929432, 'support': 1132} weighted_avg {'precision': 0.8313556576446697, 'recall': 0.8242049469964664, 'f1-score': 0.822761844517237, 'support': 1132}
 
----------
Epoch 3/40
time = 295.15 secondes

Train loss 0.319894530102786 accuracy 0.9072874188423157 macro_avg {'precision': 0.9009447366535275, 'recall': 0.899342491881743, 'f1-score': 0.8995210389315698, 'support': 10182} weighted_avg {'precision': 0.9069084807222185, 'recall': 0.9072873698683952, 'f1-score': 0.9065786420442354, 'support': 10182}
 
time = 11.73 secondes

Val loss 0.5333908815461565 accuracy 0.8630741834640503 macro_avg {'precision': 0.8655994703822996, 'recall': 0.8568930407253375, 'f1-score': 0.8583789888435118, 'support': 1132} weighted_avg {'precision': 0.8675850416396655, 'recall': 0.8630742049469965, 'f1-score': 0.8625337470888321, 'support': 1132}
 
----------
Epoch 4/40
time = 295.93 secondes

Train loss 0.23593115300127251 accuracy 0.9351797699928284 macro_avg {'precision': 0.9306976326392327, 'recall': 0.9295215924396025, 'f1-score': 0.9298589807805419, 'support': 10182} weighted_avg {'precision': 0.9350258544837118, 'recall': 0.935179728933412, 'f1-score': 0.9348803580121398, 'support': 10182}
 
time = 11.86 secondes

Val loss 0.6439552092727956 accuracy 0.8595406413078308 macro_avg {'precision': 0.8632015158580761, 'recall': 0.8523731387758453, 'f1-score': 0.8548083543837803, 'support': 1132} weighted_avg {'precision': 0.8644599513883412, 'recall': 0.8595406360424028, 'f1-score': 0.8589154676475667, 'support': 1132}
 
----------
Epoch 5/40
time = 297.87 secondes

Train loss 0.20196600315991492 accuracy 0.9461795687675476 macro_avg {'precision': 0.9433923022501792, 'recall': 0.9423388924646341, 'f1-score': 0.9427051554742922, 'support': 10182} weighted_avg {'precision': 0.9460483617752256, 'recall': 0.9461795325083481, 'f1-score': 0.9459832456254559, 'support': 10182}
 
time = 11.13 secondes

Val loss 0.7079739579242248 accuracy 0.8568904399871826 macro_avg {'precision': 0.8536552243085851, 'recall': 0.8503695412545728, 'f1-score': 0.8498191993855835, 'support': 1132} weighted_avg {'precision': 0.85939293335808, 'recall': 0.8568904593639576, 'f1-score': 0.8559836286228473, 'support': 1132}
 
----------
Epoch 6/40
time = 290.72 secondes

Train loss 0.1580544937017492 accuracy 0.9602239727973938 macro_avg {'precision': 0.9576366657611655, 'recall': 0.9571134483273793, 'f1-score': 0.9572980607809273, 'support': 10182} weighted_avg {'precision': 0.9601034481223031, 'recall': 0.9602239245727755, 'f1-score': 0.9600928251476245, 'support': 10182}
 
time = 11.76 secondes

Val loss 0.7594562303012525 accuracy 0.8648409843444824 macro_avg {'precision': 0.8614800361104514, 'recall': 0.8680817949645304, 'f1-score': 0.8615951700799936, 'support': 1132} weighted_avg {'precision': 0.8696182681030058, 'recall': 0.8648409893992933, 'f1-score': 0.8638238448032596, 'support': 1132}
 
----------
Epoch 7/40
time = 297.18 secondes

Train loss 0.16237037618874076 accuracy 0.9605185985565186 macro_avg {'precision': 0.9582962710827925, 'recall': 0.9581825164861325, 'f1-score': 0.9581930175334531, 'support': 10182} weighted_avg {'precision': 0.9607433721294917, 'recall': 0.9605185621685327, 'f1-score': 0.9605863511489368, 'support': 10182}
 
time = 11.82 secondes

Val loss 0.8670197723705557 accuracy 0.8560070991516113 macro_avg {'precision': 0.8608354952639417, 'recall': 0.8517574776380454, 'f1-score': 0.8527087346202495, 'support': 1132} weighted_avg {'precision': 0.8631770048173685, 'recall': 0.8560070671378092, 'f1-score': 0.8561776066722249, 'support': 1132}
 
----------
Epoch 8/40
time = 296.43 secondes

Train loss 0.13485472650889282 accuracy 0.9677863121032715 macro_avg {'precision': 0.9662822279216288, 'recall': 0.9660455870012676, 'f1-score': 0.9661428739789899, 'support': 10182} weighted_avg {'precision': 0.9678151746757876, 'recall': 0.9677862895305441, 'f1-score': 0.9677813081054597, 'support': 10182}
 
time = 12.20 secondes

Val loss 0.8050074077844226 accuracy 0.8683745861053467 macro_avg {'precision': 0.8777055855546531, 'recall': 0.8645275971990772, 'f1-score': 0.8669717129825247, 'support': 1132} weighted_avg {'precision': 0.8766003999288293, 'recall': 0.8683745583038869, 'f1-score': 0.8682498847876179, 'support': 1132}
 
----------
Epoch 9/40
time = 297.74 secondes

Train loss 0.13896042781460188 accuracy 0.9694559574127197 macro_avg {'precision': 0.9674365059952779, 'recall': 0.9676518270699181, 'f1-score': 0.9674714988807634, 'support': 10182} weighted_avg {'precision': 0.969583815159731, 'recall': 0.9694559025731684, 'f1-score': 0.969458834084228, 'support': 10182}
 
time = 11.29 secondes

Val loss 0.8624035822789998 accuracy 0.8639575839042664 macro_avg {'precision': 0.8758244537346487, 'recall': 0.8620582294327794, 'f1-score': 0.8642872326060373, 'support': 1132} weighted_avg {'precision': 0.8751488550246326, 'recall': 0.8639575971731449, 'f1-score': 0.8651548793690081, 'support': 1132}
 
----------
Epoch 10/40
time = 290.61 secondes

Train loss 0.13077696678519257 accuracy 0.9715183973312378 macro_avg {'precision': 0.969919924287453, 'recall': 0.9696570701326654, 'f1-score': 0.9697566070787069, 'support': 10182} weighted_avg {'precision': 0.9716008781766534, 'recall': 0.9715183657434688, 'f1-score': 0.9715306294095237, 'support': 10182}
 
time = 11.71 secondes

Val loss 0.8892249204505327 accuracy 0.8586572408676147 macro_avg {'precision': 0.8618266901986864, 'recall': 0.8567285539828362, 'f1-score': 0.85620450297607, 'support': 1132} weighted_avg {'precision': 0.8647868745003279, 'recall': 0.8586572438162544, 'f1-score': 0.8587771298320981, 'support': 1132}
 
----------
Epoch 11/40
time = 292.69 secondes

Train loss 0.12694274168596342 accuracy 0.973384439945221 macro_avg {'precision': 0.9723734747558087, 'recall': 0.9725306360383227, 'f1-score': 0.9724047295535904, 'support': 10182} weighted_avg {'precision': 0.9735467067073881, 'recall': 0.9733844038499313, 'f1-score': 0.9734244336248603, 'support': 10182}
 
time = 10.94 secondes

Val loss 0.9269022541378894 accuracy 0.8683745861053467 macro_avg {'precision': 0.8735444837570414, 'recall': 0.8654874165619614, 'f1-score': 0.8664209014501747, 'support': 1132} weighted_avg {'precision': 0.8755263713585694, 'recall': 0.8683745583038869, 'f1-score': 0.8687396429366855, 'support': 1132}
 
----------
Epoch 12/40
time = 293.72 secondes

Train loss 0.12195208576421789 accuracy 0.9747593998908997 macro_avg {'precision': 0.9736296994269559, 'recall': 0.973240410342159, 'f1-score': 0.9733750314014797, 'support': 10182} weighted_avg {'precision': 0.9748259931474029, 'recall': 0.9747593792967982, 'f1-score': 0.9747335445356287, 'support': 10182}
 
time = 12.04 secondes

Val loss 0.8897330046014067 accuracy 0.8710247278213501 macro_avg {'precision': 0.8789191533603825, 'recall': 0.8646881333363894, 'f1-score': 0.8689371205272904, 'support': 1132} weighted_avg {'precision': 0.8788135490299948, 'recall': 0.8710247349823321, 'f1-score': 0.8720832073690271, 'support': 1132}
 
----------
Epoch 13/40
time = 289.43 secondes

Train loss 0.11040404601912804 accuracy 0.9775093793869019 macro_avg {'precision': 0.9763299148112843, 'recall': 0.9764462332221976, 'f1-score': 0.976366413400763, 'support': 10182} weighted_avg {'precision': 0.9775827969237105, 'recall': 0.9775093301905323, 'f1-score': 0.9775244424378435, 'support': 10182}
 
time = 11.31 secondes

Val loss 0.9720459557085095 accuracy 0.8674911856651306 macro_avg {'precision': 0.8697931318465424, 'recall': 0.8637895213625434, 'f1-score': 0.864952315689651, 'support': 1132} weighted_avg {'precision': 0.8725535303422224, 'recall': 0.8674911660777385, 'f1-score': 0.8682960351906353, 'support': 1132}
 
----------
Epoch 14/40
time = 291.14 secondes

Train loss 0.1015295452418466 accuracy 0.9794735908508301 macro_avg {'precision': 0.9785381100512994, 'recall': 0.978551262529812, 'f1-score': 0.978524172697675, 'support': 10182} weighted_avg {'precision': 0.9795374308919585, 'recall': 0.9794735808289138, 'f1-score': 0.9794843287291789, 'support': 10182}
 
time = 11.12 secondes

Val loss 1.0787813556200208 accuracy 0.8480565547943115 macro_avg {'precision': 0.8568239172610974, 'recall': 0.8517240671634072, 'f1-score': 0.8490050408092469, 'support': 1132} weighted_avg {'precision': 0.8646681595529612, 'recall': 0.8480565371024735, 'f1-score': 0.8511281188507689, 'support': 1132}
 
----------
Epoch 15/40
time = 296.78 secondes

Train loss 0.0883021516560781 accuracy 0.9832056760787964 macro_avg {'precision': 0.9825491258457688, 'recall': 0.9821965987873005, 'f1-score': 0.9823593584414834, 'support': 10182} weighted_avg {'precision': 0.9832094347119508, 'recall': 0.9832056570418385, 'f1-score': 0.9831955609254708, 'support': 10182}
 
time = 11.41 secondes

Val loss 0.895162898538844 accuracy 0.8745583295822144 macro_avg {'precision': 0.8803728773687027, 'recall': 0.8705085274573119, 'f1-score': 0.8726604042653093, 'support': 1132} weighted_avg {'precision': 0.879133770734736, 'recall': 0.8745583038869258, 'f1-score': 0.8743120666918212, 'support': 1132}
 
----------
Epoch 16/40
time = 293.98 secondes

Train loss 0.08291633959421088 accuracy 0.9822235703468323 macro_avg {'precision': 0.9812550073688142, 'recall': 0.9808336311370164, 'f1-score': 0.9810225703546462, 'support': 10182} weighted_avg {'precision': 0.9822462938638757, 'recall': 0.9822235317226478, 'f1-score': 0.9822154569490035, 'support': 10182}
 
time = 11.88 secondes

Val loss 0.8931056056208548 accuracy 0.8745583295822144 macro_avg {'precision': 0.8787466143622493, 'recall': 0.8740188215567974, 'f1-score': 0.8738120465270937, 'support': 1132} weighted_avg {'precision': 0.882157820789269, 'recall': 0.8745583038869258, 'f1-score': 0.8760769743642802, 'support': 1132}
 
----------
Epoch 17/40
time = 295.47 secondes

Train loss 0.0814682445863976 accuracy 0.983598530292511 macro_avg {'precision': 0.9831920180332512, 'recall': 0.983363282311754, 'f1-score': 0.9832609663005819, 'support': 10182} weighted_avg {'precision': 0.9836130795994863, 'recall': 0.9835985071695148, 'f1-score': 0.9835891949173103, 'support': 10182}
 
time = 11.92 secondes

Val loss 1.016709151867987 accuracy 0.8727915287017822 macro_avg {'precision': 0.8780180687492025, 'recall': 0.8697036079705015, 'f1-score': 0.8689418864255749, 'support': 1132} weighted_avg {'precision': 0.8753093018957424, 'recall': 0.872791519434629, 'f1-score': 0.8694580965629237, 'support': 1132}
 
----------
Epoch 18/40
time = 299.35 secondes

Train loss 0.08771437823310653 accuracy 0.9832056760787964 macro_avg {'precision': 0.9831997231590334, 'recall': 0.9831292488557388, 'f1-score': 0.9831031567509081, 'support': 10182} weighted_avg {'precision': 0.9832710921506673, 'recall': 0.9832056570418385, 'f1-score': 0.9831754116580098, 'support': 10182}
 
time = 12.52 secondes

Val loss 0.9842042993548372 accuracy 0.8763250708580017 macro_avg {'precision': 0.8786038281681723, 'recall': 0.8752270009208818, 'f1-score': 0.8732550850083858, 'support': 1132} weighted_avg {'precision': 0.8789523743078606, 'recall': 0.8763250883392226, 'f1-score': 0.8738465198648009, 'support': 1132}
 
----------
Epoch 19/40
time = 301.84 secondes

Train loss 0.07533400229752815 accuracy 0.9866431355476379 macro_avg {'precision': 0.9862599703561157, 'recall': 0.9860677106298773, 'f1-score': 0.9861437099188646, 'support': 10182} weighted_avg {'precision': 0.9867047952595253, 'recall': 0.9866430956590061, 'f1-score': 0.9866535266918647, 'support': 10182}
 
time = 12.22 secondes

Val loss 0.9682795262508567 accuracy 0.8727915287017822 macro_avg {'precision': 0.8726260728976885, 'recall': 0.8743745182494228, 'f1-score': 0.8704889372140133, 'support': 1132} weighted_avg {'precision': 0.8807427408725576, 'recall': 0.872791519434629, 'f1-score': 0.8735850828260338, 'support': 1132}
 
----------
Epoch 20/40
time = 298.94 secondes

Train loss 0.0881484313582088 accuracy 0.9836967587471008 macro_avg {'precision': 0.9825744117978046, 'recall': 0.9828702420544284, 'f1-score': 0.9827008871474311, 'support': 10182} weighted_avg {'precision': 0.983753167858985, 'recall': 0.9836967197014339, 'f1-score': 0.983704237793277, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.842448724375982 accuracy 0.880742073059082 macro_avg {'precision': 0.8814277289244752, 'recall': 0.8785670175565963, 'f1-score': 0.8785402521511623, 'support': 1132} weighted_avg {'precision': 0.8837137933959679, 'recall': 0.8807420494699647, 'f1-score': 0.8806364574509327, 'support': 1132}
 
----------
Epoch 21/40
time = 301.58 secondes

Train loss 0.08017308498736904 accuracy 0.9848753213882446 macro_avg {'precision': 0.9841875032020344, 'recall': 0.9845172611200006, 'f1-score': 0.9843322253349506, 'support': 10182} weighted_avg {'precision': 0.9849335068957673, 'recall': 0.9848752700844627, 'f1-score': 0.9848850202069679, 'support': 10182}
 
time = 11.92 secondes

Val loss 1.0284712626311836 accuracy 0.8674911856651306 macro_avg {'precision': 0.8772389565627996, 'recall': 0.8637883799686243, 'f1-score': 0.8664717107815927, 'support': 1132} weighted_avg {'precision': 0.8785410941665011, 'recall': 0.8674911660777385, 'f1-score': 0.8688386562059274, 'support': 1132}
 
----------
Epoch 22/40
time = 299.21 secondes

Train loss 0.06894142292870327 accuracy 0.9873306155204773 macro_avg {'precision': 0.9868918769787317, 'recall': 0.987263733763432, 'f1-score': 0.9870611297916436, 'support': 10182} weighted_avg {'precision': 0.9873744096906718, 'recall': 0.9873305833824396, 'f1-score': 0.9873378723778382, 'support': 10182}
 
time = 11.48 secondes

Val loss 0.9703292824726791 accuracy 0.879858672618866 macro_avg {'precision': 0.8857164548553891, 'recall': 0.8741926416791582, 'f1-score': 0.8773787022435826, 'support': 1132} weighted_avg {'precision': 0.8865855974349031, 'recall': 0.8798586572438163, 'f1-score': 0.8809607579381131, 'support': 1132}
 
----------
Epoch 23/40
time = 296.87 secondes

Train loss 0.07667959438390819 accuracy 0.9873306155204773 macro_avg {'precision': 0.987242956579165, 'recall': 0.9870020570724117, 'f1-score': 0.9871047766480162, 'support': 10182} weighted_avg {'precision': 0.9873908148526579, 'recall': 0.9873305833824396, 'f1-score': 0.987343515197334, 'support': 10182}
 
time = 12.25 secondes

Val loss 0.7770891558863862 accuracy 0.9028268456459045 macro_avg {'precision': 0.9036680600843219, 'recall': 0.9029276350136086, 'f1-score': 0.9022500497214025, 'support': 1132} weighted_avg {'precision': 0.9058631658439417, 'recall': 0.9028268551236749, 'f1-score': 0.9033249538237075, 'support': 1132}
 
----------
Epoch 24/40
time = 294.67 secondes

Train loss 0.061505902432469485 accuracy 0.9888038039207458 macro_avg {'precision': 0.987911036281031, 'recall': 0.9879403833187329, 'f1-score': 0.9879184255855465, 'support': 10182} weighted_avg {'precision': 0.988815231995876, 'recall': 0.9888037713612257, 'f1-score': 0.9888020525259754, 'support': 10182}
 
time = 11.62 secondes

Val loss 0.900747341201821 accuracy 0.880742073059082 macro_avg {'precision': 0.8795129326402567, 'recall': 0.875671674348502, 'f1-score': 0.8765873658328008, 'support': 1132} weighted_avg {'precision': 0.8835296514285452, 'recall': 0.8807420494699647, 'f1-score': 0.8811797281523696, 'support': 1132}
 
----------
Epoch 25/40
time = 298.77 secondes

Train loss 0.051664948226291696 accuracy 0.9903752207756042 macro_avg {'precision': 0.9897898818457076, 'recall': 0.9895562060864457, 'f1-score': 0.9896614602327567, 'support': 10182} weighted_avg {'precision': 0.9903870294812431, 'recall': 0.9903751718719308, 'f1-score': 0.9903716287329745, 'support': 10182}
 
time = 12.49 secondes

Val loss 0.9067088620301458 accuracy 0.8851590156555176 macro_avg {'precision': 0.8931388531187133, 'recall': 0.8819751473720849, 'f1-score': 0.885346254172817, 'support': 1132} weighted_avg {'precision': 0.8914666585642124, 'recall': 0.8851590106007067, 'f1-score': 0.8860280069053765, 'support': 1132}
 
----------
Epoch 26/40
time = 298.07 secondes

Train loss 0.05918962020192422 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888377863966407, 'recall': 0.9885782267016155, 'f1-score': 0.9886946008256867, 'support': 10182} weighted_avg {'precision': 0.988915955505508, 'recall': 0.9889019838931448, 'f1-score': 0.9888962200106027, 'support': 10182}
 
time = 11.38 secondes

Val loss 0.915467399454915 accuracy 0.8780918717384338 macro_avg {'precision': 0.8831161999277365, 'recall': 0.8770958711019002, 'f1-score': 0.8773321636409422, 'support': 1132} weighted_avg {'precision': 0.885675253664465, 'recall': 0.8780918727915195, 'f1-score': 0.8789818905673127, 'support': 1132}
 
----------
Epoch 27/40
time = 298.23 secondes

Train loss 0.04318244069166425 accuracy 0.9925358891487122 macro_avg {'precision': 0.9921541768224682, 'recall': 0.9920164171068941, 'f1-score': 0.9920795210020424, 'support': 10182} weighted_avg {'precision': 0.9925412892210868, 'recall': 0.9925358475741505, 'f1-score': 0.9925333971045885, 'support': 10182}
 
time = 12.24 secondes

Val loss 1.0270075744685503 accuracy 0.8745583295822144 macro_avg {'precision': 0.8901759161165149, 'recall': 0.8705250242910483, 'f1-score': 0.8748038602410263, 'support': 1132} weighted_avg {'precision': 0.8883473209150067, 'recall': 0.8745583038869258, 'f1-score': 0.8759680824065087, 'support': 1132}
 
----------
Epoch 28/40
time = 291.03 secondes

Train loss 0.05611544637972806 accuracy 0.9902769923210144 macro_avg {'precision': 0.9898285673543962, 'recall': 0.989764336496096, 'f1-score': 0.9897864332034165, 'support': 10182} weighted_avg {'precision': 0.9902820050944068, 'recall': 0.9902769593400118, 'f1-score': 0.9902696016103169, 'support': 10182}
 
time = 11.55 secondes

Val loss 1.0862559009950876 accuracy 0.8727915287017822 macro_avg {'precision': 0.8832795996488659, 'recall': 0.8644280711212481, 'f1-score': 0.8672157929695373, 'support': 1132} weighted_avg {'precision': 0.8805013797565487, 'recall': 0.872791519434629, 'f1-score': 0.870880107515478, 'support': 1132}
 
----------
Epoch 29/40
time = 296.12 secondes

Train loss 0.038779945457247736 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919889354957068, 'recall': 0.9918063455461678, 'f1-score': 0.9918910668646743, 'support': 10182} weighted_avg {'precision': 0.9920634796638865, 'recall': 0.9920447849145551, 'f1-score': 0.9920480915830542, 'support': 10182}
 
time = 12.52 secondes

Val loss 1.056240215185336 accuracy 0.8789752721786499 macro_avg {'precision': 0.8798056627832397, 'recall': 0.8738811292763302, 'f1-score': 0.8753173719365851, 'support': 1132} weighted_avg {'precision': 0.8799610827122846, 'recall': 0.8789752650176679, 'f1-score': 0.8780698043000237, 'support': 1132}
 
----------
Epoch 30/40
time = 291.51 secondes

Train loss 0.03676659572556959 accuracy 0.993714451789856 macro_avg {'precision': 0.9936356346294681, 'recall': 0.9934657941258047, 'f1-score': 0.9935426866188207, 'support': 10182} weighted_avg {'precision': 0.9937211525847667, 'recall': 0.9937143979571793, 'f1-score': 0.9937105211814028, 'support': 10182}
 
time = 11.78 secondes

Val loss 1.1841430544532863 accuracy 0.8666077852249146 macro_avg {'precision': 0.8708011605640487, 'recall': 0.8644871721770313, 'f1-score': 0.865127807962596, 'support': 1132} weighted_avg {'precision': 0.8735747552602027, 'recall': 0.8666077738515902, 'f1-score': 0.8675513200943009, 'support': 1132}
 
----------
Epoch 31/40
time = 295.04 secondes

Train loss 0.034178723067237925 accuracy 0.9935179948806763 macro_avg {'precision': 0.9935684769202051, 'recall': 0.9935378417278617, 'f1-score': 0.9935458226700131, 'support': 10182} weighted_avg {'precision': 0.9935362527746974, 'recall': 0.9935179728933412, 'f1-score': 0.993519758622804, 'support': 10182}
 
time = 11.82 secondes

Val loss 1.0441244944695298 accuracy 0.8825088143348694 macro_avg {'precision': 0.881666588388792, 'recall': 0.8818877831496824, 'f1-score': 0.8810329828798714, 'support': 1132} weighted_avg {'precision': 0.8847521898946427, 'recall': 0.8825088339222615, 'f1-score': 0.8828906328284153, 'support': 1132}
 
----------
Epoch 32/40
time = 303.47 secondes

Train loss 0.025831179807078067 accuracy 0.9950894117355347 macro_avg {'precision': 0.995057145318843, 'recall': 0.9951682671745837, 'f1-score': 0.99511036672603, 'support': 10182} weighted_avg {'precision': 0.9950982133139367, 'recall': 0.9950893734040464, 'f1-score': 0.9950914904501125, 'support': 10182}
 
time = 11.75 secondes

Val loss 1.1494926475520322 accuracy 0.8763250708580017 macro_avg {'precision': 0.8804343291654563, 'recall': 0.8733740920254329, 'f1-score': 0.8728648300318861, 'support': 1132} weighted_avg {'precision': 0.8832815631140575, 'recall': 0.8763250883392226, 'f1-score': 0.8758789228148647, 'support': 1132}
 
----------
Epoch 33/40
time = 292.29 secondes

Train loss 0.03170537632834979 accuracy 0.9941073060035706 macro_avg {'precision': 0.9941277866181253, 'recall': 0.9940940774408166, 'f1-score': 0.9941059754876939, 'support': 10182} weighted_avg {'precision': 0.994117980491821, 'recall': 0.9941072480848556, 'f1-score': 0.9941075291012847, 'support': 10182}
 
time = 12.42 secondes

Val loss 1.0812614406351944 accuracy 0.8772084712982178 macro_avg {'precision': 0.8800126437402316, 'recall': 0.8736061719660799, 'f1-score': 0.874349803707849, 'support': 1132} weighted_avg {'precision': 0.8827811876479591, 'recall': 0.877208480565371, 'f1-score': 0.8774631839996309, 'support': 1132}
 
----------
Epoch 34/40
time = 291.95 secondes

Train loss 0.019502009619767766 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961757821740356, 'recall': 0.9961179804922503, 'f1-score': 0.9961437111408055, 'support': 10182} weighted_avg {'precision': 0.996181834311284, 'recall': 0.9961697112551562, 'f1-score': 0.9961724754671237, 'support': 10182}
 
time = 12.29 secondes

Val loss 1.1025607920031253 accuracy 0.8772084712982178 macro_avg {'precision': 0.8747827033875337, 'recall': 0.8737829685807779, 'f1-score': 0.8732101629913798, 'support': 1132} weighted_avg {'precision': 0.8783553542493969, 'recall': 0.877208480565371, 'f1-score': 0.8767071717539358, 'support': 1132}
 
----------
Epoch 35/40
time = 295.90 secondes

Train loss 0.012931581509542161 accuracy 0.9969554543495178 macro_avg {'precision': 0.9969608337807134, 'recall': 0.9969343512533729, 'f1-score': 0.9969459787096989, 'support': 10182} weighted_avg {'precision': 0.9969583800470019, 'recall': 0.9969554115105087, 'f1-score': 0.9969553269173552, 'support': 10182}
 
time = 12.11 secondes

Val loss 1.108234219550814 accuracy 0.8842756152153015 macro_avg {'precision': 0.8844296581594667, 'recall': 0.8814823093151626, 'f1-score': 0.882127853666478, 'support': 1132} weighted_avg {'precision': 0.8860884939428796, 'recall': 0.8842756183745583, 'f1-score': 0.8843368727082908, 'support': 1132}
 
----------
Epoch 36/40
time = 297.69 secondes

Train loss 0.01640330785326107 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971029079635526, 'recall': 0.9970908133133959, 'f1-score': 0.9970933207507009, 'support': 10182} weighted_avg {'precision': 0.9971577898042147, 'recall': 0.9971518365743469, 'f1-score': 0.9971513310932651, 'support': 10182}
 
time = 11.97 secondes

Val loss 1.0751689583737485 accuracy 0.8895759582519531 macro_avg {'precision': 0.8926813750566689, 'recall': 0.8850968911803202, 'f1-score': 0.8864121539721376, 'support': 1132} weighted_avg {'precision': 0.8930243970696826, 'recall': 0.8895759717314488, 'f1-score': 0.8889636893707753, 'support': 1132}
 
----------
Epoch 37/40
time = 293.38 secondes

Train loss 0.012556412273313772 accuracy 0.9978393316268921 macro_avg {'precision': 0.9976240302280857, 'recall': 0.9976715562444394, 'f1-score': 0.9976466220277599, 'support': 10182} weighted_avg {'precision': 0.9978418011587814, 'recall': 0.9978393242977804, 'f1-score': 0.9978395736417928, 'support': 10182}
 
time = 11.98 secondes

Val loss 1.0033745876447886 accuracy 0.8931095600128174 macro_avg {'precision': 0.8951102861549405, 'recall': 0.8918776651537523, 'f1-score': 0.8928198481719196, 'support': 1132} weighted_avg {'precision': 0.8951674999629379, 'recall': 0.8931095406360424, 'f1-score': 0.8934211052706723, 'support': 1132}
 
----------
Epoch 38/40
time = 290.80 secondes

Train loss 0.008216061485423492 accuracy 0.9982321858406067 macro_avg {'precision': 0.9981796481941736, 'recall': 0.9982063900755834, 'f1-score': 0.9981919996469678, 'support': 10182} weighted_avg {'precision': 0.9982335841262115, 'recall': 0.9982321744254566, 'f1-score': 0.9982318409233338, 'support': 10182}
 
time = 11.30 secondes

Val loss 1.06445659743335 accuracy 0.8904593586921692 macro_avg {'precision': 0.8921404130252103, 'recall': 0.8870303587309737, 'f1-score': 0.8875721268925452, 'support': 1132} weighted_avg {'precision': 0.8925758457746488, 'recall': 0.8904593639575972, 'f1-score': 0.8898773596494421, 'support': 1132}
 
----------
Epoch 39/40
time = 294.09 secondes

Train loss 0.008197971947010899 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981501385949549, 'recall': 0.9981226465126101, 'f1-score': 0.9981336986035938, 'support': 10182} weighted_avg {'precision': 0.99813774393526, 'recall': 0.9981339618935376, 'f1-score': 0.9981331203371134, 'support': 10182}
 
time = 11.58 secondes

Val loss 1.0531332256176054 accuracy 0.8895759582519531 macro_avg {'precision': 0.8939346666401663, 'recall': 0.8860734388193933, 'f1-score': 0.8880972267028524, 'support': 1132} weighted_avg {'precision': 0.8921078177952027, 'recall': 0.8895759717314488, 'f1-score': 0.8892359093109908, 'support': 1132}
 
----------
Epoch 40/40
time = 292.58 secondes

Train loss 0.0027641079958579313 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991293242270929, 'recall': 0.9990916041627111, 'f1-score': 0.9991100119428358, 'support': 10182} weighted_avg {'precision': 0.9991164990189677, 'recall': 0.9991160872127284, 'f1-score': 0.999115881392864, 'support': 10182}
 
time = 12.46 secondes

Val loss 1.0702825233213804 accuracy 0.8878092169761658 macro_avg {'precision': 0.8922888117997578, 'recall': 0.8848065087083257, 'f1-score': 0.8865589944117918, 'support': 1132} weighted_avg {'precision': 0.8908323628116985, 'recall': 0.8878091872791519, 'f1-score': 0.8875507525623382, 'support': 1132}
 
----------
best_accuracy 0.9028268456459045 best_epoch 23 macro_avg {'precision': 0.9036680600843219, 'recall': 0.9029276350136086, 'f1-score': 0.9022500497214025, 'support': 1132} weighted_avg {'precision': 0.9058631658439417, 'recall': 0.9028268551236749, 'f1-score': 0.9033249538237075, 'support': 1132}

average train time 295.97230937480924

average val time 11.897810941934585
 
time = 71.99 secondes

test_accuracy 0.8281996846199036 macro_avg {'precision': 0.8259086869084659, 'recall': 0.8176456659355882, 'f1-score': 0.818284235074124, 'support': 7532} weighted_avg {'precision': 0.8359962962157376, 'recall': 0.8281996813595327, 'f1-score': 0.8288377690296781, 'support': 7532}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_5
----------
Epoch 1/40
time = 364.75 secondes

Train loss 0.27486642084948654 micro_f1_score 0.5975868769488002 
 
time = 26.44 secondes

Val loss 0.24729467415418782 micro_f1_score 0.6004746835443039
 
----------
Epoch 2/40
time = 362.82 secondes

Train loss 0.18379603548160006 micro_f1_score 0.7438201316715664 
 
time = 26.91 secondes

Val loss 0.21223972139299893 micro_f1_score 0.6836450457620373
 
----------
Epoch 3/40
time = 353.77 secondes

Train loss 0.15861991260972647 micro_f1_score 0.7884340108789005 
 
time = 25.42 secondes

Val loss 0.20326389726556715 micro_f1_score 0.7088509316770186
 
----------
Epoch 4/40
time = 355.32 secondes

Train loss 0.1421008814696793 micro_f1_score 0.8178384306080175 
 
time = 24.76 secondes

Val loss 0.1994268737855505 micro_f1_score 0.7285877426722497
 
----------
Epoch 5/40
time = 357.19 secondes

Train loss 0.12747099590361924 micro_f1_score 0.8401550012109469 
 
time = 25.92 secondes

Val loss 0.21221855783560237 micro_f1_score 0.7165653495440729
 
----------
Epoch 6/40
time = 347.44 secondes

Train loss 0.11383101854909648 micro_f1_score 0.8606985146527499 
 
time = 25.32 secondes

Val loss 0.23148198841048068 micro_f1_score 0.7079646017699116
 
----------
Epoch 7/40
time = 351.15 secondes

Train loss 0.10186314006327643 micro_f1_score 0.8798881565807869 
 
time = 27.12 secondes

Val loss 0.22766480197916267 micro_f1_score 0.7317612380250553
 
----------
Epoch 8/40
