[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
20newsgroups_BERT_head_none_1
----------
Epoch 1/40
time = 422.86 secondes

Train loss 1.263328872702934 accuracy 0.685523509979248 macro_avg {'precision': 0.7017603057498867, 'recall': 0.6702080576926586, 'f1-score': 0.667996388290267, 'support': 10182} weighted_avg {'precision': 0.7087122297631298, 'recall': 0.6855234727951287, 'f1-score': 0.6820836786233148, 'support': 10182}
 
time = 12.85 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.6117357586471128 accuracy 0.833922266960144 macro_avg {'precision': 0.8075526964716172, 'recall': 0.8275260930245845, 'f1-score': 0.812253921534946, 'support': 1132} weighted_avg {'precision': 0.8194172862521273, 'recall': 0.833922261484099, 'f1-score': 0.8212743361832183, 'support': 1132}
 
----------
Epoch 2/40
time = 439.91 secondes

Train loss 0.4386543285399909 accuracy 0.8714398145675659 macro_avg {'precision': 0.8621184933017579, 'recall': 0.8607868295548933, 'f1-score': 0.8595815488949154, 'support': 10182} weighted_avg {'precision': 0.8692875820976627, 'recall': 0.8714397957179336, 'f1-score': 0.8689765431889259, 'support': 10182}
 
time = 12.78 secondes

Val loss 0.5073278901022924 accuracy 0.8586572408676147 macro_avg {'precision': 0.8635517005739002, 'recall': 0.8604647720820278, 'f1-score': 0.8552555924202144, 'support': 1132} weighted_avg {'precision': 0.8703695371925328, 'recall': 0.8586572438162544, 'f1-score': 0.8571153378430973, 'support': 1132}
 
----------
Epoch 3/40
time = 431.58 secondes

Train loss 0.2747196465338839 accuracy 0.9231978058815002 macro_avg {'precision': 0.9193732634797367, 'recall': 0.918767342020445, 'f1-score': 0.9189110828427663, 'support': 10182} weighted_avg {'precision': 0.923690461162655, 'recall': 0.923197800039285, 'f1-score': 0.9232952996646852, 'support': 10182}
 
time = 12.56 secondes

Val loss 0.5090569610720579 accuracy 0.880742073059082 macro_avg {'precision': 0.8893712226455669, 'recall': 0.8793429707831271, 'f1-score': 0.8799391074588396, 'support': 1132} weighted_avg {'precision': 0.8904874636616423, 'recall': 0.8807420494699647, 'f1-score': 0.8813505408516, 'support': 1132}
 
----------
Epoch 4/40
time = 437.07 secondes

Train loss 0.21090531920183747 accuracy 0.9459831118583679 macro_avg {'precision': 0.9435849257774725, 'recall': 0.9435759317062413, 'f1-score': 0.9434588148368256, 'support': 10182} weighted_avg {'precision': 0.9463029497747899, 'recall': 0.94598310744451, 'f1-score': 0.9460345031700066, 'support': 10182}
 
time = 12.37 secondes

Val loss 0.4997026262555639 accuracy 0.8939929604530334 macro_avg {'precision': 0.9033339572333656, 'recall': 0.8945774671959376, 'f1-score': 0.8955135800083459, 'support': 1132} weighted_avg {'precision': 0.9037972275295929, 'recall': 0.8939929328621908, 'f1-score': 0.8951663511566404, 'support': 1132}
 
----------
Epoch 5/40
time = 395.42 secondes

Train loss 0.19058163257336225 accuracy 0.95403653383255 macro_avg {'precision': 0.9522270658610079, 'recall': 0.9520007755577243, 'f1-score': 0.951991120178459, 'support': 10182} weighted_avg {'precision': 0.954318674658952, 'recall': 0.9540365350618739, 'f1-score': 0.9540604003536982, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.510394016975983 accuracy 0.9028268456459045 macro_avg {'precision': 0.9071931730603511, 'recall': 0.9054110283893445, 'f1-score': 0.9041423732568423, 'support': 1132} weighted_avg {'precision': 0.9081880551184167, 'recall': 0.9028268551236749, 'f1-score': 0.9034682535358717, 'support': 1132}
 
----------
Epoch 6/40
time = 425.87 secondes

Train loss 0.16011137826621513 accuracy 0.9650363922119141 macro_avg {'precision': 0.9637307387385095, 'recall': 0.9638135604312433, 'f1-score': 0.9637224922030729, 'support': 10182} weighted_avg {'precision': 0.9651717078029977, 'recall': 0.96503633863681, 'f1-score': 0.9650578870618314, 'support': 10182}
 
time = 11.90 secondes

Val loss 0.5422729771382595 accuracy 0.9072438478469849 macro_avg {'precision': 0.9066473013312075, 'recall': 0.9054301498489938, 'f1-score': 0.9038594044827255, 'support': 1132} weighted_avg {'precision': 0.9100829581345792, 'recall': 0.907243816254417, 'f1-score': 0.9062308585935381, 'support': 1132}
 
----------
Epoch 7/40
time = 415.69 secondes

Train loss 0.14136511692484868 accuracy 0.9677863121032715 macro_avg {'precision': 0.9666989657427691, 'recall': 0.9665305230879839, 'f1-score': 0.9665724238679578, 'support': 10182} weighted_avg {'precision': 0.9677096164036312, 'recall': 0.9677862895305441, 'f1-score': 0.9677054079219324, 'support': 10182}
 
time = 13.29 secondes

Val loss 0.5490426182177928 accuracy 0.9063604474067688 macro_avg {'precision': 0.9133825308758444, 'recall': 0.9069435465244563, 'f1-score': 0.908165678433537, 'support': 1132} weighted_avg {'precision': 0.911229278242275, 'recall': 0.9063604240282686, 'f1-score': 0.9067468741201858, 'support': 1132}
 
----------
Epoch 8/40
time = 416.16 secondes

Train loss 0.1312545144240488 accuracy 0.9706344604492188 macro_avg {'precision': 0.9698953391326416, 'recall': 0.9701152270397738, 'f1-score': 0.9699462544438354, 'support': 10182} weighted_avg {'precision': 0.9706868058674415, 'recall': 0.9706344529561972, 'f1-score': 0.9706031148004546, 'support': 10182}
 
time = 9.84 secondes

Val loss 0.5877536177355632 accuracy 0.9178445339202881 macro_avg {'precision': 0.9268556014349253, 'recall': 0.9201675312063686, 'f1-score': 0.9206652638897882, 'support': 1132} weighted_avg {'precision': 0.9236928605226554, 'recall': 0.9178445229681979, 'f1-score': 0.9177331551364551, 'support': 1132}
 
----------
Epoch 9/40
time = 396.97 secondes

Train loss 0.1352744771490108 accuracy 0.9727951288223267 macro_avg {'precision': 0.9720780321387641, 'recall': 0.9720669462662729, 'f1-score': 0.9720418560346934, 'support': 10182} weighted_avg {'precision': 0.9728624516582113, 'recall': 0.9727951286584168, 'f1-score': 0.9727975317540679, 'support': 10182}
 
time = 13.99 secondes

Val loss 0.686660295657725 accuracy 0.8939929604530334 macro_avg {'precision': 0.9041602299420557, 'recall': 0.8962010044007845, 'f1-score': 0.895436250905812, 'support': 1132} weighted_avg {'precision': 0.901040849613466, 'recall': 0.8939929328621908, 'f1-score': 0.8922004240154964, 'support': 1132}
 
----------
Epoch 10/40
time = 433.21 secondes

Train loss 0.11525016964648158 accuracy 0.9760361909866333 macro_avg {'precision': 0.9748788870881258, 'recall': 0.9749513767834449, 'f1-score': 0.9748890720067012, 'support': 10182} weighted_avg {'precision': 0.9761174646622938, 'recall': 0.9760361422117462, 'f1-score': 0.9760524808549316, 'support': 10182}
 
time = 12.47 secondes

Val loss 0.7236972280452519 accuracy 0.8966431021690369 macro_avg {'precision': 0.9099562615528054, 'recall': 0.8971425652168501, 'f1-score': 0.9003812447732956, 'support': 1132} weighted_avg {'precision': 0.9065957347566731, 'recall': 0.8966431095406361, 'f1-score': 0.8980597728537396, 'support': 1132}
 
----------
Epoch 11/40
time = 423.15 secondes

Train loss 0.1337054156254373 accuracy 0.9744647741317749 macro_avg {'precision': 0.9735616431791406, 'recall': 0.9739405306619331, 'f1-score': 0.9737143635900004, 'support': 10182} weighted_avg {'precision': 0.974611701580378, 'recall': 0.974464741701041, 'f1-score': 0.9745064836709532, 'support': 10182}
 
time = 12.73 secondes

Val loss 0.6323745941065259 accuracy 0.9028268456459045 macro_avg {'precision': 0.9074312181979008, 'recall': 0.9007558814537223, 'f1-score': 0.9022479186062313, 'support': 1132} weighted_avg {'precision': 0.906429542585187, 'recall': 0.9028268551236749, 'f1-score': 0.902965433199013, 'support': 1132}
 
----------
Epoch 12/40
time = 430.32 secondes

Train loss 0.1023584950173296 accuracy 0.9795718193054199 macro_avg {'precision': 0.9791806644828369, 'recall': 0.9792535803811093, 'f1-score': 0.9792109710840297, 'support': 10182} weighted_avg {'precision': 0.9795779350193294, 'recall': 0.9795717933608329, 'f1-score': 0.9795693261126037, 'support': 10182}
 
time = 12.82 secondes

Val loss 0.6259938772061912 accuracy 0.9098939895629883 macro_avg {'precision': 0.9116068331010696, 'recall': 0.9121441645616958, 'f1-score': 0.9105564600009524, 'support': 1132} weighted_avg {'precision': 0.912659833756713, 'recall': 0.9098939929328622, 'f1-score': 0.9099748433918968, 'support': 1132}
 
----------
Epoch 13/40
time = 397.38 secondes

Train loss 0.1143082028901456 accuracy 0.9795718193054199 macro_avg {'precision': 0.9788124794785078, 'recall': 0.9790612730906897, 'f1-score': 0.978923249852539, 'support': 10182} weighted_avg {'precision': 0.9796261844106392, 'recall': 0.9795717933608329, 'f1-score': 0.9795876445999897, 'support': 10182}
 
time = 13.10 secondes

Val loss 0.7350068436005042 accuracy 0.8975265026092529 macro_avg {'precision': 0.9031281616681062, 'recall': 0.8971438544241377, 'f1-score': 0.8973649467259305, 'support': 1132} weighted_avg {'precision': 0.9000257003802029, 'recall': 0.8975265017667845, 'f1-score': 0.8963510036049379, 'support': 1132}
 
----------
Epoch 14/40
time = 442.70 secondes

Train loss 0.09813594200239087 accuracy 0.9813396334648132 macro_avg {'precision': 0.9806750650991777, 'recall': 0.9806106065210359, 'f1-score': 0.9806311500821968, 'support': 10182} weighted_avg {'precision': 0.9813607731786027, 'recall': 0.9813396189353761, 'f1-score': 0.9813382730965525, 'support': 10182}
 
time = 14.44 secondes

Val loss 0.7900260927474936 accuracy 0.898409903049469 macro_avg {'precision': 0.9048306313345928, 'recall': 0.9017453435070666, 'f1-score': 0.9003239498520962, 'support': 1132} weighted_avg {'precision': 0.9055264004353124, 'recall': 0.8984098939929329, 'f1-score': 0.8986787569339165, 'support': 1132}
 
----------
Epoch 15/40
time = 404.40 secondes

Train loss 0.11145889990820675 accuracy 0.9810450077056885 macro_avg {'precision': 0.980894516797268, 'recall': 0.9808296852544393, 'f1-score': 0.9808352043332249, 'support': 10182} weighted_avg {'precision': 0.9811005546971419, 'recall': 0.9810449813396189, 'f1-score': 0.9810459068878794, 'support': 10182}
 
time = 11.59 secondes

Val loss 0.7992025906837817 accuracy 0.9019434452056885 macro_avg {'precision': 0.9093172952966857, 'recall': 0.9030223193896859, 'f1-score': 0.9035790606790689, 'support': 1132} weighted_avg {'precision': 0.9078222526005729, 'recall': 0.9019434628975265, 'f1-score': 0.9023580713473868, 'support': 1132}
 
----------
Epoch 16/40
time = 421.62 secondes

Train loss 0.10440658425416628 accuracy 0.9808486104011536 macro_avg {'precision': 0.9798691219181386, 'recall': 0.9805059468632722, 'f1-score': 0.9801569037178097, 'support': 10182} weighted_avg {'precision': 0.9809187896595828, 'recall': 0.9808485562757808, 'f1-score': 0.9808582739697133, 'support': 10182}
 
time = 12.52 secondes

Val loss 0.7389955461098202 accuracy 0.8966431021690369 macro_avg {'precision': 0.9004655686083567, 'recall': 0.89773659470398, 'f1-score': 0.8971095925515616, 'support': 1132} weighted_avg {'precision': 0.9001583855840201, 'recall': 0.8966431095406361, 'f1-score': 0.8963617143793174, 'support': 1132}
 
----------
Epoch 17/40
time = 418.53 secondes

Train loss 0.08996801337670317 accuracy 0.9835003018379211 macro_avg {'precision': 0.9827848409089995, 'recall': 0.9826141169980962, 'f1-score': 0.9826890944494661, 'support': 10182} weighted_avg {'precision': 0.9834945721338348, 'recall': 0.9835002946375958, 'f1-score': 0.9834877082740924, 'support': 10182}
 
time = 12.32 secondes

Val loss 0.7066374074040115 accuracy 0.9107773900032043 macro_avg {'precision': 0.9157765213493677, 'recall': 0.9121100209334342, 'f1-score': 0.9125784332273875, 'support': 1132} weighted_avg {'precision': 0.9149100477845946, 'recall': 0.9107773851590106, 'f1-score': 0.9114034122834308, 'support': 1132}
 
----------
Epoch 18/40
time = 428.63 secondes

Train loss 0.08427978739800292 accuracy 0.9847770929336548 macro_avg {'precision': 0.9840003552191281, 'recall': 0.9839402070881164, 'f1-score': 0.9839576700590289, 'support': 10182} weighted_avg {'precision': 0.9847721191319977, 'recall': 0.9847770575525437, 'f1-score': 0.9847620563857246, 'support': 10182}
 
time = 10.95 secondes

Val loss 0.7500843799791486 accuracy 0.9081271886825562 macro_avg {'precision': 0.9134074902375465, 'recall': 0.9086413873873209, 'f1-score': 0.9089767630833373, 'support': 1132} weighted_avg {'precision': 0.9123747227306244, 'recall': 0.9081272084805654, 'f1-score': 0.9081996201140228, 'support': 1132}
 
----------
Epoch 19/40
time = 411.49 secondes

Train loss 0.08497951238823132 accuracy 0.985660970211029 macro_avg {'precision': 0.9851157347255859, 'recall': 0.9855665362914987, 'f1-score': 0.9853144724140614, 'support': 10182} weighted_avg {'precision': 0.9857341883142794, 'recall': 0.9856609703398154, 'f1-score': 0.985673944304285, 'support': 10182}
 
time = 11.25 secondes

Val loss 0.9273361888188216 accuracy 0.8869258165359497 macro_avg {'precision': 0.9029879610891067, 'recall': 0.8876237693884473, 'f1-score': 0.8899935215952063, 'support': 1132} weighted_avg {'precision': 0.8998368909422045, 'recall': 0.8869257950530035, 'f1-score': 0.8871632983298824, 'support': 1132}
 
----------
Epoch 20/40
time = 418.65 secondes

Train loss 0.07809646750437176 accuracy 0.9861520528793335 macro_avg {'precision': 0.9857269621544287, 'recall': 0.9855661646444037, 'f1-score': 0.9856295237175337, 'support': 10182} weighted_avg {'precision': 0.9861890783569941, 'recall': 0.9861520329994107, 'f1-score': 0.9861535198723276, 'support': 10182}
 
time = 12.68 secondes

Val loss 0.722247730458625 accuracy 0.9098939895629883 macro_avg {'precision': 0.917144096142812, 'recall': 0.915599447844837, 'f1-score': 0.9141903104108376, 'support': 1132} weighted_avg {'precision': 0.9160711872919659, 'recall': 0.9098939929328622, 'f1-score': 0.9106350857672734, 'support': 1132}
 
----------
Epoch 21/40
time = 408.32 secondes

Train loss 0.07467404359860146 accuracy 0.9870359897613525 macro_avg {'precision': 0.9867682507514768, 'recall': 0.9867150314448005, 'f1-score': 0.9867284640192432, 'support': 10182} weighted_avg {'precision': 0.9870710931957791, 'recall': 0.9870359457866824, 'f1-score': 0.9870405346671776, 'support': 10182}
 
time = 11.10 secondes

Val loss 0.7180338702928053 accuracy 0.9125441908836365 macro_avg {'precision': 0.9133334821298226, 'recall': 0.9152948596754227, 'f1-score': 0.9122003456428095, 'support': 1132} weighted_avg {'precision': 0.9157521607057607, 'recall': 0.9125441696113075, 'f1-score': 0.9119149032628736, 'support': 1132}
 
----------
Epoch 22/40
time = 402.96 secondes

Train loss 0.06478929906290512 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888038722666298, 'recall': 0.9885614233615909, 'f1-score': 0.9886677656744904, 'support': 10182} weighted_avg {'precision': 0.9889299453532019, 'recall': 0.9889019838931448, 'f1-score': 0.9889017233531, 'support': 10182}
 
time = 9.71 secondes

Val loss 0.8039091905748265 accuracy 0.9028268456459045 macro_avg {'precision': 0.911379396586331, 'recall': 0.9086362511731993, 'f1-score': 0.9055278072243329, 'support': 1132} weighted_avg {'precision': 0.9131956714231526, 'recall': 0.9028268551236749, 'f1-score': 0.9031382706894061, 'support': 1132}
 
----------
Epoch 23/40
time = 307.14 secondes

Train loss 0.07572478385792442 accuracy 0.9877234697341919 macro_avg {'precision': 0.9876870603793177, 'recall': 0.9876794140325146, 'f1-score': 0.9876506652659159, 'support': 10182} weighted_avg {'precision': 0.9878244292235241, 'recall': 0.9877234335101159, 'f1-score': 0.9877411389883464, 'support': 10182}
 
time = 10.33 secondes

Val loss 0.6903284197234799 accuracy 0.9107773900032043 macro_avg {'precision': 0.917567114508938, 'recall': 0.914802882340692, 'f1-score': 0.9135820177675322, 'support': 1132} weighted_avg {'precision': 0.9186626031691789, 'recall': 0.9107773851590106, 'f1-score': 0.9121404095781659, 'support': 1132}
 
----------
Epoch 24/40
time = 329.38 secondes

Train loss 0.06450561216409154 accuracy 0.9891966581344604 macro_avg {'precision': 0.988899514584395, 'recall': 0.9891949256485072, 'f1-score': 0.9890315712521845, 'support': 10182} weighted_avg {'precision': 0.9892346122554989, 'recall': 0.989196621488902, 'f1-score': 0.9892015337458244, 'support': 10182}
 
time = 10.04 secondes

Val loss 0.7212912622716443 accuracy 0.9116607904434204 macro_avg {'precision': 0.9172984907645987, 'recall': 0.9153289361821961, 'f1-score': 0.9138724106621747, 'support': 1132} weighted_avg {'precision': 0.9176888191935005, 'recall': 0.911660777385159, 'f1-score': 0.9122275304787509, 'support': 1132}
 
----------
Epoch 25/40
time = 308.95 secondes

Train loss 0.06708124603503574 accuracy 0.9890984296798706 macro_avg {'precision': 0.9889837157255682, 'recall': 0.9889354149726742, 'f1-score': 0.988925971172832, 'support': 10182} weighted_avg {'precision': 0.98920047980825, 'recall': 0.9890984089569829, 'f1-score': 0.9891157084071291, 'support': 10182}
 
time = 10.40 secondes

Val loss 0.7821798086068823 accuracy 0.9063604474067688 macro_avg {'precision': 0.9102889156579049, 'recall': 0.9085779961111446, 'f1-score': 0.9078282137759193, 'support': 1132} weighted_avg {'precision': 0.9102464363658855, 'recall': 0.9063604240282686, 'f1-score': 0.9066999661641374, 'support': 1132}
 
----------
Epoch 26/40
time = 334.99 secondes

Train loss 0.059719651531013426 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901144190725599, 'recall': 0.9900555722755475, 'f1-score': 0.990072226071695, 'support': 10182} weighted_avg {'precision': 0.9903377133949278, 'recall': 0.9902769593400118, 'f1-score': 0.990294064327027, 'support': 10182}
 
time = 10.34 secondes

Val loss 0.8507461062439637 accuracy 0.9019434452056885 macro_avg {'precision': 0.9041006705851616, 'recall': 0.9048829951850109, 'f1-score': 0.9032091138935294, 'support': 1132} weighted_avg {'precision': 0.9048160141929199, 'recall': 0.9019434628975265, 'f1-score': 0.9022105042337575, 'support': 1132}
 
----------
Epoch 27/40
time = 338.12 secondes

Train loss 0.04990207875736095 accuracy 0.9921430349349976 macro_avg {'precision': 0.9919416580763132, 'recall': 0.9919873074531784, 'f1-score': 0.9919597821306508, 'support': 10182} weighted_avg {'precision': 0.9921558156616062, 'recall': 0.9921429974464742, 'f1-score': 0.9921447476180375, 'support': 10182}
 
time = 10.39 secondes

Val loss 0.8220755069544883 accuracy 0.9037102460861206 macro_avg {'precision': 0.9095335417009747, 'recall': 0.9025996732578687, 'f1-score': 0.9042176125895927, 'support': 1132} weighted_avg {'precision': 0.908281263608202, 'recall': 0.9037102473498233, 'f1-score': 0.9040629531112894, 'support': 1132}
 
----------
Epoch 28/40
time = 317.29 secondes

Train loss 0.0663954652151331 accuracy 0.9904733896255493 macro_avg {'precision': 0.9895774285515146, 'recall': 0.9897899501197422, 'f1-score': 0.9896488037435163, 'support': 10182} weighted_avg {'precision': 0.9905539313833231, 'recall': 0.9904733844038499, 'f1-score': 0.9904804049288549, 'support': 10182}
 
time = 8.03 secondes

Val loss 0.7162565783724397 accuracy 0.9196113348007202 macro_avg {'precision': 0.9187601788032358, 'recall': 0.9195260663498706, 'f1-score': 0.9180761907672581, 'support': 1132} weighted_avg {'precision': 0.9207281596723476, 'recall': 0.9196113074204947, 'f1-score': 0.9191473840995076, 'support': 1132}
 
----------
Epoch 29/40
time = 307.91 secondes

Train loss 0.04059086503027461 accuracy 0.9930269122123718 macro_avg {'precision': 0.9925670854723581, 'recall': 0.9927167346052114, 'f1-score': 0.9926272063115512, 'support': 10182} weighted_avg {'precision': 0.9930552120686112, 'recall': 0.9930269102337458, 'f1-score': 0.9930284269781219, 'support': 10182}
 
time = 10.65 secondes

Val loss 0.706465455843935 accuracy 0.9143109321594238 macro_avg {'precision': 0.9149697942909573, 'recall': 0.9184096142999966, 'f1-score': 0.9153793656351807, 'support': 1132} weighted_avg {'precision': 0.9169750514163649, 'recall': 0.9143109540636042, 'f1-score': 0.9143225132593404, 'support': 1132}
 
----------
Epoch 30/40
time = 296.60 secondes

Train loss 0.027977638044020134 accuracy 0.9954822659492493 macro_avg {'precision': 0.9953157136769123, 'recall': 0.9953131977244756, 'f1-score': 0.9953055224206404, 'support': 10182} weighted_avg {'precision': 0.9954962153528318, 'recall': 0.9954822235317227, 'f1-score': 0.9954802846682627, 'support': 10182}
 
time = 8.04 secondes

Val loss 0.7825092716469646 accuracy 0.9107773900032043 macro_avg {'precision': 0.9142359284768053, 'recall': 0.9155555931914995, 'f1-score': 0.9131304583068877, 'support': 1132} weighted_avg {'precision': 0.9153674513654004, 'recall': 0.9107773851590106, 'f1-score': 0.9112660298856434, 'support': 1132}
 
----------
Epoch 31/40
time = 292.70 secondes

Train loss 0.03686146650539209 accuracy 0.9929287433624268 macro_avg {'precision': 0.9921378042896339, 'recall': 0.9925293015835326, 'f1-score': 0.992303869580564, 'support': 10182} weighted_avg {'precision': 0.9929820066751044, 'recall': 0.9929286977018268, 'f1-score': 0.9929317500401419, 'support': 10182}
 
time = 7.90 secondes

Val loss 0.711872795763451 accuracy 0.9187279343605042 macro_avg {'precision': 0.9221666221275185, 'recall': 0.9205913315865557, 'f1-score': 0.9198334273980173, 'support': 1132} weighted_avg {'precision': 0.9221143154425232, 'recall': 0.9187279151943463, 'f1-score': 0.9187882723136276, 'support': 1132}
 
----------
Epoch 32/40
time = 280.71 secondes

Train loss 0.02746521234741116 accuracy 0.9953840374946594 macro_avg {'precision': 0.995133299226025, 'recall': 0.9951308959815763, 'f1-score': 0.9951267083315397, 'support': 10182} weighted_avg {'precision': 0.9953967623224463, 'recall': 0.9953840109998036, 'f1-score': 0.9953852907654042, 'support': 10182}
 
time = 7.86 secondes

Val loss 0.8069455720996955 accuracy 0.9116607904434204 macro_avg {'precision': 0.9125715566774968, 'recall': 0.9158725743751722, 'f1-score': 0.9118011144847182, 'support': 1132} weighted_avg {'precision': 0.9169377210144425, 'recall': 0.911660777385159, 'f1-score': 0.9120646533457887, 'support': 1132}
 
----------
Epoch 33/40
time = 285.50 secondes

Train loss 0.027775616851617734 accuracy 0.9950894117355347 macro_avg {'precision': 0.9948285478293164, 'recall': 0.9949035795623227, 'f1-score': 0.994862261179686, 'support': 10182} weighted_avg {'precision': 0.9951005618570411, 'recall': 0.9950893734040464, 'f1-score': 0.9950914503264409, 'support': 10182}
 
time = 8.67 secondes

Val loss 0.7558389602166078 accuracy 0.916961133480072 macro_avg {'precision': 0.9195302686767495, 'recall': 0.9210061981316884, 'f1-score': 0.9184899689463981, 'support': 1132} weighted_avg {'precision': 0.9227016441153024, 'recall': 0.9169611307420494, 'f1-score': 0.9181124505052021, 'support': 1132}
 
----------
Epoch 34/40
time = 285.37 secondes

Train loss 0.02778516562054051 accuracy 0.995776891708374 macro_avg {'precision': 0.9954843399652635, 'recall': 0.9954829575525096, 'f1-score': 0.9954769365467702, 'support': 10182} weighted_avg {'precision': 0.9957837646517178, 'recall': 0.9957768611274799, 'f1-score': 0.9957737896030247, 'support': 10182}
 
time = 8.00 secondes

Val loss 0.7847715615677425 accuracy 0.9187279343605042 macro_avg {'precision': 0.9217913016109309, 'recall': 0.9210838076803286, 'f1-score': 0.9200446178342337, 'support': 1132} weighted_avg {'precision': 0.9217469247550432, 'recall': 0.9187279151943463, 'f1-score': 0.918759825244848, 'support': 1132}
 
----------
Epoch 35/40
time = 288.13 secondes

Train loss 0.022826091056206962 accuracy 0.9963661432266235 macro_avg {'precision': 0.996458026696995, 'recall': 0.9963377716028416, 'f1-score': 0.9963933626950847, 'support': 10182} weighted_avg {'precision': 0.9963763650850772, 'recall': 0.9963661363189943, 'f1-score': 0.9963666003610481, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.7679374363633799 accuracy 0.9204947352409363 macro_avg {'precision': 0.9225280347503185, 'recall': 0.9239871218910434, 'f1-score': 0.9214151904214702, 'support': 1132} weighted_avg {'precision': 0.924327377343171, 'recall': 0.9204946996466431, 'f1-score': 0.9205313326889099, 'support': 1132}
 
----------
Epoch 36/40
time = 287.46 secondes

Train loss 0.018142695244357444 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967679585525511, 'recall': 0.9967271873267508, 'f1-score': 0.9967452793521613, 'support': 10182} weighted_avg {'precision': 0.9967638259998332, 'recall': 0.9967589864466706, 'f1-score': 0.9967590703654247, 'support': 10182}
 
time = 8.49 secondes

Val loss 0.761858034702809 accuracy 0.9196113348007202 macro_avg {'precision': 0.9186531367518572, 'recall': 0.9224562970109094, 'f1-score': 0.9192263589820884, 'support': 1132} weighted_avg {'precision': 0.9230442542043331, 'recall': 0.9196113074204947, 'f1-score': 0.920024124584787, 'support': 1132}
 
----------
Epoch 37/40
time = 287.93 secondes

Train loss 0.01815121970660012 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974447130194019, 'recall': 0.9974233089452775, 'f1-score': 0.9974319411371747, 'support': 10182} weighted_avg {'precision': 0.9973505900561392, 'recall': 0.997348261638185, 'f1-score': 0.9973472903722584, 'support': 10182}
 
time = 8.44 secondes

Val loss 0.7533902160066646 accuracy 0.9204947352409363 macro_avg {'precision': 0.9237860892229335, 'recall': 0.9238759178520809, 'f1-score': 0.9218351883973682, 'support': 1132} weighted_avg {'precision': 0.9253167733775467, 'recall': 0.9204946996466431, 'f1-score': 0.9207456977204976, 'support': 1132}
 
----------
Epoch 38/40
time = 282.01 secondes

Train loss 0.006924396099478414 accuracy 0.998919665813446 macro_avg {'precision': 0.9989388564492676, 'recall': 0.9989403128091618, 'f1-score': 0.9989384844270817, 'support': 10182} weighted_avg {'precision': 0.9989217262292749, 'recall': 0.9989196621488902, 'f1-score': 0.998919568440116, 'support': 10182}
 
time = 8.43 secondes

Val loss 0.7545767329339328 accuracy 0.9222614765167236 macro_avg {'precision': 0.9254649541538227, 'recall': 0.925174469276584, 'f1-score': 0.9238377104629576, 'support': 1132} weighted_avg {'precision': 0.9264974009742808, 'recall': 0.9222614840989399, 'f1-score': 0.9227863833075717, 'support': 1132}
 
----------
Epoch 39/40
time = 288.66 secondes

Train loss 0.005710802699696776 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991570206615412, 'recall': 0.9991604609937763, 'f1-score': 0.9991580357507196, 'support': 10182} weighted_avg {'precision': 0.9991179346647294, 'recall': 0.9991160872127284, 'f1-score': 0.9991162741392261, 'support': 10182}
 
time = 8.47 secondes

Val loss 0.7573551383191213 accuracy 0.9204947352409363 macro_avg {'precision': 0.9237733347868342, 'recall': 0.92323656511568, 'f1-score': 0.9218597605883163, 'support': 1132} weighted_avg {'precision': 0.9243948136286163, 'recall': 0.9204946996466431, 'f1-score': 0.9206883332255212, 'support': 1132}
 
----------
Epoch 40/40
time = 286.94 secondes

Train loss 0.002404931281296803 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995302155591693, 'recall': 0.9995314463873919, 'f1-score': 0.9995306550741742, 'support': 10182} weighted_avg {'precision': 0.9995096737532518, 'recall': 0.9995089373404047, 'f1-score': 0.9995091215209401, 'support': 10182}
 
time = 7.89 secondes

Val loss 0.7392247663198798 accuracy 0.9249116778373718 macro_avg {'precision': 0.92752556227979, 'recall': 0.9279602441972715, 'f1-score': 0.9261728788626312, 'support': 1132} weighted_avg {'precision': 0.9282610270359913, 'recall': 0.9249116607773852, 'f1-score': 0.9248788202226942, 'support': 1132}
 
----------
best_accuracy 0.9249116778373718 best_epoch 40 macro_avg {'precision': 0.92752556227979, 'recall': 0.9279602441972715, 'f1-score': 0.9261728788626312, 'support': 1132} weighted_avg {'precision': 0.9282610270359913, 'recall': 0.9249116607773852, 'f1-score': 0.9248788202226942, 'support': 1132}

average train time 365.7174861371517

average val time 10.790838772058487
 
time = 52.47 secondes

test_accuracy 0.859134316444397 macro_avg {'precision': 0.8562653319593105, 'recall': 0.8525251481381513, 'f1-score': 0.8531800539530116, 'support': 7532} weighted_avg {'precision': 0.8622653371974954, 'recall': 0.8591343600637281, 'f1-score': 0.859578553211578, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_1
----------
Epoch 1/40
time = 282.51 secondes

Train loss 1.2969225725068403 accuracy 0.6692202091217041 macro_avg {'precision': 0.6990079037542414, 'recall': 0.6534471806001798, 'f1-score': 0.6495730201165426, 'support': 10182} weighted_avg {'precision': 0.7018961837926238, 'recall': 0.6692201924965626, 'f1-score': 0.6637489895298871, 'support': 10182}
 
time = 8.22 secondes

Val loss 0.6178673115414632 accuracy 0.8206713795661926 macro_avg {'precision': 0.8180025895695723, 'recall': 0.8132090336357443, 'f1-score': 0.7973686024587369, 'support': 1132} weighted_avg {'precision': 0.8168879723560828, 'recall': 0.8206713780918727, 'f1-score': 0.8035988661015144, 'support': 1132}
 
----------
Epoch 2/40
time = 278.35 secondes

Train loss 0.43287296337038983 accuracy 0.870163083076477 macro_avg {'precision': 0.8593323516013482, 'recall': 0.8581438199941772, 'f1-score': 0.8560909377648411, 'support': 10182} weighted_avg {'precision': 0.8674271400457985, 'recall': 0.8701630328029857, 'f1-score': 0.8668213425966006, 'support': 10182}
 
time = 8.04 secondes

Val loss 0.4601481613034094 accuracy 0.8763250708580017 macro_avg {'precision': 0.8751388073705737, 'recall': 0.8725547000375565, 'f1-score': 0.8688971065241751, 'support': 1132} weighted_avg {'precision': 0.8838287537290427, 'recall': 0.8763250883392226, 'f1-score': 0.8750101670016845, 'support': 1132}
 
----------
Epoch 3/40
time = 278.46 secondes

Train loss 0.26217240974997147 accuracy 0.9253584742546082 macro_avg {'precision': 0.9211883244475387, 'recall': 0.9202240927294902, 'f1-score': 0.9204804635106821, 'support': 10182} weighted_avg {'precision': 0.9258842414756532, 'recall': 0.9253584757415046, 'f1-score': 0.925407681030135, 'support': 10182}
 
time = 8.05 secondes

Val loss 0.5054485964733111 accuracy 0.8869258165359497 macro_avg {'precision': 0.8906360125970492, 'recall': 0.885429360424995, 'f1-score': 0.8841697835498337, 'support': 1132} weighted_avg {'precision': 0.8938782296690212, 'recall': 0.8869257950530035, 'f1-score': 0.8863795429178036, 'support': 1132}
 
----------
Epoch 4/40
time = 278.20 secondes

Train loss 0.2040974411494252 accuracy 0.9463759660720825 macro_avg {'precision': 0.9436006079897181, 'recall': 0.9430226435133227, 'f1-score': 0.9432225488759753, 'support': 10182} weighted_avg {'precision': 0.9464522606650345, 'recall': 0.9463759575721862, 'f1-score': 0.9463258945771914, 'support': 10182}
 
time = 7.39 secondes

Val loss 0.5345468768410542 accuracy 0.8913427591323853 macro_avg {'precision': 0.8998024765460169, 'recall': 0.8887086598106686, 'f1-score': 0.8908884937853816, 'support': 1132} weighted_avg {'precision': 0.8993290258802021, 'recall': 0.8913427561837456, 'f1-score': 0.8917947131128191, 'support': 1132}
 
----------
Epoch 5/40
time = 273.05 secondes

Train loss 0.18042696977244013 accuracy 0.9554115533828735 macro_avg {'precision': 0.9533120782824595, 'recall': 0.9532953259992011, 'f1-score': 0.9532134200801881, 'support': 10182} weighted_avg {'precision': 0.9556418219114741, 'recall': 0.955411510508741, 'f1-score': 0.955442495315768, 'support': 10182}
 
time = 7.94 secondes

Val loss 0.5283677883111727 accuracy 0.9028268456459045 macro_avg {'precision': 0.9120457401838495, 'recall': 0.9011717820906995, 'f1-score': 0.9027467161553304, 'support': 1132} weighted_avg {'precision': 0.9111654488900206, 'recall': 0.9028268551236749, 'f1-score': 0.9031471993329789, 'support': 1132}
 
----------
Epoch 6/40
time = 276.17 secondes

Train loss 0.15092985576740212 accuracy 0.9639560580253601 macro_avg {'precision': 0.9620543535575384, 'recall': 0.9618851244170736, 'f1-score': 0.9619422201492736, 'support': 10182} weighted_avg {'precision': 0.9639726677276419, 'recall': 0.9639560007857002, 'f1-score': 0.9639369089396777, 'support': 10182}
 
time = 8.45 secondes

Val loss 0.5068440955266698 accuracy 0.9090105891227722 macro_avg {'precision': 0.9118756341578689, 'recall': 0.9116267313428714, 'f1-score': 0.908405893727576, 'support': 1132} weighted_avg {'precision': 0.9132677887981405, 'recall': 0.9090106007067138, 'f1-score': 0.9074163661473658, 'support': 1132}
 
----------
Epoch 7/40
time = 275.76 secondes

Train loss 0.13024573340298157 accuracy 0.9691612720489502 macro_avg {'precision': 0.9682382257381181, 'recall': 0.9681045301445256, 'f1-score': 0.9681525900481149, 'support': 10182} weighted_avg {'precision': 0.9692467336587892, 'recall': 0.9691612649774111, 'f1-score': 0.9691849403511996, 'support': 10182}
 
time = 8.03 secondes

Val loss 0.6511972284192075 accuracy 0.8939929604530334 macro_avg {'precision': 0.9000090825197397, 'recall': 0.8957913176286635, 'f1-score': 0.8944776087809444, 'support': 1132} weighted_avg {'precision': 0.9014855496702763, 'recall': 0.8939929328621908, 'f1-score': 0.8943356226260927, 'support': 1132}
 
----------
Epoch 8/40
time = 278.58 secondes

Train loss 0.13233596566427439 accuracy 0.9695541262626648 macro_avg {'precision': 0.9685622920463072, 'recall': 0.9688176156067927, 'f1-score': 0.9686564907468076, 'support': 10182} weighted_avg {'precision': 0.9696769955615074, 'recall': 0.9695541151050874, 'f1-score': 0.9695833155534213, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.5798353873030119 accuracy 0.916077733039856 macro_avg {'precision': 0.9182947787854001, 'recall': 0.9174683180571899, 'f1-score': 0.9166386904635209, 'support': 1132} weighted_avg {'precision': 0.9185721983160794, 'recall': 0.916077738515901, 'f1-score': 0.916079546230566, 'support': 1132}
 
----------
Epoch 9/40
time = 276.17 secondes

Train loss 0.1284933209826704 accuracy 0.9731879830360413 macro_avg {'precision': 0.972637354566201, 'recall': 0.9720897696547249, 'f1-score': 0.9723121054175385, 'support': 10182} weighted_avg {'precision': 0.9732866582744839, 'recall': 0.9731879787860931, 'f1-score': 0.9731872923138465, 'support': 10182}
 
time = 7.91 secondes

Val loss 0.6442373096696954 accuracy 0.9063604474067688 macro_avg {'precision': 0.914805198683364, 'recall': 0.9110562710795488, 'f1-score': 0.9092146528387973, 'support': 1132} weighted_avg {'precision': 0.9164290509626355, 'recall': 0.9063604240282686, 'f1-score': 0.9075132821959441, 'support': 1132}
 
----------
Epoch 10/40
time = 277.03 secondes

Train loss 0.12729776118053387 accuracy 0.9749558568000793 macro_avg {'precision': 0.974829233945357, 'recall': 0.9748346058245311, 'f1-score': 0.9747889587102412, 'support': 10182} weighted_avg {'precision': 0.9751713110593954, 'recall': 0.9749558043606364, 'f1-score': 0.9750203664585398, 'support': 10182}
 
time = 7.95 secondes

Val loss 0.5735039518843569 accuracy 0.9134275913238525 macro_avg {'precision': 0.9188955457104205, 'recall': 0.9161372294001954, 'f1-score': 0.9145900748750113, 'support': 1132} weighted_avg {'precision': 0.9197264540498687, 'recall': 0.9134275618374559, 'f1-score': 0.913835060136854, 'support': 1132}
 
----------
Epoch 11/40
time = 278.07 secondes

Train loss 0.10826633382705862 accuracy 0.9789825677871704 macro_avg {'precision': 0.9785296418138592, 'recall': 0.978368673487122, 'f1-score': 0.9784300858383087, 'support': 10182} weighted_avg {'precision': 0.9790419137821442, 'recall': 0.9789825181693184, 'f1-score': 0.9789926848103273, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.6482050937609042 accuracy 0.9054770469665527 macro_avg {'precision': 0.911982342897376, 'recall': 0.905555224800532, 'f1-score': 0.9064187338062382, 'support': 1132} weighted_avg {'precision': 0.9105111744587654, 'recall': 0.9054770318021201, 'f1-score': 0.9055486138005372, 'support': 1132}
 
----------
Epoch 12/40
time = 276.53 secondes

Train loss 0.11111807597717845 accuracy 0.9795718193054199 macro_avg {'precision': 0.9791531399514751, 'recall': 0.9790872466974763, 'f1-score': 0.9790967541785024, 'support': 10182} weighted_avg {'precision': 0.9795850429843089, 'recall': 0.9795717933608329, 'f1-score': 0.9795550578083141, 'support': 10182}
 
time = 8.15 secondes

Val loss 0.606417962436443 accuracy 0.9178445339202881 macro_avg {'precision': 0.9218851499274692, 'recall': 0.917685445065082, 'f1-score': 0.9172825702863017, 'support': 1132} weighted_avg {'precision': 0.9219304912782988, 'recall': 0.9178445229681979, 'f1-score': 0.9174676971053674, 'support': 1132}
 
----------
Epoch 13/40
time = 276.23 secondes

Train loss 0.09951441914762507 accuracy 0.9812414646148682 macro_avg {'precision': 0.9807861875696993, 'recall': 0.9809883071182307, 'f1-score': 0.980846854626255, 'support': 10182} weighted_avg {'precision': 0.9813090406530367, 'recall': 0.981241406403457, 'f1-score': 0.9812335700031785, 'support': 10182}
 
time = 8.12 secondes

Val loss 0.700744904714643 accuracy 0.898409903049469 macro_avg {'precision': 0.9053115225987314, 'recall': 0.9020293427207839, 'f1-score': 0.9005037571768131, 'support': 1132} weighted_avg {'precision': 0.9051306774082327, 'recall': 0.8984098939929329, 'f1-score': 0.8983736730691763, 'support': 1132}
 
----------
Epoch 14/40
time = 277.41 secondes

Train loss 0.11177746440768987 accuracy 0.9798664450645447 macro_avg {'precision': 0.9793228144295754, 'recall': 0.9790438808494251, 'f1-score': 0.979144865857784, 'support': 10182} weighted_avg {'precision': 0.9799281806376431, 'recall': 0.9798664309565901, 'f1-score': 0.9798584321500692, 'support': 10182}
 
time = 9.16 secondes

Val loss 0.7096648611645641 accuracy 0.9037102460861206 macro_avg {'precision': 0.9107445639602672, 'recall': 0.9032734710598229, 'f1-score': 0.8996949395414584, 'support': 1132} weighted_avg {'precision': 0.9129325140207863, 'recall': 0.9037102473498233, 'f1-score': 0.9014940019226564, 'support': 1132}
 
----------
Epoch 15/40
time = 276.78 secondes

Train loss 0.09621515293603158 accuracy 0.9826164245605469 macro_avg {'precision': 0.9827492474722369, 'recall': 0.9823664677139595, 'f1-score': 0.9825126970820355, 'support': 10182} weighted_avg {'precision': 0.9827157192688305, 'recall': 0.9826163818503241, 'f1-score': 0.9826214830801505, 'support': 10182}
 
time = 7.93 secondes

Val loss 0.6212482714427481 accuracy 0.9107773900032043 macro_avg {'precision': 0.9137949365647504, 'recall': 0.913794636022074, 'f1-score': 0.912357163033273, 'support': 1132} weighted_avg {'precision': 0.9145403151859808, 'recall': 0.9107773851590106, 'f1-score': 0.911079195720957, 'support': 1132}
 
----------
Epoch 16/40
time = 276.74 secondes

Train loss 0.08711102321256739 accuracy 0.9828128218650818 macro_avg {'precision': 0.9822507437564957, 'recall': 0.982461266133311, 'f1-score': 0.9823149839566699, 'support': 10182} weighted_avg {'precision': 0.982925790167422, 'recall': 0.9828128069141623, 'f1-score': 0.9828283495286941, 'support': 10182}
 
time = 7.90 secondes

Val loss 0.6189469953629592 accuracy 0.9134275913238525 macro_avg {'precision': 0.9214656296456143, 'recall': 0.9149000134126306, 'f1-score': 0.915510566069836, 'support': 1132} weighted_avg {'precision': 0.9218422398714707, 'recall': 0.9134275618374559, 'f1-score': 0.9148488799201079, 'support': 1132}
 
----------
Epoch 17/40
time = 276.65 secondes

Train loss 0.07653720192004926 accuracy 0.9868395328521729 macro_avg {'precision': 0.986335937631433, 'recall': 0.9865686784279211, 'f1-score': 0.9864338856572035, 'support': 10182} weighted_avg {'precision': 0.9868764497237001, 'recall': 0.9868395207228442, 'f1-score': 0.9868408422554503, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.6496887775959896 accuracy 0.916961133480072 macro_avg {'precision': 0.9218854677920026, 'recall': 0.9182034315680256, 'f1-score': 0.9185467993501388, 'support': 1132} weighted_avg {'precision': 0.9208989934272178, 'recall': 0.9169611307420494, 'f1-score': 0.9173851252420903, 'support': 1132}
 
----------
Epoch 18/40
time = 277.85 secondes

Train loss 0.08329746264323236 accuracy 0.9850717186927795 macro_avg {'precision': 0.9847547011273299, 'recall': 0.984545426569535, 'f1-score': 0.9846384890704151, 'support': 10182} weighted_avg {'precision': 0.9850904587766539, 'recall': 0.985071695148301, 'f1-score': 0.9850702145622141, 'support': 10182}
 
time = 8.01 secondes

Val loss 0.7388151137065634 accuracy 0.9019434452056885 macro_avg {'precision': 0.9131106861508231, 'recall': 0.9058074432514344, 'f1-score': 0.9051807702184472, 'support': 1132} weighted_avg {'precision': 0.9140085359523877, 'recall': 0.9019434628975265, 'f1-score': 0.9035035325905527, 'support': 1132}
 
----------
Epoch 19/40
time = 259.43 secondes

Train loss 0.08043676043952769 accuracy 0.9851699471473694 macro_avg {'precision': 0.9852921131905108, 'recall': 0.985128176156312, 'f1-score': 0.9851929257355639, 'support': 10182} weighted_avg {'precision': 0.9852060153914801, 'recall': 0.98516990768022, 'f1-score': 0.9851705171674839, 'support': 10182}
 
time = 6.62 secondes

Val loss 0.6403847297015731 accuracy 0.9187279343605042 macro_avg {'precision': 0.922835709375169, 'recall': 0.9202783779932883, 'f1-score': 0.9193975160453801, 'support': 1132} weighted_avg {'precision': 0.9225463254406191, 'recall': 0.9187279151943463, 'f1-score': 0.9185865801565549, 'support': 1132}
 
----------
Epoch 20/40
time = 249.04 secondes

Train loss 0.07639693613235173 accuracy 0.9858574271202087 macro_avg {'precision': 0.9854707410254091, 'recall': 0.9857115512380854, 'f1-score': 0.9855770257916084, 'support': 10182} weighted_avg {'precision': 0.9858795011519844, 'recall': 0.9858573954036535, 'f1-score': 0.9858541613654894, 'support': 10182}
 
time = 6.70 secondes

Val loss 0.6247407759470712 accuracy 0.9204947352409363 macro_avg {'precision': 0.9228481696936566, 'recall': 0.9238933835370219, 'f1-score': 0.922328106010937, 'support': 1132} weighted_avg {'precision': 0.9242663140749322, 'recall': 0.9204946996466431, 'f1-score': 0.9213075272651952, 'support': 1132}
 
----------
Epoch 21/40
time = 246.69 secondes

Train loss 0.0670055868588631 accuracy 0.9874288439750671 macro_avg {'precision': 0.9871158506329394, 'recall': 0.987127204069437, 'f1-score': 0.9871137597713979, 'support': 10182} weighted_avg {'precision': 0.9874511542273045, 'recall': 0.9874287959143587, 'f1-score': 0.9874319696408839, 'support': 10182}
 
time = 6.64 secondes

Val loss 0.6709432864730152 accuracy 0.916077733039856 macro_avg {'precision': 0.9202661065749137, 'recall': 0.9187784119959235, 'f1-score': 0.9169813715343992, 'support': 1132} weighted_avg {'precision': 0.9216459854112578, 'recall': 0.916077738515901, 'f1-score': 0.9161554312720206, 'support': 1132}
 
----------
Epoch 22/40
time = 244.28 secondes

Train loss 0.06566958932033194 accuracy 0.988705575466156 macro_avg {'precision': 0.9885484540546919, 'recall': 0.9883169901327031, 'f1-score': 0.9884182754509011, 'support': 10182} weighted_avg {'precision': 0.9887191900613386, 'recall': 0.9887055588293067, 'f1-score': 0.9886985008371292, 'support': 10182}
 
time = 6.68 secondes

Val loss 0.62728135015067 accuracy 0.9302120208740234 macro_avg {'precision': 0.9320884931441593, 'recall': 0.9323260951051313, 'f1-score': 0.9307558784882032, 'support': 1132} weighted_avg {'precision': 0.9324174270998004, 'recall': 0.9302120141342756, 'f1-score': 0.9300587795105631, 'support': 1132}
 
----------
Epoch 23/40
time = 246.13 secondes

Train loss 0.0673306532131403 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888248898156748, 'recall': 0.9885946940693854, 'f1-score': 0.9886987597691703, 'support': 10182} weighted_avg {'precision': 0.9889094470375808, 'recall': 0.9889019838931448, 'f1-score': 0.9888954045588377, 'support': 10182}
 
time = 6.65 secondes

Val loss 0.6457620063639028 accuracy 0.9231448769569397 macro_avg {'precision': 0.9244918901641535, 'recall': 0.9249520807785909, 'f1-score': 0.9235676107084482, 'support': 1132} weighted_avg {'precision': 0.9269682006153632, 'recall': 0.9231448763250883, 'f1-score': 0.923856983465547, 'support': 1132}
 
----------
Epoch 24/40
time = 245.50 secondes

Train loss 0.04982319941605177 accuracy 0.9919465780258179 macro_avg {'precision': 0.9917939863670222, 'recall': 0.991717279591455, 'f1-score': 0.991748650716674, 'support': 10182} weighted_avg {'precision': 0.9919582560226016, 'recall': 0.9919465723826361, 'f1-score': 0.9919455705164054, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.6959070718767693 accuracy 0.9231448769569397 macro_avg {'precision': 0.9245436725674414, 'recall': 0.9259463173474497, 'f1-score': 0.923002765277394, 'support': 1132} weighted_avg {'precision': 0.9279284793361886, 'recall': 0.9231448763250883, 'f1-score': 0.9231571272308379, 'support': 1132}
 
----------
Epoch 25/40
time = 242.18 secondes

Train loss 0.06086601543379052 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901722636167941, 'recall': 0.9901398679269005, 'f1-score': 0.9901495225125514, 'support': 10182} weighted_avg {'precision': 0.9902883245752778, 'recall': 0.9902769593400118, 'f1-score': 0.9902761349915682, 'support': 10182}
 
time = 6.92 secondes

Val loss 0.6742879799433942 accuracy 0.9213780760765076 macro_avg {'precision': 0.9229381548093084, 'recall': 0.9237796000673366, 'f1-score': 0.921495652061276, 'support': 1132} weighted_avg {'precision': 0.925560043523906, 'recall': 0.9213780918727915, 'f1-score': 0.9216329519121286, 'support': 1132}
 
----------
Epoch 26/40
time = 248.88 secondes

Train loss 0.05257549030542423 accuracy 0.9911609292030334 macro_avg {'precision': 0.9910808696366289, 'recall': 0.9907821237032659, 'f1-score': 0.990917560655477, 'support': 10182} weighted_avg {'precision': 0.9911853547338669, 'recall': 0.9911608721272834, 'f1-score': 0.9911604214623788, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.6751866810035877 accuracy 0.9151943325996399 macro_avg {'precision': 0.9204335979635427, 'recall': 0.913816346274908, 'f1-score': 0.914417670237364, 'support': 1132} weighted_avg {'precision': 0.9203468050998197, 'recall': 0.9151943462897526, 'f1-score': 0.9151313291509376, 'support': 1132}
 
----------
Epoch 27/40
time = 239.21 secondes

Train loss 0.06064851889485233 accuracy 0.9901787638664246 macro_avg {'precision': 0.9899742752190566, 'recall': 0.9897346399647091, 'f1-score': 0.9898260791355534, 'support': 10182} weighted_avg {'precision': 0.9902250967427191, 'recall': 0.9901787468080927, 'f1-score': 0.9901776530597283, 'support': 10182}
 
time = 7.17 secondes

Val loss 0.7237941757705133 accuracy 0.9178445339202881 macro_avg {'precision': 0.9205575565857375, 'recall': 0.9187402667648943, 'f1-score': 0.9174021823579913, 'support': 1132} weighted_avg {'precision': 0.9233718497528121, 'recall': 0.9178445229681979, 'f1-score': 0.9183701700479246, 'support': 1132}
 
----------
Epoch 28/40
time = 244.59 secondes

Train loss 0.0473941769001781 accuracy 0.990669846534729 macro_avg {'precision': 0.9898383814615282, 'recall': 0.9894486745800408, 'f1-score': 0.9896052654288207, 'support': 10182} weighted_avg {'precision': 0.9906931154089333, 'recall': 0.9906698094676881, 'f1-score': 0.9906520407787675, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.618527801582056 accuracy 0.9275618195533752 macro_avg {'precision': 0.9309836575794439, 'recall': 0.9269788173553521, 'f1-score': 0.9272765374638224, 'support': 1132} weighted_avg {'precision': 0.9314191228397016, 'recall': 0.9275618374558304, 'f1-score': 0.9277511378578311, 'support': 1132}
 
----------
Epoch 29/40
time = 245.36 secondes

Train loss 0.04685501131608138 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925612122347077, 'recall': 0.9924197896874677, 'f1-score': 0.9924765805188294, 'support': 10182} weighted_avg {'precision': 0.9924713456338599, 'recall': 0.9924376350422314, 'f1-score': 0.992440169124287, 'support': 10182}
 
time = 6.64 secondes

Val loss 0.664728420510688 accuracy 0.9204947352409363 macro_avg {'precision': 0.9212692959778555, 'recall': 0.9212700369511426, 'f1-score': 0.9201878950963014, 'support': 1132} weighted_avg {'precision': 0.9234489196427954, 'recall': 0.9204946996466431, 'f1-score': 0.920805266643516, 'support': 1132}
 
----------
Epoch 30/40
time = 245.80 secondes

Train loss 0.040630959733248366 accuracy 0.9931251406669617 macro_avg {'precision': 0.9930763091446938, 'recall': 0.9928058828138939, 'f1-score': 0.992928128306561, 'support': 10182} weighted_avg {'precision': 0.9931355622752903, 'recall': 0.9931251227656649, 'f1-score': 0.9931189996999724, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.6716591406954431 accuracy 0.9275618195533752 macro_avg {'precision': 0.9298423230633901, 'recall': 0.9287195959476735, 'f1-score': 0.9275560791928289, 'support': 1132} weighted_avg {'precision': 0.9310872578012629, 'recall': 0.9275618374558304, 'f1-score': 0.9275515302741418, 'support': 1132}
 
----------
Epoch 31/40
time = 243.85 secondes

Train loss 0.03138886993134632 accuracy 0.9944019317626953 macro_avg {'precision': 0.9941576910541567, 'recall': 0.9940874247440347, 'f1-score': 0.9941157050152356, 'support': 10182} weighted_avg {'precision': 0.9944142535687619, 'recall': 0.9944018856806128, 'f1-score': 0.9944012401867748, 'support': 10182}
 
time = 6.66 secondes

Val loss 0.6928623816544952 accuracy 0.9222614765167236 macro_avg {'precision': 0.9259811527802126, 'recall': 0.9212876761998805, 'f1-score': 0.9225201460589268, 'support': 1132} weighted_avg {'precision': 0.9246300816015918, 'recall': 0.9222614840989399, 'f1-score': 0.9223871690805161, 'support': 1132}
 
----------
Epoch 32/40
time = 239.83 secondes

Train loss 0.026039394258804402 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955245742643903, 'recall': 0.995545731761894, 'f1-score': 0.9955319916305996, 'support': 10182} weighted_avg {'precision': 0.9955880740818638, 'recall': 0.9955804360636418, 'f1-score': 0.9955810095273571, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.7053976221472061 accuracy 0.9204947352409363 macro_avg {'precision': 0.9206492568686041, 'recall': 0.9212634815581536, 'f1-score': 0.9197908870930054, 'support': 1132} weighted_avg {'precision': 0.9230813107641044, 'recall': 0.9204946996466431, 'f1-score': 0.9206754925925353, 'support': 1132}
 
----------
Epoch 33/40
time = 243.95 secondes

Train loss 0.02952821153605779 accuracy 0.9951876401901245 macro_avg {'precision': 0.9949101650362893, 'recall': 0.9951265065684025, 'f1-score': 0.9950110384677279, 'support': 10182} weighted_avg {'precision': 0.995194879443827, 'recall': 0.9951875859359655, 'f1-score': 0.995184930183445, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.6955446599852326 accuracy 0.9249116778373718 macro_avg {'precision': 0.9279597012412714, 'recall': 0.9268259104984432, 'f1-score': 0.9256470045062614, 'support': 1132} weighted_avg {'precision': 0.9275136519752052, 'recall': 0.9249116607773852, 'f1-score': 0.9245491100017923, 'support': 1132}
 
----------
Epoch 34/40
time = 243.85 secondes

Train loss 0.01895888978581251 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967455061239153, 'recall': 0.9968527950086477, 'f1-score': 0.9967955332674314, 'support': 10182} weighted_avg {'precision': 0.9967642639499121, 'recall': 0.9967589864466706, 'f1-score': 0.9967580673200735, 'support': 10182}
 
time = 6.62 secondes

Val loss 0.7582450164631359 accuracy 0.9196113348007202 macro_avg {'precision': 0.923054506417887, 'recall': 0.9206827876816522, 'f1-score': 0.9200665788954655, 'support': 1132} weighted_avg {'precision': 0.9247806104527663, 'recall': 0.9196113074204947, 'f1-score': 0.9203191024778021, 'support': 1132}
 
----------
Epoch 35/40
time = 244.30 secondes

Train loss 0.025966931840632878 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955729523317478, 'recall': 0.9956335219516333, 'f1-score': 0.9955964012930973, 'support': 10182} weighted_avg {'precision': 0.9955977357018759, 'recall': 0.9955804360636418, 'f1-score': 0.9955821975941234, 'support': 10182}
 
time = 6.65 secondes

Val loss 0.7849747951001684 accuracy 0.9204947352409363 macro_avg {'precision': 0.9269717135089349, 'recall': 0.923797749332459, 'f1-score': 0.9216279486419964, 'support': 1132} weighted_avg {'precision': 0.9300542015016762, 'recall': 0.9204946996466431, 'f1-score': 0.9214146208669193, 'support': 1132}
 
----------
Epoch 36/40
time = 243.65 secondes

Train loss 0.018405589607109033 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973229169471963, 'recall': 0.9973507026085147, 'f1-score': 0.9973350101126428, 'support': 10182} weighted_avg {'precision': 0.997252026239578, 'recall': 0.9972500491062659, 'f1-score': 0.9972492297804358, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.6819082112735845 accuracy 0.9275618195533752 macro_avg {'precision': 0.9299346851891486, 'recall': 0.9294577237050661, 'f1-score': 0.9282493066791344, 'support': 1132} weighted_avg {'precision': 0.9309887136694858, 'recall': 0.9275618374558304, 'f1-score': 0.9277429408808331, 'support': 1132}
 
----------
Epoch 37/40
time = 244.63 secondes

Train loss 0.010827368891134009 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979499781265908, 'recall': 0.9979847328820572, 'f1-score': 0.997964607065749, 'support': 10182} weighted_avg {'precision': 0.9979428693758817, 'recall': 0.9979375368296994, 'f1-score': 0.9979373955656953, 'support': 10182}
 
time = 6.66 secondes

Val loss 0.7157094522011852 accuracy 0.9240282773971558 macro_avg {'precision': 0.9254139344276002, 'recall': 0.9266505832744002, 'f1-score': 0.9248236679403649, 'support': 1132} weighted_avg {'precision': 0.926610504797169, 'recall': 0.9240282685512368, 'f1-score': 0.9240745378193793, 'support': 1132}
 
----------
Epoch 38/40
time = 245.78 secondes

Train loss 0.009456222946547703 accuracy 0.997741162776947 macro_avg {'precision': 0.9977359349573194, 'recall': 0.9976994904038803, 'f1-score': 0.9977168280934998, 'support': 10182} weighted_avg {'precision': 0.9977423816258141, 'recall': 0.9977411117658613, 'f1-score': 0.9977408787319408, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.7542924706970258 accuracy 0.9240282773971558 macro_avg {'precision': 0.9258325562422611, 'recall': 0.9256825385343589, 'f1-score': 0.9237313486708988, 'support': 1132} weighted_avg {'precision': 0.9279968230332694, 'recall': 0.9240282685512368, 'f1-score': 0.9238030087069161, 'support': 1132}
 
----------
Epoch 39/40
time = 238.73 secondes

Train loss 0.007352535854161418 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986926755437773, 'recall': 0.9986910235052326, 'f1-score': 0.9986914981474875, 'support': 10182} weighted_avg {'precision': 0.9987243378159669, 'recall': 0.9987232370850521, 'f1-score': 0.9987234199163572, 'support': 10182}
 
time = 6.60 secondes

Val loss 0.7006855990163696 accuracy 0.9257950782775879 macro_avg {'precision': 0.9284223955277616, 'recall': 0.9267294347117172, 'f1-score': 0.9260686134202105, 'support': 1132} weighted_avg {'precision': 0.9290894161998515, 'recall': 0.9257950530035336, 'f1-score': 0.9258376981499183, 'support': 1132}
 
----------
Epoch 40/40
time = 244.91 secondes

Train loss 0.005852794547593289 accuracy 0.998821496963501 macro_avg {'precision': 0.998878263782677, 'recall': 0.998816872561278, 'f1-score': 0.9988469700041067, 'support': 10182} weighted_avg {'precision': 0.9988232843438156, 'recall': 0.9988214496169712, 'f1-score': 0.9988217859992964, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.696597319577821 accuracy 0.9310954213142395 macro_avg {'precision': 0.9358073857066269, 'recall': 0.9318672456783217, 'f1-score': 0.9319061096707003, 'support': 1132} weighted_avg {'precision': 0.9353481285495033, 'recall': 0.931095406360424, 'f1-score': 0.9312750407944628, 'support': 1132}
 
----------
best_accuracy 0.9310954213142395 best_epoch 40 macro_avg {'precision': 0.9358073857066269, 'recall': 0.9318672456783217, 'f1-score': 0.9319061096707003, 'support': 1132} weighted_avg {'precision': 0.9353481285495033, 'recall': 0.931095406360424, 'f1-score': 0.9312750407944628, 'support': 1132}

average train time 259.5279949247837

average val time 7.299663108587265
 
time = 44.56 secondes

test_accuracy 0.8580722212791443 macro_avg {'precision': 0.8545186616699791, 'recall': 0.8501860662121024, 'f1-score': 0.8506835019980112, 'support': 7532} weighted_avg {'precision': 0.8621381089993094, 'recall': 0.858072225172597, 'f1-score': 0.8585810469307388, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_1
----------
Epoch 1/40
time = 241.77 secondes

Train loss 1.3472077485343539 accuracy 0.6458456516265869 macro_avg {'precision': 0.6586738472353036, 'recall': 0.6294431018538945, 'f1-score': 0.6201759890715524, 'support': 10182} weighted_avg {'precision': 0.6640142119487841, 'recall': 0.6458456098998232, 'f1-score': 0.6351928249085624, 'support': 10182}
 
time = 6.95 secondes

Val loss 0.7303702214234312 accuracy 0.7818021178245544 macro_avg {'precision': 0.755608782457273, 'recall': 0.7741839150010275, 'f1-score': 0.7611240444116376, 'support': 1132} weighted_avg {'precision': 0.7655293234972989, 'recall': 0.7818021201413428, 'f1-score': 0.7702293821806502, 'support': 1132}
 
----------
Epoch 2/40
time = 240.08 secondes

Train loss 0.5276873152486664 accuracy 0.8445295691490173 macro_avg {'precision': 0.8305096409912119, 'recall': 0.8308901323633947, 'f1-score': 0.8267021500212997, 'support': 10182} weighted_avg {'precision': 0.8401270518453094, 'recall': 0.8445295619721076, 'f1-score': 0.839345119229679, 'support': 10182}
 
time = 6.64 secondes

Val loss 0.5811376035423346 accuracy 0.8321554660797119 macro_avg {'precision': 0.8341039925478008, 'recall': 0.8268637863140252, 'f1-score': 0.8231192889205516, 'support': 1132} weighted_avg {'precision': 0.8351027738386951, 'recall': 0.8321554770318021, 'f1-score': 0.8273006380553802, 'support': 1132}
 
----------
Epoch 3/40
time = 239.10 secondes

Train loss 0.34315663444688266 accuracy 0.8998232483863831 macro_avg {'precision': 0.891918023686865, 'recall': 0.8904839927308054, 'f1-score': 0.8905168409642868, 'support': 10182} weighted_avg {'precision': 0.8989758012265623, 'recall': 0.8998232174425457, 'f1-score': 0.8988360043799306, 'support': 10182}
 
time = 6.57 secondes

Val loss 0.5986397184930007 accuracy 0.8480565547943115 macro_avg {'precision': 0.8446778096467675, 'recall': 0.8425526874827286, 'f1-score': 0.8404395395038607, 'support': 1132} weighted_avg {'precision': 0.8464501428963409, 'recall': 0.8480565371024735, 'f1-score': 0.8442941203315657, 'support': 1132}
 
----------
Epoch 4/40
time = 237.07 secondes

Train loss 0.25484772684239726 accuracy 0.9290905594825745 macro_avg {'precision': 0.9238247097356356, 'recall': 0.92234484620286, 'f1-score': 0.9227073251191058, 'support': 10182} weighted_avg {'precision': 0.928613071701746, 'recall': 0.9290905519544294, 'f1-score': 0.9285493520238596, 'support': 10182}
 
time = 6.68 secondes

Val loss 0.6366221074434654 accuracy 0.8507066965103149 macro_avg {'precision': 0.8525385966910027, 'recall': 0.8422148309940767, 'f1-score': 0.8428253477854539, 'support': 1132} weighted_avg {'precision': 0.8544151560331408, 'recall': 0.8507067137809188, 'f1-score': 0.8475238244772103, 'support': 1132}
 
----------
Epoch 5/40
time = 240.36 secondes

Train loss 0.214966573169838 accuracy 0.9446081519126892 macro_avg {'precision': 0.9414748450288881, 'recall': 0.9402314252820683, 'f1-score': 0.9406628011867078, 'support': 10182} weighted_avg {'precision': 0.9446097210742511, 'recall': 0.9446081319976429, 'f1-score': 0.9444414069228331, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.7003301682121212 accuracy 0.8613074421882629 macro_avg {'precision': 0.8633847583635317, 'recall': 0.8561609430742723, 'f1-score': 0.8531061620994865, 'support': 1132} weighted_avg {'precision': 0.864580990705632, 'recall': 0.8613074204946997, 'f1-score': 0.8566461716952466, 'support': 1132}
 
----------
Epoch 6/40
time = 233.40 secondes

Train loss 0.17946462180491776 accuracy 0.9550186991691589 macro_avg {'precision': 0.9522073077702938, 'recall': 0.9514957370553001, 'f1-score': 0.9517678697032637, 'support': 10182} weighted_avg {'precision': 0.9549035766765585, 'recall': 0.9550186603810646, 'f1-score': 0.9548877367084936, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.700599104957983 accuracy 0.8692579865455627 macro_avg {'precision': 0.8749330315483004, 'recall': 0.8629649657972166, 'f1-score': 0.8651349256851315, 'support': 1132} weighted_avg {'precision': 0.8751754335909653, 'recall': 0.8692579505300353, 'f1-score': 0.8684791090635812, 'support': 1132}
 
----------
Epoch 7/40
time = 236.93 secondes

Train loss 0.176739530579744 accuracy 0.9567865133285522 macro_avg {'precision': 0.9544561501868131, 'recall': 0.9535068662453634, 'f1-score': 0.9538607499555184, 'support': 10182} weighted_avg {'precision': 0.9567285066958132, 'recall': 0.9567864859556079, 'f1-score': 0.9566550351167193, 'support': 10182}
 
time = 6.57 secondes

Val loss 0.7697714077977752 accuracy 0.8648409843444824 macro_avg {'precision': 0.885210749805273, 'recall': 0.8575451348862245, 'f1-score': 0.8546468091233448, 'support': 1132} weighted_avg {'precision': 0.8833466668642758, 'recall': 0.8648409893992933, 'f1-score': 0.8616608564727877, 'support': 1132}
 
----------
Epoch 8/40
time = 238.56 secondes

Train loss 0.14510873581011952 accuracy 0.967197060585022 macro_avg {'precision': 0.965585095736501, 'recall': 0.9650468827559688, 'f1-score': 0.9652393570728494, 'support': 10182} weighted_avg {'precision': 0.9671168861233235, 'recall': 0.9671970143390297, 'f1-score': 0.9670903564745406, 'support': 10182}
 
time = 6.59 secondes

Val loss 0.7559779315578594 accuracy 0.8745583295822144 macro_avg {'precision': 0.8739762037824208, 'recall': 0.8677579104785872, 'f1-score': 0.8670889547873395, 'support': 1132} weighted_avg {'precision': 0.8748532940290513, 'recall': 0.8745583038869258, 'f1-score': 0.8714517999484954, 'support': 1132}
 
----------
Epoch 9/40
time = 239.12 secondes

Train loss 0.13726275130687685 accuracy 0.9694559574127197 macro_avg {'precision': 0.968434920366677, 'recall': 0.9675439669131702, 'f1-score': 0.9679133422736743, 'support': 10182} weighted_avg {'precision': 0.969434600109325, 'recall': 0.9694559025731684, 'f1-score': 0.9693855663463294, 'support': 10182}
 
time = 6.62 secondes

Val loss 0.7520769388860905 accuracy 0.8692579865455627 macro_avg {'precision': 0.8714696440284152, 'recall': 0.8641839010007221, 'f1-score': 0.8636025710748794, 'support': 1132} weighted_avg {'precision': 0.8726303790055862, 'recall': 0.8692579505300353, 'f1-score': 0.8674314969013687, 'support': 1132}
 
----------
Epoch 10/40
time = 239.19 secondes

Train loss 0.11259495821986874 accuracy 0.9749558568000793 macro_avg {'precision': 0.9738426398780262, 'recall': 0.9736293362845782, 'f1-score': 0.9737087013780841, 'support': 10182} weighted_avg {'precision': 0.9749958318592865, 'recall': 0.9749558043606364, 'f1-score': 0.9749491549207708, 'support': 10182}
 
time = 6.59 secondes

Val loss 0.80851460559028 accuracy 0.8780918717384338 macro_avg {'precision': 0.8775376692304453, 'recall': 0.8744170706421366, 'f1-score': 0.8720685903350294, 'support': 1132} weighted_avg {'precision': 0.8806910511217042, 'recall': 0.8780918727915195, 'f1-score': 0.8761226144150777, 'support': 1132}
 
----------
Epoch 11/40
time = 233.82 secondes

Train loss 0.11525708641364382 accuracy 0.9762325882911682 macro_avg {'precision': 0.9750380796036676, 'recall': 0.9748631247603072, 'f1-score': 0.9749327575417294, 'support': 10182} weighted_avg {'precision': 0.9762580968974874, 'recall': 0.9762325672755844, 'f1-score': 0.9762281187447064, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.848339415797685 accuracy 0.8692579865455627 macro_avg {'precision': 0.8718144991294828, 'recall': 0.8674636998396007, 'f1-score': 0.8668349793294741, 'support': 1132} weighted_avg {'precision': 0.8732836140293408, 'recall': 0.8692579505300353, 'f1-score': 0.8686037859017687, 'support': 1132}
 
----------
Epoch 12/40
time = 237.61 secondes

Train loss 0.11495474771323912 accuracy 0.9768218994140625 macro_avg {'precision': 0.9758102138153306, 'recall': 0.9757781563483434, 'f1-score': 0.9757806796418709, 'support': 10182} weighted_avg {'precision': 0.976830260614198, 'recall': 0.9768218424670988, 'f1-score': 0.9768123850707057, 'support': 10182}
 
time = 6.57 secondes

Val loss 1.08515405222039 accuracy 0.8524734973907471 macro_avg {'precision': 0.8717298724043305, 'recall': 0.8488401322618675, 'f1-score': 0.8503631362009383, 'support': 1132} weighted_avg {'precision': 0.8682024633671844, 'recall': 0.8524734982332155, 'f1-score': 0.8522039310948594, 'support': 1132}
 
----------
Epoch 13/40
time = 241.17 secondes

Train loss 0.11827108081264072 accuracy 0.9780004024505615 macro_avg {'precision': 0.9767757990786091, 'recall': 0.9768681972688709, 'f1-score': 0.9767946800740542, 'support': 10182} weighted_avg {'precision': 0.9780144808033437, 'recall': 0.9780003928501276, 'f1-score': 0.9779808049815194, 'support': 10182}
 
time = 6.57 secondes

Val loss 0.8521554078527604 accuracy 0.8727915287017822 macro_avg {'precision': 0.8731069614886902, 'recall': 0.8716582202839047, 'f1-score': 0.8687612037532837, 'support': 1132} weighted_avg {'precision': 0.8780936867200049, 'recall': 0.872791519434629, 'f1-score': 0.8715550842969854, 'support': 1132}
 
----------
Epoch 14/40
time = 235.40 secondes

Train loss 0.09744538936649413 accuracy 0.9803575277328491 macro_avg {'precision': 0.9798307261460852, 'recall': 0.9797753263921537, 'f1-score': 0.9797766314616345, 'support': 10182} weighted_avg {'precision': 0.980400781350473, 'recall': 0.9803574936161854, 'f1-score': 0.9803528517659752, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.8042543603260641 accuracy 0.880742073059082 macro_avg {'precision': 0.885947513338289, 'recall': 0.8823489035153195, 'f1-score': 0.8818450675442652, 'support': 1132} weighted_avg {'precision': 0.8862987281851334, 'recall': 0.8807420494699647, 'f1-score': 0.8810120637771566, 'support': 1132}
 
----------
Epoch 15/40
time = 237.10 secondes

Train loss 0.09551892397681096 accuracy 0.9819289445877075 macro_avg {'precision': 0.981417691137586, 'recall': 0.9811676135190714, 'f1-score': 0.9812757272149806, 'support': 10182} weighted_avg {'precision': 0.9819511176895208, 'recall': 0.9819288941268906, 'f1-score': 0.9819239971292127, 'support': 10182}
 
time = 7.01 secondes

Val loss 0.82605421280531 accuracy 0.8754417300224304 macro_avg {'precision': 0.8844822896358627, 'recall': 0.8746456365178954, 'f1-score': 0.8763494816747913, 'support': 1132} weighted_avg {'precision': 0.8827574694685693, 'recall': 0.8754416961130742, 'f1-score': 0.8759957131522383, 'support': 1132}
 
----------
Epoch 16/40
time = 239.69 secondes

Train loss 0.08174075578548927 accuracy 0.9837949872016907 macro_avg {'precision': 0.9832475340956179, 'recall': 0.9828544949337376, 'f1-score': 0.9830241271129616, 'support': 10182} weighted_avg {'precision': 0.983796581746036, 'recall': 0.983794932233353, 'f1-score': 0.983773057653208, 'support': 10182}
 
time = 6.62 secondes

Val loss 0.9293587152722363 accuracy 0.8754417300224304 macro_avg {'precision': 0.8767288290456774, 'recall': 0.8747750159684097, 'f1-score': 0.8745884475459735, 'support': 1132} weighted_avg {'precision': 0.8790145518656616, 'recall': 0.8754416961130742, 'f1-score': 0.876044835732452, 'support': 1132}
 
----------
Epoch 17/40
time = 232.88 secondes

Train loss 0.10422934487551502 accuracy 0.9806521534919739 macro_avg {'precision': 0.9803743764476355, 'recall': 0.9793260497634572, 'f1-score': 0.9797693959180179, 'support': 10182} weighted_avg {'precision': 0.9807674868080917, 'recall': 0.9806521312119426, 'f1-score': 0.9806409096361794, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.9996208591631804 accuracy 0.8568904399871826 macro_avg {'precision': 0.8684251785800472, 'recall': 0.8551031478585711, 'f1-score': 0.856214195270969, 'support': 1132} weighted_avg {'precision': 0.8678230026973988, 'recall': 0.8568904593639576, 'f1-score': 0.8565221011356411, 'support': 1132}
 
----------
Epoch 18/40
time = 239.78 secondes

Train loss 0.09818284542129524 accuracy 0.9822235703468323 macro_avg {'precision': 0.981567891319466, 'recall': 0.9807171864516977, 'f1-score': 0.9810698404602004, 'support': 10182} weighted_avg {'precision': 0.9822577205753532, 'recall': 0.9822235317226478, 'f1-score': 0.9821836804463303, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.9611741167255005 accuracy 0.8763250708580017 macro_avg {'precision': 0.8796434503844495, 'recall': 0.8751120624994057, 'f1-score': 0.8752767247659777, 'support': 1132} weighted_avg {'precision': 0.8810069184388993, 'recall': 0.8763250883392226, 'f1-score': 0.8764888631028868, 'support': 1132}
 
----------
Epoch 19/40
time = 238.92 secondes

Train loss 0.08990923927023338 accuracy 0.9829110503196716 macro_avg {'precision': 0.9823564625547437, 'recall': 0.9821682388740902, 'f1-score': 0.9822517665241562, 'support': 10182} weighted_avg {'precision': 0.9829301654040842, 'recall': 0.9829110194460813, 'f1-score': 0.9829098803028228, 'support': 10182}
 
time = 6.64 secondes

Val loss 0.8867306650077603 accuracy 0.8816254734992981 macro_avg {'precision': 0.8864244983633487, 'recall': 0.8812401105534875, 'f1-score': 0.8810892921291265, 'support': 1132} weighted_avg {'precision': 0.8886849361847445, 'recall': 0.8816254416961131, 'f1-score': 0.8824699760819708, 'support': 1132}
 
----------
Epoch 20/40
time = 238.67 secondes

Train loss 0.07592277920328062 accuracy 0.9849734902381897 macro_avg {'precision': 0.9843171313619978, 'recall': 0.9841402125074363, 'f1-score': 0.9842069349329717, 'support': 10182} weighted_avg {'precision': 0.9850301931431361, 'recall': 0.9849734826163818, 'f1-score': 0.9849800259739702, 'support': 10182}
 
time = 6.59 secondes

Val loss 0.9597058566043262 accuracy 0.8763250708580017 macro_avg {'precision': 0.8850404920613139, 'recall': 0.8717796668671417, 'f1-score': 0.8746914000041505, 'support': 1132} weighted_avg {'precision': 0.8869709100066283, 'recall': 0.8763250883392226, 'f1-score': 0.8778902943411949, 'support': 1132}
 
----------
Epoch 21/40
time = 233.72 secondes

Train loss 0.08081973473469432 accuracy 0.98448246717453 macro_avg {'precision': 0.9839967645376883, 'recall': 0.9835426326893513, 'f1-score': 0.9837418155766997, 'support': 10182} weighted_avg {'precision': 0.9845448870511013, 'recall': 0.9844824199567865, 'f1-score': 0.984488060798911, 'support': 10182}
 
time = 6.56 secondes

Val loss 0.9217149923882664 accuracy 0.8780918717384338 macro_avg {'precision': 0.8887162850833953, 'recall': 0.8740274273737999, 'f1-score': 0.876079059307082, 'support': 1132} weighted_avg {'precision': 0.8853674465158449, 'recall': 0.8780918727915195, 'f1-score': 0.8773144583436765, 'support': 1132}
 
----------
Epoch 22/40
time = 241.35 secondes

Train loss 0.06064497587564175 accuracy 0.9884109497070312 macro_avg {'precision': 0.9876057470443736, 'recall': 0.9876780402442031, 'f1-score': 0.9876308367033501, 'support': 10182} weighted_avg {'precision': 0.9884359378669114, 'recall': 0.9884109212335495, 'f1-score': 0.9884127523522467, 'support': 10182}
 
time = 6.57 secondes

Val loss 0.8681360932849356 accuracy 0.8966431021690369 macro_avg {'precision': 0.9000597976795974, 'recall': 0.8943446791600886, 'f1-score': 0.8946223987276, 'support': 1132} weighted_avg {'precision': 0.8988015399118942, 'recall': 0.8966431095406361, 'f1-score': 0.8955775477742589, 'support': 1132}
 
----------
Epoch 23/40
time = 239.57 secondes

Train loss 0.0487043178360393 accuracy 0.9901787638664246 macro_avg {'precision': 0.9897635222749411, 'recall': 0.9898124447034903, 'f1-score': 0.9897778220944338, 'support': 10182} weighted_avg {'precision': 0.9902065091745481, 'recall': 0.9901787468080927, 'f1-score': 0.9901821753140922, 'support': 10182}
 
time = 6.63 secondes

Val loss 0.8397452606703565 accuracy 0.8939929604530334 macro_avg {'precision': 0.8953584589587077, 'recall': 0.8940819731799353, 'f1-score': 0.8932263949621972, 'support': 1132} weighted_avg {'precision': 0.8975805619198689, 'recall': 0.8939929328621908, 'f1-score': 0.8942482010694541, 'support': 1132}
 
----------
Epoch 24/40
time = 241.29 secondes

Train loss 0.0700404301231808 accuracy 0.9870359897613525 macro_avg {'precision': 0.9867381134644686, 'recall': 0.9864996218757325, 'f1-score': 0.9865898630821798, 'support': 10182} weighted_avg {'precision': 0.9870594236293605, 'recall': 0.9870359457866824, 'f1-score': 0.9870208068435593, 'support': 10182}
 
time = 6.62 secondes

Val loss 0.8942251624271002 accuracy 0.8895759582519531 macro_avg {'precision': 0.8913252056605188, 'recall': 0.8918549105329199, 'f1-score': 0.8898366353975833, 'support': 1132} weighted_avg {'precision': 0.8932680029052917, 'recall': 0.8895759717314488, 'f1-score': 0.8895230088023315, 'support': 1132}
 
----------
Epoch 25/40
time = 239.65 secondes

Train loss 0.05302922059048771 accuracy 0.9908662438392639 macro_avg {'precision': 0.9907867983531702, 'recall': 0.9909866651284146, 'f1-score': 0.9908750542934541, 'support': 10182} weighted_avg {'precision': 0.9908866622149002, 'recall': 0.9908662345315262, 'f1-score': 0.9908649145170451, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.9645736264650059 accuracy 0.879858672618866 macro_avg {'precision': 0.8822924874691296, 'recall': 0.877254558730144, 'f1-score': 0.8773469609697686, 'support': 1132} weighted_avg {'precision': 0.8837196378312123, 'recall': 0.8798586572438163, 'f1-score': 0.8794011217613007, 'support': 1132}
 
----------
Epoch 26/40
time = 236.22 secondes

Train loss 0.04986547119302683 accuracy 0.9911609292030334 macro_avg {'precision': 0.9905531811651433, 'recall': 0.9904669014744993, 'f1-score': 0.9905009442143221, 'support': 10182} weighted_avg {'precision': 0.9911766311952576, 'recall': 0.9911608721272834, 'f1-score': 0.991160242097238, 'support': 10182}
 
time = 6.59 secondes

Val loss 1.043353783992438 accuracy 0.8833922147750854 macro_avg {'precision': 0.8890802176603938, 'recall': 0.8825155545525931, 'f1-score': 0.882840549776207, 'support': 1132} weighted_avg {'precision': 0.8886238219571639, 'recall': 0.8833922261484098, 'f1-score': 0.8829478640743208, 'support': 1132}
 
----------
Epoch 27/40
time = 240.47 secondes

Train loss 0.059550896425904366 accuracy 0.9899823665618896 macro_avg {'precision': 0.9899932758366896, 'recall': 0.9898614724029778, 'f1-score': 0.9899162404938565, 'support': 10182} weighted_avg {'precision': 0.9900071605258699, 'recall': 0.9899823217442546, 'f1-score': 0.9899835624900184, 'support': 10182}
 
time = 6.61 secondes

Val loss 1.032059349740169 accuracy 0.8745583295822144 macro_avg {'precision': 0.8750391026877541, 'recall': 0.8752149399323811, 'f1-score': 0.8734068567777064, 'support': 1132} weighted_avg {'precision': 0.8794199186781315, 'recall': 0.8745583038869258, 'f1-score': 0.8753841981964772, 'support': 1132}
 
----------
Epoch 28/40
time = 234.96 secondes

Train loss 0.05736698466137238 accuracy 0.9918484091758728 macro_avg {'precision': 0.9915641664610101, 'recall': 0.991532218490636, 'f1-score': 0.9915296063659069, 'support': 10182} weighted_avg {'precision': 0.9918720081768004, 'recall': 0.991848359850717, 'f1-score': 0.9918413367962913, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.899304182005105 accuracy 0.8966431021690369 macro_avg {'precision': 0.9015585917928185, 'recall': 0.8975831867529749, 'f1-score': 0.8979648989562389, 'support': 1132} weighted_avg {'precision': 0.9008889524081777, 'recall': 0.8966431095406361, 'f1-score': 0.8972947291583541, 'support': 1132}
 
----------
Epoch 29/40
time = 240.00 secondes

Train loss 0.05284892660136085 accuracy 0.9907680749893188 macro_avg {'precision': 0.9906058272154779, 'recall': 0.990549970945364, 'f1-score': 0.9905710618274938, 'support': 10182} weighted_avg {'precision': 0.9907784598018171, 'recall': 0.9907680219996071, 'f1-score': 0.9907669001742819, 'support': 10182}
 
time = 6.70 secondes

Val loss 1.0305673002363158 accuracy 0.870141327381134 macro_avg {'precision': 0.8746996507809796, 'recall': 0.87011125018951, 'f1-score': 0.8702716943579618, 'support': 1132} weighted_avg {'precision': 0.8765542307247277, 'recall': 0.8701413427561837, 'f1-score': 0.8710909615310511, 'support': 1132}
 
----------
Epoch 30/40
time = 239.15 secondes

Train loss 0.05214421411618268 accuracy 0.9908662438392639 macro_avg {'precision': 0.9901879625842549, 'recall': 0.9904262409121257, 'f1-score': 0.9902874518283792, 'support': 10182} weighted_avg {'precision': 0.9909232058318942, 'recall': 0.9908662345315262, 'f1-score': 0.9908777646276664, 'support': 10182}
 
time = 6.58 secondes

Val loss 0.9768490558131483 accuracy 0.8754417300224304 macro_avg {'precision': 0.8840592199804351, 'recall': 0.8750051070134195, 'f1-score': 0.8767906173484539, 'support': 1132} weighted_avg {'precision': 0.8823201181588158, 'recall': 0.8754416961130742, 'f1-score': 0.8762061995236295, 'support': 1132}
 
----------
Epoch 31/40
time = 239.06 secondes

Train loss 0.03765507584104176 accuracy 0.9941073060035706 macro_avg {'precision': 0.994075125878753, 'recall': 0.9939485148046134, 'f1-score': 0.9940062780766269, 'support': 10182} weighted_avg {'precision': 0.9941163703806891, 'recall': 0.9941072480848556, 'f1-score': 0.994106444325313, 'support': 10182}
 
time = 6.72 secondes

Val loss 0.9773574404710634 accuracy 0.8842756152153015 macro_avg {'precision': 0.8912039713256894, 'recall': 0.8804096239277985, 'f1-score': 0.8822412915515626, 'support': 1132} weighted_avg {'precision': 0.8869850953974864, 'recall': 0.8842756183745583, 'f1-score': 0.8824877600711577, 'support': 1132}
 
----------
Epoch 32/40
time = 240.81 secondes

Train loss 0.03556496856623453 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945818921746039, 'recall': 0.9944105429300276, 'f1-score': 0.9944880647718236, 'support': 10182} weighted_avg {'precision': 0.9946115035526512, 'recall': 0.994598310744451, 'f1-score': 0.9945976664646321, 'support': 10182}
 
time = 6.61 secondes

Val loss 0.966306443152782 accuracy 0.8948763608932495 macro_avg {'precision': 0.8931810714142683, 'recall': 0.8940291147806618, 'f1-score': 0.8925124882512628, 'support': 1132} weighted_avg {'precision': 0.8977064779685465, 'recall': 0.8948763250883393, 'f1-score': 0.8952263755011991, 'support': 1132}
 
----------
Epoch 33/40
time = 234.64 secondes

Train loss 0.02387851592169713 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963864524305984, 'recall': 0.9963522387243777, 'f1-score': 0.9963667333974463, 'support': 10182} weighted_avg {'precision': 0.9963702907508338, 'recall': 0.9963661363189943, 'f1-score': 0.9963655798695558, 'support': 10182}
 
time = 6.65 secondes

Val loss 1.0550654139150422 accuracy 0.8842756152153015 macro_avg {'precision': 0.8878579378181286, 'recall': 0.8837502952450074, 'f1-score': 0.8839494106467229, 'support': 1132} weighted_avg {'precision': 0.887534898863284, 'recall': 0.8842756183745583, 'f1-score': 0.8840953960780281, 'support': 1132}
 
----------
Epoch 34/40
time = 237.97 secondes

Train loss 0.018826123815696757 accuracy 0.9964643716812134 macro_avg {'precision': 0.9963500263433293, 'recall': 0.9963868853862067, 'f1-score': 0.9963642868168401, 'support': 10182} weighted_avg {'precision': 0.9964713372896152, 'recall': 0.9964643488509134, 'f1-score': 0.9964640364388768, 'support': 10182}
 
time = 6.65 secondes

Val loss 1.0384142697047036 accuracy 0.8860424160957336 macro_avg {'precision': 0.889049557673238, 'recall': 0.8886547076545781, 'f1-score': 0.8871282953012802, 'support': 1132} weighted_avg {'precision': 0.8902263160514828, 'recall': 0.8860424028268551, 'f1-score': 0.8862596884879824, 'support': 1132}
 
----------
Epoch 35/40
time = 239.33 secondes

Train loss 0.014028972809900205 accuracy 0.9971518516540527 macro_avg {'precision': 0.99696869387513, 'recall': 0.997121593135352, 'f1-score': 0.9970426570331428, 'support': 10182} weighted_avg {'precision': 0.997158391159185, 'recall': 0.9971518365743469, 'f1-score': 0.997152747165159, 'support': 10182}
 
time = 6.53 secondes

Val loss 0.9238613046549751 accuracy 0.8931095600128174 macro_avg {'precision': 0.8937241125435404, 'recall': 0.8931764251850914, 'f1-score': 0.8925884912298798, 'support': 1132} weighted_avg {'precision': 0.8944997635486307, 'recall': 0.8931095406360424, 'f1-score': 0.8929028930335862, 'support': 1132}
 
----------
Epoch 36/40
time = 238.69 secondes

Train loss 0.013028179891846788 accuracy 0.997741162776947 macro_avg {'precision': 0.9976451707656657, 'recall': 0.9976992263224531, 'f1-score': 0.9976709278032363, 'support': 10182} weighted_avg {'precision': 0.9977435852984263, 'recall': 0.9977411117658613, 'f1-score': 0.9977410964973032, 'support': 10182}
 
time = 6.56 secondes

Val loss 1.1226156781889023 accuracy 0.879858672618866 macro_avg {'precision': 0.8922487123221707, 'recall': 0.8810267721104001, 'f1-score': 0.8832529221612628, 'support': 1132} weighted_avg {'precision': 0.8901332347003527, 'recall': 0.8798586572438163, 'f1-score': 0.8812210589448336, 'support': 1132}
 
----------
Epoch 37/40
time = 239.13 secondes

Train loss 0.013944828629779749 accuracy 0.9972500801086426 macro_avg {'precision': 0.9971051723850298, 'recall': 0.9971334377936383, 'f1-score': 0.9971162733669885, 'support': 10182} weighted_avg {'precision': 0.9972553681302293, 'recall': 0.9972500491062659, 'f1-score': 0.9972498335578932, 'support': 10182}
 
time = 6.65 secondes

Val loss 1.072903850248545 accuracy 0.8966431021690369 macro_avg {'precision': 0.8976783238998831, 'recall': 0.8980079199967042, 'f1-score': 0.89655699657898, 'support': 1132} weighted_avg {'precision': 0.8987445577881484, 'recall': 0.8966431095406361, 'f1-score': 0.8964163914126926, 'support': 1132}
 
----------
Epoch 38/40
time = 233.82 secondes

Train loss 0.014206144153778874 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976492396980262, 'recall': 0.9976348620097053, 'f1-score': 0.997639042820899, 'support': 10182} weighted_avg {'precision': 0.9976514699744656, 'recall': 0.9976428992339422, 'f1-score': 0.9976441085859882, 'support': 10182}
 
time = 6.64 secondes

Val loss 1.0727970508883053 accuracy 0.8939929604530334 macro_avg {'precision': 0.894430726096809, 'recall': 0.895667002461807, 'f1-score': 0.893899378048663, 'support': 1132} weighted_avg {'precision': 0.8965425725979081, 'recall': 0.8939929328621908, 'f1-score': 0.8940036694870727, 'support': 1132}
 
----------
Epoch 39/40
time = 240.05 secondes

Train loss 0.011065367794031241 accuracy 0.9979375600814819 macro_avg {'precision': 0.9977928892942414, 'recall': 0.9978338247773179, 'f1-score': 0.9978124048910727, 'support': 10182} weighted_avg {'precision': 0.9979396813425134, 'recall': 0.9979375368296994, 'f1-score': 0.9979376584936511, 'support': 10182}
 
time = 6.58 secondes

Val loss 1.088020405029581 accuracy 0.8931095600128174 macro_avg {'precision': 0.8944855781865078, 'recall': 0.8968867101879695, 'f1-score': 0.8939816071819617, 'support': 1132} weighted_avg {'precision': 0.8971440083812074, 'recall': 0.8931095406360424, 'f1-score': 0.8933648173617432, 'support': 1132}
 
----------
Epoch 40/40
time = 238.19 secondes

Train loss 0.002793283508862041 accuracy 0.9993125200271606 macro_avg {'precision': 0.999244540990192, 'recall': 0.9992828478215492, 'f1-score': 0.999262798615789, 'support': 10182} weighted_avg {'precision': 0.9993145303826179, 'recall': 0.9993125122765665, 'f1-score': 0.999312644136429, 'support': 10182}
 
time = 6.64 secondes

Val loss 1.065746181866083 accuracy 0.8975265026092529 macro_avg {'precision': 0.899851415598407, 'recall': 0.8988910081743293, 'f1-score': 0.8985678180956229, 'support': 1132} weighted_avg {'precision': 0.90045803916306, 'recall': 0.8975265017667845, 'f1-score': 0.8981326466849124, 'support': 1132}
 
----------
best_accuracy 0.8975265026092529 best_epoch 40 macro_avg {'precision': 0.899851415598407, 'recall': 0.8988910081743293, 'f1-score': 0.8985678180956229, 'support': 1132} weighted_avg {'precision': 0.90045803916306, 'recall': 0.8975265017667845, 'f1-score': 0.8981326466849124, 'support': 1132}

average train time 238.217453956604

average val time 6.626222056150437
 
time = 44.13 secondes

test_accuracy 0.8293945789337158 macro_avg {'precision': 0.823528904880385, 'recall': 0.8191776793308441, 'f1-score': 0.8200504915975977, 'support': 7532} weighted_avg {'precision': 0.8329069857410771, 'recall': 0.8293945831120553, 'f1-score': 0.8298707634096723, 'support': 7532}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_1
----------
Epoch 1/40
time = 259.94 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.27981970086693764 micro_f1_score 0.5812321759992757 
 
time = 15.38 secondes

Val loss 0.2371031925326488 micro_f1_score 0.6332945285215367
 
----------
Epoch 2/40
time = 257.84 secondes

Train loss 0.18487925270052105 micro_f1_score 0.7423609951577893 
 
time = 15.12 secondes

Val loss 0.2073975880859328 micro_f1_score 0.7021023403411344
 
----------
Epoch 3/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.20 GiB total capacity; 4.22 GiB already allocated; 94.31 MiB free; 4.33 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 4.28 GiB already allocated; 22.31 MiB free; 4.32 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 4.26 GiB already allocated; 22.31 MiB free; 4.32 GiB reserved in total by PyTorch)
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_1
----------
Epoch 1/40
time = 13.87 secondes

Train loss 0.6497498226888252 accuracy 0.6375969052314758 macro_avg {'precision': 0.3187984496124031, 'recall': 0.5, 'f1-score': 0.38934911242603554, 'support': 516} weighted_avg {'precision': 0.40652980590108767, 'recall': 0.6375968992248062, 'f1-score': 0.4964955735975415, 'support': 516}
 
time = 0.50 secondes

Val loss 0.6415752172470093 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 12.65 secondes

Train loss 0.5473138337785547 accuracy 0.6899224519729614 macro_avg {'precision': 0.753581514762516, 'recall': 0.5802707930367504, 'f1-score': 0.5496203194553548, 'support': 516} weighted_avg {'precision': 0.7327529828541859, 'recall': 0.689922480620155, 'f1-score': 0.6187970794741104, 'support': 516}
 
time = 0.43 secondes

Val loss 0.5661985501646996 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 3/40
time = 12.64 secondes

Train loss 0.39935411422541645 accuracy 0.8430232405662537 macro_avg {'precision': 0.8293788580246914, 'recall': 0.8330461778521854, 'f1-score': 0.8311184021787004, 'support': 516} weighted_avg {'precision': 0.84405692231314, 'recall': 0.8430232558139535, 'f1-score': 0.8434577395232692, 'support': 516}
 
time = 0.42 secondes

Val loss 0.42188359797000885 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 4/40
time = 12.79 secondes

Train loss 0.36475145466851466 accuracy 0.8624030947685242 macro_avg {'precision': 0.8552631578947368, 'recall': 0.8436275864310908, 'f1-score': 0.8487559395783364, 'support': 516} weighted_avg {'precision': 0.8612981096151231, 'recall': 0.8624031007751938, 'f1-score': 0.8612585001586832, 'support': 516}
 
time = 0.43 secondes

Val loss 0.6532080695033073 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 5/40
time = 14.44 secondes

Train loss 0.29063164645975287 accuracy 0.8895348906517029 macro_avg {'precision': 0.8814497118910425, 'recall': 0.8787526616062286, 'f1-score': 0.8800641028254992, 'support': 516} weighted_avg {'precision': 0.8892071064845835, 'recall': 0.8895348837209303, 'f1-score': 0.8893389365299903, 'support': 516}
 
time = 0.49 secondes

Val loss 0.6402130573987961 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 6/40
time = 16.34 secondes

Train loss 0.35683982136348885 accuracy 0.8817829489707947 macro_avg {'precision': 0.8693276276091374, 'recall': 0.8899842335386766, 'f1-score': 0.876047019906669, 'support': 516} weighted_avg {'precision': 0.891435817285089, 'recall': 0.8817829457364341, 'f1-score': 0.8833848709681703, 'support': 516}
 
time = 0.44 secondes

Val loss 1.0011636465787888 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 7/40
time = 13.75 secondes

Train loss 0.3321582189845768 accuracy 0.9127907156944275 macro_avg {'precision': 0.9127906976744186, 'recall': 0.8969897436730978, 'f1-score': 0.9038935130190764, 'support': 516} weighted_avg {'precision': 0.9127906976744186, 'recall': 0.9127906976744186, 'f1-score': 0.9119406481850547, 'support': 516}
 
time = 0.43 secondes

Val loss 0.7357102409005165 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 8/40
time = 12.80 secondes

Train loss 0.15613841801656014 accuracy 0.9554263353347778 macro_avg {'precision': 0.9532477737035097, 'recall': 0.9500430733221723, 'f1-score': 0.9516048134208155, 'support': 516} weighted_avg {'precision': 0.9553380356613511, 'recall': 0.9554263565891473, 'f1-score': 0.9553472901787681, 'support': 516}
 
time = 0.44 secondes

Val loss 1.2296946346759796 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 9/40
time = 12.62 secondes

Train loss 0.26891360079135856 accuracy 0.9263566136360168 macro_avg {'precision': 0.9315066142786061, 'recall': 0.9087820814979763, 'f1-score': 0.9183040847957602, 'support': 516} weighted_avg {'precision': 0.927488462802522, 'recall': 0.9263565891472868, 'f1-score': 0.9253624528075922, 'support': 516}
 
time = 0.43 secondes

Val loss 0.6751642152667046 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 10/40
time = 12.73 secondes

Train loss 0.164714800419681 accuracy 0.963178277015686 macro_avg {'precision': 0.9628051589129434, 'recall': 0.9572761406303334, 'f1-score': 0.95992593410097, 'support': 516} weighted_avg {'precision': 0.9631537461749132, 'recall': 0.9631782945736435, 'f1-score': 0.9630676700677702, 'support': 516}
 
time = 0.43 secondes

Val loss 0.8801421821117401 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 11/40
time = 12.35 secondes

Train loss 0.10004786909981207 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 0.43 secondes

Val loss 0.9811482727527618 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 12/40
time = 11.96 secondes

Train loss 0.4463144719431346 accuracy 0.8895348906517029 macro_avg {'precision': 0.8771218290009395, 'recall': 0.8914471010841474, 'f1-score': 0.8828799770633982, 'support': 516} weighted_avg {'precision': 0.8940704229455422, 'recall': 0.8895348837209303, 'f1-score': 0.8905628774322564, 'support': 516}
 
time = 0.43 secondes

Val loss 1.235312283039093 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 13/40
time = 12.17 secondes

Train loss 0.1606470047016487 accuracy 0.963178277015686 macro_avg {'precision': 0.9628051589129434, 'recall': 0.9572761406303334, 'f1-score': 0.95992593410097, 'support': 516} weighted_avg {'precision': 0.9631537461749132, 'recall': 0.9631782945736435, 'f1-score': 0.9630676700677702, 'support': 516}
 
time = 0.43 secondes

Val loss 0.9011640697717667 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 12.91 secondes

Train loss 0.14107725354419512 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 0.43 secondes

Val loss 0.9651502445340157 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 15/40
time = 14.15 secondes

Train loss 0.30749566324944183 accuracy 0.9282945990562439 macro_avg {'precision': 0.922029060716139, 'recall': 0.9229962778148009, 'f1-score': 0.9225083713850837, 'support': 516} weighted_avg {'precision': 0.9283840809709433, 'recall': 0.9282945736434108, 'f1-score': 0.9283356105388599, 'support': 516}
 
time = 0.48 secondes

Val loss 0.6679177507758141 accuracy 0.875 macro_avg {'precision': 0.8704453441295547, 'recall': 0.8704453441295547, 'f1-score': 0.8704453441295547, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 64}
 
----------
Epoch 16/40
time = 14.17 secondes

Train loss 0.2413742032755787 accuracy 0.9457364082336426 macro_avg {'precision': 0.9431890907300744, 'recall': 0.9389821692700291, 'f1-score': 0.9410141259083857, 'support': 516} weighted_avg {'precision': 0.9456005757950096, 'recall': 0.9457364341085271, 'f1-score': 0.945607055801674, 'support': 516}
 
time = 0.43 secondes

Val loss 1.0141752064228058 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 17/40
time = 14.84 secondes

Train loss 0.13302335811595462 accuracy 0.963178277015686 macro_avg {'precision': 0.9679874974793305, 'recall': 0.952659980820181, 'f1-score': 0.9595262373519492, 'support': 516} weighted_avg {'precision': 0.9639225759757141, 'recall': 0.9631782945736435, 'f1-score': 0.9628719930002111, 'support': 516}
 
time = 0.52 secondes

Val loss 0.9144729375839233 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 18/40
time = 15.58 secondes

Train loss 0.21919925697147846 accuracy 0.963178277015686 macro_avg {'precision': 0.9710472628357701, 'recall': 0.9503519009151049, 'f1-score': 0.9593152816682228, 'support': 516} weighted_avg {'precision': 0.964698436169736, 'recall': 0.9631782945736435, 'f1-score': 0.9627652680365858, 'support': 516}
 
time = 0.51 secondes

Val loss 1.3414529412984848 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 19/40
time = 15.93 secondes

Train loss 0.38409668593808555 accuracy 0.9186046719551086 macro_avg {'precision': 0.9089317823783079, 'recall': 0.9177055735253483, 'f1-score': 0.9129050925925927, 'support': 516} weighted_avg {'precision': 0.9201903673569684, 'recall': 0.9186046511627907, 'f1-score': 0.9190364359029574, 'support': 516}
 
time = 0.49 secondes

Val loss 0.9446245655417442 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 20/40
time = 16.12 secondes

Train loss 0.04707739501133223 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 0.51 secondes

Val loss 1.1036700457334518 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 21/40
time = 15.79 secondes

Train loss 0.009351984218510828 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.51 secondes

Val loss 1.7306371331214905 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 22/40
time = 15.57 secondes

Train loss 0.3479974633682463 accuracy 0.9437984228134155 macro_avg {'precision': 0.9594972067039106, 'recall': 0.9224598930481284, 'f1-score': 0.9368647553952281, 'support': 516} weighted_avg {'precision': 0.9483510891689403, 'recall': 0.9437984496124031, 'f1-score': 0.9426225599498413, 'support': 516}
 
time = 0.48 secondes

Val loss 0.9992091874592006 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 23/40
time = 15.72 secondes

Train loss 0.05293145311721177 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 0.52 secondes

Val loss 1.0578662306070328 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 24/40
time = 15.82 secondes

Train loss 0.1093981269408356 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 0.49 secondes

Val loss 1.174094595015049 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 25/40
time = 16.31 secondes

Train loss 0.06081831817000145 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 0.50 secondes

Val loss 0.8113657534122467 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 26/40
time = 16.19 secondes

Train loss 0.017687214224486415 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.51 secondes

Val loss 1.2191552817821503 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 27/40
time = 15.96 secondes

Train loss 0.17339280556982636 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 0.52 secondes

Val loss 1.0568205986346584 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 28/40
time = 18.01 secondes

Train loss 0.10128347138842483 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 0.51 secondes

Val loss 0.8007376089226454 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 29/40
time = 16.83 secondes

Train loss 0.026362332782644608 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 0.49 secondes

Val loss 1.3697749823331833 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 30/40
time = 15.70 secondes

Train loss 0.016012080997990615 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.49 secondes

Val loss 1.258295327425003 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 31/40
time = 15.84 secondes

Train loss 0.023972487085936307 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.49 secondes

Val loss 1.5049920678138733 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 32/40
time = 15.77 secondes

Train loss 0.0012407177418936044 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.49 secondes

Val loss 1.5751837193965912 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 33/40
time = 16.02 secondes

Train loss 0.00485061050946542 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.53 secondes

Val loss 1.3690105825662613 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 34/40
time = 15.89 secondes

Train loss 0.03204983368535371 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.49 secondes

Val loss 1.450488105416298 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 35/40
time = 15.62 secondes

Train loss 0.03943715578784714 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.52 secondes

Val loss 1.6082563996315002 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 36/40
time = 15.71 secondes

Train loss 0.05294996648312504 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.49 secondes

Val loss 1.4278729259967804 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 37/40
time = 15.84 secondes

Train loss 0.009556862803892176 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.48 secondes

Val loss 1.4980215728282928 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 38/40
time = 15.99 secondes

Train loss 0.01645873166544885 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.52 secondes

Val loss 1.4008569046854973 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 39/40
time = 15.55 secondes

Train loss 0.0003001420197754421 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.50 secondes

Val loss 1.5744231045246124 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 40/40
time = 15.60 secondes

Train loss 0.00032377227960916406 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.54 secondes

Val loss 1.5871494114398956 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 15 macro_avg {'precision': 0.8704453441295547, 'recall': 0.8704453441295547, 'f1-score': 0.8704453441295547, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 64}

average train time 14.864006781578064

average val time 0.47893723249435427
 
time = 0.58 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_1
----------
Epoch 1/40
time = 15.73 secondes

Train loss 0.6521028171886097 accuracy 0.6375969052314758 macro_avg {'precision': 0.5690661478599222, 'recall': 0.501154039952538, 'f1-score': 0.39437760078329476, 'support': 516} weighted_avg {'precision': 0.5880727234337766, 'recall': 0.6375968992248062, 'f1-score': 0.49999576707899707, 'support': 516}
 
time = 0.55 secondes

Val loss 0.628048449754715 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 15.32 secondes

Train loss 0.54683984319369 accuracy 0.6976743936538696 macro_avg {'precision': 0.7800770218228499, 'recall': 0.5886579002974497, 'f1-score': 0.560879811468971, 'support': 516} weighted_avg {'precision': 0.7531158014150521, 'recall': 0.6976744186046512, 'f1-score': 0.6283271524872577, 'support': 516}
 
time = 0.49 secondes

Val loss 0.5041516125202179 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 3/40
time = 17.18 secondes

Train loss 0.4351443521904223 accuracy 0.8294573426246643 macro_avg {'precision': 0.8170515392138985, 'recall': 0.8108674804544642, 'f1-score': 0.8137153546989613, 'support': 516} weighted_avg {'precision': 0.8282010782522562, 'recall': 0.8294573643410853, 'f1-score': 0.8286177904935053, 'support': 516}
 
time = 0.51 secondes

Val loss 0.3473462089896202 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 4/40
time = 17.06 secondes

Train loss 0.37204946396928845 accuracy 0.8604651093482971 macro_avg {'precision': 0.8470227304420583, 'recall': 0.8640345886904084, 'f1-score': 0.8530379746835443, 'support': 516} weighted_avg {'precision': 0.8682318280960096, 'recall': 0.8604651162790697, 'f1-score': 0.862129820429791, 'support': 516}
 
time = 0.50 secondes

Val loss 0.46252889931201935 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 5/40
time = 15.42 secondes

Train loss 0.2824774421751499 accuracy 0.9108527302742004 macro_avg {'precision': 0.908906577293674, 'recall': 0.8966240267867303, 'f1-score': 0.9021357301888349, 'support': 516} weighted_avg {'precision': 0.9105713441347348, 'recall': 0.9108527131782945, 'f1-score': 0.9101734677505445, 'support': 516}
 
time = 0.54 secondes

Val loss 0.36663534492254257 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 6/40
time = 15.43 secondes

Train loss 0.19417889991944487 accuracy 0.9379844665527344 macro_avg {'precision': 0.932903141914406, 'recall': 0.932903141914406, 'f1-score': 0.932903141914406, 'support': 516} weighted_avg {'precision': 0.937984496124031, 'recall': 0.937984496124031, 'f1-score': 0.937984496124031, 'support': 516}
 
time = 0.50 secondes

Val loss 0.3482399173080921 accuracy 0.90625 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}
 
----------
Epoch 7/40
time = 15.52 secondes

Train loss 0.20124689498069612 accuracy 0.9418604373931885 macro_avg {'precision': 0.9354973821989528, 'recall': 0.9394047754498318, 'f1-score': 0.9373816805009466, 'support': 516} weighted_avg {'precision': 0.9422403506635821, 'recall': 0.9418604651162791, 'f1-score': 0.9419902849602019, 'support': 516}
 
time = 0.50 secondes

Val loss 0.4872385263442993 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 8/40
time = 15.45 secondes

Train loss 0.24494540228536635 accuracy 0.9282945990562439 macro_avg {'precision': 0.9329844006568144, 'recall': 0.9114558782894202, 'f1-score': 0.9205608837664094, 'support': 516} weighted_avg {'precision': 0.9292846482351294, 'recall': 0.9282945736434108, 'f1-score': 0.9273819021672429, 'support': 516}
 
time = 0.49 secondes

Val loss 0.48606792837381363 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 9/40
time = 15.34 secondes

Train loss 0.1456150637770241 accuracy 0.963178277015686 macro_avg {'precision': 0.9616946045049765, 'recall': 0.9584301805828714, 'f1-score': 0.9600213676084998, 'support': 516} weighted_avg {'precision': 0.963118144976265, 'recall': 0.9631782945736435, 'f1-score': 0.9631129788433301, 'support': 516}
 
time = 0.55 secondes

Val loss 0.7013436332345009 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 10/40
time = 15.54 secondes

Train loss 0.2659206335065943 accuracy 0.9282945990562439 macro_avg {'precision': 0.9200070436063263, 'recall': 0.9264583976724152, 'f1-score': 0.9230257508134063, 'support': 516} weighted_avg {'precision': 0.9292010222412169, 'recall': 0.9282945736434108, 'f1-score': 0.9285677718642259, 'support': 516}
 
time = 0.49 secondes

Val loss 0.8883287981152534 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 11/40
time = 15.43 secondes

Train loss 0.3320716272080035 accuracy 0.9127907156944275 macro_avg {'precision': 0.9046335163061028, 'recall': 0.9073761032459405, 'f1-score': 0.9059671573490999, 'support': 516} weighted_avg {'precision': 0.9131505733230207, 'recall': 0.9127906976744186, 'f1-score': 0.9129379683289218, 'support': 516}
 
time = 0.52 secondes

Val loss 1.0112219005823135 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 12/40
time = 15.47 secondes

Train loss 0.15987917570975807 accuracy 0.963178277015686 macro_avg {'precision': 0.9628051589129434, 'recall': 0.9572761406303334, 'f1-score': 0.95992593410097, 'support': 516} weighted_avg {'precision': 0.9631537461749132, 'recall': 0.9631782945736435, 'f1-score': 0.9630676700677702, 'support': 516}
 
time = 0.58 secondes

Val loss 0.5782497343607247 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 13/40
time = 15.31 secondes

Train loss 0.11851691235576502 accuracy 0.9689922332763672 macro_avg {'precision': 0.9710226613397874, 'recall': 0.9618354111470506, 'f1-score': 0.9661300644907203, 'support': 516} weighted_avg {'precision': 0.9691978595331823, 'recall': 0.9689922480620154, 'f1-score': 0.9688395982715464, 'support': 516}
 
time = 0.49 secondes

Val loss 0.9395258948206902 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 14/40
time = 15.36 secondes

Train loss 0.4876722109849762 accuracy 0.8992248177528381 macro_avg {'precision': 0.8949552522373881, 'recall': 0.8851974058482194, 'f1-score': 0.8896492728828058, 'support': 516} weighted_avg {'precision': 0.898697700773876, 'recall': 0.8992248062015504, 'f1-score': 0.8985948369042644, 'support': 516}
 
time = 0.51 secondes

Val loss 1.4282640665769577 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 15.79 secondes

Train loss 0.29667151750375825 accuracy 0.9360464811325073 macro_avg {'precision': 0.9376386368219398, 'recall': 0.9233051054077337, 'f1-score': 0.929703464874438, 'support': 516} weighted_avg {'precision': 0.9362929119555549, 'recall': 0.936046511627907, 'f1-score': 0.9355145141582613, 'support': 516}
 
time = 0.52 secondes

Val loss 0.901273250579834 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 16/40
time = 15.64 secondes

Train loss 0.09871569063133476 accuracy 0.9670542478561401 macro_avg {'precision': 0.9599294835143892, 'recall': 0.9707020138809876, 'f1-score': 0.9647845199622633, 'support': 516} weighted_avg {'precision': 0.9683604732420003, 'recall': 0.9670542635658915, 'f1-score': 0.967244852723448, 'support': 516}
 
time = 0.49 secondes

Val loss 0.6970617853221484 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 17/40
time = 15.26 secondes

Train loss 0.12101934187001351 accuracy 0.9689922332763672 macro_avg {'precision': 0.9752439373767674, 'recall': 0.9583732912894365, 'f1-score': 0.9658730158730159, 'support': 516} weighted_avg {'precision': 0.9700219380667982, 'recall': 0.9689922480620154, 'f1-score': 0.968712316968131, 'support': 516}
 
time = 0.51 secondes

Val loss 1.3307055607438087 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 18/40
time = 15.39 secondes

Train loss 0.16042370022323943 accuracy 0.9534883499145508 macro_avg {'precision': 0.9439573366794761, 'recall': 0.9600637160086471, 'f1-score': 0.9506377551020408, 'support': 516} weighted_avg {'precision': 0.956725327516492, 'recall': 0.9534883720930233, 'f1-score': 0.9539021713336497, 'support': 516}
 
time = 0.50 secondes

Val loss 0.894675113260746 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 19/40
time = 15.22 secondes

Train loss 0.017339914915448226 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.49 secondes

Val loss 0.697502853901824 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 20/40
time = 15.43 secondes

Train loss 0.04061477846522449 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 0.53 secondes

Val loss 1.199612818658352 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 21/40
time = 15.90 secondes

Train loss 0.015731700021371416 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.50 secondes

Val loss 1.101220041513443 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 22/40
time = 15.92 secondes

Train loss 0.3724358789702158 accuracy 0.9321705102920532 macro_avg {'precision': 0.9298611111111111, 'recall': 0.9225736716349984, 'f1-score': 0.9260002868205937, 'support': 516} weighted_avg {'precision': 0.931963285960379, 'recall': 0.9321705426356589, 'f1-score': 0.9318806648456894, 'support': 516}
 
time = 0.50 secondes

Val loss 1.17018561065197 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 23/40
time = 15.24 secondes

Train loss 0.1472503173060955 accuracy 0.9689922332763672 macro_avg {'precision': 0.9605911330049262, 'recall': 0.9756838905775076, 'f1-score': 0.9670261202971483, 'support': 516} weighted_avg {'precision': 0.9714362088058961, 'recall': 0.9689922480620154, 'f1-score': 0.9692419150797764, 'support': 516}
 
time = 0.50 secondes

Val loss 0.9616588801145554 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 24/40
time = 15.25 secondes

Train loss 0.07188182418890805 accuracy 0.9844961166381836 macro_avg {'precision': 0.9867898078667436, 'recall': 0.9797636656209873, 'f1-score': 0.9831063383970666, 'support': 516} weighted_avg {'precision': 0.9846748526415846, 'recall': 0.9844961240310077, 'f1-score': 0.9844397813701723, 'support': 516}
 
time = 0.56 secondes

Val loss 1.674562245607376 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 25/40
time = 15.40 secondes

Train loss 0.21184843604031345 accuracy 0.9651162624359131 macro_avg {'precision': 0.9655149666034468, 'recall': 0.9587958974692392, 'f1-score': 0.9619892613933996, 'support': 516} weighted_avg {'precision': 0.9651473456308333, 'recall': 0.9651162790697675, 'f1-score': 0.9649895080828875, 'support': 516}
 
time = 0.51 secondes

Val loss 1.450227439403534 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 26/40
time = 15.40 secondes

Train loss 0.09911691583516641 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 0.53 secondes

Val loss 1.0457831770181656 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 27/40
time = 17.33 secondes

Train loss 0.10767687208223806 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 0.52 secondes

Val loss 1.1994261220097542 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 28/40
time = 16.87 secondes

Train loss 0.06186445462905491 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.49 secondes

Val loss 1.2844854965806007 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 29/40
time = 15.51 secondes

Train loss 0.032371954321261553 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.54 secondes

Val loss 1.757397472858429 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 30/40
time = 15.23 secondes

Train loss 0.04300440704471178 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.54 secondes

Val loss 1.5983220785856247 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 31/40
time = 15.20 secondes

Train loss 0.034094060018436394 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 0.44 secondes

Val loss 1.3949481844902039 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 32/40
time = 16.48 secondes

Train loss 0.021810512885470718 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 0.60 secondes

Val loss 1.8207805007696152 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 33/40
time = 15.96 secondes

Train loss 0.023278859101110633 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.52 secondes

Val loss 1.199673369526863 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 34/40
time = 15.81 secondes

Train loss 0.006237012790568935 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.51 secondes

Val loss 1.6442071199417114 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 35/40
time = 15.35 secondes

Train loss 0.12446052896694075 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 0.51 secondes

Val loss 1.9595113694667816 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 36/40
time = 15.38 secondes

Train loss 9.361738369934204e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.50 secondes

Val loss 1.2776632457971573 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 37/40
time = 15.35 secondes

Train loss 0.06042611329669881 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 0.50 secondes

Val loss 1.2928082793951035 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 38/40
time = 15.55 secondes

Train loss 0.00012322442754256454 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.53 secondes

Val loss 1.2258716896176338 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 39/40
time = 15.94 secondes

Train loss 0.012169567741776436 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.50 secondes

Val loss 1.251491367816925 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 40/40
time = 18.52 secondes

Train loss 0.00010365405085560104 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.51 secondes

Val loss 1.1002135500311852 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 6 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}

average train time 15.74707052707672

average val time 0.5135234832763672
 
time = 0.56 secondes

test_accuracy 0.9230769276618958 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9074074074074074, 'f1-score': 0.9181153943058704, 'support': 65} weighted_avg {'precision': 0.9320214669051878, 'recall': 0.9230769230769231, 'f1-score': 0.9215264453359691, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_1
----------
Epoch 1/40
time = 15.86 secondes

Train loss 0.6526197140867059 accuracy 0.6143410801887512 macro_avg {'precision': 0.503931544865865, 'recall': 0.501381597126278, 'f1-score': 0.44843071006139645, 'support': 516} weighted_avg {'precision': 0.5409083249073137, 'recall': 0.6143410852713178, 'f1-score': 0.5316790255377528, 'support': 516}
 
time = 0.57 secondes

Val loss 0.6312668770551682 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 15.25 secondes

Train loss 0.5690703888734182 accuracy 0.6744186282157898 macro_avg {'precision': 0.7719755600814664, 'recall': 0.5542642588950474, 'f1-score': 0.5013345605154165, 'support': 516} weighted_avg {'precision': 0.7422479041348932, 'recall': 0.6744186046511628, 'f1-score': 0.5821830284998769, 'support': 516}
 
time = 0.49 secondes

Val loss 0.6328044310212135 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 3/40
time = 15.37 secondes

Train loss 0.4210562218319286 accuracy 0.8236433863639832 macro_avg {'precision': 0.8084939489018377, 'recall': 0.8132324496529753, 'f1-score': 0.8106849547032428, 'support': 516} weighted_avg {'precision': 0.8253003832535901, 'recall': 0.8236434108527132, 'f1-score': 0.8243153308012043, 'support': 516}
 
time = 0.50 secondes

Val loss 0.5771171674132347 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 4/40
time = 15.15 secondes

Train loss 0.29059525940454367 accuracy 0.893410861492157 macro_avg {'precision': 0.887202380952381, 'recall': 0.880638135331502, 'f1-score': 0.8837147364323616, 'support': 516} weighted_avg {'precision': 0.8928536821705426, 'recall': 0.8934108527131783, 'f1-score': 0.8929553304717976, 'support': 516}
 
time = 0.57 secondes

Val loss 0.46151573583483696 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 5/40
time = 15.25 secondes

Train loss 0.2564642609407504 accuracy 0.9205426573753357 macro_avg {'precision': 0.9191510695187166, 'recall': 0.9076849308388732, 'f1-score': 0.9128834204252061, 'support': 516} weighted_avg {'precision': 0.9203559621523029, 'recall': 0.9205426356589147, 'f1-score': 0.9199919731257723, 'support': 516}
 
time = 0.52 secondes

Val loss 0.4925745502114296 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 6/40
time = 15.10 secondes

Train loss 0.3784245044896097 accuracy 0.854651153087616 macro_avg {'precision': 0.8439659143251959, 'recall': 0.8398566389805439, 'f1-score': 0.8418128977669866, 'support': 516} weighted_avg {'precision': 0.8539481859179673, 'recall': 0.8546511627906976, 'f1-score': 0.854214487109619, 'support': 516}
 
time = 0.53 secondes

Val loss 0.9956193715333939 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 7/40
time = 15.16 secondes

Train loss 0.16979059713864417 accuracy 0.9534883499145508 macro_avg {'precision': 0.9496773564358045, 'recall': 0.9496773564358045, 'f1-score': 0.9496773564358045, 'support': 516} weighted_avg {'precision': 0.9534883720930233, 'recall': 0.9534883720930233, 'f1-score': 0.9534883720930233, 'support': 516}
 
time = 0.51 secondes

Val loss 0.8487242758274078 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 8/40
time = 15.28 secondes

Train loss 0.1774346839749452 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 0.53 secondes

Val loss 0.47660934180021286 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 9/40
time = 15.33 secondes

Train loss 0.23804370309649545 accuracy 0.9379844665527344 macro_avg {'precision': 0.9368068564229233, 'recall': 0.9282869821042536, 'f1-score': 0.9322601289814404, 'support': 516} weighted_avg {'precision': 0.9378652414707542, 'recall': 0.937984496124031, 'f1-score': 0.9376791965430928, 'support': 516}
 
time = 0.49 secondes

Val loss 1.2045360505580902 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 15.31 secondes

Train loss 0.149623142837575 accuracy 0.9554263353347778 macro_avg {'precision': 0.9638752052545156, 'recall': 0.9408107537018676, 'f1-score': 0.950618927746687, 'support': 516} weighted_avg {'precision': 0.9572100024185028, 'recall': 0.9554263565891473, 'f1-score': 0.954859020266124, 'support': 516}
 
time = 0.49 secondes

Val loss 0.7359544038772583 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 11/40
time = 15.48 secondes

Train loss 0.13404714843173596 accuracy 0.9709302186965942 macro_avg {'precision': 0.9690615835777125, 'recall': 0.9679713277961088, 'f1-score': 0.9685118812727058, 'support': 516} weighted_avg {'precision': 0.970904279100078, 'recall': 0.9709302325581395, 'f1-score': 0.970913321010689, 'support': 516}
 
time = 0.50 secondes

Val loss 1.4302899092435837 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 12/40
time = 15.17 secondes

Train loss 0.25577435417411226 accuracy 0.9437984228134155 macro_avg {'precision': 0.9379560865353568, 'recall': 0.9409245322887376, 'f1-score': 0.9394010569583089, 'support': 516} weighted_avg {'precision': 0.9440562009246258, 'recall': 0.9437984496124031, 'f1-score': 0.9438933573675274, 'support': 516}
 
time = 0.51 secondes

Val loss 0.8123436346650124 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 13/40
time = 15.26 secondes

Train loss 0.13983612304384058 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 0.51 secondes

Val loss 0.6312096483306959 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 14/40
time = 15.29 secondes

Train loss 0.38513540657886275 accuracy 0.9127907156944275 macro_avg {'precision': 0.9046335163061028, 'recall': 0.9073761032459405, 'f1-score': 0.9059671573490999, 'support': 516} weighted_avg {'precision': 0.9131505733230207, 'recall': 0.9127906976744186, 'f1-score': 0.9129379683289218, 'support': 516}
 
time = 0.50 secondes

Val loss 1.3679458796977997 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 15/40
time = 15.16 secondes

Train loss 0.2357301508062378 accuracy 0.9476743936538696 macro_avg {'precision': 0.9583910753880266, 'recall': 0.9301155665360923, 'f1-score': 0.9417146729922061, 'support': 516} weighted_avg {'precision': 0.9502965793069665, 'recall': 0.9476744186046512, 'f1-score': 0.9468436661859467, 'support': 516}
 
time = 0.49 secondes

Val loss 0.6888693086802959 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 16/40
time = 15.14 secondes

Train loss 0.14373373921085714 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 0.49 secondes

Val loss 0.600094374269247 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 17/40
time = 15.96 secondes

Train loss 0.21370121941436082 accuracy 0.9437984228134155 macro_avg {'precision': 0.9426587301587301, 'recall': 0.9351543325260472, 'f1-score': 0.9386859519370634, 'support': 516} weighted_avg {'precision': 0.9436961670973298, 'recall': 0.9437984496124031, 'f1-score': 0.9435582651578568, 'support': 516}
 
time = 0.54 secondes

Val loss 0.7555860355496407 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 18/40
time = 17.62 secondes

Train loss 0.07068626955857105 accuracy 0.9806201457977295 macro_avg {'precision': 0.9790322318482518, 'recall': 0.9790322318482518, 'f1-score': 0.9790322318482518, 'support': 516} weighted_avg {'precision': 0.9806201550387597, 'recall': 0.9806201550387597, 'f1-score': 0.9806201550387597, 'support': 516}
 
time = 0.52 secondes

Val loss 0.8254535458981991 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 19/40
time = 16.23 secondes

Train loss 0.03372203405226835 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 0.49 secondes

Val loss 0.9083893773931777 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 20/40
time = 15.20 secondes

Train loss 0.16080194301409365 accuracy 0.963178277015686 macro_avg {'precision': 0.9579475308641976, 'recall': 0.9630463403930237, 'f1-score': 0.9603857980419174, 'support': 516} weighted_avg {'precision': 0.9635745645516317, 'recall': 0.9631782945736435, 'f1-score': 0.9632802105054582, 'support': 516}
 
time = 0.54 secondes

Val loss 0.8099442981183529 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 21/40
time = 15.20 secondes

Train loss 0.0393160743652984 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 0.53 secondes

Val loss 0.715918862784747 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 22/40
time = 15.03 secondes

Train loss 0.06731004566377537 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 0.52 secondes

Val loss 1.3878135904669762 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 23/40
time = 15.13 secondes

Train loss 0.32292595553338865 accuracy 0.9360464811325073 macro_avg {'precision': 0.9276785714285715, 'recall': 0.9359995448856525, 'f1-score': 0.93149533123866, 'support': 516} weighted_avg {'precision': 0.9372612126245847, 'recall': 0.936046511627907, 'f1-score': 0.9363544862407133, 'support': 516}
 
time = 0.52 secondes

Val loss 0.9882924109697342 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 24/40
time = 15.07 secondes

Train loss 0.04861439738747184 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 0.52 secondes

Val loss 1.2360263168811798 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 25/40
time = 14.94 secondes

Train loss 0.027073134512950976 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 0.52 secondes

Val loss 0.7343165874481201 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 26/40
time = 15.11 secondes

Train loss 0.07798762060349074 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 0.51 secondes

Val loss 0.881963774561882 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 27/40
time = 15.28 secondes

Train loss 0.06888424664749905 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 0.50 secondes

Val loss 0.9281606897711754 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 28/40
time = 15.07 secondes

Train loss 0.015246792636444849 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.51 secondes

Val loss 0.885535717010498 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 29/40
time = 15.40 secondes

Train loss 0.005844348264156107 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.50 secondes

Val loss 0.9586604535579681 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 30/40
time = 15.47 secondes

Train loss 0.03203589223619818 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.55 secondes

Val loss 1.2708243131637573 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 31/40
time = 15.09 secondes

Train loss 0.013498394786438439 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.54 secondes

Val loss 0.9750786359909398 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 32/40
time = 15.08 secondes

Train loss 0.04469414363627562 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 0.57 secondes

Val loss 1.8110402524471283 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 33/40
time = 15.09 secondes

Train loss 0.030739721022793234 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 0.50 secondes

Val loss 1.844399854540825 accuracy 0.75 macro_avg {'precision': 0.7658730158730158, 'recall': 0.771255060728745, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.7896825396825398, 'recall': 0.75, 'f1-score': 0.7512218963831867, 'support': 64}
 
----------
Epoch 34/40
time = 15.42 secondes

Train loss 0.05816493709889156 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.55 secondes

Val loss 0.92239439568948 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 35/40
time = 15.55 secondes

Train loss 0.030984816165459273 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 0.50 secondes

Val loss 0.7257545984757598 accuracy 0.921875 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}
 
----------
Epoch 36/40
time = 15.81 secondes

Train loss 0.01591785053218094 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.50 secondes

Val loss 1.2548086792230606 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 37/40
time = 15.34 secondes

Train loss 0.00017420089209212386 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.50 secondes

Val loss 0.8089485988020897 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 38/40
time = 16.34 secondes

Train loss 0.00018871922679174918 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.51 secondes

Val loss 1.163941204547882 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 39/40
time = 16.99 secondes

Train loss 0.00028965537763504085 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.53 secondes

Val loss 1.1149426996707916 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 40/40
time = 15.52 secondes

Train loss 0.00011148778029371786 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.53 secondes

Val loss 0.945868656039238 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 35 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}

average train time 15.437897217273711

average val time 0.5173777639865875
 
time = 0.57 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_none_2
----------
Epoch 1/40
time = 307.39 secondes

Train loss 1.2939576355731657 accuracy 0.6737380027770996 macro_avg {'precision': 0.6802212800602707, 'recall': 0.6575997731259353, 'f1-score': 0.650865939473951, 'support': 10182} weighted_avg {'precision': 0.6872353001693964, 'recall': 0.67373796896484, 'f1-score': 0.6653587256683803, 'support': 10182}
 
time = 8.22 secondes

Val loss 0.6245732855209163 accuracy 0.8215547800064087 macro_avg {'precision': 0.8055011499463204, 'recall': 0.8140509719302882, 'f1-score': 0.8023723360740238, 'support': 1132} weighted_avg {'precision': 0.8163276564303512, 'recall': 0.8215547703180212, 'f1-score': 0.8116300056018562, 'support': 1132}
 
----------
Epoch 2/40
time = 304.21 secondes

Train loss 0.45332559815708845 accuracy 0.8675113320350647 macro_avg {'precision': 0.8568393486994346, 'recall': 0.8553258110494543, 'f1-score': 0.8524297901168104, 'support': 10182} weighted_avg {'precision': 0.8646832859375679, 'recall': 0.8675112944411707, 'f1-score': 0.8634108416669946, 'support': 10182}
 
time = 7.76 secondes

Val loss 0.47446284841903497 accuracy 0.8657243847846985 macro_avg {'precision': 0.8624996625697945, 'recall': 0.8615677666893777, 'f1-score': 0.8568472543429809, 'support': 1132} weighted_avg {'precision': 0.870717618199977, 'recall': 0.8657243816254417, 'f1-score': 0.8630941568981029, 'support': 1132}
 
----------
Epoch 3/40
time = 303.68 secondes

Train loss 0.28902300931162417 accuracy 0.9198585748672485 macro_avg {'precision': 0.9145112656642042, 'recall': 0.913053293261439, 'f1-score': 0.9134202191853438, 'support': 10182} weighted_avg {'precision': 0.919294783569784, 'recall': 0.9198585739540366, 'f1-score': 0.9192758778296702, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.4712714188876496 accuracy 0.8860424160957336 macro_avg {'precision': 0.8875306501748179, 'recall': 0.8833995446632275, 'f1-score': 0.8812750813803802, 'support': 1132} weighted_avg {'precision': 0.8926563550996814, 'recall': 0.8860424028268551, 'f1-score': 0.8853677847266296, 'support': 1132}
 
----------
Epoch 4/40
time = 302.30 secondes

Train loss 0.21491624082305602 accuracy 0.9454920887947083 macro_avg {'precision': 0.9423658504647643, 'recall': 0.9416529359577728, 'f1-score': 0.9419057859400116, 'support': 10182} weighted_avg {'precision': 0.9455761176388208, 'recall': 0.9454920447849146, 'f1-score': 0.9454369176431281, 'support': 10182}
 
time = 7.90 secondes

Val loss 0.4931063304825778 accuracy 0.8922261595726013 macro_avg {'precision': 0.8978376816462988, 'recall': 0.8896333891835699, 'f1-score': 0.8903611269329771, 'support': 1132} weighted_avg {'precision': 0.8977282391139901, 'recall': 0.892226148409894, 'f1-score': 0.8918981319943077, 'support': 1132}
 
----------
Epoch 5/40
time = 303.45 secondes

Train loss 0.1929517158923387 accuracy 0.9529561996459961 macro_avg {'precision': 0.9507121368247722, 'recall': 0.9502275333039046, 'f1-score': 0.9503602691539987, 'support': 10182} weighted_avg {'precision': 0.9532687813152998, 'recall': 0.9529561972107641, 'f1-score': 0.953004823872251, 'support': 10182}
 
time = 7.96 secondes

Val loss 0.4462692226171756 accuracy 0.9054770469665527 macro_avg {'precision': 0.9069106879066439, 'recall': 0.9086217464823004, 'f1-score': 0.90578059996072, 'support': 1132} weighted_avg {'precision': 0.9078518531327685, 'recall': 0.9054770318021201, 'f1-score': 0.9045108450101863, 'support': 1132}
 
----------
Epoch 6/40
time = 303.14 secondes

Train loss 0.16086626728832887 accuracy 0.961009681224823 macro_avg {'precision': 0.9596069595742819, 'recall': 0.9599298271615841, 'f1-score': 0.9597138701798787, 'support': 10182} weighted_avg {'precision': 0.9609399110375586, 'recall': 0.961009624828128, 'f1-score': 0.9609222349848496, 'support': 10182}
 
time = 7.85 secondes

Val loss 0.48749238938342415 accuracy 0.9063604474067688 macro_avg {'precision': 0.9117914499619506, 'recall': 0.9073284147534197, 'f1-score': 0.9076942509975264, 'support': 1132} weighted_avg {'precision': 0.9105590535628427, 'recall': 0.9063604240282686, 'f1-score': 0.906534522752469, 'support': 1132}
 
----------
Epoch 7/40
time = 305.92 secondes

Train loss 0.1470743791343501 accuracy 0.9656256437301636 macro_avg {'precision': 0.9648731028213907, 'recall': 0.9646826148709777, 'f1-score': 0.9647263034818143, 'support': 10182} weighted_avg {'precision': 0.9657355129632806, 'recall': 0.9656256138283245, 'f1-score': 0.9656308435545577, 'support': 10182}
 
time = 7.87 secondes

Val loss 0.5972520319825287 accuracy 0.8975265026092529 macro_avg {'precision': 0.9079132270497627, 'recall': 0.8964550975526608, 'f1-score': 0.8990543337776187, 'support': 1132} weighted_avg {'precision': 0.9059771546267148, 'recall': 0.8975265017667845, 'f1-score': 0.8983509621350398, 'support': 1132}
 
----------
Epoch 8/40
time = 303.42 secondes

Train loss 0.1376420815950084 accuracy 0.971420168876648 macro_avg {'precision': 0.9700516007033556, 'recall': 0.9703312894350496, 'f1-score': 0.9701255801435884, 'support': 10182} weighted_avg {'precision': 0.9715459299089612, 'recall': 0.9714201532115498, 'f1-score': 0.9714278196969671, 'support': 10182}
 
time = 7.95 secondes

Val loss 0.639765087037567 accuracy 0.8957597017288208 macro_avg {'precision': 0.8975078254146783, 'recall': 0.8965578169783395, 'f1-score': 0.8945082515021093, 'support': 1132} weighted_avg {'precision': 0.8991438507049017, 'recall': 0.8957597173144877, 'f1-score': 0.8948630789324803, 'support': 1132}
 
----------
Epoch 9/40
time = 303.82 secondes

Train loss 0.13943793637473523 accuracy 0.9731879830360413 macro_avg {'precision': 0.9723550137527857, 'recall': 0.9721703325298856, 'f1-score': 0.972222896864198, 'support': 10182} weighted_avg {'precision': 0.9732129616370456, 'recall': 0.9731879787860931, 'f1-score': 0.9731597116392822, 'support': 10182}
 
time = 7.84 secondes

Val loss 0.5332711139844705 accuracy 0.9125441908836365 macro_avg {'precision': 0.9146277766017998, 'recall': 0.9125631951683415, 'f1-score': 0.912514428185905, 'support': 1132} weighted_avg {'precision': 0.9159656131267084, 'recall': 0.9125441696113075, 'f1-score': 0.9131868351513136, 'support': 1132}
 
----------
Epoch 10/40
time = 304.61 secondes

Train loss 0.12326535520771024 accuracy 0.9751522541046143 macro_avg {'precision': 0.9744171185995294, 'recall': 0.9741298157370517, 'f1-score': 0.9742156783252158, 'support': 10182} weighted_avg {'precision': 0.9751406774515563, 'recall': 0.9751522294244745, 'f1-score': 0.9750908505981273, 'support': 10182}
 
time = 7.76 secondes

Val loss 0.6447713094301076 accuracy 0.9001767039299011 macro_avg {'precision': 0.9044954346332741, 'recall': 0.9040439002505176, 'f1-score': 0.9005926444347487, 'support': 1132} weighted_avg {'precision': 0.9082373471264726, 'recall': 0.9001766784452296, 'f1-score': 0.9001916039418207, 'support': 1132}
 
----------
Epoch 11/40
time = 303.75 secondes

Train loss 0.10894380923543524 accuracy 0.9780986309051514 macro_avg {'precision': 0.9772497512932828, 'recall': 0.9772344373591773, 'f1-score': 0.9772096389735591, 'support': 10182} weighted_avg {'precision': 0.9781855228478457, 'recall': 0.9780986053820467, 'f1-score': 0.9781110433483634, 'support': 10182}
 
time = 7.90 secondes

Val loss 0.767275440474254 accuracy 0.8975265026092529 macro_avg {'precision': 0.9022150618033311, 'recall': 0.896717736394676, 'f1-score': 0.8959006734790694, 'support': 1132} weighted_avg {'precision': 0.902153427506617, 'recall': 0.8975265017667845, 'f1-score': 0.8965400121752841, 'support': 1132}
 
----------
Epoch 12/40
time = 303.81 secondes

Train loss 0.11634666326133117 accuracy 0.9771165251731873 macro_avg {'precision': 0.975905339316016, 'recall': 0.975368963277503, 'f1-score': 0.9755858623753951, 'support': 10182} weighted_avg {'precision': 0.9771546727457299, 'recall': 0.977116480062856, 'f1-score': 0.9770868107118694, 'support': 10182}
 
time = 7.82 secondes

Val loss 0.6753904554887566 accuracy 0.9063604474067688 macro_avg {'precision': 0.9130384638676837, 'recall': 0.9072940274875061, 'f1-score': 0.9082550733565785, 'support': 1132} weighted_avg {'precision': 0.9099511212529602, 'recall': 0.9063604240282686, 'f1-score': 0.9062442394837413, 'support': 1132}
 
----------
Epoch 13/40
time = 305.77 secondes

Train loss 0.10590423744831057 accuracy 0.980553925037384 macro_avg {'precision': 0.9794128268983873, 'recall': 0.9794339829844271, 'f1-score': 0.9794055178756003, 'support': 10182} weighted_avg {'precision': 0.98059497376354, 'recall': 0.9805539186800236, 'f1-score': 0.9805560012502381, 'support': 10182}
 
time = 7.73 secondes

Val loss 0.8553219720845039 accuracy 0.8869258165359497 macro_avg {'precision': 0.8997789422068884, 'recall': 0.8941109981052607, 'f1-score': 0.8894071276390371, 'support': 1132} weighted_avg {'precision': 0.9015639439673931, 'recall': 0.8869257950530035, 'f1-score': 0.8861518506605071, 'support': 1132}
 
----------
Epoch 14/40
time = 304.43 secondes

Train loss 0.10345571131862241 accuracy 0.980455756187439 macro_avg {'precision': 0.9800873122602234, 'recall': 0.9801308369167134, 'f1-score': 0.9800844580280696, 'support': 10182} weighted_avg {'precision': 0.9804913386799431, 'recall': 0.9804557061481045, 'f1-score': 0.9804497145521798, 'support': 10182}
 
time = 7.82 secondes

Val loss 0.7797888501159499 accuracy 0.8966431021690369 macro_avg {'precision': 0.8971876875084351, 'recall': 0.8982660409345611, 'f1-score': 0.8942594748025121, 'support': 1132} weighted_avg {'precision': 0.9019918880589344, 'recall': 0.8966431095406361, 'f1-score': 0.8961709319279649, 'support': 1132}
 
----------
Epoch 15/40
time = 302.86 secondes

Train loss 0.10236474894091532 accuracy 0.9803575277328491 macro_avg {'precision': 0.9794852704279025, 'recall': 0.979738716411511, 'f1-score': 0.9795678810440144, 'support': 10182} weighted_avg {'precision': 0.9804605701675876, 'recall': 0.9803574936161854, 'f1-score': 0.9803691241480311, 'support': 10182}
 
time = 7.91 secondes

Val loss 0.7441550598954897 accuracy 0.898409903049469 macro_avg {'precision': 0.90051622949976, 'recall': 0.9009297954956967, 'f1-score': 0.8983605678115906, 'support': 1132} weighted_avg {'precision': 0.9032052200665471, 'recall': 0.8984098939929329, 'f1-score': 0.8985186999555411, 'support': 1132}
 
----------
Epoch 16/40
time = 304.90 secondes

Train loss 0.09983642694253488 accuracy 0.9818307161331177 macro_avg {'precision': 0.9813273131204895, 'recall': 0.9812695362794477, 'f1-score': 0.9812559371628785, 'support': 10182} weighted_avg {'precision': 0.9818809343653255, 'recall': 0.9818306815949716, 'f1-score': 0.9818134749293642, 'support': 10182}
 
time = 8.41 secondes

Val loss 0.6725841275608769 accuracy 0.9107773900032043 macro_avg {'precision': 0.912141215974579, 'recall': 0.9146380439124602, 'f1-score': 0.9116888424541424, 'support': 1132} weighted_avg {'precision': 0.9157525888377083, 'recall': 0.9107773851590106, 'f1-score': 0.9116600672737574, 'support': 1132}
 
----------
Epoch 17/40
time = 303.55 secondes

Train loss 0.08146494512894296 accuracy 0.9847770929336548 macro_avg {'precision': 0.9840762035627832, 'recall': 0.9843062286353202, 'f1-score': 0.9841588527425568, 'support': 10182} weighted_avg {'precision': 0.9848455311375426, 'recall': 0.9847770575525437, 'f1-score': 0.9847831002256076, 'support': 10182}
 
time = 7.79 secondes

Val loss 0.8187082709158807 accuracy 0.9037102460861206 macro_avg {'precision': 0.9059499830125013, 'recall': 0.9075987251165906, 'f1-score': 0.9037623225942607, 'support': 1132} weighted_avg {'precision': 0.9103970931995312, 'recall': 0.9037102473498233, 'f1-score': 0.9039460129556737, 'support': 1132}
 
----------
Epoch 18/40
time = 306.66 secondes

Train loss 0.07933113485630874 accuracy 0.9864466786384583 macro_avg {'precision': 0.9855133675250523, 'recall': 0.9854213202783724, 'f1-score': 0.9854578546933608, 'support': 10182} weighted_avg {'precision': 0.9864619175413657, 'recall': 0.986446670595168, 'f1-score': 0.9864446848156315, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.7084931753737512 accuracy 0.9090105891227722 macro_avg {'precision': 0.9101490282268265, 'recall': 0.9120069900260626, 'f1-score': 0.9100182682905424, 'support': 1132} weighted_avg {'precision': 0.9110572676750658, 'recall': 0.9090106007067138, 'f1-score': 0.9090117303439829, 'support': 1132}
 
----------
Epoch 19/40
time = 301.51 secondes

Train loss 0.08251336899851154 accuracy 0.9864466786384583 macro_avg {'precision': 0.9865563746247952, 'recall': 0.9865778559963528, 'f1-score': 0.9865553372869529, 'support': 10182} weighted_avg {'precision': 0.9864972953142219, 'recall': 0.986446670595168, 'f1-score': 0.9864600273531403, 'support': 10182}
 
time = 7.82 secondes

Val loss 0.6993827468467201 accuracy 0.9107773900032043 macro_avg {'precision': 0.9132274304585032, 'recall': 0.9130748391980703, 'f1-score': 0.9115811555269125, 'support': 1132} weighted_avg {'precision': 0.9132080387980115, 'recall': 0.9107773851590106, 'f1-score': 0.9103819733300159, 'support': 1132}
 
----------
Epoch 20/40
time = 303.49 secondes

Train loss 0.07197901094465978 accuracy 0.9869377613067627 macro_avg {'precision': 0.9869961539263704, 'recall': 0.9867961425212946, 'f1-score': 0.9868774214427278, 'support': 10182} weighted_avg {'precision': 0.9869817967402134, 'recall': 0.9869377332547633, 'f1-score': 0.9869409404079333, 'support': 10182}
 
time = 8.02 secondes

Val loss 0.8241028934653641 accuracy 0.8931095600128174 macro_avg {'precision': 0.9101561753705016, 'recall': 0.8997554922522666, 'f1-score': 0.8979557594488374, 'support': 1132} weighted_avg {'precision': 0.9146903635445138, 'recall': 0.8931095406360424, 'f1-score': 0.8968255931795044, 'support': 1132}
 
----------
Epoch 21/40
time = 298.97 secondes

Train loss 0.08203420181301081 accuracy 0.9850717186927795 macro_avg {'precision': 0.9849278500610694, 'recall': 0.984915448849821, 'f1-score': 0.9848850150506957, 'support': 10182} weighted_avg {'precision': 0.9851123717703733, 'recall': 0.985071695148301, 'f1-score': 0.985054712183634, 'support': 10182}
 
time = 8.12 secondes

Val loss 0.7163356101159031 accuracy 0.9116607904434204 macro_avg {'precision': 0.9121958128890121, 'recall': 0.9147188714035629, 'f1-score': 0.9115377963000055, 'support': 1132} weighted_avg {'precision': 0.9167611737806407, 'recall': 0.911660777385159, 'f1-score': 0.9122506387619103, 'support': 1132}
 
----------
Epoch 22/40
time = 303.29 secondes

Train loss 0.059787140211885983 accuracy 0.989589512348175 macro_avg {'precision': 0.9891252033022171, 'recall': 0.989076664891258, 'f1-score': 0.9890967305113596, 'support': 10182} weighted_avg {'precision': 0.9896005181789317, 'recall': 0.9895894716165783, 'f1-score': 0.9895906090839011, 'support': 10182}
 
time = 7.73 secondes

Val loss 0.703432681626996 accuracy 0.9143109321594238 macro_avg {'precision': 0.9214603530130188, 'recall': 0.9178394335449443, 'f1-score': 0.9172365430424521, 'support': 1132} weighted_avg {'precision': 0.9215569141968374, 'recall': 0.9143109540636042, 'f1-score': 0.9153091019811195, 'support': 1132}
 
----------
Epoch 23/40
time = 300.20 secondes

Train loss 0.050258539198299985 accuracy 0.9914555549621582 macro_avg {'precision': 0.991193822876383, 'recall': 0.9912173150530921, 'f1-score': 0.9911958977958173, 'support': 10182} weighted_avg {'precision': 0.9914694105371521, 'recall': 0.9914555097230406, 'f1-score': 0.9914527276204995, 'support': 10182}
 
time = 7.67 secondes

Val loss 0.7440438789228825 accuracy 0.9107773900032043 macro_avg {'precision': 0.913615160448729, 'recall': 0.9145709053592042, 'f1-score': 0.9123035461774508, 'support': 1132} weighted_avg {'precision': 0.9151058083145447, 'recall': 0.9107773851590106, 'f1-score': 0.9111787137206944, 'support': 1132}
 
----------
Epoch 24/40
time = 307.20 secondes

Train loss 0.0765166764061262 accuracy 0.9879198670387268 macro_avg {'precision': 0.9880540654366925, 'recall': 0.987863574238518, 'f1-score': 0.9879294153252781, 'support': 10182} weighted_avg {'precision': 0.9879881521294487, 'recall': 0.987919858573954, 'f1-score': 0.9879239692608993, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.7245105306727977 accuracy 0.9125441908836365 macro_avg {'precision': 0.9136147487958945, 'recall': 0.9146427443164049, 'f1-score': 0.9124602187272737, 'support': 1132} weighted_avg {'precision': 0.9156321994468402, 'recall': 0.9125441696113075, 'f1-score': 0.9126829919576174, 'support': 1132}
 
----------
Epoch 25/40
time = 303.28 secondes

Train loss 0.0639551625651479 accuracy 0.9889020323753357 macro_avg {'precision': 0.988372321567131, 'recall': 0.9886961759117178, 'f1-score': 0.98851918791059, 'support': 10182} weighted_avg {'precision': 0.9889464337238353, 'recall': 0.9889019838931448, 'f1-score': 0.9889119893889511, 'support': 10182}
 
time = 7.78 secondes

Val loss 0.8484462634309828 accuracy 0.9028268456459045 macro_avg {'precision': 0.9071247138515206, 'recall': 0.9075591586605372, 'f1-score': 0.9055023529835811, 'support': 1132} weighted_avg {'precision': 0.9067562679234583, 'recall': 0.9028268551236749, 'f1-score': 0.9027410429303899, 'support': 1132}
 
----------
Epoch 26/40
time = 300.93 secondes

Train loss 0.05300829038215385 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913805901963745, 'recall': 0.9913746155443874, 'f1-score': 0.9913705954297252, 'support': 10182} weighted_avg {'precision': 0.9914773773629579, 'recall': 0.9914555097230406, 'f1-score': 0.9914594164046721, 'support': 10182}
 
time = 7.96 secondes

Val loss 0.726459628073019 accuracy 0.9081271886825562 macro_avg {'precision': 0.9113125120024816, 'recall': 0.9104257667095418, 'f1-score': 0.9086904620631081, 'support': 1132} weighted_avg {'precision': 0.9143804267860547, 'recall': 0.9081272084805654, 'f1-score': 0.9091972927190142, 'support': 1132}
 
----------
Epoch 27/40
time = 305.36 secondes

Train loss 0.054560220646037334 accuracy 0.9915537238121033 macro_avg {'precision': 0.9914408553573623, 'recall': 0.9915092288695625, 'f1-score': 0.9914667815278735, 'support': 10182} weighted_avg {'precision': 0.9915792513151368, 'recall': 0.9915537222549597, 'f1-score': 0.9915584105084768, 'support': 10182}
 
time = 7.86 secondes

Val loss 0.8698433408787077 accuracy 0.8939929604530334 macro_avg {'precision': 0.9008852100870017, 'recall': 0.8963063818551216, 'f1-score': 0.8942933164862905, 'support': 1132} weighted_avg {'precision': 0.905461119877014, 'recall': 0.8939929328621908, 'f1-score': 0.8958496753981372, 'support': 1132}
 
----------
Epoch 28/40
time = 302.44 secondes

Train loss 0.053570121396938813 accuracy 0.9913573265075684 macro_avg {'precision': 0.9913280212393785, 'recall': 0.9911751237389718, 'f1-score': 0.9912346516820214, 'support': 10182} weighted_avg {'precision': 0.9913832677079448, 'recall': 0.9913572971911215, 'f1-score': 0.9913537105685096, 'support': 10182}
 
time = 7.79 secondes

Val loss 0.7792568869527444 accuracy 0.9072438478469849 macro_avg {'precision': 0.9129934402668974, 'recall': 0.9113391406964997, 'f1-score': 0.9107693898798794, 'support': 1132} weighted_avg {'precision': 0.9123946182497428, 'recall': 0.907243816254417, 'f1-score': 0.9083890807862166, 'support': 1132}
 
----------
Epoch 29/40
time = 304.39 secondes

Train loss 0.04589089121404946 accuracy 0.992634117603302 macro_avg {'precision': 0.9928663270728894, 'recall': 0.9928422936790557, 'f1-score': 0.9928486830567953, 'support': 10182} weighted_avg {'precision': 0.9926541846436112, 'recall': 0.9926340601060696, 'f1-score': 0.9926383618795596, 'support': 10182}
 
time = 7.87 secondes

Val loss 0.7157607864466345 accuracy 0.9143109321594238 macro_avg {'precision': 0.918425860405146, 'recall': 0.9160519919928498, 'f1-score': 0.9153364414669187, 'support': 1132} weighted_avg {'precision': 0.9176073919617325, 'recall': 0.9143109540636042, 'f1-score': 0.9141118915612008, 'support': 1132}
 
----------
Epoch 30/40
time = 302.23 secondes

Train loss 0.039133932543444924 accuracy 0.993812620639801 macro_avg {'precision': 0.9940168118777611, 'recall': 0.9939082937930541, 'f1-score': 0.9939486482351546, 'support': 10182} weighted_avg {'precision': 0.993850763461079, 'recall': 0.9938126104890984, 'f1-score': 0.9938171860203135, 'support': 10182}
 
time = 7.79 secondes

Val loss 0.6918297593571404 accuracy 0.916961133480072 macro_avg {'precision': 0.9184369731012622, 'recall': 0.9191512018521522, 'f1-score': 0.9173351713564706, 'support': 1132} weighted_avg {'precision': 0.9203077745818695, 'recall': 0.9169611307420494, 'f1-score': 0.9172676674333157, 'support': 1132}
 
----------
Epoch 31/40
time = 303.99 secondes

Train loss 0.026548539875541476 accuracy 0.9956786632537842 macro_avg {'precision': 0.9956275908090454, 'recall': 0.9955663020723048, 'f1-score': 0.9955914860629822, 'support': 10182} weighted_avg {'precision': 0.9956865382753459, 'recall': 0.9956786485955608, 'f1-score': 0.9956770745202879, 'support': 10182}
 
time = 7.75 secondes

Val loss 0.7715683647718475 accuracy 0.9151943325996399 macro_avg {'precision': 0.9185628954635945, 'recall': 0.9166093638379899, 'f1-score': 0.9166113677156412, 'support': 1132} weighted_avg {'precision': 0.9170161935953625, 'recall': 0.9151943462897526, 'f1-score': 0.9151187619357573, 'support': 1132}
 
----------
Epoch 32/40
time = 304.33 secondes

Train loss 0.03939303894383177 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934059053272641, 'recall': 0.9937298812730185, 'f1-score': 0.9935568821129974, 'support': 10182} weighted_avg {'precision': 0.9940411384530143, 'recall': 0.9940090355529365, 'f1-score': 0.9940157623883106, 'support': 10182}
 
time = 7.71 secondes

Val loss 0.868837547896989 accuracy 0.9054770469665527 macro_avg {'precision': 0.91023764975721, 'recall': 0.9087840357361913, 'f1-score': 0.907495033363497, 'support': 1132} weighted_avg {'precision': 0.911185848319937, 'recall': 0.9054770318021201, 'f1-score': 0.9061571429955775, 'support': 1132}
 
----------
Epoch 33/40
time = 302.54 secondes

Train loss 0.02889696934948023 accuracy 0.9951876401901245 macro_avg {'precision': 0.9949412254457715, 'recall': 0.9950389911987207, 'f1-score': 0.9949836972599921, 'support': 10182} weighted_avg {'precision': 0.9952028915273452, 'recall': 0.9951875859359655, 'f1-score': 0.9951892270027843, 'support': 10182}
 
time = 7.77 secondes

Val loss 0.750472167340543 accuracy 0.9125441908836365 macro_avg {'precision': 0.9164193784581997, 'recall': 0.9158066569498068, 'f1-score': 0.9142588442810625, 'support': 1132} weighted_avg {'precision': 0.9177677779497543, 'recall': 0.9125441696113075, 'f1-score': 0.9133647270504299, 'support': 1132}
 
----------
Epoch 34/40
time = 304.25 secondes

Train loss 0.017097397192094715 accuracy 0.9974464774131775 macro_avg {'precision': 0.9973343726186015, 'recall': 0.997453435640602, 'f1-score': 0.9973919442398964, 'support': 10182} weighted_avg {'precision': 0.9974465757769226, 'recall': 0.9974464741701041, 'f1-score': 0.9974446590170032, 'support': 10182}
 
time = 7.73 secondes

Val loss 0.8033182197310376 accuracy 0.9134275913238525 macro_avg {'precision': 0.9165723014392861, 'recall': 0.9166813464587131, 'f1-score': 0.9154560285190222, 'support': 1132} weighted_avg {'precision': 0.9164032670061162, 'recall': 0.9134275618374559, 'f1-score': 0.9137072577341125, 'support': 1132}
 
----------
Epoch 35/40
time = 302.82 secondes

Train loss 0.014816566782130303 accuracy 0.9973483085632324 macro_avg {'precision': 0.9973913531258598, 'recall': 0.9972797505020331, 'f1-score': 0.997332134651241, 'support': 10182} weighted_avg {'precision': 0.9973513046108805, 'recall': 0.997348261638185, 'f1-score': 0.9973464165810884, 'support': 10182}
 
time = 7.84 secondes

Val loss 0.7438631629490668 accuracy 0.9204947352409363 macro_avg {'precision': 0.9214051193198328, 'recall': 0.9235584706137695, 'f1-score': 0.9209186853918412, 'support': 1132} weighted_avg {'precision': 0.9246244679556012, 'recall': 0.9204946996466431, 'f1-score': 0.921039863362485, 'support': 1132}
 
----------
Epoch 36/40
time = 302.51 secondes

Train loss 0.01858473744919659 accuracy 0.9974464774131775 macro_avg {'precision': 0.9975098005966727, 'recall': 0.9975328759171276, 'f1-score': 0.9975177922443302, 'support': 10182} weighted_avg {'precision': 0.9974525565060115, 'recall': 0.9974464741701041, 'f1-score': 0.9974458299523752, 'support': 10182}
 
time = 7.79 secondes

Val loss 0.8061037172476677 accuracy 0.9125441908836365 macro_avg {'precision': 0.9181007552949396, 'recall': 0.9154680477785035, 'f1-score': 0.9152217570947603, 'support': 1132} weighted_avg {'precision': 0.9175658030312105, 'recall': 0.9125441696113075, 'f1-score': 0.9133755148513087, 'support': 1132}
 
----------
Epoch 37/40
time = 304.19 secondes

Train loss 0.014927222895334285 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975607044292942, 'recall': 0.9976073089596722, 'f1-score': 0.9975829515359752, 'support': 10182} weighted_avg {'precision': 0.9975477117066596, 'recall': 0.9975446867020232, 'f1-score': 0.9975451500579163, 'support': 10182}
 
time = 7.79 secondes

Val loss 0.8229892789103117 accuracy 0.9143109321594238 macro_avg {'precision': 0.9192581549623217, 'recall': 0.9184237648466098, 'f1-score': 0.9170906461676186, 'support': 1132} weighted_avg {'precision': 0.9193723978909515, 'recall': 0.9143109540636042, 'f1-score': 0.9149347458951818, 'support': 1132}
 
----------
Epoch 38/40
time = 302.59 secondes

Train loss 0.011549853834781297 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982168471344446, 'recall': 0.9982411624771993, 'f1-score': 0.9982272892195135, 'support': 10182} weighted_avg {'precision': 0.9982351576736103, 'recall': 0.9982321744254566, 'f1-score': 0.998231899540709, 'support': 10182}
 
time = 7.91 secondes

Val loss 0.7832251156505919 accuracy 0.9151943325996399 macro_avg {'precision': 0.9198313861923857, 'recall': 0.9205447122818546, 'f1-score': 0.9182244058063838, 'support': 1132} weighted_avg {'precision': 0.9199577624431463, 'recall': 0.9151943462897526, 'f1-score': 0.9155532971704794, 'support': 1132}
 
----------
Epoch 39/40
time = 303.05 secondes

Train loss 0.005243707041918413 accuracy 0.998919665813446 macro_avg {'precision': 0.9989349187917126, 'recall': 0.998954130944315, 'f1-score': 0.9989431538162131, 'support': 10182} weighted_avg {'precision': 0.9989215558130767, 'recall': 0.9989196621488902, 'f1-score': 0.9989192040642794, 'support': 10182}
 
time = 8.93 secondes

Val loss 0.751774008115525 accuracy 0.9204947352409363 macro_avg {'precision': 0.9262255324647827, 'recall': 0.9245876687609001, 'f1-score': 0.9240587056489179, 'support': 1132} weighted_avg {'precision': 0.9247409663371807, 'recall': 0.9204946996466431, 'f1-score': 0.9211460373525127, 'support': 1132}
 
----------
Epoch 40/40
time = 302.89 secondes

Train loss 0.0021102025747134416 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995204175883879, 'recall': 0.9994512884337816, 'f1-score': 0.9994854049191249, 'support': 10182} weighted_avg {'precision': 0.9995098729944137, 'recall': 0.9995089373404047, 'f1-score': 0.9995089958791866, 'support': 10182}
 
time = 7.70 secondes

Val loss 0.7457766706116723 accuracy 0.9231448769569397 macro_avg {'precision': 0.9281622129953773, 'recall': 0.925905700766589, 'f1-score': 0.9259043397659887, 'support': 1132} weighted_avg {'precision': 0.926292756726228, 'recall': 0.9231448763250883, 'f1-score': 0.9235304107909369, 'support': 1132}
 
----------
best_accuracy 0.9231448769569397 best_epoch 40 macro_avg {'precision': 0.9281622129953773, 'recall': 0.925905700766589, 'f1-score': 0.9259043397659887, 'support': 1132} weighted_avg {'precision': 0.926292756726228, 'recall': 0.9231448763250883, 'f1-score': 0.9235304107909369, 'support': 1132}

average train time 303.60304508805274

average val time 7.891708171367645
 
time = 52.43 secondes

test_accuracy 0.8564789891242981 macro_avg {'precision': 0.8566633111120755, 'recall': 0.8492035525243947, 'f1-score': 0.8496339447681052, 'support': 7532} weighted_avg {'precision': 0.86348166303125, 'recall': 0.8564790228359002, 'f1-score': 0.8571032177202611, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_head_tail_2
----------
Epoch 1/40
time = 299.69 secondes

Train loss 1.25955233983754 accuracy 0.6739344000816345 macro_avg {'precision': 0.67354026984953, 'recall': 0.657904215085276, 'f1-score': 0.6519678592611036, 'support': 10182} weighted_avg {'precision': 0.6846014090150826, 'recall': 0.673934394028678, 'f1-score': 0.6672987539734079, 'support': 10182}
 
time = 8.20 secondes

Val loss 0.6192504998663781 accuracy 0.8206713795661926 macro_avg {'precision': 0.7919755357157208, 'recall': 0.8128813657958508, 'f1-score': 0.7975187873053518, 'support': 1132} weighted_avg {'precision': 0.8004811211108993, 'recall': 0.8206713780918727, 'f1-score': 0.8057048273594716, 'support': 1132}
 
----------
Epoch 2/40
time = 301.02 secondes

Train loss 0.44003452039564983 accuracy 0.8708505630493164 macro_avg {'precision': 0.8616421332171285, 'recall': 0.8597675523323118, 'f1-score': 0.8583134505310002, 'support': 10182} weighted_avg {'precision': 0.8688793601593174, 'recall': 0.8708505205264192, 'f1-score': 0.8680959656292183, 'support': 10182}
 
time = 8.02 secondes

Val loss 0.4662209380627938 accuracy 0.8745583295822144 macro_avg {'precision': 0.8710522733380589, 'recall': 0.8685891513249251, 'f1-score': 0.866142952139257, 'support': 1132} weighted_avg {'precision': 0.8784824764796456, 'recall': 0.8745583038869258, 'f1-score': 0.8729471633942095, 'support': 1132}
 
----------
Epoch 3/40
time = 299.95 secondes

Train loss 0.28899724637063184 accuracy 0.9174032807350159 macro_avg {'precision': 0.9127343051888005, 'recall': 0.9118699295902534, 'f1-score': 0.9121114887675634, 'support': 10182} weighted_avg {'precision': 0.9175739346549392, 'recall': 0.9174032606560597, 'f1-score': 0.9173139300228857, 'support': 10182}
 
time = 7.92 secondes

Val loss 0.45066745133257247 accuracy 0.8904593586921692 macro_avg {'precision': 0.8895329100557096, 'recall': 0.8895034866255752, 'f1-score': 0.8863271777319846, 'support': 1132} weighted_avg {'precision': 0.894577019510613, 'recall': 0.8904593639575972, 'f1-score': 0.889480693446758, 'support': 1132}
 
----------
Epoch 4/40
time = 303.07 secondes

Train loss 0.20109286809265556 accuracy 0.9473581314086914 macro_avg {'precision': 0.9445047861174573, 'recall': 0.9446199433940249, 'f1-score': 0.9444564937670895, 'support': 10182} weighted_avg {'precision': 0.9477620468560546, 'recall': 0.9473580828913769, 'f1-score': 0.9474701452373234, 'support': 10182}
 
time = 7.87 secondes

Val loss 0.5222189538672724 accuracy 0.8931095600128174 macro_avg {'precision': 0.9000082563746942, 'recall': 0.8954004003726534, 'f1-score': 0.8927185893239329, 'support': 1132} weighted_avg {'precision': 0.9057539518843535, 'recall': 0.8931095406360424, 'f1-score': 0.8941087839394624, 'support': 1132}
 
----------
Epoch 5/40
time = 299.91 secondes

Train loss 0.18660718332146392 accuracy 0.953938364982605 macro_avg {'precision': 0.9521586576833266, 'recall': 0.9521958453389756, 'f1-score': 0.9520913274565819, 'support': 10182} weighted_avg {'precision': 0.9541819979882308, 'recall': 0.9539383225299548, 'f1-score': 0.9539831061532218, 'support': 10182}
 
time = 7.85 secondes

Val loss 0.5740526254275735 accuracy 0.9019434452056885 macro_avg {'precision': 0.9117650560748402, 'recall': 0.9002210674279686, 'f1-score': 0.9027486743156612, 'support': 1132} weighted_avg {'precision': 0.9090615956995037, 'recall': 0.9019434628975265, 'f1-score': 0.9024479330918828, 'support': 1132}
 
----------
Epoch 6/40
time = 300.27 secondes

Train loss 0.1677034526623477 accuracy 0.9639560580253601 macro_avg {'precision': 0.9625606974903207, 'recall': 0.9624819994536882, 'f1-score': 0.9624805670800864, 'support': 10182} weighted_avg {'precision': 0.964133818197634, 'recall': 0.9639560007857002, 'f1-score': 0.964006347788831, 'support': 10182}
 
time = 7.90 secondes

Val loss 0.519748640866478 accuracy 0.898409903049469 macro_avg {'precision': 0.9048091325311918, 'recall': 0.9001355664086829, 'f1-score': 0.8986839929369059, 'support': 1132} weighted_avg {'precision': 0.9026371214169197, 'recall': 0.8984098939929329, 'f1-score': 0.8966752147798461, 'support': 1132}
 
----------
Epoch 7/40
time = 296.75 secondes

Train loss 0.16472340081816575 accuracy 0.9625810384750366 macro_avg {'precision': 0.9614741706808907, 'recall': 0.9616914581207526, 'f1-score': 0.9615383847851875, 'support': 10182} weighted_avg {'precision': 0.9627207536776811, 'recall': 0.9625810253388333, 'f1-score': 0.9626086582204836, 'support': 10182}
 
time = 8.09 secondes

Val loss 0.4711593476125748 accuracy 0.9081271886825562 macro_avg {'precision': 0.9085492915025043, 'recall': 0.9094124182756215, 'f1-score': 0.9081201013722218, 'support': 1132} weighted_avg {'precision': 0.9101918553902579, 'recall': 0.9081272084805654, 'f1-score': 0.9082908397237586, 'support': 1132}
 
----------
Epoch 8/40
time = 301.74 secondes

Train loss 0.13929621712382323 accuracy 0.9701434373855591 macro_avg {'precision': 0.9693644750077466, 'recall': 0.9689049526633975, 'f1-score': 0.9690684252990472, 'support': 10182} weighted_avg {'precision': 0.9701431245989341, 'recall': 0.9701433902966018, 'f1-score': 0.9700920082486473, 'support': 10182}
 
time = 7.78 secondes

Val loss 0.6400444545851968 accuracy 0.8975265026092529 macro_avg {'precision': 0.8963810030972532, 'recall': 0.8947856018291722, 'f1-score': 0.8918825058941501, 'support': 1132} weighted_avg {'precision': 0.9015513941412212, 'recall': 0.8975265017667845, 'f1-score': 0.8961405710893232, 'support': 1132}
 
----------
Epoch 9/40
time = 298.87 secondes

Train loss 0.12416506510838687 accuracy 0.9730898141860962 macro_avg {'precision': 0.9720876462584082, 'recall': 0.9717931325648946, 'f1-score': 0.9718906609773853, 'support': 10182} weighted_avg {'precision': 0.973178529261081, 'recall': 0.973089766254174, 'f1-score': 0.9730860492921618, 'support': 10182}
 
time = 7.83 secondes

Val loss 0.6453780781233381 accuracy 0.9019434452056885 macro_avg {'precision': 0.9075966855521334, 'recall': 0.8951999875704054, 'f1-score': 0.897252395773638, 'support': 1132} weighted_avg {'precision': 0.906759041160326, 'recall': 0.9019434628975265, 'f1-score': 0.9009450396880117, 'support': 1132}
 
----------
Epoch 10/40
time = 299.62 secondes

Train loss 0.12486470736509475 accuracy 0.9746611714363098 macro_avg {'precision': 0.9736800518944625, 'recall': 0.9735588110150262, 'f1-score': 0.9735972207252823, 'support': 10182} weighted_avg {'precision': 0.9746996891017132, 'recall': 0.9746611667648792, 'f1-score': 0.9746575734191162, 'support': 10182}
 
time = 7.89 secondes

Val loss 0.7068277121981456 accuracy 0.9001767039299011 macro_avg {'precision': 0.907618864079403, 'recall': 0.8977717826571701, 'f1-score': 0.899408127153135, 'support': 1132} weighted_avg {'precision': 0.907569067669007, 'recall': 0.9001766784452296, 'f1-score': 0.9007996477217886, 'support': 1132}
 
----------
Epoch 11/40
time = 298.72 secondes

Train loss 0.10496793978228844 accuracy 0.9797682762145996 macro_avg {'precision': 0.979141577026223, 'recall': 0.9793445397725948, 'f1-score': 0.9792182470929811, 'support': 10182} weighted_avg {'precision': 0.9798402237359631, 'recall': 0.979768218424671, 'f1-score': 0.9797813252105148, 'support': 10182}
 
time = 7.86 secondes

Val loss 0.637016935655429 accuracy 0.9037102460861206 macro_avg {'precision': 0.9088723742626683, 'recall': 0.9064697343738348, 'f1-score': 0.9058358487128937, 'support': 1132} weighted_avg {'precision': 0.9072724790937041, 'recall': 0.9037102473498233, 'f1-score': 0.9036259131295081, 'support': 1132}
 
----------
Epoch 12/40
time = 299.67 secondes

Train loss 0.10733301309417104 accuracy 0.9803575277328491 macro_avg {'precision': 0.9802162162542821, 'recall': 0.9802871380445011, 'f1-score': 0.9802417579133339, 'support': 10182} weighted_avg {'precision': 0.980388031124684, 'recall': 0.9803574936161854, 'f1-score': 0.9803628414255207, 'support': 10182}
 
time = 7.83 secondes

Val loss 0.6850872722203912 accuracy 0.8992933034896851 macro_avg {'precision': 0.9086159812667377, 'recall': 0.9044463082072995, 'f1-score': 0.9005641569292058, 'support': 1132} weighted_avg {'precision': 0.9082771673310484, 'recall': 0.8992932862190812, 'f1-score': 0.8971726686045731, 'support': 1132}
 
----------
Epoch 13/40
time = 299.84 secondes

Train loss 0.09591770229861916 accuracy 0.9817324876785278 macro_avg {'precision': 0.9814797291799394, 'recall': 0.9816544219304066, 'f1-score': 0.9815419005393606, 'support': 10182} weighted_avg {'precision': 0.9817876882088911, 'recall': 0.9817324690630524, 'f1-score': 0.9817349663124888, 'support': 10182}
 
time = 7.80 secondes

Val loss 0.8543743970855155 accuracy 0.8922261595726013 macro_avg {'precision': 0.8971690856719541, 'recall': 0.894784227522549, 'f1-score': 0.8919862502238862, 'support': 1132} weighted_avg {'precision': 0.8987399381822523, 'recall': 0.892226148409894, 'f1-score': 0.8910913279689041, 'support': 1132}
 
----------
Epoch 14/40
time = 298.00 secondes

Train loss 0.11819402534511285 accuracy 0.9788843393325806 macro_avg {'precision': 0.9784993408583988, 'recall': 0.9788315606304584, 'f1-score': 0.978635478696748, 'support': 10182} weighted_avg {'precision': 0.9789671637697872, 'recall': 0.9788843056373994, 'f1-score': 0.9788987590102978, 'support': 10182}
 
time = 7.72 secondes

Val loss 0.745908230796053 accuracy 0.9037102460861206 macro_avg {'precision': 0.9115622002294528, 'recall': 0.9066008078595089, 'f1-score': 0.9060712215648445, 'support': 1132} weighted_avg {'precision': 0.9119514987069921, 'recall': 0.9037102473498233, 'f1-score': 0.9047130901139708, 'support': 1132}
 
----------
Epoch 15/40
time = 298.88 secondes

Train loss 0.10249408086304669 accuracy 0.9813396334648132 macro_avg {'precision': 0.9803338819968632, 'recall': 0.9803368310051394, 'f1-score': 0.9802975921425053, 'support': 10182} weighted_avg {'precision': 0.9814289048810196, 'recall': 0.9813396189353761, 'f1-score': 0.9813508458862861, 'support': 10182}
 
time = 7.73 secondes

Val loss 0.734035702909238 accuracy 0.9037102460861206 macro_avg {'precision': 0.9120812002378079, 'recall': 0.9006539651303112, 'f1-score': 0.9016388965240687, 'support': 1132} weighted_avg {'precision': 0.9090140659682706, 'recall': 0.9037102473498233, 'f1-score': 0.9025899528920069, 'support': 1132}
 
----------
Epoch 16/40
time = 299.90 secondes

Train loss 0.09152075657068648 accuracy 0.9838931560516357 macro_avg {'precision': 0.9830003087931557, 'recall': 0.9824830176920901, 'f1-score': 0.9827200625314431, 'support': 10182} weighted_avg {'precision': 0.9838860233960337, 'recall': 0.983893144765272, 'f1-score': 0.9838704413720345, 'support': 10182}
 
time = 8.03 secondes

Val loss 0.7807374051132594 accuracy 0.9045936465263367 macro_avg {'precision': 0.9076053994990707, 'recall': 0.9069499129275597, 'f1-score': 0.9049290947165733, 'support': 1132} weighted_avg {'precision': 0.9100542394238891, 'recall': 0.9045936395759717, 'f1-score': 0.9048145093195289, 'support': 1132}
 
----------
Epoch 17/40
time = 300.85 secondes

Train loss 0.08122026742857198 accuracy 0.9850717186927795 macro_avg {'precision': 0.984360141780049, 'recall': 0.9847757840507099, 'f1-score': 0.9845427009401704, 'support': 10182} weighted_avg {'precision': 0.9851331117902545, 'recall': 0.985071695148301, 'f1-score': 0.9850820611466568, 'support': 10182}
 
time = 7.98 secondes

Val loss 0.7189583522888658 accuracy 0.9098939895629883 macro_avg {'precision': 0.9207882363351813, 'recall': 0.9121224589733927, 'f1-score': 0.9133957543834155, 'support': 1132} weighted_avg {'precision': 0.9189937579048817, 'recall': 0.9098939929328622, 'f1-score': 0.9112613732647916, 'support': 1132}
 
----------
Epoch 18/40
time = 300.02 secondes

Train loss 0.1022522151118494 accuracy 0.9831074476242065 macro_avg {'precision': 0.9829408093170949, 'recall': 0.9828940047664638, 'f1-score': 0.9828906922252498, 'support': 10182} weighted_avg {'precision': 0.9831528614537507, 'recall': 0.9831074445099195, 'f1-score': 0.9831034053843816, 'support': 10182}
 
time = 7.44 secondes

Val loss 0.753393532426677 accuracy 0.9098939895629883 macro_avg {'precision': 0.9155629425372102, 'recall': 0.9111237453893255, 'f1-score': 0.9117735934658999, 'support': 1132} weighted_avg {'precision': 0.9139226257359004, 'recall': 0.9098939929328622, 'f1-score': 0.910218135633989, 'support': 1132}
 
----------
Epoch 19/40
time = 298.52 secondes

Train loss 0.09606389578569505 accuracy 0.9847770929336548 macro_avg {'precision': 0.9842685637901771, 'recall': 0.9842273680685519, 'f1-score': 0.9842238391898472, 'support': 10182} weighted_avg {'precision': 0.9847950298903279, 'recall': 0.9847770575525437, 'f1-score': 0.984761498638257, 'support': 10182}
 
time = 7.91 secondes

Val loss 0.6733368854300762 accuracy 0.9151943325996399 macro_avg {'precision': 0.917220396102787, 'recall': 0.9156704978868548, 'f1-score': 0.9156468264906465, 'support': 1132} weighted_avg {'precision': 0.9174583061955862, 'recall': 0.9151943462897526, 'f1-score': 0.915538012397467, 'support': 1132}
 
----------
Epoch 20/40
time = 298.60 secondes

Train loss 0.07877118369237099 accuracy 0.9861520528793335 macro_avg {'precision': 0.985358292704414, 'recall': 0.9850228483483356, 'f1-score': 0.9851615717063742, 'support': 10182} weighted_avg {'precision': 0.9862211922622968, 'recall': 0.9861520329994107, 'f1-score': 0.9861583830503217, 'support': 10182}
 
time = 7.82 secondes

Val loss 0.8861028122089305 accuracy 0.8886925578117371 macro_avg {'precision': 0.8978015451586471, 'recall': 0.8860647066705989, 'f1-score': 0.8820662056466284, 'support': 1132} weighted_avg {'precision': 0.9044262995368099, 'recall': 0.8886925795053003, 'f1-score': 0.8883066945550375, 'support': 1132}
 
----------
Epoch 21/40
time = 299.76 secondes

Train loss 0.07825926103592803 accuracy 0.9859556555747986 macro_avg {'precision': 0.9857544562913327, 'recall': 0.9859924376227134, 'f1-score': 0.9858509231752797, 'support': 10182} weighted_avg {'precision': 0.986011164888648, 'recall': 0.9859556079355726, 'f1-score': 0.9859627447425688, 'support': 10182}
 
time = 7.94 secondes

Val loss 0.6547068581232042 accuracy 0.916077733039856 macro_avg {'precision': 0.919569772884517, 'recall': 0.9201639170419809, 'f1-score': 0.9187090835504167, 'support': 1132} weighted_avg {'precision': 0.9187714271601003, 'recall': 0.916077738515901, 'f1-score': 0.9161711269446058, 'support': 1132}
 
----------
Epoch 22/40
time = 301.35 secondes

Train loss 0.06333579889622834 accuracy 0.9885091781616211 macro_avg {'precision': 0.9878995935693977, 'recall': 0.9878852871286707, 'f1-score': 0.9878684131377649, 'support': 10182} weighted_avg {'precision': 0.9885484900420877, 'recall': 0.9885091337654685, 'f1-score': 0.9885062882544103, 'support': 10182}
 
time = 7.96 secondes

Val loss 0.6077793748017555 accuracy 0.9196113348007202 macro_avg {'precision': 0.922053729534225, 'recall': 0.9203390342196285, 'f1-score': 0.9196735173566581, 'support': 1132} weighted_avg {'precision': 0.9231378856439916, 'recall': 0.9196113074204947, 'f1-score': 0.9199672647662235, 'support': 1132}
 
----------
Epoch 23/40
time = 302.99 secondes

Train loss 0.061163835561886544 accuracy 0.9898841381072998 macro_avg {'precision': 0.9895490184669852, 'recall': 0.9896208530599899, 'f1-score': 0.9895687745668675, 'support': 10182} weighted_avg {'precision': 0.9899245326321842, 'recall': 0.9898841092123355, 'f1-score': 0.9898878524222365, 'support': 10182}
 
time = 8.06 secondes

Val loss 0.9913419161155258 accuracy 0.8736749291419983 macro_avg {'precision': 0.8949397865344079, 'recall': 0.8692230187195878, 'f1-score': 0.8710281137080894, 'support': 1132} weighted_avg {'precision': 0.896858263556245, 'recall': 0.8736749116607774, 'f1-score': 0.8747450976151306, 'support': 1132}
 
----------
Epoch 24/40
time = 302.19 secondes

Train loss 0.0660803439555932 accuracy 0.9896877408027649 macro_avg {'precision': 0.9895244984302215, 'recall': 0.9895089832766646, 'f1-score': 0.9895064301254823, 'support': 10182} weighted_avg {'precision': 0.9896935091822876, 'recall': 0.9896876841484974, 'f1-score': 0.9896799439119469, 'support': 10182}
 
time = 7.99 secondes

Val loss 0.6618723540909549 accuracy 0.9143109321594238 macro_avg {'precision': 0.9219423235215878, 'recall': 0.9164501592752637, 'f1-score': 0.9173731505666088, 'support': 1132} weighted_avg {'precision': 0.9203421501622996, 'recall': 0.9143109540636042, 'f1-score': 0.915423956944184, 'support': 1132}
 
----------
Epoch 25/40
time = 301.93 secondes

Train loss 0.06096799843231748 accuracy 0.9902769923210144 macro_avg {'precision': 0.990163916543124, 'recall': 0.990145987490814, 'f1-score': 0.9901467346430011, 'support': 10182} weighted_avg {'precision': 0.9903003357575776, 'recall': 0.9902769593400118, 'f1-score': 0.9902803610472671, 'support': 10182}
 
time = 7.97 secondes

Val loss 0.644580207566192 accuracy 0.9151943325996399 macro_avg {'precision': 0.9177067750585819, 'recall': 0.9180009892116507, 'f1-score': 0.9169770735644018, 'support': 1132} weighted_avg {'precision': 0.9185429543272852, 'recall': 0.9151943462897526, 'f1-score': 0.9160070377110562, 'support': 1132}
 
----------
Epoch 26/40
time = 312.65 secondes

Train loss 0.0469190923426343 accuracy 0.9918484091758728 macro_avg {'precision': 0.9918780971651222, 'recall': 0.9915166463656355, 'f1-score': 0.9916877391459342, 'support': 10182} weighted_avg {'precision': 0.991869568519211, 'recall': 0.991848359850717, 'f1-score': 0.9918505169491202, 'support': 10182}
 
time = 8.29 secondes

Val loss 0.7083961036979405 accuracy 0.916077733039856 macro_avg {'precision': 0.9258854291122567, 'recall': 0.916948928931656, 'f1-score': 0.9184860922386815, 'support': 1132} weighted_avg {'precision': 0.9227776239673701, 'recall': 0.916077738515901, 'f1-score': 0.9164718093893051, 'support': 1132}
 
----------
Epoch 27/40
time = 313.17 secondes

Train loss 0.043555738948650814 accuracy 0.9921430349349976 macro_avg {'precision': 0.9922968479342495, 'recall': 0.9921527816320472, 'f1-score': 0.9922187086701205, 'support': 10182} weighted_avg {'precision': 0.9921547797058115, 'recall': 0.9921429974464742, 'f1-score': 0.9921427392870439, 'support': 10182}
 
time = 8.49 secondes

Val loss 0.61340797770636 accuracy 0.9222614765167236 macro_avg {'precision': 0.927462138932895, 'recall': 0.9216747153616376, 'f1-score': 0.9228613673209486, 'support': 1132} weighted_avg {'precision': 0.9263551856797974, 'recall': 0.9222614840989399, 'f1-score': 0.9225712207388798, 'support': 1132}
 
----------
Epoch 28/40
time = 308.81 secondes

Train loss 0.041924168599678874 accuracy 0.9927322864532471 macro_avg {'precision': 0.9922520553094998, 'recall': 0.9923346007106671, 'f1-score': 0.9922829541654872, 'support': 10182} weighted_avg {'precision': 0.9927567843879382, 'recall': 0.9927322726379886, 'f1-score': 0.9927342854651721, 'support': 10182}
 
time = 8.29 secondes

Val loss 0.8089663784721011 accuracy 0.9054770469665527 macro_avg {'precision': 0.9105317152091118, 'recall': 0.9098977225814451, 'f1-score': 0.9065545767461172, 'support': 1132} weighted_avg {'precision': 0.9110416435035361, 'recall': 0.9054770318021201, 'f1-score': 0.9042976328921907, 'support': 1132}
 
----------
Epoch 29/40
time = 313.91 secondes

Train loss 0.03641817632232913 accuracy 0.9942054748535156 macro_avg {'precision': 0.9940196927449556, 'recall': 0.9939413261627059, 'f1-score': 0.9939722840287846, 'support': 10182} weighted_avg {'precision': 0.9942215132062674, 'recall': 0.9942054606167747, 'f1-score': 0.9942056057169806, 'support': 10182}
 
time = 8.06 secondes

Val loss 0.7815570873912883 accuracy 0.9107773900032043 macro_avg {'precision': 0.911010183764119, 'recall': 0.910852574537083, 'f1-score': 0.9094074549513772, 'support': 1132} weighted_avg {'precision': 0.915106612983471, 'recall': 0.9107773851590106, 'f1-score': 0.9115915315849261, 'support': 1132}
 
----------
Epoch 30/40
time = 313.24 secondes

Train loss 0.038548609342381655 accuracy 0.9939108490943909 macro_avg {'precision': 0.9935700329868323, 'recall': 0.9936675865738165, 'f1-score': 0.9936136020628725, 'support': 10182} weighted_avg {'precision': 0.9939170026645844, 'recall': 0.9939108230210175, 'f1-score': 0.9939086615567483, 'support': 10182}
 
time = 8.38 secondes

Val loss 0.859576631231288 accuracy 0.9090105891227722 macro_avg {'precision': 0.913549709989069, 'recall': 0.9094530202562598, 'f1-score': 0.9085002627304378, 'support': 1132} weighted_avg {'precision': 0.917031747416533, 'recall': 0.9090106007067138, 'f1-score': 0.9101138092757727, 'support': 1132}
 
----------
Epoch 31/40
time = 308.34 secondes

Train loss 0.030537872064941234 accuracy 0.9953840374946594 macro_avg {'precision': 0.9954910104495619, 'recall': 0.9953914560846882, 'f1-score': 0.9954349382317487, 'support': 10182} weighted_avg {'precision': 0.995405825050284, 'recall': 0.9953840109998036, 'f1-score': 0.9953886989649176, 'support': 10182}
 
time = 7.96 secondes

Val loss 0.6716469365662088 accuracy 0.9249116778373718 macro_avg {'precision': 0.9259435974608987, 'recall': 0.9264025690254198, 'f1-score': 0.9257172281491577, 'support': 1132} weighted_avg {'precision': 0.9259040753572281, 'recall': 0.9249116607773852, 'f1-score': 0.9249361411188713, 'support': 1132}
 
----------
Epoch 32/40
time = 311.55 secondes

Train loss 0.03323601008814647 accuracy 0.9945983290672302 macro_avg {'precision': 0.9946639324867401, 'recall': 0.9947503671183309, 'f1-score': 0.9947009748144946, 'support': 10182} weighted_avg {'precision': 0.9946026293006758, 'recall': 0.994598310744451, 'f1-score': 0.9945940956224145, 'support': 10182}
 
time = 8.41 secondes

Val loss 0.8299065719931835 accuracy 0.9116607904434204 macro_avg {'precision': 0.9175890504119669, 'recall': 0.9155029843466715, 'f1-score': 0.9141688846624559, 'support': 1132} weighted_avg {'precision': 0.9179953150716483, 'recall': 0.911660777385159, 'f1-score': 0.9124622397550414, 'support': 1132}
 
----------
Epoch 33/40
time = 310.56 secondes

Train loss 0.020172971646742848 accuracy 0.9966608285903931 macro_avg {'precision': 0.996622842670499, 'recall': 0.9964391077834568, 'f1-score': 0.9965269184127108, 'support': 10182} weighted_avg {'precision': 0.9966650193845771, 'recall': 0.9966607739147515, 'f1-score': 0.996659825322578, 'support': 10182}
 
time = 8.00 secondes

Val loss 0.8015025200530403 accuracy 0.9151943325996399 macro_avg {'precision': 0.9186565127750184, 'recall': 0.9188293380358423, 'f1-score': 0.9169959857320974, 'support': 1132} weighted_avg {'precision': 0.9191832824032818, 'recall': 0.9151943462897526, 'f1-score': 0.9155266707539953, 'support': 1132}
 
----------
Epoch 34/40
time = 306.03 secondes

Train loss 0.032124455854123476 accuracy 0.9951876401901245 macro_avg {'precision': 0.9948173448466457, 'recall': 0.9949571178262422, 'f1-score': 0.9948640731845538, 'support': 10182} weighted_avg {'precision': 0.99520950108692, 'recall': 0.9951875859359655, 'f1-score': 0.9951793758548888, 'support': 10182}
 
time = 8.22 secondes

Val loss 0.7369778442108826 accuracy 0.9222614765167236 macro_avg {'precision': 0.9284168130623002, 'recall': 0.9254010865289558, 'f1-score': 0.9252263918230712, 'support': 1132} weighted_avg {'precision': 0.9276105097202679, 'recall': 0.9222614840989399, 'f1-score': 0.9232307048848253, 'support': 1132}
 
----------
Epoch 35/40
time = 315.75 secondes

Train loss 0.017392152582218916 accuracy 0.9969554543495178 macro_avg {'precision': 0.9969346554487647, 'recall': 0.9969334280340002, 'f1-score': 0.9969316950072351, 'support': 10182} weighted_avg {'precision': 0.9969580174552014, 'recall': 0.9969554115105087, 'f1-score': 0.9969543477754818, 'support': 10182}
 
time = 8.61 secondes

Val loss 0.7330945553483001 accuracy 0.9178445339202881 macro_avg {'precision': 0.9237665582367006, 'recall': 0.920641894594624, 'f1-score': 0.9202352191871188, 'support': 1132} weighted_avg {'precision': 0.9222658599326797, 'recall': 0.9178445229681979, 'f1-score': 0.9181754804489021, 'support': 1132}
 
----------
Epoch 36/40
time = 309.70 secondes

Train loss 0.017719463514047993 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971050824753149, 'recall': 0.9972145763141175, 'f1-score': 0.9971567988516845, 'support': 10182} weighted_avg {'precision': 0.9971546591460807, 'recall': 0.9971518365743469, 'f1-score': 0.9971502689295979, 'support': 10182}
 
time = 8.39 secondes

Val loss 0.6840428973339929 accuracy 0.9231448769569397 macro_avg {'precision': 0.9279392648377401, 'recall': 0.925681341551279, 'f1-score': 0.9256560719964634, 'support': 1132} weighted_avg {'precision': 0.9272589565159237, 'recall': 0.9231448763250883, 'f1-score': 0.9240181764433868, 'support': 1132}
 
----------
Epoch 37/40
time = 304.27 secondes

Train loss 0.011298307448286575 accuracy 0.9979375600814819 macro_avg {'precision': 0.9978787063759725, 'recall': 0.9978786273325613, 'f1-score': 0.9978761418785872, 'support': 10182} weighted_avg {'precision': 0.9979424510493127, 'recall': 0.9979375368296994, 'f1-score': 0.997937392846491, 'support': 10182}
 
time = 8.55 secondes

Val loss 0.7272610446377423 accuracy 0.9196113348007202 macro_avg {'precision': 0.9235580375663088, 'recall': 0.9230073747752202, 'f1-score': 0.9218743031399358, 'support': 1132} weighted_avg {'precision': 0.9228876350394439, 'recall': 0.9196113074204947, 'f1-score': 0.919738021249286, 'support': 1132}
 
----------
Epoch 38/40
time = 317.91 secondes

Train loss 0.009135809698054914 accuracy 0.9985268115997314 macro_avg {'precision': 0.9984655227179495, 'recall': 0.9984714571266933, 'f1-score': 0.9984678349718544, 'support': 10182} weighted_avg {'precision': 0.9985283617233501, 'recall': 0.998526812021214, 'f1-score': 0.9985269235428893, 'support': 10182}
 
time = 8.26 secondes

Val loss 0.6940779520717909 accuracy 0.9231448769569397 macro_avg {'precision': 0.9246004789462934, 'recall': 0.9253562046891345, 'f1-score': 0.9237911455263793, 'support': 1132} weighted_avg {'precision': 0.9265191870534121, 'recall': 0.9231448763250883, 'f1-score': 0.923599074073264, 'support': 1132}
 
----------
Epoch 39/40
time = 308.01 secondes

Train loss 0.007613591889299124 accuracy 0.998821496963501 macro_avg {'precision': 0.9988426973011257, 'recall': 0.9988024165712343, 'f1-score': 0.9988218355858404, 'support': 10182} weighted_avg {'precision': 0.9988237127845546, 'recall': 0.9988214496169712, 'f1-score': 0.9988218910544359, 'support': 10182}
 
time = 8.23 secondes

Val loss 0.6622537837784863 accuracy 0.9310954213142395 macro_avg {'precision': 0.9344315261276194, 'recall': 0.932498655169888, 'f1-score': 0.9324348945105948, 'support': 1132} weighted_avg {'precision': 0.9330079923660588, 'recall': 0.931095406360424, 'f1-score': 0.93095676660862, 'support': 1132}
 
----------
Epoch 40/40
time = 305.05 secondes

Train loss 0.004836392465636217 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992782176147363, 'recall': 0.999261652837952, 'f1-score': 0.999269641347014, 'support': 10182} weighted_avg {'precision': 0.9993130769275501, 'recall': 0.9993125122765665, 'f1-score': 0.9993125041244868, 'support': 10182}
 
time = 8.42 secondes

Val loss 0.6982937031675327 accuracy 0.926678478717804 macro_avg {'precision': 0.9299059356380843, 'recall': 0.9287412353450384, 'f1-score': 0.9278631998797289, 'support': 1132} weighted_avg {'precision': 0.9297893155517514, 'recall': 0.926678445229682, 'f1-score': 0.9267140969631378, 'support': 1132}
 
----------
best_accuracy 0.9310954213142395 best_epoch 39 macro_avg {'precision': 0.9344315261276194, 'recall': 0.932498655169888, 'f1-score': 0.9324348945105948, 'support': 1132} weighted_avg {'precision': 0.9330079923660588, 'recall': 0.931095406360424, 'f1-score': 0.93095676660862, 'support': 1132}

average train time 304.02661590576173

average val time 8.049620246887207
 
time = 56.21 secondes

test_accuracy 0.8601964712142944 macro_avg {'precision': 0.8578183749877903, 'recall': 0.8523064046597753, 'f1-score': 0.8530378108015487, 'support': 7532} weighted_avg {'precision': 0.8623344886577672, 'recall': 0.8601964949548593, 'f1-score': 0.8594150997065566, 'support': 7532}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_BERT_tail_2
----------
Epoch 1/40
time = 320.22 secondes

Train loss 1.338247965980362 accuracy 0.6564525961875916 macro_avg {'precision': 0.6517449495690129, 'recall': 0.6409032310519438, 'f1-score': 0.6327183669443712, 'support': 10182} weighted_avg {'precision': 0.6640885534889883, 'recall': 0.6564525633470831, 'f1-score': 0.6476068565832246, 'support': 10182}
 
time = 8.67 secondes

Val loss 0.7052263474800218 accuracy 0.7915194630622864 macro_avg {'precision': 0.769569228218609, 'recall': 0.7817041602523022, 'f1-score': 0.7700158178393529, 'support': 1132} weighted_avg {'precision': 0.7767249724060007, 'recall': 0.7915194346289752, 'f1-score': 0.7788752334354788, 'support': 1132}
 
----------
Epoch 2/40
time = 308.86 secondes

Train loss 0.5182671194817151 accuracy 0.8501276969909668 macro_avg {'precision': 0.8366636884419767, 'recall': 0.8368503456250697, 'f1-score': 0.832840648538518, 'support': 10182} weighted_avg {'precision': 0.8459028014795801, 'recall': 0.8501276762914948, 'f1-score': 0.8452053538832487, 'support': 10182}
 
time = 8.31 secondes

Val loss 0.5415159095550927 accuracy 0.8392226099967957 macro_avg {'precision': 0.8340697754287929, 'recall': 0.8317706423285877, 'f1-score': 0.8299488101825231, 'support': 1132} weighted_avg {'precision': 0.8432904159046328, 'recall': 0.8392226148409894, 'f1-score': 0.8384185527481746, 'support': 1132}
 
----------
Epoch 3/40
time = 303.15 secondes

Train loss 0.33370025627595756 accuracy 0.9042428135871887 macro_avg {'precision': 0.8976416690810577, 'recall': 0.8964986249594474, 'f1-score': 0.8966549419232817, 'support': 10182} weighted_avg {'precision': 0.9043064908225056, 'recall': 0.9042427813789039, 'f1-score': 0.9038962102241068, 'support': 10182}
 
time = 9.05 secondes

Val loss 0.5729276182943247 accuracy 0.8586572408676147 macro_avg {'precision': 0.8619017029944007, 'recall': 0.8533170867379519, 'f1-score': 0.855233456028546, 'support': 1132} weighted_avg {'precision': 0.8632364803276142, 'recall': 0.8586572438162544, 'f1-score': 0.858745054333143, 'support': 1132}
 
----------
Epoch 4/40
time = 313.59 secondes

Train loss 0.25034259176583523 accuracy 0.9294834136962891 macro_avg {'precision': 0.9247844065817039, 'recall': 0.9241191152890309, 'f1-score': 0.9243329637332467, 'support': 10182} weighted_avg {'precision': 0.9296761676944256, 'recall': 0.9294834020821057, 'f1-score': 0.9294651717965411, 'support': 10182}
 
time = 8.58 secondes

Val loss 0.5790796351986347 accuracy 0.8745583295822144 macro_avg {'precision': 0.879705594908519, 'recall': 0.871913809436416, 'f1-score': 0.8704749779291246, 'support': 1132} weighted_avg {'precision': 0.8797764337550157, 'recall': 0.8745583038869258, 'f1-score': 0.8715064886005104, 'support': 1132}
 
----------
Epoch 5/40
time = 312.75 secondes

Train loss 0.20140249356685946 accuracy 0.9469652771949768 macro_avg {'precision': 0.9442490998818915, 'recall': 0.9430381131544543, 'f1-score': 0.9435215245860089, 'support': 10182} weighted_avg {'precision': 0.946757785286615, 'recall': 0.9469652327637006, 'f1-score': 0.9467637306755394, 'support': 10182}
 
time = 8.24 secondes

Val loss 0.7114950385679242 accuracy 0.8568904399871826 macro_avg {'precision': 0.8668227687788608, 'recall': 0.8551749333269336, 'f1-score': 0.8558185750753685, 'support': 1132} weighted_avg {'precision': 0.8730611187672395, 'recall': 0.8568904593639576, 'f1-score': 0.8596838502203872, 'support': 1132}
 
----------
Epoch 6/40
time = 308.69 secondes

Train loss 0.1733208008213232 accuracy 0.9562954306602478 macro_avg {'precision': 0.9530445523929776, 'recall': 0.9527129217752808, 'f1-score': 0.952818665521092, 'support': 10182} weighted_avg {'precision': 0.9562991424309477, 'recall': 0.9562954232960126, 'f1-score': 0.9562431131586818, 'support': 10182}
 
time = 8.59 secondes

Val loss 0.739164548696504 accuracy 0.8551236987113953 macro_avg {'precision': 0.8566393002041981, 'recall': 0.8509742036621242, 'f1-score': 0.8487077916444103, 'support': 1132} weighted_avg {'precision': 0.859637924485781, 'recall': 0.8551236749116607, 'f1-score': 0.8523382429384692, 'support': 1132}
 
----------
Epoch 7/40
time = 311.93 secondes

Train loss 0.16845653803300498 accuracy 0.9604203701019287 macro_avg {'precision': 0.958084093902832, 'recall': 0.9575989490664766, 'f1-score': 0.9578090134985853, 'support': 10182} weighted_avg {'precision': 0.960405850800519, 'recall': 0.9604203496366136, 'f1-score': 0.9603844109058542, 'support': 10182}
 
time = 8.50 secondes

Val loss 0.731453774874033 accuracy 0.8674911856651306 macro_avg {'precision': 0.8703784360549329, 'recall': 0.8617156211545695, 'f1-score': 0.8626147803154716, 'support': 1132} weighted_avg {'precision': 0.8746081339112232, 'recall': 0.8674911660777385, 'f1-score': 0.8680424299641178, 'support': 1132}
 
----------
Epoch 8/40
time = 307.66 secondes

Train loss 0.14032596403574263 accuracy 0.9649381637573242 macro_avg {'precision': 0.9628480266018468, 'recall': 0.9627667629775569, 'f1-score': 0.9627603703997801, 'support': 10182} weighted_avg {'precision': 0.9649801795922303, 'recall': 0.9649381261048909, 'f1-score': 0.9649134394246022, 'support': 10182}
 
time = 8.29 secondes

Val loss 0.7726496968046979 accuracy 0.8657243847846985 macro_avg {'precision': 0.8697393409398201, 'recall': 0.8636686521518773, 'f1-score': 0.8619010275159067, 'support': 1132} weighted_avg {'precision': 0.8739606405148882, 'recall': 0.8657243816254417, 'f1-score': 0.865270631968905, 'support': 1132}
 
----------
Epoch 9/40
time = 308.19 secondes

Train loss 0.1271296743559578 accuracy 0.9708309173583984 macro_avg {'precision': 0.9692668581292023, 'recall': 0.9690626652225992, 'f1-score': 0.9691225938861756, 'support': 10182} weighted_avg {'precision': 0.9707976397814951, 'recall': 0.9708308780200353, 'f1-score': 0.9707737255048253, 'support': 10182}
 
time = 8.66 secondes

Val loss 0.8379463042279305 accuracy 0.8825088143348694 macro_avg {'precision': 0.8879434682814542, 'recall': 0.8779025766787554, 'f1-score': 0.8787817260191952, 'support': 1132} weighted_avg {'precision': 0.889004176122495, 'recall': 0.8825088339222615, 'f1-score': 0.8822476666221504, 'support': 1132}
 
----------
Epoch 10/40
time = 312.51 secondes

Train loss 0.13265953789789703 accuracy 0.971420168876648 macro_avg {'precision': 0.9697112908171256, 'recall': 0.9693597373787253, 'f1-score': 0.9694863874553876, 'support': 10182} weighted_avg {'precision': 0.9713898390912125, 'recall': 0.9714201532115498, 'f1-score': 0.9713579128883467, 'support': 10182}
 
time = 8.33 secondes

Val loss 0.8170956772703737 accuracy 0.8710247278213501 macro_avg {'precision': 0.8750606927227377, 'recall': 0.8621151305509747, 'f1-score': 0.863934522436803, 'support': 1132} weighted_avg {'precision': 0.8751564246307465, 'recall': 0.8710247349823321, 'f1-score': 0.8689425552574203, 'support': 1132}
 
----------
Epoch 11/40
time = 309.00 secondes

Train loss 0.11470121450696998 accuracy 0.9746611714363098 macro_avg {'precision': 0.9726011893842232, 'recall': 0.9729279224139352, 'f1-score': 0.9727310253637376, 'support': 10182} weighted_avg {'precision': 0.9747829233302278, 'recall': 0.9746611667648792, 'f1-score': 0.9746913653069597, 'support': 10182}
 
time = 8.18 secondes

Val loss 0.9760955509341905 accuracy 0.8577738404273987 macro_avg {'precision': 0.865714705400225, 'recall': 0.8632711330805233, 'f1-score': 0.8582300348132159, 'support': 1132} weighted_avg {'precision': 0.8761786951946624, 'recall': 0.857773851590106, 'f1-score': 0.8602057190522384, 'support': 1132}
 
----------
Epoch 12/40
time = 310.10 secondes

Train loss 0.11293581039817482 accuracy 0.9770182967185974 macro_avg {'precision': 0.9759908364577455, 'recall': 0.9755831848174829, 'f1-score': 0.9757635693091935, 'support': 10182} weighted_avg {'precision': 0.977012249466042, 'recall': 0.9770182675309369, 'f1-score': 0.9769948240974234, 'support': 10182}
 
time = 8.39 secondes

Val loss 0.8337907013417759 accuracy 0.8780918717384338 macro_avg {'precision': 0.8876273426281911, 'recall': 0.8739736285563359, 'f1-score': 0.8772878438622493, 'support': 1132} weighted_avg {'precision': 0.8831902317253781, 'recall': 0.8780918727915195, 'f1-score': 0.8773423094265524, 'support': 1132}
 
----------
Epoch 13/40
time = 313.77 secondes

Train loss 0.10531884459850854 accuracy 0.9794735908508301 macro_avg {'precision': 0.9787015833746094, 'recall': 0.9785504148813595, 'f1-score': 0.9785785603193267, 'support': 10182} weighted_avg {'precision': 0.9795868041510433, 'recall': 0.9794735808289138, 'f1-score': 0.9794840777527432, 'support': 10182}
 
time = 8.38 secondes

Val loss 0.9378063953391433 accuracy 0.8719081282615662 macro_avg {'precision': 0.8818392336777148, 'recall': 0.8704344953890532, 'f1-score': 0.8716079654848986, 'support': 1132} weighted_avg {'precision': 0.8824509040962666, 'recall': 0.8719081272084805, 'f1-score': 0.8728801640126845, 'support': 1132}
 
----------
Epoch 14/40
time = 306.84 secondes

Train loss 0.11398601444739463 accuracy 0.9772146940231323 macro_avg {'precision': 0.976764081458253, 'recall': 0.9764505521576987, 'f1-score': 0.9765491205594777, 'support': 10182} weighted_avg {'precision': 0.9773820098510843, 'recall': 0.9772146925947751, 'f1-score': 0.9772434858207348, 'support': 10182}
 
time = 8.21 secondes

Val loss 1.0014601832542251 accuracy 0.8577738404273987 macro_avg {'precision': 0.868709328629208, 'recall': 0.8558808620350833, 'f1-score': 0.855568855412313, 'support': 1132} weighted_avg {'precision': 0.8716251710169647, 'recall': 0.857773851590106, 'f1-score': 0.8579618177086387, 'support': 1132}
 
----------
Epoch 15/40
time = 310.40 secondes

Train loss 0.10113791733762882 accuracy 0.9817324876785278 macro_avg {'precision': 0.9812421987559521, 'recall': 0.9812053639001865, 'f1-score': 0.9812062675800272, 'support': 10182} weighted_avg {'precision': 0.9817802104890125, 'recall': 0.9817324690630524, 'f1-score': 0.9817384419571117, 'support': 10182}
 
time = 8.36 secondes

Val loss 0.9990888818152394 accuracy 0.8727915287017822 macro_avg {'precision': 0.8792546876438394, 'recall': 0.8709187391683466, 'f1-score': 0.8708962383397886, 'support': 1132} weighted_avg {'precision': 0.879162835712208, 'recall': 0.872791519434629, 'f1-score': 0.8718372363369307, 'support': 1132}
 
----------
Epoch 16/40
time = 307.91 secondes

Train loss 0.08328787871010329 accuracy 0.9837949872016907 macro_avg {'precision': 0.9834156709396622, 'recall': 0.9829778540572205, 'f1-score': 0.9831790158152727, 'support': 10182} weighted_avg {'precision': 0.9837989745451539, 'recall': 0.983794932233353, 'f1-score': 0.9837818579775836, 'support': 10182}
 
time = 8.33 secondes

Val loss 1.0269700027980742 accuracy 0.8692579865455627 macro_avg {'precision': 0.8755527117883274, 'recall': 0.8608398422472383, 'f1-score': 0.8621995077834137, 'support': 1132} weighted_avg {'precision': 0.8746116308935796, 'recall': 0.8692579505300353, 'f1-score': 0.8674815432347414, 'support': 1132}
 
----------
Epoch 17/40
time = 303.40 secondes

Train loss 0.09217557241770825 accuracy 0.9832056760787964 macro_avg {'precision': 0.9822592588583328, 'recall': 0.982537565608182, 'f1-score': 0.9823827857907009, 'support': 10182} weighted_avg {'precision': 0.9832233446063818, 'recall': 0.9832056570418385, 'f1-score': 0.9831990801294013, 'support': 10182}
 
time = 8.09 secondes

Val loss 0.9050326387875084 accuracy 0.8763250708580017 macro_avg {'precision': 0.879106168895755, 'recall': 0.8737669021161253, 'f1-score': 0.8749792827252543, 'support': 1132} weighted_avg {'precision': 0.8798852514733468, 'recall': 0.8763250883392226, 'f1-score': 0.876654758979767, 'support': 1132}
 
----------
Epoch 18/40
time = 308.35 secondes

Train loss 0.09564668387959542 accuracy 0.9832056760787964 macro_avg {'precision': 0.982670896459229, 'recall': 0.9820788294100261, 'f1-score': 0.9823278518589411, 'support': 10182} weighted_avg {'precision': 0.9832545917673108, 'recall': 0.9832056570418385, 'f1-score': 0.9831852602776792, 'support': 10182}
 
time = 8.47 secondes

Val loss 0.8238715971289219 accuracy 0.8904593586921692 macro_avg {'precision': 0.8918787303050427, 'recall': 0.8911671409575292, 'f1-score': 0.8901491318894083, 'support': 1132} weighted_avg {'precision': 0.8941717249113397, 'recall': 0.8904593639575972, 'f1-score': 0.8910702594932621, 'support': 1132}
 
----------
Epoch 19/40
time = 307.49 secondes

Train loss 0.07362236403762834 accuracy 0.9863485097885132 macro_avg {'precision': 0.985515671432303, 'recall': 0.9856744581194088, 'f1-score': 0.9855714516549018, 'support': 10182} weighted_avg {'precision': 0.9863945910716675, 'recall': 0.9863484580632489, 'f1-score': 0.9863472359825014, 'support': 10182}
 
time = 8.22 secondes

Val loss 0.954496574170521 accuracy 0.8763250708580017 macro_avg {'precision': 0.8885223414691413, 'recall': 0.8713040255514782, 'f1-score': 0.8743813856364474, 'support': 1132} weighted_avg {'precision': 0.8850766860159388, 'recall': 0.8763250883392226, 'f1-score': 0.8757258750061196, 'support': 1132}
 
----------
Epoch 20/40
time = 307.57 secondes

Train loss 0.08252836218455525 accuracy 0.9843842387199402 macro_avg {'precision': 0.9839824232002007, 'recall': 0.983425973088399, 'f1-score': 0.9836819591887982, 'support': 10182} weighted_avg {'precision': 0.9843878801664078, 'recall': 0.9843842074248674, 'f1-score': 0.9843682165067267, 'support': 10182}
 
time = 8.05 secondes

Val loss 0.9666415486065835 accuracy 0.879858672618866 macro_avg {'precision': 0.882128307401041, 'recall': 0.8788808853019262, 'f1-score': 0.8780906032866683, 'support': 1132} weighted_avg {'precision': 0.8852063235466647, 'recall': 0.8798586572438163, 'f1-score': 0.8800771705338538, 'support': 1132}
 
----------
Epoch 21/40
time = 307.85 secondes

Train loss 0.0650960920629672 accuracy 0.9882145524024963 macro_avg {'precision': 0.9877944576645179, 'recall': 0.9877049608593005, 'f1-score': 0.9877322110146493, 'support': 10182} weighted_avg {'precision': 0.9882650419545278, 'recall': 0.9882144961697112, 'f1-score': 0.9882222221873228, 'support': 10182}
 
time = 8.34 secondes

Val loss 0.9403118649035451 accuracy 0.8754417300224304 macro_avg {'precision': 0.8770080260726678, 'recall': 0.8717703933516232, 'f1-score': 0.8721727452188789, 'support': 1132} weighted_avg {'precision': 0.8799982404104051, 'recall': 0.8754416961130742, 'f1-score': 0.8754210340453844, 'support': 1132}
 
----------
Epoch 22/40
time = 310.00 secondes

Train loss 0.07025356644346627 accuracy 0.9867413640022278 macro_avg {'precision': 0.9861366369999466, 'recall': 0.9863144752335827, 'f1-score': 0.9862156759678719, 'support': 10182} weighted_avg {'precision': 0.986759618150144, 'recall': 0.9867413081909252, 'f1-score': 0.9867412158962744, 'support': 10182}
 
time = 8.30 secondes

Val loss 1.0394878492971003 accuracy 0.8648409843444824 macro_avg {'precision': 0.872667006872231, 'recall': 0.8663035722595186, 'f1-score': 0.8660595197868138, 'support': 1132} weighted_avg {'precision': 0.8763964104041936, 'recall': 0.8648409893992933, 'f1-score': 0.8669843975426375, 'support': 1132}
 
----------
Epoch 23/40
time = 306.33 secondes

Train loss 0.06393094454584311 accuracy 0.9882145524024963 macro_avg {'precision': 0.9878648920980219, 'recall': 0.9879114060459573, 'f1-score': 0.9878729267685081, 'support': 10182} weighted_avg {'precision': 0.9882461748078519, 'recall': 0.9882144961697112, 'f1-score': 0.9882147461272122, 'support': 10182}
 
time = 8.18 secondes

Val loss 1.0203629459592007 accuracy 0.8736749291419983 macro_avg {'precision': 0.8756016684201855, 'recall': 0.8728307297551592, 'f1-score': 0.8717280125284489, 'support': 1132} weighted_avg {'precision': 0.8778830779242375, 'recall': 0.8736749116607774, 'f1-score': 0.8731524898932008, 'support': 1132}
 
----------
Epoch 24/40
time = 311.10 secondes

Train loss 0.06642742328256637 accuracy 0.988705575466156 macro_avg {'precision': 0.987698274171277, 'recall': 0.9878467794554174, 'f1-score': 0.987752656575833, 'support': 10182} weighted_avg {'precision': 0.9887500399842503, 'recall': 0.9887055588293067, 'f1-score': 0.9887121744496737, 'support': 10182}
 
time = 8.72 secondes

Val loss 0.9244489061561516 accuracy 0.880742073059082 macro_avg {'precision': 0.8858222546358903, 'recall': 0.8800457545740443, 'f1-score': 0.8800868011491273, 'support': 1132} weighted_avg {'precision': 0.8873589571333872, 'recall': 0.8807420494699647, 'f1-score': 0.881502634488669, 'support': 1132}
 
----------
Epoch 25/40
time = 309.35 secondes

Train loss 0.06735502938633775 accuracy 0.9883127212524414 macro_avg {'precision': 0.987624436752743, 'recall': 0.9877858650170112, 'f1-score': 0.9876800313745898, 'support': 10182} weighted_avg {'precision': 0.9883944870807512, 'recall': 0.9883127087016303, 'f1-score': 0.9883295458177437, 'support': 10182}
 
time = 8.30 secondes

Val loss 0.8539889652039536 accuracy 0.8948763608932495 macro_avg {'precision': 0.8966847394180277, 'recall': 0.8954338561063832, 'f1-score': 0.8941198626902332, 'support': 1132} weighted_avg {'precision': 0.8982817589350007, 'recall': 0.8948763250883393, 'f1-score': 0.8947236430045382, 'support': 1132}
 
----------
Epoch 26/40
time = 304.06 secondes

Train loss 0.057085726093806285 accuracy 0.9899823665618896 macro_avg {'precision': 0.9894725945929185, 'recall': 0.9896237124166689, 'f1-score': 0.9895310729076063, 'support': 10182} weighted_avg {'precision': 0.9900200610459495, 'recall': 0.9899823217442546, 'f1-score': 0.9899839801534652, 'support': 10182}
 
time = 7.91 secondes

Val loss 1.0001466779158619 accuracy 0.8754417300224304 macro_avg {'precision': 0.8754525561502357, 'recall': 0.8749056514682032, 'f1-score': 0.8739570910597505, 'support': 1132} weighted_avg {'precision': 0.87596361463957, 'recall': 0.8754416961130742, 'f1-score': 0.8746011155908654, 'support': 1132}
 
----------
Epoch 27/40
time = 308.79 secondes

Train loss 0.04783031648898306 accuracy 0.9913573265075684 macro_avg {'precision': 0.9908513926685201, 'recall': 0.9906436094053148, 'f1-score': 0.9907419669210041, 'support': 10182} weighted_avg {'precision': 0.991351597703733, 'recall': 0.9913572971911215, 'f1-score': 0.9913495008988563, 'support': 10182}
 
time = 8.56 secondes

Val loss 1.0176214348390766 accuracy 0.8772084712982178 macro_avg {'precision': 0.8826489300622123, 'recall': 0.8729591591602469, 'f1-score': 0.8753395844220571, 'support': 1132} weighted_avg {'precision': 0.8825022362569719, 'recall': 0.877208480565371, 'f1-score': 0.8774935157125731, 'support': 1132}
 
----------
Epoch 28/40
time = 308.54 secondes

Train loss 0.04072966468899452 accuracy 0.9924376606941223 macro_avg {'precision': 0.9919061010526452, 'recall': 0.9920735497512124, 'f1-score': 0.9919808594021944, 'support': 10182} weighted_avg {'precision': 0.9924600557904101, 'recall': 0.9924376350422314, 'f1-score': 0.9924410576624446, 'support': 10182}
 
time = 8.25 secondes

Val loss 1.0767498425390238 accuracy 0.8825088143348694 macro_avg {'precision': 0.8869375122540493, 'recall': 0.8808485610960061, 'f1-score': 0.8820892128401399, 'support': 1132} weighted_avg {'precision': 0.8861352216027867, 'recall': 0.8825088339222615, 'f1-score': 0.8825991227537512, 'support': 1132}
 
----------
Epoch 29/40
time = 303.44 secondes

Train loss 0.034679373116690254 accuracy 0.9933215975761414 macro_avg {'precision': 0.9930898792960166, 'recall': 0.9931795767841971, 'f1-score': 0.993127214256595, 'support': 10182} weighted_avg {'precision': 0.9933337678191076, 'recall': 0.993321547829503, 'f1-score': 0.9933206066326077, 'support': 10182}
 
time = 8.34 secondes

Val loss 1.0635571956016987 accuracy 0.8816254734992981 macro_avg {'precision': 0.8887649082733123, 'recall': 0.8825288136728922, 'f1-score': 0.8841209909843151, 'support': 1132} weighted_avg {'precision': 0.8883029073070999, 'recall': 0.8816254416961131, 'f1-score': 0.8833884383729838, 'support': 1132}
 
----------
Epoch 30/40
time = 308.81 secondes

Train loss 0.04866654621728916 accuracy 0.9916519522666931 macro_avg {'precision': 0.9914112481413913, 'recall': 0.9912650375958671, 'f1-score': 0.9913292785663476, 'support': 10182} weighted_avg {'precision': 0.9916628966705191, 'recall': 0.9916519347868789, 'f1-score': 0.9916486092739784, 'support': 10182}
 
time = 8.38 secondes

Val loss 1.0017690670567492 accuracy 0.8886925578117371 macro_avg {'precision': 0.892108677562897, 'recall': 0.8876849923818206, 'f1-score': 0.8883145858368893, 'support': 1132} weighted_avg {'precision': 0.8922225146339391, 'recall': 0.8886925795053003, 'f1-score': 0.8888277532757493, 'support': 1132}
 
----------
Epoch 31/40
time = 309.37 secondes

Train loss 0.03055749970238195 accuracy 0.9943037033081055 macro_avg {'precision': 0.9941216809037506, 'recall': 0.9941513166513577, 'f1-score': 0.9941313883588554, 'support': 10182} weighted_avg {'precision': 0.9943126926286381, 'recall': 0.9943036731486937, 'f1-score': 0.9943029179416338, 'support': 10182}
 
time = 8.37 secondes

Val loss 1.026589689955587 accuracy 0.8878092169761658 macro_avg {'precision': 0.8907660159625591, 'recall': 0.8874930795060653, 'f1-score': 0.8878969377684559, 'support': 1132} weighted_avg {'precision': 0.89002750453098, 'recall': 0.8878091872791519, 'f1-score': 0.8876275309563793, 'support': 1132}
 
----------
Epoch 32/40
time = 303.41 secondes

Train loss 0.029394353979378524 accuracy 0.9944019317626953 macro_avg {'precision': 0.9944723472515344, 'recall': 0.9944329212031082, 'f1-score': 0.9944454990783598, 'support': 10182} weighted_avg {'precision': 0.9944103608681236, 'recall': 0.9944018856806128, 'f1-score': 0.994398911727406, 'support': 10182}
 
time = 9.33 secondes

Val loss 1.1169127846085143 accuracy 0.8772084712982178 macro_avg {'precision': 0.8858294179375408, 'recall': 0.8777609356757206, 'f1-score': 0.8787960043508954, 'support': 1132} weighted_avg {'precision': 0.8863660535755502, 'recall': 0.877208480565371, 'f1-score': 0.8788280371430206, 'support': 1132}
 
----------
Epoch 33/40
time = 310.23 secondes

Train loss 0.029547060082878093 accuracy 0.9949911832809448 macro_avg {'precision': 0.9947686776865086, 'recall': 0.9948394315920943, 'f1-score': 0.9948005563283051, 'support': 10182} weighted_avg {'precision': 0.9949986739785404, 'recall': 0.9949911608721272, 'f1-score': 0.9949915750610724, 'support': 10182}
 
time = 8.52 secondes

Val loss 1.0079899036891604 accuracy 0.8833922147750854 macro_avg {'precision': 0.8853620476447587, 'recall': 0.881463463758379, 'f1-score': 0.8811049016425073, 'support': 1132} weighted_avg {'precision': 0.8864081572549982, 'recall': 0.8833922261484098, 'f1-score': 0.8828597797070523, 'support': 1132}
 
----------
Epoch 34/40
time = 310.83 secondes

Train loss 0.02735058315421032 accuracy 0.9951876401901245 macro_avg {'precision': 0.9950351977717936, 'recall': 0.9948232999055436, 'f1-score': 0.9949227493908408, 'support': 10182} weighted_avg {'precision': 0.9951934808587556, 'recall': 0.9951875859359655, 'f1-score': 0.9951850026470997, 'support': 10182}
 
time = 8.29 secondes

Val loss 0.9773601495931281 accuracy 0.8913427591323853 macro_avg {'precision': 0.8950732612951692, 'recall': 0.8938100563742584, 'f1-score': 0.8927925290897291, 'support': 1132} weighted_avg {'precision': 0.8963493078416178, 'recall': 0.8913427561837456, 'f1-score': 0.8920991063444577, 'support': 1132}
 
----------
Epoch 35/40
time = 303.89 secondes

Train loss 0.016721047615963932 accuracy 0.9969554543495178 macro_avg {'precision': 0.9969777553197545, 'recall': 0.9969496155721755, 'f1-score': 0.9969624889939821, 'support': 10182} weighted_avg {'precision': 0.9969562742318984, 'recall': 0.9969554115105087, 'f1-score': 0.9969546224501207, 'support': 10182}
 
time = 8.19 secondes

Val loss 1.0986538733269415 accuracy 0.8825088143348694 macro_avg {'precision': 0.8861255857704856, 'recall': 0.8834791561686914, 'f1-score': 0.8825929702729448, 'support': 1132} weighted_avg {'precision': 0.8873807896302193, 'recall': 0.8825088339222615, 'f1-score': 0.8825704700857182, 'support': 1132}
 
----------
Epoch 36/40
time = 307.05 secondes

Train loss 0.018567081910086398 accuracy 0.9965626001358032 macro_avg {'precision': 0.9962625521614419, 'recall': 0.9965104840269146, 'f1-score': 0.9963819386783273, 'support': 10182} weighted_avg {'precision': 0.9965720743957354, 'recall': 0.9965625613828325, 'f1-score': 0.9965636581514095, 'support': 10182}
 
time = 8.23 secondes

Val loss 1.0434540558257346 accuracy 0.8842756152153015 macro_avg {'precision': 0.8881705622199494, 'recall': 0.8859486917099092, 'f1-score': 0.8856793392284207, 'support': 1132} weighted_avg {'precision': 0.8899657901713558, 'recall': 0.8842756183745583, 'f1-score': 0.8856502506174831, 'support': 1132}
 
----------
Epoch 37/40
time = 307.59 secondes

Train loss 0.015548597108855764 accuracy 0.9975447058677673 macro_avg {'precision': 0.9976054962598517, 'recall': 0.997511378327655, 'f1-score': 0.997556142783448, 'support': 10182} weighted_avg {'precision': 0.9975495395628077, 'recall': 0.9975446867020232, 'f1-score': 0.9975448868471822, 'support': 10182}
 
time = 8.29 secondes

Val loss 1.1043694509106399 accuracy 0.8886925578117371 macro_avg {'precision': 0.895549463366575, 'recall': 0.8914364262271018, 'f1-score': 0.8896494551178714, 'support': 1132} weighted_avg {'precision': 0.9001295567625411, 'recall': 0.8886925795053003, 'f1-score': 0.890485442099665, 'support': 1132}
 
----------
Epoch 38/40
time = 303.80 secondes

Train loss 0.008600004933812461 accuracy 0.9982321858406067 macro_avg {'precision': 0.9981830544061164, 'recall': 0.9982524727172327, 'f1-score': 0.9982168685026602, 'support': 10182} weighted_avg {'precision': 0.9982338988536108, 'recall': 0.9982321744254566, 'f1-score': 0.9982321621421326, 'support': 10182}
 
time = 7.75 secondes

Val loss 1.0721114319226794 accuracy 0.8860424160957336 macro_avg {'precision': 0.8881970856271911, 'recall': 0.8870366214800225, 'f1-score': 0.8862370398900522, 'support': 1132} weighted_avg {'precision': 0.8911754016975774, 'recall': 0.8860424028268551, 'f1-score': 0.8871175660687921, 'support': 1132}
 
----------
Epoch 39/40
time = 310.66 secondes

Train loss 0.002249864296060351 accuracy 0.998919665813446 macro_avg {'precision': 0.9989396607290774, 'recall': 0.9989123870977963, 'f1-score': 0.9989256678952165, 'support': 10182} weighted_avg {'precision': 0.9989202661276142, 'recall': 0.9989196621488902, 'f1-score': 0.9989196487191433, 'support': 10182}
 
time = 8.48 secondes

Val loss 1.0914309046944817 accuracy 0.8895759582519531 macro_avg {'precision': 0.8911707643579755, 'recall': 0.8905748435607908, 'f1-score': 0.8892216914553392, 'support': 1132} weighted_avg {'precision': 0.8942036257694388, 'recall': 0.8895759717314488, 'f1-score': 0.8901574959089651, 'support': 1132}
 
----------
Epoch 40/40
time = 309.79 secondes

Train loss 0.0032140377387800336 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990326694912246, 'recall': 0.9990026890237791, 'f1-score': 0.9990170505480045, 'support': 10182} weighted_avg {'precision': 0.9990184775212153, 'recall': 0.9990178746808093, 'f1-score': 0.9990175797515805, 'support': 10182}
 
time = 8.03 secondes

Val loss 1.1260294311316716 accuracy 0.8833922147750854 macro_avg {'precision': 0.8871537380478541, 'recall': 0.8854589906390359, 'f1-score': 0.8841513894674955, 'support': 1132} weighted_avg {'precision': 0.8892425695557562, 'recall': 0.8833922261484098, 'f1-score': 0.8840508971977776, 'support': 1132}
 
----------
best_accuracy 0.8948763608932495 best_epoch 25 macro_avg {'precision': 0.8966847394180277, 'recall': 0.8954338561063832, 'f1-score': 0.8941198626902332, 'support': 1132} weighted_avg {'precision': 0.8982817589350007, 'recall': 0.8948763250883393, 'f1-score': 0.8947236430045382, 'support': 1132}

average train time 308.68189826011655

average val time 8.367447924613952
 
time = 53.69 secondes

test_accuracy 0.8281996846199036 macro_avg {'precision': 0.8270047565290295, 'recall': 0.8186074623647551, 'f1-score': 0.8188225084290254, 'support': 7532} weighted_avg {'precision': 0.8342000593454972, 'recall': 0.8281996813595327, 'f1-score': 0.8275247315426482, 'support': 7532}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_2
----------
Epoch 1/40
time = 293.78 secondes

Train loss 0.2707194018135737 micro_f1_score 0.607479174212242 
 
time = 17.52 secondes

Val loss 0.24392803453031134 micro_f1_score 0.6103542234332425
 
----------
Epoch 2/40
time = 301.87 secondes

Train loss 0.1832946844667465 micro_f1_score 0.7448395921412584 
 
time = 16.99 secondes

Val loss 0.20892381973442484 micro_f1_score 0.694888178913738
 
----------
Epoch 3/40
time = 299.28 secondes

Train loss 0.1587210224521858 micro_f1_score 0.7862182116488926 
 
time = 16.92 secondes

Val loss 0.20534692668035381 micro_f1_score 0.7046263345195729
 
----------
Epoch 4/40
time = 292.01 secondes

Train loss 0.14107325987907143 micro_f1_score 0.81879304021841 
 
time = 17.26 secondes

Val loss 0.21253921213697213 micro_f1_score 0.7006566241792197
 
----------
Epoch 5/40
time = 305.20 secondes

Train loss 0.12734648193828427 micro_f1_score 0.8401882047537924 
 
time = 17.09 secondes

Val loss 0.21385108398609473 micro_f1_score 0.708349218452154
 
----------
Epoch 6/40
time = 296.18 secondes

Train loss 0.11746944989505652 micro_f1_score 0.8580871387690944 
 
time = 16.81 secondes

Val loss 0.21456570398123537 micro_f1_score 0.7203007518796992
 
----------
Epoch 7/40
time = 291.49 secondes

Train loss 0.1048635850031231 micro_f1_score 0.8751401569758129 
 
time = 17.05 secondes

Val loss 0.2370078735908524 micro_f1_score 0.7162412134665187
 
----------
Epoch 8/40
time = 308.72 secondes

Train loss 0.09378978568506804 micro_f1_score 0.890501110053917 
 
time = 17.50 secondes

Val loss 0.23419620731814964 micro_f1_score 0.721216509775525
 
----------
Epoch 9/40
time = 297.09 secondes

Train loss 0.08302472701321381 micro_f1_score 0.9058791057134971 
 
time = 16.80 secondes

Val loss 0.26072531511060526 micro_f1_score 0.721311475409836
 
----------
Epoch 10/40
time = 292.09 secondes

Train loss 0.07581199761186433 micro_f1_score 0.9149654522613065 
 
time = 17.18 secondes

Val loss 0.281043708812995 micro_f1_score 0.7146529562982006
 
----------
Epoch 11/40
time = 305.07 secondes

Train loss 0.06632431746494058 micro_f1_score 0.9287248584260888 
 
time = 17.01 secondes

Val loss 0.2976686037221893 micro_f1_score 0.7192293970745629
 
----------
Epoch 12/40
time = 300.58 secondes

Train loss 0.057691542930515094 micro_f1_score 0.9383225605482439 
 
time = 16.68 secondes

Val loss 0.3044913374498242 micro_f1_score 0.7256446991404011
 
----------
Epoch 13/40
time = 291.22 secondes

Train loss 0.05072741295601166 micro_f1_score 0.9449722728506612 
 
time = 17.20 secondes

Val loss 0.32909170403832294 micro_f1_score 0.7155049786628734
 
----------
Epoch 14/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.20 GiB total capacity; 13.89 GiB already allocated; 66.31 MiB free; 13.99 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.88 GiB already allocated; 28.31 MiB free; 13.97 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 18.31 MiB free; 13.97 GiB reserved in total by PyTorch)
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 14.31 MiB free; 13.97 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 14.31 MiB free; 13.96 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 79.20 GiB total capacity; 13.85 GiB already allocated; 10.31 MiB free; 13.96 GiB reserved in total by PyTorch)
