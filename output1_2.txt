[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
ECtHR_BERT_head_none_1
----------
Epoch 1/40
time = 506.01 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.2804569788075782 micro_f1_score 0.5818882466281311 
 
time = 34.75 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.23783346961756222 micro_f1_score 0.6345157433240335
 
----------
Epoch 2/40
time = 476.09 secondes

Train loss 0.18628405775572804 micro_f1_score 0.7398877572230307 
 
time = 45.85 secondes

Val loss 0.2073489772003205 micro_f1_score 0.6868442292171105
 
----------
Epoch 3/40
time = 483.86 secondes

Train loss 0.15960108807293683 micro_f1_score 0.7850252452690777 
 
time = 45.85 secondes

Val loss 0.19912525254194854 micro_f1_score 0.7110073901205757
 
----------
Epoch 4/40
time = 482.29 secondes

Train loss 0.1409532786892341 micro_f1_score 0.8186835484132782 
 
time = 45.87 secondes

Val loss 0.2035165182391151 micro_f1_score 0.7276958882854926
 
----------
Epoch 5/40
time = 476.46 secondes

Train loss 0.12795666822710552 micro_f1_score 0.8382275719998385 
 
time = 46.18 secondes

Val loss 0.21280535054011424 micro_f1_score 0.7204874333587206
 
----------
Epoch 6/40
time = 479.90 secondes

Train loss 0.11346205365382604 micro_f1_score 0.8603607214428858 
 
time = 45.97 secondes

Val loss 0.23058600076397912 micro_f1_score 0.7122571001494769
 
----------
Epoch 7/40
time = 476.26 secondes

Train loss 0.10261836867813054 micro_f1_score 0.8784622731614136 
 
time = 45.85 secondes

Val loss 0.2239383929332749 micro_f1_score 0.7246590490232215
 
----------
Epoch 8/40
time = 486.56 secondes

Train loss 0.09023932748482572 micro_f1_score 0.895446813560663 
 
time = 45.85 secondes

Val loss 0.24799074110437613 micro_f1_score 0.7272061515928232
 
----------
Epoch 9/40
time = 483.77 secondes

Train loss 0.0817274188043902 micro_f1_score 0.9069785759294267 
 
time = 46.11 secondes

Val loss 0.2627149858191365 micro_f1_score 0.712458896602119
 
----------
Epoch 10/40
time = 478.36 secondes

Train loss 0.07109046861327983 micro_f1_score 0.921493425172198 
 
time = 45.83 secondes

Val loss 0.2661759629845619 micro_f1_score 0.716871832005793
 
----------
Epoch 11/40
time = 481.54 secondes

Train loss 0.06129695204808167 micro_f1_score 0.9334008018372193 
 
time = 45.97 secondes

Val loss 0.2752551117637118 micro_f1_score 0.7247639796659405
 
----------
Epoch 12/40
time = 483.33 secondes

Train loss 0.053073615115135905 micro_f1_score 0.9450413062870884 
 
time = 42.67 secondes

Val loss 0.3000153930949383 micro_f1_score 0.7289652703186538
 
----------
Epoch 13/40
time = 480.23 secondes

Train loss 0.0469089022288015 micro_f1_score 0.9512430885821445 
 
time = 45.03 secondes

Val loss 0.32351943923801674 micro_f1_score 0.7202595529920693
 
----------
Epoch 14/40
time = 464.86 secondes

Train loss 0.039867176152010624 micro_f1_score 0.9591026481131711 
 
time = 45.68 secondes

Val loss 0.35508922572995794 micro_f1_score 0.7118644067796609
 
----------
Epoch 15/40
time = 468.18 secondes

Train loss 0.03487320116402263 micro_f1_score 0.9635552821774566 
 
time = 45.82 secondes

Val loss 0.3731955700233334 micro_f1_score 0.7157001414427157
 
----------
Epoch 16/40
time = 475.64 secondes

Train loss 0.030335103321677864 micro_f1_score 0.9682217196304672 
 
time = 45.76 secondes

Val loss 0.38210300881354536 micro_f1_score 0.7196294976843606
 
----------
Epoch 17/40
time = 480.89 secondes

Train loss 0.027712089614732913 micro_f1_score 0.9704734949896734 
 
time = 45.74 secondes

Val loss 0.40021133239640566 micro_f1_score 0.7151037938439513
 
----------
Epoch 18/40
time = 472.84 secondes

Train loss 0.026145221574729108 micro_f1_score 0.9725880551301685 
 
time = 45.80 secondes

Val loss 0.41753451355168075 micro_f1_score 0.7192118226600984
 
----------
Epoch 19/40
time = 441.75 secondes

Train loss 0.021644521615969286 micro_f1_score 0.9781719484689783 
 
time = 46.37 secondes

Val loss 0.41489062641487745 micro_f1_score 0.7248510339992991
 
----------
Epoch 20/40
time = 480.86 secondes

Train loss 0.019219876780397015 micro_f1_score 0.9801810058425937 
 
time = 45.76 secondes

Val loss 0.46038221042664323 micro_f1_score 0.7097465191003213
 
----------
Epoch 21/40
time = 491.65 secondes

Train loss 0.017442838108190126 micro_f1_score 0.9805880782578849 
 
time = 45.87 secondes

Val loss 0.4619181065774355 micro_f1_score 0.7208653175157014
 
----------
Epoch 22/40
time = 505.78 secondes

Train loss 0.015360030920720903 micro_f1_score 0.9834839989319908 
 
time = 47.44 secondes

Val loss 0.46367626380724986 micro_f1_score 0.7185628742514969
 
----------
Epoch 23/40
time = 500.25 secondes

Train loss 0.015432252638660233 micro_f1_score 0.9845274390243903 
 
time = 46.74 secondes

Val loss 0.48847981774416127 micro_f1_score 0.7146912704045423
 
----------
Epoch 24/40
time = 502.37 secondes

Train loss 0.013183228972277222 micro_f1_score 0.9861898421152748 
 
time = 45.41 secondes

Val loss 0.5010589488217088 micro_f1_score 0.7202016564638098
 
----------
Epoch 25/40
time = 500.85 secondes

Train loss 0.011464698623263053 micro_f1_score 0.9876947693245458 
 
time = 46.91 secondes

Val loss 0.5141131697130985 micro_f1_score 0.7147937411095306
 
----------
Epoch 26/40
time = 501.97 secondes

Train loss 0.011073308182355364 micro_f1_score 0.9888170406998857 
 
time = 47.77 secondes

Val loss 0.5161541492724028 micro_f1_score 0.7235859124866596
 
----------
Epoch 27/40
time = 500.22 secondes

Train loss 0.010004377891504896 micro_f1_score 0.9895619047619048 
 
time = 44.61 secondes

Val loss 0.5300766842775657 micro_f1_score 0.719534376136777
 
----------
Epoch 28/40
time = 509.44 secondes

Train loss 0.009609156783247001 micro_f1_score 0.9898413423125214 
 
time = 47.32 secondes

Val loss 0.5424610200475474 micro_f1_score 0.7164285714285714
 
----------
Epoch 29/40
time = 504.76 secondes

Train loss 0.008465084558767624 micro_f1_score 0.9917072428484479 
 
time = 40.70 secondes

Val loss 0.5689370407432807 micro_f1_score 0.7154811715481171
 
----------
Epoch 30/40
time = 500.30 secondes

Train loss 0.007903362613938002 micro_f1_score 0.9921253851713775 
 
time = 46.11 secondes

Val loss 0.5607585621173264 micro_f1_score 0.7173990710968202
 
----------
Epoch 31/40
time = 510.36 secondes

Train loss 0.006221188131409387 micro_f1_score 0.9937231331076197 
 
time = 46.36 secondes

Val loss 0.5642578787490969 micro_f1_score 0.7307420494699647
 
----------
Epoch 32/40
time = 502.24 secondes

Train loss 0.00662462264492435 micro_f1_score 0.9929671165177724 
 
time = 45.88 secondes

Val loss 0.5748273696078628 micro_f1_score 0.7269528501055595
 
----------
Epoch 33/40
time = 501.01 secondes

Train loss 0.005504724319814101 micro_f1_score 0.994407882223152 
 
time = 41.87 secondes

Val loss 0.5772586218157753 micro_f1_score 0.7192857142857144
 
----------
Epoch 34/40
time = 500.95 secondes

Train loss 0.005454211495856037 micro_f1_score 0.9943361082601588 
 
time = 42.38 secondes

Val loss 0.5766447252425991 micro_f1_score 0.7303730017761988
 
----------
Epoch 35/40
time = 493.10 secondes

Train loss 0.004387327973219382 micro_f1_score 0.9952487741837394 
 
time = 47.10 secondes

Val loss 0.5941003404679845 micro_f1_score 0.7264987584249735
 
----------
Epoch 36/40
time = 501.18 secondes

Train loss 0.0032818681517882567 micro_f1_score 0.9964669680507541 
 
time = 46.39 secondes

Val loss 0.5979671341473939 micro_f1_score 0.7270145544905929
 
----------
Epoch 37/40
time = 510.88 secondes

Train loss 0.002834785496017978 micro_f1_score 0.9972263383867168 
 
time = 47.72 secondes

Val loss 0.5985197207478227 micro_f1_score 0.7289982425307558
 
----------
Epoch 38/40
time = 507.32 secondes

Train loss 0.002239012798934316 micro_f1_score 0.9980237154150198 
 
time = 46.48 secondes

Val loss 0.6192701581071635 micro_f1_score 0.7229085774797036
 
----------
Epoch 39/40
time = 510.17 secondes

Train loss 0.0017592592516307746 micro_f1_score 0.9982902085945514 
 
time = 46.05 secondes

Val loss 0.6172564840707623 micro_f1_score 0.735012415750266
 
----------
Epoch 40/40
time = 510.22 secondes

Train loss 0.0016811353923503294 micro_f1_score 0.9982521468196671 
 
time = 47.00 secondes

Val loss 0.6210620537644527 micro_f1_score 0.7297297297297296
 
----------
best_f1_socre 0.735012415750266 best_epoch 39

average train time 490.6178145945072

average val time 45.4702605843544
 
time = 52.17 secondes

test_f1_score 0.7215363511659809

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_1
----------
Epoch 1/40
time = 518.72 secondes

Train loss 0.27570446902835694 micro_f1_score 0.6094351445707635 
 
time = 45.13 secondes

Val loss 0.21998196596004924 micro_f1_score 0.6693515908175593
 
----------
Epoch 2/40
time = 508.37 secondes

Train loss 0.17478582924147984 micro_f1_score 0.7618537590113285 
 
time = 49.28 secondes

Val loss 0.18571782502971712 micro_f1_score 0.7410071942446043
 
----------
Epoch 3/40
time = 508.64 secondes

Train loss 0.14849478256729273 micro_f1_score 0.8007798221030827 
 
time = 47.08 secondes

Val loss 0.18520203171694866 micro_f1_score 0.7444051825677267
 
----------
Epoch 4/40
time = 508.30 secondes

Train loss 0.1290407631093183 micro_f1_score 0.8340558766859345 
 
time = 45.83 secondes

Val loss 0.18083925874995405 micro_f1_score 0.7564646854496333
 
----------
Epoch 5/40
time = 509.31 secondes

Train loss 0.1143022081118312 micro_f1_score 0.860907643312102 
 
time = 47.60 secondes

Val loss 0.19666106522571844 micro_f1_score 0.7442218798151
 
----------
Epoch 6/40
time = 502.91 secondes

Train loss 0.10172378454055335 micro_f1_score 0.8774919741587729 
 
time = 40.95 secondes

Val loss 0.1967203452206049 micro_f1_score 0.7499999999999999
 
----------
Epoch 7/40
time = 512.51 secondes

Train loss 0.0898977640504437 micro_f1_score 0.8935110126932659 
 
time = 46.38 secondes

Val loss 0.2127039514970584 micro_f1_score 0.7494440326167532
 
----------
Epoch 8/40
time = 504.79 secondes

Train loss 0.07952816450699896 micro_f1_score 0.9087345146620668 
 
time = 46.17 secondes

Val loss 0.22984964791379991 micro_f1_score 0.7495334079880552
 
----------
Epoch 9/40
time = 509.75 secondes

Train loss 0.07036959582369204 micro_f1_score 0.9224942407559252 
 
time = 47.52 secondes

Val loss 0.2311722736378185 micro_f1_score 0.759747493501671
 
----------
Epoch 10/40
time = 503.94 secondes

Train loss 0.061654081158256074 micro_f1_score 0.9333126189458965 
 
time = 38.17 secondes

Val loss 0.26082825611849303 micro_f1_score 0.7381305637982195
 
----------
Epoch 11/40
time = 506.73 secondes

Train loss 0.05440029566142675 micro_f1_score 0.9408065830842681 
 
time = 46.17 secondes

Val loss 0.2764568137096577 micro_f1_score 0.7506297229219143
 
----------
Epoch 12/40
time = 499.66 secondes

Train loss 0.04730266691332364 micro_f1_score 0.9502454865272354 
 
time = 49.01 secondes

Val loss 0.30042490863897764 micro_f1_score 0.7427341227125942
 
----------
Epoch 13/40
time = 503.52 secondes

Train loss 0.044799936162769324 micro_f1_score 0.9519953730480047 
 
time = 47.58 secondes

Val loss 0.3034028253350102 micro_f1_score 0.7467532467532467
 
----------
Epoch 14/40
time = 506.48 secondes

Train loss 0.03728348524991406 micro_f1_score 0.9595073133179369 
 
time = 36.61 secondes

Val loss 0.3228647164145454 micro_f1_score 0.7491065046461758
 
----------
Epoch 15/40
time = 500.51 secondes

Train loss 0.033952836463697726 micro_f1_score 0.9632335974155835 
 
time = 48.18 secondes

Val loss 0.3358303266348409 micro_f1_score 0.7444168734491317
 
----------
Epoch 16/40
time = 506.07 secondes

Train loss 0.03060308824836587 micro_f1_score 0.967984356428051 
 
time = 44.90 secondes

Val loss 0.34308123295424414 micro_f1_score 0.7599421547360811
 
----------
Epoch 17/40
time = 509.57 secondes

Train loss 0.026355441888639083 micro_f1_score 0.971395749569213 
 
time = 47.83 secondes

Val loss 0.37555412056504706 micro_f1_score 0.7473722363175063
 
----------
Epoch 18/40
time = 510.70 secondes

Train loss 0.024552619428403238 micro_f1_score 0.9738977342314757 
 
time = 48.17 secondes

Val loss 0.3601852371433719 micro_f1_score 0.7581699346405228
 
----------
Epoch 19/40
time = 506.59 secondes

Train loss 0.020895436418170387 micro_f1_score 0.9778389118141525 
 
time = 48.58 secondes

Val loss 0.37636599103446866 micro_f1_score 0.7570864729099389
 
----------
Epoch 20/40
time = 503.63 secondes

Train loss 0.01981595504104982 micro_f1_score 0.9785951390743638 
 
time = 43.49 secondes

Val loss 0.41228034890821724 micro_f1_score 0.7491833030852995
 
----------
Epoch 21/40
time = 513.28 secondes

Train loss 0.016700300203163286 micro_f1_score 0.980832378770523 
 
time = 48.25 secondes

Val loss 0.41394789956632205 micro_f1_score 0.7530249110320285
 
----------
Epoch 22/40
time = 503.47 secondes

Train loss 0.01594335833885067 micro_f1_score 0.9832525845954297 
 
time = 46.50 secondes

Val loss 0.429209933173461 micro_f1_score 0.7450980392156862
 
----------
Epoch 23/40
time = 516.39 secondes

Train loss 0.01506049416519844 micro_f1_score 0.9847642264035956 
 
time = 45.59 secondes

Val loss 0.4287601201260676 micro_f1_score 0.751470588235294
 
----------
Epoch 24/40
time = 501.60 secondes

Train loss 0.014172010197839594 micro_f1_score 0.9850723533891851 
 
time = 47.20 secondes

Val loss 0.4455558140991164 micro_f1_score 0.7447118891320205
 
----------
Epoch 25/40
time = 510.27 secondes

Train loss 0.012940526990820905 micro_f1_score 0.986058205089136 
 
time = 44.94 secondes

Val loss 0.4443013802415035 micro_f1_score 0.7554088742207554
 
----------
Epoch 26/40
time = 506.59 secondes

Train loss 0.011168359902103065 micro_f1_score 0.9878847912221882 
 
time = 48.03 secondes

Val loss 0.46389655316950845 micro_f1_score 0.7496360989810772
 
----------
Epoch 27/40
time = 505.10 secondes

Train loss 0.009369613420445554 micro_f1_score 0.9899235712384501 
 
time = 48.14 secondes

Val loss 0.47818697793561904 micro_f1_score 0.7538627380524615
 
----------
Epoch 28/40
time = 505.38 secondes

Train loss 0.008996814915578423 micro_f1_score 0.9901337091920308 
 
time = 46.69 secondes

Val loss 0.49486840284261546 micro_f1_score 0.7489923048735799
 
----------
Epoch 29/40
time = 510.43 secondes

Train loss 0.00824860909299926 micro_f1_score 0.9920918561326134 
 
time = 41.57 secondes

Val loss 0.4875104379702787 micro_f1_score 0.7540864511442064
 
----------
Epoch 30/40
time = 506.40 secondes

Train loss 0.007229134245760695 micro_f1_score 0.9920541383112192 
 
time = 46.43 secondes

Val loss 0.5141654781630782 micro_f1_score 0.75475763016158
 
----------
Epoch 31/40
time = 504.58 secondes

Train loss 0.0076012524677066765 micro_f1_score 0.9928614823815309 
 
time = 47.57 secondes

Val loss 0.5279252201807304 micro_f1_score 0.7530774800868936
 
----------
Epoch 32/40
time = 501.78 secondes

Train loss 0.0054617439597358175 micro_f1_score 0.9947552447552447 
 
time = 47.38 secondes

Val loss 0.5268285596956972 micro_f1_score 0.751008434176751
 
----------
Epoch 33/40
time = 502.14 secondes

Train loss 0.004627003307346591 micro_f1_score 0.9954396898989131 
 
time = 47.84 secondes

Val loss 0.5421098242284822 micro_f1_score 0.7434782608695651
 
----------
Epoch 34/40
time = 500.31 secondes

Train loss 0.005343213272983515 micro_f1_score 0.9948671153188092 
 
time = 47.19 secondes

Val loss 0.5304189988824187 micro_f1_score 0.7543150936467131
 
----------
Epoch 35/40
time = 508.60 secondes

Train loss 0.0038986212689099023 micro_f1_score 0.9964274855579203 
 
time = 47.24 secondes

Val loss 0.5194919903258808 micro_f1_score 0.7613803230543319
 
----------
Epoch 36/40
time = 510.20 secondes

Train loss 0.0032698579825919624 micro_f1_score 0.9966562808724068 
 
time = 48.04 secondes

Val loss 0.5382208563998098 micro_f1_score 0.7531531531531532
 
----------
Epoch 37/40
time = 504.59 secondes

Train loss 0.0035378619206968068 micro_f1_score 0.9969242453009303 
 
time = 47.86 secondes

Val loss 0.5402519307175621 micro_f1_score 0.7583454281567489
 
----------
Epoch 38/40
time = 497.04 secondes

Train loss 0.0022226934041247805 micro_f1_score 0.9979486400243124 
 
time = 47.22 secondes

Val loss 0.5384613690806217 micro_f1_score 0.7617315387413606
 
----------
Epoch 39/40
time = 505.15 secondes

Train loss 0.001398453143277751 micro_f1_score 0.9986704653371321 
 
time = 47.76 secondes

Val loss 0.5369389897487202 micro_f1_score 0.7603787327021123
 
----------
Epoch 40/40
time = 503.40 secondes

Train loss 0.001464493613284831 micro_f1_score 0.9984424267750637 
 
time = 45.87 secondes

Val loss 0.5722495715637677 micro_f1_score 0.7508113956004328
 
----------
best_f1_socre 0.7617315387413606 best_epoch 38

average train time 506.43472374081614

average val time 46.29930005669594
 
time = 53.77 secondes

test_f1_score 0.738559772969138

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_1
----------
Epoch 1/40
time = 520.25 secondes

Train loss 0.2746562957226693 micro_f1_score 0.6031435929313559 
 
time = 48.19 secondes

Val loss 0.22359705178952607 micro_f1_score 0.660757453666398
 
----------
Epoch 2/40
time = 500.85 secondes

Train loss 0.1804099289616486 micro_f1_score 0.7529987963308844 
 
time = 46.70 secondes

Val loss 0.19575887442123693 micro_f1_score 0.7154728927582114
 
----------
Epoch 3/40
time = 502.60 secondes

Train loss 0.15627025279912862 micro_f1_score 0.7932358467445471 
 
time = 43.56 secondes

Val loss 0.19503839680405913 micro_f1_score 0.7239359625146428
 
----------
Epoch 4/40
time = 504.03 secondes

Train loss 0.13761272570034405 micro_f1_score 0.8239479322472409 
 
time = 45.85 secondes

Val loss 0.1963696643465855 micro_f1_score 0.723371049551307
 
----------
Epoch 5/40
time = 493.84 secondes

Train loss 0.12398361065634736 micro_f1_score 0.84546584847391 
 
time = 43.15 secondes

Val loss 0.1926589705294273 micro_f1_score 0.7433155080213905
 
----------
Epoch 6/40
time = 476.38 secondes

Train loss 0.10972230315275558 micro_f1_score 0.868479821343117 
 
time = 43.20 secondes

Val loss 0.21069088492725715 micro_f1_score 0.7363259147491513
 
----------
Epoch 7/40
time = 476.74 secondes

Train loss 0.09846788072404829 micro_f1_score 0.8836822074215034 
 
time = 46.27 secondes

Val loss 0.2191496077375334 micro_f1_score 0.7386576677915261
 
----------
Epoch 8/40
time = 479.86 secondes

Train loss 0.08861446638281147 micro_f1_score 0.8974713006430234 
 
time = 46.06 secondes

Val loss 0.22379347272827976 micro_f1_score 0.743807763401109
 
----------
Epoch 9/40
time = 473.35 secondes

Train loss 0.07886911129981682 micro_f1_score 0.9116271759204684 
 
time = 31.01 secondes

Val loss 0.24429748628716 micro_f1_score 0.7402550091074682
 
----------
Epoch 10/40
time = 469.81 secondes

Train loss 0.068979981696015 micro_f1_score 0.923425004876146 
 
time = 45.92 secondes

Val loss 0.24912584163859242 micro_f1_score 0.7470501474926253
 
----------
Epoch 11/40
time = 465.18 secondes

Train loss 0.06292343647093386 micro_f1_score 0.9322640921831205 
 
time = 46.38 secondes

Val loss 0.263491081226556 micro_f1_score 0.7432333577176298
 
----------
Epoch 12/40
time = 468.36 secondes

Train loss 0.05497131182786984 micro_f1_score 0.9417050780493474 
 
time = 46.30 secondes

Val loss 0.2769502308525023 micro_f1_score 0.7540263543191802
 
----------
Epoch 13/40
time = 476.26 secondes

Train loss 0.047821540639710586 micro_f1_score 0.9505662273412437 
 
time = 45.81 secondes

Val loss 0.30313109008015177 micro_f1_score 0.7351749539594843
 
----------
Epoch 14/40
time = 472.84 secondes

Train loss 0.042747416397607006 micro_f1_score 0.9540788762830902 
 
time = 45.82 secondes

Val loss 0.31879562383792437 micro_f1_score 0.7423423423423424
 
----------
Epoch 15/40
time = 478.33 secondes

Train loss 0.03742063533040686 micro_f1_score 0.9603171548439243 
 
time = 34.87 secondes

Val loss 0.3297859571996282 micro_f1_score 0.7458242556281771
 
----------
Epoch 16/40
time = 475.07 secondes

Train loss 0.03335297975808735 micro_f1_score 0.9644681750086429 
 
time = 46.00 secondes

Val loss 0.341770664223882 micro_f1_score 0.7451263537906136
 
----------
Epoch 17/40
time = 478.43 secondes

Train loss 0.02830202784252915 micro_f1_score 0.9709794901284263 
 
time = 46.33 secondes

Val loss 0.345536682205122 micro_f1_score 0.7593738623953404
 
----------
Epoch 18/40
time = 480.21 secondes

Train loss 0.02484264615535115 micro_f1_score 0.9732047159699893 
 
time = 46.02 secondes

Val loss 0.35964583935307676 micro_f1_score 0.7398230088495575
 
----------
Epoch 19/40
time = 466.41 secondes

Train loss 0.023427264103487656 micro_f1_score 0.9754810083005011 
 
time = 45.85 secondes

Val loss 0.37939256942663035 micro_f1_score 0.7502726281352236
 
----------
Epoch 20/40
time = 483.27 secondes

Train loss 0.020399674525859907 micro_f1_score 0.9789542034299683 
 
time = 45.97 secondes

Val loss 0.3986355468142228 micro_f1_score 0.7425531914893617
 
----------
Epoch 21/40
time = 478.49 secondes

Train loss 0.01857897577697709 micro_f1_score 0.9802902979373568 
 
time = 45.84 secondes

Val loss 0.41747945217324084 micro_f1_score 0.7433501078360891
 
----------
Epoch 22/40
time = 479.63 secondes

Train loss 0.017558835703289127 micro_f1_score 0.9811594756754691 
 
time = 46.12 secondes

Val loss 0.4083784976821454 micro_f1_score 0.7507930912936199
 
----------
Epoch 23/40
time = 470.54 secondes

Train loss 0.01567814215439055 micro_f1_score 0.9825954198473282 
 
time = 46.45 secondes

Val loss 0.42771461227389634 micro_f1_score 0.7465879749170048
 
----------
Epoch 24/40
time = 473.28 secondes

Train loss 0.014674028186303215 micro_f1_score 0.9843690430804423 
 
time = 46.02 secondes

Val loss 0.4370339992837828 micro_f1_score 0.7476635514018691
 
----------
Epoch 25/40
time = 475.86 secondes

Train loss 0.01275469140353642 micro_f1_score 0.9860688185140074 
 
time = 42.44 secondes

Val loss 0.4432838303876705 micro_f1_score 0.751596877217885
 
----------
Epoch 26/40
time = 470.32 secondes

Train loss 0.011705293429370179 micro_f1_score 0.9878894051336735 
 
time = 46.20 secondes

Val loss 0.4553334534656806 micro_f1_score 0.7431091510474092
 
----------
Epoch 27/40
time = 475.17 secondes

Train loss 0.01001973471838036 micro_f1_score 0.9900937285681628 
 
time = 45.87 secondes

Val loss 0.4754749236048245 micro_f1_score 0.7461706783369803
 
----------
Epoch 28/40
time = 474.58 secondes

Train loss 0.010275660639452833 micro_f1_score 0.9891647340607534 
 
time = 46.00 secondes

Val loss 0.47850791548119215 micro_f1_score 0.7535596933187295
 
----------
Epoch 29/40
time = 477.90 secondes

Train loss 0.008448261072283515 micro_f1_score 0.99078586658544 
 
time = 46.07 secondes

Val loss 0.4890764168784267 micro_f1_score 0.7458624494299375
 
----------
Epoch 30/40
time = 472.69 secondes

Train loss 0.007773911128029581 micro_f1_score 0.9910958904109589 
 
time = 37.56 secondes

Val loss 0.4800793778945188 micro_f1_score 0.7565789473684211
 
----------
Epoch 31/40
time = 473.41 secondes

Train loss 0.007774244896201118 micro_f1_score 0.9918959022942587 
 
time = 46.31 secondes

Val loss 0.5008559825479008 micro_f1_score 0.7465099191770757
 
----------
Epoch 32/40
time = 481.56 secondes

Train loss 0.006271598140848984 micro_f1_score 0.993272264244175 
 
time = 45.93 secondes

Val loss 0.48491940054981436 micro_f1_score 0.7600147004777655
 
----------
Epoch 33/40
time = 476.38 secondes

Train loss 0.006027488423125498 micro_f1_score 0.9938776286268395 
 
time = 45.82 secondes

Val loss 0.5366975513638043 micro_f1_score 0.7458483754512634
 
----------
Epoch 34/40
time = 474.38 secondes

Train loss 0.004217025486902891 micro_f1_score 0.9954768330229199 
 
time = 45.85 secondes

Val loss 0.5325925738596525 micro_f1_score 0.7464114832535885
 
----------
Epoch 35/40
time = 459.90 secondes

Train loss 0.0037236477030517987 micro_f1_score 0.9962000303997568 
 
time = 30.63 secondes

Val loss 0.5264490684036349 micro_f1_score 0.7474452554744526
 
----------
Epoch 36/40
time = 482.06 secondes

Train loss 0.0035615973882371903 micro_f1_score 0.9961231470923603 
 
time = 21.01 secondes

Val loss 0.5382907651975507 micro_f1_score 0.7472924187725631
 
----------
Epoch 37/40
time = 461.82 secondes

Train loss 0.003104051732738266 micro_f1_score 0.9969221415814873 
 
time = 46.08 secondes

Val loss 0.5522115233003116 micro_f1_score 0.7449856733524355
 
----------
Epoch 38/40
time = 480.74 secondes

Train loss 0.002557515781069293 micro_f1_score 0.9973785190532275 
 
time = 46.06 secondes

Val loss 0.5335400935079231 micro_f1_score 0.756308579668349
 
----------
Epoch 39/40
time = 473.24 secondes

Train loss 0.0016426204212457215 micro_f1_score 0.9984044977966874 
 
time = 45.89 secondes

Val loss 0.5418197522397901 micro_f1_score 0.754191937210132
 
----------
Epoch 40/40
time = 475.18 secondes

Train loss 0.0018369423315185108 micro_f1_score 0.9980614998669658 
 
time = 45.88 secondes

Val loss 0.5579696346501835 micro_f1_score 0.7473385379701917
 
----------
best_f1_socre 0.7600147004777655 best_epoch 32

average train time 478.22971239089964

average val time 43.93179240822792
 
time = 51.05 secondes

test_f1_score 0.7473002159827214

----------
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_1
----------
Epoch 1/40
time = 17.74 secondes

Train loss 0.6634786959850427 accuracy 0.604651153087616 macro_avg {'precision': 0.46723044397463004, 'recall': 0.4891666531215968, 'f1-score': 0.4293396942426543, 'support': 516} weighted_avg {'precision': 0.5126112394906338, 'recall': 0.6046511627906976, 'f1-score': 0.5163824513539206, 'support': 516}
 
time = 1.22 secondes

Val loss 0.6336194574832916 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 15.67 secondes

Train loss 0.505781765236999 accuracy 0.7306201457977295 macro_avg {'precision': 0.7528108465608465, 'recall': 0.6491149651349902, 'f1-score': 0.6522152343731059, 'support': 516} weighted_avg {'precision': 0.7437560241581559, 'recall': 0.7306201550387597, 'f1-score': 0.6976580863507501, 'support': 516}
 
time = 1.04 secondes

Val loss 0.5580794811248779 accuracy 0.71875 macro_avg {'precision': 0.7083333333333333, 'recall': 0.7024291497975709, 'f1-score': 0.7046153846153846, 'support': 64} weighted_avg {'precision': 0.7161458333333333, 'recall': 0.71875, 'f1-score': 0.7167307692307692, 'support': 64}
 
----------
Epoch 3/40
time = 15.52 secondes

Train loss 0.41175049046675366 accuracy 0.8352712988853455 macro_avg {'precision': 0.8207270408163265, 'recall': 0.8269671504965622, 'f1-score': 0.8235485804632152, 'support': 516} weighted_avg {'precision': 0.8373825838474925, 'recall': 0.8352713178294574, 'f1-score': 0.8360645857715339, 'support': 516}
 
time = 1.03 secondes

Val loss 0.43673380464315414 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 4/40
time = 15.65 secondes

Train loss 0.31617514619773085 accuracy 0.8779069781303406 macro_avg {'precision': 0.865001565925462, 'recall': 0.8788664401930986, 'f1-score': 0.8705515535963875, 'support': 516} weighted_avg {'precision': 0.882622415312566, 'recall': 0.877906976744186, 'f1-score': 0.8790431803198623, 'support': 516}
 
time = 1.03 secondes

Val loss 0.7019896656274796 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 5/40
time = 17.03 secondes

Train loss 0.2904723178256642 accuracy 0.9127907156944275 macro_avg {'precision': 0.9085317460317461, 'recall': 0.9016059034832502, 'f1-score': 0.9048575116264777, 'support': 516} weighted_avg {'precision': 0.9124084840654608, 'recall': 0.9127906976744186, 'f1-score': 0.9124179976587435, 'support': 516}
 
time = 1.05 secondes

Val loss 0.5466563776135445 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 6/40
time = 16.00 secondes

Train loss 0.23550457394484317 accuracy 0.9224806427955627 macro_avg {'precision': 0.9140987182983364, 'recall': 0.9195910472506217, 'f1-score': 0.9166935744268646, 'support': 516} weighted_avg {'precision': 0.9232543341725805, 'recall': 0.9224806201550387, 'f1-score': 0.9227359309959876, 'support': 516}
 
time = 1.03 secondes

Val loss 0.6798510700464249 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 7/40
time = 15.68 secondes

Train loss 0.18668025142202774 accuracy 0.9457364082336426 macro_avg {'precision': 0.9396536447845348, 'recall': 0.9435983290801814, 'f1-score': 0.9415562351342167, 'support': 516} weighted_avg {'precision': 0.9460995857099596, 'recall': 0.9457364341085271, 'f1-score': 0.9458575992961883, 'support': 516}
 
time = 1.04 secondes

Val loss 0.7095450162887573 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 8/40
time = 15.73 secondes

Train loss 0.14452446370639585 accuracy 0.9593023061752319 macro_avg {'precision': 0.9538001543209876, 'recall': 0.9588527867626742, 'f1-score': 0.9562158820463298, 'support': 516} weighted_avg {'precision': 0.9597191567374868, 'recall': 0.9593023255813954, 'f1-score': 0.9594149695060329, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0426375716924667 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 9/40
time = 15.66 secondes

Train loss 0.212431918956678 accuracy 0.9476743936538696 macro_avg {'precision': 0.949331550802139, 'recall': 0.9370398062513207, 'f1-score': 0.9426305451580625, 'support': 516} weighted_avg {'precision': 0.9478967168262654, 'recall': 0.9476744186046512, 'f1-score': 0.9473117871803867, 'support': 516}
 
time = 1.03 secondes

Val loss 0.9518323987722397 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 10/40
time = 15.98 secondes

Train loss 0.09325832249878933 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1296310722827911 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 11/40
time = 15.53 secondes

Train loss 0.4155102070759643 accuracy 0.9127907156944275 macro_avg {'precision': 0.9350425768233988, 'recall': 0.8819872242901029, 'f1-score': 0.9002435912307156, 'support': 516} weighted_avg {'precision': 0.9209364748628845, 'recall': 0.9127906976744186, 'f1-score': 0.9099795973236436, 'support': 516}
 
time = 1.03 secondes

Val loss 0.786511491984129 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 12/40
time = 15.58 secondes

Train loss 0.18045913792836168 accuracy 0.9573643207550049 macro_avg {'precision': 0.9473684210526316, 'recall': 0.9665653495440729, 'f1-score': 0.9549266247379455, 'support': 516} weighted_avg {'precision': 0.9618523051815586, 'recall': 0.9573643410852714, 'f1-score': 0.9578112557489479, 'support': 516}
 
time = 1.03 secondes

Val loss 0.9950597286224365 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 13/40
time = 15.65 secondes

Train loss 0.3775819616258201 accuracy 0.8875969052314758 macro_avg {'precision': 0.875847503022697, 'recall': 0.8991596638655461, 'f1-score': 0.8826444984707081, 'support': 516} weighted_avg {'precision': 0.8996819924612613, 'recall': 0.8875968992248062, 'f1-score': 0.8892788466507263, 'support': 516}
 
time = 1.04 secondes

Val loss 0.6977469213306904 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 14/40
time = 15.61 secondes

Train loss 0.09153536744204095 accuracy 0.9806201457977295 macro_avg {'precision': 0.9812927681780141, 'recall': 0.9767241519431757, 'f1-score': 0.978933616395852, 'support': 516} weighted_avg {'precision': 0.98065602773952, 'recall': 0.9806201550387597, 'f1-score': 0.9805739485005979, 'support': 516}
 
time = 1.03 secondes

Val loss 1.0175443291664124 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 15/40
time = 15.50 secondes

Train loss 0.1353608556215256 accuracy 0.9728682041168213 macro_avg {'precision': 0.9740249031087655, 'recall': 0.9671830047299383, 'f1-score': 0.9704360921948665, 'support': 516} weighted_avg {'precision': 0.9729583484351338, 'recall': 0.9728682170542635, 'f1-score': 0.9727696173978015, 'support': 516}
 
time = 1.04 secondes

Val loss 1.2007273584604263 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 16/40
time = 15.58 secondes

Train loss 0.15615937252401968 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 1.04 secondes

Val loss 1.09597347676754 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 17/40
time = 16.02 secondes

Train loss 0.09571268709524619 accuracy 0.9806201457977295 macro_avg {'precision': 0.9790322318482518, 'recall': 0.9790322318482518, 'f1-score': 0.9790322318482518, 'support': 516} weighted_avg {'precision': 0.9806201550387597, 'recall': 0.9806201550387597, 'f1-score': 0.9806201550387597, 'support': 516}
 
time = 1.03 secondes

Val loss 1.2713378742337227 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 18/40
time = 16.10 secondes

Train loss 0.33285937528478715 accuracy 0.9341084957122803 macro_avg {'precision': 0.9471486707890704, 'recall': 0.9125530289485233, 'f1-score': 0.9260857109152496, 'support': 516} weighted_avg {'precision': 0.9377966485702076, 'recall': 0.9341085271317829, 'f1-score': 0.9327871221078833, 'support': 516}
 
time = 1.06 secondes

Val loss 0.9918077737092972 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 19/40
time = 16.58 secondes

Train loss 0.12046213579279455 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9912732392549515 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 20/40
time = 15.35 secondes

Train loss 0.08434435033070092 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 1.03 secondes

Val loss 0.6926561892032623 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 21/40
time = 15.29 secondes

Train loss 0.22241389040595316 accuracy 0.9534883499145508 macro_avg {'precision': 0.9465132997843277, 'recall': 0.9542935162459568, 'f1-score': 0.9501248489730165, 'support': 516} weighted_avg {'precision': 0.9543740955607941, 'recall': 0.9534883720930233, 'f1-score': 0.9536891794434714, 'support': 516}
 
time = 0.43 secondes

Val loss 1.6328659355640411 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 22/40
time = 14.31 secondes

Train loss 0.029512416162161215 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.03 secondes

Val loss 1.7002360820770264 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 23/40
time = 15.65 secondes

Train loss 0.3315009389691774 accuracy 0.9457364082336426 macro_avg {'precision': 0.9607843137254901, 'recall': 0.9251336898395721, 'f1-score': 0.9391294089890292, 'support': 516} weighted_avg {'precision': 0.9499924000607995, 'recall': 0.9457364341085271, 'f1-score': 0.9446482182064923, 'support': 516}
 
time = 1.03 secondes

Val loss 1.1932746469974518 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 24/40
time = 15.44 secondes

Train loss 0.10209415744016455 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 1.03 secondes

Val loss 1.2806468904018402 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 25/40
time = 15.54 secondes

Train loss 0.08588892433115027 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 1.04 secondes

Val loss 1.521543249487877 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 26/40
time = 15.66 secondes

Train loss 0.12204994678419705 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.03 secondes

Val loss 1.4810068905353546 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 27/40
time = 15.68 secondes

Train loss 0.06973913210359486 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.04 secondes

Val loss 1.28304623067379 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 28/40
time = 16.06 secondes

Train loss 0.004020648195309508 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.03 secondes

Val loss 1.466261386871338 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 29/40
time = 15.71 secondes

Train loss 0.1311726791830028 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.03 secondes

Val loss 1.5679965019226074 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 30/40
time = 15.69 secondes

Train loss 0.027731689650064447 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.03 secondes

Val loss 1.809530958533287 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 31/40
time = 15.58 secondes

Train loss 0.022239881039819342 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.03 secondes

Val loss 1.9180109798908234 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 32/40
time = 15.60 secondes

Train loss 0.007021469056560432 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.03 secondes

Val loss 2.0828984081745148 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 33/40
time = 15.44 secondes

Train loss 0.03766377326885986 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.03 secondes

Val loss 1.7725324183702469 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 34/40
time = 15.61 secondes

Train loss 0.011992859281952295 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.03 secondes

Val loss 1.7622771263122559 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 35/40
time = 16.04 secondes

Train loss 0.0015087289754195478 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.03 secondes

Val loss 1.8000438660383224 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 36/40
time = 15.67 secondes

Train loss 0.014856227347274509 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.04 secondes

Val loss 1.7995176911354065 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 15.58 secondes

Train loss 0.00011126053582164317 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.03 secondes

Val loss 2.111596405506134 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 38/40
time = 15.63 secondes

Train loss 0.015950965012245542 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.03 secondes

Val loss 2.1945945471525192 accuracy 0.75 macro_avg {'precision': 0.7658730158730158, 'recall': 0.771255060728745, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.7896825396825398, 'recall': 0.75, 'f1-score': 0.7512218963831867, 'support': 64}
 
----------
Epoch 39/40
time = 15.68 secondes

Train loss 0.01493664928575251 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.03 secondes

Val loss 2.0203352123498917 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 40/40
time = 15.77 secondes

Train loss 9.164287445001361e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.03 secondes

Val loss 1.8848342895507812 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 20 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 15.74487699866295

average val time 1.0244645059108735
 
time = 1.24 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_1
----------
Epoch 1/40
time = 18.96 secondes

Train loss 0.6628503835562504 accuracy 0.6317829489707947 macro_avg {'precision': 0.4180039138943249, 'recall': 0.49659476943582076, 'f1-score': 0.39211309523809523, 'support': 516} weighted_avg {'precision': 0.47799723903578634, 'recall': 0.6317829457364341, 'f1-score': 0.4971535852713178, 'support': 516}
 
time = 0.74 secondes

Val loss 0.6295455396175385 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 16.51 secondes

Train loss 0.4562738280404698 accuracy 0.7965116500854492 macro_avg {'precision': 0.7966988727858293, 'recall': 0.7515644555694618, 'f1-score': 0.7642041127189643, 'support': 516} weighted_avg {'precision': 0.7965880862325082, 'recall': 0.7965116279069767, 'f1-score': 0.7882233124922511, 'support': 516}
 
time = 0.57 secondes

Val loss 0.40233074873685837 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 3/40
time = 16.07 secondes

Train loss 0.33964662931182166 accuracy 0.8740310072898865 macro_avg {'precision': 0.8658730158730159, 'recall': 0.8596703671797539, 'f1-score': 0.8625719612382454, 'support': 516} weighted_avg {'precision': 0.8732988802756245, 'recall': 0.874031007751938, 'f1-score': 0.8734926632848516, 'support': 516}
 
time = 1.05 secondes

Val loss 0.35796137899160385 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 4/40
time = 15.85 secondes

Train loss 0.26679121364246716 accuracy 0.9166666865348816 macro_avg {'precision': 0.9137856525496975, 'recall': 0.9046454171610617, 'f1-score': 0.9088620073524881, 'support': 516} weighted_avg {'precision': 0.9163425525785077, 'recall': 0.9166666666666666, 'f1-score': 0.9162014882969474, 'support': 516}
 
time = 1.05 secondes

Val loss 0.4431004077196121 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 5/40
time = 16.01 secondes

Train loss 0.22460599367817244 accuracy 0.9302325248718262 macro_avg {'precision': 0.9272202523295127, 'recall': 0.9210539147960926, 'f1-score': 0.9239785227867994, 'support': 516} weighted_avg {'precision': 0.9299978330114812, 'recall': 0.9302325581395349, 'f1-score': 0.9299790161657754, 'support': 516}
 
time = 0.84 secondes

Val loss 0.36050155386328697 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 6/40
time = 15.98 secondes

Train loss 0.16348214661984733 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.05 secondes

Val loss 0.34221141459420323 accuracy 0.90625 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}
 
----------
Epoch 7/40
time = 15.89 secondes

Train loss 0.28223440233110025 accuracy 0.9282945990562439 macro_avg {'precision': 0.9302325581395349, 'recall': 0.9137639581944963, 'f1-score': 0.9209791107045739, 'support': 516} weighted_avg {'precision': 0.9286325941950603, 'recall': 0.9282945736434108, 'f1-score': 0.9275956440632671, 'support': 516}
 
time = 1.05 secondes

Val loss 1.269290342926979 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 8/40
time = 15.97 secondes

Train loss 0.18133225770328532 accuracy 0.9457364082336426 macro_avg {'precision': 0.9491565412292085, 'recall': 0.9332119695073386, 'f1-score': 0.9402777777777778, 'support': 516} weighted_avg {'precision': 0.9462997458695805, 'recall': 0.9457364341085271, 'f1-score': 0.9452465546942291, 'support': 516}
 
time = 1.05 secondes

Val loss 0.6174051351845264 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 9/40
time = 15.71 secondes

Train loss 0.7598081720520206 accuracy 0.8624030947685242 macro_avg {'precision': 0.8507323771742448, 'recall': 0.8736326251970807, 'f1-score': 0.8566930181069992, 'support': 516} weighted_avg {'precision': 0.8766267951638506, 'recall': 0.8624031007751938, 'f1-score': 0.8645651709116947, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9094495549798012 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 10/40
time = 15.66 secondes

Train loss 0.28750495851801877 accuracy 0.9263566136360168 macro_avg {'precision': 0.9171427207485321, 'recall': 0.9260926807860475, 'f1-score': 0.9211998456790123, 'support': 516} weighted_avg {'precision': 0.9278670593765909, 'recall': 0.9263565891472868, 'f1-score': 0.9267472515312469, 'support': 516}
 
time = 1.04 secondes

Val loss 0.8810809329152107 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 11/40
time = 15.66 secondes

Train loss 0.08311033513128871 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.26 secondes

Val loss 0.4948413297533989 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 12/40
time = 15.70 secondes

Train loss 0.06142362351458745 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.04 secondes

Val loss 1.5874108970165253 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 15.86 secondes

Train loss 0.06420099733143368 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 1.06 secondes

Val loss 0.5166541649959981 accuracy 0.90625 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}
 
----------
Epoch 14/40
time = 15.98 secondes

Train loss 0.12164887162207653 accuracy 0.963178277015686 macro_avg {'precision': 0.9564732142857143, 'recall': 0.9653544202980999, 'f1-score': 0.9605579179858952, 'support': 516} weighted_avg {'precision': 0.9641516126799556, 'recall': 0.9631782945736435, 'f1-score': 0.9633556132901075, 'support': 516}
 
time = 1.05 secondes

Val loss 0.8456711024045944 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 15/40
time = 15.84 secondes

Train loss 0.38747851732963073 accuracy 0.9166666865348816 macro_avg {'precision': 0.9353551912568305, 'recall': 0.8884888578255287, 'f1-score': 0.9052665286168691, 'support': 516} weighted_avg {'precision': 0.9230692167577413, 'recall': 0.9166666666666666, 'f1-score': 0.914310213550228, 'support': 516}
 
time = 1.05 secondes

Val loss 1.58351668715477 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 16/40
time = 15.93 secondes

Train loss 0.21031239659306733 accuracy 0.9399224519729614 macro_avg {'precision': 0.9363541121005763, 'recall': 0.9332688588007737, 'f1-score': 0.9347717050454469, 'support': 516} weighted_avg {'precision': 0.9397778170315235, 'recall': 0.939922480620155, 'f1-score': 0.9398159128496439, 'support': 516}
 
time = 1.05 secondes

Val loss 0.919677734375 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 17/40
time = 15.94 secondes

Train loss 0.0826659318567677 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9269739910960197 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 18/40
time = 15.64 secondes

Train loss 0.12887730393876237 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.04 secondes

Val loss 1.331927239894867 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 19/40
time = 15.72 secondes

Train loss 0.37671724605289375 accuracy 0.9360464811325073 macro_avg {'precision': 0.9259049773755657, 'recall': 0.9406157046958048, 'f1-score': 0.9320594818677658, 'support': 516} weighted_avg {'precision': 0.9392392168554959, 'recall': 0.936046511627907, 'f1-score': 0.9365887476752862, 'support': 516}
 
time = 0.92 secondes

Val loss 1.4992181807756424 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 20/40
time = 15.80 secondes

Train loss 0.07597242550180068 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 0.43 secondes

Val loss 1.3317749202251434 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 21/40
time = 16.23 secondes

Train loss 0.1084483665057853 accuracy 0.9767441749572754 macro_avg {'precision': 0.9712437095614666, 'recall': 0.9794548380280546, 'f1-score': 0.9750624244865083, 'support': 516} weighted_avg {'precision': 0.9774426592509617, 'recall': 0.9767441860465116, 'f1-score': 0.9768445897217357, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0214295089244843 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 22/40
time = 15.72 secondes

Train loss 0.09515326165869324 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.38 secondes

Val loss 0.7636239901185036 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 23/40
time = 15.76 secondes

Train loss 0.1738001392170025 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.04 secondes

Val loss 0.7040937021374702 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 24/40
time = 15.66 secondes

Train loss 0.023255324948078134 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.05 secondes

Val loss 1.6722402423620224 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 25/40
time = 15.70 secondes

Train loss 0.2183066088693908 accuracy 0.9554263353347778 macro_avg {'precision': 0.9461726998491704, 'recall': 0.961583472847553, 'f1-score': 0.9526475176654124, 'support': 516} weighted_avg {'precision': 0.9583395448221028, 'recall': 0.9554263565891473, 'f1-score': 0.9558042786827752, 'support': 516}
 
time = 1.04 secondes

Val loss 1.43671552836895 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 26/40
time = 15.69 secondes

Train loss 0.12066827521387798 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.05 secondes

Val loss 1.459636390209198 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 27/40
time = 15.63 secondes

Train loss 0.032706072872811506 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0415266901254654 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 28/40
time = 15.67 secondes

Train loss 0.2983545111086586 accuracy 0.9515503644943237 macro_avg {'precision': 0.9410377358490566, 'recall': 0.9620060790273557, 'f1-score': 0.9489244438109492, 'support': 516} weighted_avg {'precision': 0.9572637852859441, 'recall': 0.9515503875968992, 'f1-score': 0.9521114866964612, 'support': 516}
 
time = 1.04 secondes

Val loss 1.3416277095675468 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 29/40
time = 16.14 secondes

Train loss 0.06511727149667092 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.04 secondes

Val loss 0.8708817958831787 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 30/40
time = 15.60 secondes

Train loss 0.04144886207337329 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.05 secondes

Val loss 1.4607957601547241 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 31/40
time = 16.71 secondes

Train loss 0.03843684383195289 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.06 secondes

Val loss 1.2835112735629082 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 32/40
time = 15.62 secondes

Train loss 0.016523988967960715 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.04 secondes

Val loss 1.2867908030748367 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 33/40
time = 15.61 secondes

Train loss 0.06296595040586192 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9128449220133916 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 34/40
time = 15.67 secondes

Train loss 0.014218168155683528 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0166187044487742 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 35/40
time = 15.79 secondes

Train loss 0.03437636720958504 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.05 secondes

Val loss 1.906571015715599 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 36/40
time = 15.75 secondes

Train loss 8.44753391874926e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.05 secondes

Val loss 0.7774071809762972 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 37/40
time = 15.63 secondes

Train loss 0.00011370064572529924 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1958118139409635 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 38/40
time = 15.68 secondes

Train loss 0.013056622736423213 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9627771750092506 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 39/40
time = 15.68 secondes

Train loss 5.59912982818346e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.05 secondes

Val loss 1.2242348343133926 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 40/40
time = 16.12 secondes

Train loss 5.350993028101088e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.05 secondes

Val loss 1.6714696139097214 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 6 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}

average train time 15.918346786499024

average val time 1.0166025578975677
 
time = 1.26 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9049707602339181, 'recall': 0.9049707602339181, 'f1-score': 0.9049707602339181, 'support': 65} weighted_avg {'precision': 0.9076923076923077, 'recall': 0.9076923076923077, 'f1-score': 0.9076923076923077, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_1
----------
Epoch 1/40
time = 17.69 secondes

Train loss 0.6680439963485255 accuracy 0.6143410801887512 macro_avg {'precision': 0.5006741140215716, 'recall': 0.5002275571737399, 'f1-score': 0.4450443439207484, 'support': 516} weighted_avg {'precision': 0.5383860530810669, 'recall': 0.6143410852713178, 'f1-score': 0.5293957027691022, 'support': 516}
 
time = 1.23 secondes

Val loss 0.6712975054979324 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 15.48 secondes

Train loss 0.5477101884104989 accuracy 0.6860464811325073 macro_avg {'precision': 0.7042003549595741, 'recall': 0.5841555190741674, 'f1-score': 0.5627576106287269, 'support': 516} weighted_avg {'precision': 0.6978509811834737, 'recall': 0.686046511627907, 'f1-score': 0.6266518585918056, 'support': 516}
 
time = 1.04 secondes

Val loss 0.4967493340373039 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 3/40
time = 15.45 secondes

Train loss 0.4262808380704938 accuracy 0.8352712988853455 macro_avg {'precision': 0.8232142857142857, 'recall': 0.8177348308762576, 'f1-score': 0.8202864108500134, 'support': 516} weighted_avg {'precision': 0.8341892764857882, 'recall': 0.8352713178294574, 'f1-score': 0.8345673289109601, 'support': 516}
 
time = 1.04 secondes

Val loss 0.4238586947321892 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 4/40
time = 15.51 secondes

Train loss 0.32016519524834375 accuracy 0.8817829489707947 macro_avg {'precision': 0.8736757254721327, 'recall': 0.8692115143929913, 'f1-score': 0.8713411568504825, 'support': 516} weighted_avg {'precision': 0.8812495759822038, 'recall': 0.8817829457364341, 'f1-score': 0.8814277828491568, 'support': 516}
 
time = 1.04 secondes

Val loss 0.6212184876203537 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 5/40
time = 15.46 secondes

Train loss 0.34815526166648575 accuracy 0.8624030947685242 macro_avg {'precision': 0.8488412151581585, 'recall': 0.8620922256717001, 'f1-score': 0.8541136556403732, 'support': 516} weighted_avg {'precision': 0.8673584051352645, 'recall': 0.8624031007751938, 'f1-score': 0.8636835841700033, 'support': 516}
 
time = 1.04 secondes

Val loss 0.5301002562046051 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 6/40
time = 15.82 secondes

Train loss 0.1761878261511976 accuracy 0.9418604373931885 macro_avg {'precision': 0.9354973821989528, 'recall': 0.9394047754498318, 'f1-score': 0.9373816805009466, 'support': 516} weighted_avg {'precision': 0.9422403506635821, 'recall': 0.9418604651162791, 'f1-score': 0.9419902849602019, 'support': 516}
 
time = 1.04 secondes

Val loss 0.5894298404455185 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 7/40
time = 15.54 secondes

Train loss 0.146246847245052 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 1.04 secondes

Val loss 0.8151478171348572 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 8/40
time = 15.21 secondes

Train loss 0.2779965138232166 accuracy 0.9263566136360168 macro_avg {'precision': 0.9220203810367744, 'recall': 0.9180144011182809, 'f1-score': 0.9199477423042377, 'support': 516} weighted_avg {'precision': 0.926125324714726, 'recall': 0.9263565891472868, 'f1-score': 0.9261810043022717, 'support': 516}
 
time = 1.04 secondes

Val loss 0.6350322142243385 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 9/40
time = 15.45 secondes

Train loss 0.20172272243000794 accuracy 0.9457364082336426 macro_avg {'precision': 0.9366500829187396, 'recall': 0.9493685288428717, 'f1-score': 0.9421783953384132, 'support': 516} weighted_avg {'precision': 0.9479681694884748, 'recall': 0.9457364341085271, 'f1-score': 0.9461255945990081, 'support': 516}
 
time = 1.04 secondes

Val loss 1.4652857780456543 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 10/40
time = 15.46 secondes

Train loss 0.5695421920355522 accuracy 0.8682170510292053 macro_avg {'precision': 0.8741965105601469, 'recall': 0.8378004973749655, 'f1-score': 0.8508670520231214, 'support': 516} weighted_avg {'precision': 0.8701532591596016, 'recall': 0.8682170542635659, 'f1-score': 0.8648653492852981, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1138538271188736 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 11/40
time = 16.85 secondes

Train loss 0.402853588594801 accuracy 0.9069767594337463 macro_avg {'precision': 0.9056775476499435, 'recall': 0.8912764332038425, 'f1-score': 0.8976190476190476, 'support': 516} weighted_avg {'precision': 0.9067627588742178, 'recall': 0.9069767441860465, 'f1-score': 0.9061369509043927, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0432690680027008 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 12/40
time = 15.69 secondes

Train loss 0.2268762182176226 accuracy 0.9496123790740967 macro_avg {'precision': 0.9496377832667473, 'recall': 0.9408676429953026, 'f1-score': 0.9449613547974203, 'support': 516} weighted_avg {'precision': 0.9496149732441648, 'recall': 0.9496124031007752, 'f1-score': 0.9493643471912628, 'support': 516}
 
time = 1.04 secondes

Val loss 0.897117555141449 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 13/40
time = 15.44 secondes

Train loss 0.1688236690401523 accuracy 0.963178277015686 macro_avg {'precision': 0.955253164556962, 'recall': 0.967662500203176, 'f1-score': 0.9607235142118863, 'support': 516} weighted_avg {'precision': 0.9649546168187617, 'recall': 0.9631782945736435, 'f1-score': 0.9634256755403321, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0132050961256027 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 14/40
time = 15.43 secondes

Train loss 0.12966044406251362 accuracy 0.9748061895370483 macro_avg {'precision': 0.9722366372599895, 'recall': 0.9733189213789964, 'f1-score': 0.9727732115677321, 'support': 516} weighted_avg {'precision': 0.9748429096116791, 'recall': 0.9748062015503876, 'f1-score': 0.9748206199190588, 'support': 516}
 
time = 1.05 secondes

Val loss 1.3935942202806473 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 15/40
time = 15.45 secondes

Train loss 0.24759238001636483 accuracy 0.9399224519729614 macro_avg {'precision': 0.9447296837810268, 'recall': 0.9251905791330072, 'f1-score': 0.9336196700902584, 'support': 516} weighted_avg {'precision': 0.9408511448671417, 'recall': 0.939922480620155, 'f1-score': 0.9392485952175874, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9466823264956474 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 16/40
time = 15.45 secondes

Train loss 0.09848370384001597 accuracy 0.9786821603775024 macro_avg {'precision': 0.9736985336492284, 'recall': 0.9809745948669604, 'f1-score': 0.977115763755337, 'support': 516} weighted_avg {'precision': 0.9792272558278521, 'recall': 0.9786821705426356, 'f1-score': 0.9787633916353105, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1825512051582336 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 17/40
time = 15.77 secondes

Train loss 0.09045162618470688 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.04 secondes

Val loss 0.7084202244877815 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 18/40
time = 15.57 secondes

Train loss 0.12833046887041719 accuracy 0.9689922332763672 macro_avg {'precision': 0.9616695464705229, 'recall': 0.9733758106724315, 'f1-score': 0.9668907104701712, 'support': 516} weighted_avg {'precision': 0.9704816110975734, 'recall': 0.9689922480620154, 'f1-score': 0.9691862361474164, 'support': 516}
 
time = 1.05 secondes

Val loss 0.7275867403950542 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 19/40
time = 15.42 secondes

Train loss 0.09900666923248068 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 1.04 secondes

Val loss 1.348335474729538 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 20/40
time = 15.46 secondes

Train loss 0.3345847188911373 accuracy 0.9399224519729614 macro_avg {'precision': 0.9303304534275083, 'recall': 0.9436552183736164, 'f1-score': 0.9360484873684168, 'support': 516} weighted_avg {'precision': 0.9424917736181854, 'recall': 0.939922480620155, 'f1-score': 0.9403800388782344, 'support': 516}
 
time = 1.03 secondes

Val loss 1.4060862213373184 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 21/40
time = 15.38 secondes

Train loss 0.07065165730962304 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.05 secondes

Val loss 0.8371436079032719 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 22/40
time = 15.43 secondes

Train loss 0.02248276636060892 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.04 secondes

Val loss 1.0718052983283997 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 23/40
time = 15.16 secondes

Train loss 0.032093124021423246 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.05 secondes

Val loss 1.3643615692853928 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 24/40
time = 15.27 secondes

Train loss 0.13619122744509668 accuracy 0.9709302186965942 macro_avg {'precision': 0.9628712871287128, 'recall': 0.9772036474164134, 'f1-score': 0.9690557196943952, 'support': 516} weighted_avg {'precision': 0.9730888786553075, 'recall': 0.9709302325581395, 'f1-score': 0.9711516317152747, 'support': 516}
 
time = 1.05 secondes

Val loss 1.7095573842525482 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 25/40
time = 15.91 secondes

Train loss 0.04895228252809664 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.05 secondes

Val loss 0.8964223116636276 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 26/40
time = 15.91 secondes

Train loss 0.04477987644812939 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.05 secondes

Val loss 0.7168666422367096 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 27/40
time = 15.67 secondes

Train loss 0.03391683044063746 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1691963374614716 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 28/40
time = 15.77 secondes

Train loss 0.14069211208190996 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 1.04 secondes

Val loss 1.7045730203390121 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 29/40
time = 15.35 secondes

Train loss 0.11112338239697485 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.04 secondes

Val loss 1.5543132722377777 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 30/40
time = 15.32 secondes

Train loss 0.010558746155407844 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 0.86 secondes

Val loss 1.3383421897888184 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 31/40
time = 15.71 secondes

Train loss 0.040511777785881845 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.05 secondes

Val loss 1.1179071856313385 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 32/40
time = 15.50 secondes

Train loss 0.17474219472293925 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.04 secondes

Val loss 0.8704386195822735 accuracy 0.90625 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}
 
----------
Epoch 33/40
time = 15.27 secondes

Train loss 0.02914876179596776 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.04 secondes

Val loss 1.3850717097520828 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 34/40
time = 15.46 secondes

Train loss 0.023667214564435806 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.04 secondes

Val loss 1.2099405527114868 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 35/40
time = 15.48 secondes

Train loss 0.29112445827393624 accuracy 0.9573643207550049 macro_avg {'precision': 0.9686609686609686, 'recall': 0.9411764705882353, 'f1-score': 0.9525735294117648, 'support': 516} weighted_avg {'precision': 0.9600366615870491, 'recall': 0.9573643410852714, 'f1-score': 0.9567216712266302, 'support': 516}
 
time = 1.04 secondes

Val loss 1.469855785369873 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 36/40
time = 15.55 secondes

Train loss 0.28274168125635973 accuracy 0.9593023061752319 macro_avg {'precision': 0.97, 'recall': 0.9438502673796791, 'f1-score': 0.9547910399813089, 'support': 516} weighted_avg {'precision': 0.9617441860465116, 'recall': 0.9593023255813954, 'f1-score': 0.9587211170071511, 'support': 516}
 
time = 1.04 secondes

Val loss 1.1300178170204163 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 37/40
time = 15.40 secondes

Train loss 0.10794885203270524 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.04 secondes

Val loss 0.9582151174545288 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 38/40
time = 15.42 secondes

Train loss 0.08670985151900712 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.04 secondes

Val loss 0.7627979442477226 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 39/40
time = 15.08 secondes

Train loss 0.06837185649342384 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.04 secondes

Val loss 0.8411782458424568 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 40/40
time = 14.87 secondes

Train loss 0.05745976562541204 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 1.04 secondes

Val loss 0.796119786798954 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 32 macro_avg {'precision': 0.9318181818181819, 'recall': 0.8846153846153846, 'f1-score': 0.8981972428419936, 'support': 64} weighted_avg {'precision': 0.9190340909090909, 'recall': 0.90625, 'f1-score': 0.9035657476139979, 'support': 64}

average train time 15.562625366449357

average val time 1.0421944200992583
 
time = 1.25 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_3
----------
Epoch 1/40
time = 486.68 secondes

Train loss 0.27477540203311424 micro_f1_score 0.5902128236410465 
 
time = 47.04 secondes

Val loss 0.2317189847836729 micro_f1_score 0.6415686274509804
 
----------
Epoch 2/40
time = 473.94 secondes

Train loss 0.1812411280298555 micro_f1_score 0.7509121061359868 
 
time = 45.43 secondes

Val loss 0.19872222352223318 micro_f1_score 0.7063492063492063
 
----------
Epoch 3/40
time = 471.08 secondes

Train loss 0.15629126305381458 micro_f1_score 0.791473662635786 
 
time = 45.45 secondes

Val loss 0.20199320611895108 micro_f1_score 0.7101848210774676
 
----------
Epoch 4/40
time = 468.83 secondes

Train loss 0.1393125063882352 micro_f1_score 0.8214676889375685 
 
time = 45.82 secondes

Val loss 0.20587793102518456 micro_f1_score 0.7068766807529774
 
----------
Epoch 5/40
time = 477.14 secondes

Train loss 0.12366924025286156 micro_f1_score 0.8453857303913674 
 
time = 45.55 secondes

Val loss 0.20351979551745242 micro_f1_score 0.7299324831207802
 
----------
Epoch 6/40
time = 468.25 secondes

Train loss 0.11195172522686891 micro_f1_score 0.8605126970754603 
 
time = 45.42 secondes

Val loss 0.22545507586881763 micro_f1_score 0.7108299218459248
 
----------
Epoch 7/40
time = 476.77 secondes

Train loss 0.0986947941887486 micro_f1_score 0.8824560006370947 
 
time = 46.96 secondes

Val loss 0.2323730795598421 micro_f1_score 0.7254612546125462
 
----------
Epoch 8/40
time = 486.23 secondes

Train loss 0.08841057839459396 micro_f1_score 0.8975413076132501 
 
time = 46.26 secondes

Val loss 0.2508279180429021 micro_f1_score 0.7207074428887252
 
----------
Epoch 9/40
time = 486.50 secondes

Train loss 0.07757325964719729 micro_f1_score 0.9110412573673871 
 
time = 46.34 secondes

Val loss 0.2541575688319128 micro_f1_score 0.7251881046219993
 
----------
Epoch 10/40
time = 474.71 secondes

Train loss 0.06817924862744304 micro_f1_score 0.9225781249999999 
 
time = 46.88 secondes

Val loss 0.2728426902264845 micro_f1_score 0.7307692307692307
 
----------
Epoch 11/40
time = 482.47 secondes

Train loss 0.05899429018777032 micro_f1_score 0.9332295113879697 
 
time = 43.87 secondes

Val loss 0.2919442807553244 micro_f1_score 0.72654835204636
 
----------
Epoch 12/40
time = 485.50 secondes

Train loss 0.050339524228302006 micro_f1_score 0.9455391776570985 
 
time = 45.62 secondes

Val loss 0.310023519958629 micro_f1_score 0.7360057782592994
 
----------
Epoch 13/40
time = 490.17 secondes

Train loss 0.04445552793897789 micro_f1_score 0.9516328741680854 
 
time = 46.67 secondes

Val loss 0.3269376316275753 micro_f1_score 0.7272069464544139
 
----------
Epoch 14/40
time = 474.93 secondes

Train loss 0.038293953655027524 micro_f1_score 0.9591954687319384 
 
time = 46.50 secondes

Val loss 0.3409447196077128 micro_f1_score 0.7322805728975396
 
----------
Epoch 15/40
time = 493.40 secondes

Train loss 0.033401174119963135 micro_f1_score 0.96442718147906 
 
time = 45.74 secondes

Val loss 0.3557852755804531 micro_f1_score 0.7283645354998234
 
----------
Epoch 16/40
time = 492.36 secondes

Train loss 0.02883589468856535 micro_f1_score 0.9698876059687751 
 
time = 46.74 secondes

Val loss 0.38037801289656126 micro_f1_score 0.7244715155858116
 
----------
Epoch 17/40
time = 488.13 secondes

Train loss 0.0274821167744629 micro_f1_score 0.9714548450132189 
 
time = 46.46 secondes

Val loss 0.4055815257254194 micro_f1_score 0.7296908698777858
 
----------
Epoch 18/40
time = 489.15 secondes

Train loss 0.022618111938176266 micro_f1_score 0.9757496940024479 
 
time = 46.60 secondes

Val loss 0.4617792792984697 micro_f1_score 0.7208229868747782
 
----------
Epoch 19/40
time = 488.08 secondes

Train loss 0.021869396851980128 micro_f1_score 0.9767850996290206 
 
time = 46.67 secondes

Val loss 0.4333992458757807 micro_f1_score 0.7324729682595047
 
----------
Epoch 20/40
time = 472.37 secondes

Train loss 0.0185238054239554 micro_f1_score 0.9805236879216372 
 
time = 45.38 secondes

Val loss 0.4645592773058375 micro_f1_score 0.7272079772079773
 
----------
Epoch 21/40
time = 468.73 secondes

Train loss 0.017125727797712636 micro_f1_score 0.9815323565323565 
 
time = 45.39 secondes

Val loss 0.4668423289158305 micro_f1_score 0.7344632768361582
 
----------
Epoch 22/40
time = 467.91 secondes

Train loss 0.015297976038041146 micro_f1_score 0.9832666285496474 
 
time = 45.61 secondes

Val loss 0.4658169568073554 micro_f1_score 0.7331902718168813
 
----------
Epoch 23/40
time = 465.11 secondes

Train loss 0.014070766011004175 micro_f1_score 0.9840749771411155 
 
time = 45.52 secondes

Val loss 0.4616761725456988 micro_f1_score 0.7433628318584071
 
----------
Epoch 24/40
time = 464.56 secondes

Train loss 0.012701517248658362 micro_f1_score 0.9865266042475451 
 
time = 45.32 secondes

Val loss 0.491778381290983 micro_f1_score 0.7325072886297376
 
----------
Epoch 25/40
time = 464.57 secondes

Train loss 0.012470307733262112 micro_f1_score 0.9865580137846997 
 
time = 45.75 secondes

Val loss 0.5177739398157011 micro_f1_score 0.7304347826086955
 
----------
Epoch 26/40
time = 458.25 secondes

Train loss 0.011462801145843277 micro_f1_score 0.9882764920828259 
 
time = 45.62 secondes

Val loss 0.5203840109657069 micro_f1_score 0.7364963503649634
 
----------
Epoch 27/40
time = 470.27 secondes

Train loss 0.009528449534814541 micro_f1_score 0.9900967471623371 
 
time = 45.47 secondes

Val loss 0.5274819055053054 micro_f1_score 0.7258467023172905
 
----------
Epoch 28/40
time = 465.67 secondes

Train loss 0.009707440057867611 micro_f1_score 0.9899589228662712 
 
time = 45.33 secondes

Val loss 0.5166851792667733 micro_f1_score 0.7403471484236627
 
----------
Epoch 29/40
time = 474.33 secondes

Train loss 0.009003788326586177 micro_f1_score 0.9903762029746283 
 
time = 45.36 secondes

Val loss 0.5706159142685718 micro_f1_score 0.7254425546685179
 
----------
Epoch 30/40
time = 468.10 secondes

Train loss 0.007463600582818512 micro_f1_score 0.9931952100361148 
 
time = 45.34 secondes

Val loss 0.540865070751456 micro_f1_score 0.7377351530800441
 
----------
Epoch 31/40
time = 475.84 secondes

Train loss 0.006186095391869359 micro_f1_score 0.9936465664827848 
 
time = 45.68 secondes

Val loss 0.548206975714105 micro_f1_score 0.7429590017825314
 
----------
Epoch 32/40
time = 471.06 secondes

Train loss 0.006770758686657287 micro_f1_score 0.9930059297552076 
 
time = 36.80 secondes

Val loss 0.5606771912731108 micro_f1_score 0.7415891195418753
 
----------
Epoch 33/40
time = 468.67 secondes

Train loss 0.005206182109417044 micro_f1_score 0.9950952435268622 
 
time = 36.02 secondes

Val loss 0.5692576751357219 micro_f1_score 0.7393501805054152
 
----------
Epoch 34/40
time = 462.07 secondes

Train loss 0.00481766222628967 micro_f1_score 0.9947544473164057 
 
time = 41.91 secondes

Val loss 0.5856658889621985 micro_f1_score 0.7395079594790159
 
----------
Epoch 35/40
time = 459.27 secondes

Train loss 0.003466017270499366 micro_f1_score 0.9962358845671268 
 
time = 45.47 secondes

Val loss 0.5833353290303809 micro_f1_score 0.7452796579978624
 
----------
Epoch 36/40
time = 468.56 secondes

Train loss 0.0030185606883458456 micro_f1_score 0.9967713753940822 
 
time = 34.88 secondes

Val loss 0.58909237360368 micro_f1_score 0.7371115173674588
 
----------
Epoch 37/40
time = 457.73 secondes

Train loss 0.002865559954068738 micro_f1_score 0.997036699338956 
 
time = 45.85 secondes

Val loss 0.5942361411012587 micro_f1_score 0.7400215749730314
 
----------
Epoch 38/40
time = 446.27 secondes

Train loss 0.002393366477835943 micro_f1_score 0.9980625308665426 
 
time = 45.67 secondes

Val loss 0.6075879623655414 micro_f1_score 0.7349441038586367
 
----------
Epoch 39/40
time = 463.39 secondes

Train loss 0.0016920560013597818 micro_f1_score 0.9982143535579955 
 
time = 45.45 secondes

Val loss 0.5955839780021887 micro_f1_score 0.7387711103126122
 
----------
Epoch 40/40
time = 464.87 secondes

Train loss 0.0018885329755911706 micro_f1_score 0.9980247663906404 
 
time = 45.43 secondes

Val loss 0.6120048776024678 micro_f1_score 0.7320214669051878
 
----------
best_f1_socre 0.7452796579978624 best_epoch 35

average train time 473.29821399450304

average val time 44.98157344460488
 
time = 46.06 secondes

test_f1_score 0.7125086385625431

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_3
----------
Epoch 1/40
time = 489.57 secondes

Train loss 0.2777215289774242 micro_f1_score 0.5939351074175582 
 
time = 47.27 secondes

Val loss 0.23471273359705191 micro_f1_score 0.6331894860729698
 
----------
Epoch 2/40
time = 473.36 secondes

Train loss 0.17682877236994 micro_f1_score 0.7553725813091806 
 
time = 46.10 secondes

Val loss 0.190761533428411 micro_f1_score 0.7198105761641674
 
----------
Epoch 3/40
time = 480.44 secondes

Train loss 0.1483711578891621 micro_f1_score 0.8039669958948096 
 
time = 46.05 secondes

Val loss 0.18827153803383717 micro_f1_score 0.7345971563981043
 
----------
Epoch 4/40
time = 476.55 secondes

Train loss 0.12909542779094196 micro_f1_score 0.835715432792677 
 
time = 46.11 secondes

Val loss 0.18688063641063501 micro_f1_score 0.7477790652761683
 
----------
Epoch 5/40
time = 469.60 secondes

Train loss 0.11100403946899884 micro_f1_score 0.8634371763206119 
 
time = 42.83 secondes

Val loss 0.1941961504396845 micro_f1_score 0.7482068705171763
 
----------
Epoch 6/40
time = 474.75 secondes

Train loss 0.09750289577856526 micro_f1_score 0.8858309870325575 
 
time = 36.34 secondes

Val loss 0.19651692275141106 micro_f1_score 0.749624060150376
 
----------
Epoch 7/40
time = 474.64 secondes

Train loss 0.086873272748513 micro_f1_score 0.9005990856061801 
 
time = 45.91 secondes

Val loss 0.21228437467676695 micro_f1_score 0.7481315396113601
 
----------
Epoch 8/40
time = 477.65 secondes

Train loss 0.07744295279336003 micro_f1_score 0.9135279347143754 
 
time = 45.86 secondes

Val loss 0.2284998877248803 micro_f1_score 0.7454746952345771
 
----------
Epoch 9/40
time = 472.98 secondes

Train loss 0.06798717314083767 micro_f1_score 0.9267644183773216 
 
time = 46.78 secondes

Val loss 0.24096492323719088 micro_f1_score 0.7513771575468233
 
----------
Epoch 10/40
time = 477.28 secondes

Train loss 0.0596755083318934 micro_f1_score 0.9367265935092225 
 
time = 45.80 secondes

Val loss 0.2611697179372193 micro_f1_score 0.7475409836065574
 
----------
Epoch 11/40
time = 476.71 secondes

Train loss 0.052615041482086115 micro_f1_score 0.943243977188967 
 
time = 46.02 secondes

Val loss 0.2731798892138434 micro_f1_score 0.7503536067892503
 
----------
Epoch 12/40
time = 467.68 secondes

Train loss 0.04415067041225664 micro_f1_score 0.9530434782608695 
 
time = 45.76 secondes

Val loss 0.29011139719456924 micro_f1_score 0.7513533020570191
 
----------
Epoch 13/40
time = 478.96 secondes

Train loss 0.03939583777252853 micro_f1_score 0.9595219737856592 
 
time = 45.98 secondes

Val loss 0.32117819651717044 micro_f1_score 0.742675608895164
 
----------
Epoch 14/40
time = 466.86 secondes

Train loss 0.035138516836518606 micro_f1_score 0.9624903920061492 
 
time = 46.02 secondes

Val loss 0.31587161929880986 micro_f1_score 0.7536842105263157
 
----------
Epoch 15/40
time = 470.55 secondes

Train loss 0.030827199927581525 micro_f1_score 0.9684767602393005 
 
time = 46.10 secondes

Val loss 0.3333441908852976 micro_f1_score 0.7555233611010503
 
----------
Epoch 16/40
time = 473.80 secondes

Train loss 0.02771693800517299 micro_f1_score 0.970017231476163 
 
time = 46.09 secondes

Val loss 0.33994256491299535 micro_f1_score 0.7548500881834215
 
----------
Epoch 17/40
time = 471.76 secondes

Train loss 0.024515597011552082 micro_f1_score 0.9734587731375248 
 
time = 45.83 secondes

Val loss 0.3349884047371442 micro_f1_score 0.761124955500178
 
----------
Epoch 18/40
time = 473.86 secondes

Train loss 0.020829913012005874 micro_f1_score 0.978234305788911 
 
time = 42.23 secondes

Val loss 0.3585407660632837 micro_f1_score 0.7524324324324324
 
----------
Epoch 19/40
time = 475.41 secondes

Train loss 0.02170587322999291 micro_f1_score 0.9766766077846601 
 
time = 45.85 secondes

Val loss 0.3776849311639051 micro_f1_score 0.7537580529706513
 
----------
Epoch 20/40
time = 454.98 secondes

Train loss 0.017844544809184727 micro_f1_score 0.980863985332875 
 
time = 45.93 secondes

Val loss 0.3794210686302576 micro_f1_score 0.7584269662921349
 
----------
Epoch 21/40
time = 464.32 secondes

Train loss 0.016648395767284406 micro_f1_score 0.9820889822417415 
 
time = 45.91 secondes

Val loss 0.3960628830751435 micro_f1_score 0.7588961510530138
 
----------
Epoch 22/40
time = 600.30 secondes

Train loss 0.015767656538600357 micro_f1_score 0.9825831777125653 
 
time = 54.07 secondes

Val loss 0.4065543507210544 micro_f1_score 0.7476901208244491
 
----------
Epoch 23/40
time = 620.78 secondes

Train loss 0.013452065391240532 micro_f1_score 0.9860766736601183 
 
time = 53.43 secondes

Val loss 0.42066908359039024 micro_f1_score 0.757183908045977
 
----------
Epoch 24/40
time = 621.46 secondes

Train loss 0.0125917791517733 micro_f1_score 0.9873919171142346 
 
time = 54.54 secondes

Val loss 0.42362464695680335 micro_f1_score 0.7536443148688046
 
----------
Epoch 25/40
time = 632.05 secondes

Train loss 0.011533844497263 micro_f1_score 0.9878206592068204 
 
time = 53.23 secondes

Val loss 0.4235735954564126 micro_f1_score 0.7551319648093842
 
----------
Epoch 26/40
time = 614.67 secondes

Train loss 0.013012689357954613 micro_f1_score 0.9868746433326993 
 
time = 52.17 secondes

Val loss 0.4515418773058985 micro_f1_score 0.7468123861566485
 
----------
Epoch 27/40
time = 619.87 secondes

Train loss 0.010477780062560546 micro_f1_score 0.9891842486099475 
 
time = 54.13 secondes

Val loss 0.4641357986409156 micro_f1_score 0.7517166606432959
 
----------
Epoch 28/40
time = 632.10 secondes

Train loss 0.008627219576016802 micro_f1_score 0.9909512584594329 
 
time = 52.20 secondes

Val loss 0.454658817683087 micro_f1_score 0.7592727272727273
 
----------
Epoch 29/40
time = 625.39 secondes

Train loss 0.007504459542506411 micro_f1_score 0.9920924574209247 
 
time = 53.89 secondes

Val loss 0.4741856298241459 micro_f1_score 0.7579941860465116
 
----------
Epoch 30/40
time = 626.83 secondes

Train loss 0.007222879553339701 micro_f1_score 0.9922068047899638 
 
time = 53.71 secondes

Val loss 0.49916560019625994 micro_f1_score 0.7533474277660324
 
----------
Epoch 31/40
time = 605.55 secondes

Train loss 0.006455196512650071 micro_f1_score 0.9929655119966538 
 
time = 54.39 secondes

Val loss 0.5175414836553277 micro_f1_score 0.7504399859204505
 
----------
Epoch 32/40
time = 623.61 secondes

Train loss 0.0048649632718700785 micro_f1_score 0.9949072666463971 
 
time = 54.29 secondes

Val loss 0.5087402536243689 micro_f1_score 0.7569319409434642
 
----------
Epoch 33/40
time = 645.22 secondes

Train loss 0.005302011530985256 micro_f1_score 0.9947926565053784 
 
time = 54.11 secondes

Val loss 0.5175846368074417 micro_f1_score 0.753956834532374
 
----------
Epoch 34/40
time = 660.97 secondes

Train loss 0.003904127536149751 micro_f1_score 0.9957042387378825 
 
time = 54.38 secondes

Val loss 0.5362592460434945 micro_f1_score 0.7483917083631164
 
----------
Epoch 35/40
time = 654.52 secondes

Train loss 0.003477356603426407 micro_f1_score 0.9964642816408775 
 
time = 53.01 secondes

Val loss 0.5368077285954209 micro_f1_score 0.7481135465325189
 
----------
Epoch 36/40
time = 658.97 secondes

Train loss 0.0030248922945542585 micro_f1_score 0.9967325227963526 
 
time = 53.44 secondes

Val loss 0.539518414462199 micro_f1_score 0.7551601423487545
 
----------
Epoch 37/40
time = 637.12 secondes

Train loss 0.0030447843887396538 micro_f1_score 0.9969588686991561 
 
time = 53.37 secondes

Val loss 0.5405255818708998 micro_f1_score 0.7500898957209636
 
----------
Epoch 38/40
time = 652.66 secondes

Train loss 0.0019029603397611608 micro_f1_score 0.9979480164158687 
 
time = 52.99 secondes

Val loss 0.5376184196745764 micro_f1_score 0.755028735632184
 
----------
Epoch 39/40
time = 652.93 secondes

Train loss 0.0014245576787387207 micro_f1_score 0.9985942783328902 
 
time = 52.19 secondes

Val loss 0.5318985125813328 micro_f1_score 0.7547033285094066
 
----------
Epoch 40/40
time = 647.90 secondes

Train loss 0.0013067387154470445 micro_f1_score 0.9984418348344926 
 
time = 54.15 secondes

Val loss 0.5599594111325311 micro_f1_score 0.7498238195912614
 
----------
best_f1_socre 0.761124955500178 best_epoch 17

average train time 549.3650981366634

average val time 49.211229622364044
 
time = 58.91 secondes

test_f1_score 0.7415886229621921

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_3
----------
Epoch 1/40
time = 670.72 secondes

Train loss 0.3085758966771332 micro_f1_score 0.5203752843062927 
 
time = 55.02 secondes

Val loss 0.3093137000916434 micro_f1_score 0.314317673378076
 
----------
Epoch 2/40
time = 644.40 secondes

Train loss 0.2544130223559904 micro_f1_score 0.5706024553254017 
 
time = 54.52 secondes

Val loss 0.30721171639981815 micro_f1_score 0.4340807174887892
 
----------
Epoch 3/40
time = 649.17 secondes

Train loss 0.24893275449673335 micro_f1_score 0.5869637354823417 
 
time = 55.61 secondes

Val loss 0.2795113596271296 micro_f1_score 0.3870967741935484
 
----------
Epoch 4/40
time = 619.77 secondes

Train loss 0.23357753938248565 micro_f1_score 0.6069195498124219 
 
time = 54.03 secondes

Val loss 0.26851901973857256 micro_f1_score 0.5528950805398346
 
----------
Epoch 5/40
time = 623.96 secondes

Train loss 0.2176110056270887 micro_f1_score 0.6770290635091496 
 
time = 53.83 secondes

Val loss 0.25287708688954835 micro_f1_score 0.5979983319432861
 
----------
Epoch 6/40
time = 626.11 secondes

Train loss 0.2053142257504635 micro_f1_score 0.7031897791691345 
 
time = 53.83 secondes

Val loss 0.24291965267697319 micro_f1_score 0.6279552053090004
 
----------
Epoch 7/40
time = 625.90 secondes

Train loss 0.19628399368878957 micro_f1_score 0.721001297668383 
 
time = 52.79 secondes

Val loss 0.2466990603286712 micro_f1_score 0.6299148763680583
 
----------
Epoch 8/40
time = 624.18 secondes

Train loss 0.1863280160671419 micro_f1_score 0.7361953001743753 
 
time = 51.43 secondes

Val loss 0.23831495300668185 micro_f1_score 0.6478087649402391
 
----------
Epoch 9/40
time = 615.15 secondes

Train loss 0.17166709961990514 micro_f1_score 0.7603034652450276 
 
time = 53.70 secondes

Val loss 0.22147805817791674 micro_f1_score 0.6845003933910307
 
----------
Epoch 10/40
time = 615.49 secondes

Train loss 0.1603768340437799 micro_f1_score 0.7839425587467364 
 
time = 53.66 secondes

Val loss 0.22285935624701078 micro_f1_score 0.6903398243604429
 
----------
Epoch 11/40
time = 626.45 secondes

Train loss 0.14952373169698158 micro_f1_score 0.8038961038961039 
 
time = 53.56 secondes

Val loss 0.21871560824210526 micro_f1_score 0.6959591996861514
 
----------
Epoch 12/40
time = 620.82 secondes

Train loss 0.14051488949371888 micro_f1_score 0.8197725989839529 
 
time = 53.74 secondes

Val loss 0.22255257016322652 micro_f1_score 0.7063369397217929
 
----------
Epoch 13/40
time = 632.83 secondes

Train loss 0.1332272893707226 micro_f1_score 0.8327691811734366 
 
time = 52.79 secondes

Val loss 0.22267357589768583 micro_f1_score 0.7052469135802469
 
----------
Epoch 14/40
time = 600.97 secondes

Train loss 0.1266538202796165 micro_f1_score 0.8403570854109699 
 
time = 53.85 secondes

Val loss 0.22485995964437236 micro_f1_score 0.7081081081081081
 
----------
Epoch 15/40
time = 613.51 secondes

Train loss 0.11904219600061576 micro_f1_score 0.8536849276640083 
 
time = 52.24 secondes

Val loss 0.223681776616417 micro_f1_score 0.7203325774754346
 
----------
Epoch 16/40
time = 625.97 secondes

Train loss 0.11450926549229268 micro_f1_score 0.8633300099700898 
 
time = 54.62 secondes

Val loss 0.23631235615151827 micro_f1_score 0.7209039548022599
 
----------
Epoch 17/40
time = 625.95 secondes

Train loss 0.1082709302236368 micro_f1_score 0.8700600947188284 
 
time = 54.00 secondes

Val loss 0.22813341705525508 micro_f1_score 0.7280303030303031
 
----------
Epoch 18/40
time = 628.47 secondes

Train loss 0.10371336225621604 micro_f1_score 0.8781903474596485 
 
time = 51.96 secondes

Val loss 0.24924105625660692 micro_f1_score 0.7195213163799551
 
----------
Epoch 19/40
time = 602.57 secondes

Train loss 0.09924537482763733 micro_f1_score 0.8841788920083831 
 
time = 53.40 secondes

Val loss 0.24061146244162418 micro_f1_score 0.7220973782771536
 
----------
Epoch 20/40
time = 627.89 secondes

Train loss 0.09358700078215686 micro_f1_score 0.8937125748502995 
 
time = 52.29 secondes

Val loss 0.24541898230548764 micro_f1_score 0.728471967753756
 
----------
Epoch 21/40
time = 628.15 secondes

Train loss 0.08855201621447598 micro_f1_score 0.9013020730891781 
 
time = 53.59 secondes

Val loss 0.2462073706212591 micro_f1_score 0.7350943396226415
 
----------
Epoch 22/40
time = 629.79 secondes

Train loss 0.08364179485418775 micro_f1_score 0.9075914071397715 
 
time = 52.10 secondes

Val loss 0.2577163807925631 micro_f1_score 0.7386321626617376
 
----------
Epoch 23/40
time = 626.28 secondes

Train loss 0.07833296434014096 micro_f1_score 0.9150362673985493 
 
time = 51.18 secondes

Val loss 0.2648148154381846 micro_f1_score 0.7407134976094153
 
----------
Epoch 24/40
time = 607.53 secondes

Train loss 0.0743686444310656 micro_f1_score 0.9192891811492093 
 
time = 53.54 secondes

Val loss 0.2681706674763414 micro_f1_score 0.7383143172616857
 
----------
Epoch 25/40
time = 628.05 secondes

Train loss 0.07115603797641155 micro_f1_score 0.9256701392953296 
 
time = 53.30 secondes

Val loss 0.2666688743429106 micro_f1_score 0.7390350877192983
 
----------
Epoch 26/40
time = 624.01 secondes

Train loss 0.06611325209373022 micro_f1_score 0.9314417118135402 
 
time = 53.51 secondes

Val loss 0.28622074510718953 micro_f1_score 0.7304029304029304
 
----------
Epoch 27/40
time = 626.96 secondes

Train loss 0.06267883041789671 micro_f1_score 0.9355942750466708 
 
time = 53.32 secondes

Val loss 0.2870834279255789 micro_f1_score 0.7421758569299552
 
----------
Epoch 28/40
time = 614.75 secondes

Train loss 0.05854794487550116 micro_f1_score 0.9400000000000001 
 
time = 48.33 secondes

Val loss 0.2996993387331728 micro_f1_score 0.7296908698777858
 
----------
Epoch 29/40
time = 613.03 secondes

Train loss 0.05578418921066767 micro_f1_score 0.9442633131501319 
 
time = 53.72 secondes

Val loss 0.29341068680657717 micro_f1_score 0.7376811594202898
 
----------
Epoch 30/40
time = 626.23 secondes

Train loss 0.053462298151508374 micro_f1_score 0.9475355248383474 
 
time = 53.94 secondes

Val loss 0.3063774111329532 micro_f1_score 0.7343976777939042
 
----------
Epoch 31/40
time = 630.99 secondes

Train loss 0.05020343530168002 micro_f1_score 0.9511307311028502 
 
time = 53.19 secondes

Val loss 0.31404240795823396 micro_f1_score 0.7284576393917451
 
----------
Epoch 32/40
time = 629.23 secondes

Train loss 0.046762352830285694 micro_f1_score 0.9553440136212368 
 
time = 53.77 secondes

Val loss 0.31989894917265316 micro_f1_score 0.7348403301040545
 
----------
Epoch 33/40
time = 623.22 secondes

Train loss 0.045337537911443695 micro_f1_score 0.9557084331761614 
 
time = 51.35 secondes

Val loss 0.3228201171169516 micro_f1_score 0.7321688500727803
 
----------
Epoch 34/40
time = 619.05 secondes

Train loss 0.0426227638250435 micro_f1_score 0.9582239382239381 
 
time = 52.38 secondes

Val loss 0.329954881770689 micro_f1_score 0.7337662337662338
 
----------
Epoch 35/40
time = 629.61 secondes

Train loss 0.04115644901432936 micro_f1_score 0.961068024848555 
 
time = 53.29 secondes

Val loss 0.33202750480077303 micro_f1_score 0.7326804497642365
 
----------
Epoch 36/40
time = 632.86 secondes

Train loss 0.03864191537135624 micro_f1_score 0.9640543042270905 
 
time = 52.80 secondes

Val loss 0.3370884713090834 micro_f1_score 0.7325875135330205
 
----------
Epoch 37/40
time = 627.46 secondes

Train loss 0.03676496544403972 micro_f1_score 0.9656156040397811 
 
time = 51.75 secondes

Val loss 0.3443531369576689 micro_f1_score 0.7313218390804598
 
----------
Epoch 38/40
time = 610.56 secondes

Train loss 0.03647016952158296 micro_f1_score 0.9649136335595311 
 
time = 51.54 secondes

Val loss 0.3482671783107226 micro_f1_score 0.7319698600645856
 
----------
Epoch 39/40
time = 616.91 secondes

Train loss 0.035242546862201046 micro_f1_score 0.9662921348314606 
 
time = 53.91 secondes

Val loss 0.3535155087220864 micro_f1_score 0.7322325915290739
 
----------
Epoch 40/40
time = 622.90 secondes

Train loss 0.03518779641636102 micro_f1_score 0.9658810844115836 
 
time = 52.71 secondes

Val loss 0.36571737684187344 micro_f1_score 0.7327647476901208
 
----------
best_f1_socre 0.7421758569299552 best_epoch 27

average train time 624.6961242556572

average val time 53.10247476100922
 
time = 59.51 secondes

test_f1_score 0.7234972677595629

----------
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_3
----------
Epoch 1/40
time = 26.13 secondes

Train loss 0.6503762656992133 accuracy 0.6375969052314758 macro_avg {'precision': 0.3187984496124031, 'recall': 0.5, 'f1-score': 0.38934911242603554, 'support': 516} weighted_avg {'precision': 0.40652980590108767, 'recall': 0.6375968992248062, 'f1-score': 0.4964955735975415, 'support': 516}
 
time = 1.58 secondes

Val loss 0.5925196260213852 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 22.45 secondes

Train loss 0.504297036113161 accuracy 0.7577519416809082 macro_avg {'precision': 0.7646304809052333, 'recall': 0.6946263998829706, 'f1-score': 0.7057038696519093, 'support': 516} weighted_avg {'precision': 0.7612854360602174, 'recall': 0.7577519379844961, 'f1-score': 0.7397629742750768, 'support': 516}
 
time = 1.39 secondes

Val loss 0.44885531812906265 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 22.90 secondes

Train loss 0.3763168688976403 accuracy 0.8468992114067078 macro_avg {'precision': 0.8341658017644007, 'recall': 0.8349316515774589, 'f1-score': 0.8345449010654491, 'support': 516} weighted_avg {'precision': 0.8470811308496558, 'recall': 0.8468992248062015, 'f1-score': 0.846986844123512, 'support': 516}
 
time = 1.36 secondes

Val loss 0.3598036468029022 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 4/40
time = 22.42 secondes

Train loss 0.3648382355317925 accuracy 0.854651153087616 macro_avg {'precision': 0.8445436507936508, 'recall': 0.8387025990280058, 'f1-score': 0.8414291860441294, 'support': 516} weighted_avg {'precision': 0.8537440783807063, 'recall': 0.8546511627906976, 'f1-score': 0.854029996097906, 'support': 516}
 
time = 1.32 secondes

Val loss 0.6148463189601898 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 5/40
time = 22.71 secondes

Train loss 0.22741246742732596 accuracy 0.9282945990562439 macro_avg {'precision': 0.9236838658983761, 'recall': 0.9206881979097248, 'f1-score': 0.9221468737639206, 'support': 516} weighted_avg {'precision': 0.9281076530591528, 'recall': 0.9282945736434108, 'f1-score': 0.9281673798528007, 'support': 516}
 
time = 1.36 secondes

Val loss 0.5253624655306339 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 6/40
time = 22.66 secondes

Train loss 0.18730123482193006 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.34 secondes

Val loss 0.46328531950712204 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 7/40
time = 22.90 secondes

Train loss 0.13154965956610712 accuracy 0.9651162624359131 macro_avg {'precision': 0.9680515974201289, 'recall': 0.956487817564163, 'f1-score': 0.9618016713825097, 'support': 516} weighted_avg {'precision': 0.9654786640512936, 'recall': 0.9651162790697675, 'f1-score': 0.9648982127745531, 'support': 516}
 
time = 1.44 secondes

Val loss 0.8642601296305656 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 8/40
time = 22.91 secondes

Train loss 0.20717106001084726 accuracy 0.9534883499145508 macro_avg {'precision': 0.9608648943607934, 'recall': 0.9392909968629618, 'f1-score': 0.9485406555415199, 'support': 516} weighted_avg {'precision': 0.9549802530011117, 'recall': 0.9534883720930233, 'f1-score': 0.9529317539809791, 'support': 516}
 
time = 1.46 secondes

Val loss 1.4715239182114601 accuracy 0.765625 macro_avg {'precision': 0.8170731707317074, 'recall': 0.8026315789473684, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.8513719512195121, 'recall': 0.765625, 'f1-score': 0.7630444091020308, 'support': 64}
 
----------
Epoch 9/40
time = 22.69 secondes

Train loss 0.2563585212778752 accuracy 0.9457364082336426 macro_avg {'precision': 0.9366500829187396, 'recall': 0.9493685288428717, 'f1-score': 0.9421783953384132, 'support': 516} weighted_avg {'precision': 0.9479681694884748, 'recall': 0.9457364341085271, 'f1-score': 0.9461255945990081, 'support': 516}
 
time = 1.38 secondes

Val loss 0.8161009773612022 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 22.95 secondes

Train loss 0.22007223371077667 accuracy 0.9515503644943237 macro_avg {'precision': 0.9480449657869012, 'recall': 0.9470035596443607, 'f1-score': 0.9475198021211764, 'support': 516} weighted_avg {'precision': 0.9515017011828714, 'recall': 0.9515503875968992, 'f1-score': 0.9515222016844816, 'support': 516}
 
time = 1.33 secondes

Val loss 0.49435109831392765 accuracy 0.875 macro_avg {'precision': 0.8704453441295547, 'recall': 0.8704453441295547, 'f1-score': 0.8704453441295547, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 64}
 
----------
Epoch 11/40
time = 24.00 secondes

Train loss 0.1419846836343464 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.28 secondes

Val loss 0.8532760143280029 accuracy 0.84375 macro_avg {'precision': 0.8611111111111112, 'recall': 0.868421052631579, 'f1-score': 0.8435972629521016, 'support': 64} weighted_avg {'precision': 0.8871527777777778, 'recall': 0.84375, 'f1-score': 0.8445136852394917, 'support': 64}
 
----------
Epoch 12/40
time = 22.28 secondes

Train loss 0.2493398943139861 accuracy 0.9418604373931885 macro_avg {'precision': 0.933040597308308, 'recall': 0.9440209352599841, 'f1-score': 0.937920082131571, 'support': 516} weighted_avg {'precision': 0.9436543365348494, 'recall': 0.9418604651162791, 'f1-score': 0.942224192776406, 'support': 516}
 
time = 1.38 secondes

Val loss 0.63872379809618 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 13/40
time = 22.26 secondes

Train loss 0.30831969809492654 accuracy 0.9399224519729614 macro_avg {'precision': 0.9288888888888889, 'recall': 0.951733498041383, 'f1-score': 0.9368961721902899, 'support': 516} weighted_avg {'precision': 0.9475409130060294, 'recall': 0.939922480620155, 'f1-score': 0.9406991438455187, 'support': 516}
 
time = 1.36 secondes

Val loss 0.9527616128325462 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 14/40
time = 22.52 secondes

Train loss 0.13176287359304048 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.36 secondes

Val loss 0.9469823837280273 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 15/40
time = 23.36 secondes

Train loss 0.14442497934567544 accuracy 0.9670542478561401 macro_avg {'precision': 0.9682539682539683, 'recall': 0.9603156543081449, 'f1-score': 0.9640572821700026, 'support': 516} weighted_avg {'precision': 0.9671619293712317, 'recall': 0.9670542635658915, 'f1-score': 0.9669134657821921, 'support': 516}
 
time = 1.45 secondes

Val loss 1.2422265857458115 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 16/40
time = 22.70 secondes

Train loss 0.07694661065540982 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 1.42 secondes

Val loss 1.50016587972641 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 17/40
time = 22.10 secondes

Train loss 0.2560364510546523 accuracy 0.9496123790740967 macro_avg {'precision': 0.9391189495765675, 'recall': 0.9593322822359118, 'f1-score': 0.9468319515558866, 'support': 516} weighted_avg {'precision': 0.9549707623471791, 'recall': 0.9496124031007752, 'f1-score': 0.9501779186692271, 'support': 516}
 
time = 1.27 secondes

Val loss 2.072985291481018 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 18/40
time = 22.65 secondes

Train loss 0.2553178423990947 accuracy 0.9515503644943237 macro_avg {'precision': 0.9549808429118773, 'recall': 0.9400793199291322, 'f1-score': 0.9467450491473015, 'support': 516} weighted_avg {'precision': 0.9520812913956459, 'recall': 0.9515503875968992, 'f1-score': 0.9511473592108038, 'support': 516}
 
time = 1.30 secondes

Val loss 1.3047069311141968 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 19/40
time = 22.79 secondes

Train loss 0.11400060755179518 accuracy 0.9748061895370483 macro_avg {'precision': 0.9722366372599895, 'recall': 0.9733189213789964, 'f1-score': 0.9727732115677321, 'support': 516} weighted_avg {'precision': 0.9748429096116791, 'recall': 0.9748062015503876, 'f1-score': 0.9748206199190588, 'support': 516}
 
time = 1.16 secondes

Val loss 1.6865396276116371 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 20/40
time = 22.95 secondes

Train loss 0.13859658972995187 accuracy 0.9709302186965942 macro_avg {'precision': 0.9766586005242992, 'recall': 0.9610470880808804, 'f1-score': 0.968047029488381, 'support': 516} weighted_avg {'precision': 0.9718167656957595, 'recall': 0.9709302325581395, 'f1-score': 0.9706884155264824, 'support': 516}
 
time = 1.28 secondes

Val loss 0.6166546512395144 accuracy 0.890625 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}
 
----------
Epoch 21/40
time = 25.06 secondes

Train loss 0.017086054978955708 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.37 secondes

Val loss 1.4837556183338165 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 22/40
time = 22.82 secondes

Train loss 0.051069964035625824 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4840765297412872 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 23/40
time = 23.00 secondes

Train loss 0.17975094708945658 accuracy 0.9689922332763672 macro_avg {'precision': 0.9685915423620342, 'recall': 0.9641434910521269, 'f1-score': 0.9662937862333634, 'support': 516} weighted_avg {'precision': 0.9689708770913499, 'recall': 0.9689922480620154, 'f1-score': 0.9689183176009566, 'support': 516}
 
time = 1.18 secondes

Val loss 1.4335039854049683 accuracy 0.78125 macro_avg {'precision': 0.8097165991902835, 'recall': 0.8097165991902835, 'f1-score': 0.78125, 'support': 64} weighted_avg {'precision': 0.8381831983805669, 'recall': 0.78125, 'f1-score': 0.78125, 'support': 64}
 
----------
Epoch 24/40
time = 22.18 secondes

Train loss 0.03483245534130908 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.43 secondes

Val loss 0.9045321755111217 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 25/40
time = 21.85 secondes

Train loss 0.01646099064347447 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.40 secondes

Val loss 1.2136347442865372 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 26/40
time = 22.30 secondes

Train loss 0.07719364046131501 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.34 secondes

Val loss 1.2712173014879227 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 27/40
time = 22.29 secondes

Train loss 0.26875067821873183 accuracy 0.9534883499145508 macro_avg {'precision': 0.9516565746073943, 'recall': 0.9473692765307284, 'f1-score': 0.949440679350045, 'support': 516} weighted_avg {'precision': 0.953390676227123, 'recall': 0.9534883720930233, 'f1-score': 0.9533774764014349, 'support': 516}
 
time = 1.85 secondes

Val loss 1.6666103303432465 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 28/40
time = 22.92 secondes

Train loss 0.048128116096698 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.41 secondes

Val loss 1.7780887633562088 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 29/40
time = 22.28 secondes

Train loss 0.028973631715581923 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.36 secondes

Val loss 1.240877291864308 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 30/40
time = 22.04 secondes

Train loss 0.07075592775072437 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.08 secondes

Val loss 1.3931741882115602 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 31/40
time = 21.78 secondes

Train loss 0.09386128032488297 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.37 secondes

Val loss 2.3367167562246323 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 32/40
time = 23.34 secondes

Train loss 0.057428140570691816 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.39 secondes

Val loss 2.1370555758476257 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 33/40
time = 22.08 secondes

Train loss 0.018069743036793432 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.35 secondes

Val loss 1.5223383158445358 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 34/40
time = 22.11 secondes

Train loss 0.00036078286013269627 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.34 secondes

Val loss 2.0061972737312317 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 35/40
time = 22.83 secondes

Train loss 0.10087531574853612 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.41 secondes

Val loss 1.4385723918676376 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 36/40
time = 24.47 secondes

Train loss 0.0002607689013089067 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.33 secondes

Val loss 1.5255422294139862 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 37/40
time = 22.24 secondes

Train loss 0.02565944841383801 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.19 secondes

Val loss 1.397129274904728 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 21.54 secondes

Train loss 5.936221030865316e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.37 secondes

Val loss 1.674959510564804 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 39/40
time = 22.45 secondes

Train loss 0.00034501850181682545 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.34 secondes

Val loss 1.8164147287607193 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 40/40
time = 22.73 secondes

Train loss 7.460020314090687e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.28 secondes

Val loss 1.585797667503357 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 20 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}

average train time 22.766751050949097

average val time 1.3596497058868409
 
time = 1.63 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_3
----------
Epoch 1/40
time = 25.60 secondes

Train loss 0.6509956825863231 accuracy 0.6337209343910217 macro_avg {'precision': 0.5387500000000001, 'recall': 0.505038765989955, 'f1-score': 0.4204899962563954, 'support': 516} weighted_avg {'precision': 0.5666133720930233, 'recall': 0.6337209302325582, 'f1-score': 0.5172273528845587, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6266066133975983 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 22.68 secondes

Train loss 0.5014958056536588 accuracy 0.7422480583190918 macro_avg {'precision': 0.7709302325581395, 'recall': 0.6628496659785771, 'f1-score': 0.6687949731427992, 'support': 516} weighted_avg {'precision': 0.7590904993690284, 'recall': 0.7422480620155039, 'f1-score': 0.7117181773400175, 'support': 516}
 
time = 1.25 secondes

Val loss 0.4381308779120445 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 3/40
time = 22.33 secondes

Train loss 0.39240987508585956 accuracy 0.8468992114067078 macro_avg {'precision': 0.8349921424829754, 'recall': 0.8326235716723827, 'f1-score': 0.8337730547932357, 'support': 516} weighted_avg {'precision': 0.8464165052525572, 'recall': 0.8468992248062015, 'f1-score': 0.8466276488748987, 'support': 516}
 
time = 1.25 secondes

Val loss 0.3958050012588501 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 4/40
time = 23.54 secondes

Train loss 0.2855622924186967 accuracy 0.9050387740135193 macro_avg {'precision': 0.8952263558942178, 'recall': 0.9012970758903174, 'f1-score': 0.8980611294555922, 'support': 516} weighted_avg {'precision': 0.9061119913550777, 'recall': 0.9050387596899225, 'f1-score': 0.9054005627391101, 'support': 516}
 
time = 1.32 secondes

Val loss 0.39533019065856934 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 5/40
time = 22.34 secondes

Train loss 0.20499724251302806 accuracy 0.9341084957122803 macro_avg {'precision': 0.931475220582172, 'recall': 0.9252474684264422, 'f1-score': 0.9282019381875328, 'support': 516} weighted_avg {'precision': 0.9339033344136316, 'recall': 0.9341085271317829, 'f1-score': 0.9338690708232323, 'support': 516}
 
time = 1.30 secondes

Val loss 0.523843377828598 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 6/40
time = 22.47 secondes

Train loss 0.32769677246158774 accuracy 0.9089147448539734 macro_avg {'precision': 0.8970022343594837, 'recall': 0.9158769890935097, 'f1-score': 0.9039779543645845, 'support': 516} weighted_avg {'precision': 0.9153889103792829, 'recall': 0.9089147286821705, 'f1-score': 0.909969594989347, 'support': 516}
 
time = 1.28 secondes

Val loss 0.8089216686785221 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 7/40
time = 22.08 secondes

Train loss 0.32921767866972723 accuracy 0.9011628031730652 macro_avg {'precision': 0.8997093023255814, 'recall': 0.884409082782049, 'f1-score': 0.8910793147549534, 'support': 516} weighted_avg {'precision': 0.9009092752839374, 'recall': 0.9011627906976745, 'f1-score': 0.9001994012763953, 'support': 516}
 
time = 1.32 secondes

Val loss 0.6816576272249222 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 8/40
time = 22.72 secondes

Train loss 0.14788812844816482 accuracy 0.9457364082336426 macro_avg {'precision': 0.9520658902170762, 'recall': 0.9309038896022626, 'f1-score': 0.9399640981317732, 'support': 516} weighted_avg {'precision': 0.9470165488271101, 'recall': 0.9457364341085271, 'f1-score': 0.9450870463111423, 'support': 516}
 
time = 1.36 secondes

Val loss 0.6324226446449757 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 9/40
time = 22.41 secondes

Train loss 0.18088621239770541 accuracy 0.9573643207550049 macro_avg {'precision': 0.9548460847554503, 'recall': 0.952716870113616, 'f1-score': 0.953763440860215, 'support': 516} weighted_avg {'precision': 0.9572953477611666, 'recall': 0.9573643410852714, 'f1-score': 0.9573143285821456, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3168173134326935 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 10/40
time = 25.19 secondes

Train loss 0.09607642867856404 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.18 secondes

Val loss 0.7414986123330891 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 11/40
time = 22.54 secondes

Train loss 0.3540196406556237 accuracy 0.9302325248718262 macro_avg {'precision': 0.9223760406807937, 'recall': 0.927978154511321, 'f1-score': 0.9250242169841782, 'support': 516} weighted_avg {'precision': 0.9309577751357264, 'recall': 0.9302325581395349, 'f1-score': 0.930462337896389, 'support': 516}
 
time = 1.18 secondes

Val loss 0.7413870990276337 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 12/40
time = 22.82 secondes

Train loss 0.14024591866429104 accuracy 0.963178277015686 macro_avg {'precision': 0.9665775401069518, 'recall': 0.9538140207727192, 'f1-score': 0.9596289021482662, 'support': 516} weighted_avg {'precision': 0.9636342909256727, 'recall': 0.9631782945736435, 'f1-score': 0.9629231094973091, 'support': 516}
 
time = 1.34 secondes

Val loss 1.63224196434021 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 13/40
time = 22.26 secondes

Train loss 0.11005997949166957 accuracy 0.9709302186965942 macro_avg {'precision': 0.9712936763834967, 'recall': 0.9656632478910326, 'f1-score': 0.9683625795533974, 'support': 516} weighted_avg {'precision': 0.9709541433361235, 'recall': 0.9709302325581395, 'f1-score': 0.970842897421924, 'support': 516}
 
time = 1.31 secondes

Val loss 0.8709902465343475 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 14/40
time = 22.93 secondes

Train loss 0.056405008590610865 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 1.40 secondes

Val loss 1.7168422043323517 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 15/40
time = 22.48 secondes

Train loss 0.058695363007824526 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 1.42 secondes

Val loss 1.7737182676792145 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 16/40
time = 23.18 secondes

Train loss 0.24259126725585453 accuracy 0.9496123790740967 macro_avg {'precision': 0.9391189495765675, 'recall': 0.9593322822359118, 'f1-score': 0.9468319515558866, 'support': 516} weighted_avg {'precision': 0.9549707623471791, 'recall': 0.9496124031007752, 'f1-score': 0.9501779186692271, 'support': 516}
 
time = 1.42 secondes

Val loss 0.8795256018638611 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 17/40
time = 22.34 secondes

Train loss 0.38300349621038715 accuracy 0.9263566136360168 macro_avg {'precision': 0.9399073860511329, 'recall': 0.903011881735286, 'f1-score': 0.9171511627906976, 'support': 516} weighted_avg {'precision': 0.930381578326647, 'recall': 0.9263565891472868, 'f1-score': 0.9247509915269515, 'support': 516}
 
time = 1.40 secondes

Val loss 0.9035662710666656 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 18/40
time = 22.66 secondes

Train loss 0.10524560890696717 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 1.31 secondes

Val loss 1.372967705130577 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 19/40
time = 22.15 secondes

Train loss 0.38042154245494836 accuracy 0.9341084957122803 macro_avg {'precision': 0.9336533173341333, 'recall': 0.9229393885213659, 'f1-score': 0.9278476015002961, 'support': 516} weighted_avg {'precision': 0.9340523283913323, 'recall': 0.9341085271317829, 'f1-score': 0.9336966241297115, 'support': 516}
 
time = 1.33 secondes

Val loss 1.1163724511861801 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 20/40
time = 22.26 secondes

Train loss 0.02101169667686477 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1384074985980988 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 21/40
time = 23.65 secondes

Train loss 0.04349113626063406 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.47 secondes

Val loss 1.870915949344635 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 22/40
time = 23.83 secondes

Train loss 0.1972290409171502 accuracy 0.963178277015686 macro_avg {'precision': 0.9710472628357701, 'recall': 0.9503519009151049, 'f1-score': 0.9593152816682228, 'support': 516} weighted_avg {'precision': 0.964698436169736, 'recall': 0.9631782945736435, 'f1-score': 0.9627652680365858, 'support': 516}
 
time = 1.38 secondes

Val loss 0.6098794487043051 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 23/40
time = 21.89 secondes

Train loss 0.30284233419771417 accuracy 0.9437984228134155 macro_avg {'precision': 0.9594972067039106, 'recall': 0.9224598930481284, 'f1-score': 0.9368647553952281, 'support': 516} weighted_avg {'precision': 0.9483510891689403, 'recall': 0.9437984496124031, 'f1-score': 0.9426225599498413, 'support': 516}
 
time = 1.37 secondes

Val loss 1.0537696853280067 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 24/40
time = 23.31 secondes

Train loss 0.1573827228276059 accuracy 0.9651162624359131 macro_avg {'precision': 0.9560975609756097, 'recall': 0.9726443768996961, 'f1-score': 0.9629783163265306, 'support': 516} weighted_avg {'precision': 0.9681792399319343, 'recall': 0.9651162790697675, 'f1-score': 0.9654266285002373, 'support': 516}
 
time = 1.37 secondes

Val loss 0.9263665899634361 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 25/40
time = 23.66 secondes

Train loss 0.03945339809367645 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.21 secondes

Val loss 1.2822320312261581 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 26/40
time = 23.11 secondes

Train loss 0.12988585122917412 accuracy 0.9689922332763672 macro_avg {'precision': 0.9723513824308785, 'recall': 0.9606813711945126, 'f1-score': 0.9660459301177864, 'support': 516} weighted_avg {'precision': 0.9694069560087888, 'recall': 0.9689922480620154, 'f1-score': 0.9687984113551584, 'support': 516}
 
time = 1.35 secondes

Val loss 1.1284472346305847 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 27/40
time = 22.95 secondes

Train loss 0.08246188599282918 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.37 secondes

Val loss 1.2328359559178352 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 28/40
time = 18.88 secondes

Train loss 0.05447731309289917 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.18 secondes

Val loss 1.315235897898674 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 29/40
time = 20.16 secondes

Train loss 0.02987680960998687 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.33 secondes

Val loss 1.3759575188159943 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 30/40
time = 22.82 secondes

Train loss 0.04282608038744057 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.36 secondes

Val loss 1.5633101165294647 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 31/40
time = 22.85 secondes

Train loss 0.03143509269901904 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3281793594360352 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 32/40
time = 22.25 secondes

Train loss 0.030389157925100968 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4192143082618713 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 33/40
time = 22.70 secondes

Train loss 0.07918273150822973 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 1.31 secondes

Val loss 1.2304939478635788 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 34/40
time = 23.62 secondes

Train loss 0.008679966057322665 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.30 secondes

Val loss 1.1299671307206154 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 35/40
time = 24.05 secondes

Train loss 0.0004912076732249592 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.27 secondes

Val loss 1.6755010187625885 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 36/40
time = 22.52 secondes

Train loss 0.0001304592180090505 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.76 secondes

Val loss 1.32887801527977 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 37/40
time = 22.90 secondes

Train loss 0.014834055304439089 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.37 secondes

Val loss 1.5959761440753937 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 38/40
time = 20.45 secondes

Train loss 7.960899000119588e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.41 secondes

Val loss 1.4933059811592102 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 39/40
time = 20.59 secondes

Train loss 7.576094481698942e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.37 secondes

Val loss 1.2923797070980072 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 40/40
time = 20.80 secondes

Train loss 7.215757244866285e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.40 secondes

Val loss 1.2590699046850204 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 22 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}

average train time 22.59942283630371

average val time 1.3446102619171143
 
time = 1.69 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_3
----------
Epoch 1/40
time = 23.46 secondes

Train loss 0.6627967339573484 accuracy 0.6124030947685242 macro_avg {'precision': 0.43568228105906315, 'recall': 0.48716740080945337, 'f1-score': 0.4063506672802577, 'support': 516} weighted_avg {'precision': 0.4895328312729914, 'recall': 0.6124031007751938, 'f1-score': 0.5025988434522344, 'support': 516}
 
time = 1.54 secondes

Val loss 0.6728263199329376 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 20.33 secondes

Train loss 0.5337712972453146 accuracy 0.6937984228134155 macro_avg {'precision': 0.7755200774068698, 'recall': 0.5833103067145621, 'f1-score': 0.5524275895386372, 'support': 516} weighted_avg {'precision': 0.7490258510442802, 'recall': 0.6937984496124031, 'f1-score': 0.6216505624023434, 'support': 516}
 
time = 1.42 secondes

Val loss 0.4833974540233612 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 20.19 secondes

Train loss 0.3699362255407102 accuracy 0.8701550364494324 macro_avg {'precision': 0.8580553243260549, 'recall': 0.8635550932171708, 'f1-score': 0.860614197418871, 'support': 516} weighted_avg {'precision': 0.8714784450258688, 'recall': 0.8701550387596899, 'f1-score': 0.870649749051436, 'support': 516}
 
time = 1.38 secondes

Val loss 0.543437123298645 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 4/40
time = 20.96 secondes

Train loss 0.33894439030325774 accuracy 0.8740310072898865 macro_avg {'precision': 0.8658730158730159, 'recall': 0.8596703671797539, 'f1-score': 0.8625719612382454, 'support': 516} weighted_avg {'precision': 0.8732988802756245, 'recall': 0.874031007751938, 'f1-score': 0.8734926632848516, 'support': 516}
 
time = 1.29 secondes

Val loss 0.5117336362600327 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 5/40
time = 20.65 secondes

Train loss 0.3235345901639173 accuracy 0.8856589198112488 macro_avg {'precision': 0.8786706349206349, 'recall': 0.8722510280708028, 'f1-score': 0.8752576263547152, 'support': 516} weighted_avg {'precision': 0.8850317614125753, 'recall': 0.8856589147286822, 'f1-score': 0.8851702635970193, 'support': 516}
 
time = 1.42 secondes

Val loss 0.5972323343157768 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 6/40
time = 20.85 secondes

Train loss 0.19742784265315894 accuracy 0.9244186282157898 macro_avg {'precision': 0.917129480142073, 'recall': 0.9199567641369895, 'f1-score': 0.9185048697025533, 'support': 516} weighted_avg {'precision': 0.9247401836736227, 'recall': 0.9244186046511628, 'f1-score': 0.924546239218399, 'support': 516}
 
time = 1.32 secondes

Val loss 0.6748993769288063 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 7/40
time = 21.87 secondes

Train loss 0.17541596863531705 accuracy 0.9437984228134155 macro_avg {'precision': 0.9365275020810655, 'recall': 0.9432326121938137, 'f1-score': 0.9396688317186157, 'support': 516} weighted_avg {'precision': 0.9445937094986431, 'recall': 0.9437984496124031, 'f1-score': 0.9440125779476365, 'support': 516}
 
time = 1.33 secondes

Val loss 0.5730150938034058 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 8/40
time = 19.23 secondes

Train loss 0.12753853575806273 accuracy 0.9728682041168213 macro_avg {'precision': 0.9696616669093734, 'recall': 0.9717991645400907, 'f1-score': 0.9707122470160872, 'support': 516} weighted_avg {'precision': 0.9729611605367241, 'recall': 0.9728682170542635, 'f1-score': 0.9728990166262376, 'support': 516}
 
time = 1.27 secondes

Val loss 0.9344480037689209 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 9/40
time = 19.89 secondes

Train loss 0.17654042508961124 accuracy 0.963178277015686 macro_avg {'precision': 0.9547360787034118, 'recall': 0.9688165401557141, 'f1-score': 0.9608039116129006, 'support': 516} weighted_avg {'precision': 0.9654396023960269, 'recall': 0.9631782945736435, 'f1-score': 0.9634587335060146, 'support': 516}
 
time = 1.17 secondes

Val loss 0.7489924654364586 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 10/40
time = 21.98 secondes

Train loss 0.19564702764689695 accuracy 0.9554263353347778 macro_avg {'precision': 0.9532477737035097, 'recall': 0.9500430733221723, 'f1-score': 0.9516048134208155, 'support': 516} weighted_avg {'precision': 0.9553380356613511, 'recall': 0.9554263565891473, 'f1-score': 0.9553472901787681, 'support': 516}
 
time = 1.37 secondes

Val loss 0.693743146955967 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 11/40
time = 22.32 secondes

Train loss 0.18667137912813236 accuracy 0.9515503644943237 macro_avg {'precision': 0.944787731318435, 'recall': 0.951619719454513, 'f1-score': 0.9479903721712205, 'support': 516} weighted_avg {'precision': 0.9522900531273563, 'recall': 0.9515503875968992, 'f1-score': 0.9517349809893417, 'support': 516}
 
time = 1.35 secondes

Val loss 0.6989004462957382 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 12/40
time = 22.57 secondes

Train loss 0.1748041759710759 accuracy 0.9476743936538696 macro_avg {'precision': 0.943841642228739, 'recall': 0.942810006014011, 'f1-score': 0.9433213862908705, 'support': 516} weighted_avg {'precision': 0.94762118559943, 'recall': 0.9476744186046512, 'f1-score': 0.9476439778192401, 'support': 516}
 
time = 1.40 secondes

Val loss 1.2842356711626053 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 22.79 secondes

Train loss 0.08987875011128683 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.33 secondes

Val loss 0.8150594308972359 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 14/40
time = 23.17 secondes

Train loss 0.1139960867832556 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.33 secondes

Val loss 0.7194723745342344 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 15/40
time = 22.22 secondes

Train loss 0.14980827233133218 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 1.33 secondes

Val loss 1.143124870955944 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 16/40
time = 22.07 secondes

Train loss 0.1168598596810956 accuracy 0.9748061895370483 macro_avg {'precision': 0.9722366372599895, 'recall': 0.9733189213789964, 'f1-score': 0.9727732115677321, 'support': 516} weighted_avg {'precision': 0.9748429096116791, 'recall': 0.9748062015503876, 'f1-score': 0.9748206199190588, 'support': 516}
 
time = 1.30 secondes

Val loss 1.275737687945366 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 17/40
time = 22.42 secondes

Train loss 0.16760760960592466 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 1.39 secondes

Val loss 0.8697168081998825 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 18/40
time = 22.69 secondes

Train loss 0.04029351533002531 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.36 secondes

Val loss 0.9416374191641808 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 19/40
time = 24.96 secondes

Train loss 0.06274730088295076 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.32 secondes

Val loss 1.2673816978931427 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 20/40
time = 21.77 secondes

Train loss 0.05832654356190963 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.28 secondes

Val loss 1.385620728135109 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 21/40
time = 22.31 secondes

Train loss 0.010212744775785584 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.37 secondes

Val loss 1.531151443719864 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 22/40
time = 22.65 secondes

Train loss 0.08004948277128719 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.36 secondes

Val loss 1.3872569501399994 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 23/40
time = 22.31 secondes

Train loss 0.24057785222292738 accuracy 0.961240291595459 macro_avg {'precision': 0.9696638985045103, 'recall': 0.947678104123661, 'f1-score': 0.9571172129512666, 'support': 516} weighted_avg {'precision': 0.9629439571751132, 'recall': 0.9612403100775194, 'f1-score': 0.960776461650816, 'support': 516}
 
time = 1.35 secondes

Val loss 1.3555873930454254 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 24/40
time = 22.08 secondes

Train loss 0.24150184197633556 accuracy 0.9476743936538696 macro_avg {'precision': 0.9384656618528096, 'recall': 0.9520423256343156, 'f1-score': 0.9443002954499113, 'support': 516} weighted_avg {'precision': 0.9501410498774661, 'recall': 0.9476744186046512, 'f1-score': 0.9480729370874944, 'support': 516}
 
time = 1.31 secondes

Val loss 1.7604705393314362 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 25/40
time = 22.26 secondes

Train loss 0.11485619725091524 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.31 secondes

Val loss 1.1079966872930527 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 26/40
time = 21.99 secondes

Train loss 0.0414901496996842 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.41 secondes

Val loss 1.635060429573059 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 27/40
time = 23.04 secondes

Train loss 0.12300890154173513 accuracy 0.9748061895370483 macro_avg {'precision': 0.9712786567646109, 'recall': 0.9744729613315346, 'f1-score': 0.9728349565675176, 'support': 516} weighted_avg {'precision': 0.9749618285262307, 'recall': 0.9748062015503876, 'f1-score': 0.9748487464061328, 'support': 516}
 
time = 1.39 secondes

Val loss 1.355460062623024 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 28/40
time = 22.85 secondes

Train loss 0.08010077242568403 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.42 secondes

Val loss 1.270419955253601 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 29/40
time = 22.57 secondes

Train loss 0.2288842813013065 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.40 secondes

Val loss 1.8518516421318054 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 30/40
time = 22.51 secondes

Train loss 0.04140685981176582 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.47 secondes

Val loss 1.2788763642311096 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 31/40
time = 23.16 secondes

Train loss 0.16450538393110037 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.39 secondes

Val loss 1.9819650650024414 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 32/40
time = 24.61 secondes

Train loss 0.09004868880252946 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 1.40 secondes

Val loss 1.7378307357430458 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 33/40
time = 22.15 secondes

Train loss 0.05794502737240471 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.27 secondes

Val loss 1.6111666858196259 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 34/40
time = 22.77 secondes

Train loss 0.1519980798973737 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.40 secondes

Val loss 1.3820015788078308 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 35/40
time = 22.04 secondes

Train loss 0.025512878563225087 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.20 secondes

Val loss 1.2526503503322601 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 36/40
time = 21.42 secondes

Train loss 0.021446643884480705 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.39 secondes

Val loss 1.0760826468467712 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 37/40
time = 22.46 secondes

Train loss 0.00016229362143238893 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.45 secondes

Val loss 1.2256381064653397 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 38/40
time = 22.00 secondes

Train loss 0.011589276282227895 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.22 secondes

Val loss 1.3811354339122772 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 21.97 secondes

Train loss 0.00033326667890474766 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.29 secondes

Val loss 1.4226485192775726 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 40/40
time = 23.90 secondes

Train loss 0.00010050080406169097 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3008616864681244 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 7 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}

average train time 22.185407996177673

average val time 1.3521966934204102
 
time = 1.67 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9425, 'recall': 0.9312865497076024, 'f1-score': 0.9358974358974359, 'support': 65} weighted_avg {'precision': 0.9395384615384614, 'recall': 0.9384615384615385, 'f1-score': 0.9380670611439843, 'support': 65}

----------
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_none_5
----------
Epoch 1/40
time = 637.73 secondes

Train loss 0.2915662079109802 micro_f1_score 0.5578742348358375 
 
time = 53.02 secondes

Val loss 0.2561654902872492 micro_f1_score 0.5085662759242561
 
----------
Epoch 2/40
time = 626.52 secondes

Train loss 0.19164199429387982 micro_f1_score 0.7276150627615062 
 
time = 52.50 secondes

Val loss 0.21206852683766944 micro_f1_score 0.6908797417271993
 
----------
Epoch 3/40
time = 624.06 secondes

Train loss 0.16602954127498576 micro_f1_score 0.775623040105628 
 
time = 53.62 secondes

Val loss 0.21031517144597944 micro_f1_score 0.7053254437869821
 
----------
Epoch 4/40
time = 604.38 secondes

Train loss 0.1475258945411927 micro_f1_score 0.8062759125274368 
 
time = 53.03 secondes

Val loss 0.21245583000241733 micro_f1_score 0.702954898911353
 
----------
Epoch 5/40
time = 625.15 secondes

Train loss 0.13360636421722602 micro_f1_score 0.830012957563978 
 
time = 52.63 secondes

Val loss 0.2073919389580117 micro_f1_score 0.7145586549484141
 
----------
Epoch 6/40
time = 626.46 secondes

Train loss 0.12028239792766603 micro_f1_score 0.8523958584156032 
 
time = 49.21 secondes

Val loss 0.2157714710128112 micro_f1_score 0.7182361733931241
 
----------
Epoch 7/40
time = 622.96 secondes

Train loss 0.10934484153314754 micro_f1_score 0.8679079781507913 
 
time = 49.50 secondes

Val loss 0.23068996702061326 micro_f1_score 0.7111756168359943
 
----------
Epoch 8/40
time = 622.74 secondes

Train loss 0.09909305191590442 micro_f1_score 0.8832777513101476 
 
time = 50.13 secondes

Val loss 0.23443534945855377 micro_f1_score 0.7213474917612596
 
----------
Epoch 9/40
time = 604.76 secondes

Train loss 0.0892345881626547 micro_f1_score 0.8974105554457403 
 
time = 51.88 secondes

Val loss 0.24332475442378249 micro_f1_score 0.72211998527788
 
----------
Epoch 10/40
time = 626.44 secondes

Train loss 0.08139570816545873 micro_f1_score 0.9081132001413038 
 
time = 54.26 secondes

Val loss 0.26226802671053373 micro_f1_score 0.7144927536231884
 
----------
Epoch 11/40
time = 626.77 secondes

Train loss 0.07150750354033064 micro_f1_score 0.9214974431041887 
 
time = 50.85 secondes

Val loss 0.2754409087241673 micro_f1_score 0.7224862888482633
 
----------
Epoch 12/40
time = 623.98 secondes

Train loss 0.06302306842612657 micro_f1_score 0.9335044330377974 
 
time = 53.73 secondes

Val loss 0.2899292278729501 micro_f1_score 0.7221226245966296
 
----------
Epoch 13/40
time = 626.07 secondes

Train loss 0.05647022286807565 micro_f1_score 0.940368574199806 
 
time = 53.98 secondes

Val loss 0.31815181074083826 micro_f1_score 0.7113850616388687
 
----------
Epoch 14/40
time = 612.82 secondes

Train loss 0.051222286400435545 micro_f1_score 0.9449300023203651 
 
time = 53.64 secondes

Val loss 0.34433561416923025 micro_f1_score 0.7110794442465266
 
----------
Epoch 15/40
time = 626.11 secondes

Train loss 0.04429945924239619 micro_f1_score 0.9536515770802807 
 
time = 52.66 secondes

Val loss 0.3586486872346675 micro_f1_score 0.7140864714086471
 
----------
Epoch 16/40
time = 628.91 secondes

Train loss 0.03952307170026239 micro_f1_score 0.9586891299330718 
 
time = 51.54 secondes

Val loss 0.37427795458523955 micro_f1_score 0.7192186955005232
 
----------
Epoch 17/40
time = 612.30 secondes

Train loss 0.035014528976879206 micro_f1_score 0.9623938846848231 
 
time = 54.07 secondes

Val loss 0.3947087664340363 micro_f1_score 0.7146316153580077
 
----------
Epoch 18/40
time = 626.31 secondes

Train loss 0.03218931164424699 micro_f1_score 0.9654934172648063 
 
time = 51.66 secondes

Val loss 0.3969643450662738 micro_f1_score 0.7182203389830508
 
----------
Epoch 19/40
time = 596.29 secondes

Train loss 0.027331572665931524 micro_f1_score 0.9717349674454231 
 
time = 54.02 secondes

Val loss 0.4121750108286983 micro_f1_score 0.7115181401902078
 
----------
Epoch 20/40
time = 620.51 secondes

Train loss 0.025599470885621534 micro_f1_score 0.9733103580317825 
 
time = 53.17 secondes

Val loss 0.4206241325276797 micro_f1_score 0.7205673758865249
 
----------
Epoch 21/40
time = 624.26 secondes

Train loss 0.022697105808162574 micro_f1_score 0.9749866136311482 
 
time = 52.21 secondes

Val loss 0.44950812371050725 micro_f1_score 0.7149449769258075
 
----------
Epoch 22/40
time = 613.96 secondes

Train loss 0.020862833872439576 micro_f1_score 0.9773413320087119 
 
time = 52.12 secondes

Val loss 0.45183445610960976 micro_f1_score 0.7159172019985724
 
----------
Epoch 23/40
time = 621.71 secondes

Train loss 0.0179984748464965 micro_f1_score 0.9803517607111518 
 
time = 53.49 secondes

Val loss 0.4675686948123525 micro_f1_score 0.7222619899785254
 
----------
Epoch 24/40
time = 602.02 secondes

Train loss 0.01657466442520344 micro_f1_score 0.982406594664733 
 
time = 50.22 secondes

Val loss 0.47665675497445903 micro_f1_score 0.7200282087447107
 
----------
Epoch 25/40
time = 627.66 secondes

Train loss 0.015683468441643568 micro_f1_score 0.9830482648280066 
 
time = 53.39 secondes

Val loss 0.4776788013147526 micro_f1_score 0.735252808988764
 
----------
Epoch 26/40
time = 624.50 secondes

Train loss 0.012838889922823983 micro_f1_score 0.9874247389680664 
 
time = 52.09 secondes

Val loss 0.5041218922763574 micro_f1_score 0.7252204585537918
 
----------
Epoch 27/40
time = 625.55 secondes

Train loss 0.012418414628880962 micro_f1_score 0.9872820044170284 
 
time = 51.99 secondes

Val loss 0.5174566609937636 micro_f1_score 0.7309608540925268
 
----------
Epoch 28/40
time = 619.80 secondes

Train loss 0.011331894686212238 micro_f1_score 0.9886887306242145 
 
time = 53.77 secondes

Val loss 0.5187655596948061 micro_f1_score 0.7286378262424026
 
----------
Epoch 29/40
time = 606.22 secondes

Train loss 0.010271169964094575 micro_f1_score 0.9893847734276909 
 
time = 51.75 secondes

Val loss 0.5254402742034099 micro_f1_score 0.7293178519593614
 
----------
Epoch 30/40
time = 620.20 secondes

Train loss 0.009986983422854095 micro_f1_score 0.9901050388186939 
 
time = 54.03 secondes

Val loss 0.518619249834389 micro_f1_score 0.7316546762589928
 
----------
Epoch 31/40
time = 622.36 secondes

Train loss 0.008687911824138913 micro_f1_score 0.9912871437811513 
 
time = 53.05 secondes

Val loss 0.5413224298934467 micro_f1_score 0.7242120343839542
 
----------
Epoch 32/40
time = 605.81 secondes

Train loss 0.008867937781217954 micro_f1_score 0.9912123863506676 
 
time = 52.28 secondes

Val loss 0.5403936649443674 micro_f1_score 0.7321554770318021
 
----------
Epoch 33/40
time = 605.39 secondes

Train loss 0.00707221869405174 micro_f1_score 0.9931874405328259 
 
time = 51.88 secondes

Val loss 0.5476505408277277 micro_f1_score 0.7346938775510204
 
----------
Epoch 34/40
time = 583.06 secondes

Train loss 0.006161651835157557 micro_f1_score 0.9941053432211446 
 
time = 52.30 secondes

Val loss 0.5608907183174228 micro_f1_score 0.7319884726224785
 
----------
Epoch 35/40
time = 605.56 secondes

Train loss 0.004896661154208715 micro_f1_score 0.9951712862628798 
 
time = 50.68 secondes

Val loss 0.576927693652325 micro_f1_score 0.731811697574893
 
----------
Epoch 36/40
time = 607.89 secondes

Train loss 0.004485680644089977 micro_f1_score 0.9954025608875716 
 
time = 53.08 secondes

Val loss 0.5756611154704797 micro_f1_score 0.7324638702855129
 
----------
Epoch 37/40
time = 606.88 secondes

Train loss 0.0038693634841144337 micro_f1_score 0.9958197157406703 
 
time = 53.04 secondes

Val loss 0.5871802394995924 micro_f1_score 0.7335243553008596
 
----------
Epoch 38/40
time = 588.01 secondes

Train loss 0.003244729370769844 micro_f1_score 0.9967322744889429 
 
time = 52.14 secondes

Val loss 0.5825307498701283 micro_f1_score 0.7416370106761565
 
----------
Epoch 39/40
time = 603.19 secondes

Train loss 0.002548821844166915 micro_f1_score 0.9979854802539055 
 
time = 51.56 secondes

Val loss 0.5882352568575593 micro_f1_score 0.735575221238938
 
----------
Epoch 40/40
time = 604.96 secondes

Train loss 0.0017960788422512065 micro_f1_score 0.9983659509785293 
 
time = 51.91 secondes

Val loss 0.5921909076268556 micro_f1_score 0.7357549857549859
 
----------
best_f1_socre 0.7416370106761565 best_epoch 38

average train time 616.006008130312

average val time 52.40200302600861
 
time = 49.59 secondes

test_f1_score 0.7189856065798491

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_head_tail_5
----------
Epoch 1/40
time = 504.63 secondes

Train loss 0.2747668520824329 micro_f1_score 0.6048858916528963 
 
time = 42.09 secondes

Val loss 0.22586832647440863 micro_f1_score 0.6320032245062475
 
----------
Epoch 2/40
time = 500.06 secondes

Train loss 0.17793754525147043 micro_f1_score 0.7548586754693626 
 
time = 49.53 secondes

Val loss 0.1958449140923922 micro_f1_score 0.7274167987321712
 
----------
Epoch 3/40
time = 540.84 secondes

Train loss 0.14860509668585953 micro_f1_score 0.8050554720201569 
 
time = 48.01 secondes

Val loss 0.18590884692356235 micro_f1_score 0.743169398907104
 
----------
Epoch 4/40
time = 528.48 secondes

Train loss 0.1294111451738187 micro_f1_score 0.8363752801793147 
 
time = 49.92 secondes

Val loss 0.1825496087186649 micro_f1_score 0.753757225433526
 
----------
Epoch 5/40
time = 532.97 secondes

Train loss 0.11462310235276148 micro_f1_score 0.8607181285617502 
 
time = 49.38 secondes

Val loss 0.19773412660741416 micro_f1_score 0.7471612414837244
 
----------
Epoch 6/40
time = 533.68 secondes

Train loss 0.10158234724422564 micro_f1_score 0.8779558800190445 
 
time = 50.23 secondes

Val loss 0.20492982882700983 micro_f1_score 0.750561797752809
 
----------
Epoch 7/40
time = 524.45 secondes

Train loss 0.08974770803658946 micro_f1_score 0.8957437576426965 
 
time = 49.71 secondes

Val loss 0.22181771964323324 micro_f1_score 0.7377777777777779
 
----------
Epoch 8/40
time = 477.69 secondes

Train loss 0.08021630001011061 micro_f1_score 0.9106175939731618 
 
time = 49.89 secondes

Val loss 0.23683946811762013 micro_f1_score 0.7392571012381646
 
----------
Epoch 9/40
time = 550.24 secondes

Train loss 0.07120005470020949 micro_f1_score 0.9213588809215939 
 
time = 46.80 secondes

Val loss 0.2459899312282195 micro_f1_score 0.7466473359913013
 
----------
Epoch 10/40
time = 523.43 secondes

Train loss 0.06287276040938859 micro_f1_score 0.9336030183982263 
 
time = 50.45 secondes

Val loss 0.25282480054702916 micro_f1_score 0.7482895210658984
 
----------
Epoch 11/40
time = 530.61 secondes

Train loss 0.05467037834218695 micro_f1_score 0.9419665385660496 
 
time = 49.46 secondes

Val loss 0.2707535133498614 micro_f1_score 0.7564241766196163
 
----------
Epoch 12/40
time = 522.28 secondes

Train loss 0.04850847902204338 micro_f1_score 0.9497228359886808 
 
time = 50.08 secondes

Val loss 0.28493784673389844 micro_f1_score 0.7506243310738494
 
----------
Epoch 13/40
time = 535.20 secondes

Train loss 0.04252050265057331 micro_f1_score 0.9568303691987192 
 
time = 49.96 secondes

Val loss 0.3060574724537427 micro_f1_score 0.7427356484762581
 
----------
Epoch 14/40
time = 536.36 secondes

Train loss 0.03848999761829471 micro_f1_score 0.958729914068822 
 
time = 50.19 secondes

Val loss 0.3201086681763657 micro_f1_score 0.7432432432432433
 
----------
Epoch 15/40
time = 521.61 secondes

Train loss 0.03400136479449265 micro_f1_score 0.9648198700449844 
 
time = 49.29 secondes

Val loss 0.3279217893227202 micro_f1_score 0.7437433909058865
 
----------
Epoch 16/40
time = 539.57 secondes

Train loss 0.03087503757445259 micro_f1_score 0.9677295722826921 
 
time = 49.53 secondes

Val loss 0.336991478063044 micro_f1_score 0.7446504992867333
 
----------
Epoch 17/40
time = 535.44 secondes

Train loss 0.027048109941025106 micro_f1_score 0.9708099009143424 
 
time = 46.90 secondes

Val loss 0.35062065012142307 micro_f1_score 0.7476702508960573
 
----------
Epoch 18/40
time = 534.17 secondes

Train loss 0.02454654303891165 micro_f1_score 0.9732853643600734 
 
time = 49.28 secondes

Val loss 0.37172051116091304 micro_f1_score 0.7461322081575246
 
----------
Epoch 19/40
time = 536.23 secondes

Train loss 0.022314308800940142 micro_f1_score 0.9755687249091951 
 
time = 50.07 secondes

Val loss 0.3696767977270924 micro_f1_score 0.7517266448564158
 
----------
Epoch 20/40
time = 519.68 secondes

Train loss 0.01878365405642759 micro_f1_score 0.9801688892285354 
 
time = 47.44 secondes

Val loss 0.384676706595499 micro_f1_score 0.7508999280057597
 
----------
Epoch 21/40
time = 530.03 secondes

Train loss 0.01804144935009095 micro_f1_score 0.9813422870006486 
 
time = 48.91 secondes

Val loss 0.4014235490658244 micro_f1_score 0.7466570292735815
 
----------
Epoch 22/40
time = 534.01 secondes

Train loss 0.015609062487167214 micro_f1_score 0.9831102977620191 
 
time = 50.31 secondes

Val loss 0.40744201802327984 micro_f1_score 0.7488151658767772
 
----------
Epoch 23/40
time = 522.84 secondes

Train loss 0.014207118664089977 micro_f1_score 0.985469661721521 
 
time = 46.22 secondes

Val loss 0.42047337002930096 micro_f1_score 0.7517266448564158
 
----------
Epoch 24/40
time = 534.35 secondes

Train loss 0.013265751554763892 micro_f1_score 0.9858886346300534 
 
time = 48.01 secondes

Val loss 0.43621045949517706 micro_f1_score 0.751701898960946
 
----------
Epoch 25/40
time = 531.68 secondes

Train loss 0.012772733352281025 micro_f1_score 0.9867083063564002 
 
time = 49.93 secondes

Val loss 0.44758362799394324 micro_f1_score 0.7517266448564158
 
----------
Epoch 26/40
time = 535.48 secondes

Train loss 0.010866959123794349 micro_f1_score 0.9881976699916242 
 
time = 48.58 secondes

Val loss 0.45985696599131726 micro_f1_score 0.7499097798628652
 
----------
Epoch 27/40
time = 538.03 secondes

Train loss 0.009894399685108182 micro_f1_score 0.9892636868956064 
 
time = 49.43 secondes

Val loss 0.446689208633587 micro_f1_score 0.7487328023171613
 
----------
Epoch 28/40
time = 526.01 secondes

Train loss 0.0085853688935196 micro_f1_score 0.9912911199847879 
 
time = 49.73 secondes

Val loss 0.46371164246172203 micro_f1_score 0.7577413479052822
 
----------
Epoch 29/40
time = 536.79 secondes

Train loss 0.009223886835860793 micro_f1_score 0.9903791306993193 
 
time = 49.54 secondes

Val loss 0.4823601200688081 micro_f1_score 0.7517934002869441
 
----------
Epoch 30/40
time = 535.72 secondes

Train loss 0.00735721266781282 micro_f1_score 0.9918637365979774 
 
time = 47.34 secondes

Val loss 0.4869396938163726 micro_f1_score 0.7535185853482497
 
----------
Epoch 31/40
time = 532.67 secondes

Train loss 0.006698926676744213 micro_f1_score 0.99308142629058 
 
time = 35.98 secondes

Val loss 0.5157192592493823 micro_f1_score 0.7461177320332248
 
----------
Epoch 32/40
time = 532.44 secondes

Train loss 0.00595104567065383 micro_f1_score 0.994368769500038 
 
time = 49.55 secondes

Val loss 0.49563553062130195 micro_f1_score 0.7524254401724758
 
----------
Epoch 33/40
time = 523.23 secondes

Train loss 0.00562651036386694 micro_f1_score 0.9944541517891058 
 
time = 49.73 secondes

Val loss 0.5134527340042786 micro_f1_score 0.7576766555678877
 
----------
Epoch 34/40
time = 533.57 secondes

Train loss 0.0048532794599940735 micro_f1_score 0.9952098540145984 
 
time = 49.52 secondes

Val loss 0.514156385156952 micro_f1_score 0.7577505407354003
 
----------
Epoch 35/40
time = 531.15 secondes

Train loss 0.004427977966357454 micro_f1_score 0.9958178085316707 
 
time = 50.01 secondes

Val loss 0.5185629460410993 micro_f1_score 0.7609475951184493
 
----------
Epoch 36/40
time = 522.85 secondes

Train loss 0.003578123313152016 micro_f1_score 0.9966974148730214 
 
time = 50.25 secondes

Val loss 0.5258816683390102 micro_f1_score 0.7593466424682395
 
----------
Epoch 37/40
time = 535.10 secondes

Train loss 0.0032476671702055568 micro_f1_score 0.9966562808724068 
 
time = 49.18 secondes

Val loss 0.5466466938130191 micro_f1_score 0.7489331436699858
 
----------
Epoch 38/40
time = 523.69 secondes

Train loss 0.002853177561112855 micro_f1_score 0.9974170022031451 
 
time = 49.77 secondes

Val loss 0.5355112217977399 micro_f1_score 0.7571428571428572
 
----------
Epoch 39/40
time = 535.82 secondes

Train loss 0.0022113558103400636 micro_f1_score 0.9977975241133137 
 
time = 49.10 secondes

Val loss 0.5408068379906358 micro_f1_score 0.7614646285104871
 
----------
Epoch 40/40
time = 534.94 secondes

Train loss 0.0017414214145491814 micro_f1_score 0.9982907281498081 
 
time = 48.12 secondes

Val loss 0.5508331547750801 micro_f1_score 0.7567567567567568
 
----------
best_f1_socre 0.7614646285104871 best_epoch 39

average train time 528.9501752614975

average val time 48.685406333208086
 
time = 53.57 secondes

test_f1_score 0.7384508509899271

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_BERT_tail_5
----------
Epoch 1/40
time = 532.52 secondes

Train loss 0.27449444755240604 micro_f1_score 0.6079827011442472 
 
time = 51.13 secondes

Val loss 0.21771404489141996 micro_f1_score 0.660618556701031
 
----------
Epoch 2/40
time = 531.79 secondes

Train loss 0.17771230970954036 micro_f1_score 0.756536897152818 
 
time = 47.32 secondes

Val loss 0.19547061500002127 micro_f1_score 0.7161366313309776
 
----------
Epoch 3/40
time = 528.28 secondes

Train loss 0.1508007169239693 micro_f1_score 0.8003759552122921 
 
time = 48.87 secondes

Val loss 0.1900923651505689 micro_f1_score 0.7348980377068104
 
----------
Epoch 4/40
time = 534.00 secondes

Train loss 0.13183941914624459 micro_f1_score 0.8293645997018414 
 
time = 49.29 secondes

Val loss 0.19827542252472188 micro_f1_score 0.7366795366795366
 
----------
Epoch 5/40
time = 530.69 secondes

Train loss 0.11835713650662083 micro_f1_score 0.8520251089520611 
 
time = 49.28 secondes

Val loss 0.19510874726244662 micro_f1_score 0.7518740629685158
 
----------
Epoch 6/40
time = 523.44 secondes

Train loss 0.10395906182291272 micro_f1_score 0.8736444885799405 
 
time = 50.02 secondes

Val loss 0.2182789581110243 micro_f1_score 0.7324792765636774
 
----------
Epoch 7/40
time = 535.69 secondes

Train loss 0.0928984896380555 micro_f1_score 0.8887398935121278 
 
time = 48.19 secondes

Val loss 0.2173607979641586 micro_f1_score 0.7498116051243408
 
----------
Epoch 8/40
time = 535.13 secondes

Train loss 0.08460517485651213 micro_f1_score 0.9015950150879806 
 
time = 49.34 secondes

Val loss 0.23669082005737258 micro_f1_score 0.742367833209233
 
----------
Epoch 9/40
time = 525.46 secondes

Train loss 0.07411195055942411 micro_f1_score 0.9151642862717553 
 
time = 49.12 secondes

Val loss 0.25249960420073053 micro_f1_score 0.7469613259668509
 
----------
Epoch 10/40
time = 532.22 secondes

Train loss 0.06592458546295896 micro_f1_score 0.9254312526770765 
 
time = 49.53 secondes

Val loss 0.25859249022896175 micro_f1_score 0.7462135205024011
 
----------
Epoch 11/40
time = 530.04 secondes

Train loss 0.05677895954357007 micro_f1_score 0.938748644881524 
 
time = 48.10 secondes

Val loss 0.27685207727014044 micro_f1_score 0.7492753623188405
 
----------
Epoch 12/40
time = 534.93 secondes

Train loss 0.05101968658047619 micro_f1_score 0.9429787234042554 
 
time = 49.05 secondes

Val loss 0.2928266181747933 micro_f1_score 0.7448425624321389
 
----------
Epoch 13/40
time = 536.28 secondes

Train loss 0.044394264227777785 micro_f1_score 0.9539184711412498 
 
time = 50.21 secondes

Val loss 0.3018650854403367 micro_f1_score 0.7499999999999999
 
----------
Epoch 14/40
time = 522.28 secondes

Train loss 0.03994471418193063 micro_f1_score 0.9555026129726406 
 
time = 49.88 secondes

Val loss 0.3196006494223094 micro_f1_score 0.7390998593530239
 
----------
Epoch 15/40
time = 533.97 secondes

Train loss 0.03487265089155502 micro_f1_score 0.9623408498235926 
 
time = 46.67 secondes

Val loss 0.34412410470550175 micro_f1_score 0.7446885127835794
 
----------
Epoch 16/40
time = 534.90 secondes

Train loss 0.03055700299766351 micro_f1_score 0.9676035842842919 
 
time = 46.12 secondes

Val loss 0.34809115248136835 micro_f1_score 0.7389903329752954
 
----------
Epoch 17/40
time = 536.51 secondes

Train loss 0.026261264657515715 micro_f1_score 0.9723305052358021 
 
time = 49.77 secondes

Val loss 0.35702449748994874 micro_f1_score 0.7501789549033642
 
----------
Epoch 18/40
time = 539.15 secondes

Train loss 0.02390682149965836 micro_f1_score 0.9747744993120318 
 
time = 45.98 secondes

Val loss 0.3844899608921565 micro_f1_score 0.7426921688920967
 
----------
Epoch 19/40
time = 522.21 secondes

Train loss 0.02139748547733279 micro_f1_score 0.9761622345513679 
 
time = 50.21 secondes

Val loss 0.3843521159142256 micro_f1_score 0.7527968242511729
 
----------
Epoch 20/40
time = 532.27 secondes

Train loss 0.01920149823108495 micro_f1_score 0.978291556979894 
 
time = 49.36 secondes

Val loss 0.3890612524796705 micro_f1_score 0.759493670886076
 
----------
Epoch 21/40
time = 540.04 secondes

Train loss 0.01617099237484073 micro_f1_score 0.9825097380279539 
 
time = 51.07 secondes

Val loss 0.42588861680162127 micro_f1_score 0.7480371163454674
 
----------
Epoch 22/40
time = 521.24 secondes

Train loss 0.015708717795902747 micro_f1_score 0.9838052051975765 
 
time = 50.71 secondes

Val loss 0.4440508409723884 micro_f1_score 0.7456296824830538
 
----------
Epoch 23/40
time = 538.67 secondes

Train loss 0.015434053893939662 micro_f1_score 0.9837491416800183 
 
time = 50.34 secondes

Val loss 0.43047154770751833 micro_f1_score 0.752280189711784
 
----------
Epoch 24/40
time = 532.44 secondes

Train loss 0.01386315961481651 micro_f1_score 0.9846787102675509 
 
time = 48.63 secondes

Val loss 0.4542354370360492 micro_f1_score 0.75408670931059
 
----------
Epoch 25/40
time = 538.78 secondes

Train loss 0.012687989991785683 micro_f1_score 0.9874381423677199 
 
time = 50.07 secondes

Val loss 0.4476934086958893 micro_f1_score 0.7477702461648235
 
----------
Epoch 26/40
time = 533.27 secondes

Train loss 0.011266448615984897 micro_f1_score 0.987916904898037 
 
time = 49.77 secondes

Val loss 0.4753768053821853 micro_f1_score 0.7484143763213531
 
----------
Epoch 27/40
time = 520.94 secondes

Train loss 0.01075179192303695 micro_f1_score 0.9889591106373258 
 
time = 48.49 secondes

Val loss 0.47965834660791473 micro_f1_score 0.7486318861729296
 
----------
Epoch 28/40
time = 535.45 secondes

Train loss 0.009520644304719607 micro_f1_score 0.9892734880182579 
 
time = 49.60 secondes

Val loss 0.4797847541812502 micro_f1_score 0.7514492753623189
 
----------
Epoch 29/40
time = 535.40 secondes

Train loss 0.008204619930833573 micro_f1_score 0.9912117177097204 
 
time = 47.25 secondes

Val loss 0.48970843488197835 micro_f1_score 0.758645795413178
 
----------
Epoch 30/40
time = 536.67 secondes

Train loss 0.007319766548863373 micro_f1_score 0.9927756653992396 
 
time = 48.78 secondes

Val loss 0.4995010175473118 micro_f1_score 0.7575647101713452
 
----------
Epoch 31/40
time = 534.15 secondes

Train loss 0.006282753840587412 micro_f1_score 0.9931165620840464 
 
time = 49.88 secondes

Val loss 0.5089208689808357 micro_f1_score 0.7647058823529411
 
----------
Epoch 32/40
time = 529.53 secondes

Train loss 0.006050854724775376 micro_f1_score 0.9937340978999734 
 
time = 48.04 secondes

Val loss 0.5189008450318799 micro_f1_score 0.751808972503618
 
----------
Epoch 33/40
time = 534.69 secondes

Train loss 0.004741290797791989 micro_f1_score 0.994906879513493 
 
time = 49.05 secondes

Val loss 0.5414693921682288 micro_f1_score 0.7519884309472161
 
----------
Epoch 34/40
time = 542.02 secondes

Train loss 0.004481330381775905 micro_f1_score 0.9952473289988973 
 
time = 46.22 secondes

Val loss 0.5497518997700488 micro_f1_score 0.7601290785227679
 
----------
Epoch 35/40
time = 524.28 secondes

Train loss 0.004081403476805274 micro_f1_score 0.9956703380174705 
 
time = 44.06 secondes

Val loss 0.5394671531852151 micro_f1_score 0.7621446563512054
 
----------
Epoch 36/40
time = 536.96 secondes

Train loss 0.0034402479089745155 micro_f1_score 0.9963511972633978 
 
time = 49.81 secondes

Val loss 0.5470845141738164 micro_f1_score 0.7604507451835696
 
----------
Epoch 37/40
time = 523.46 secondes

Train loss 0.0026176699987371576 micro_f1_score 0.9971871674015508 
 
time = 50.35 secondes

Val loss 0.5562467368655517 micro_f1_score 0.7577729573391179
 
----------
Epoch 38/40
time = 537.73 secondes

Train loss 0.0026138467352776955 micro_f1_score 0.9975693125712115 
 
time = 49.29 secondes

Val loss 0.555454138605321 micro_f1_score 0.7611886860007162
 
----------
Epoch 39/40
time = 533.32 secondes

Train loss 0.0017789517127041747 micro_f1_score 0.9982521468196671 
 
time = 50.01 secondes

Val loss 0.5592660044060379 micro_f1_score 0.763110307414105
 
----------
Epoch 40/40
time = 528.93 secondes

Train loss 0.0016332848649268795 micro_f1_score 0.9982140821522211 
 
time = 46.74 secondes

Val loss 0.5766408716435315 micro_f1_score 0.7563506261180679
 
----------
best_f1_socre 0.7647058823529411 best_epoch 31

average train time 532.2431358873844

average val time 48.88977432847023
 
time = 50.00 secondes

test_f1_score 0.7484188334504568

----------
516 516
datasets imported
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_none_5
----------
Epoch 1/40
time = 20.13 secondes

Train loss 0.6462159536101602 accuracy 0.6259689927101135 macro_avg {'precision': 0.4605862265224815, 'recall': 0.49549761877671766, 'f1-score': 0.40377534709125856, 'support': 516} weighted_avg {'precision': 0.5087099001557447, 'recall': 0.625968992248062, 'f1-score': 0.503938831574643, 'support': 516}
 
time = 1.37 secondes

Val loss 0.5959101319313049 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.62 secondes

Train loss 0.49835846866622113 accuracy 0.7984496355056763 macro_avg {'precision': 0.7935954869752779, 'recall': 0.758854412171058, 'f1-score': 0.7698128099102655, 'support': 516} weighted_avg {'precision': 0.7967003780146962, 'recall': 0.7984496124031008, 'f1-score': 0.7921558096574228, 'support': 516}
 
time = 1.20 secondes

Val loss 0.5994574576616287 accuracy 0.734375 macro_avg {'precision': 0.7258748674443266, 'recall': 0.715587044534413, 'f1-score': 0.7189356755360372, 'support': 64} weighted_avg {'precision': 0.7315416224814422, 'recall': 0.734375, 'f1-score': 0.7312871351072074, 'support': 64}
 
----------
Epoch 3/40
time = 18.13 secondes

Train loss 0.42426105069391656 accuracy 0.8217054009437561 macro_avg {'precision': 0.8062544420753376, 'recall': 0.8151748126716838, 'f1-score': 0.8100147275405007, 'support': 516} weighted_avg {'precision': 0.8255004049519843, 'recall': 0.8217054263565892, 'f1-score': 0.8229840965395988, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4888661578297615 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 4/40
time = 17.59 secondes

Train loss 0.4102749072692611 accuracy 0.8372092843055725 macro_avg {'precision': 0.8245152206186198, 'recall': 0.8446434666710011, 'f1-score': 0.8300368598541291, 'support': 516} weighted_avg {'precision': 0.8502660720813133, 'recall': 0.8372093023255814, 'f1-score': 0.8396452261838105, 'support': 516}
 
time = 1.19 secondes

Val loss 0.572905421257019 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 5/40
time = 18.96 secondes

Train loss 0.31649179643753805 accuracy 0.8875969052314758 macro_avg {'precision': 0.8872398469536571, 'recall': 0.8668465451944801, 'f1-score': 0.8753062346882656, 'support': 516} weighted_avg {'precision': 0.88751842619818, 'recall': 0.8875968992248062, 'f1-score': 0.8860795332326408, 'support': 516}
 
time = 1.21 secondes

Val loss 0.531412348151207 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 6/40
time = 17.57 secondes

Train loss 0.4626806065665953 accuracy 0.8313953280448914 macro_avg {'precision': 0.8174299429164504, 'recall': 0.8181574370560603, 'f1-score': 0.8177899543378995, 'support': 516} weighted_avg {'precision': 0.8315948546360773, 'recall': 0.8313953488372093, 'f1-score': 0.831491840996779, 'support': 516}
 
time = 1.24 secondes

Val loss 0.7461899816989899 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 7/40
time = 17.76 secondes

Train loss 0.269648060089711 accuracy 0.9147287011146545 macro_avg {'precision': 0.9132299958106409, 'recall': 0.9008175804170797, 'f1-score': 0.9063906984414941, 'support': 516} weighted_avg {'precision': 0.9145120046245329, 'recall': 0.9147286821705426, 'f1-score': 0.9140789691526946, 'support': 516}
 
time = 1.20 secondes

Val loss 0.7824915796518326 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 8/40
time = 17.82 secondes

Train loss 0.20103141538460145 accuracy 0.9341084957122803 macro_avg {'precision': 0.927184857027789, 'recall': 0.9310176681891325, 'f1-score': 0.9290325712344062, 'support': 516} weighted_avg {'precision': 0.9345218805708273, 'recall': 0.9341085271317829, 'f1-score': 0.9342556562882287, 'support': 516}
 
time = 1.11 secondes

Val loss 0.7441833168268204 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 9/40
time = 17.84 secondes

Train loss 0.180755512732448 accuracy 0.9496123790740967 macro_avg {'precision': 0.9464195313137911, 'recall': 0.9443297628529168, 'f1-score': 0.9453567937438906, 'support': 516} weighted_avg {'precision': 0.9495249271614058, 'recall': 0.9496124031007752, 'f1-score': 0.949553297415263, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5866265371441841 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 10/40
time = 17.82 secondes

Train loss 0.1247914438135922 accuracy 0.9651162624359131 macro_avg {'precision': 0.9655149666034468, 'recall': 0.9587958974692392, 'f1-score': 0.9619892613933996, 'support': 516} weighted_avg {'precision': 0.9651473456308333, 'recall': 0.9651162790697675, 'f1-score': 0.9649895080828875, 'support': 516}
 
time = 1.16 secondes

Val loss 0.6265026032924652 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 11/40
time = 18.09 secondes

Train loss 0.3170081827309773 accuracy 0.9224806427955627 macro_avg {'precision': 0.9187103158241939, 'recall': 0.9126668075353932, 'f1-score': 0.9155316919853327, 'support': 516} weighted_avg {'precision': 0.9221868302071807, 'recall': 0.9224806201550387, 'f1-score': 0.9221989068508614, 'support': 516}
 
time = 1.15 secondes

Val loss 1.0699334293603897 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 12/40
time = 17.48 secondes

Train loss 0.24297644617035985 accuracy 0.9399224519729614 macro_avg {'precision': 0.9462233169129721, 'recall': 0.9240365391804691, 'f1-score': 0.9334429026150998, 'support': 516} weighted_avg {'precision': 0.9412526571708609, 'recall': 0.939922480620155, 'f1-score': 0.9391578099239063, 'support': 516}
 
time = 1.21 secondes

Val loss 0.9238975346088409 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 13/40
time = 17.84 secondes

Train loss 0.1130937011700801 accuracy 0.9689922332763672 macro_avg {'precision': 0.9697699348561062, 'recall': 0.9629894510995888, 'f1-score': 0.966212676794133, 'support': 516} weighted_avg {'precision': 0.9690528470329837, 'recall': 0.9689922480620154, 'f1-score': 0.9688795627403446, 'support': 516}
 
time = 1.21 secondes

Val loss 0.9115114063024521 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 17.77 secondes

Train loss 0.1546275984834541 accuracy 0.963178277015686 macro_avg {'precision': 0.9606549364613881, 'recall': 0.9595842205354095, 'f1-score': 0.960115049612094, 'support': 516} weighted_avg {'precision': 0.9631432479331955, 'recall': 0.9631782945736435, 'f1-score': 0.9631568732802058, 'support': 516}
 
time = 1.21 secondes

Val loss 1.032797560095787 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 15/40
time = 17.76 secondes

Train loss 0.07431802467555937 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.21 secondes

Val loss 0.6879541653906927 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 16/40
time = 17.66 secondes

Train loss 0.23802901274581073 accuracy 0.9437984228134155 macro_avg {'precision': 0.9396383186705768, 'recall': 0.9386164523836614, 'f1-score': 0.9391229704605646, 'support': 516} weighted_avg {'precision': 0.9437406700159889, 'recall': 0.9437984496124031, 'f1-score': 0.9437657539539986, 'support': 516}
 
time = 1.23 secondes

Val loss 1.5027006566524506 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 17/40
time = 17.64 secondes

Train loss 0.06591099329384495 accuracy 0.9825581312179565 macro_avg {'precision': 0.9816715542521994, 'recall': 0.9805519886871576, 'f1-score': 0.9811071287636235, 'support': 516} weighted_avg {'precision': 0.982545825850402, 'recall': 0.9825581395348837, 'f1-score': 0.9825479926064133, 'support': 516}
 
time = 1.25 secondes

Val loss 1.4595406651496887 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 18/40
time = 17.53 secondes

Train loss 0.43267591706491215 accuracy 0.9147287011146545 macro_avg {'precision': 0.9182265840811215, 'recall': 0.8962014206069275, 'f1-score': 0.9054047297635117, 'support': 516} weighted_avg {'precision': 0.9154974518212192, 'recall': 0.9147286821705426, 'f1-score': 0.9135775769351066, 'support': 516}
 
time = 1.25 secondes

Val loss 1.2567818015813828 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 19/40
time = 18.14 secondes

Train loss 0.06609132798092271 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.24 secondes

Val loss 0.9925869554281235 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 20/40
time = 17.79 secondes

Train loss 0.07538396189567831 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 1.27 secondes

Val loss 1.7590546682476997 accuracy 0.75 macro_avg {'precision': 0.8095238095238095, 'recall': 0.7894736842105263, 'f1-score': 0.7490196078431373, 'support': 64} weighted_avg {'precision': 0.8452380952380952, 'recall': 0.75, 'f1-score': 0.746078431372549, 'support': 64}
 
----------
Epoch 21/40
time = 17.48 secondes

Train loss 0.3920557027308722 accuracy 0.9244186282157898 macro_avg {'precision': 0.914060036576906, 'recall': 0.9268810038522178, 'f1-score': 0.9195448712054275, 'support': 516} weighted_avg {'precision': 0.9271932210996244, 'recall': 0.9244186046511628, 'f1-score': 0.9249942424597142, 'support': 516}
 
time = 1.20 secondes

Val loss 1.2659379988908768 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 22/40
time = 17.33 secondes

Train loss 0.08668202769441644 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.22 secondes

Val loss 1.2458498924970627 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 23/40
time = 17.62 secondes

Train loss 0.07525712528766951 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 1.12 secondes

Val loss 2.0944349467754364 accuracy 0.703125 macro_avg {'precision': 0.7487135506003431, 'recall': 0.6467611336032388, 'f1-score': 0.6388476388476387, 'support': 64} weighted_avg {'precision': 0.7356882504288165, 'recall': 0.703125, 'f1-score': 0.6674153549153548, 'support': 64}
 
----------
Epoch 24/40
time = 17.62 secondes

Train loss 0.024977007481290704 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4501541554927826 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 25/40
time = 17.64 secondes

Train loss 0.03201063972664997 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.21 secondes

Val loss 1.2842075526714325 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 26/40
time = 17.49 secondes

Train loss 0.15983196521957518 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.22 secondes

Val loss 1.9730994403362274 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 27/40
time = 18.40 secondes

Train loss 0.022202298072939317 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.24 secondes

Val loss 2.4159396290779114 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 28/40
time = 18.86 secondes

Train loss 0.2744762653795381 accuracy 0.9593023061752319 macro_avg {'precision': 0.9666609996599796, 'recall': 0.9461583472847553, 'f1-score': 0.9550326797385621, 'support': 516} weighted_avg {'precision': 0.9607238876193037, 'recall': 0.9593023255813954, 'f1-score': 0.9588458225667528, 'support': 516}
 
time = 1.02 secondes

Val loss 1.2459171265363693 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 29/40
time = 17.25 secondes

Train loss 0.11379873389325273 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.22 secondes

Val loss 1.5327107310295105 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 30/40
time = 17.30 secondes

Train loss 0.011912659291269709 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.25 secondes

Val loss 0.9744991734623909 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 31/40
time = 17.34 secondes

Train loss 0.017284214241292582 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.26 secondes

Val loss 1.8163243532180786 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 32/40
time = 17.49 secondes

Train loss 0.10978848398813032 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.23 secondes

Val loss 1.6438608169555664 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 33/40
time = 17.23 secondes

Train loss 0.038982735758922485 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.21 secondes

Val loss 2.1417019367218018 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 34/40
time = 18.28 secondes

Train loss 0.006104760153958165 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 1.3573497533798218 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 35/40
time = 17.39 secondes

Train loss 0.00014798971449525914 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.26 secondes

Val loss 2.0698814690113068 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 36/40
time = 17.48 secondes

Train loss 0.08951712580936587 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.16 secondes

Val loss 2.7268578708171844 accuracy 0.703125 macro_avg {'precision': 0.7487135506003431, 'recall': 0.6467611336032388, 'f1-score': 0.6388476388476387, 'support': 64} weighted_avg {'precision': 0.7356882504288165, 'recall': 0.703125, 'f1-score': 0.6674153549153548, 'support': 64}
 
----------
Epoch 37/40
time = 17.92 secondes

Train loss 0.03212647247820507 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.21 secondes

Val loss 1.7387153208255768 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 38/40
time = 17.22 secondes

Train loss 0.0005161041392994141 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.00 secondes

Val loss 1.300906962598674 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 39/40
time = 18.00 secondes

Train loss 0.002476379965435516 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4754628864175174 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 40/40
time = 18.00 secondes

Train loss 0.00036304062263242844 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.3121371113229543 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 15 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}

average train time 17.807117170095445

average val time 1.2071483910083771
 
time = 1.41 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_head_tail_5
----------
Epoch 1/40
time = 20.98 secondes

Train loss 0.6661233649109349 accuracy 0.606589138507843 macro_avg {'precision': 0.44770563827190624, 'recall': 0.48607025015035027, 'f1-score': 0.41556985119761647, 'support': 516} weighted_avg {'precision': 0.4980660362185983, 'recall': 0.6065891472868217, 'f1-score': 0.5075181225354711, 'support': 516}
 
time = 1.40 secondes

Val loss 0.6265179365873337 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.56 secondes

Train loss 0.47683841983477276 accuracy 0.786821722984314 macro_avg {'precision': 0.8062100617053514, 'recall': 0.7266550720868619, 'f1-score': 0.7415300546448088, 'support': 516} weighted_avg {'precision': 0.7967164527687401, 'recall': 0.7868217054263565, 'f1-score': 0.7713051213623079, 'support': 516}
 
time = 1.22 secondes

Val loss 0.49453578144311905 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 3/40
time = 17.93 secondes

Train loss 0.3394917209040035 accuracy 0.8837209343910217 macro_avg {'precision': 0.888060884731251, 'recall': 0.8580368317539782, 'f1-score': 0.8695630192622053, 'support': 516} weighted_avg {'precision': 0.8849483921109764, 'recall': 0.8837209302325582, 'f1-score': 0.8813890390139117, 'support': 516}
 
time = 1.23 secondes

Val loss 0.7257399335503578 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 4/40
time = 18.07 secondes

Train loss 0.4811041924086484 accuracy 0.817829430103302 macro_avg {'precision': 0.8024482904178978, 'recall': 0.8144433788989484, 'f1-score': 0.8070429482997311, 'support': 516} weighted_avg {'precision': 0.8238612875394169, 'recall': 0.8178294573643411, 'f1-score': 0.8195977375388673, 'support': 516}
 
time = 1.21 secondes

Val loss 0.42842499911785126 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 5/40
time = 17.17 secondes

Train loss 0.3172789304093881 accuracy 0.8856589198112488 macro_avg {'precision': 0.8882088302992257, 'recall': 0.8618646684979601, 'f1-score': 0.8722809784911503, 'support': 516} weighted_avg {'precision': 0.8863229552418446, 'recall': 0.8856589147286822, 'f1-score': 0.8836562296631834, 'support': 516}
 
time = 1.22 secondes

Val loss 0.37994974479079247 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 6/40
time = 17.46 secondes

Train loss 0.21067240060956188 accuracy 0.9282945990562439 macro_avg {'precision': 0.9236838658983761, 'recall': 0.9206881979097248, 'f1-score': 0.9221468737639206, 'support': 516} weighted_avg {'precision': 0.9281076530591528, 'recall': 0.9282945736434108, 'f1-score': 0.9281673798528007, 'support': 516}
 
time = 1.23 secondes

Val loss 0.4881817065179348 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 7/40
time = 17.81 secondes

Train loss 0.1966841709941174 accuracy 0.9515503644943237 macro_avg {'precision': 0.9480449657869012, 'recall': 0.9470035596443607, 'f1-score': 0.9475198021211764, 'support': 516} weighted_avg {'precision': 0.9515017011828714, 'recall': 0.9515503875968992, 'f1-score': 0.9515222016844816, 'support': 516}
 
time = 1.26 secondes

Val loss 0.6617848686873913 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 17.34 secondes

Train loss 0.19576111105694013 accuracy 0.9457364082336426 macro_avg {'precision': 0.9552965552965553, 'recall': 0.9285958096971865, 'f1-score': 0.9396390374331551, 'support': 516} weighted_avg {'precision': 0.9479979681530069, 'recall': 0.9457364341085271, 'f1-score': 0.9449184906520748, 'support': 516}
 
time = 1.26 secondes

Val loss 0.6016623340547085 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 9/40
time = 18.34 secondes

Train loss 0.27867634650884254 accuracy 0.9457364082336426 macro_avg {'precision': 0.9396536447845348, 'recall': 0.9435983290801814, 'f1-score': 0.9415562351342167, 'support': 516} weighted_avg {'precision': 0.9460995857099596, 'recall': 0.9457364341085271, 'f1-score': 0.9458575992961883, 'support': 516}
 
time = 1.26 secondes

Val loss 1.3798088431358337 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 10/40
time = 17.62 secondes

Train loss 0.26985992125771713 accuracy 0.9360464811325073 macro_avg {'precision': 0.9321306966998428, 'recall': 0.929075305170424, 'f1-score': 0.9305634279516048, 'support': 516} weighted_avg {'precision': 0.9358877623740666, 'recall': 0.936046511627907, 'f1-score': 0.9359330685173628, 'support': 516}
 
time = 1.23 secondes

Val loss 0.918486587703228 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 11/40
time = 18.23 secondes

Train loss 0.3111891728882311 accuracy 0.9205426573753357 macro_avg {'precision': 0.9123263888888888, 'recall': 0.9169172504591778, 'f1-score': 0.9145167220904531, 'support': 516} weighted_avg {'precision': 0.9211650785960379, 'recall': 0.9205426356589147, 'f1-score': 0.9207625595117782, 'support': 516}
 
time = 1.17 secondes

Val loss 0.6044767908751965 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 12/40
time = 18.40 secondes

Train loss 0.15509706262541426 accuracy 0.9593023061752319 macro_avg {'precision': 0.9666609996599796, 'recall': 0.9461583472847553, 'f1-score': 0.9550326797385621, 'support': 516} weighted_avg {'precision': 0.9607238876193037, 'recall': 0.9593023255813954, 'f1-score': 0.9588458225667528, 'support': 516}
 
time = 1.26 secondes

Val loss 0.664915319532156 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 13/40
time = 17.48 secondes

Train loss 0.21818552881295822 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 1.22 secondes

Val loss 0.7363989874720573 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 14/40
time = 17.59 secondes

Train loss 0.22827258164937975 accuracy 0.9360464811325073 macro_avg {'precision': 0.9312316715542521, 'recall': 0.9302293451229622, 'f1-score': 0.9307261387999528, 'support': 516} weighted_avg {'precision': 0.9359796388491063, 'recall': 0.936046511627907, 'f1-score': 0.9360093062235157, 'support': 516}
 
time = 1.20 secondes

Val loss 1.171860821545124 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 15/40
time = 17.55 secondes

Train loss 0.1579666162883355 accuracy 0.9651162624359131 macro_avg {'precision': 0.9667456857251795, 'recall': 0.9576418575167012, 'f1-score': 0.9618963225520603, 'support': 516} weighted_avg {'precision': 0.9652812822753787, 'recall': 0.9651162790697675, 'f1-score': 0.9649445480554899, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7291651666164398 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 16/40
time = 17.44 secondes

Train loss 0.07521762814069392 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.17 secondes

Val loss 0.9426508522301447 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 17/40
time = 17.39 secondes

Train loss 0.15496099789302345 accuracy 0.9670542478561401 macro_avg {'precision': 0.9738372093023255, 'recall': 0.9556994944979926, 'f1-score': 0.9636931049183177, 'support': 516} weighted_avg {'precision': 0.9682373354966649, 'recall': 0.9670542635658915, 'f1-score': 0.9667331337587985, 'support': 516}
 
time = 1.22 secondes

Val loss 0.7525347843766212 accuracy 0.859375 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}
 
----------
Epoch 18/40
time = 17.40 secondes

Train loss 0.12066165172092785 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.17 secondes

Val loss 0.7644600381609052 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 19/40
time = 17.86 secondes

Train loss 0.14242866007032606 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 1.22 secondes

Val loss 1.194577932357788 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 20/40
time = 17.83 secondes

Train loss 0.09583858137590472 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.25 secondes

Val loss 0.9665282964706421 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 21/40
time = 17.46 secondes

Train loss 0.1548591956679681 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 1.24 secondes

Val loss 1.3758466094732285 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 22/40
time = 17.75 secondes

Train loss 0.40670998959279986 accuracy 0.9282945990562439 macro_avg {'precision': 0.9181276407895567, 'recall': 0.9310745574825675, 'f1-score': 0.9236707752461748, 'support': 516} weighted_avg {'precision': 0.9310178592292646, 'recall': 0.9282945736434108, 'f1-score': 0.9288406915643441, 'support': 516}
 
time = 1.25 secondes

Val loss 1.069616824388504 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 23/40
time = 16.98 secondes

Train loss 0.0660722454353659 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.11 secondes

Val loss 0.567152151488699 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 24/40
time = 16.50 secondes

Train loss 0.013054076903217443 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.20 secondes

Val loss 0.915854761202354 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 25/40
time = 16.94 secondes

Train loss 0.09404046933350126 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5995277467591222 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 26/40
time = 16.65 secondes

Train loss 0.03400332905584946 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1173034235835075 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 27/40
time = 16.17 secondes

Train loss 0.10936328725074418 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 0.99 secondes

Val loss 1.117713525891304 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 28/40
time = 14.82 secondes

Train loss 0.13602476901194843 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.03 secondes

Val loss 1.134314052760601 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 29/40
time = 14.55 secondes

Train loss 0.02064652899086165 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.04 secondes

Val loss 0.6763639971613884 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 30/40
time = 16.20 secondes

Train loss 0.014953564375349688 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.20 secondes

Val loss 0.8688077814877033 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 31/40
time = 17.60 secondes

Train loss 0.031435688595097 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.22 secondes

Val loss 1.1274272948503494 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 32/40
time = 17.35 secondes

Train loss 0.07594833335183053 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.22 secondes

Val loss 1.1744657456874847 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 33/40
time = 17.39 secondes

Train loss 0.02990649437450691 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.25 secondes

Val loss 1.4045640230178833 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 34/40
time = 17.56 secondes

Train loss 0.03504056669066124 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.21 secondes

Val loss 1.5479869991540909 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 35/40
time = 18.03 secondes

Train loss 0.005020391420905732 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.23 secondes

Val loss 1.1337285488843918 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 36/40
time = 17.58 secondes

Train loss 0.023963465394141775 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.18 secondes

Val loss 1.3285614252090454 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 37/40
time = 17.42 secondes

Train loss 0.00357368570147435 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 0.7725195431848988 accuracy 0.890625 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}
 
----------
Epoch 38/40
time = 17.38 secondes

Train loss 0.008087146220725228 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.26 secondes

Val loss 1.0918526090681553 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 39/40
time = 17.30 secondes

Train loss 0.020241431359229893 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.25 secondes

Val loss 0.8257203889879747 accuracy 0.90625 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}
 
----------
Epoch 40/40
time = 17.21 secondes

Train loss 0.00020367855551850164 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.25 secondes

Val loss 0.8326466569924378 accuracy 0.890625 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 23 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}

average train time 17.406286656856537

average val time 1.2081338047981263
 
time = 1.45 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_BERT_tail_5
----------
Epoch 1/40
time = 20.34 secondes

Train loss 0.6397943605076183 accuracy 0.6356589198112488 macro_avg {'precision': 0.31844660194174756, 'recall': 0.49848024316109424, 'f1-score': 0.3886255924170616, 'support': 516} weighted_avg {'precision': 0.4060811319334688, 'recall': 0.6356589147286822, 'f1-score': 0.4955729453690437, 'support': 516}
 
time = 1.35 secondes

Val loss 0.6453469842672348 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 17.14 secondes

Train loss 0.5003739739909316 accuracy 0.7170542478561401 macro_avg {'precision': 0.7636917901818564, 'recall': 0.6223201079271167, 'f1-score': 0.6146496163682864, 'support': 516} weighted_avg {'precision': 0.746710947157582, 'recall': 0.7170542635658915, 'f1-score': 0.6693167588572335, 'support': 516}
 
time = 1.05 secondes

Val loss 0.45866313576698303 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 3/40
time = 17.74 secondes

Train loss 0.3748708719556982 accuracy 0.854651153087616 macro_avg {'precision': 0.8429618768328446, 'recall': 0.8421647188856201, 'f1-score': 0.8425594063635291, 'support': 516} weighted_avg {'precision': 0.8544888115968385, 'recall': 0.8546511627906976, 'f1-score': 0.8545666050534447, 'support': 516}
 
time = 1.21 secondes

Val loss 0.35211852192878723 accuracy 0.875 macro_avg {'precision': 0.8690476190476191, 'recall': 0.8765182186234818, 'f1-score': 0.8718718718718719, 'support': 64} weighted_avg {'precision': 0.8779761904761905, 'recall': 0.875, 'f1-score': 0.8756256256256256, 'support': 64}
 
----------
Epoch 4/40
time = 17.27 secondes

Train loss 0.2844462538081588 accuracy 0.9031007885932922 macro_avg {'precision': 0.895860210663836, 'recall': 0.8940071192887213, 'f1-score': 0.8949169110459433, 'support': 516} weighted_avg {'precision': 0.9029024035628407, 'recall': 0.9031007751937985, 'f1-score': 0.9029871104139672, 'support': 516}
 
time = 1.24 secondes

Val loss 0.41746921092271805 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 5/40
time = 18.23 secondes

Train loss 0.2957005716408744 accuracy 0.8972868323326111 macro_avg {'precision': 0.8891984359726295, 'recall': 0.8882938088194658, 'f1-score': 0.8887419804968939, 'support': 516} weighted_avg {'precision': 0.897174483014693, 'recall': 0.8972868217054264, 'f1-score': 0.8972270675711009, 'support': 516}
 
time = 1.22 secondes

Val loss 0.4939323365688324 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 6/40
time = 18.10 secondes

Train loss 0.17604223192867005 accuracy 0.9476743936538696 macro_avg {'precision': 0.943841642228739, 'recall': 0.942810006014011, 'f1-score': 0.9433213862908705, 'support': 516} weighted_avg {'precision': 0.94762118559943, 'recall': 0.9476744186046512, 'f1-score': 0.9476439778192401, 'support': 516}
 
time = 1.22 secondes

Val loss 0.9973655343055725 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 7/40
time = 17.30 secondes

Train loss 0.2513428579620791 accuracy 0.9321705102920532 macro_avg {'precision': 0.92305126739089, 'recall': 0.932960031207841, 'f1-score': 0.9274975410987776, 'support': 516} weighted_avg {'precision': 0.9338424097638666, 'recall': 0.9321705426356589, 'f1-score': 0.9325629320776871, 'support': 516}
 
time = 1.19 secondes

Val loss 0.621039018034935 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 8/40
time = 17.64 secondes

Train loss 0.25271023948197113 accuracy 0.9379844665527344 macro_avg {'precision': 0.9368068564229233, 'recall': 0.9282869821042536, 'f1-score': 0.9322601289814404, 'support': 516} weighted_avg {'precision': 0.9378652414707542, 'recall': 0.937984496124031, 'f1-score': 0.9376791965430928, 'support': 516}
 
time = 1.26 secondes

Val loss 0.4347002739086747 accuracy 0.90625 macro_avg {'precision': 0.9177489177489178, 'recall': 0.8906882591093117, 'f1-score': 0.9, 'support': 64} weighted_avg {'precision': 0.9108495670995671, 'recall': 0.90625, 'f1-score': 0.9046875, 'support': 64}
 
----------
Epoch 9/40
time = 17.76 secondes

Train loss 0.30143885595272435 accuracy 0.9186046719551086 macro_avg {'precision': 0.9099600571071079, 'recall': 0.915397493620272, 'f1-score': 0.912528253148208, 'support': 516} weighted_avg {'precision': 0.9194026136910076, 'recall': 0.9186046511627907, 'f1-score': 0.9188727275457869, 'support': 516}
 
time = 1.24 secondes

Val loss 0.41438962053507566 accuracy 0.921875 macro_avg {'precision': 0.9294803817603394, 'recall': 0.909919028340081, 'f1-score': 0.9173340222164816, 'support': 64} weighted_avg {'precision': 0.9244101272534465, 'recall': 0.921875, 'f1-score': 0.9209668044432964, 'support': 64}
 
----------
Epoch 10/40
time = 18.21 secondes

Train loss 0.11462607463313775 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.26 secondes

Val loss 0.5732801388949156 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 11/40
time = 17.69 secondes

Train loss 0.28365611713238514 accuracy 0.9321705102920532 macro_avg {'precision': 0.9209475769016526, 'recall': 0.9421923508281456, 'f1-score': 0.9286253463014413, 'support': 516} weighted_avg {'precision': 0.9390573625178902, 'recall': 0.9321705426356589, 'f1-score': 0.9330028930793448, 'support': 516}
 
time = 1.24 secondes

Val loss 0.7167027965188026 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 12/40
time = 17.62 secondes

Train loss 0.26544462612152775 accuracy 0.9399224519729614 macro_avg {'precision': 0.9307594936708861, 'recall': 0.9425011784210784, 'f1-score': 0.9359173126614988, 'support': 516} weighted_avg {'precision': 0.9419762535570602, 'recall': 0.939922480620155, 'f1-score': 0.940326102197384, 'support': 516}
 
time = 1.22 secondes

Val loss 0.6342039033770561 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 13/40
time = 17.66 secondes

Train loss 0.05442044126914081 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.22 secondes

Val loss 1.006429597735405 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 14/40
time = 17.30 secondes

Train loss 0.21605103531725367 accuracy 0.9593023061752319 macro_avg {'precision': 0.9585609001776667, 'recall': 0.9530825869999837, 'f1-score': 0.9557076113747562, 'support': 516} weighted_avg {'precision': 0.959253547594308, 'recall': 0.9593023255813954, 'f1-score': 0.9591800563906934, 'support': 516}
 
time = 1.27 secondes

Val loss 0.7306887432932854 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 15/40
time = 17.60 secondes

Train loss 0.16503870930649678 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.21 secondes

Val loss 0.6916542707476765 accuracy 0.890625 macro_avg {'precision': 0.8955461293743372, 'recall': 0.8775303643724697, 'f1-score': 0.8842676311030742, 'support': 64} weighted_avg {'precision': 0.8922653764581123, 'recall': 0.890625, 'f1-score': 0.8893535262206149, 'support': 64}
 
----------
Epoch 16/40
time = 17.68 secondes

Train loss 0.12092675232843524 accuracy 0.9728682041168213 macro_avg {'precision': 0.9766511674416278, 'recall': 0.9648749248248623, 'f1-score': 0.9702901888530631, 'support': 516} weighted_avg {'precision': 0.9733352479662837, 'recall': 0.9728682170542635, 'f1-score': 0.9726986099357636, 'support': 516}
 
time = 1.20 secondes

Val loss 0.7865408807992935 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 17/40
time = 17.59 secondes

Train loss 0.07244862693319605 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 1.21 secondes

Val loss 0.8827765062451363 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 18/40
time = 17.01 secondes

Train loss 0.09304871607861115 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 1.26 secondes

Val loss 1.2041582241654396 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 19/40
time = 17.38 secondes

Train loss 0.45171981964218005 accuracy 0.9108527302742004 macro_avg {'precision': 0.9112128146453089, 'recall': 0.894315946881654, 'f1-score': 0.9016295608640154, 'support': 516} weighted_avg {'precision': 0.9109189387354466, 'recall': 0.9108527131782945, 'f1-score': 0.9099187230705195, 'support': 516}
 
time = 1.27 secondes

Val loss 1.274016112089157 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 20/40
time = 17.39 secondes

Train loss 0.041777757117277804 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 1.03 secondes

Val loss 1.00965116918087 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 21/40
time = 18.89 secondes

Train loss 0.24989009691776257 accuracy 0.9573643207550049 macro_avg {'precision': 0.9622002393029879, 'recall': 0.9457926303983876, 'f1-score': 0.9530753968253968, 'support': 516} weighted_avg {'precision': 0.9581608419681893, 'recall': 0.9573643410852714, 'f1-score': 0.9569794358311798, 'support': 516}
 
time = 1.19 secondes

Val loss 1.9198892712593079 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 22/40
time = 18.26 secondes

Train loss 0.0918027577951734 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.22 secondes

Val loss 0.857952579157427 accuracy 0.890625 macro_avg {'precision': 0.906423034330011, 'recall': 0.8714574898785425, 'f1-score': 0.8823220383504071, 'support': 64} weighted_avg {'precision': 0.8978059246954595, 'recall': 0.890625, 'f1-score': 0.8881829524560021, 'support': 64}
 
----------
Epoch 23/40
time = 17.97 secondes

Train loss 0.03941843954045467 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.22 secondes

Val loss 1.0917232260107994 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 24/40
time = 17.13 secondes

Train loss 0.09080374131779977 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.21 secondes

Val loss 1.236706092953682 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 25/40
time = 17.56 secondes

Train loss 0.010824954398258618 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.23 secondes

Val loss 1.8965464234352112 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 26/40
time = 18.32 secondes

Train loss 0.1016674156575887 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.25 secondes

Val loss 1.4440962821245193 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 27/40
time = 17.78 secondes

Train loss 0.19736256605017732 accuracy 0.963178277015686 macro_avg {'precision': 0.9538834951456311, 'recall': 0.9711246200607903, 'f1-score': 0.960959992354466, 'support': 516} weighted_avg {'precision': 0.9665744712877248, 'recall': 0.9631782945736435, 'f1-score': 0.9635209591440854, 'support': 516}
 
time = 1.22 secondes

Val loss 1.3530784994363785 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 28/40
time = 17.34 secondes

Train loss 0.22387175287726815 accuracy 0.9554263353347778 macro_avg {'precision': 0.9673295454545454, 'recall': 0.9385026737967914, 'f1-score': 0.95034953625262, 'support': 516} weighted_avg {'precision': 0.9583388389711065, 'recall': 0.9554263565891473, 'f1-score': 0.9547186786028435, 'support': 516}
 
time = 1.23 secondes

Val loss 1.1136690974235535 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 29/40
time = 17.41 secondes

Train loss 0.0023138285345560166 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.21 secondes

Val loss 0.9816391170024872 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 30/40
time = 17.22 secondes

Train loss 0.1892826118401541 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.24 secondes

Val loss 1.006489422172308 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 31/40
time = 17.81 secondes

Train loss 0.036652879147864456 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.23 secondes

Val loss 1.626455396413803 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 32/40
time = 17.95 secondes

Train loss 0.07172201403326736 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.19 secondes

Val loss 1.1502835750579834 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 33/40
time = 17.57 secondes

Train loss 0.002383291208058257 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.26 secondes

Val loss 1.2167542949318886 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 34/40
time = 17.45 secondes

Train loss 0.01490095275860795 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.22 secondes

Val loss 1.0323389917612076 accuracy 0.890625 macro_avg {'precision': 0.9222222222222223, 'recall': 0.8653846153846154, 'f1-score': 0.880053547523427, 'support': 64} weighted_avg {'precision': 0.9076388888888889, 'recall': 0.890625, 'f1-score': 0.8867302543507363, 'support': 64}
 
----------
Epoch 35/40
time = 17.91 secondes

Train loss 0.0018748986498615 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.25 secondes

Val loss 1.526188462972641 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 36/40
time = 19.00 secondes

Train loss 0.012337036978516897 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.25 secondes

Val loss 1.0926959589123726 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 37/40
time = 17.50 secondes

Train loss 0.03584025102882703 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.25 secondes

Val loss 1.5464341342449188 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 38/40
time = 17.21 secondes

Train loss 0.024721543527310572 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.25 secondes

Val loss 1.2221839129924774 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 39/40
time = 17.15 secondes

Train loss 0.00016095133888125983 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.22 secondes

Val loss 1.32506462931633 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 40/40
time = 17.24 secondes

Train loss 0.00020041520165801612 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.30 secondes

Val loss 1.293651893734932 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 9 macro_avg {'precision': 0.9294803817603394, 'recall': 0.909919028340081, 'f1-score': 0.9173340222164816, 'support': 64} weighted_avg {'precision': 0.9244101272534465, 'recall': 0.921875, 'f1-score': 0.9209668044432964, 'support': 64}

average train time 17.733747231960297

average val time 1.2253009021282195
 
time = 1.41 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9425, 'recall': 0.9312865497076024, 'f1-score': 0.9358974358974359, 'support': 65} weighted_avg {'precision': 0.9395384615384614, 'recall': 0.9384615384615385, 'f1-score': 0.9380670611439843, 'support': 65}

----------
