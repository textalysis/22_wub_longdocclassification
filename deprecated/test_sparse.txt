[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Longformer_1024_256_1
----------
Epoch 1/40
time = 35.49 secondes

Train loss 0.6710504654682043 accuracy 0.6240310072898865 macro_avg {'precision': 0.5382669196710943, 'recall': 0.5147505810834972, 'f1-score': 0.47027072793853053, 'support': 516} weighted_avg {'precision': 0.5676835875635575, 'recall': 0.624031007751938, 'f1-score': 0.5488101514403428, 'support': 516}
 
time = 1.08 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.6524198055267334 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 29.49 secondes

Train loss 0.483280953132745 accuracy 0.7771317958831787 macro_avg {'precision': 0.7678822658274713, 'recall': 0.7352128472278661, 'f1-score': 0.7450669553673845, 'support': 516} weighted_avg {'precision': 0.7737457990006573, 'recall': 0.7771317829457365, 'f1-score': 0.7699478598270895, 'support': 516}
 
time = 0.98 secondes

Val loss 0.456590011715889 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 3/40
time = 29.08 secondes

Train loss 0.3750968897207217 accuracy 0.8585271239280701 macro_avg {'precision': 0.8526181570894253, 'recall': 0.837125952895665, 'f1-score': 0.8436850295673826, 'support': 516} weighted_avg {'precision': 0.8573856253080613, 'recall': 0.8585271317829457, 'f1-score': 0.8569402403510931, 'support': 516}
 
time = 1.04 secondes

Val loss 0.5292843133211136 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 4/40
time = 28.56 secondes

Train loss 0.35542329039537546 accuracy 0.8720930218696594 macro_avg {'precision': 0.8674802949402491, 'recall': 0.8523804105781578, 'f1-score': 0.8588598047179351, 'support': 516} weighted_avg {'precision': 0.8712447054046756, 'recall': 0.872093023255814, 'f1-score': 0.8707529504924845, 'support': 516}
 
time = 0.97 secondes

Val loss 0.5364467836916447 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 5/40
time = 28.67 secondes

Train loss 0.36772589583062765 accuracy 0.854651153087616 macro_avg {'precision': 0.8421536971262512, 'recall': 0.8444727987906961, 'f1-score': 0.8432785955818332, 'support': 516} weighted_avg {'precision': 0.8552025215700115, 'recall': 0.8546511627906976, 'f1-score': 0.8548966138815365, 'support': 516}
 
time = 0.89 secondes

Val loss 0.4108906537294388 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 6/40
time = 27.58 secondes

Train loss 0.2155428926432223 accuracy 0.9224806427955627 macro_avg {'precision': 0.9169265942679841, 'recall': 0.9149748874404694, 'f1-score': 0.9159335288367546, 'support': 516} weighted_avg {'precision': 0.9223284550622427, 'recall': 0.9224806201550387, 'f1-score': 0.9223896883311736, 'support': 516}
 
time = 1.00 secondes

Val loss 0.6259705424308777 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 7/40
time = 31.29 secondes

Train loss 0.13717314676438092 accuracy 0.9593023061752319 macro_avg {'precision': 0.9651162790697674, 'recall': 0.9473123872372933, 'f1-score': 0.9551503060755688, 'support': 516} weighted_avg {'precision': 0.9603163872363439, 'recall': 0.9593023255813954, 'f1-score': 0.9589056358196921, 'support': 516}
 
time = 1.09 secondes

Val loss 0.7849201932549477 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 8/40
time = 28.58 secondes

Train loss 0.173196487082874 accuracy 0.9515503644943237 macro_avg {'precision': 0.9471328489880644, 'recall': 0.9481575995968987, 'f1-score': 0.947640791476408, 'support': 516} weighted_avg {'precision': 0.9516134952913111, 'recall': 0.9515503875968992, 'f1-score': 0.9515781152289595, 'support': 516}
 
time = 0.90 secondes

Val loss 0.940225288271904 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 9/40
time = 28.17 secondes

Train loss 0.25201711445256614 accuracy 0.9321705102920532 macro_avg {'precision': 0.9221952450022073, 'recall': 0.9352681111129171, 'f1-score': 0.9277966792869222, 'support': 516} weighted_avg {'precision': 0.934842497358905, 'recall': 0.9321705426356589, 'f1-score': 0.9326871406689743, 'support': 516}
 
time = 1.00 secondes

Val loss 1.6253045201301575 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 27.84 secondes

Train loss 0.35771884351869987 accuracy 0.9069767594337463 macro_avg {'precision': 0.9035548222588871, 'recall': 0.8935845131089186, 'f1-score': 0.8981377903533592, 'support': 516} weighted_avg {'precision': 0.9065542846888663, 'recall': 0.9069767441860465, 'f1-score': 0.906395234065475, 'support': 516}
 
time = 1.03 secondes

Val loss 0.9628527015447617 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 11/40
time = 27.76 secondes

Train loss 0.16455536518619876 accuracy 0.9651162624359131 macro_avg {'precision': 0.9570244018005212, 'recall': 0.9703362969946199, 'f1-score': 0.9628289684318372, 'support': 516} weighted_avg {'precision': 0.9671037576973015, 'recall': 0.9651162790697675, 'f1-score': 0.965366453670791, 'support': 516}
 
time = 1.03 secondes

Val loss 1.0642718952149153 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 12/40
time = 28.67 secondes

Train loss 0.1537792187485717 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.08 secondes

Val loss 2.0127590000629425 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 13/40
time = 27.56 secondes

Train loss 0.1276878675985658 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 0.92 secondes

Val loss 1.3209304362535477 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 28.42 secondes

Train loss 0.12965390706526567 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.06 secondes

Val loss 1.5249550342559814 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 15/40
time = 28.11 secondes

Train loss 0.07258619727993694 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.02 secondes

Val loss 1.0193206130716135 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 16/40
time = 30.07 secondes

Train loss 0.2524781176197752 accuracy 0.9457364082336426 macro_avg {'precision': 0.9453608076521394, 'recall': 0.936674089364953, 'f1-score': 0.9407276128587603, 'support': 516} weighted_avg {'precision': 0.9456983959863613, 'recall': 0.9457364341085271, 'f1-score': 0.9454692969752061, 'support': 516}
 
time = 0.94 secondes

Val loss 1.0527266040444374 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 17/40
time = 28.86 secondes

Train loss 0.7805063992087856 accuracy 0.8856589198112488 macro_avg {'precision': 0.8766646489104116, 'recall': 0.9045641467418689, 'f1-score': 0.881819981599879, 'support': 516} weighted_avg {'precision': 0.9056915976875575, 'recall': 0.8856589147286822, 'f1-score': 0.8876815784202022, 'support': 516}
 
time = 1.02 secondes

Val loss 1.5104913115501404 accuracy 0.640625 macro_avg {'precision': 0.7653061224489797, 'recall': 0.6973684210526316, 'f1-score': 0.6296855345911949, 'support': 64} weighted_avg {'precision': 0.809311224489796, 'recall': 0.640625, 'f1-score': 0.617751572327044, 'support': 64}
 
----------
Epoch 18/40
time = 27.85 secondes

Train loss 0.3241571173262359 accuracy 0.9244186282157898 macro_avg {'precision': 0.9131142506142507, 'recall': 0.9372673634250606, 'f1-score': 0.9208884520884522, 'support': 516} weighted_avg {'precision': 0.9342355436832182, 'recall': 0.9244186046511628, 'f1-score': 0.9254873664362037, 'support': 516}
 
time = 1.10 secondes

Val loss 1.2198699451982975 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 19/40
time = 28.22 secondes

Train loss 0.09959936832301812 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 0.95 secondes

Val loss 1.4501279443502426 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 20/40
time = 27.78 secondes

Train loss 0.07464519945135566 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 0.88 secondes

Val loss 1.127007813192904 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 21/40
time = 28.33 secondes

Train loss 0.11055423935172395 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 0.93 secondes

Val loss 1.7482298910617828 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 22/40
time = 28.90 secondes

Train loss 0.12829028625988445 accuracy 0.963178277015686 macro_avg {'precision': 0.9628051589129434, 'recall': 0.9572761406303334, 'f1-score': 0.95992593410097, 'support': 516} weighted_avg {'precision': 0.9631537461749132, 'recall': 0.9631782945736435, 'f1-score': 0.9630676700677702, 'support': 516}
 
time = 0.96 secondes

Val loss 1.6495601683855057 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 23/40
time = 28.00 secondes

Train loss 0.4388933092861517 accuracy 0.9282945990562439 macro_avg {'precision': 0.9289675337769712, 'recall': 0.9149179981470345, 'f1-score': 0.9211826727380064, 'support': 516} weighted_avg {'precision': 0.9283987222355093, 'recall': 0.9282945736434108, 'f1-score': 0.9276980916319898, 'support': 516}
 
time = 0.90 secondes

Val loss 2.5217131078243256 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 24/40
time = 28.24 secondes

Train loss 0.039083808210941214 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.91 secondes

Val loss 1.2653399967603036 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 25/40
time = 27.98 secondes

Train loss 0.06607374908961708 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.98 secondes

Val loss 1.9400316774845123 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 26/40
time = 30.81 secondes

Train loss 0.0731854799358354 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.02 secondes

Val loss 1.80514957010746 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 27/40
time = 28.22 secondes

Train loss 0.15257548648073818 accuracy 0.9709302186965942 macro_avg {'precision': 0.9680526725480021, 'recall': 0.9691253677486469, 'f1-score': 0.9685844748858448, 'support': 516} weighted_avg {'precision': 0.9709713405582844, 'recall': 0.9709302325581395, 'f1-score': 0.9709468691373756, 'support': 516}
 
time = 0.95 secondes

Val loss 1.5772926211357117 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 28/40
time = 28.26 secondes

Train loss 0.10160174138119063 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 0.98 secondes

Val loss 1.3274145527393557 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 29/40
time = 28.14 secondes

Train loss 0.1106397328357244 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 1.01 secondes

Val loss 1.5627728700637817 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 30/40
time = 28.03 secondes

Train loss 0.10130258721377079 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 0.96 secondes

Val loss 1.3942400515079498 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 31/40
time = 28.31 secondes

Train loss 0.0350851483883823 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 0.97 secondes

Val loss 1.5330155491828918 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 32/40
time = 28.18 secondes

Train loss 0.0008151724285915296 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.97 secondes

Val loss 2.012040376663208 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 33/40
time = 28.20 secondes

Train loss 0.13931620158010363 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 0.99 secondes

Val loss 1.6388399004936218 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 34/40
time = 28.77 secondes

Train loss 0.017722889358220997 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.90 secondes

Val loss 1.9709820300340652 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 35/40
time = 27.68 secondes

Train loss 0.034705765135048285 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.08 secondes

Val loss 2.169890820980072 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 36/40
time = 28.05 secondes

Train loss 0.01600908455745384 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.98 secondes

Val loss 1.8208508491516113 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 37/40
time = 31.23 secondes

Train loss 7.561684579934192e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.08 secondes

Val loss 1.716577485203743 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 38/40
time = 27.67 secondes

Train loss 0.027726684652544933 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.88 secondes

Val loss 1.8943638652563095 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 39/40
time = 28.32 secondes

Train loss 8.345514211352125e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.93 secondes

Val loss 1.4009183458983898 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 40/40
time = 28.50 secondes

Train loss 6.839786488633376e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.12 secondes

Val loss 1.3754421786870807 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 15 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 28.69711412191391

average val time 0.9868344247341156
 
time = 1.01 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_1
----------
Epoch 1/40
time = 37.34 secondes

Train loss 0.653100255763892 accuracy 0.6259689927101135 macro_avg {'precision': 0.4935483870967742, 'recall': 0.4989597386343319, 'f1-score': 0.416846728151076, 'support': 516} weighted_avg {'precision': 0.5330520130032508, 'recall': 0.625968992248062, 'f1-score': 0.5129482216843188, 'support': 516}
 
time = 1.25 secondes

Val loss 0.5812919437885284 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 2/40
time = 35.83 secondes

Train loss 0.40377068429282215 accuracy 0.8410852551460266 macro_avg {'precision': 0.8332793342768958, 'recall': 0.8176779415828227, 'f1-score': 0.8241805731001928, 'support': 516} weighted_avg {'precision': 0.8395065424780901, 'recall': 0.8410852713178295, 'f1-score': 0.8391834927683453, 'support': 516}
 
time = 1.12 secondes

Val loss 0.3771030195057392 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 3/40
time = 35.29 secondes

Train loss 0.3337746742322589 accuracy 0.8662790656089783 macro_avg {'precision': 0.8669592696629214, 'recall': 0.8397428603936739, 'f1-score': 0.850211405372431, 'support': 516} weighted_avg {'precision': 0.8664664717794618, 'recall': 0.8662790697674418, 'f1-score': 0.86371204646173, 'support': 516}
 
time = 1.13 secondes

Val loss 0.451164610683918 accuracy 0.859375 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}
 
----------
Epoch 4/40
time = 35.56 secondes

Train loss 0.34263111154238385 accuracy 0.8701550364494324 macro_avg {'precision': 0.8571135775997982, 'recall': 0.8681712530273231, 'f1-score': 0.8617822146349654, 'support': 516} weighted_avg {'precision': 0.8736482872846609, 'recall': 0.8701550387596899, 'f1-score': 0.8711439549948936, 'support': 516}
 
time = 1.11 secondes

Val loss 0.37321773543953896 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 5/40
time = 35.64 secondes

Train loss 0.22803308933295988 accuracy 0.9224806427955627 macro_avg {'precision': 0.9153924566768603, 'recall': 0.9172829673455456, 'f1-score': 0.9163207057602492, 'support': 516} weighted_avg {'precision': 0.9226860741688989, 'recall': 0.9224806201550387, 'f1-score': 0.9225686189321072, 'support': 516}
 
time = 1.24 secondes

Val loss 0.6092197299003601 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 6/40
time = 37.62 secondes

Train loss 0.2767731015514018 accuracy 0.9050387740135193 macro_avg {'precision': 0.8943682104059463, 'recall': 0.9036051557953937, 'f1-score': 0.8984965575382886, 'support': 516} weighted_avg {'precision': 0.9069950270586513, 'recall': 0.9050387596899225, 'f1-score': 0.905588104908762, 'support': 516}
 
time = 1.32 secondes

Val loss 0.5959191620349884 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 7/40
time = 35.80 secondes

Train loss 0.2097536547561035 accuracy 0.9282945990562439 macro_avg {'precision': 0.922029060716139, 'recall': 0.9229962778148009, 'f1-score': 0.9225083713850837, 'support': 516} weighted_avg {'precision': 0.9283840809709433, 'recall': 0.9282945736434108, 'f1-score': 0.9283356105388599, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5962822809815407 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 8/40
time = 36.29 secondes

Train loss 0.13404670566546195 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.15 secondes

Val loss 0.9576348811388016 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 9/40
time = 35.71 secondes

Train loss 0.1194090315045535 accuracy 0.9728682041168213 macro_avg {'precision': 0.9740249031087655, 'recall': 0.9671830047299383, 'f1-score': 0.9704360921948665, 'support': 516} weighted_avg {'precision': 0.9729583484351338, 'recall': 0.9728682170542635, 'f1-score': 0.9727696173978015, 'support': 516}
 
time = 1.19 secondes

Val loss 1.0482741817831993 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 10/40
time = 36.06 secondes

Train loss 0.09688440598829677 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.18 secondes

Val loss 1.5427087247371674 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 36.81 secondes

Train loss 0.23155320420063977 accuracy 0.9496123790740967 macro_avg {'precision': 0.9521407624633431, 'recall': 0.9385595630902264, 'f1-score': 0.9446854127154284, 'support': 516} weighted_avg {'precision': 0.9499779490327127, 'recall': 0.9496124031007752, 'f1-score': 0.9492284817720469, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0825803130865097 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 12/40
time = 36.79 secondes

Train loss 0.12264938391374679 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.28 secondes

Val loss 1.4131671637296677 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 13/40
time = 37.63 secondes

Train loss 0.3539659626584387 accuracy 0.9166666865348816 macro_avg {'precision': 0.9056372549019608, 'recall': 0.9196479365440567, 'f1-score': 0.911471446070119, 'support': 516} weighted_avg {'precision': 0.920138888888889, 'recall': 0.9166666666666666, 'f1-score': 0.9173732166677971, 'support': 516}
 
time = 1.25 secondes

Val loss 1.2752325534820557 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 14/40
time = 36.57 secondes

Train loss 0.10908935406019515 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 1.17 secondes

Val loss 1.5216321051120758 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 15/40
time = 36.06 secondes

Train loss 0.13675896991546985 accuracy 0.9748061895370483 macro_avg {'precision': 0.9722366372599895, 'recall': 0.9733189213789964, 'f1-score': 0.9727732115677321, 'support': 516} weighted_avg {'precision': 0.9748429096116791, 'recall': 0.9748062015503876, 'f1-score': 0.9748206199190588, 'support': 516}
 
time = 1.28 secondes

Val loss 1.4822283685207367 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 16/40
time = 36.74 secondes

Train loss 0.15914139923883008 accuracy 0.9709302186965942 macro_avg {'precision': 0.9654383044118588, 'recall': 0.972587487606261, 'f1-score': 0.9687942233027322, 'support': 516} weighted_avg {'precision': 0.9715309121991389, 'recall': 0.9709302325581395, 'f1-score': 0.9710409885936052, 'support': 516}
 
time = 1.25 secondes

Val loss 1.0666689425706863 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 17/40
time = 36.30 secondes

Train loss 0.03774997102278355 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.20 secondes

Val loss 1.3186561465263367 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 18/40
time = 36.36 secondes

Train loss 0.04208678399630695 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.23 secondes

Val loss 1.6961020231246948 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 19/40
time = 36.71 secondes

Train loss 0.14439543479900088 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 1.31 secondes

Val loss 1.4212730079889297 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 20/40
time = 36.86 secondes

Train loss 0.24330855313790822 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.35 secondes

Val loss 1.4089889749884605 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 21/40
time = 37.37 secondes

Train loss 0.12701709466769404 accuracy 0.9728682041168213 macro_avg {'precision': 0.9740249031087655, 'recall': 0.9671830047299383, 'f1-score': 0.9704360921948665, 'support': 516} weighted_avg {'precision': 0.9729583484351338, 'recall': 0.9728682170542635, 'f1-score': 0.9727696173978015, 'support': 516}
 
time = 1.30 secondes

Val loss 1.2470958344638348 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 22/40
time = 37.02 secondes

Train loss 0.13759647529690427 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.29 secondes

Val loss 2.5265198349952698 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 23/40
time = 37.07 secondes

Train loss 0.20282457375750793 accuracy 0.9534883499145508 macro_avg {'precision': 0.9642061642061641, 'recall': 0.9369829169578856, 'f1-score': 0.9482620320855615, 'support': 516} weighted_avg {'precision': 0.9560237637757016, 'recall': 0.9534883720930233, 'f1-score': 0.9527872777017784, 'support': 516}
 
time = 1.23 secondes

Val loss 1.1403222158551216 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 24/40
time = 37.42 secondes

Train loss 0.3535435064448834 accuracy 0.9418604373931885 macro_avg {'precision': 0.958217270194986, 'recall': 0.9197860962566845, 'f1-score': 0.934593023255814, 'support': 516} weighted_avg {'precision': 0.9467189220703505, 'recall': 0.9418604651162791, 'f1-score': 0.9405928880475933, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4130823612213135 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 25/40
time = 37.36 secondes

Train loss 0.05339616969594675 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2943629622459412 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 26/40
time = 37.43 secondes

Train loss 0.18786131410976822 accuracy 0.963178277015686 macro_avg {'precision': 0.9727011494252873, 'recall': 0.9491978609625669, 'f1-score': 0.9592069403124805, 'support': 516} weighted_avg {'precision': 0.9651886750423238, 'recall': 0.9631782945736435, 'f1-score': 0.962709625437233, 'support': 516}
 
time = 1.19 secondes

Val loss 1.4316061586141586 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 27/40
time = 37.20 secondes

Train loss 0.017271959231562283 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.17 secondes

Val loss 1.7183738499879837 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 28/40
time = 37.92 secondes

Train loss 0.07987996679995293 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.26 secondes

Val loss 1.3770747110247612 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 29/40
time = 37.51 secondes

Train loss 0.02657901951434641 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.12 secondes

Val loss 1.8989408314228058 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 30/40
time = 37.08 secondes

Train loss 0.035653042415409196 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.22 secondes

Val loss 1.8053470253944397 accuracy 0.78125 macro_avg {'precision': 0.8097165991902835, 'recall': 0.8097165991902835, 'f1-score': 0.78125, 'support': 64} weighted_avg {'precision': 0.8381831983805669, 'recall': 0.78125, 'f1-score': 0.78125, 'support': 64}
 
----------
Epoch 31/40
time = 36.76 secondes

Train loss 0.06005627316600029 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 1.21 secondes

Val loss 2.0119456350803375 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 32/40
time = 37.29 secondes

Train loss 8.434665814451309e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.12 secondes

Val loss 1.8381114304065704 accuracy 0.78125 macro_avg {'precision': 0.8097165991902835, 'recall': 0.8097165991902835, 'f1-score': 0.78125, 'support': 64} weighted_avg {'precision': 0.8381831983805669, 'recall': 0.78125, 'f1-score': 0.78125, 'support': 64}
 
----------
Epoch 33/40
time = 37.08 secondes

Train loss 0.16980448839813383 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.10 secondes

Val loss 1.3212704509496689 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 34/40
time = 36.48 secondes

Train loss 0.03320640016417284 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.22 secondes

Val loss 1.1827987283468246 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 35/40
time = 36.87 secondes

Train loss 0.026125381678646205 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.28 secondes

Val loss 1.5619274824857712 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 38.04 secondes

Train loss 0.00015208405172663996 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.25 secondes

Val loss 1.792539119720459 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 37/40
time = 36.82 secondes

Train loss 0.00023111380913619405 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.22 secondes

Val loss 1.564741611480713 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 36.36 secondes

Train loss 4.982320685733364e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.28 secondes

Val loss 1.7855963110923767 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 39/40
time = 36.69 secondes

Train loss 4.743123027958173e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.16 secondes

Val loss 2.0800199061632156 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 40/40
time = 37.50 secondes

Train loss 0.016515279365855597 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.24 secondes

Val loss 2.0936179906129837 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 3 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}

average train time 36.78049626350403

average val time 1.2158302783966064
 
time = 1.43 secondes

test_accuracy 0.8615384697914124 macro_avg {'precision': 0.8571428571428572, 'recall': 0.8654970760233918, 'f1-score': 0.8594087959625091, 'support': 65} weighted_avg {'precision': 0.8668131868131868, 'recall': 0.8615384615384616, 'f1-score': 0.8623370861294439, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_1
----------
Epoch 1/40
time = 54.84 secondes

Train loss 0.6291608024727214 accuracy 0.6472868323326111 macro_avg {'precision': 0.6042039942315256, 'recall': 0.5387578629130569, 'f1-score': 0.5000851716208159, 'support': 516} weighted_avg {'precision': 0.618839787296822, 'recall': 0.6472868217054264, 'f1-score': 0.5747374370208683, 'support': 516}
 
time = 1.54 secondes

Val loss 0.6071645691990852 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 2/40
time = 54.51 secondes

Train loss 0.3913250190742088 accuracy 0.8313953280448914 macro_avg {'precision': 0.825224942456581, 'recall': 0.8031549176730653, 'f1-score': 0.8116685615038994, 'support': 516} weighted_avg {'precision': 0.8297884721755873, 'recall': 0.8313953488372093, 'f1-score': 0.8284422369609653, 'support': 516}
 
time = 1.57 secondes

Val loss 0.40257441997528076 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 3/40
time = 54.48 secondes

Train loss 0.2717534914951433 accuracy 0.895348846912384 macro_avg {'precision': 0.8874336572221768, 'recall': 0.885620012028022, 'f1-score': 0.8865102639296187, 'support': 516} weighted_avg {'precision': 0.8951319829630797, 'recall': 0.8953488372093024, 'f1-score': 0.8952260792470844, 'support': 516}
 
time = 1.55 secondes

Val loss 0.45407774299383163 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 55.05 secondes

Train loss 0.16086416276679796 accuracy 0.9457364082336426 macro_avg {'precision': 0.9431890907300744, 'recall': 0.9389821692700291, 'f1-score': 0.9410141259083857, 'support': 516} weighted_avg {'precision': 0.9456005757950096, 'recall': 0.9457364341085271, 'f1-score': 0.945607055801674, 'support': 516}
 
time = 1.61 secondes

Val loss 0.9890318661928177 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 5/40
time = 54.78 secondes

Train loss 0.15513807144298247 accuracy 0.9554263353347778 macro_avg {'precision': 0.9522482893450636, 'recall': 0.9511971132747102, 'f1-score': 0.9517182179514823, 'support': 516} weighted_avg {'precision': 0.9553822167663129, 'recall': 0.9554263565891473, 'f1-score': 0.955400425549723, 'support': 516}
 
time = 1.43 secondes

Val loss 1.6848997473716736 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 6/40
time = 54.68 secondes

Train loss 0.15772021960848095 accuracy 0.9496123790740967 macro_avg {'precision': 0.9496377832667473, 'recall': 0.9408676429953026, 'f1-score': 0.9449613547974203, 'support': 516} weighted_avg {'precision': 0.9496149732441648, 'recall': 0.9496124031007752, 'f1-score': 0.9493643471912628, 'support': 516}
 
time = 1.53 secondes

Val loss 1.1839231252670288 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 7/40
time = 54.53 secondes

Train loss 0.11009460356030049 accuracy 0.9709302186965942 macro_avg {'precision': 0.9752005347593583, 'recall': 0.9622011280334184, 'f1-score': 0.9681280806433681, 'support': 516} weighted_avg {'precision': 0.9715030779753763, 'recall': 0.9709302325581395, 'f1-score': 0.9707287706557703, 'support': 516}
 
time = 1.46 secondes

Val loss 0.9567240551114082 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 8/40
time = 54.49 secondes

Train loss 0.24754270701316383 accuracy 0.9379844665527344 macro_avg {'precision': 0.931341119613371, 'recall': 0.9352112218194821, 'f1-score': 0.9332071258676763, 'support': 516} weighted_avg {'precision': 0.9383811156172047, 'recall': 0.937984496124031, 'f1-score': 0.9381229706242151, 'support': 516}
 
time = 1.48 secondes

Val loss 1.7164086401462555 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 9/40
time = 54.34 secondes

Train loss 0.1742345500785053 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.43 secondes

Val loss 2.2951018512248993 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 10/40
time = 54.46 secondes

Train loss 0.1053893209847791 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 1.51 secondes

Val loss 2.6474506855010986 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 11/40
time = 54.91 secondes

Train loss 0.10388514494865597 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.44 secondes

Val loss 2.4455079436302185 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 12/40
time = 54.67 secondes

Train loss 0.11494059201548666 accuracy 0.9670542478561401 macro_avg {'precision': 0.9638687078360145, 'recall': 0.9649318141182972, 'f1-score': 0.9643957382039574, 'support': 516} weighted_avg {'precision': 0.9670997715048896, 'recall': 0.9670542635658915, 'f1-score': 0.9670731183556924, 'support': 516}
 
time = 1.61 secondes

Val loss 1.926014930009842 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 13/40
time = 54.72 secondes

Train loss 0.4696365613247811 accuracy 0.9108527302742004 macro_avg {'precision': 0.9042867641054952, 'recall': 0.9023942265494206, 'f1-score': 0.9033235581622678, 'support': 516} weighted_avg {'precision': 0.9106728241626014, 'recall': 0.9108527131782945, 'f1-score': 0.9107481415808497, 'support': 516}
 
time = 1.66 secondes

Val loss 1.2978059388697147 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 14/40
time = 54.85 secondes

Train loss 0.33017855446616357 accuracy 0.9341084957122803 macro_avg {'precision': 0.9435860894349919, 'recall': 0.9148611088535995, 'f1-score': 0.9265018852115625, 'support': 516} weighted_avg {'precision': 0.9365028586610147, 'recall': 0.9341085271317829, 'f1-score': 0.9330087716734378, 'support': 516}
 
time = 1.51 secondes

Val loss 1.7108701020479202 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 15/40
time = 54.43 secondes

Train loss 0.1622154880764852 accuracy 0.9554263353347778 macro_avg {'precision': 0.9458033197619793, 'recall': 0.962737512800091, 'f1-score': 0.9527410433764589, 'support': 516} weighted_avg {'precision': 0.9589424661990741, 'recall': 0.9554263565891473, 'f1-score': 0.9558411610691561, 'support': 516}
 
time = 1.54 secondes

Val loss 1.0842865407466888 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 16/40
time = 54.47 secondes

Train loss 0.016653765219829933 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.65 secondes

Val loss 1.6118466556072235 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 17/40
time = 54.59 secondes

Train loss 0.06862760322286648 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.49 secondes

Val loss 1.5990178287684103 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 18/40
time = 54.55 secondes

Train loss 0.2118596030363044 accuracy 0.961240291595459 macro_avg {'precision': 0.9713467048710602, 'recall': 0.946524064171123, 'f1-score': 0.9570021498925053, 'support': 516} weighted_avg {'precision': 0.9634614957464295, 'recall': 0.9612403100775194, 'f1-score': 0.9607170804250486, 'support': 516}
 
time = 1.56 secondes

Val loss 1.2792070806026459 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 19/40
time = 54.30 secondes

Train loss 0.13640943221098772 accuracy 0.9670542478561401 macro_avg {'precision': 0.9583333333333333, 'recall': 0.9741641337386018, 'f1-score': 0.9650003391440005, 'support': 516} weighted_avg {'precision': 0.9697997416020671, 'recall': 0.9670542635658915, 'f1-score': 0.9673335972872688, 'support': 516}
 
time = 1.63 secondes

Val loss 1.7856219559907913 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 20/40
time = 54.89 secondes

Train loss 0.0802300014807825 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.59 secondes

Val loss 1.7517135441303253 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 21/40
time = 54.68 secondes

Train loss 0.12578634612994696 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.54 secondes

Val loss 1.3829979124711826 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 22/40
time = 54.30 secondes

Train loss 0.3297932953018145 accuracy 0.9418604373931885 macro_avg {'precision': 0.9362652298432115, 'recall': 0.9382507354972938, 'f1-score': 0.9372405293201869, 'support': 516} weighted_avg {'precision': 0.9420226458488318, 'recall': 0.9418604651162791, 'f1-score': 0.9419264641990804, 'support': 516}
 
time = 1.47 secondes

Val loss 2.2294629514217377 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 23/40
time = 54.63 secondes

Train loss 0.039183055911659416 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.62 secondes

Val loss 1.43848419142887 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 24/40
time = 54.44 secondes

Train loss 0.1653884747311443 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 1.49 secondes

Val loss 1.7653790414333344 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 25/40
time = 54.29 secondes

Train loss 0.015426083326791271 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.62 secondes

Val loss 1.7862603664398193 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 26/40
time = 54.04 secondes

Train loss 0.020444341749239495 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.48 secondes

Val loss 1.8965023756027222 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 27/40
time = 54.20 secondes

Train loss 0.027621816873623615 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.55 secondes

Val loss 2.1219781041145325 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 28/40
time = 54.83 secondes

Train loss 0.020745615674141762 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.58 secondes

Val loss 1.9422816932201385 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 29/40
time = 54.51 secondes

Train loss 0.05321941504624909 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.62 secondes

Val loss 1.8027299344539642 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 30/40
time = 54.22 secondes

Train loss 0.02355433836242865 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.47 secondes

Val loss 2.1644850969314575 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 31/40
time = 54.65 secondes

Train loss 0.04380126749950278 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 1.54 secondes

Val loss 2.7500805258750916 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 32/40
time = 54.44 secondes

Train loss 0.0019479961918643146 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.46 secondes

Val loss 1.9075327515602112 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 33/40
time = 54.70 secondes

Train loss 0.02027271529831606 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.42 secondes

Val loss 2.2867960035800934 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 34/40
time = 54.38 secondes

Train loss 0.06920628918305738 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.57 secondes

Val loss 2.57716166973114 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 35/40
time = 54.85 secondes

Train loss 2.788851072016934e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.45 secondes

Val loss 1.9855290651321411 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 54.68 secondes

Train loss 0.07837793827341309 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.56 secondes

Val loss 2.179258644580841 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 37/40
time = 54.31 secondes

Train loss 0.020185293216965158 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.64 secondes

Val loss 2.854239046573639 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 38/40
time = 54.14 secondes

Train loss 0.03460458040353842 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.45 secondes

Val loss 2.8368512988090515 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 39/40
time = 54.68 secondes

Train loss 0.009367350737937324 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.60 secondes

Val loss 2.539868116378784 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 40/40
time = 54.62 secondes

Train loss 3.384664137918276e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.49 secondes

Val loss 2.2616680562496185 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
best_accuracy 0.8125 best_epoch 3 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}

average train time 54.55321429371834

average val time 1.5359297752380372
 
time = 1.72 secondes

test_accuracy 0.9230769276618958 macro_avg {'precision': 0.9303861788617886, 'recall': 0.9127680311890838, 'f1-score': 0.9193348225366097, 'support': 65} weighted_avg {'precision': 0.9256566604127581, 'recall': 0.9230769230769231, 'f1-score': 0.9222750443897131, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_1
----------
Epoch 1/40
time = 99.46 secondes

Train loss 0.62968571619554 accuracy 0.6375969052314758 macro_avg {'precision': 0.5752118644067796, 'recall': 0.5253888789558376, 'f1-score': 0.4785090065988943, 'support': 516} weighted_avg {'precision': 0.5959097030613587, 'recall': 0.6375968992248062, 'f1-score': 0.5577738513458399, 'support': 516}
 
time = 2.06 secondes

Val loss 0.6491236239671707 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 2/40
time = 99.69 secondes

Train loss 0.4052905803828528 accuracy 0.8217054009437561 macro_avg {'precision': 0.8144169364010148, 'recall': 0.7920940136209222, 'f1-score': 0.8005646299657189, 'support': 516} weighted_avg {'precision': 0.8197518104922085, 'recall': 0.8217054263565892, 'f1-score': 0.8184336364389544, 'support': 516}
 
time = 2.01 secondes

Val loss 0.43378572165966034 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 3/40
time = 99.45 secondes

Train loss 0.2517655062856096 accuracy 0.9011628031730652 macro_avg {'precision': 0.895734126984127, 'recall': 0.8890252425922014, 'f1-score': 0.892171846510008, 'support': 516} weighted_avg {'precision': 0.9006756029285099, 'recall': 0.9011627906976745, 'f1-score': 0.9007403973465761, 'support': 516}
 
time = 1.87 secondes

Val loss 0.5283290296792984 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 4/40
time = 99.32 secondes

Train loss 0.1803983133709566 accuracy 0.9379844665527344 macro_avg {'precision': 0.9320906752099413, 'recall': 0.9340571818669441, 'f1-score': 0.9330565646081994, 'support': 516} weighted_avg {'precision': 0.9381553315128452, 'recall': 0.937984496124031, 'f1-score': 0.938054895145686, 'support': 516}
 
time = 1.95 secondes

Val loss 0.8653410524129868 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 5/40
time = 99.83 secondes

Train loss 0.17638303351122886 accuracy 0.9360464811325073 macro_avg {'precision': 0.9303969901401141, 'recall': 0.9313833850755002, 'f1-score': 0.9308858447488584, 'support': 516} weighted_avg {'precision': 0.9361272190777326, 'recall': 0.936046511627907, 'f1-score': 0.9360831121022263, 'support': 516}
 
time = 1.84 secondes

Val loss 1.4382009953260422 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 6/40
time = 99.45 secondes

Train loss 0.11492157539627938 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.91 secondes

Val loss 1.3047122359275818 accuracy 0.734375 macro_avg {'precision': 0.744055068836045, 'recall': 0.6973684210526316, 'f1-score': 0.7023255813953488, 'support': 64} weighted_avg {'precision': 0.740183041301627, 'recall': 0.734375, 'f1-score': 0.7206395348837209, 'support': 64}
 
----------
Epoch 7/40
time = 99.33 secondes

Train loss 0.310447221313194 accuracy 0.9244186282157898 macro_avg {'precision': 0.9258720930232558, 'recall': 0.9095704045641467, 'f1-score': 0.9167077112831996, 'support': 516} weighted_avg {'precision': 0.9246721200649, 'recall': 0.9244186046511628, 'f1-score': 0.9236818950937141, 'support': 516}
 
time = 1.91 secondes

Val loss 0.7575634121894836 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 8/40
time = 99.37 secondes

Train loss 0.041898989732461894 accuracy 0.9864341020584106 macro_avg {'precision': 0.9870350969093766, 'recall': 0.9835915023649693, 'f1-score': 0.9852710301715525, 'support': 516} weighted_avg {'precision': 0.9864584729210066, 'recall': 0.9864341085271318, 'f1-score': 0.9864100448370163, 'support': 516}
 
time = 2.05 secondes

Val loss 1.5175736546516418 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 9/40
time = 99.28 secondes

Train loss 0.22607258016113052 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 1.89 secondes

Val loss 1.2881184220314026 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 10/40
time = 99.44 secondes

Train loss 0.26809778717649874 accuracy 0.9515503644943237 macro_avg {'precision': 0.9441326530612244, 'recall': 0.9527737594070511, 'f1-score': 0.9481025236656515, 'support': 516} weighted_avg {'precision': 0.9526271555133681, 'recall': 0.9515503875968992, 'f1-score': 0.9517837016975099, 'support': 516}
 
time = 2.07 secondes

Val loss 1.0775373987853527 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 11/40
time = 99.74 secondes

Train loss 0.14890232984025992 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 1.91 secondes

Val loss 1.3543130904436111 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 99.52 secondes

Train loss 0.1407132398039032 accuracy 0.9534883499145508 macro_avg {'precision': 0.9593185863208746, 'recall': 0.9404450368155, 'f1-score': 0.9486762926247037, 'support': 516} weighted_avg {'precision': 0.9545605953992947, 'recall': 0.9534883720930233, 'f1-score': 0.953001072906358, 'support': 516}
 
time = 1.98 secondes

Val loss 1.4146633297204971 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 13/40
time = 99.34 secondes

Train loss 0.31165245409867953 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 1.89 secondes

Val loss 1.960549771785736 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 14/40
time = 99.70 secondes

Train loss 0.21631481150204004 accuracy 0.9554263353347778 macro_avg {'precision': 0.9522482893450636, 'recall': 0.9511971132747102, 'f1-score': 0.9517182179514823, 'support': 516} weighted_avg {'precision': 0.9553822167663129, 'recall': 0.9554263565891473, 'f1-score': 0.955400425549723, 'support': 516}
 
time = 2.00 secondes

Val loss 1.2938392758369446 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 15/40
time = 99.31 secondes

Train loss 0.21201125091597947 accuracy 0.9573643207550049 macro_avg {'precision': 0.9622002393029879, 'recall': 0.9457926303983876, 'f1-score': 0.9530753968253968, 'support': 516} weighted_avg {'precision': 0.9581608419681893, 'recall': 0.9573643410852714, 'f1-score': 0.9569794358311798, 'support': 516}
 
time = 1.99 secondes

Val loss 1.1795170456171036 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 16/40
time = 99.56 secondes

Train loss 0.08824598063118615 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 1.89 secondes

Val loss 1.5159240067005157 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 17/40
time = 99.50 secondes

Train loss 0.0447942551651398 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.97 secondes

Val loss 1.7004007548093796 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 18/40
time = 99.54 secondes

Train loss 0.06678422000583271 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.85 secondes

Val loss 2.2519355714321136 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 19/40
time = 99.38 secondes

Train loss 0.26387188793953764 accuracy 0.9534883499145508 macro_avg {'precision': 0.9608648943607934, 'recall': 0.9392909968629618, 'f1-score': 0.9485406555415199, 'support': 516} weighted_avg {'precision': 0.9549802530011117, 'recall': 0.9534883720930233, 'f1-score': 0.9529317539809791, 'support': 516}
 
time = 1.87 secondes

Val loss 1.663646250963211 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 20/40
time = 99.41 secondes

Train loss 0.20241538035880888 accuracy 0.961240291595459 macro_avg {'precision': 0.9680650902618866, 'recall': 0.9488321440761991, 'f1-score': 0.9572302438539197, 'support': 516} weighted_avg {'precision': 0.962495442065449, 'recall': 0.9612403100775194, 'f1-score': 0.960834227421965, 'support': 516}
 
time = 1.98 secondes

Val loss 1.8543893694877625 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 21/40
time = 99.59 secondes

Train loss 0.022064099805985195 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.90 secondes

Val loss 1.6474340036511421 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 22/40
time = 99.38 secondes

Train loss 0.10660936872569216 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 1.89 secondes

Val loss 1.3929017931222916 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 23/40
time = 99.61 secondes

Train loss 0.08590642222473187 accuracy 0.9748061895370483 macro_avg {'precision': 0.9732649071358749, 'recall': 0.9721648814264584, 'f1-score': 0.9727102971030117, 'support': 516} weighted_avg {'precision': 0.9747847946835194, 'recall': 0.9748062015503876, 'f1-score': 0.9747915448759306, 'support': 516}
 
time = 1.98 secondes

Val loss 1.7043509185314178 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 24/40
time = 99.46 secondes

Train loss 0.006331559115620401 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.91 secondes

Val loss 1.5567190796136856 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 25/40
time = 99.28 secondes

Train loss 0.2614562592637164 accuracy 0.9554263353347778 macro_avg {'precision': 0.9673295454545454, 'recall': 0.9385026737967914, 'f1-score': 0.95034953625262, 'support': 516} weighted_avg {'precision': 0.9583388389711065, 'recall': 0.9554263565891473, 'f1-score': 0.9547186786028435, 'support': 516}
 
time = 1.84 secondes

Val loss 1.7223396301269531 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 26/40
time = 99.47 secondes

Train loss 0.07324415782436104 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.92 secondes

Val loss 1.6998321413993835 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 27/40
time = 99.37 secondes

Train loss 0.02958592100990107 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.80 secondes

Val loss 1.5660022795200348 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 28/40
time = 99.35 secondes

Train loss 0.038058502572257014 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.80 secondes

Val loss 1.3476222604513168 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 29/40
time = 99.68 secondes

Train loss 0.02295246491253651 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.80 secondes

Val loss 1.38865727186203 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 30/40
time = 98.91 secondes

Train loss 0.06367499712470101 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.82 secondes

Val loss 1.0833283776883036 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 31/40
time = 99.55 secondes

Train loss 0.06415716841652422 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.80 secondes

Val loss 1.608703225851059 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 32/40
time = 99.44 secondes

Train loss 0.06369210713802947 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.80 secondes

Val loss 2.1121588200330734 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 33/40
time = 99.57 secondes

Train loss 0.04538741322837516 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.80 secondes

Val loss 2.2619059681892395 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 34/40
time = 99.32 secondes

Train loss 0.03641299037818416 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.81 secondes

Val loss 1.7408372685313225 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 35/40
time = 99.22 secondes

Train loss 0.05153477637599501 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.80 secondes

Val loss 2.5927220284938812 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 36/40
time = 99.27 secondes

Train loss 0.01585684356122687 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.80 secondes

Val loss 1.999933496077574 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 99.40 secondes

Train loss 0.019527735354517285 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.80 secondes

Val loss 2.230191648006439 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 38/40
time = 99.69 secondes

Train loss 0.018491219441178448 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.80 secondes

Val loss 1.851663943265521 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 39/40
time = 99.42 secondes

Train loss 3.2687329979980305e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.80 secondes

Val loss 2.0381953002834052 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 40/40
time = 99.39 secondes

Train loss 3.5441010395791665e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.80 secondes

Val loss 2.1483893245458603 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 30 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}

average train time 99.45000395774841

average val time 1.8894500851631164
 
time = 1.88 secondes

test_accuracy 0.9846153855323792 macro_avg {'precision': 0.9871794871794872, 'recall': 0.9814814814814814, 'f1-score': 0.9840725312423425, 'support': 65} weighted_avg {'precision': 0.9850098619329388, 'recall': 0.9846153846153847, 'f1-score': 0.9845701468342976, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 1; 79.20 GiB total capacity; 73.98 GiB already allocated; 98.31 MiB free; 77.09 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 1; 79.20 GiB total capacity; 72.42 GiB already allocated; 1.22 GiB free; 75.96 GiB reserved in total by PyTorch)
Downloading:   0%|          | 0.00/826k [00:00<?, ?B/s]Downloading: 100%|| 826k/826k [00:00<00:00, 13.0MB/s]
Downloading:   0%|          | 0.00/775 [00:00<?, ?B/s]Downloading: 100%|| 775/775 [00:00<00:00, 468kB/s]
Downloading:   0%|          | 0.00/0.99k [00:00<?, ?B/s]Downloading: 100%|| 0.99k/0.99k [00:00<00:00, 612kB/s]
Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]Downloading: 100%|| 760/760 [00:00<00:00, 420kB/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_1
----------
Epoch 1/40
time = 29.26 secondes

Train loss 0.6243748565514883 accuracy 0.6608527302742004 macro_avg {'precision': 0.6792181069958847, 'recall': 0.542471921070169, 'f1-score': 0.4894122303582031, 'support': 516} weighted_avg {'precision': 0.6734990589211088, 'recall': 0.6608527131782945, 'f1-score': 0.5708321252092163, 'support': 516}
 
time = 0.87 secondes

Val loss 0.5650296956300735 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 2/40
time = 28.32 secondes

Train loss 0.42091758233128174 accuracy 0.8255813717842102 macro_avg {'precision': 0.8156813259894617, 'recall': 0.8009037270614241, 'f1-score': 0.8070274582806994, 'support': 516} weighted_avg {'precision': 0.8235791341300872, 'recall': 0.8255813953488372, 'f1-score': 0.8234940774286718, 'support': 516}
 
time = 0.87 secondes

Val loss 0.3957005813717842 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 3/40
time = 28.27 secondes

Train loss 0.3321981985460628 accuracy 0.8759689927101135 macro_avg {'precision': 0.8652978010776176, 'recall': 0.8669603237813501, 'f1-score': 0.8661131292163985, 'support': 516} weighted_avg {'precision': 0.8762783021370603, 'recall': 0.875968992248062, 'f1-score': 0.8761097902913715, 'support': 516}
 
time = 0.87 secondes

Val loss 0.6244345754384995 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 4/40
time = 28.26 secondes

Train loss 0.27423468006379675 accuracy 0.9031007885932922 macro_avg {'precision': 0.8939347563431332, 'recall': 0.8974692391463355, 'f1-score': 0.8956361341682443, 'support': 516} weighted_avg {'precision': 0.9036480001998084, 'recall': 0.9031007751937985, 'f1-score': 0.9033171416003363, 'support': 516}
 
time = 0.87 secondes

Val loss 0.30522119998931885 accuracy 0.890625 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}
 
----------
Epoch 5/40
time = 29.98 secondes

Train loss 0.17943390046782565 accuracy 0.9360464811325073 macro_avg {'precision': 0.9352270460740642, 'recall': 0.9256131853128098, 'f1-score': 0.9300568893635375, 'support': 516} weighted_avg {'precision': 0.9359543217530997, 'recall': 0.936046511627907, 'f1-score': 0.9356895142744016, 'support': 516}
 
time = 0.88 secondes

Val loss 0.44447220489382744 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 6/40
time = 28.69 secondes

Train loss 0.23699094315595698 accuracy 0.9360464811325073 macro_avg {'precision': 0.9289158950617284, 'recall': 0.9336914649805763, 'f1-score': 0.9311963860728039, 'support': 516} weighted_avg {'precision': 0.9365867098526174, 'recall': 0.936046511627907, 'f1-score': 0.93622352350948, 'support': 516}
 
time = 0.87 secondes

Val loss 1.4490277767181396 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 7/40
time = 28.26 secondes

Train loss 0.20836809036237272 accuracy 0.9379844665527344 macro_avg {'precision': 0.9404607425133554, 'recall': 0.9248248622466395, 'f1-score': 0.9317460317460317, 'support': 516} weighted_avg {'precision': 0.938392348470508, 'recall': 0.937984496124031, 'f1-score': 0.9374246339362619, 'support': 516}
 
time = 0.87 secondes

Val loss 0.8226605951786041 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 8/40
time = 28.28 secondes

Train loss 0.10726876142716994 accuracy 0.9728682041168213 macro_avg {'precision': 0.9706451245875526, 'recall': 0.9706451245875526, 'f1-score': 0.9706451245875526, 'support': 516} weighted_avg {'precision': 0.9728682170542635, 'recall': 0.9728682170542635, 'f1-score': 0.9728682170542635, 'support': 516}
 
time = 0.87 secondes

Val loss 1.2149045914411545 accuracy 0.734375 macro_avg {'precision': 0.7571428571428571, 'recall': 0.6912955465587045, 'f1-score': 0.694981777403981, 'support': 64} weighted_avg {'precision': 0.7491071428571429, 'recall': 0.734375, 'f1-score': 0.7155347631062519, 'support': 64}
 
----------
Epoch 9/40
time = 28.46 secondes

Train loss 0.1870558140587739 accuracy 0.9457364082336426 macro_avg {'precision': 0.9442401253401501, 'recall': 0.937828129317491, 'f1-score': 0.9408721843897327, 'support': 516} weighted_avg {'precision': 0.9456198386200823, 'recall': 0.9457364341085271, 'f1-score': 0.945539234795603, 'support': 516}
 
time = 0.87 secondes

Val loss 0.8017411455512047 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 10/40
time = 28.51 secondes

Train loss 0.1535078762928165 accuracy 0.963178277015686 macro_avg {'precision': 0.959684743124027, 'recall': 0.9607382604879476, 'f1-score': 0.96020700152207, 'support': 516} weighted_avg {'precision': 0.9632282024514951, 'recall': 0.9631782945736435, 'f1-score': 0.9631993675740091, 'support': 516}
 
time = 0.87 secondes

Val loss 1.2479440122842789 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 11/40
time = 28.32 secondes

Train loss 0.21201057982927357 accuracy 0.9515503644943237 macro_avg {'precision': 0.9471328489880644, 'recall': 0.9481575995968987, 'f1-score': 0.947640791476408, 'support': 516} weighted_avg {'precision': 0.9516134952913111, 'recall': 0.9515503875968992, 'f1-score': 0.9515781152289595, 'support': 516}
 
time = 0.87 secondes

Val loss 0.6055113561451435 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 12/40
time = 28.31 secondes

Train loss 0.17136586397166617 accuracy 0.9534883499145508 macro_avg {'precision': 0.9593185863208746, 'recall': 0.9404450368155, 'f1-score': 0.9486762926247037, 'support': 516} weighted_avg {'precision': 0.9545605953992947, 'recall': 0.9534883720930233, 'f1-score': 0.953001072906358, 'support': 516}
 
time = 0.87 secondes

Val loss 0.654843982309103 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 13/40
time = 29.63 secondes

Train loss 0.04712404276837002 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 0.89 secondes

Val loss 1.1598779261112213 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 14/40
time = 28.39 secondes

Train loss 0.29642592268205725 accuracy 0.9282945990562439 macro_avg {'precision': 0.9181276407895567, 'recall': 0.9310745574825675, 'f1-score': 0.9236707752461748, 'support': 516} weighted_avg {'precision': 0.9310178592292646, 'recall': 0.9282945736434108, 'f1-score': 0.9288406915643441, 'support': 516}
 
time = 0.88 secondes

Val loss 1.3714307844638824 accuracy 0.78125 macro_avg {'precision': 0.8097165991902835, 'recall': 0.8097165991902835, 'f1-score': 0.78125, 'support': 64} weighted_avg {'precision': 0.8381831983805669, 'recall': 0.78125, 'f1-score': 0.78125, 'support': 64}
 
----------
Epoch 15/40
time = 28.48 secondes

Train loss 0.24264344526102033 accuracy 0.9476743936538696 macro_avg {'precision': 0.9429488842760767, 'recall': 0.9439640459665491, 'f1-score': 0.9434520547945207, 'support': 516} weighted_avg {'precision': 0.9477419262379165, 'recall': 0.9476744186046512, 'f1-score': 0.9477043644472762, 'support': 516}
 
time = 0.87 secondes

Val loss 0.7809207482787315 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 16/40
time = 28.42 secondes

Train loss 0.05064189977675789 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.87 secondes

Val loss 1.3344328254461288 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 17/40
time = 28.29 secondes

Train loss 0.0409341708264864 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.87 secondes

Val loss 0.9939691442996264 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 18/40
time = 28.29 secondes

Train loss 0.09170332318171859 accuracy 0.9767441749572754 macro_avg {'precision': 0.9748386782179023, 'recall': 0.9748386782179023, 'f1-score': 0.9748386782179023, 'support': 516} weighted_avg {'precision': 0.9767441860465116, 'recall': 0.9767441860465116, 'f1-score': 0.9767441860465116, 'support': 516}
 
time = 0.87 secondes

Val loss 1.396754890680313 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 19/40
time = 28.60 secondes

Train loss 0.1161949681462085 accuracy 0.9748061895370483 macro_avg {'precision': 0.9688137755102041, 'recall': 0.9779350811891487, 'f1-score': 0.9730133123061389, 'support': 516} weighted_avg {'precision': 0.9756760698465433, 'recall': 0.9748062015503876, 'f1-score': 0.9749275248827052, 'support': 516}
 
time = 0.87 secondes

Val loss 2.373705744743347 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 20/40
time = 28.26 secondes

Train loss 0.31030850929373904 accuracy 0.9321705102920532 macro_avg {'precision': 0.9309387673691909, 'recall': 0.9214196316824602, 'f1-score': 0.9258179129613275, 'support': 516} weighted_avg {'precision': 0.9320319679181813, 'recall': 0.9321705426356589, 'f1-score': 0.9317919090789107, 'support': 516}
 
time = 0.87 secondes

Val loss 1.7054722756147385 accuracy 0.71875 macro_avg {'precision': 0.7954545454545454, 'recall': 0.763157894736842, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.8338068181818182, 'recall': 0.71875, 'f1-score': 0.711268472906404, 'support': 64}
 
----------
Epoch 21/40
time = 29.37 secondes

Train loss 0.3058171493475763 accuracy 0.9418604373931885 macro_avg {'precision': 0.9335645974889805, 'recall': 0.9428668953074459, 'f1-score': 0.9377893518518519, 'support': 516} weighted_avg {'precision': 0.9432204434158361, 'recall': 0.9418604651162791, 'f1-score': 0.9421688827878265, 'support': 516}
 
time = 0.87 secondes

Val loss 1.5705745071172714 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 22/40
time = 29.27 secondes

Train loss 0.07708399859565719 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 0.87 secondes

Val loss 1.3922889679670334 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 23/40
time = 28.27 secondes

Train loss 0.11716173767248013 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 0.87 secondes

Val loss 1.0836983260232955 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 24/40
time = 28.30 secondes

Train loss 0.09251328420412558 accuracy 0.9728682041168213 macro_avg {'precision': 0.9651741293532339, 'recall': 0.9787234042553192, 'f1-score': 0.9710891976692066, 'support': 516} weighted_avg {'precision': 0.9747579929808323, 'recall': 0.9728682170542635, 'f1-score': 0.9730627972995041, 'support': 516}
 
time = 0.88 secondes

Val loss 1.429535150527954 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 25/40
time = 28.39 secondes

Train loss 0.03045276303248212 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.87 secondes

Val loss 1.3082697093486786 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 26/40
time = 28.43 secondes

Train loss 0.16811671474010148 accuracy 0.9593023061752319 macro_avg {'precision': 0.9495192307692308, 'recall': 0.9680851063829787, 'f1-score': 0.9569342050354708, 'support': 516} weighted_avg {'precision': 0.9634112254025045, 'recall': 0.9593023255813954, 'f1-score': 0.9597133217092003, 'support': 516}
 
time = 0.88 secondes

Val loss 2.3229075372219086 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 27/40
time = 28.28 secondes

Train loss 0.08547316660714745 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 0.87 secondes

Val loss 1.0376881286501884 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 28/40
time = 28.22 secondes

Train loss 0.013241019246792845 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.87 secondes

Val loss 1.758055865764618 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 29/40
time = 28.30 secondes

Train loss 0.0020242442361918756 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.87 secondes

Val loss 1.1291704177856445 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 30/40
time = 28.27 secondes

Train loss 0.07842041036465988 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 0.87 secondes

Val loss 1.2174106240272522 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 31/40
time = 28.75 secondes

Train loss 0.040379298187679415 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 0.87 secondes

Val loss 1.906285673379898 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 32/40
time = 28.26 secondes

Train loss 0.01696755804688578 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 0.87 secondes

Val loss 1.408784456551075 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 33/40
time = 29.39 secondes

Train loss 0.05313703918606431 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.87 secondes

Val loss 1.9154931902885437 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 34/40
time = 28.67 secondes

Train loss 0.00931041067341346 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 0.87 secondes

Val loss 1.2077099969610572 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 35/40
time = 28.46 secondes

Train loss 0.003939126461442687 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.87 secondes

Val loss 1.3280140547503834 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 36/40
time = 28.28 secondes

Train loss 0.0002619722283932126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.87 secondes

Val loss 1.9580652713775635 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 37/40
time = 28.34 secondes

Train loss 0.013564824793403122 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.88 secondes

Val loss 1.8490167260169983 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 38/40
time = 28.25 secondes

Train loss 5.763600854675822e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.87 secondes

Val loss 1.401460746259545 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 39/40
time = 28.30 secondes

Train loss 8.401217630969107e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.290614788660605 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 40/40
time = 28.25 secondes

Train loss 5.4745227812831715e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.87 secondes

Val loss 1.2895805272710277 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 4 macro_avg {'precision': 0.8887179487179487, 'recall': 0.8836032388663968, 'f1-score': 0.8859180035650623, 'support': 64} weighted_avg {'precision': 0.890352564102564, 'recall': 0.890625, 'f1-score': 0.8902629233511586, 'support': 64}

average train time 28.533660101890565

average val time 0.8790079414844513
 
time = 1.00 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.91, 'recall': 0.8996101364522417, 'f1-score': 0.9038461538461539, 'support': 65} weighted_avg {'precision': 0.9083076923076924, 'recall': 0.9076923076923077, 'f1-score': 0.9071005917159765, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 21.24 secondes

Train loss 0.6172280727010785 accuracy 0.6976743936538696 macro_avg {'precision': 0.8243929983060418, 'recall': 0.5840417404872974, 'f1-score': 0.5493954321540528, 'support': 516} weighted_avg {'precision': 0.7844062464891586, 'recall': 0.6976744186046512, 'f1-score': 0.6205292702485966, 'support': 516}
 
time = 0.70 secondes

Val loss 0.552846759557724 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 21.37 secondes

Train loss 0.4366909333250739 accuracy 0.8042635917663574 macro_avg {'precision': 0.7961538461538462, 'recall': 0.7703379224030038, 'f1-score': 0.779475049401888, 'support': 516} weighted_avg {'precision': 0.8017988471476843, 'recall': 0.8042635658914729, 'f1-score': 0.7998216929944952, 'support': 516}
 
time = 0.71 secondes

Val loss 0.5016823336482048 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 21.22 secondes

Train loss 0.2720895226706158 accuracy 0.9069767594337463 macro_avg {'precision': 0.8993547128716091, 'recall': 0.8993547128716091, 'f1-score': 0.8993547128716091, 'support': 516} weighted_avg {'precision': 0.9069767441860465, 'recall': 0.9069767441860465, 'f1-score': 0.9069767441860465, 'support': 516}
 
time = 0.71 secondes

Val loss 0.471643827855587 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 4/40
time = 21.24 secondes

Train loss 0.18747205179974888 accuracy 0.9399224519729614 macro_avg {'precision': 0.9345809548521017, 'recall': 0.9355769387058499, 'f1-score': 0.9350745814307458, 'support': 516} weighted_avg {'precision': 0.9399987881311272, 'recall': 0.939922480620155, 'f1-score': 0.9399568628839098, 'support': 516}
 
time = 0.71 secondes

Val loss 0.8538496866822243 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 21.25 secondes

Train loss 0.2668325439603491 accuracy 0.9147287011146545 macro_avg {'precision': 0.9155860666158149, 'recall': 0.8985095005120036, 'f1-score': 0.9059065364786234, 'support': 516} weighted_avg {'precision': 0.9148863620685237, 'recall': 0.9147286821705426, 'f1-score': 0.9138353003283229, 'support': 516}
 
time = 0.71 secondes

Val loss 0.45449307560920715 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 6/40
time = 21.31 secondes

Train loss 0.3679408499914588 accuracy 0.8972868323326111 macro_avg {'precision': 0.8923442590253308, 'recall': 0.8836776490093137, 'f1-score': 0.8876671253414389, 'support': 516} weighted_avg {'precision': 0.8967307834039157, 'recall': 0.8972868217054264, 'f1-score': 0.8967134623194933, 'support': 516}
 
time = 0.71 secondes

Val loss 1.1848738342523575 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 7/40
time = 21.17 secondes

Train loss 0.19810524756427517 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 0.71 secondes

Val loss 1.114901915192604 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 8/40
time = 21.23 secondes

Train loss 0.20239627022634854 accuracy 0.9476743936538696 macro_avg {'precision': 0.9550492610837438, 'recall': 0.9324236464411684, 'f1-score': 0.9420309151808933, 'support': 516} weighted_avg {'precision': 0.9492313297946818, 'recall': 0.9476744186046512, 'f1-score': 0.9470084150950151, 'support': 516}
 
time = 0.71 secondes

Val loss 0.9863500446081161 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 9/40
time = 21.24 secondes

Train loss 0.13287725160251174 accuracy 0.963178277015686 macro_avg {'precision': 0.955253164556962, 'recall': 0.967662500203176, 'f1-score': 0.9607235142118863, 'support': 516} weighted_avg {'precision': 0.9649546168187617, 'recall': 0.9631782945736435, 'f1-score': 0.9634256755403321, 'support': 516}
 
time = 0.71 secondes

Val loss 1.4546691477298737 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 10/40
time = 21.20 secondes

Train loss 0.2178638074741078 accuracy 0.9554263353347778 macro_avg {'precision': 0.9638752052545156, 'recall': 0.9408107537018676, 'f1-score': 0.950618927746687, 'support': 516} weighted_avg {'precision': 0.9572100024185028, 'recall': 0.9554263565891473, 'f1-score': 0.954859020266124, 'support': 516}
 
time = 0.71 secondes

Val loss 1.044068843126297 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 11/40
time = 21.29 secondes

Train loss 0.1897339096793792 accuracy 0.9496123790740967 macro_avg {'precision': 0.9395900755124056, 'recall': 0.9570242023308356, 'f1-score': 0.9466289005935427, 'support': 516} weighted_avg {'precision': 0.9535427276452338, 'recall': 0.9496124031007752, 'f1-score': 0.9501015018724527, 'support': 516}
 
time = 0.71 secondes

Val loss 0.6359679102897644 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 12/40
time = 21.19 secondes

Train loss 0.335270614391475 accuracy 0.9341084957122803 macro_avg {'precision': 0.9237236295192535, 'recall': 0.9390959478568991, 'f1-score': 0.9300701530612245, 'support': 516} weighted_avg {'precision': 0.9376354734907553, 'recall': 0.9341085271317829, 'f1-score': 0.9346947427226705, 'support': 516}
 
time = 0.70 secondes

Val loss 1.1660326570272446 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 13/40
time = 21.25 secondes

Train loss 0.08184205680718702 accuracy 0.9767441749572754 macro_avg {'precision': 0.972039974975537, 'recall': 0.9783007980755165, 'f1-score': 0.9750080723280594, 'support': 516} weighted_avg {'precision': 0.9771784209146016, 'recall': 0.9767441860465116, 'f1-score': 0.9768207792987963, 'support': 516}
 
time = 0.71 secondes

Val loss 1.41078382730484 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 14/40
time = 21.24 secondes

Train loss 0.056775430522534545 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 0.71 secondes

Val loss 0.9651990681886673 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 15/40
time = 21.27 secondes

Train loss 0.2560764821422653 accuracy 0.9457364082336426 macro_avg {'precision': 0.9389306854457082, 'recall': 0.9447523690327195, 'f1-score': 0.9416855020988053, 'support': 516} weighted_avg {'precision': 0.9463646570620181, 'recall': 0.9457364341085271, 'f1-score': 0.9459151516971914, 'support': 516}
 
time = 0.70 secondes

Val loss 1.323923334479332 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 16/40
time = 21.22 secondes

Train loss 0.14740278465041862 accuracy 0.9476743936538696 macro_avg {'precision': 0.9389240506329114, 'recall': 0.9508882856817775, 'f1-score': 0.9441860465116279, 'support': 516} weighted_avg {'precision': 0.9496357079776274, 'recall': 0.9476744186046512, 'f1-score': 0.9480259599783667, 'support': 516}
 
time = 0.71 secondes

Val loss 1.1103900372982025 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 17/40
time = 21.46 secondes

Train loss 0.08349637556768191 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 0.71 secondes

Val loss 1.9499627649784088 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 18/40
time = 21.29 secondes

Train loss 0.08639744131880545 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 0.71 secondes

Val loss 2.673064410686493 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 19/40
time = 21.19 secondes

Train loss 0.44259410772726615 accuracy 0.8992248177528381 macro_avg {'precision': 0.9046977517277579, 'recall': 0.8759650862279148, 'f1-score': 0.8872756604154064, 'support': 516} weighted_avg {'precision': 0.9006917812910493, 'recall': 0.8992248062015504, 'f1-score': 0.8973755336394091, 'support': 516}
 
time = 0.71 secondes

Val loss 1.1352142840623856 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 20/40
time = 21.25 secondes

Train loss 0.14318476627478516 accuracy 0.9728682041168213 macro_avg {'precision': 0.9740249031087655, 'recall': 0.9671830047299383, 'f1-score': 0.9704360921948665, 'support': 516} weighted_avg {'precision': 0.9729583484351338, 'recall': 0.9728682170542635, 'f1-score': 0.9727696173978015, 'support': 516}
 
time = 0.71 secondes

Val loss 1.7272545993328094 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 21/40
time = 21.18 secondes

Train loss 0.052866000238502624 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 0.71 secondes

Val loss 2.0143634378910065 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 22/40
time = 21.21 secondes

Train loss 0.07319361391957059 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 0.70 secondes

Val loss 1.497203916311264 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 23/40
time = 21.23 secondes

Train loss 0.10046575150353777 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 0.71 secondes

Val loss 1.9439382553100586 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 24/40
time = 21.26 secondes

Train loss 0.2591613863046267 accuracy 0.9457364082336426 macro_avg {'precision': 0.9362281433450321, 'recall': 0.9505225687954099, 'f1-score': 0.9422957105200096, 'support': 516} weighted_avg {'precision': 0.9485024823306347, 'recall': 0.9457364341085271, 'f1-score': 0.9461733513896088, 'support': 516}
 
time = 0.71 secondes

Val loss 2.0861687064170837 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 25/40
time = 21.24 secondes

Train loss 0.08510304181960016 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 0.70 secondes

Val loss 1.2452519834041595 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 26/40
time = 21.23 secondes

Train loss 0.0205511293628881 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 0.71 secondes

Val loss 1.4258800446987152 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 27/40
time = 21.26 secondes

Train loss 0.01957762011884232 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 0.71 secondes

Val loss 2.4672626852989197 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 28/40
time = 21.18 secondes

Train loss 0.0942270784693061 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 0.71 secondes

Val loss 1.5506331771612167 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 29/40
time = 21.27 secondes

Train loss 0.045179651982228584 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.71 secondes

Val loss 1.437577873468399 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 30/40
time = 21.28 secondes

Train loss 0.009855636771438489 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 0.71 secondes

Val loss 1.6475042402744293 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 31/40
time = 21.40 secondes

Train loss 0.0622751542435832 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.71 secondes

Val loss 2.155895233154297 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 32/40
time = 21.21 secondes

Train loss 0.0001532266956708168 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.71 secondes

Val loss 1.1164403557777405 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 33/40
time = 21.26 secondes

Train loss 0.05320279331102607 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 0.72 secondes

Val loss 1.369447499513626 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 34/40
time = 21.25 secondes

Train loss 0.03694808256334385 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 0.71 secondes

Val loss 1.4656716883182526 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 35/40
time = 21.17 secondes

Train loss 0.00015235680025811732 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.71 secondes

Val loss 1.0457758828997612 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 36/40
time = 21.26 secondes

Train loss 0.03293324336294917 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 0.71 secondes

Val loss 1.3743610084056854 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 37/40
time = 21.22 secondes

Train loss 0.00016935009361160073 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.71 secondes

Val loss 1.826458990573883 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 38/40
time = 21.26 secondes

Train loss 0.010813907186357856 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 0.71 secondes

Val loss 1.9328604936599731 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 39/40
time = 21.21 secondes

Train loss 7.232984187959863e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.71 secondes

Val loss 1.8964862823486328 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 40/40
time = 21.25 secondes

Train loss 7.255995219703905e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 0.71 secondes

Val loss 1.7974223494529724 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 32 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}

average train time 21.248727929592132

average val time 0.7072337210178375
 
time = 0.74 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_1
----------
Epoch 1/40
time = 94.52 secondes

Train loss 0.6157084513794292 accuracy 0.7054263353347778 macro_avg {'precision': 0.7451322182249749, 'recall': 0.6074313671309917, 'f1-score': 0.5943647986098182, 'support': 516} weighted_avg {'precision': 0.7309658052795288, 'recall': 0.7054263565891473, 'f1-score': 0.6527749513248726, 'support': 516}
 
time = 1.58 secondes

Val loss 0.5171730667352676 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 2/40
time = 93.42 secondes

Train loss 0.4266997187426596 accuracy 0.8255813717842102 macro_avg {'precision': 0.8119430906316152, 'recall': 0.8089820067291906, 'f1-score': 0.8104025475626684, 'support': 516} weighted_avg {'precision': 0.824854019097252, 'recall': 0.8255813953488372, 'f1-score': 0.8251655365053805, 'support': 516}
 
time = 1.58 secondes

Val loss 0.5023626461625099 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 3/40
time = 93.37 secondes

Train loss 0.27758084576238284 accuracy 0.9069767594337463 macro_avg {'precision': 0.9008516713434747, 'recall': 0.8970466329665329, 'f1-score': 0.8988813587000898, 'support': 516} weighted_avg {'precision': 0.9066500736344427, 'recall': 0.9069767441860465, 'f1-score': 0.9067549528028697, 'support': 516}
 
time = 1.58 secondes

Val loss 0.37843305617570877 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 4/40
time = 94.06 secondes

Train loss 0.29547187369881256 accuracy 0.8914728760719299 macro_avg {'precision': 0.8872894847088395, 'recall': 0.8756562586349821, 'f1-score': 0.880860888925538, 'support': 516} weighted_avg {'precision': 0.8908680416857461, 'recall': 0.8914728682170543, 'f1-score': 0.8906459607397933, 'support': 516}
 
time = 1.59 secondes

Val loss 0.831359013915062 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 5/40
time = 94.55 secondes

Train loss 0.17918172473031463 accuracy 0.9418604373931885 macro_avg {'precision': 0.9389553487914144, 'recall': 0.9347886156396794, 'f1-score': 0.9368008491875561, 'support': 516} weighted_avg {'precision': 0.941705525578953, 'recall': 0.9418604651162791, 'f1-score': 0.9417218455017936, 'support': 516}
 
time = 1.54 secondes

Val loss 0.5692940205335617 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 6/40
time = 94.51 secondes

Train loss 0.2123442766341296 accuracy 0.9302325248718262 macro_avg {'precision': 0.9282529051937072, 'recall': 0.9198998748435545, 'f1-score': 0.9237926451041205, 'support': 516} weighted_avg {'precision': 0.9300320869551473, 'recall': 0.9302325581395349, 'f1-score': 0.9298890961109795, 'support': 516}
 
time = 1.54 secondes

Val loss 0.6123411059379578 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 7/40
time = 93.81 secondes

Train loss 0.12013260482556441 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 1.58 secondes

Val loss 1.0508247464895248 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 8/40
time = 94.99 secondes

Train loss 0.3439550475979393 accuracy 0.9166666865348816 macro_avg {'precision': 0.9159608792095181, 'recall': 0.9023373372559855, 'f1-score': 0.9084014845333587, 'support': 516} weighted_avg {'precision': 0.9165574376554412, 'recall': 0.9166666666666666, 'f1-score': 0.9159734578425828, 'support': 516}
 
time = 1.54 secondes

Val loss 1.4383622407913208 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 9/40
time = 94.80 secondes

Train loss 0.1593900362495333 accuracy 0.9651162624359131 macro_avg {'precision': 0.9655149666034468, 'recall': 0.9587958974692392, 'f1-score': 0.9619892613933996, 'support': 516} weighted_avg {'precision': 0.9651473456308333, 'recall': 0.9651162790697675, 'f1-score': 0.9649895080828875, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5422360599040985 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 10/40
time = 93.77 secondes

Train loss 0.10147050925121276 accuracy 0.9728682041168213 macro_avg {'precision': 0.9766511674416278, 'recall': 0.9648749248248623, 'f1-score': 0.9702901888530631, 'support': 516} weighted_avg {'precision': 0.9733352479662837, 'recall': 0.9728682170542635, 'f1-score': 0.9726986099357636, 'support': 516}
 
time = 1.58 secondes

Val loss 0.9001774340867996 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 11/40
time = 94.95 secondes

Train loss 0.16123345125974578 accuracy 0.963178277015686 macro_avg {'precision': 0.9558319039451115, 'recall': 0.966508460250638, 'f1-score': 0.9606415223107649, 'support': 516} weighted_avg {'precision': 0.9645251328555409, 'recall': 0.9631782945736435, 'f1-score': 0.9633913059850301, 'support': 516}
 
time = 1.54 secondes

Val loss 0.7926241345703602 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 12/40
time = 94.66 secondes

Train loss 0.09664340029033183 accuracy 0.9670542478561401 macro_avg {'precision': 0.9599294835143892, 'recall': 0.9707020138809876, 'f1-score': 0.9647845199622633, 'support': 516} weighted_avg {'precision': 0.9683604732420003, 'recall': 0.9670542635658915, 'f1-score': 0.967244852723448, 'support': 516}
 
time = 1.54 secondes

Val loss 0.547138391295448 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 13/40
time = 94.78 secondes

Train loss 0.13278100122944592 accuracy 0.963178277015686 macro_avg {'precision': 0.9694767441860466, 'recall': 0.951505940867643, 'f1-score': 0.9594217054969434, 'support': 516} weighted_avg {'precision': 0.9642768613665045, 'recall': 0.9631782945736435, 'f1-score': 0.9628193847892454, 'support': 516}
 
time = 1.54 secondes

Val loss 1.119183138012886 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 94.22 secondes

Train loss 0.15681040822528303 accuracy 0.963178277015686 macro_avg {'precision': 0.9547360787034118, 'recall': 0.9688165401557141, 'f1-score': 0.9608039116129006, 'support': 516} weighted_avg {'precision': 0.9654396023960269, 'recall': 0.9631782945736435, 'f1-score': 0.9634587335060146, 'support': 516}
 
time = 1.58 secondes

Val loss 1.0596434623003006 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 15/40
time = 93.84 secondes

Train loss 0.2384206335480099 accuracy 0.9515503644943237 macro_avg {'precision': 0.9435391652372784, 'recall': 0.9539277993595892, 'f1-score': 0.9482125293562697, 'support': 516} weighted_avg {'precision': 0.953019111696163, 'recall': 0.9515503875968992, 'f1-score': 0.9518306657697765, 'support': 516}
 
time = 1.57 secondes

Val loss 1.5036740750074387 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 16/40
time = 93.45 secondes

Train loss 0.26107272030044854 accuracy 0.9244186282157898 macro_avg {'precision': 0.9223622099594442, 'recall': 0.913032524421761, 'f1-score': 0.9173399601569079, 'support': 516} weighted_avg {'precision': 0.9241872602483444, 'recall': 0.9244186046511628, 'f1-score': 0.923996698687929, 'support': 516}
 
time = 1.57 secondes

Val loss 0.7615621015429497 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 17/40
time = 94.13 secondes

Train loss 0.14904424310379633 accuracy 0.9593023061752319 macro_avg {'precision': 0.9555007784120395, 'recall': 0.956544706857598, 'f1-score': 0.9560182648401826, 'support': 516} weighted_avg {'precision': 0.9593566333981004, 'recall': 0.9593023255813954, 'f1-score': 0.959325616792326, 'support': 516}
 
time = 1.58 secondes

Val loss 1.4985910952091217 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 18/40
time = 93.64 secondes

Train loss 0.019797024057797073 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.57 secondes

Val loss 1.5581448674201965 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 19/40
time = 93.99 secondes

Train loss 0.11647040051034172 accuracy 0.9689922332763672 macro_avg {'precision': 0.9605911330049262, 'recall': 0.9756838905775076, 'f1-score': 0.9670261202971483, 'support': 516} weighted_avg {'precision': 0.9714362088058961, 'recall': 0.9689922480620154, 'f1-score': 0.9692419150797764, 'support': 516}
 
time = 1.56 secondes

Val loss 1.5293864607810974 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 20/40
time = 93.75 secondes

Train loss 0.2281444943346838 accuracy 0.963178277015686 macro_avg {'precision': 0.9679874974793305, 'recall': 0.952659980820181, 'f1-score': 0.9595262373519492, 'support': 516} weighted_avg {'precision': 0.9639225759757141, 'recall': 0.9631782945736435, 'f1-score': 0.9628719930002111, 'support': 516}
 
time = 1.57 secondes

Val loss 1.9721994421997806 accuracy 0.734375 macro_avg {'precision': 0.7831389183457051, 'recall': 0.7702429149797572, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.815648197242842, 'recall': 0.734375, 'f1-score': 0.7314503303156348, 'support': 64}
 
----------
Epoch 21/40
time = 95.18 secondes

Train loss 0.2434434929450755 accuracy 0.9515503644943237 macro_avg {'precision': 0.9412231559290383, 'recall': 0.9608520390748175, 'f1-score': 0.9488288145342033, 'support': 516} weighted_avg {'precision': 0.9564988527710827, 'recall': 0.9515503875968992, 'f1-score': 0.9520764059199412, 'support': 516}
 
time = 1.54 secondes

Val loss 1.6896581947803497 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 22/40
time = 94.04 secondes

Train loss 0.0009537009120156819 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.3411813527345657 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 23/40
time = 94.17 secondes

Train loss 0.11723236754275576 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.58 secondes

Val loss 2.103453427553177 accuracy 0.75 macro_avg {'precision': 0.8095238095238095, 'recall': 0.7894736842105263, 'f1-score': 0.7490196078431373, 'support': 64} weighted_avg {'precision': 0.8452380952380952, 'recall': 0.75, 'f1-score': 0.746078431372549, 'support': 64}
 
----------
Epoch 24/40
time = 94.48 secondes

Train loss 0.3269967606514304 accuracy 0.9379844665527344 macro_avg {'precision': 0.926974387579603, 'recall': 0.9479056612974011, 'f1-score': 0.9346835443037975, 'support': 516} weighted_avg {'precision': 0.9443458921719228, 'recall': 0.937984496124031, 'f1-score': 0.9387243646354627, 'support': 516}
 
time = 1.54 secondes

Val loss 1.0803547439863905 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 25/40
time = 94.72 secondes

Train loss 0.11288700416193795 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.54 secondes

Val loss 0.8297417813446373 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 26/40
time = 94.00 secondes

Train loss 0.013111456256769034 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.58 secondes

Val loss 0.9176444001495838 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 27/40
time = 94.05 secondes

Train loss 0.03330608095601554 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.57 secondes

Val loss 2.2797267735004425 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 28/40
time = 94.00 secondes

Train loss 0.2584717126290233 accuracy 0.963178277015686 macro_avg {'precision': 0.9542797888386123, 'recall': 0.9699705801082522, 'f1-score': 0.9608827319844713, 'support': 516} weighted_avg {'precision': 0.9659796760087458, 'recall': 0.9631782945736435, 'f1-score': 0.9634904910857709, 'support': 516}
 
time = 1.58 secondes

Val loss 1.2401527389883995 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 29/40
time = 94.33 secondes

Train loss 0.060758428021499916 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.58 secondes

Val loss 1.1977751031517982 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 30/40
time = 93.53 secondes

Train loss 0.13504788962712733 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.58 secondes

Val loss 1.5974779278039932 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 31/40
time = 94.71 secondes

Train loss 0.0534163561878262 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.56 secondes

Val loss 2.202148288488388 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 32/40
time = 94.02 secondes

Train loss 0.09501564236129387 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.58 secondes

Val loss 1.250752657026169 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 33/40
time = 94.23 secondes

Train loss 0.04936381765869693 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.58 secondes

Val loss 1.4794599459855817 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 34/40
time = 94.71 secondes

Train loss 0.0014649155158567187 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5211873054504395 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 35/40
time = 95.12 secondes

Train loss 0.08999644970445485 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.58 secondes

Val loss 1.7890346348285675 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 36/40
time = 93.75 secondes

Train loss 7.373102804801117e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.383051112294197 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 37/40
time = 93.69 secondes

Train loss 0.03793042387824795 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.58 secondes

Val loss 1.1988167184499616 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 38/40
time = 93.94 secondes

Train loss 7.318135590828729e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.9029316753149033 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 39/40
time = 93.89 secondes

Train loss 0.01873425297713821 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.58 secondes

Val loss 1.7314420863986015 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 40/40
time = 95.04 secondes

Train loss 6.37193875401422e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5568330772221088 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 3 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 94.2197026014328

average val time 1.5651475191116333
 
time = 1.80 secondes

test_accuracy 0.8461538553237915 macro_avg {'precision': 0.8514492753623188, 'recall': 0.830896686159844, 'f1-score': 0.8374999999999999, 'support': 65} weighted_avg {'precision': 0.8483835005574136, 'recall': 0.8461538461538461, 'f1-score': 0.8438461538461538, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 1; 79.20 GiB total capacity; 75.91 GiB already allocated; 48.31 MiB free; 77.13 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 1; 79.20 GiB total capacity; 73.26 GiB already allocated; 48.31 MiB free; 77.13 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 1; 79.20 GiB total capacity; 75.62 GiB already allocated; 332.31 MiB free; 76.86 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_1
----------
Epoch 1/40
time = 490.97 secondes

Train loss 1.2095349352672298 accuracy 0.6515419483184814 macro_avg {'precision': 0.6685516469474122, 'recall': 0.63805323204182, 'f1-score': 0.6388412482289538, 'support': 10182} weighted_avg {'precision': 0.6730376265796312, 'recall': 0.6515419367511295, 'f1-score': 0.6504528141140393, 'support': 10182}
 
time = 14.27 secondes

Val loss 0.5685036323020156 accuracy 0.833038866519928 macro_avg {'precision': 0.8315939187000835, 'recall': 0.8219580747058414, 'f1-score': 0.8115508439388817, 'support': 1132} weighted_avg {'precision': 0.8338985222600459, 'recall': 0.8330388692579506, 'f1-score': 0.8208262234217159, 'support': 1132}
 
----------
Epoch 2/40
time = 480.78 secondes

Train loss 0.4152351686061364 accuracy 0.8792968392372131 macro_avg {'precision': 0.872431458993932, 'recall': 0.8708299751975025, 'f1-score': 0.8706536172915543, 'support': 10182} weighted_avg {'precision': 0.8783103227095566, 'recall': 0.8792967982714595, 'f1-score': 0.8780523977397158, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.5028718608156056 accuracy 0.8674911856651306 macro_avg {'precision': 0.8722632814458675, 'recall': 0.865690022253145, 'f1-score': 0.8605571264514138, 'support': 1132} weighted_avg {'precision': 0.8751616041278513, 'recall': 0.8674911660777385, 'f1-score': 0.8633541926899924, 'support': 1132}
 
----------
Epoch 3/40
time = 483.44 secondes

Train loss 0.24911536447399732 accuracy 0.9312512278556824 macro_avg {'precision': 0.928053102701646, 'recall': 0.9266516741734925, 'f1-score': 0.9270846200010926, 'support': 10182} weighted_avg {'precision': 0.9310945470791558, 'recall': 0.931251227656649, 'f1-score': 0.9309458129912127, 'support': 10182}
 
time = 13.95 secondes

Val loss 0.49024899439020475 accuracy 0.8886925578117371 macro_avg {'precision': 0.8962544887615174, 'recall': 0.8915831834610408, 'f1-score': 0.886735695788858, 'support': 1132} weighted_avg {'precision': 0.8963038193264536, 'recall': 0.8886925795053003, 'f1-score': 0.8841487315576548, 'support': 1132}
 
----------
Epoch 4/40
time = 484.18 secondes

Train loss 0.1803103933912034 accuracy 0.9524651765823364 macro_avg {'precision': 0.9502452410290289, 'recall': 0.9499782876660241, 'f1-score': 0.9500659431550265, 'support': 10182} weighted_avg {'precision': 0.9525455942875651, 'recall': 0.9524651345511688, 'f1-score': 0.9524604233525912, 'support': 10182}
 
time = 13.95 secondes

Val loss 0.4843599525195035 accuracy 0.9054770469665527 macro_avg {'precision': 0.9079477873555772, 'recall': 0.9058314003135773, 'f1-score': 0.9053817966931179, 'support': 1132} weighted_avg {'precision': 0.9064225833599889, 'recall': 0.9054770318021201, 'f1-score': 0.904409939075008, 'support': 1132}
 
----------
Epoch 5/40
time = 485.12 secondes

Train loss 0.16582933633611646 accuracy 0.9563936591148376 macro_avg {'precision': 0.9549917522959029, 'recall': 0.9547488094540462, 'f1-score': 0.9548153419958167, 'support': 10182} weighted_avg {'precision': 0.9564211951905023, 'recall': 0.9563936358279317, 'f1-score': 0.9563535375034581, 'support': 10182}
 
time = 13.94 secondes

Val loss 0.47067145360666524 accuracy 0.9045936465263367 macro_avg {'precision': 0.9089381563093456, 'recall': 0.9049143632474937, 'f1-score': 0.9054317891380034, 'support': 1132} weighted_avg {'precision': 0.9077910131247513, 'recall': 0.9045936395759717, 'f1-score': 0.9046948334103795, 'support': 1132}
 
----------
Epoch 6/40
time = 480.81 secondes

Train loss 0.14168268542559861 accuracy 0.9654292464256287 macro_avg {'precision': 0.9647424270588703, 'recall': 0.9645806063359348, 'f1-score': 0.9646309903912401, 'support': 10182} weighted_avg {'precision': 0.9654635683554086, 'recall': 0.9654291887644864, 'f1-score': 0.9654168251656642, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.5802012753917206 accuracy 0.8966431021690369 macro_avg {'precision': 0.9024406531764979, 'recall': 0.8961042918516302, 'f1-score': 0.8968604727244056, 'support': 1132} weighted_avg {'precision': 0.9027094722161273, 'recall': 0.8966431095406361, 'f1-score': 0.8973679043771429, 'support': 1132}
 
----------
Epoch 7/40
time = 484.77 secondes

Train loss 0.1333853766458106 accuracy 0.9678845405578613 macro_avg {'precision': 0.9664140755108399, 'recall': 0.9668598327402618, 'f1-score': 0.9665704548480148, 'support': 10182} weighted_avg {'precision': 0.9680314286571735, 'recall': 0.9678845020624631, 'f1-score': 0.9679059239202409, 'support': 10182}
 
time = 13.94 secondes

Val loss 0.6037614560164642 accuracy 0.8966431021690369 macro_avg {'precision': 0.9048991229107106, 'recall': 0.899993857614034, 'f1-score': 0.898261666005839, 'support': 1132} weighted_avg {'precision': 0.9053577776680873, 'recall': 0.8966431095406361, 'f1-score': 0.8961958794870989, 'support': 1132}
 
----------
Epoch 8/40
time = 481.30 secondes

Train loss 0.1176286344941405 accuracy 0.972304105758667 macro_avg {'precision': 0.9717501952826846, 'recall': 0.9718272775764681, 'f1-score': 0.9717771043423594, 'support': 10182} weighted_avg {'precision': 0.9723817275544185, 'recall': 0.9723040659988215, 'f1-score': 0.9723309285830779, 'support': 10182}
 
time = 13.94 secondes

Val loss 0.7307839619268788 accuracy 0.898409903049469 macro_avg {'precision': 0.9037348406331243, 'recall': 0.8995881164992466, 'f1-score': 0.8978077697587873, 'support': 1132} weighted_avg {'precision': 0.9062183138518456, 'recall': 0.8984098939929329, 'f1-score': 0.8984524644359351, 'support': 1132}
 
----------
Epoch 9/40
time = 483.80 secondes

Train loss 0.11762729975820908 accuracy 0.9737772941589355 macro_avg {'precision': 0.97250142808763, 'recall': 0.9725585400285273, 'f1-score': 0.972502587215681, 'support': 10182} weighted_avg {'precision': 0.9738718563934775, 'recall': 0.9737772539776075, 'f1-score': 0.9737972185344957, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.6353382379838108 accuracy 0.8931095600128174 macro_avg {'precision': 0.8990881354311515, 'recall': 0.8939444722759206, 'f1-score': 0.8944117776088888, 'support': 1132} weighted_avg {'precision': 0.8957556692320734, 'recall': 0.8931095406360424, 'f1-score': 0.8924268620425106, 'support': 1132}
 
----------
Epoch 10/40
time = 480.00 secondes

Train loss 0.10227696101412943 accuracy 0.9773129224777222 macro_avg {'precision': 0.976900956921835, 'recall': 0.9773228801915324, 'f1-score': 0.9770800891802942, 'support': 10182} weighted_avg {'precision': 0.9773835437904588, 'recall': 0.9773129051266942, 'f1-score': 0.9773194302438769, 'support': 10182}
 
time = 13.93 secondes

Val loss 0.5773125469777242 accuracy 0.9143109321594238 macro_avg {'precision': 0.9199820655905773, 'recall': 0.9150732619719836, 'f1-score': 0.9159359983860185, 'support': 1132} weighted_avg {'precision': 0.9191655351533412, 'recall': 0.9143109540636042, 'f1-score': 0.9151784256749407, 'support': 1132}
 
----------
Epoch 11/40
time = 481.69 secondes

Train loss 0.10203222776203909 accuracy 0.9789825677871704 macro_avg {'precision': 0.9783175637020343, 'recall': 0.9785316372830385, 'f1-score': 0.978401674825373, 'support': 10182} weighted_avg {'precision': 0.9790409689874976, 'recall': 0.9789825181693184, 'f1-score': 0.9789891597874298, 'support': 10182}
 
time = 13.91 secondes

Val loss 0.6053006711123269 accuracy 0.9116607904434204 macro_avg {'precision': 0.9153417148477956, 'recall': 0.9151268386727838, 'f1-score': 0.9121529938378726, 'support': 1132} weighted_avg {'precision': 0.9174528303622008, 'recall': 0.911660777385159, 'f1-score': 0.9112030426127357, 'support': 1132}
 
----------
Epoch 12/40
time = 483.34 secondes

Train loss 0.11233933556161428 accuracy 0.9780986309051514 macro_avg {'precision': 0.9773278651817554, 'recall': 0.9777585188889508, 'f1-score': 0.977477945794494, 'support': 10182} weighted_avg {'precision': 0.9782016306877043, 'recall': 0.9780986053820467, 'f1-score': 0.9780927749574382, 'support': 10182}
 
time = 14.10 secondes

Val loss 0.6445316029536295 accuracy 0.9143109321594238 macro_avg {'precision': 0.9146188402063199, 'recall': 0.9167802403468285, 'f1-score': 0.9140629719135707, 'support': 1132} weighted_avg {'precision': 0.9191048315933275, 'recall': 0.9143109540636042, 'f1-score': 0.9151020424584756, 'support': 1132}
 
----------
Epoch 13/40
time = 484.10 secondes

Train loss 0.08856058574859232 accuracy 0.9827145934104919 macro_avg {'precision': 0.9821701004300769, 'recall': 0.9823483256810308, 'f1-score': 0.9822357339364404, 'support': 10182} weighted_avg {'precision': 0.9827479718462596, 'recall': 0.9827145943822432, 'f1-score': 0.9827077645346748, 'support': 10182}
 
time = 13.93 secondes

Val loss 0.6341866116370665 accuracy 0.9116607904434204 macro_avg {'precision': 0.9173081583986947, 'recall': 0.9130435816133874, 'f1-score': 0.9130333482296151, 'support': 1132} weighted_avg {'precision': 0.9165767738303792, 'recall': 0.911660777385159, 'f1-score': 0.9122004356513492, 'support': 1132}
 
----------
Epoch 14/40
time = 479.87 secondes

Train loss 0.09564918732660142 accuracy 0.981634259223938 macro_avg {'precision': 0.9812139061685103, 'recall': 0.9811492379689039, 'f1-score': 0.9811653172608608, 'support': 10182} weighted_avg {'precision': 0.9816756531682345, 'recall': 0.9816342565311333, 'f1-score': 0.9816389101769484, 'support': 10182}
 
time = 13.92 secondes

Val loss 0.6447363142520567 accuracy 0.9116607904434204 macro_avg {'precision': 0.9153105231510736, 'recall': 0.9122879210172627, 'f1-score': 0.9121386414215451, 'support': 1132} weighted_avg {'precision': 0.9147256921905368, 'recall': 0.911660777385159, 'f1-score': 0.9117979501327695, 'support': 1132}
 
----------
Epoch 15/40
time = 481.99 secondes

Train loss 0.07486303901809083 accuracy 0.9853663444519043 macro_avg {'precision': 0.9851301753487508, 'recall': 0.9849926691348362, 'f1-score': 0.9850466832168749, 'support': 10182} weighted_avg {'precision': 0.9853900808007976, 'recall': 0.9853663327440582, 'f1-score': 0.9853637157617441, 'support': 10182}
 
time = 13.91 secondes

Val loss 0.7090041818227176 accuracy 0.9019434452056885 macro_avg {'precision': 0.9096757149748445, 'recall': 0.9059228558490731, 'f1-score': 0.9048133541387837, 'support': 1132} weighted_avg {'precision': 0.9078103319341458, 'recall': 0.9019434628975265, 'f1-score': 0.9014620186321347, 'support': 1132}
 
----------
Epoch 16/40
time = 480.23 secondes

Train loss 0.07538650252573866 accuracy 0.9846788644790649 macro_avg {'precision': 0.9844247533266328, 'recall': 0.9840102293466189, 'f1-score': 0.9841896081063229, 'support': 10182} weighted_avg {'precision': 0.9846967859242386, 'recall': 0.9846788450206246, 'f1-score': 0.9846614300877818, 'support': 10182}
 
time = 13.93 secondes

Val loss 0.6005720572092555 accuracy 0.9151943325996399 macro_avg {'precision': 0.9165589078334824, 'recall': 0.9192056818558088, 'f1-score': 0.9166983780525049, 'support': 1132} weighted_avg {'precision': 0.9167373432162497, 'recall': 0.9151943462897526, 'f1-score': 0.9146525316282623, 'support': 1132}
 
----------
Epoch 17/40
time = 484.03 secondes

Train loss 0.08628783830699631 accuracy 0.9832056760787964 macro_avg {'precision': 0.9831419422104306, 'recall': 0.9830111883073975, 'f1-score': 0.9830521432503077, 'support': 10182} weighted_avg {'precision': 0.9832194955674366, 'recall': 0.9832056570418385, 'f1-score': 0.9831876491111473, 'support': 10182}
 
time = 13.90 secondes

Val loss 0.764296146247636 accuracy 0.8975265026092529 macro_avg {'precision': 0.9124401620683773, 'recall': 0.9037389475519702, 'f1-score': 0.9034790584258543, 'support': 1132} weighted_avg {'precision': 0.9114079681778882, 'recall': 0.8975265017667845, 'f1-score': 0.8993813998332514, 'support': 1132}
 
----------
Epoch 18/40
time = 483.09 secondes

Train loss 0.08057403537138015 accuracy 0.9852681756019592 macro_avg {'precision': 0.9845412893009259, 'recall': 0.9843492852890379, 'f1-score': 0.9843879093515373, 'support': 10182} weighted_avg {'precision': 0.9853694906558582, 'recall': 0.985268120212139, 'f1-score': 0.9852663371499152, 'support': 10182}
 
time = 13.94 secondes

Val loss 0.6829312344105885 accuracy 0.9125441908836365 macro_avg {'precision': 0.9173457271235306, 'recall': 0.9155131615933219, 'f1-score': 0.9137958291060514, 'support': 1132} weighted_avg {'precision': 0.9187047273533061, 'recall': 0.9125441696113075, 'f1-score': 0.9130504874467967, 'support': 1132}
 
----------
Epoch 19/40
time = 477.12 secondes

Train loss 0.06447775299752286 accuracy 0.9879198670387268 macro_avg {'precision': 0.9872212015815609, 'recall': 0.9870461117058923, 'f1-score': 0.9871214651161561, 'support': 10182} weighted_avg {'precision': 0.9879397288426011, 'recall': 0.987919858573954, 'f1-score': 0.9879180475095339, 'support': 10182}
 
time = 13.92 secondes

Val loss 0.712277651747851 accuracy 0.9143109321594238 macro_avg {'precision': 0.9206083682602278, 'recall': 0.9162907998077225, 'f1-score': 0.9152241408933259, 'support': 1132} weighted_avg {'precision': 0.9197980525791353, 'recall': 0.9143109540636042, 'f1-score': 0.9134116203654021, 'support': 1132}
 
----------
Epoch 20/40
time = 482.26 secondes

Train loss 0.07238084454550359 accuracy 0.9879198670387268 macro_avg {'precision': 0.9875481346616738, 'recall': 0.9876122313671581, 'f1-score': 0.9875623638690477, 'support': 10182} weighted_avg {'precision': 0.987956046508221, 'recall': 0.987919858573954, 'f1-score': 0.9879209563794609, 'support': 10182}
 
time = 13.96 secondes

Val loss 0.5772143342840882 accuracy 0.9196113348007202 macro_avg {'precision': 0.9208264474572594, 'recall': 0.9212058273854027, 'f1-score': 0.9203094456300024, 'support': 1132} weighted_avg {'precision': 0.9218280983844876, 'recall': 0.9196113074204947, 'f1-score': 0.9199858392740003, 'support': 1132}
 
----------
Epoch 21/40
time = 483.43 secondes

Train loss 0.05669674789784308 accuracy 0.9892948865890503 macro_avg {'precision': 0.9888260623652801, 'recall': 0.9887982469971751, 'f1-score': 0.9888013260974894, 'support': 10182} weighted_avg {'precision': 0.9893264455865428, 'recall': 0.9892948340208211, 'f1-score': 0.9892995881913295, 'support': 10182}
 
time = 13.93 secondes

Val loss 0.7909916051991184 accuracy 0.9037102460861206 macro_avg {'precision': 0.9148197687014499, 'recall': 0.9063737694080333, 'f1-score': 0.9078322588452034, 'support': 1132} weighted_avg {'precision': 0.9126750317448317, 'recall': 0.9037102473498233, 'f1-score': 0.905196978971592, 'support': 1132}
 
----------
Epoch 22/40
time = 481.89 secondes

Train loss 0.06037010665345784 accuracy 0.9892948865890503 macro_avg {'precision': 0.9892586435071739, 'recall': 0.9892026814715967, 'f1-score': 0.9892238219729691, 'support': 10182} weighted_avg {'precision': 0.9893144328230704, 'recall': 0.9892948340208211, 'f1-score': 0.9892977717926067, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.7548885409722087 accuracy 0.9090105891227722 macro_avg {'precision': 0.9137162519950726, 'recall': 0.9070848518913911, 'f1-score': 0.9076034932711329, 'support': 1132} weighted_avg {'precision': 0.9122648702486297, 'recall': 0.9090106007067138, 'f1-score': 0.9081419871615355, 'support': 1132}
 
----------
Epoch 23/40
time = 479.50 secondes

Train loss 0.04563106446654828 accuracy 0.9910627007484436 macro_avg {'precision': 0.9902745335259112, 'recall': 0.9905020851396256, 'f1-score': 0.9903731421861253, 'support': 10182} weighted_avg {'precision': 0.9910904742949965, 'recall': 0.9910626595953643, 'f1-score': 0.991064520170915, 'support': 10182}
 
time = 13.91 secondes

Val loss 0.6408776318011674 accuracy 0.916961133480072 macro_avg {'precision': 0.9234435329535922, 'recall': 0.9180891726813849, 'f1-score': 0.9194424561989376, 'support': 1132} weighted_avg {'precision': 0.9212059233257384, 'recall': 0.9169611307420494, 'f1-score': 0.9176370980508501, 'support': 1132}
 
----------
Epoch 24/40
time = 483.71 secondes

Train loss 0.049187312726595905 accuracy 0.9916519522666931 macro_avg {'precision': 0.991721812542055, 'recall': 0.9917268474920423, 'f1-score': 0.9917018472742314, 'support': 10182} weighted_avg {'precision': 0.9916938755930803, 'recall': 0.9916519347868789, 'f1-score': 0.9916504932596305, 'support': 10182}
 
time = 13.94 secondes

Val loss 0.7768729687977868 accuracy 0.9116607904434204 macro_avg {'precision': 0.9158528313223385, 'recall': 0.9134684277121365, 'f1-score': 0.9135459411503234, 'support': 1132} weighted_avg {'precision': 0.9160088618168095, 'recall': 0.911660777385159, 'f1-score': 0.9126277640826786, 'support': 1132}
 
----------
Epoch 25/40
time = 482.53 secondes

Train loss 0.050053995878829874 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913512616094099, 'recall': 0.991471409305146, 'f1-score': 0.9913987175597567, 'support': 10182} weighted_avg {'precision': 0.9914572289796563, 'recall': 0.9914555097230406, 'f1-score': 0.991444295219198, 'support': 10182}
 
time = 13.90 secondes

Val loss 0.8523483267125697 accuracy 0.9037102460861206 macro_avg {'precision': 0.916396926421795, 'recall': 0.9045448014343866, 'f1-score': 0.9064173854868287, 'support': 1132} weighted_avg {'precision': 0.9159907345890624, 'recall': 0.9037102473498233, 'f1-score': 0.9058851027115987, 'support': 1132}
 
----------
Epoch 26/40
time = 480.56 secondes

Train loss 0.05211095589052157 accuracy 0.9907680749893188 macro_avg {'precision': 0.9902564522253746, 'recall': 0.9906836271824615, 'f1-score': 0.9904442729042732, 'support': 10182} weighted_avg {'precision': 0.9908434757090278, 'recall': 0.9907680219996071, 'f1-score': 0.9907823579594968, 'support': 10182}
 
time = 14.14 secondes

Val loss 0.8332384658556613 accuracy 0.8975265026092529 macro_avg {'precision': 0.9036112808294832, 'recall': 0.8989245690769175, 'f1-score': 0.8980944016015757, 'support': 1132} weighted_avg {'precision': 0.902134079031678, 'recall': 0.8975265017667845, 'f1-score': 0.8964988153851214, 'support': 1132}
 
----------
Epoch 27/40
time = 484.48 secondes

Train loss 0.0421181912171169 accuracy 0.9921430349349976 macro_avg {'precision': 0.9923264682562237, 'recall': 0.9923486870019241, 'f1-score': 0.9923316313788273, 'support': 10182} weighted_avg {'precision': 0.9921465170954478, 'recall': 0.9921429974464742, 'f1-score': 0.992138549552221, 'support': 10182}
 
time = 13.90 secondes

Val loss 0.7310696348975679 accuracy 0.916077733039856 macro_avg {'precision': 0.9178084220659869, 'recall': 0.9196946394153839, 'f1-score': 0.9168958316516391, 'support': 1132} weighted_avg {'precision': 0.9191631800107342, 'recall': 0.916077738515901, 'f1-score': 0.9157432774241623, 'support': 1132}
 
----------
Epoch 28/40
time = 484.60 secondes

Train loss 0.04489328676376306 accuracy 0.9925358891487122 macro_avg {'precision': 0.992688660229731, 'recall': 0.9925899518752198, 'f1-score': 0.9926255557109535, 'support': 10182} weighted_avg {'precision': 0.9925541374963746, 'recall': 0.9925358475741505, 'f1-score': 0.9925310787946837, 'support': 10182}
 
time = 13.92 secondes

Val loss 0.7319078465435256 accuracy 0.916077733039856 macro_avg {'precision': 0.9218208000646664, 'recall': 0.9199340456071685, 'f1-score': 0.9191217457139741, 'support': 1132} weighted_avg {'precision': 0.9197250416981915, 'recall': 0.916077738515901, 'f1-score': 0.9159912900523501, 'support': 1132}
 
----------
Epoch 29/40
time = 499.80 secondes

Train loss 0.037806522122437757 accuracy 0.993714451789856 macro_avg {'precision': 0.99356360556928, 'recall': 0.9936012825425286, 'f1-score': 0.9935739653887732, 'support': 10182} weighted_avg {'precision': 0.9937181146131907, 'recall': 0.9937143979571793, 'f1-score': 0.9937077818123429, 'support': 10182}
 
time = 13.96 secondes

Val loss 0.7802052230859182 accuracy 0.9125441908836365 macro_avg {'precision': 0.9175526843068248, 'recall': 0.9172736636737637, 'f1-score': 0.915559481982797, 'support': 1132} weighted_avg {'precision': 0.9175905662503635, 'recall': 0.9125441696113075, 'f1-score': 0.9131417834365785, 'support': 1132}
 
----------
Epoch 30/40
time = 500.51 secondes

Train loss 0.029881541806703688 accuracy 0.9947947859764099 macro_avg {'precision': 0.994811779485952, 'recall': 0.9948210850923698, 'f1-score': 0.9948073382419332, 'support': 10182} weighted_avg {'precision': 0.9948108547758884, 'recall': 0.9947947358082891, 'f1-score': 0.9947934369559518, 'support': 10182}
 
time = 13.89 secondes

Val loss 0.6946923797445955 accuracy 0.916077733039856 macro_avg {'precision': 0.9231968485570633, 'recall': 0.9214917331824353, 'f1-score': 0.9195383478511412, 'support': 1132} weighted_avg {'precision': 0.9225334455623287, 'recall': 0.916077738515901, 'f1-score': 0.9162063803470664, 'support': 1132}
 
----------
Epoch 31/40
time = 496.35 secondes

Train loss 0.022041834998725356 accuracy 0.9954822659492493 macro_avg {'precision': 0.995557030401575, 'recall': 0.9955876078198276, 'f1-score': 0.9955691344938209, 'support': 10182} weighted_avg {'precision': 0.995489514267577, 'recall': 0.9954822235317227, 'f1-score': 0.9954826101522781, 'support': 10182}
 
time = 13.99 secondes

Val loss 0.7241406728567648 accuracy 0.9125441908836365 macro_avg {'precision': 0.9158770658245651, 'recall': 0.9172433557353246, 'f1-score': 0.9151654030488336, 'support': 1132} weighted_avg {'precision': 0.917537707385341, 'recall': 0.9125441696113075, 'f1-score': 0.913636686546883, 'support': 1132}
 
----------
Epoch 32/40
time = 495.74 secondes

Train loss 0.020262958652772917 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963681007900403, 'recall': 0.99646362006876, 'f1-score': 0.9964130494105753, 'support': 10182} weighted_avg {'precision': 0.9963729763168199, 'recall': 0.9963661363189943, 'f1-score': 0.9963667188782492, 'support': 10182}
 
time = 13.93 secondes

Val loss 0.7484377293843812 accuracy 0.9107773900032043 macro_avg {'precision': 0.9145150420052742, 'recall': 0.9150107061957484, 'f1-score': 0.9133420384837125, 'support': 1132} weighted_avg {'precision': 0.9142050558372029, 'recall': 0.9107773851590106, 'f1-score': 0.9109608705193449, 'support': 1132}
 
----------
Epoch 33/40
time = 498.16 secondes

Train loss 0.02148931541562901 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961897578064962, 'recall': 0.9960422254460705, 'f1-score': 0.9961128540173554, 'support': 10182} weighted_avg {'precision': 0.9960784905138325, 'recall': 0.9960714987232371, 'f1-score': 0.9960720685004828, 'support': 10182}
 
time = 13.91 secondes

Val loss 0.7341021310218475 accuracy 0.916961133480072 macro_avg {'precision': 0.919551496857013, 'recall': 0.9213686183000552, 'f1-score': 0.9190104589040713, 'support': 1132} weighted_avg {'precision': 0.9201435139882618, 'recall': 0.9169611307420494, 'f1-score': 0.9169858821864485, 'support': 1132}
 
----------
Epoch 34/40
time = 500.64 secondes

Train loss 0.022558169406410495 accuracy 0.9959732890129089 macro_avg {'precision': 0.996070784012953, 'recall': 0.9960605876700785, 'f1-score': 0.9960648470301029, 'support': 10182} weighted_avg {'precision': 0.9959739129353852, 'recall': 0.995973286191318, 'f1-score': 0.9959727506944526, 'support': 10182}
 
time = 13.87 secondes

Val loss 0.7506204248025747 accuracy 0.9116607904434204 macro_avg {'precision': 0.9199061593761277, 'recall': 0.9161035522601846, 'f1-score': 0.915328697533582, 'support': 1132} weighted_avg {'precision': 0.9174088065411126, 'recall': 0.911660777385159, 'f1-score': 0.9116759580341798, 'support': 1132}
 
----------
Epoch 35/40
time = 495.06 secondes

Train loss 0.009732583659124616 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982271123624227, 'recall': 0.9981690165032736, 'f1-score': 0.9981967841119618, 'support': 10182} weighted_avg {'precision': 0.9982364490329545, 'recall': 0.9982321744254566, 'f1-score': 0.9982330090933593, 'support': 10182}
 
time = 13.89 secondes

Val loss 0.7275898357824394 accuracy 0.9116607904434204 macro_avg {'precision': 0.9127168705924713, 'recall': 0.9143964153060473, 'f1-score': 0.9120546832232532, 'support': 1132} weighted_avg {'precision': 0.9153668795155459, 'recall': 0.911660777385159, 'f1-score': 0.9119966877953319, 'support': 1132}
 
----------
Epoch 36/40
time = 496.92 secondes

Train loss 0.01026224339503832 accuracy 0.9980357885360718 macro_avg {'precision': 0.9978847749781773, 'recall': 0.9979130611031174, 'f1-score': 0.997896952203134, 'support': 10182} weighted_avg {'precision': 0.998038879218633, 'recall': 0.9980357493616185, 'f1-score': 0.9980354334593563, 'support': 10182}
 
time = 13.86 secondes

Val loss 0.6823566099005226 accuracy 0.9178445339202881 macro_avg {'precision': 0.9222041822698976, 'recall': 0.9218206104009588, 'f1-score': 0.9207525403938585, 'support': 1132} weighted_avg {'precision': 0.9215746036872755, 'recall': 0.9178445229681979, 'f1-score': 0.9183488980386951, 'support': 1132}
 
----------
Epoch 37/40
time = 495.47 secondes

Train loss 0.008414045445388069 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985890877484813, 'recall': 0.9985588452071319, 'f1-score': 0.9985732331337992, 'support': 10182} weighted_avg {'precision': 0.9985299478185924, 'recall': 0.998526812021214, 'f1-score': 0.9985276305506318, 'support': 10182}
 
time = 13.92 secondes

Val loss 0.7060393138648143 accuracy 0.9240282773971558 macro_avg {'precision': 0.9292787945393076, 'recall': 0.9270369099370976, 'f1-score': 0.9269835183129145, 'support': 1132} weighted_avg {'precision': 0.9277750402620383, 'recall': 0.9240282685512368, 'f1-score': 0.924696994053939, 'support': 1132}
 
----------
Epoch 38/40
time = 497.14 secondes

Train loss 0.005849552400072603 accuracy 0.998919665813446 macro_avg {'precision': 0.9988556874459269, 'recall': 0.9988366402335824, 'f1-score': 0.9988456899232683, 'support': 10182} weighted_avg {'precision': 0.998920182465542, 'recall': 0.9989196621488902, 'f1-score': 0.9989194460209151, 'support': 10182}
 
time = 13.86 secondes

Val loss 0.7080054863044879 accuracy 0.9222614765167236 macro_avg {'precision': 0.924846537684736, 'recall': 0.9267548361428883, 'f1-score': 0.9245038889947395, 'support': 1132} weighted_avg {'precision': 0.9251622771728113, 'recall': 0.9222614840989399, 'f1-score': 0.9223899492431336, 'support': 1132}
 
----------
Epoch 39/40
time = 499.05 secondes

Train loss 0.005558462483726947 accuracy 0.9986250400543213 macro_avg {'precision': 0.998667694755247, 'recall': 0.9985580992109183, 'f1-score': 0.9986112073722241, 'support': 10182} weighted_avg {'precision': 0.9986279843440979, 'recall': 0.998625024553133, 'f1-score': 0.9986249157207776, 'support': 10182}
 
time = 13.86 secondes

Val loss 0.7009058555791904 accuracy 0.926678478717804 macro_avg {'precision': 0.9287306068084193, 'recall': 0.9299685404396675, 'f1-score': 0.9281494643439558, 'support': 1132} weighted_avg {'precision': 0.928937679281479, 'recall': 0.926678445229682, 'f1-score': 0.926556225513016, 'support': 1132}
 
----------
Epoch 40/40
time = 498.89 secondes

Train loss 0.0039020070368351754 accuracy 0.9993125200271606 macro_avg {'precision': 0.999088229112598, 'recall': 0.9993317558768673, 'f1-score': 0.9992060186119541, 'support': 10182} weighted_avg {'precision': 0.9993200132540397, 'recall': 0.9993125122765665, 'f1-score': 0.9993131332744898, 'support': 10182}
 
time = 13.88 secondes

Val loss 0.7117981864143025 accuracy 0.9213780760765076 macro_avg {'precision': 0.9242577262742661, 'recall': 0.9260113399924744, 'f1-score': 0.9238218360974733, 'support': 1132} weighted_avg {'precision': 0.9242403289300931, 'recall': 0.9213780918727915, 'f1-score': 0.9214707520307831, 'support': 1132}
 
----------
best_accuracy 0.926678478717804 best_epoch 39 macro_avg {'precision': 0.9287306068084193, 'recall': 0.9299685404396675, 'f1-score': 0.9281494643439558, 'support': 1132} weighted_avg {'precision': 0.928937679281479, 'recall': 0.926678445229682, 'f1-score': 0.926556225513016, 'support': 1132}

average train time 487.18260078430177

average val time 13.941221272945404
 
time = 92.71 secondes

test_accuracy 0.8631173372268677 macro_avg {'precision': 0.8584869642858186, 'recall': 0.8564802204942227, 'f1-score': 0.8565798192036824, 'support': 7532} weighted_avg {'precision': 0.8640882111665341, 'recall': 0.86311736590547, 'f1-score': 0.8627761181078138, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_1
----------
Epoch 1/40
time = 664.18 secondes

Train loss 1.088416678728638 accuracy 0.697014331817627 macro_avg {'precision': 0.6914313969004604, 'recall': 0.6835770423697393, 'f1-score': 0.6796517774604021, 'support': 10182} weighted_avg {'precision': 0.6977757344231735, 'recall': 0.6970143390296601, 'f1-score': 0.6910322664977255, 'support': 10182}
 
time = 17.77 secondes

Val loss 0.5840333196478831 accuracy 0.8206713795661926 macro_avg {'precision': 0.8247615841397316, 'recall': 0.8165121465354195, 'f1-score': 0.8013913614699689, 'support': 1132} weighted_avg {'precision': 0.8273844426114874, 'recall': 0.8206713780918727, 'f1-score': 0.8074222356429119, 'support': 1132}
 
----------
Epoch 2/40
time = 655.38 secondes

Train loss 0.38879554431294816 accuracy 0.8885288238525391 macro_avg {'precision': 0.8810818156067318, 'recall': 0.8803120263332694, 'f1-score': 0.8802151978166135, 'support': 10182} weighted_avg {'precision': 0.887415987277633, 'recall': 0.8885287762718523, 'f1-score': 0.8875868309718993, 'support': 10182}
 
time = 17.71 secondes

Val loss 0.44143058766256754 accuracy 0.8869258165359497 macro_avg {'precision': 0.8891083140067104, 'recall': 0.890940896263271, 'f1-score': 0.8867176040710014, 'support': 1132} weighted_avg {'precision': 0.8911626552616327, 'recall': 0.8869257950530035, 'f1-score': 0.8853424757776202, 'support': 1132}
 
----------
Epoch 3/40
time = 656.90 secondes

Train loss 0.2348806131177902 accuracy 0.9357690215110779 macro_avg {'precision': 0.9326891443687668, 'recall': 0.9318942524221698, 'f1-score': 0.932157294203719, 'support': 10182} weighted_avg {'precision': 0.9360785060777604, 'recall': 0.9357690041249264, 'f1-score': 0.9357906376450971, 'support': 10182}
 
time = 17.51 secondes

Val loss 0.4426151219637356 accuracy 0.8895759582519531 macro_avg {'precision': 0.8954941475656627, 'recall': 0.8918868539961137, 'f1-score': 0.8891419435100797, 'support': 1132} weighted_avg {'precision': 0.8999327263983373, 'recall': 0.8895759717314488, 'f1-score': 0.8898323901908073, 'support': 1132}
 
----------
Epoch 4/40
time = 657.75 secondes

Train loss 0.178870563171263 accuracy 0.9534472823143005 macro_avg {'precision': 0.9514775067777252, 'recall': 0.9511319700853538, 'f1-score': 0.9512140250671592, 'support': 10182} weighted_avg {'precision': 0.9536286597949925, 'recall': 0.9534472598703595, 'f1-score': 0.9534462396526991, 'support': 10182}
 
time = 17.68 secondes

Val loss 0.4965710430438827 accuracy 0.9019434452056885 macro_avg {'precision': 0.9030111920722634, 'recall': 0.9024213418099414, 'f1-score': 0.901205664031459, 'support': 1132} weighted_avg {'precision': 0.9045085876732517, 'recall': 0.9019434628975265, 'f1-score': 0.9017647579386009, 'support': 1132}
 
----------
Epoch 5/40
time = 655.67 secondes

Train loss 0.15457912612274388 accuracy 0.9631703495979309 macro_avg {'precision': 0.9618191432556248, 'recall': 0.9615442922362678, 'f1-score': 0.9616329971755997, 'support': 10182} weighted_avg {'precision': 0.9633111373128992, 'recall': 0.9631703005303477, 'f1-score': 0.9631909668884986, 'support': 10182}
 
time = 17.77 secondes

Val loss 0.5993488334089806 accuracy 0.8851590156555176 macro_avg {'precision': 0.895450016590871, 'recall': 0.890541993959026, 'f1-score': 0.8869905093183457, 'support': 1132} weighted_avg {'precision': 0.8993008712660866, 'recall': 0.8851590106007067, 'f1-score': 0.8861065353268622, 'support': 1132}
 
----------
Epoch 6/40
time = 657.50 secondes

Train loss 0.13999938837737225 accuracy 0.9665095806121826 macro_avg {'precision': 0.9647593085686836, 'recall': 0.9650119732074509, 'f1-score': 0.9648574339547874, 'support': 10182} weighted_avg {'precision': 0.9666263538710996, 'recall': 0.9665095266155962, 'f1-score': 0.9665420288335094, 'support': 10182}
 
time = 17.80 secondes

Val loss 0.5525409960356856 accuracy 0.9028268456459045 macro_avg {'precision': 0.9063314101082112, 'recall': 0.9033222625808875, 'f1-score': 0.902813986760734, 'support': 1132} weighted_avg {'precision': 0.9050473101306468, 'recall': 0.9028268551236749, 'f1-score': 0.901861815279827, 'support': 1132}
 
----------
Epoch 7/40
time = 657.62 secondes

Train loss 0.14395352075858922 accuracy 0.9678845405578613 macro_avg {'precision': 0.96732001516949, 'recall': 0.9670785823216839, 'f1-score': 0.9671507702668203, 'support': 10182} weighted_avg {'precision': 0.9679359632328601, 'recall': 0.9678845020624631, 'f1-score': 0.9678609616523142, 'support': 10182}
 
time = 17.71 secondes

Val loss 0.6456332245405475 accuracy 0.8992933034896851 macro_avg {'precision': 0.9037344096586418, 'recall': 0.8941029638936413, 'f1-score': 0.8954076718230024, 'support': 1132} weighted_avg {'precision': 0.9003166092896854, 'recall': 0.8992932862190812, 'f1-score': 0.8967554080196892, 'support': 1132}
 
----------
Epoch 8/40
time = 657.19 secondes

Train loss 0.12451454259698634 accuracy 0.9722058773040771 macro_avg {'precision': 0.9708868422175, 'recall': 0.9712076677119, 'f1-score': 0.9710162924503274, 'support': 10182} weighted_avg {'precision': 0.9723187355920647, 'recall': 0.9722058534669024, 'f1-score': 0.9722342266297805, 'support': 10182}
 
time = 17.69 secondes

Val loss 0.6962343903666717 accuracy 0.8931095600128174 macro_avg {'precision': 0.8983996953243919, 'recall': 0.8924750488185325, 'f1-score': 0.8909058691656547, 'support': 1132} weighted_avg {'precision': 0.8984112986178203, 'recall': 0.8931095406360424, 'f1-score': 0.8915135496904945, 'support': 1132}
 
----------
Epoch 9/40
time = 658.61 secondes

Train loss 0.11612581693635138 accuracy 0.9730898141860962 macro_avg {'precision': 0.9725775041314593, 'recall': 0.9726300931978527, 'f1-score': 0.9725672110673014, 'support': 10182} weighted_avg {'precision': 0.9731617610577963, 'recall': 0.973089766254174, 'f1-score': 0.9730882877185998, 'support': 10182}
 
time = 17.70 secondes

Val loss 0.5710606125030095 accuracy 0.916077733039856 macro_avg {'precision': 0.9211011297829467, 'recall': 0.9190778455670762, 'f1-score': 0.9171201663641666, 'support': 1132} weighted_avg {'precision': 0.9197246389306968, 'recall': 0.916077738515901, 'f1-score': 0.9149649207764773, 'support': 1132}
 
----------
Epoch 10/40
time = 657.81 secondes

Train loss 0.11579015065073471 accuracy 0.9766254425048828 macro_avg {'precision': 0.9758037861187363, 'recall': 0.9760531516555571, 'f1-score': 0.9759014104787846, 'support': 10182} weighted_avg {'precision': 0.9767109738773881, 'recall': 0.9766254174032607, 'f1-score': 0.9766429413175216, 'support': 10182}
 
time = 17.80 secondes

Val loss 0.6352090667916829 accuracy 0.898409903049469 macro_avg {'precision': 0.9064796554713815, 'recall': 0.9001784663002805, 'f1-score': 0.899586635505886, 'support': 1132} weighted_avg {'precision': 0.906395930233492, 'recall': 0.8984098939929329, 'f1-score': 0.8982999899292664, 'support': 1132}
 
----------
Epoch 11/40
time = 655.76 secondes

Train loss 0.10926258985358973 accuracy 0.9773129224777222 macro_avg {'precision': 0.9766330973275876, 'recall': 0.976760409390623, 'f1-score': 0.976649567207273, 'support': 10182} weighted_avg {'precision': 0.9773192619705491, 'recall': 0.9773129051266942, 'f1-score': 0.9772687108475394, 'support': 10182}
 
time = 17.63 secondes

Val loss 0.909448165478903 accuracy 0.870141327381134 macro_avg {'precision': 0.8901788696657682, 'recall': 0.8692910637540294, 'f1-score': 0.8703361805770513, 'support': 1132} weighted_avg {'precision': 0.8867356106802278, 'recall': 0.8701413427561837, 'f1-score': 0.8689734802998423, 'support': 1132}
 
----------
Epoch 12/40
time = 651.21 secondes

Train loss 0.08971485907676648 accuracy 0.981634259223938 macro_avg {'precision': 0.9811994627956551, 'recall': 0.981175450636863, 'f1-score': 0.9811604257533866, 'support': 10182} weighted_avg {'precision': 0.981731935086491, 'recall': 0.9816342565311333, 'f1-score': 0.9816559185168117, 'support': 10182}
 
time = 17.68 secondes

Val loss 0.6014994363211141 accuracy 0.9037102460861206 macro_avg {'precision': 0.9065351453139252, 'recall': 0.903385997840787, 'f1-score': 0.9031866994871051, 'support': 1132} weighted_avg {'precision': 0.9084565218227318, 'recall': 0.9037102473498233, 'f1-score': 0.9042158849599298, 'support': 1132}
 
----------
Epoch 13/40
time = 653.26 secondes

Train loss 0.11429695638528169 accuracy 0.9786878824234009 macro_avg {'precision': 0.9782838773038265, 'recall': 0.978349853099673, 'f1-score': 0.9782770310071701, 'support': 10182} weighted_avg {'precision': 0.9787335465653224, 'recall': 0.9786878805735612, 'f1-score': 0.9786712664083909, 'support': 10182}
 
time = 17.64 secondes

Val loss 0.7887279969241641 accuracy 0.8886925578117371 macro_avg {'precision': 0.9038717344035005, 'recall': 0.891957967089626, 'f1-score': 0.8913604020247003, 'support': 1132} weighted_avg {'precision': 0.9055718061052199, 'recall': 0.8886925795053003, 'f1-score': 0.890767271315123, 'support': 1132}
 
----------
Epoch 14/40
time = 654.05 secondes

Train loss 0.10690273047902119 accuracy 0.9797682762145996 macro_avg {'precision': 0.979318600894854, 'recall': 0.9795199497182807, 'f1-score': 0.979375902182843, 'support': 10182} weighted_avg {'precision': 0.9799030262110171, 'recall': 0.979768218424671, 'f1-score': 0.9797908564532771, 'support': 10182}
 
time = 17.66 secondes

Val loss 0.6210074601856858 accuracy 0.9196113348007202 macro_avg {'precision': 0.9236752030168919, 'recall': 0.9199448566737759, 'f1-score': 0.9201715555401483, 'support': 1132} weighted_avg {'precision': 0.9224771146090768, 'recall': 0.9196113074204947, 'f1-score': 0.9193927320360543, 'support': 1132}
 
----------
Epoch 15/40
time = 653.51 secondes

Train loss 0.09579686357475159 accuracy 0.9814378619194031 macro_avg {'precision': 0.9810032354592011, 'recall': 0.9810653183526853, 'f1-score': 0.9810291426463541, 'support': 10182} weighted_avg {'precision': 0.9814296628411912, 'recall': 0.9814378314672952, 'f1-score': 0.9814286050309421, 'support': 10182}
 
time = 17.69 secondes

Val loss 0.5947789170049232 accuracy 0.916077733039856 macro_avg {'precision': 0.9224326204665575, 'recall': 0.9170129265186736, 'f1-score': 0.918180906890874, 'support': 1132} weighted_avg {'precision': 0.9195478186391997, 'recall': 0.916077738515901, 'f1-score': 0.9161009180613783, 'support': 1132}
 
----------
Epoch 16/40
time = 654.50 secondes

Train loss 0.08000543841612788 accuracy 0.9848753213882446 macro_avg {'precision': 0.9847550192071466, 'recall': 0.9847893599560094, 'f1-score': 0.9847544502438627, 'support': 10182} weighted_avg {'precision': 0.98490969908655, 'recall': 0.9848752700844627, 'f1-score': 0.984875699088937, 'support': 10182}
 
time = 17.58 secondes

Val loss 0.6459516679421706 accuracy 0.9098939895629883 macro_avg {'precision': 0.9163988091933633, 'recall': 0.914177078334329, 'f1-score': 0.9117305494920481, 'support': 1132} weighted_avg {'precision': 0.9173134717977646, 'recall': 0.9098939929328622, 'f1-score': 0.9099414186470477, 'support': 1132}
 
----------
Epoch 17/40
time = 652.27 secondes

Train loss 0.07645935863245946 accuracy 0.9846788644790649 macro_avg {'precision': 0.9847305844289627, 'recall': 0.9847860726250799, 'f1-score': 0.9847506967494004, 'support': 10182} weighted_avg {'precision': 0.9847304564611379, 'recall': 0.9846788450206246, 'f1-score': 0.9846969120822624, 'support': 10182}
 
time = 17.78 secondes

Val loss 0.8424927462312527 accuracy 0.8869258165359497 macro_avg {'precision': 0.9014963135471239, 'recall': 0.8921851015386583, 'f1-score': 0.8891490229473268, 'support': 1132} weighted_avg {'precision': 0.9035247784421715, 'recall': 0.8869257950530035, 'f1-score': 0.88627321789365, 'support': 1132}
 
----------
Epoch 18/40
time = 653.56 secondes

Train loss 0.07697856634886521 accuracy 0.9858574271202087 macro_avg {'precision': 0.98543773794269, 'recall': 0.985636334206306, 'f1-score': 0.9855137895327205, 'support': 10182} weighted_avg {'precision': 0.9858760716070502, 'recall': 0.9858573954036535, 'f1-score': 0.9858444654614228, 'support': 10182}
 
time = 17.60 secondes

Val loss 0.7072363303097876 accuracy 0.9054770469665527 macro_avg {'precision': 0.9124093876027682, 'recall': 0.9100486494708353, 'f1-score': 0.9083774625244885, 'support': 1132} weighted_avg {'precision': 0.9136761148879585, 'recall': 0.9054770318021201, 'f1-score': 0.9067522264632968, 'support': 1132}
 
----------
Epoch 19/40
time = 654.93 secondes

Train loss 0.07250640403229511 accuracy 0.9862502813339233 macro_avg {'precision': 0.9859863764678003, 'recall': 0.9855185079628288, 'f1-score': 0.9857091107580456, 'support': 10182} weighted_avg {'precision': 0.9862810733981734, 'recall': 0.9862502455313298, 'f1-score': 0.9862268956267589, 'support': 10182}
 
time = 17.60 secondes

Val loss 0.6583103312738567 accuracy 0.9063604474067688 macro_avg {'precision': 0.9081288703150934, 'recall': 0.9087703965169606, 'f1-score': 0.9067651007971934, 'support': 1132} weighted_avg {'precision': 0.911304534260694, 'recall': 0.9063604240282686, 'f1-score': 0.9070791960826833, 'support': 1132}
 
----------
Epoch 20/40
time = 654.21 secondes

Train loss 0.06956301428135203 accuracy 0.9885091781616211 macro_avg {'precision': 0.9881601693415624, 'recall': 0.9880734782775406, 'f1-score': 0.9880969603415377, 'support': 10182} weighted_avg {'precision': 0.988549950959445, 'recall': 0.9885091337654685, 'f1-score': 0.9885106162786886, 'support': 10182}
 
time = 17.74 secondes

Val loss 0.7406655255754103 accuracy 0.9125441908836365 macro_avg {'precision': 0.9179913830034139, 'recall': 0.9150993375097919, 'f1-score': 0.9141744168910334, 'support': 1132} weighted_avg {'precision': 0.9175385222718879, 'recall': 0.9125441696113075, 'f1-score': 0.912485460662354, 'support': 1132}
 
----------
Epoch 21/40
time = 653.39 secondes

Train loss 0.06849580281112545 accuracy 0.9882145524024963 macro_avg {'precision': 0.9875391909757367, 'recall': 0.987224010704699, 'f1-score': 0.9873663820695299, 'support': 10182} weighted_avg {'precision': 0.9882312490755917, 'recall': 0.9882144961697112, 'f1-score': 0.9882093083039317, 'support': 10182}
 
time = 17.71 secondes

Val loss 0.7523663290007725 accuracy 0.9045936465263367 macro_avg {'precision': 0.9101915434182472, 'recall': 0.904424587734945, 'f1-score': 0.9036169185313163, 'support': 1132} weighted_avg {'precision': 0.9127428122455714, 'recall': 0.9045936395759717, 'f1-score': 0.9050410178944105, 'support': 1132}
 
----------
Epoch 22/40
time = 652.98 secondes

Train loss 0.0662523262824383 accuracy 0.9884109497070312 macro_avg {'precision': 0.9879140068247306, 'recall': 0.9879919065927474, 'f1-score': 0.9879327349290973, 'support': 10182} weighted_avg {'precision': 0.9884505695134413, 'recall': 0.9884109212335495, 'f1-score': 0.9884102474242706, 'support': 10182}
 
time = 17.59 secondes

Val loss 0.7796339136267549 accuracy 0.9010601043701172 macro_avg {'precision': 0.9080124880383105, 'recall': 0.9028275758978227, 'f1-score': 0.9031577120862684, 'support': 1132} weighted_avg {'precision': 0.9069085322873077, 'recall': 0.901060070671378, 'f1-score': 0.9016891949598346, 'support': 1132}
 
----------
Epoch 23/40
time = 651.06 secondes

Train loss 0.07456006797195414 accuracy 0.9878216981887817 macro_avg {'precision': 0.9875253606659526, 'recall': 0.9874164544700358, 'f1-score': 0.9874341118946204, 'support': 10182} weighted_avg {'precision': 0.9878873428523968, 'recall': 0.9878216460420349, 'f1-score': 0.9878221060596699, 'support': 10182}
 
time = 17.71 secondes

Val loss 0.7855850774928038 accuracy 0.9028268456459045 macro_avg {'precision': 0.907875990514019, 'recall': 0.9042400161353512, 'f1-score': 0.9021373065818553, 'support': 1132} weighted_avg {'precision': 0.9098292016160917, 'recall': 0.9028268551236749, 'f1-score': 0.9021881201914118, 'support': 1132}
 
----------
Epoch 24/40
time = 654.59 secondes

Train loss 0.04827253521756606 accuracy 0.9913573265075684 macro_avg {'precision': 0.9912124158998221, 'recall': 0.9912418666422876, 'f1-score': 0.9912183311313477, 'support': 10182} weighted_avg {'precision': 0.9913774696271789, 'recall': 0.9913572971911215, 'f1-score': 0.9913583578316401, 'support': 10182}
 
time = 17.67 secondes

Val loss 0.7522185644697792 accuracy 0.9116607904434204 macro_avg {'precision': 0.9155542373311822, 'recall': 0.911599632479428, 'f1-score': 0.9117414629724239, 'support': 1132} weighted_avg {'precision': 0.9151200362995455, 'recall': 0.911660777385159, 'f1-score': 0.9115808179138318, 'support': 1132}
 
----------
Epoch 25/40
time = 652.35 secondes

Train loss 0.04860527331907271 accuracy 0.9908662438392639 macro_avg {'precision': 0.9903535876184101, 'recall': 0.9903441515332114, 'f1-score': 0.9903345806001971, 'support': 10182} weighted_avg {'precision': 0.9908888749718143, 'recall': 0.9908662345315262, 'f1-score': 0.990863704370557, 'support': 10182}
 
time = 17.68 secondes

Val loss 0.7119115066903555 accuracy 0.9045936465263367 macro_avg {'precision': 0.9134270371879815, 'recall': 0.9066881668520324, 'f1-score': 0.9068548591860868, 'support': 1132} weighted_avg {'precision': 0.9144958430054683, 'recall': 0.9045936395759717, 'f1-score': 0.9061875856600154, 'support': 1132}
 
----------
Epoch 26/40
time = 652.32 secondes

Train loss 0.04172119230711224 accuracy 0.9919465780258179 macro_avg {'precision': 0.9918859963590181, 'recall': 0.9917505709587333, 'f1-score': 0.9918122273746504, 'support': 10182} weighted_avg {'precision': 0.9919615775306037, 'recall': 0.9919465723826361, 'f1-score': 0.9919482465283962, 'support': 10182}
 
time = 17.72 secondes

Val loss 0.7706036650882927 accuracy 0.9028268456459045 macro_avg {'precision': 0.9149174598428331, 'recall': 0.9025422265786662, 'f1-score': 0.905160619710377, 'support': 1132} weighted_avg {'precision': 0.9115352935199217, 'recall': 0.9028268551236749, 'f1-score': 0.9037196410843643, 'support': 1132}
 
----------
Epoch 27/40
time = 651.41 secondes

Train loss 0.04944086411993779 accuracy 0.9910627007484436 macro_avg {'precision': 0.9908938900633043, 'recall': 0.9909852512491323, 'f1-score': 0.9909283912975366, 'support': 10182} weighted_avg {'precision': 0.9910792704936026, 'recall': 0.9910626595953643, 'f1-score': 0.9910597951314758, 'support': 10182}
 
time = 17.64 secondes

Val loss 0.8664215619456102 accuracy 0.8992933034896851 macro_avg {'precision': 0.909641925519441, 'recall': 0.9038181569349091, 'f1-score': 0.9023145844452836, 'support': 1132} weighted_avg {'precision': 0.913353180287158, 'recall': 0.8992932862190812, 'f1-score': 0.9018138692271123, 'support': 1132}
 
----------
Epoch 28/40
time = 653.43 secondes

Train loss 0.03969712117018325 accuracy 0.9928305149078369 macro_avg {'precision': 0.9923303338165145, 'recall': 0.992363138171601, 'f1-score': 0.9923416030753943, 'support': 10182} weighted_avg {'precision': 0.992838197397325, 'recall': 0.9928304851699077, 'f1-score': 0.992829443938425, 'support': 10182}
 
time = 17.64 secondes

Val loss 0.7366936879559841 accuracy 0.9143109321594238 macro_avg {'precision': 0.9152715453981892, 'recall': 0.9181188314036375, 'f1-score': 0.9149730234077256, 'support': 1132} weighted_avg {'precision': 0.920016100410824, 'recall': 0.9143109540636042, 'f1-score': 0.9155735741637898, 'support': 1132}
 
----------
Epoch 29/40
time = 653.11 secondes

Train loss 0.03592434715419143 accuracy 0.9945001006126404 macro_avg {'precision': 0.9945742610086293, 'recall': 0.994433435546785, 'f1-score': 0.9944891174799457, 'support': 10182} weighted_avg {'precision': 0.994533962051937, 'recall': 0.9945000982125319, 'f1-score': 0.9945021012461867, 'support': 10182}
 
time = 17.69 secondes

Val loss 0.8503590579808511 accuracy 0.9054770469665527 macro_avg {'precision': 0.9104095976379558, 'recall': 0.9086762668137334, 'f1-score': 0.9071416338522372, 'support': 1132} weighted_avg {'precision': 0.9131884797712734, 'recall': 0.9054770318021201, 'f1-score': 0.9068448061437313, 'support': 1132}
 
----------
Epoch 30/40
time = 653.58 secondes

Train loss 0.05715109154266679 accuracy 0.9914555549621582 macro_avg {'precision': 0.9915229262614746, 'recall': 0.9914623394203957, 'f1-score': 0.9914088346065253, 'support': 10182} weighted_avg {'precision': 0.9915465717905275, 'recall': 0.9914555097230406, 'f1-score': 0.9914150877750836, 'support': 10182}
 
time = 17.63 secondes

Val loss 0.8489875358834365 accuracy 0.9054770469665527 macro_avg {'precision': 0.9143741769054016, 'recall': 0.9084767327791615, 'f1-score': 0.9055388594959576, 'support': 1132} weighted_avg {'precision': 0.9200235973594691, 'recall': 0.9054770318021201, 'f1-score': 0.9075122734436157, 'support': 1132}
 
----------
Epoch 31/40
time = 674.23 secondes

Train loss 0.03313311431716737 accuracy 0.9942054748535156 macro_avg {'precision': 0.9943026684985984, 'recall': 0.9942322263427735, 'f1-score': 0.9942584508376623, 'support': 10182} weighted_avg {'precision': 0.9942208455442101, 'recall': 0.9942054606167747, 'f1-score': 0.9942040006733409, 'support': 10182}
 
time = 17.71 secondes

Val loss 0.7013496366364539 accuracy 0.9178445339202881 macro_avg {'precision': 0.9204078987100027, 'recall': 0.9206532266602461, 'f1-score': 0.9199595079756173, 'support': 1132} weighted_avg {'precision': 0.919425996544241, 'recall': 0.9178445229681979, 'f1-score': 0.9180817177497341, 'support': 1132}
 
----------
Epoch 32/40
time = 676.90 secondes

Train loss 0.034454918374570896 accuracy 0.9945983290672302 macro_avg {'precision': 0.9943993398172731, 'recall': 0.9947031494773511, 'f1-score': 0.9945408130264666, 'support': 10182} weighted_avg {'precision': 0.9946238028769603, 'recall': 0.994598310744451, 'f1-score': 0.994602139172913, 'support': 10182}
 
time = 17.61 secondes

Val loss 0.7890206558466315 accuracy 0.9045936465263367 macro_avg {'precision': 0.9063678772818774, 'recall': 0.9084099355376332, 'f1-score': 0.904848876972672, 'support': 1132} weighted_avg {'precision': 0.9116727966111698, 'recall': 0.9045936395759717, 'f1-score': 0.9059260451152601, 'support': 1132}
 
----------
Epoch 33/40
time = 681.34 secondes

Train loss 0.022846269270877278 accuracy 0.9958751201629639 macro_avg {'precision': 0.9957638949939536, 'recall': 0.9957198866119293, 'f1-score': 0.9957365736361521, 'support': 10182} weighted_avg {'precision': 0.9958843965254717, 'recall': 0.995875073659399, 'f1-score': 0.9958746243243458, 'support': 10182}
 
time = 17.60 secondes

Val loss 0.7245341620579034 accuracy 0.9134275913238525 macro_avg {'precision': 0.9162896654487698, 'recall': 0.9168747313996297, 'f1-score': 0.9143051842653491, 'support': 1132} weighted_avg {'precision': 0.9199961879329276, 'recall': 0.9134275618374559, 'f1-score': 0.9145678487135506, 'support': 1132}
 
----------
Epoch 34/40
time = 689.74 secondes

Train loss 0.016585285046579773 accuracy 0.9969554543495178 macro_avg {'precision': 0.9968483870071821, 'recall': 0.9967275621151881, 'f1-score': 0.9967847545116577, 'support': 10182} weighted_avg {'precision': 0.9969584963159349, 'recall': 0.9969554115105087, 'f1-score': 0.9969542130306815, 'support': 10182}
 
time = 17.64 secondes

Val loss 0.6950252719458584 accuracy 0.9178445339202881 macro_avg {'precision': 0.918801637306181, 'recall': 0.918348800582859, 'f1-score': 0.9177843243115982, 'support': 1132} weighted_avg {'precision': 0.9191979491774248, 'recall': 0.9178445229681979, 'f1-score': 0.9177049213102881, 'support': 1132}
 
----------
Epoch 35/40
time = 677.14 secondes

Train loss 0.017532950631053548 accuracy 0.9964643716812134 macro_avg {'precision': 0.9964738392663008, 'recall': 0.9965111698498698, 'f1-score': 0.9964825048241194, 'support': 10182} weighted_avg {'precision': 0.9964870279126172, 'recall': 0.9964643488509134, 'f1-score': 0.9964656352926811, 'support': 10182}
 
time = 17.62 secondes

Val loss 0.8320555253637176 accuracy 0.9063604474067688 macro_avg {'precision': 0.9168383227224928, 'recall': 0.9084469594570121, 'f1-score': 0.9094661175011407, 'support': 1132} weighted_avg {'precision': 0.9163986087042082, 'recall': 0.9063604240282686, 'f1-score': 0.9079876694857385, 'support': 1132}
 
----------
Epoch 36/40
time = 683.13 secondes

Train loss 0.018980574076900677 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971817248126303, 'recall': 0.9971875885651158, 'f1-score': 0.9971822982216123, 'support': 10182} weighted_avg {'precision': 0.9971576376826928, 'recall': 0.9971518365743469, 'f1-score': 0.9971523683004411, 'support': 10182}
 
time = 17.72 secondes

Val loss 0.6897616148790278 accuracy 0.9196113348007202 macro_avg {'precision': 0.9219385275861418, 'recall': 0.9219559569481263, 'f1-score': 0.920885988478411, 'support': 1132} weighted_avg {'precision': 0.9227222628645627, 'recall': 0.9196113074204947, 'f1-score': 0.9201108890852696, 'support': 1132}
 
----------
Epoch 37/40
time = 688.08 secondes

Train loss 0.012209769033912805 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979404907979126, 'recall': 0.9980086274474071, 'f1-score': 0.9979717515837923, 'support': 10182} weighted_avg {'precision': 0.9979443751686339, 'recall': 0.9979375368296994, 'f1-score': 0.9979381701519562, 'support': 10182}
 
time = 17.91 secondes

Val loss 0.7748106168185676 accuracy 0.916077733039856 macro_avg {'precision': 0.9163978862289655, 'recall': 0.9202872595721916, 'f1-score': 0.9165977614844538, 'support': 1132} weighted_avg {'precision': 0.9195872534871188, 'recall': 0.916077738515901, 'f1-score': 0.915916156258582, 'support': 1132}
 
----------
Epoch 38/40
time = 680.47 secondes

Train loss 0.010159258160032325 accuracy 0.9978393316268921 macro_avg {'precision': 0.9978498413002237, 'recall': 0.9978002027278003, 'f1-score': 0.9978218691523079, 'support': 10182} weighted_avg {'precision': 0.997843710448131, 'recall': 0.9978393242977804, 'f1-score': 0.9978384662644227, 'support': 10182}
 
time = 17.67 secondes

Val loss 0.6874252736496358 accuracy 0.9257950782775879 macro_avg {'precision': 0.92751570850508, 'recall': 0.9280733090267688, 'f1-score': 0.9269276519850657, 'support': 1132} weighted_avg {'precision': 0.9270447257944922, 'recall': 0.9257950530035336, 'f1-score': 0.9254954721069634, 'support': 1132}
 
----------
Epoch 39/40
time = 684.85 secondes

Train loss 0.011214200273566613 accuracy 0.9983304142951965 macro_avg {'precision': 0.9981211500485851, 'recall': 0.9983165178315708, 'f1-score': 0.9982140030369464, 'support': 10182} weighted_avg {'precision': 0.9983388502723947, 'recall': 0.9983303869573757, 'f1-score': 0.9983305449171549, 'support': 10182}
 
time = 17.68 secondes

Val loss 0.7247389433575758 accuracy 0.9222614765167236 macro_avg {'precision': 0.9217568512138159, 'recall': 0.9250233782676786, 'f1-score': 0.9218878122193453, 'support': 1132} weighted_avg {'precision': 0.9252591963522148, 'recall': 0.9222614840989399, 'f1-score': 0.9222972915120737, 'support': 1132}
 
----------
Epoch 40/40
time = 685.25 secondes

Train loss 0.005511616690242673 accuracy 0.9993125200271606 macro_avg {'precision': 0.9991818819122876, 'recall': 0.9993272158386237, 'f1-score': 0.9992528081154308, 'support': 10182} weighted_avg {'precision': 0.99931620807466, 'recall': 0.9993125122765665, 'f1-score': 0.9993129202966987, 'support': 10182}
 
time = 17.61 secondes

Val loss 0.7234744901132371 accuracy 0.9204947352409363 macro_avg {'precision': 0.9228444303704831, 'recall': 0.92367279110729, 'f1-score': 0.9209450306884357, 'support': 1132} weighted_avg {'precision': 0.9258850538483883, 'recall': 0.9204946996466431, 'f1-score': 0.920986776320274, 'support': 1132}
 
----------
best_accuracy 0.9257950782775879 best_epoch 38 macro_avg {'precision': 0.92751570850508, 'recall': 0.9280733090267688, 'f1-score': 0.9269276519850657, 'support': 1132} weighted_avg {'precision': 0.9270447257944922, 'recall': 0.9257950530035336, 'f1-score': 0.9254954721069634, 'support': 1132}

average train time 661.6304587602615

average val time 17.680194330215453
 
time = 116.95 secondes

test_accuracy 0.8544874787330627 macro_avg {'precision': 0.8527002858691342, 'recall': 0.8476725913425621, 'f1-score': 0.8488226624479592, 'support': 7532} weighted_avg {'precision': 0.8591166497605246, 'recall': 0.8544875199150292, 'f1-score': 0.8554369158858369, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_1
----------
Epoch 1/40
time = 965.62 secondes

Train loss 1.0954116932825542 accuracy 0.690826952457428 macro_avg {'precision': 0.6876285157413344, 'recall': 0.6774028384771262, 'f1-score': 0.6756899997694406, 'support': 10182} weighted_avg {'precision': 0.6971793498889092, 'recall': 0.6908269495187586, 'f1-score': 0.6878700867392141, 'support': 10182}
 
time = 23.46 secondes

Val loss 0.5809255684135666 accuracy 0.8303887248039246 macro_avg {'precision': 0.823734636147073, 'recall': 0.8269594379816553, 'f1-score': 0.8182100479557436, 'support': 1132} weighted_avg {'precision': 0.8259755488909174, 'recall': 0.8303886925795053, 'f1-score': 0.8218652861984879, 'support': 1132}
 
----------
Epoch 2/40
time = 966.53 secondes

Train loss 0.4028202299747961 accuracy 0.8815557360649109 macro_avg {'precision': 0.8750696125787212, 'recall': 0.8737191503593749, 'f1-score': 0.8737449221690667, 'support': 10182} weighted_avg {'precision': 0.881024867988903, 'recall': 0.8815556865055981, 'f1-score': 0.8807714938669933, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.45362179731609115 accuracy 0.8772084712982178 macro_avg {'precision': 0.8792011952739802, 'recall': 0.8738827600377823, 'f1-score': 0.8708738866568326, 'support': 1132} weighted_avg {'precision': 0.8799543938932038, 'recall': 0.877208480565371, 'f1-score': 0.8733209400963625, 'support': 1132}
 
----------
Epoch 3/40
time = 964.48 secondes

Train loss 0.24130461553076582 accuracy 0.930465579032898 macro_avg {'precision': 0.9273872388582219, 'recall': 0.926375907464911, 'f1-score': 0.9267156253924653, 'support': 10182} weighted_avg {'precision': 0.9307458325026443, 'recall': 0.9304655274012964, 'f1-score': 0.9304447093898525, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.3596516256548569 accuracy 0.9098939895629883 macro_avg {'precision': 0.9102515559812602, 'recall': 0.9116836929337169, 'f1-score': 0.9095695775573299, 'support': 1132} weighted_avg {'precision': 0.9120522516739523, 'recall': 0.9098939929328622, 'f1-score': 0.909525064591682, 'support': 1132}
 
----------
Epoch 4/40
time = 968.08 secondes

Train loss 0.18455653053816565 accuracy 0.9527598023414612 macro_avg {'precision': 0.9504516043630413, 'recall': 0.9507556129461145, 'f1-score': 0.9505155282729941, 'support': 10182} weighted_avg {'precision': 0.9530816538080399, 'recall': 0.952759772146926, 'f1-score': 0.9528401579763375, 'support': 10182}
 
time = 23.09 secondes

Val loss 0.4398327532263709 accuracy 0.9134275913238525 macro_avg {'precision': 0.9199001688319829, 'recall': 0.9140338935057049, 'f1-score': 0.9153500103540291, 'support': 1132} weighted_avg {'precision': 0.9167820241390764, 'recall': 0.9134275618374559, 'f1-score': 0.9135159372460805, 'support': 1132}
 
----------
Epoch 5/40
time = 968.37 secondes

Train loss 0.1495226655437595 accuracy 0.9617953300476074 macro_avg {'precision': 0.9603253767050568, 'recall': 0.9600477272306444, 'f1-score': 0.9601322910596183, 'support': 10182} weighted_avg {'precision': 0.9619265930223337, 'recall': 0.9617953250834806, 'f1-score': 0.961810020903094, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.4808327972882388 accuracy 0.9116607904434204 macro_avg {'precision': 0.9140055897963523, 'recall': 0.9139208772050061, 'f1-score': 0.9130756820403956, 'support': 1132} weighted_avg {'precision': 0.9142227232596711, 'recall': 0.911660777385159, 'f1-score': 0.9119937659730017, 'support': 1132}
 
----------
Epoch 6/40
time = 971.36 secondes

Train loss 0.14095715677995801 accuracy 0.966116726398468 macro_avg {'precision': 0.9649569343050001, 'recall': 0.9651840516559933, 'f1-score': 0.9649728724886011, 'support': 10182} weighted_avg {'precision': 0.9661973249726087, 'recall': 0.9661166764879199, 'f1-score': 0.9660679341082612, 'support': 10182}
 
time = 23.08 secondes

Val loss 0.49322620531688377 accuracy 0.9072438478469849 macro_avg {'precision': 0.9124759738229444, 'recall': 0.9065245601494805, 'f1-score': 0.9074967498762202, 'support': 1132} weighted_avg {'precision': 0.9118920288022461, 'recall': 0.907243816254417, 'f1-score': 0.9076474716340519, 'support': 1132}
 
----------
Epoch 7/40
time = 970.45 secondes

Train loss 0.1323866675812729 accuracy 0.9695541262626648 macro_avg {'precision': 0.9683028117941305, 'recall': 0.9683279042811895, 'f1-score': 0.9682810226235343, 'support': 10182} weighted_avg {'precision': 0.9696967470361368, 'recall': 0.9695541151050874, 'f1-score': 0.9695918956704601, 'support': 10182}
 
time = 23.16 secondes

Val loss 0.5800896516991254 accuracy 0.8895759582519531 macro_avg {'precision': 0.8990186496787054, 'recall': 0.8938215258483172, 'f1-score': 0.8935862382067737, 'support': 1132} weighted_avg {'precision': 0.8985746678629889, 'recall': 0.8895759717314488, 'f1-score': 0.891067503045565, 'support': 1132}
 
----------
Epoch 8/40
time = 965.94 secondes

Train loss 0.11157493858758633 accuracy 0.9759379625320435 macro_avg {'precision': 0.975342297586241, 'recall': 0.9753985664645726, 'f1-score': 0.9753326017835462, 'support': 10182} weighted_avg {'precision': 0.9761278076251216, 'recall': 0.9759379296798272, 'f1-score': 0.9759963165064615, 'support': 10182}
 
time = 23.18 secondes

Val loss 0.6083566317163428 accuracy 0.9019434452056885 macro_avg {'precision': 0.9172392695925922, 'recall': 0.9002028970183302, 'f1-score': 0.9034752316911406, 'support': 1132} weighted_avg {'precision': 0.9122985062377084, 'recall': 0.9019434628975265, 'f1-score': 0.9020003610258676, 'support': 1132}
 
----------
Epoch 9/40
time = 968.99 secondes

Train loss 0.13198484040159306 accuracy 0.9721076488494873 macro_avg {'precision': 0.9716200389355161, 'recall': 0.9715947495941932, 'f1-score': 0.9715738345513962, 'support': 10182} weighted_avg {'precision': 0.9722644680736517, 'recall': 0.9721076409349833, 'f1-score': 0.9721524665235256, 'support': 10182}
 
time = 23.02 secondes

Val loss 0.604627471392184 accuracy 0.9037102460861206 macro_avg {'precision': 0.9017982951812984, 'recall': 0.9057765664316946, 'f1-score': 0.9022362154989938, 'support': 1132} weighted_avg {'precision': 0.9075903158938541, 'recall': 0.9037102473498233, 'f1-score': 0.9040017455256225, 'support': 1132}
 
----------
Epoch 10/40
time = 965.66 secondes

Train loss 0.10748218739044514 accuracy 0.9780004024505615 macro_avg {'precision': 0.9775944220438753, 'recall': 0.9776084179221346, 'f1-score': 0.97758161536788, 'support': 10182} weighted_avg {'precision': 0.9780671940468423, 'recall': 0.9780003928501276, 'f1-score': 0.9780138062399768, 'support': 10182}
 
time = 23.09 secondes

Val loss 0.6623819948839759 accuracy 0.8992933034896851 macro_avg {'precision': 0.904084069430606, 'recall': 0.90453862002768, 'f1-score': 0.9003084682861097, 'support': 1132} weighted_avg {'precision': 0.9047046030068235, 'recall': 0.8992932862190812, 'f1-score': 0.8975612434741094, 'support': 1132}
 
----------
Epoch 11/40
time = 970.17 secondes

Train loss 0.09321530791288925 accuracy 0.9807503819465637 macro_avg {'precision': 0.9803605323553173, 'recall': 0.980530688503786, 'f1-score': 0.9804217061495676, 'support': 10182} weighted_avg {'precision': 0.98080132091593, 'recall': 0.9807503437438617, 'f1-score': 0.980751571387994, 'support': 10182}
 
time = 23.08 secondes

Val loss 0.5441727708796823 accuracy 0.9151943325996399 macro_avg {'precision': 0.9145151973567556, 'recall': 0.9170934323504921, 'f1-score': 0.9149374263056356, 'support': 1132} weighted_avg {'precision': 0.9163140061783984, 'recall': 0.9151943462897526, 'f1-score': 0.9148863282887159, 'support': 1132}
 
----------
Epoch 12/40
time = 972.12 secondes

Train loss 0.10144521100425564 accuracy 0.9795718193054199 macro_avg {'precision': 0.9791794426294705, 'recall': 0.9792457309405043, 'f1-score': 0.9792031359434274, 'support': 10182} weighted_avg {'precision': 0.9795577960125846, 'recall': 0.9795717933608329, 'f1-score': 0.9795550513001994, 'support': 10182}
 
time = 23.11 secondes

Val loss 0.6441987427498762 accuracy 0.9037102460861206 macro_avg {'precision': 0.9119735506436152, 'recall': 0.907177931076464, 'f1-score': 0.9064494364803993, 'support': 1132} weighted_avg {'precision': 0.9114673569056009, 'recall': 0.9037102473498233, 'f1-score': 0.9045590445752474, 'support': 1132}
 
----------
Epoch 13/40
time = 968.21 secondes

Train loss 0.10515141277450643 accuracy 0.9788843393325806 macro_avg {'precision': 0.97865126834786, 'recall': 0.9783693868821091, 'f1-score': 0.9784765899120982, 'support': 10182} weighted_avg {'precision': 0.9790070875507872, 'recall': 0.9788843056373994, 'f1-score': 0.9789122132291588, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.8556847286479905 accuracy 0.880742073059082 macro_avg {'precision': 0.8964951901013174, 'recall': 0.8879235522212106, 'f1-score': 0.8825012489779077, 'support': 1132} weighted_avg {'precision': 0.8996134352691785, 'recall': 0.8807420494699647, 'f1-score': 0.8795386081028691, 'support': 1132}
 
----------
Epoch 14/40
time = 968.49 secondes

Train loss 0.08892558381998374 accuracy 0.9814378619194031 macro_avg {'precision': 0.9811602281954677, 'recall': 0.9809383594379313, 'f1-score': 0.9810189286559673, 'support': 10182} weighted_avg {'precision': 0.9814909012398922, 'recall': 0.9814378314672952, 'f1-score': 0.9814340939537953, 'support': 10182}
 
time = 23.10 secondes

Val loss 0.7193309799163409 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131747027093373, 'recall': 0.9076481842794916, 'f1-score': 0.9077384912612336, 'support': 1132} weighted_avg {'precision': 0.9122619810538526, 'recall': 0.9028268551236749, 'f1-score': 0.9046428573050657, 'support': 1132}
 
----------
Epoch 15/40
time = 969.07 secondes

Train loss 0.07814028948380336 accuracy 0.9846788644790649 macro_avg {'precision': 0.9842907199775321, 'recall': 0.9843670460450424, 'f1-score': 0.9843191167290778, 'support': 10182} weighted_avg {'precision': 0.9846949632961616, 'recall': 0.9846788450206246, 'f1-score': 0.9846769445986301, 'support': 10182}
 
time = 23.02 secondes

Val loss 0.7958902395039331 accuracy 0.8975265026092529 macro_avg {'precision': 0.9018700095562784, 'recall': 0.8960288914519021, 'f1-score': 0.8962925191142972, 'support': 1132} weighted_avg {'precision': 0.9025697365144769, 'recall': 0.8975265017667845, 'f1-score': 0.897563844585828, 'support': 1132}
 
----------
Epoch 16/40
time = 971.33 secondes

Train loss 0.09109884635658165 accuracy 0.982518196105957 macro_avg {'precision': 0.9824392675433764, 'recall': 0.9821601265061212, 'f1-score': 0.9822744139058004, 'support': 10182} weighted_avg {'precision': 0.9825573121937259, 'recall': 0.9825181693184051, 'f1-score': 0.9825126067933159, 'support': 10182}
 
time = 23.07 secondes

Val loss 0.7415124171552442 accuracy 0.9037102460861206 macro_avg {'precision': 0.9076686019829425, 'recall': 0.9058509528976192, 'f1-score': 0.9045369041354532, 'support': 1132} weighted_avg {'precision': 0.909054019615083, 'recall': 0.9037102473498233, 'f1-score': 0.9041042392621694, 'support': 1132}
 
----------
Epoch 17/40
time = 972.68 secondes

Train loss 0.08167435966991647 accuracy 0.9850717186927795 macro_avg {'precision': 0.9845687909325884, 'recall': 0.9839707556121212, 'f1-score': 0.9842385523610766, 'support': 10182} weighted_avg {'precision': 0.985078716396846, 'recall': 0.985071695148301, 'f1-score': 0.9850489433334392, 'support': 10182}
 
time = 24.94 secondes

Val loss 0.7358383647610743 accuracy 0.9045936465263367 macro_avg {'precision': 0.906767816166502, 'recall': 0.9047126440467845, 'f1-score': 0.9038004558534551, 'support': 1132} weighted_avg {'precision': 0.9072784128810467, 'recall': 0.9045936395759717, 'f1-score': 0.9040828954471587, 'support': 1132}
 
----------
Epoch 18/40
time = 959.58 secondes

Train loss 0.06528634096307477 accuracy 0.9880180954933167 macro_avg {'precision': 0.9878238282158456, 'recall': 0.9879469589733134, 'f1-score': 0.9878606229847762, 'support': 10182} weighted_avg {'precision': 0.9880851978826523, 'recall': 0.9880180711058731, 'f1-score': 0.9880277638267638, 'support': 10182}
 
time = 25.32 secondes

Val loss 0.6823947674379205 accuracy 0.9143109321594238 macro_avg {'precision': 0.9181510031130189, 'recall': 0.9184470436694008, 'f1-score': 0.9157922324013825, 'support': 1132} weighted_avg {'precision': 0.9195396634492811, 'recall': 0.9143109540636042, 'f1-score': 0.91415264153448, 'support': 1132}
 
----------
Epoch 19/40
time = 966.48 secondes

Train loss 0.07346799348286959 accuracy 0.9862502813339233 macro_avg {'precision': 0.9854845178468812, 'recall': 0.9859474046681852, 'f1-score': 0.9856905939335826, 'support': 10182} weighted_avg {'precision': 0.9863183674995455, 'recall': 0.9862502455313298, 'f1-score': 0.9862603812559522, 'support': 10182}
 
time = 25.80 secondes

Val loss 0.8198750485920447 accuracy 0.8975265026092529 macro_avg {'precision': 0.9098300688612024, 'recall': 0.8991376472410874, 'f1-score': 0.9015771507641714, 'support': 1132} weighted_avg {'precision': 0.9070531021473535, 'recall': 0.8975265017667845, 'f1-score': 0.8993210272168709, 'support': 1132}
 
----------
Epoch 20/40
time = 957.43 secondes

Train loss 0.07025680103163535 accuracy 0.9877234697341919 macro_avg {'precision': 0.987130094642402, 'recall': 0.9869154248384471, 'f1-score': 0.9870011065564123, 'support': 10182} weighted_avg {'precision': 0.9877470895799713, 'recall': 0.9877234335101159, 'f1-score': 0.9877140873700552, 'support': 10182}
 
time = 25.71 secondes

Val loss 0.7376722465253895 accuracy 0.9054770469665527 macro_avg {'precision': 0.9129985518954644, 'recall': 0.9079527818589745, 'f1-score': 0.9063805891165106, 'support': 1132} weighted_avg {'precision': 0.9179114295170079, 'recall': 0.9054770318021201, 'f1-score': 0.9081590967518536, 'support': 1132}
 
----------
Epoch 21/40
time = 957.44 secondes

Train loss 0.06816737965604679 accuracy 0.9873306155204773 macro_avg {'precision': 0.9870724252067259, 'recall': 0.9871494738031854, 'f1-score': 0.987088046152536, 'support': 10182} weighted_avg {'precision': 0.9873834915511397, 'recall': 0.9873305833824396, 'f1-score': 0.9873345803979872, 'support': 10182}
 
time = 24.78 secondes

Val loss 0.7411019585442132 accuracy 0.9125441908836365 macro_avg {'precision': 0.9199696919557538, 'recall': 0.9153535029887969, 'f1-score': 0.9158985437859165, 'support': 1132} weighted_avg {'precision': 0.9183600515604278, 'recall': 0.9125441696113075, 'f1-score': 0.9135862367896271, 'support': 1132}
 
----------
Epoch 22/40
time = 957.21 secondes

Train loss 0.06654198208904989 accuracy 0.9882145524024963 macro_avg {'precision': 0.987992939283485, 'recall': 0.9881280203522274, 'f1-score': 0.9880387670013372, 'support': 10182} weighted_avg {'precision': 0.9882680689055793, 'recall': 0.9882144961697112, 'f1-score': 0.9882211503182174, 'support': 10182}
 
time = 25.29 secondes

Val loss 0.8058818453426053 accuracy 0.898409903049469 macro_avg {'precision': 0.9130239017417262, 'recall': 0.9008526513337982, 'f1-score': 0.9028918130660102, 'support': 1132} weighted_avg {'precision': 0.9108874878479181, 'recall': 0.8984098939929329, 'f1-score': 0.9007133619018449, 'support': 1132}
 
----------
Epoch 23/40
time = 960.65 secondes

Train loss 0.047422164412291835 accuracy 0.9913573265075684 macro_avg {'precision': 0.9914111228857797, 'recall': 0.9911849272056541, 'f1-score': 0.9912860289420795, 'support': 10182} weighted_avg {'precision': 0.9913757346665991, 'recall': 0.9913572971911215, 'f1-score': 0.9913544947428372, 'support': 10182}
 
time = 26.02 secondes

Val loss 0.6589086460564277 accuracy 0.9222614765167236 macro_avg {'precision': 0.9251590983227187, 'recall': 0.9245950739470465, 'f1-score': 0.9237514578624506, 'support': 1132} weighted_avg {'precision': 0.9257099410182524, 'recall': 0.9222614840989399, 'f1-score': 0.9229099417180715, 'support': 1132}
 
----------
Epoch 24/40
time = 956.50 secondes

Train loss 0.05097491358688011 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918847018248387, 'recall': 0.991546604046689, 'f1-score': 0.9916987763247216, 'support': 10182} weighted_avg {'precision': 0.992176276808549, 'recall': 0.9921429974464742, 'f1-score': 0.9921428216425745, 'support': 10182}
 
time = 25.37 secondes

Val loss 0.6930503463251664 accuracy 0.9098939895629883 macro_avg {'precision': 0.9176863177356559, 'recall': 0.9127845699091063, 'f1-score': 0.9127078240727403, 'support': 1132} weighted_avg {'precision': 0.9165114203153616, 'recall': 0.9098939929328622, 'f1-score': 0.9104412174272615, 'support': 1132}
 
----------
Epoch 25/40
time = 959.56 secondes

Train loss 0.046911925357488476 accuracy 0.9919465780258179 macro_avg {'precision': 0.9919359879121175, 'recall': 0.9917428104010406, 'f1-score': 0.9918242286799295, 'support': 10182} weighted_avg {'precision': 0.9919802686559405, 'recall': 0.9919465723826361, 'f1-score': 0.9919496548734505, 'support': 10182}
 
time = 26.02 secondes

Val loss 0.6897173249553176 accuracy 0.916961133480072 macro_avg {'precision': 0.9227802926698085, 'recall': 0.9190953592230203, 'f1-score': 0.919311464365524, 'support': 1132} weighted_avg {'precision': 0.9211705609213204, 'recall': 0.9169611307420494, 'f1-score': 0.9173525152771684, 'support': 1132}
 
----------
Epoch 26/40
time = 956.43 secondes

Train loss 0.03658169105767237 accuracy 0.993812620639801 macro_avg {'precision': 0.9936108122755305, 'recall': 0.9937700646215608, 'f1-score': 0.9936874978778754, 'support': 10182} weighted_avg {'precision': 0.9938191111970686, 'recall': 0.9938126104890984, 'f1-score': 0.9938131551648813, 'support': 10182}
 
time = 25.57 secondes

Val loss 0.790889695320876 accuracy 0.9125441908836365 macro_avg {'precision': 0.9167183538871523, 'recall': 0.9169701675216773, 'f1-score': 0.9146023854336265, 'support': 1132} weighted_avg {'precision': 0.9173962159221107, 'recall': 0.9125441696113075, 'f1-score': 0.9125343273904056, 'support': 1132}
 
----------
Epoch 27/40
time = 957.61 secondes

Train loss 0.05038433560858125 accuracy 0.9914555549621582 macro_avg {'precision': 0.9914312268136392, 'recall': 0.9912985580020782, 'f1-score': 0.9913576831111968, 'support': 10182} weighted_avg {'precision': 0.9914721341847766, 'recall': 0.9914555097230406, 'f1-score': 0.9914567565323011, 'support': 10182}
 
time = 25.70 secondes

Val loss 0.7929607204394825 accuracy 0.9090105891227722 macro_avg {'precision': 0.9179542733349548, 'recall': 0.9125489286106834, 'f1-score': 0.9127604890855092, 'support': 1132} weighted_avg {'precision': 0.9161020032054892, 'recall': 0.9090106007067138, 'f1-score': 0.9099692588113688, 'support': 1132}
 
----------
Epoch 28/40
time = 960.85 secondes

Train loss 0.03845359618662055 accuracy 0.992634117603302 macro_avg {'precision': 0.9926583130329641, 'recall': 0.9926018247924302, 'f1-score': 0.9926248571455829, 'support': 10182} weighted_avg {'precision': 0.9926424975187322, 'recall': 0.9926340601060696, 'f1-score': 0.9926333903179938, 'support': 10182}
 
time = 25.97 secondes

Val loss 0.6074250645712748 accuracy 0.9275618195533752 macro_avg {'precision': 0.9302611553069544, 'recall': 0.9294051530674983, 'f1-score': 0.9287275834478332, 'support': 1132} weighted_avg {'precision': 0.9300798703638463, 'recall': 0.9275618374558304, 'f1-score': 0.9278299151380157, 'support': 1132}
 
----------
Epoch 29/40
time = 957.51 secondes

Train loss 0.03409542233133851 accuracy 0.9943037033081055 macro_avg {'precision': 0.9944010195874089, 'recall': 0.9943548430230656, 'f1-score': 0.9943688044403289, 'support': 10182} weighted_avg {'precision': 0.9943221370800791, 'recall': 0.9943036731486937, 'f1-score': 0.9943034809305197, 'support': 10182}
 
time = 25.96 secondes

Val loss 1.0248021198448711 accuracy 0.8931095600128174 macro_avg {'precision': 0.9016028426986814, 'recall': 0.9015247792844823, 'f1-score': 0.8942945760921827, 'support': 1132} weighted_avg {'precision': 0.908802443221821, 'recall': 0.8931095406360424, 'f1-score': 0.893898485872777, 'support': 1132}
 
----------
Epoch 30/40
time = 960.70 secondes

Train loss 0.038657898408285804 accuracy 0.993714451789856 macro_avg {'precision': 0.9934631869720743, 'recall': 0.9936460140570054, 'f1-score': 0.9935504379239439, 'support': 10182} weighted_avg {'precision': 0.9937212174653245, 'recall': 0.9937143979571793, 'f1-score': 0.9937138679362457, 'support': 10182}
 
time = 23.07 secondes

Val loss 0.7568353580377142 accuracy 0.9134275913238525 macro_avg {'precision': 0.9180253490120869, 'recall': 0.9167884865102934, 'f1-score': 0.9151008912072802, 'support': 1132} weighted_avg {'precision': 0.919397776975511, 'recall': 0.9134275618374559, 'f1-score': 0.9140118257837954, 'support': 1132}
 
----------
Epoch 31/40
time = 963.08 secondes

Train loss 0.035260227475986915 accuracy 0.9941073060035706 macro_avg {'precision': 0.9942001712786344, 'recall': 0.9942641276791164, 'f1-score': 0.9942254722429201, 'support': 10182} weighted_avg {'precision': 0.9941349281736613, 'recall': 0.9941072480848556, 'f1-score': 0.9941143997825315, 'support': 10182}
 
time = 23.30 secondes

Val loss 0.6727326568665453 accuracy 0.9222614765167236 macro_avg {'precision': 0.9257014063328277, 'recall': 0.9253387660884226, 'f1-score': 0.924161917630639, 'support': 1132} weighted_avg {'precision': 0.9247543756771139, 'recall': 0.9222614840989399, 'f1-score': 0.9219279297819951, 'support': 1132}
 
----------
Epoch 32/40
time = 959.33 secondes

Train loss 0.023207483677093646 accuracy 0.9955804944038391 macro_avg {'precision': 0.9954854349439752, 'recall': 0.9955403094520937, 'f1-score': 0.9955096724460704, 'support': 10182} weighted_avg {'precision': 0.9955864847859819, 'recall': 0.9955804360636418, 'f1-score': 0.9955802392805401, 'support': 10182}
 
time = 23.21 secondes

Val loss 0.6475216441818112 accuracy 0.9249116778373718 macro_avg {'precision': 0.9282560339821482, 'recall': 0.9277679416842654, 'f1-score': 0.9270691790223754, 'support': 1132} weighted_avg {'precision': 0.9275340966051095, 'recall': 0.9249116607773852, 'f1-score': 0.9252081535778388, 'support': 1132}
 
----------
Epoch 33/40
time = 959.94 secondes

Train loss 0.0160876415316503 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967485667169751, 'recall': 0.9967220332870432, 'f1-score': 0.996733413741274, 'support': 10182} weighted_avg {'precision': 0.9967612867969827, 'recall': 0.9967589864466706, 'f1-score': 0.9967582383935477, 'support': 10182}
 
time = 23.11 secondes

Val loss 0.8350241010644105 accuracy 0.9072438478469849 macro_avg {'precision': 0.9197728587709733, 'recall': 0.9098811655689654, 'f1-score': 0.9110063221289613, 'support': 1132} weighted_avg {'precision': 0.9211158293473797, 'recall': 0.907243816254417, 'f1-score': 0.9103052576552205, 'support': 1132}
 
----------
Epoch 34/40
time = 965.70 secondes

Train loss 0.025190415298081692 accuracy 0.9963661432266235 macro_avg {'precision': 0.9962767768256093, 'recall': 0.9964021152725119, 'f1-score': 0.9963309146850212, 'support': 10182} weighted_avg {'precision': 0.9963809785902945, 'recall': 0.9963661363189943, 'f1-score': 0.9963651565135856, 'support': 10182}
 
time = 23.41 secondes

Val loss 0.7556215967217187 accuracy 0.9196113348007202 macro_avg {'precision': 0.9268254593976799, 'recall': 0.9226311208092989, 'f1-score': 0.9223411474821794, 'support': 1132} weighted_avg {'precision': 0.9262818474793093, 'recall': 0.9196113074204947, 'f1-score': 0.9203474165823061, 'support': 1132}
 
----------
Epoch 35/40
time = 965.13 secondes

Train loss 0.020145969173522807 accuracy 0.9965626001358032 macro_avg {'precision': 0.9964583594229335, 'recall': 0.9964859884475123, 'f1-score': 0.9964681463023821, 'support': 10182} weighted_avg {'precision': 0.996572077795466, 'recall': 0.9965625613828325, 'f1-score': 0.996563373790118, 'support': 10182}
 
time = 23.60 secondes

Val loss 0.7105791607547718 accuracy 0.9213780760765076 macro_avg {'precision': 0.9252562371127476, 'recall': 0.9225103009448686, 'f1-score': 0.9229244817794393, 'support': 1132} weighted_avg {'precision': 0.9234058431019758, 'recall': 0.9213780918727915, 'f1-score': 0.9214648154687226, 'support': 1132}
 
----------
Epoch 36/40
time = 960.02 secondes

Train loss 0.017337390213419943 accuracy 0.9966608285903931 macro_avg {'precision': 0.9967212056390661, 'recall': 0.9967676813982635, 'f1-score': 0.9967387536064347, 'support': 10182} weighted_avg {'precision': 0.9966652617226207, 'recall': 0.9966607739147515, 'f1-score': 0.9966571497671001, 'support': 10182}
 
time = 23.48 secondes

Val loss 0.7596212603626221 accuracy 0.9222614765167236 macro_avg {'precision': 0.9278020132606762, 'recall': 0.9250495642858063, 'f1-score': 0.924729657068099, 'support': 1132} weighted_avg {'precision': 0.92777453584526, 'recall': 0.9222614840989399, 'f1-score': 0.9232754602354899, 'support': 1132}
 
----------
Epoch 37/40
time = 965.78 secondes

Train loss 0.011836256523687042 accuracy 0.9979375600814819 macro_avg {'precision': 0.9978991185661851, 'recall': 0.9979179896138664, 'f1-score': 0.9979052068950981, 'support': 10182} weighted_avg {'precision': 0.9979456934571496, 'recall': 0.9979375368296994, 'f1-score': 0.997938187095852, 'support': 10182}
 
time = 24.75 secondes

Val loss 0.7513246231665875 accuracy 0.9187279343605042 macro_avg {'precision': 0.9235490703641526, 'recall': 0.9211174338549035, 'f1-score': 0.9203441841695754, 'support': 1132} weighted_avg {'precision': 0.9235339446022647, 'recall': 0.9187279151943463, 'f1-score': 0.9191752649030689, 'support': 1132}
 
----------
Epoch 38/40
time = 957.48 secondes

Train loss 0.006318755272521949 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986742503078933, 'recall': 0.9986055792633979, 'f1-score': 0.998638528493758, 'support': 10182} weighted_avg {'precision': 0.9986274584714645, 'recall': 0.998625024553133, 'f1-score': 0.9986249308584265, 'support': 10182}
 
time = 24.74 secondes

Val loss 0.6821288545610079 accuracy 0.9231448769569397 macro_avg {'precision': 0.9287377560352675, 'recall': 0.9254101862574176, 'f1-score': 0.925696527848521, 'support': 1132} weighted_avg {'precision': 0.9271311946535056, 'recall': 0.9231448763250883, 'f1-score': 0.9236851773870484, 'support': 1132}
 
----------
Epoch 39/40
time = 957.84 secondes

Train loss 0.0069117827824554685 accuracy 0.998919665813446 macro_avg {'precision': 0.9988820052638928, 'recall': 0.9989192020461093, 'f1-score': 0.9988993624523447, 'support': 10182} weighted_avg {'precision': 0.9989220393287717, 'recall': 0.9989196621488902, 'f1-score': 0.998919662963311, 'support': 10182}
 
time = 24.74 secondes

Val loss 0.7080261701584802 accuracy 0.9231448769569397 macro_avg {'precision': 0.9264526077844575, 'recall': 0.9249672677858909, 'f1-score': 0.9240829256427598, 'support': 1132} weighted_avg {'precision': 0.92796452034876, 'recall': 0.9231448763250883, 'f1-score': 0.9238125601579259, 'support': 1132}
 
----------
Epoch 40/40
time = 953.64 secondes

Train loss 0.0032625782163995323 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992884677362863, 'recall': 0.9993355735339552, 'f1-score': 0.9993112349722975, 'support': 10182} weighted_avg {'precision': 0.9993140910622771, 'recall': 0.9993125122765665, 'f1-score': 0.9993125301950059, 'support': 10182}
 
time = 24.92 secondes

Val loss 0.6670447373672546 accuracy 0.9275618195533752 macro_avg {'precision': 0.9303332905227666, 'recall': 0.9290602456394185, 'f1-score': 0.9283834368643722, 'support': 1132} weighted_avg {'precision': 0.9312980181763427, 'recall': 0.9275618374558304, 'f1-score': 0.9279968234416306, 'support': 1132}
 
----------
best_accuracy 0.9275618195533752 best_epoch 28 macro_avg {'precision': 0.9302611553069544, 'recall': 0.9294051530674983, 'f1-score': 0.9287275834478332, 'support': 1132} weighted_avg {'precision': 0.9300798703638463, 'recall': 0.9275618374558304, 'f1-score': 0.9278299151380157, 'support': 1132}

average train time 963.5854761302471

average val time 24.104535645246507
 
time = 165.64 secondes

test_accuracy 0.849176824092865 macro_avg {'precision': 0.8513810879800182, 'recall': 0.843177809418447, 'f1-score': 0.8431546077338282, 'support': 7532} weighted_avg {'precision': 0.858089549935084, 'recall': 0.8491768454593733, 'f1-score': 0.850235771172137, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_1
----------
Epoch 1/40
time = 1969.33 secondes

Train loss 1.1156561003655803 accuracy 0.6880770325660706 macro_avg {'precision': 0.6939395955737158, 'recall': 0.6752097268938038, 'f1-score': 0.6748522113858718, 'support': 10182} weighted_avg {'precision': 0.7024808705593026, 'recall': 0.6880769986250246, 'f1-score': 0.6868156517931813, 'support': 10182}
 
time = 33.07 secondes

Val loss 0.5367528096261159 accuracy 0.8507066965103149 macro_avg {'precision': 0.8596986618276468, 'recall': 0.8515676400811666, 'f1-score': 0.8497931774003197, 'support': 1132} weighted_avg {'precision': 0.8617409397624122, 'recall': 0.8507067137809188, 'f1-score': 0.8507352796875487, 'support': 1132}
 
----------
Epoch 2/40
time = 1969.57 secondes

Train loss 0.37676163643797395 accuracy 0.8922608494758606 macro_avg {'precision': 0.8877288779996049, 'recall': 0.8858720378162588, 'f1-score': 0.8862446885622053, 'support': 10182} weighted_avg {'precision': 0.8920791425456841, 'recall': 0.892260852484777, 'f1-score': 0.891699396242165, 'support': 10182}
 
time = 31.69 secondes

Val loss 0.5491694311650706 accuracy 0.8471731543540955 macro_avg {'precision': 0.8599743844283878, 'recall': 0.8465665253234933, 'f1-score': 0.8424284280113211, 'support': 1132} weighted_avg {'precision': 0.8686502128127123, 'recall': 0.8471731448763251, 'f1-score': 0.8462238928525985, 'support': 1132}
 
----------
Epoch 3/40
time = 1967.67 secondes

Train loss 0.23024162759615496 accuracy 0.9346886873245239 macro_avg {'precision': 0.9320451617189965, 'recall': 0.9315838612330307, 'f1-score': 0.931699118028441, 'support': 10182} weighted_avg {'precision': 0.9351604313446157, 'recall': 0.9346886662738165, 'f1-score': 0.934813049192827, 'support': 10182}
 
time = 30.90 secondes

Val loss 0.5036856151435157 accuracy 0.8931095600128174 macro_avg {'precision': 0.898585443430769, 'recall': 0.8942124793095415, 'f1-score': 0.8929483431015738, 'support': 1132} weighted_avg {'precision': 0.8968662244676104, 'recall': 0.8931095406360424, 'f1-score': 0.8913889646402493, 'support': 1132}
 
----------
Epoch 4/40
time = 1967.27 secondes

Train loss 0.1674684068568934 accuracy 0.9555097222328186 macro_avg {'precision': 0.9544373296537403, 'recall': 0.9542845617215846, 'f1-score': 0.954236931547465, 'support': 10182} weighted_avg {'precision': 0.9558387421917691, 'recall': 0.95550972304066, 'f1-score': 0.9555590083527119, 'support': 10182}
 
time = 31.28 secondes

Val loss 0.46623366109331627 accuracy 0.9028268456459045 macro_avg {'precision': 0.9065065576614245, 'recall': 0.904620160314407, 'f1-score': 0.9027491873824414, 'support': 1132} weighted_avg {'precision': 0.9052071760820889, 'recall': 0.9028268551236749, 'f1-score': 0.9009426477597292, 'support': 1132}
 
----------
Epoch 5/40
time = 1966.85 secondes

Train loss 0.1481046392088917 accuracy 0.9638578295707703 macro_avg {'precision': 0.9627915012254318, 'recall': 0.9630010584236427, 'f1-score': 0.9628402389276486, 'support': 10182} weighted_avg {'precision': 0.9641536252670474, 'recall': 0.9638577882537812, 'f1-score': 0.9639545961346526, 'support': 10182}
 
time = 31.38 secondes

Val loss 0.4788184596232178 accuracy 0.9151943325996399 macro_avg {'precision': 0.9183954820350145, 'recall': 0.9157430660921653, 'f1-score': 0.9150859148937455, 'support': 1132} weighted_avg {'precision': 0.9176498902381787, 'recall': 0.9151943462897526, 'f1-score': 0.9143011198885236, 'support': 1132}
 
----------
Epoch 6/40
time = 1969.27 secondes

Train loss 0.14844109057081464 accuracy 0.9645453095436096 macro_avg {'precision': 0.9638848898033222, 'recall': 0.9636437085962543, 'f1-score': 0.9637331830290197, 'support': 10182} weighted_avg {'precision': 0.9645645078592318, 'recall': 0.9645452759772147, 'f1-score': 0.9645238408442048, 'support': 10182}
 
time = 31.09 secondes

Val loss 0.5905231291495434 accuracy 0.9054770469665527 macro_avg {'precision': 0.9106468485390794, 'recall': 0.9051072575963135, 'f1-score': 0.9043388749478405, 'support': 1132} weighted_avg {'precision': 0.9115790352873957, 'recall': 0.9054770318021201, 'f1-score': 0.9051294456258565, 'support': 1132}
 
----------
Epoch 7/40
time = 1967.41 secondes

Train loss 0.11452982599272801 accuracy 0.9722058773040771 macro_avg {'precision': 0.9712194321995427, 'recall': 0.9712175073749508, 'f1-score': 0.9711912726476489, 'support': 10182} weighted_avg {'precision': 0.9722204690398006, 'recall': 0.9722058534669024, 'f1-score': 0.9721853232391087, 'support': 10182}
 
time = 30.93 secondes

Val loss 0.6837185127324503 accuracy 0.8948763608932495 macro_avg {'precision': 0.9024970518936193, 'recall': 0.9002041934712068, 'f1-score': 0.8971286214591734, 'support': 1132} weighted_avg {'precision': 0.9037247617391475, 'recall': 0.8948763250883393, 'f1-score': 0.8947468498131026, 'support': 1132}
 
----------
Epoch 8/40
time = 1967.02 secondes

Train loss 0.1265417806734002 accuracy 0.9716166257858276 macro_avg {'precision': 0.9706315651519732, 'recall': 0.9707589518734256, 'f1-score': 0.9706799271162259, 'support': 10182} weighted_avg {'precision': 0.9716389193587885, 'recall': 0.9716165782753879, 'f1-score': 0.9716123486527168, 'support': 10182}
 
time = 31.47 secondes

Val loss 0.5447955994553615 accuracy 0.9090105891227722 macro_avg {'precision': 0.910629889621276, 'recall': 0.9126938888833159, 'f1-score': 0.9104479288455287, 'support': 1132} weighted_avg {'precision': 0.9107581886367643, 'recall': 0.9090106007067138, 'f1-score': 0.9086438713525469, 'support': 1132}
 
----------
Epoch 9/40
time = 1966.66 secondes

Train loss 0.11089130272629913 accuracy 0.9756433367729187 macro_avg {'precision': 0.9750880098782341, 'recall': 0.9751816715920129, 'f1-score': 0.9751030425696815, 'support': 10182} weighted_avg {'precision': 0.9757275482180245, 'recall': 0.97564329208407, 'f1-score': 0.9756550064935666, 'support': 10182}
 
time = 30.91 secondes

Val loss 0.7129011700716047 accuracy 0.8992933034896851 macro_avg {'precision': 0.9074313907714938, 'recall': 0.8971803145019489, 'f1-score': 0.8970624606575603, 'support': 1132} weighted_avg {'precision': 0.9052718765674737, 'recall': 0.8992932862190812, 'f1-score': 0.897761778420596, 'support': 1132}
 
----------
Epoch 10/40
time = 1968.74 secondes

Train loss 0.0906249744004078 accuracy 0.980553925037384 macro_avg {'precision': 0.9796481174141476, 'recall': 0.979722887885413, 'f1-score': 0.9796672915089367, 'support': 10182} weighted_avg {'precision': 0.9805812063607772, 'recall': 0.9805539186800236, 'f1-score': 0.9805495940162028, 'support': 10182}
 
time = 30.93 secondes

Val loss 0.6674932412486311 accuracy 0.9107773900032043 macro_avg {'precision': 0.9181603494064218, 'recall': 0.9123950181350453, 'f1-score': 0.9135162640233021, 'support': 1132} weighted_avg {'precision': 0.9163448282123631, 'recall': 0.9107773851590106, 'f1-score': 0.9116589927405326, 'support': 1132}
 
----------
Epoch 11/40
time = 1968.18 secondes

Train loss 0.10406781192767062 accuracy 0.9789825677871704 macro_avg {'precision': 0.978589969536271, 'recall': 0.978617691954647, 'f1-score': 0.9785812635995249, 'support': 10182} weighted_avg {'precision': 0.9790727190986475, 'recall': 0.9789825181693184, 'f1-score': 0.9790049888210214, 'support': 10182}
 
time = 31.29 secondes

Val loss 0.6621417869823168 accuracy 0.9090105891227722 macro_avg {'precision': 0.9152849603552576, 'recall': 0.9083804742631928, 'f1-score': 0.9094504707065767, 'support': 1132} weighted_avg {'precision': 0.9147856921559071, 'recall': 0.9090106007067138, 'f1-score': 0.9096037396257315, 'support': 1132}
 
----------
Epoch 12/40
time = 1969.56 secondes

Train loss 0.09879575716502935 accuracy 0.980455756187439 macro_avg {'precision': 0.9796322211724722, 'recall': 0.9792958745210699, 'f1-score': 0.9794465381575147, 'support': 10182} weighted_avg {'precision': 0.9804890644502134, 'recall': 0.9804557061481045, 'f1-score': 0.9804551647824941, 'support': 10182}
 
time = 32.17 secondes

Val loss 0.6492842833220903 accuracy 0.9063604474067688 macro_avg {'precision': 0.9088412647096857, 'recall': 0.9080875807827473, 'f1-score': 0.9071976594554835, 'support': 1132} weighted_avg {'precision': 0.9093294712833818, 'recall': 0.9063604240282686, 'f1-score': 0.9065173200826719, 'support': 1132}
 
----------
Epoch 13/40
time = 1967.86 secondes

Train loss 0.09369973363518826 accuracy 0.9817324876785278 macro_avg {'precision': 0.9812179292703428, 'recall': 0.9810332055549953, 'f1-score': 0.981109493655639, 'support': 10182} weighted_avg {'precision': 0.9817719584920086, 'recall': 0.9817324690630524, 'f1-score': 0.9817361684137438, 'support': 10182}
 
time = 30.76 secondes

Val loss 0.9047959833139468 accuracy 0.8825088143348694 macro_avg {'precision': 0.8963623952088113, 'recall': 0.8884292852132603, 'f1-score': 0.8738336988332124, 'support': 1132} weighted_avg {'precision': 0.9012875758632772, 'recall': 0.8825088339222615, 'f1-score': 0.8710572541358352, 'support': 1132}
 
----------
Epoch 14/40
time = 1967.95 secondes

Train loss 0.09550825972076908 accuracy 0.9817324876785278 macro_avg {'precision': 0.9809331013001886, 'recall': 0.9814965919404777, 'f1-score': 0.9811427625722523, 'support': 10182} weighted_avg {'precision': 0.9818524628442341, 'recall': 0.9817324690630524, 'f1-score': 0.9817263518058402, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.6626368139406853 accuracy 0.9098939895629883 macro_avg {'precision': 0.9168618675745861, 'recall': 0.9129619638881128, 'f1-score': 0.9120890202579179, 'support': 1132} weighted_avg {'precision': 0.9158526693127622, 'recall': 0.9098939929328622, 'f1-score': 0.909762811783352, 'support': 1132}
 
----------
Epoch 15/40
time = 1967.90 secondes

Train loss 0.07692723115959804 accuracy 0.9850717186927795 macro_avg {'precision': 0.9843270911512121, 'recall': 0.9843181605053758, 'f1-score': 0.9843107166412983, 'support': 10182} weighted_avg {'precision': 0.9850940344654847, 'recall': 0.985071695148301, 'f1-score': 0.9850709655282249, 'support': 10182}
 
time = 30.84 secondes

Val loss 0.6781495634830618 accuracy 0.9125441908836365 macro_avg {'precision': 0.9152660359232575, 'recall': 0.9144776316463246, 'f1-score': 0.9121542647056465, 'support': 1132} weighted_avg {'precision': 0.9173848041612914, 'recall': 0.9125441696113075, 'f1-score': 0.9126191875103727, 'support': 1132}
 
----------
Epoch 16/40
time = 1968.10 secondes

Train loss 0.0750780283001283 accuracy 0.9866431355476379 macro_avg {'precision': 0.9858918011773262, 'recall': 0.9855607293545159, 'f1-score': 0.9857086424919604, 'support': 10182} weighted_avg {'precision': 0.9866641632751197, 'recall': 0.9866430956590061, 'f1-score': 0.986636914650074, 'support': 10182}
 
time = 30.84 secondes

Val loss 0.6867075405904652 accuracy 0.9045936465263367 macro_avg {'precision': 0.9080458389823691, 'recall': 0.9058795315012732, 'f1-score': 0.9053435664155345, 'support': 1132} weighted_avg {'precision': 0.9083404948090498, 'recall': 0.9045936395759717, 'f1-score': 0.9047736903641405, 'support': 1132}
 
----------
Epoch 17/40
time = 1968.35 secondes

Train loss 0.07300471013220763 accuracy 0.9857591986656189 macro_avg {'precision': 0.9852802804885125, 'recall': 0.985147983043946, 'f1-score': 0.985197090117327, 'support': 10182} weighted_avg {'precision': 0.9857893228564907, 'recall': 0.9857591828717345, 'f1-score': 0.9857576666246162, 'support': 10182}
 
time = 31.50 secondes

Val loss 0.5952261553605458 accuracy 0.9257950782775879 macro_avg {'precision': 0.9274656166323816, 'recall': 0.9260169356691668, 'f1-score': 0.9260591113129746, 'support': 1132} weighted_avg {'precision': 0.9276916627945143, 'recall': 0.9257950530035336, 'f1-score': 0.9260313058761332, 'support': 1132}
 
----------
Epoch 18/40
time = 1968.23 secondes

Train loss 0.07034564817338125 accuracy 0.987625241279602 macro_avg {'precision': 0.9874519164242554, 'recall': 0.987319596592134, 'f1-score': 0.987366758438546, 'support': 10182} weighted_avg {'precision': 0.9876784472738857, 'recall': 0.9876252209781968, 'f1-score': 0.9876330194544024, 'support': 10182}
 
time = 31.01 secondes

Val loss 0.7667589933119762 accuracy 0.9019434452056885 macro_avg {'precision': 0.9090454336593765, 'recall': 0.8990187815107005, 'f1-score': 0.8994367060941109, 'support': 1132} weighted_avg {'precision': 0.9093779320662115, 'recall': 0.9019434628975265, 'f1-score': 0.9011355178037215, 'support': 1132}
 
----------
Epoch 19/40
time = 1969.34 secondes

Train loss 0.07468594358979488 accuracy 0.9866431355476379 macro_avg {'precision': 0.9865456806584223, 'recall': 0.9863758063109703, 'f1-score': 0.9864437953985726, 'support': 10182} weighted_avg {'precision': 0.9866912437003861, 'recall': 0.9866430956590061, 'f1-score': 0.9866503103198314, 'support': 10182}
 
time = 31.67 secondes

Val loss 0.689009317999413 accuracy 0.9187279343605042 macro_avg {'precision': 0.9195296110400722, 'recall': 0.9209226332544086, 'f1-score': 0.9185065640780163, 'support': 1132} weighted_avg {'precision': 0.9210348379466033, 'recall': 0.9187279151943463, 'f1-score': 0.918014782645164, 'support': 1132}
 
----------
Epoch 20/40
time = 1970.38 secondes

Train loss 0.06759523029909381 accuracy 0.9873306155204773 macro_avg {'precision': 0.9869737002293419, 'recall': 0.9869554944969371, 'f1-score': 0.9869466781023218, 'support': 10182} weighted_avg {'precision': 0.9873885682947254, 'recall': 0.9873305833824396, 'f1-score': 0.9873419297097317, 'support': 10182}
 
time = 32.47 secondes

Val loss 0.7842806870909735 accuracy 0.9019434452056885 macro_avg {'precision': 0.9082400971754895, 'recall': 0.9017556957963953, 'f1-score': 0.9007158391788408, 'support': 1132} weighted_avg {'precision': 0.9101204216707273, 'recall': 0.9019434628975265, 'f1-score': 0.901753366431064, 'support': 1132}
 
----------
Epoch 21/40
time = 1968.94 secondes

Train loss 0.07249719949646001 accuracy 0.987625241279602 macro_avg {'precision': 0.9874036897860481, 'recall': 0.9873407694258454, 'f1-score': 0.9873537647368049, 'support': 10182} weighted_avg {'precision': 0.987652051445917, 'recall': 0.9876252209781968, 'f1-score': 0.9876198055167783, 'support': 10182}
 
time = 30.78 secondes

Val loss 0.8451056354742704 accuracy 0.8948763608932495 macro_avg {'precision': 0.9145266401122646, 'recall': 0.8973780724731928, 'f1-score': 0.8999460725417698, 'support': 1132} weighted_avg {'precision': 0.9101231268213059, 'recall': 0.8948763250883393, 'f1-score': 0.8956322155158466, 'support': 1132}
 
----------
Epoch 22/40
time = 1967.35 secondes

Train loss 0.04456270651343469 accuracy 0.9915537238121033 macro_avg {'precision': 0.9911484532010073, 'recall': 0.9913735276797212, 'f1-score': 0.991256655819267, 'support': 10182} weighted_avg {'precision': 0.9915674934964279, 'recall': 0.9915537222549597, 'f1-score': 0.991556526879235, 'support': 10182}
 
time = 31.18 secondes

Val loss 0.7602377541444812 accuracy 0.9081271886825562 macro_avg {'precision': 0.9172312542224612, 'recall': 0.9095461158180391, 'f1-score': 0.9103388696955758, 'support': 1132} weighted_avg {'precision': 0.9158308043893121, 'recall': 0.9081272084805654, 'f1-score': 0.9087365119974261, 'support': 1132}
 
----------
Epoch 23/40
time = 1968.92 secondes

Train loss 0.06508864633072234 accuracy 0.9890002012252808 macro_avg {'precision': 0.9888837291872467, 'recall': 0.9888926729815679, 'f1-score': 0.9888763799650416, 'support': 10182} weighted_avg {'precision': 0.9890171089739401, 'recall': 0.9890001964250639, 'f1-score': 0.988996679217429, 'support': 10182}
 
time = 31.80 secondes

Val loss 0.7870738143394422 accuracy 0.9081271886825562 macro_avg {'precision': 0.9223210842463778, 'recall': 0.911138058284777, 'f1-score': 0.9115742363403407, 'support': 1132} weighted_avg {'precision': 0.9215161268841603, 'recall': 0.9081272084805654, 'f1-score': 0.9089133057958443, 'support': 1132}
 
----------
Epoch 24/40
time = 1969.05 secondes

Train loss 0.050383355161881936 accuracy 0.9908662438392639 macro_avg {'precision': 0.990720561143522, 'recall': 0.9903168530583418, 'f1-score': 0.9904900803271734, 'support': 10182} weighted_avg {'precision': 0.9908723135421121, 'recall': 0.9908662345315262, 'f1-score': 0.9908431636471868, 'support': 10182}
 
time = 30.88 secondes

Val loss 0.6375590208235351 accuracy 0.9196113348007202 macro_avg {'precision': 0.9247670765531859, 'recall': 0.9197302261680053, 'f1-score': 0.919878644768341, 'support': 1132} weighted_avg {'precision': 0.9239224766408989, 'recall': 0.9196113074204947, 'f1-score': 0.9194982793169191, 'support': 1132}
 
----------
Epoch 25/40
time = 1967.50 secondes

Train loss 0.03789173212385357 accuracy 0.9933215975761414 macro_avg {'precision': 0.993223119905676, 'recall': 0.993274037134821, 'f1-score': 0.9932456832713799, 'support': 10182} weighted_avg {'precision': 0.9933211884982651, 'recall': 0.993321547829503, 'f1-score': 0.9933186662619775, 'support': 10182}
 
time = 31.06 secondes

Val loss 0.7066802216672649 accuracy 0.9196113348007202 macro_avg {'precision': 0.9258705465548779, 'recall': 0.92298493954264, 'f1-score': 0.9231400092423689, 'support': 1132} weighted_avg {'precision': 0.9230730262168728, 'recall': 0.9196113074204947, 'f1-score': 0.9199616402248103, 'support': 1132}
 
----------
Epoch 26/40
time = 1970.24 secondes

Train loss 0.04538584498287339 accuracy 0.9925358891487122 macro_avg {'precision': 0.9924941480990638, 'recall': 0.9924920710331169, 'f1-score': 0.9924693820884063, 'support': 10182} weighted_avg {'precision': 0.9925675572874594, 'recall': 0.9925358475741505, 'f1-score': 0.9925273601926069, 'support': 10182}
 
time = 31.39 secondes

Val loss 0.6735755487557904 accuracy 0.9196113348007202 macro_avg {'precision': 0.9266010755027502, 'recall': 0.9204788818440937, 'f1-score': 0.9211814610167405, 'support': 1132} weighted_avg {'precision': 0.9244475511684381, 'recall': 0.9196113074204947, 'f1-score': 0.9197223101689566, 'support': 1132}
 
----------
Epoch 27/40
time = 1970.36 secondes

Train loss 0.03865078300210654 accuracy 0.9931251406669617 macro_avg {'precision': 0.9929223081397943, 'recall': 0.9929059165489909, 'f1-score': 0.9929013227859169, 'support': 10182} weighted_avg {'precision': 0.9931498337834147, 'recall': 0.9931251227656649, 'f1-score': 0.9931241991853007, 'support': 10182}
 
time = 33.80 secondes

Val loss 0.7303964099595709 accuracy 0.9125441908836365 macro_avg {'precision': 0.9136352365355954, 'recall': 0.9119182223719962, 'f1-score': 0.9113135870303773, 'support': 1132} weighted_avg {'precision': 0.9158670669037602, 'recall': 0.9125441696113075, 'f1-score': 0.9128800870156009, 'support': 1132}
 
----------
Epoch 28/40
time = 1974.64 secondes

Train loss 0.038805423571924264 accuracy 0.992634117603302 macro_avg {'precision': 0.992496106160023, 'recall': 0.9925274956603616, 'f1-score': 0.9924963360359058, 'support': 10182} weighted_avg {'precision': 0.9926604437333354, 'recall': 0.9926340601060696, 'f1-score': 0.9926316850652308, 'support': 10182}
 
time = 34.02 secondes

Val loss 0.7164577275468897 accuracy 0.916961133480072 macro_avg {'precision': 0.9229683545446943, 'recall': 0.9187890181484452, 'f1-score': 0.9189708498621971, 'support': 1132} weighted_avg {'precision': 0.9211599977706397, 'recall': 0.9169611307420494, 'f1-score': 0.9171482676834114, 'support': 1132}
 
----------
Epoch 29/40
time = 1976.06 secondes

Train loss 0.03290819619558439 accuracy 0.9944019317626953 macro_avg {'precision': 0.9943185608862593, 'recall': 0.9941281216880448, 'f1-score': 0.9942151558770007, 'support': 10182} weighted_avg {'precision': 0.9944112413973945, 'recall': 0.9944018856806128, 'f1-score': 0.9943983843558961, 'support': 10182}
 
time = 33.39 secondes

Val loss 0.6264945508354827 accuracy 0.926678478717804 macro_avg {'precision': 0.931369720285516, 'recall': 0.9289639876429139, 'f1-score': 0.9285872558954147, 'support': 1132} weighted_avg {'precision': 0.9302928850662366, 'recall': 0.926678445229682, 'f1-score': 0.9268253866149903, 'support': 1132}
 
----------
Epoch 30/40
time = 1972.75 secondes

Train loss 0.03286592265416105 accuracy 0.9936162233352661 macro_avg {'precision': 0.993776175319612, 'recall': 0.9936830925625866, 'f1-score': 0.9937251307537835, 'support': 10182} weighted_avg {'precision': 0.9936276825447218, 'recall': 0.9936161854252603, 'f1-score': 0.9936174463208958, 'support': 10182}
 
time = 34.12 secondes

Val loss 0.7075607613574826 accuracy 0.9213780760765076 macro_avg {'precision': 0.9232474170271139, 'recall': 0.9239753709173252, 'f1-score': 0.9215333584290504, 'support': 1132} weighted_avg {'precision': 0.9249448318950841, 'recall': 0.9213780918727915, 'f1-score': 0.920805734018261, 'support': 1132}
 
----------
Epoch 31/40
time = 1975.68 secondes

Train loss 0.028810246736762933 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953998224434523, 'recall': 0.9954347363337902, 'f1-score': 0.9954112801676441, 'support': 10182} weighted_avg {'precision': 0.9953997065931007, 'recall': 0.9953840109998036, 'f1-score': 0.9953856737326428, 'support': 10182}
 
time = 33.30 secondes

Val loss 0.6770085665912504 accuracy 0.9222614765167236 macro_avg {'precision': 0.9268979778158297, 'recall': 0.9236380971431011, 'f1-score': 0.9237736434875009, 'support': 1132} weighted_avg {'precision': 0.9240805541323128, 'recall': 0.9222614840989399, 'f1-score': 0.9215963871901871, 'support': 1132}
 
----------
Epoch 32/40
time = 1974.08 secondes

Train loss 0.018347759505502114 accuracy 0.9967589974403381 macro_avg {'precision': 0.9968374837550794, 'recall': 0.9966995745204453, 'f1-score': 0.9967650445930282, 'support': 10182} weighted_avg {'precision': 0.9967669782539086, 'recall': 0.9967589864466706, 'f1-score': 0.9967595938086168, 'support': 10182}
 
time = 33.75 secondes

Val loss 0.6862825452214604 accuracy 0.9178445339202881 macro_avg {'precision': 0.9235129349475301, 'recall': 0.9195014597540089, 'f1-score': 0.9190698896009678, 'support': 1132} weighted_avg {'precision': 0.9217549757169377, 'recall': 0.9178445229681979, 'f1-score': 0.9174367588905451, 'support': 1132}
 
----------
Epoch 33/40
time = 1976.25 secondes

Train loss 0.02432708912124933 accuracy 0.9955804944038391 macro_avg {'precision': 0.995734622460137, 'recall': 0.9956741436616119, 'f1-score': 0.9956960326655249, 'support': 10182} weighted_avg {'precision': 0.995598208048581, 'recall': 0.9955804360636418, 'f1-score': 0.9955808126612817, 'support': 10182}
 
time = 33.90 secondes

Val loss 0.6598666850929387 accuracy 0.9213780760765076 macro_avg {'precision': 0.926404279267854, 'recall': 0.9221635200978004, 'f1-score': 0.9226146058337393, 'support': 1132} weighted_avg {'precision': 0.9245340303062064, 'recall': 0.9213780918727915, 'f1-score': 0.9213551110142159, 'support': 1132}
 
----------
Epoch 34/40
time = 1974.97 secondes

Train loss 0.024045900295667316 accuracy 0.9965626001358032 macro_avg {'precision': 0.9965739456242861, 'recall': 0.9966720922760175, 'f1-score': 0.9966208645752644, 'support': 10182} weighted_avg {'precision': 0.9965678189098051, 'recall': 0.9965625613828325, 'f1-score': 0.9965630186899048, 'support': 10182}
 
time = 33.85 secondes

Val loss 0.6488794243969737 accuracy 0.9257950782775879 macro_avg {'precision': 0.9274322658260192, 'recall': 0.928363981062877, 'f1-score': 0.9267874482946088, 'support': 1132} weighted_avg {'precision': 0.9282061622364292, 'recall': 0.9257950530035336, 'f1-score': 0.9257863138584761, 'support': 1132}
 
----------
Epoch 35/40
time = 1970.19 secondes

Train loss 0.017861617704273008 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973326780462969, 'recall': 0.9973180545645418, 'f1-score': 0.9973236420291179, 'support': 10182} weighted_avg {'precision': 0.9972530008294209, 'recall': 0.9972500491062659, 'f1-score': 0.9972497494642651, 'support': 10182}
 
time = 32.86 secondes

Val loss 0.7316930985063254 accuracy 0.9222614765167236 macro_avg {'precision': 0.9266699700124683, 'recall': 0.9236495203760672, 'f1-score': 0.9228714783996665, 'support': 1132} weighted_avg {'precision': 0.9262155047536949, 'recall': 0.9222614840989399, 'f1-score': 0.9219306546148104, 'support': 1132}
 
----------
Epoch 36/40
time = 1972.30 secondes

Train loss 0.012783697693592779 accuracy 0.9978393316268921 macro_avg {'precision': 0.9978290775850596, 'recall': 0.997856206787978, 'f1-score': 0.9978412100996037, 'support': 10182} weighted_avg {'precision': 0.9978417850118855, 'recall': 0.9978393242977804, 'f1-score': 0.9978391257279868, 'support': 10182}
 
time = 33.70 secondes

Val loss 0.6202488047644731 accuracy 0.9275618195533752 macro_avg {'precision': 0.9294826242173599, 'recall': 0.9293734933070492, 'f1-score': 0.9287703376954421, 'support': 1132} weighted_avg {'precision': 0.9293500741066512, 'recall': 0.9275618374558304, 'f1-score': 0.9277408787441092, 'support': 1132}
 
----------
Epoch 37/40
time = 1975.17 secondes

Train loss 0.006930531266160394 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984705542010813, 'recall': 0.9984182331822316, 'f1-score': 0.998443350911935, 'support': 10182} weighted_avg {'precision': 0.9984297041808421, 'recall': 0.9984285994892949, 'f1-score': 0.9984281083786422, 'support': 10182}
 
time = 33.65 secondes

Val loss 0.7607237091825213 accuracy 0.9143109321594238 macro_avg {'precision': 0.9221243617192408, 'recall': 0.9172948343270555, 'f1-score': 0.917396976117178, 'support': 1132} weighted_avg {'precision': 0.9220994522102982, 'recall': 0.9143109540636042, 'f1-score': 0.9156626199125625, 'support': 1132}
 
----------
Epoch 38/40
time = 1973.85 secondes

Train loss 0.007980673692710901 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986535681887252, 'recall': 0.9985049213348848, 'f1-score': 0.9985768079289915, 'support': 10182} weighted_avg {'precision': 0.9986315657712207, 'recall': 0.998625024553133, 'f1-score': 0.9986260049449338, 'support': 10182}
 
time = 33.83 secondes

Val loss 0.6942520020549867 accuracy 0.9249116778373718 macro_avg {'precision': 0.9283632858810058, 'recall': 0.9265743397971853, 'f1-score': 0.9262758783640889, 'support': 1132} weighted_avg {'precision': 0.9279122504846691, 'recall': 0.9249116607773852, 'f1-score': 0.9252631442675798, 'support': 1132}
 
----------
Epoch 39/40
time = 1972.70 secondes

Train loss 0.00329516498504388 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990397693375556, 'recall': 0.9990181865542509, 'f1-score': 0.9990288652980936, 'support': 10182} weighted_avg {'precision': 0.9991164599358097, 'recall': 0.9991160872127284, 'f1-score': 0.9991161699498377, 'support': 10182}
 
time = 34.06 secondes

Val loss 0.7106747437480574 accuracy 0.9293286204338074 macro_avg {'precision': 0.9330233793019251, 'recall': 0.9315547026938619, 'f1-score': 0.930953892629876, 'support': 1132} weighted_avg {'precision': 0.9322413791590806, 'recall': 0.9293286219081273, 'f1-score': 0.9294417109740774, 'support': 1132}
 
----------
Epoch 40/40
time = 1976.32 secondes

Train loss 0.0015450194008410174 accuracy 0.9997053742408752 macro_avg {'precision': 0.9997173224785165, 'recall': 0.9997167421527259, 'f1-score': 0.9997166751949731, 'support': 10182} weighted_avg {'precision': 0.9997062896709112, 'recall': 0.9997053624042428, 'f1-score': 0.9997054553877998, 'support': 10182}
 
time = 34.02 secondes

Val loss 0.7034735860869288 accuracy 0.926678478717804 macro_avg {'precision': 0.9314125073309609, 'recall': 0.9291962974020846, 'f1-score': 0.9287119334523954, 'support': 1132} weighted_avg {'precision': 0.9303520069491147, 'recall': 0.926678445229682, 'f1-score': 0.9269593282541249, 'support': 1132}
 
----------
best_accuracy 0.9293286204338074 best_epoch 39 macro_avg {'precision': 0.9330233793019251, 'recall': 0.9315547026938619, 'f1-score': 0.930953892629876, 'support': 1132} weighted_avg {'precision': 0.9322413791590806, 'recall': 0.9293286219081273, 'f1-score': 0.9294417109740774, 'support': 1132}

average train time 1970.3236602663994

average val time 32.19191780090332
 
time = 224.91 secondes

test_accuracy 0.8588687777519226 macro_avg {'precision': 0.8569767332329468, 'recall': 0.8525261827851432, 'f1-score': 0.8531514062090622, 'support': 7532} weighted_avg {'precision': 0.8636905513051706, 'recall': 0.8588688263409453, 'f1-score': 0.8598108369711058, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 1; 79.20 GiB total capacity; 73.79 GiB already allocated; 34.31 MiB free; 77.15 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 1; 79.20 GiB total capacity; 72.42 GiB already allocated; 1.41 GiB free; 75.77 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_1
----------
Epoch 1/40
time = 593.83 secondes

Train loss 1.363876957487274 accuracy 0.6318012475967407 macro_avg {'precision': 0.6219675669063636, 'recall': 0.6162290621080941, 'f1-score': 0.6051465940952174, 'support': 10182} weighted_avg {'precision': 0.6316392143743552, 'recall': 0.6318012178353958, 'f1-score': 0.6196438237991014, 'support': 10182}
 
time = 15.96 secondes

Val loss 0.7715614349909232 accuracy 0.7553003430366516 macro_avg {'precision': 0.7354244236221849, 'recall': 0.7534070641028876, 'f1-score': 0.7303889198226365, 'support': 1132} weighted_avg {'precision': 0.7416914577762688, 'recall': 0.7553003533568905, 'f1-score': 0.7320592418114062, 'support': 1132}
 
----------
Epoch 2/40
time = 591.58 secondes

Train loss 0.557014677468892 accuracy 0.8348065614700317 macro_avg {'precision': 0.8235278910687225, 'recall': 0.824108631834321, 'f1-score': 0.8213978910487546, 'support': 10182} weighted_avg {'precision': 0.8310764268037744, 'recall': 0.8348065213121194, 'f1-score': 0.8311939609268059, 'support': 10182}
 
time = 16.83 secondes

Val loss 0.6228385150012835 accuracy 0.8171378374099731 macro_avg {'precision': 0.8255867284755831, 'recall': 0.8135230640802507, 'f1-score': 0.8146722821998271, 'support': 1132} weighted_avg {'precision': 0.8265312731144926, 'recall': 0.8171378091872792, 'f1-score': 0.8170113081839144, 'support': 1132}
 
----------
Epoch 3/40
time = 591.02 secondes

Train loss 0.3304647668155153 accuracy 0.9054213762283325 macro_avg {'precision': 0.9000156533271527, 'recall': 0.8994345710236665, 'f1-score': 0.8994722141335683, 'support': 10182} weighted_avg {'precision': 0.9051178955287316, 'recall': 0.9054213317619328, 'f1-score': 0.9050478533084585, 'support': 10182}
 
time = 16.98 secondes

Val loss 0.5897660834688536 accuracy 0.8480565547943115 macro_avg {'precision': 0.8554812201140407, 'recall': 0.8496052395125681, 'f1-score': 0.8472474845973192, 'support': 1132} weighted_avg {'precision': 0.855459524224257, 'recall': 0.8480565371024735, 'f1-score': 0.8465987198812588, 'support': 1132}
 
----------
Epoch 4/40
time = 591.08 secondes

Train loss 0.20999993272915224 accuracy 0.9425457119941711 macro_avg {'precision': 0.9399918834256425, 'recall': 0.9395274108860698, 'f1-score': 0.9396731969263794, 'support': 10182} weighted_avg {'precision': 0.9425577259492951, 'recall': 0.9425456688273424, 'f1-score': 0.9424733314175996, 'support': 10182}
 
time = 16.36 secondes

Val loss 0.661742647381788 accuracy 0.8577738404273987 macro_avg {'precision': 0.8626146239192239, 'recall': 0.8580163044028115, 'f1-score': 0.8575658095971855, 'support': 1132} weighted_avg {'precision': 0.8628709373262081, 'recall': 0.857773851590106, 'f1-score': 0.8576208601658056, 'support': 1132}
 
----------
Epoch 5/40
time = 591.32 secondes

Train loss 0.17041391923035287 accuracy 0.9538401365280151 macro_avg {'precision': 0.9519984648865659, 'recall': 0.9520746047290434, 'f1-score': 0.9519585271365163, 'support': 10182} weighted_avg {'precision': 0.954084984932269, 'recall': 0.9538401099980357, 'f1-score': 0.9538951641091675, 'support': 10182}
 
time = 16.88 secondes

Val loss 0.706289945747441 accuracy 0.8630741834640503 macro_avg {'precision': 0.8679350152267146, 'recall': 0.8654781447224268, 'f1-score': 0.8626445529599197, 'support': 1132} weighted_avg {'precision': 0.8717788129881208, 'recall': 0.8630742049469965, 'f1-score': 0.8629949681000579, 'support': 1132}
 
----------
Epoch 6/40
time = 588.21 secondes

Train loss 0.1524967707958938 accuracy 0.9637596011161804 macro_avg {'precision': 0.962485424276862, 'recall': 0.9624959023069751, 'f1-score': 0.9624404402727766, 'support': 10182} weighted_avg {'precision': 0.9638391377789158, 'recall': 0.9637595757218621, 'f1-score': 0.963747875245792, 'support': 10182}
 
time = 16.60 secondes

Val loss 0.6874209726311292 accuracy 0.8683745861053467 macro_avg {'precision': 0.8799058617325649, 'recall': 0.8726318980113007, 'f1-score': 0.8722875376302491, 'support': 1132} weighted_avg {'precision': 0.8791664266133817, 'recall': 0.8683745583038869, 'f1-score': 0.8700393650266647, 'support': 1132}
 
----------
Epoch 7/40
time = 592.27 secondes

Train loss 0.13819951308197437 accuracy 0.968375563621521 macro_avg {'precision': 0.9674030603339565, 'recall': 0.9674738486491107, 'f1-score': 0.9674013396569426, 'support': 10182} weighted_avg {'precision': 0.9685122859396822, 'recall': 0.9683755647220585, 'f1-score': 0.9684074722612818, 'support': 10182}
 
time = 15.79 secondes

Val loss 0.7984327265654992 accuracy 0.8630741834640503 macro_avg {'precision': 0.8715978937348534, 'recall': 0.8668550380468105, 'f1-score': 0.8648611959438245, 'support': 1132} weighted_avg {'precision': 0.8723325128457514, 'recall': 0.8630742049469965, 'f1-score': 0.8636296793338736, 'support': 1132}
 
----------
Epoch 8/40
time = 590.49 secondes

Train loss 0.12317228548743563 accuracy 0.9732862114906311 macro_avg {'precision': 0.9724951214080756, 'recall': 0.9723666981310402, 'f1-score': 0.9723912457039574, 'support': 10182} weighted_avg {'precision': 0.9733612956986031, 'recall': 0.9732861913180122, 'f1-score': 0.9732836193913214, 'support': 10182}
 
time = 17.01 secondes

Val loss 0.915242240833886 accuracy 0.8480565547943115 macro_avg {'precision': 0.8638470784763621, 'recall': 0.8514379211584696, 'f1-score': 0.8502917763218477, 'support': 1132} weighted_avg {'precision': 0.86563440699172, 'recall': 0.8480565371024735, 'f1-score': 0.8498161115745764, 'support': 1132}
 
----------
Epoch 9/40
time = 589.95 secondes

Train loss 0.11929547100214052 accuracy 0.975348711013794 macro_avg {'precision': 0.9748550098854357, 'recall': 0.9750641277251461, 'f1-score': 0.974905984714986, 'support': 10182} weighted_avg {'precision': 0.9755099523612107, 'recall': 0.9753486544883128, 'f1-score': 0.9753784855921932, 'support': 10182}
 
time = 16.94 secondes

Val loss 0.9743840965826858 accuracy 0.8568904399871826 macro_avg {'precision': 0.8614498163141816, 'recall': 0.862305237813872, 'f1-score': 0.8562614516710854, 'support': 1132} weighted_avg {'precision': 0.869886895673077, 'recall': 0.8568904593639576, 'f1-score': 0.8576059226414608, 'support': 1132}
 
----------
Epoch 10/40
time = 591.33 secondes

Train loss 0.12115937158082696 accuracy 0.9755451083183289 macro_avg {'precision': 0.9751269915474285, 'recall': 0.975241098210174, 'f1-score': 0.9751306070715116, 'support': 10182} weighted_avg {'precision': 0.9756298213876539, 'recall': 0.9755450795521509, 'f1-score': 0.9755337063961421, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8715683236278751 accuracy 0.8710247278213501 macro_avg {'precision': 0.8890760600229839, 'recall': 0.8728518774969205, 'f1-score': 0.8747442694517422, 'support': 1132} weighted_avg {'precision': 0.88790957681844, 'recall': 0.8710247349823321, 'f1-score': 0.8734591811290356, 'support': 1132}
 
----------
Epoch 11/40
time = 590.53 secondes

Train loss 0.09847337799733874 accuracy 0.9797682762145996 macro_avg {'precision': 0.9799861915122132, 'recall': 0.9796889643826276, 'f1-score': 0.9798243457235722, 'support': 10182} weighted_avg {'precision': 0.9797793695191083, 'recall': 0.979768218424671, 'f1-score': 0.9797613412107742, 'support': 10182}
 
time = 17.32 secondes

Val loss 0.8261909657764629 accuracy 0.870141327381134 macro_avg {'precision': 0.8814086513621197, 'recall': 0.8700234456181505, 'f1-score': 0.8725273976731547, 'support': 1132} weighted_avg {'precision': 0.8801421048250971, 'recall': 0.8701413427561837, 'f1-score': 0.8717788348292034, 'support': 1132}
 
----------
Epoch 12/40
time = 588.72 secondes

Train loss 0.11166711710587607 accuracy 0.9788843393325806 macro_avg {'precision': 0.9779078823520801, 'recall': 0.977934775809091, 'f1-score': 0.9778793862226907, 'support': 10182} weighted_avg {'precision': 0.9789895700748765, 'recall': 0.9788843056373994, 'f1-score': 0.9788993400241113, 'support': 10182}
 
time = 18.27 secondes

Val loss 0.9196654146440445 accuracy 0.8745583295822144 macro_avg {'precision': 0.8801204634456591, 'recall': 0.8781593563857418, 'f1-score': 0.873650868248254, 'support': 1132} weighted_avg {'precision': 0.8870410538921207, 'recall': 0.8745583038869258, 'f1-score': 0.8757542254895645, 'support': 1132}
 
----------
Epoch 13/40
time = 591.02 secondes

Train loss 0.09493987134946005 accuracy 0.9808486104011536 macro_avg {'precision': 0.9805280737054817, 'recall': 0.9802781807544244, 'f1-score': 0.9803775649346832, 'support': 10182} weighted_avg {'precision': 0.9808520353523572, 'recall': 0.9808485562757808, 'f1-score': 0.9808266829087218, 'support': 10182}
 
time = 16.61 secondes

Val loss 0.8753603373372987 accuracy 0.8763250708580017 macro_avg {'precision': 0.8879689631390846, 'recall': 0.8786380267781541, 'f1-score': 0.8802813737967169, 'support': 1132} weighted_avg {'precision': 0.8871468005925203, 'recall': 0.8763250883392226, 'f1-score': 0.8782337932978843, 'support': 1132}
 
----------
Epoch 14/40
time = 591.74 secondes

Train loss 0.09757459068237646 accuracy 0.980455756187439 macro_avg {'precision': 0.9804781256664219, 'recall': 0.9805058542140817, 'f1-score': 0.9804226025878698, 'support': 10182} weighted_avg {'precision': 0.9805905625375722, 'recall': 0.9804557061481045, 'f1-score': 0.9804505640179547, 'support': 10182}
 
time = 16.77 secondes

Val loss 0.9440175439993536 accuracy 0.870141327381134 macro_avg {'precision': 0.8776667072798903, 'recall': 0.8711471268188944, 'f1-score': 0.8720968405512318, 'support': 1132} weighted_avg {'precision': 0.8760384226076041, 'recall': 0.8701413427561837, 'f1-score': 0.870524956327045, 'support': 1132}
 
----------
Epoch 15/40
time = 589.56 secondes

Train loss 0.07339005263290076 accuracy 0.9864466786384583 macro_avg {'precision': 0.9862388393610388, 'recall': 0.9861366091113395, 'f1-score': 0.9861579702410161, 'support': 10182} weighted_avg {'precision': 0.986505096117307, 'recall': 0.986446670595168, 'f1-score': 0.9864452027337688, 'support': 10182}
 
time = 16.34 secondes

Val loss 0.9512021561105273 accuracy 0.8833922147750854 macro_avg {'precision': 0.8887365879951028, 'recall': 0.8827653256199213, 'f1-score': 0.8835691770259411, 'support': 1132} weighted_avg {'precision': 0.8870937153200148, 'recall': 0.8833922261484098, 'f1-score': 0.8830996000945425, 'support': 1132}
 
----------
Epoch 16/40
time = 589.18 secondes

Train loss 0.08344646213513877 accuracy 0.9848753213882446 macro_avg {'precision': 0.9840932809011184, 'recall': 0.9840578368789611, 'f1-score': 0.9840593331990292, 'support': 10182} weighted_avg {'precision': 0.984913325629185, 'recall': 0.9848752700844627, 'f1-score': 0.9848796329346475, 'support': 10182}
 
time = 16.75 secondes

Val loss 1.073947195377091 accuracy 0.8551236987113953 macro_avg {'precision': 0.8707538056922042, 'recall': 0.8583180701886379, 'f1-score': 0.8564478758728822, 'support': 1132} weighted_avg {'precision': 0.8688378889227628, 'recall': 0.8551236749116607, 'f1-score': 0.8535218997839005, 'support': 1132}
 
----------
Epoch 17/40
time = 586.51 secondes

Train loss 0.07991379073025473 accuracy 0.9862502813339233 macro_avg {'precision': 0.9855950188348116, 'recall': 0.9855060561959436, 'f1-score': 0.9855382053544879, 'support': 10182} weighted_avg {'precision': 0.9862813908655562, 'recall': 0.9862502455313298, 'f1-score': 0.9862534609093064, 'support': 10182}
 
time = 16.71 secondes

Val loss 1.0605800584295575 accuracy 0.8736749291419983 macro_avg {'precision': 0.8850479162897056, 'recall': 0.8722001319107303, 'f1-score': 0.8737280761990893, 'support': 1132} weighted_avg {'precision': 0.8860168641686001, 'recall': 0.8736749116607774, 'f1-score': 0.8749506594201214, 'support': 1132}
 
----------
Epoch 18/40
time = 589.07 secondes

Train loss 0.0861483214397726 accuracy 0.9852681756019592 macro_avg {'precision': 0.9854210150411511, 'recall': 0.9852482915666446, 'f1-score': 0.9852790957757647, 'support': 10182} weighted_avg {'precision': 0.9853368224525374, 'recall': 0.985268120212139, 'f1-score': 0.9852456805130646, 'support': 10182}
 
time = 17.10 secondes

Val loss 1.1581905079441077 accuracy 0.862190842628479 macro_avg {'precision': 0.8834115785618744, 'recall': 0.8657130543275858, 'f1-score': 0.8670116732249078, 'support': 1132} weighted_avg {'precision': 0.8830328201499245, 'recall': 0.8621908127208481, 'f1-score': 0.8657278388065928, 'support': 1132}
 
----------
Epoch 19/40
time = 591.21 secondes

Train loss 0.08721661214878289 accuracy 0.985660970211029 macro_avg {'precision': 0.9859819693174604, 'recall': 0.9857599266485101, 'f1-score': 0.9858134164448554, 'support': 10182} weighted_avg {'precision': 0.98579752788549, 'recall': 0.9856609703398154, 'f1-score': 0.9856699487542481, 'support': 10182}
 
time = 16.96 secondes

Val loss 1.0670490343973014 accuracy 0.870141327381134 macro_avg {'precision': 0.8729220068011241, 'recall': 0.8740597762290451, 'f1-score': 0.8684269699636449, 'support': 1132} weighted_avg {'precision': 0.8803565538930843, 'recall': 0.8701413427561837, 'f1-score': 0.8706957707947908, 'support': 1132}
 
----------
Epoch 20/40
time = 590.38 secondes

Train loss 0.06570890435313298 accuracy 0.9885091781616211 macro_avg {'precision': 0.9886874073720705, 'recall': 0.9885492361972533, 'f1-score': 0.9885932643088433, 'support': 10182} weighted_avg {'precision': 0.9885425087397866, 'recall': 0.9885091337654685, 'f1-score': 0.9885003831991043, 'support': 10182}
 
time = 17.16 secondes

Val loss 0.8751781067657645 accuracy 0.8860424160957336 macro_avg {'precision': 0.8890840916721503, 'recall': 0.889544503541317, 'f1-score': 0.8868606135251248, 'support': 1132} weighted_avg {'precision': 0.8910605422308987, 'recall': 0.8860424028268551, 'f1-score': 0.8862569954616933, 'support': 1132}
 
----------
Epoch 21/40
time = 590.97 secondes

Train loss 0.05312643634292733 accuracy 0.9898841381072998 macro_avg {'precision': 0.9895693848104479, 'recall': 0.9897152709414268, 'f1-score': 0.9896265168873996, 'support': 10182} weighted_avg {'precision': 0.9899090755547636, 'recall': 0.9898841092123355, 'f1-score': 0.9898804301973363, 'support': 10182}
 
time = 17.53 secondes

Val loss 0.9317981935970929 accuracy 0.880742073059082 macro_avg {'precision': 0.88694554817333, 'recall': 0.8827598760506181, 'f1-score': 0.8819589043249154, 'support': 1132} weighted_avg {'precision': 0.8897223131762549, 'recall': 0.8807420494699647, 'f1-score': 0.8821971658207212, 'support': 1132}
 
----------
Epoch 22/40
time = 591.99 secondes

Train loss 0.05768580543410917 accuracy 0.9896877408027649 macro_avg {'precision': 0.9893712237861207, 'recall': 0.9895111387946492, 'f1-score': 0.9894246042589856, 'support': 10182} weighted_avg {'precision': 0.9897221554263462, 'recall': 0.9896876841484974, 'f1-score': 0.9896889058922641, 'support': 10182}
 
time = 16.53 secondes

Val loss 0.946540291215339 accuracy 0.8869258165359497 macro_avg {'precision': 0.8933017385894922, 'recall': 0.8895337385641824, 'f1-score': 0.889069429577923, 'support': 1132} weighted_avg {'precision': 0.8944900650587266, 'recall': 0.8869257950530035, 'f1-score': 0.8881182654227018, 'support': 1132}
 
----------
Epoch 23/40
time = 591.67 secondes

Train loss 0.053760909237346964 accuracy 0.9907680749893188 macro_avg {'precision': 0.9905670015897478, 'recall': 0.9906797369997078, 'f1-score': 0.9906061990334599, 'support': 10182} weighted_avg {'precision': 0.9907953966840135, 'recall': 0.9907680219996071, 'f1-score': 0.9907640727029239, 'support': 10182}
 
time = 17.68 secondes

Val loss 1.1075881983504612 accuracy 0.8657243847846985 macro_avg {'precision': 0.8717974588695439, 'recall': 0.8700513279328828, 'f1-score': 0.8666531908860623, 'support': 1132} weighted_avg {'precision': 0.8766704047717264, 'recall': 0.8657243816254417, 'f1-score': 0.8664772788871773, 'support': 1132}
 
----------
Epoch 24/40
time = 594.86 secondes

Train loss 0.04264928724816335 accuracy 0.992634117603302 macro_avg {'precision': 0.9927044697623456, 'recall': 0.9925318882351573, 'f1-score': 0.992611148712025, 'support': 10182} weighted_avg {'precision': 0.9926479271692571, 'recall': 0.9926340601060696, 'f1-score': 0.9926340719124993, 'support': 10182}
 
time = 17.60 secondes

Val loss 1.0959075825307543 accuracy 0.870141327381134 macro_avg {'precision': 0.8834549488828355, 'recall': 0.8743032146165184, 'f1-score': 0.8729561203459628, 'support': 1132} weighted_avg {'precision': 0.882659132646032, 'recall': 0.8701413427561837, 'f1-score': 0.8703099764615837, 'support': 1132}
 
----------
Epoch 25/40
time = 597.54 secondes

Train loss 0.03986413236122974 accuracy 0.9925358891487122 macro_avg {'precision': 0.9922058627132602, 'recall': 0.9923444790675997, 'f1-score': 0.9922534681558121, 'support': 10182} weighted_avg {'precision': 0.9925819150017311, 'recall': 0.9925358475741505, 'f1-score': 0.9925370970230118, 'support': 10182}
 
time = 16.98 secondes

Val loss 1.050225748368998 accuracy 0.8833922147750854 macro_avg {'precision': 0.8886843794174336, 'recall': 0.8851697202769422, 'f1-score': 0.8830492139815641, 'support': 1132} weighted_avg {'precision': 0.892767284065299, 'recall': 0.8833922261484098, 'f1-score': 0.884887483886181, 'support': 1132}
 
----------
Epoch 26/40
time = 591.67 secondes

Train loss 0.037054791675010496 accuracy 0.9934197664260864 macro_avg {'precision': 0.99313065754043, 'recall': 0.99305843625437, 'f1-score': 0.9930893648984123, 'support': 10182} weighted_avg {'precision': 0.9934227638452284, 'recall': 0.9934197603614221, 'f1-score': 0.9934162942643276, 'support': 10182}
 
time = 17.08 secondes

Val loss 1.2359041081161732 accuracy 0.8692579865455627 macro_avg {'precision': 0.8788665106551745, 'recall': 0.8691041453495527, 'f1-score': 0.869427202041732, 'support': 1132} weighted_avg {'precision': 0.8807546080452783, 'recall': 0.8692579505300353, 'f1-score': 0.8701553542881958, 'support': 1132}
 
----------
Epoch 27/40
time = 593.63 secondes

Train loss 0.0516049438832212 accuracy 0.991750180721283 macro_avg {'precision': 0.9912488329231636, 'recall': 0.991254815479271, 'f1-score': 0.991241716452129, 'support': 10182} weighted_avg {'precision': 0.991762385652508, 'recall': 0.9917501473187978, 'f1-score': 0.9917465797821747, 'support': 10182}
 
time = 17.07 secondes

Val loss 1.010328092641225 accuracy 0.8772084712982178 macro_avg {'precision': 0.8802975889295386, 'recall': 0.8800168786144997, 'f1-score': 0.8772845256166903, 'support': 1132} weighted_avg {'precision': 0.8852345293050069, 'recall': 0.877208480565371, 'f1-score': 0.878839866751506, 'support': 1132}
 
----------
Epoch 28/40
time = 593.86 secondes

Train loss 0.045970420075234705 accuracy 0.9923394322395325 macro_avg {'precision': 0.9918883137128901, 'recall': 0.9923099255524779, 'f1-score': 0.9920861849760758, 'support': 10182} weighted_avg {'precision': 0.9923792146286943, 'recall': 0.9923394225103123, 'f1-score': 0.992347840108906, 'support': 10182}
 
time = 17.07 secondes

Val loss 1.060616118166033 accuracy 0.879858672618866 macro_avg {'precision': 0.886134539117783, 'recall': 0.881986200366811, 'f1-score': 0.8802027136621368, 'support': 1132} weighted_avg {'precision': 0.8879126083079533, 'recall': 0.8798586572438163, 'f1-score': 0.879857961971647, 'support': 1132}
 
----------
Epoch 29/40
time = 593.07 secondes

Train loss 0.03604197155530513 accuracy 0.9933215975761414 macro_avg {'precision': 0.9934465075493447, 'recall': 0.9930509621662074, 'f1-score': 0.9932306503472974, 'support': 10182} weighted_avg {'precision': 0.9933666329078297, 'recall': 0.993321547829503, 'f1-score': 0.9933273210615942, 'support': 10182}
 
time = 16.87 secondes

Val loss 1.02011854675051 accuracy 0.8825088143348694 macro_avg {'precision': 0.8835137716391983, 'recall': 0.8835498606724196, 'f1-score': 0.8808415971579413, 'support': 1132} weighted_avg {'precision': 0.8870495079628559, 'recall': 0.8825088339222615, 'f1-score': 0.8820430577388052, 'support': 1132}
 
----------
Epoch 30/40
time = 595.95 secondes

Train loss 0.025511366884401206 accuracy 0.9949911832809448 macro_avg {'precision': 0.9950273528496307, 'recall': 0.994802850174025, 'f1-score': 0.9949063661226448, 'support': 10182} weighted_avg {'precision': 0.9950058711949755, 'recall': 0.9949911608721272, 'f1-score': 0.9949906916521188, 'support': 10182}
 
time = 16.84 secondes

Val loss 1.1592239148430707 accuracy 0.8780918717384338 macro_avg {'precision': 0.8832126853429637, 'recall': 0.8801163133437109, 'f1-score': 0.8776773527196845, 'support': 1132} weighted_avg {'precision': 0.8868508029648029, 'recall': 0.8780918727915195, 'f1-score': 0.8784662478891833, 'support': 1132}
 
----------
Epoch 31/40
time = 596.37 secondes

Train loss 0.02625853095316581 accuracy 0.9950894117355347 macro_avg {'precision': 0.994888898106014, 'recall': 0.9949997004368457, 'f1-score': 0.9949419516382341, 'support': 10182} weighted_avg {'precision': 0.9950943943152157, 'recall': 0.9950893734040464, 'f1-score': 0.9950895183048087, 'support': 10182}
 
time = 17.09 secondes

Val loss 1.1038773953608232 accuracy 0.8754417300224304 macro_avg {'precision': 0.8761754979375477, 'recall': 0.8760495883239889, 'f1-score': 0.8721431941579116, 'support': 1132} weighted_avg {'precision': 0.8809500067986047, 'recall': 0.8754416961130742, 'f1-score': 0.8744360729032542, 'support': 1132}
 
----------
Epoch 32/40
time = 598.12 secondes

Train loss 0.023324909990409783 accuracy 0.9951876401901245 macro_avg {'precision': 0.9949992353799839, 'recall': 0.9949740802314357, 'f1-score': 0.9949839566757296, 'support': 10182} weighted_avg {'precision': 0.9951899149342343, 'recall': 0.9951875859359655, 'f1-score': 0.9951860679130825, 'support': 10182}
 
time = 16.89 secondes

Val loss 0.9937067284990917 accuracy 0.8860424160957336 macro_avg {'precision': 0.8909909452163924, 'recall': 0.8890918349858283, 'f1-score': 0.8886510312947313, 'support': 1132} weighted_avg {'precision': 0.889317443931592, 'recall': 0.8860424028268551, 'f1-score': 0.886198659644742, 'support': 1132}
 
----------
Epoch 33/40
time = 591.63 secondes

Train loss 0.024219514309115023 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967531430342742, 'recall': 0.9967280454065491, 'f1-score': 0.9967348394881075, 'support': 10182} weighted_avg {'precision': 0.996764479150501, 'recall': 0.9967589864466706, 'f1-score': 0.9967561068562973, 'support': 10182}
 
time = 14.70 secondes

Val loss 0.9897398034304707 accuracy 0.8904593586921692 macro_avg {'precision': 0.8930753401191481, 'recall': 0.8916098243322255, 'f1-score': 0.8907420182850002, 'support': 1132} weighted_avg {'precision': 0.8951604337475846, 'recall': 0.8904593639575972, 'f1-score': 0.8912490058371428, 'support': 1132}
 
----------
Epoch 34/40
time = 588.77 secondes

Train loss 0.01670256114611473 accuracy 0.9967589974403381 macro_avg {'precision': 0.9965914452528237, 'recall': 0.9965634902416246, 'f1-score': 0.9965752051325204, 'support': 10182} weighted_avg {'precision': 0.9967641947055316, 'recall': 0.9967589864466706, 'f1-score': 0.996759533458411, 'support': 10182}
 
time = 14.73 secondes

Val loss 0.9774474917593464 accuracy 0.8913427591323853 macro_avg {'precision': 0.8930191813625322, 'recall': 0.8907362668637111, 'f1-score': 0.8908365919973773, 'support': 1132} weighted_avg {'precision': 0.8933516103386252, 'recall': 0.8913427561837456, 'f1-score': 0.8913361512496238, 'support': 1132}
 
----------
Epoch 35/40
time = 588.03 secondes

Train loss 0.01597459156630574 accuracy 0.9975447058677673 macro_avg {'precision': 0.9976161459476721, 'recall': 0.997610643715241, 'f1-score': 0.9976120086802747, 'support': 10182} weighted_avg {'precision': 0.9975484252481964, 'recall': 0.9975446867020232, 'f1-score': 0.9975451462297761, 'support': 10182}
 
time = 16.28 secondes

Val loss 0.9407146067782711 accuracy 0.8966431021690369 macro_avg {'precision': 0.9004323806377723, 'recall': 0.8955636473332775, 'f1-score': 0.8964118357354021, 'support': 1132} weighted_avg {'precision': 0.8991742397743231, 'recall': 0.8966431095406361, 'f1-score': 0.8963355344711164, 'support': 1132}
 
----------
Epoch 36/40
time = 588.31 secondes

Train loss 0.007348901658403964 accuracy 0.998821496963501 macro_avg {'precision': 0.9988026642635607, 'recall': 0.9987538272088969, 'f1-score': 0.9987774301659209, 'support': 10182} weighted_avg {'precision': 0.9988218339050232, 'recall': 0.9988214496169712, 'f1-score': 0.998820852670386, 'support': 10182}
 
time = 14.76 secondes

Val loss 0.9138935802004813 accuracy 0.9072438478469849 macro_avg {'precision': 0.909810069277295, 'recall': 0.9093737167984097, 'f1-score': 0.9082030826228028, 'support': 1132} weighted_avg {'precision': 0.9102942464481957, 'recall': 0.907243816254417, 'f1-score': 0.9073994714608414, 'support': 1132}
 
----------
Epoch 37/40
time = 586.91 secondes

Train loss 0.01273118704690345 accuracy 0.9983304142951965 macro_avg {'precision': 0.9981670347875464, 'recall': 0.9982542380728147, 'f1-score': 0.9982087857933551, 'support': 10182} weighted_avg {'precision': 0.998333738714354, 'recall': 0.9983303869573757, 'f1-score': 0.9983303455360703, 'support': 10182}
 
time = 14.67 secondes

Val loss 1.0919852412349735 accuracy 0.8886925578117371 macro_avg {'precision': 0.8948524538983282, 'recall': 0.8904521803714369, 'f1-score': 0.8883246571372927, 'support': 1132} weighted_avg {'precision': 0.8978709575176661, 'recall': 0.8886925795053003, 'f1-score': 0.8894881551724885, 'support': 1132}
 
----------
Epoch 38/40
time = 584.25 secondes

Train loss 0.01865072085014877 accuracy 0.997741162776947 macro_avg {'precision': 0.9976236963774193, 'recall': 0.9976474224237742, 'f1-score': 0.9976308035695904, 'support': 10182} weighted_avg {'precision': 0.9977524370501674, 'recall': 0.9977411117658613, 'f1-score': 0.9977425297494421, 'support': 10182}
 
time = 14.65 secondes

Val loss 1.0109761600443292 accuracy 0.8966431021690369 macro_avg {'precision': 0.8996604189940669, 'recall': 0.8975337933339338, 'f1-score': 0.8974052179529807, 'support': 1132} weighted_avg {'precision': 0.8993350507324346, 'recall': 0.8966431095406361, 'f1-score': 0.8967795436010648, 'support': 1132}
 
----------
Epoch 39/40
time = 585.50 secondes

Train loss 0.009422494329458686 accuracy 0.998919665813446 macro_avg {'precision': 0.9989388009801641, 'recall': 0.9989095909144632, 'f1-score': 0.9989234451328652, 'support': 10182} weighted_avg {'precision': 0.9989205407240646, 'recall': 0.9989196621488902, 'f1-score': 0.9989193417572121, 'support': 10182}
 
time = 14.69 secondes

Val loss 0.9406755209846536 accuracy 0.8992933034896851 macro_avg {'precision': 0.9010791360853293, 'recall': 0.9005931081054206, 'f1-score': 0.8995829560929911, 'support': 1132} weighted_avg {'precision': 0.9016531805539091, 'recall': 0.8992932862190812, 'f1-score': 0.8992986843600851, 'support': 1132}
 
----------
Epoch 40/40
time = 583.33 secondes

Train loss 0.002459614557655196 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990985364285295, 'recall': 0.9991335006604857, 'f1-score': 0.9991148780812986, 'support': 10182} weighted_avg {'precision': 0.9991182192094876, 'recall': 0.9991160872127284, 'f1-score': 0.9991160143108517, 'support': 10182}
 
time = 14.66 secondes

Val loss 0.9178134458127549 accuracy 0.8992933034896851 macro_avg {'precision': 0.902189933006866, 'recall': 0.9001146802556063, 'f1-score': 0.8998476335335134, 'support': 1132} weighted_avg {'precision': 0.902119500593555, 'recall': 0.8992932862190812, 'f1-score': 0.8994650571513435, 'support': 1132}
 
----------
best_accuracy 0.9072438478469849 best_epoch 36 macro_avg {'precision': 0.909810069277295, 'recall': 0.9093737167984097, 'f1-score': 0.9082030826228028, 'support': 1132} weighted_avg {'precision': 0.9102942464481957, 'recall': 0.907243816254417, 'f1-score': 0.9073994714608414, 'support': 1132}

average train time 590.8849567055702

average val time 16.514378243684767
 
time = 96.05 secondes

test_accuracy 0.8311205506324768 macro_avg {'precision': 0.8285864063206934, 'recall': 0.8254993675605865, 'f1-score': 0.825322148403276, 'support': 7532} weighted_avg {'precision': 0.8355296673709282, 'recall': 0.8311205523101434, 'f1-score': 0.8316809154554151, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 426.65 secondes

Train loss 1.4535107555999487 accuracy 0.5951679348945618 macro_avg {'precision': 0.5938783786300208, 'recall': 0.5792260414617891, 'f1-score': 0.5685507453904417, 'support': 10182} weighted_avg {'precision': 0.6004721356329941, 'recall': 0.5951679434295816, 'f1-score': 0.582526252921625, 'support': 10182}
 
time = 11.62 secondes

Val loss 0.7857380941720076 accuracy 0.7446996569633484 macro_avg {'precision': 0.7268897924080193, 'recall': 0.7426184679961072, 'f1-score': 0.72035778375684, 'support': 1132} weighted_avg {'precision': 0.7345444121665975, 'recall': 0.7446996466431095, 'f1-score': 0.7224104674865213, 'support': 1132}
 
----------
Epoch 2/40
time = 427.48 secondes

Train loss 0.5950068874720315 accuracy 0.8164408206939697 macro_avg {'precision': 0.803639743008004, 'recall': 0.8039876031410236, 'f1-score': 0.7997826297779997, 'support': 10182} weighted_avg {'precision': 0.8121045208498117, 'recall': 0.8164407778432528, 'f1-score': 0.811395992365592, 'support': 10182}
 
time = 11.60 secondes

Val loss 0.6057542557237854 accuracy 0.8197879791259766 macro_avg {'precision': 0.8218302005193283, 'recall': 0.8140227036017501, 'f1-score': 0.8101398303558586, 'support': 1132} weighted_avg {'precision': 0.8260705580850053, 'recall': 0.8197879858657244, 'f1-score': 0.81551873985687, 'support': 1132}
 
----------
Epoch 3/40
time = 426.90 secondes

Train loss 0.35011144251134274 accuracy 0.8955019116401672 macro_avg {'precision': 0.8890795393087908, 'recall': 0.8886736068130295, 'f1-score': 0.888769847509239, 'support': 10182} weighted_avg {'precision': 0.8954347980195607, 'recall': 0.8955018660381064, 'f1-score': 0.89537171509582, 'support': 10182}
 
time = 12.57 secondes

Val loss 0.6107110614088219 accuracy 0.8356890678405762 macro_avg {'precision': 0.8373302504929988, 'recall': 0.8334345806300952, 'f1-score': 0.831677822568275, 'support': 1132} weighted_avg {'precision': 0.8428556425844013, 'recall': 0.8356890459363958, 'f1-score': 0.8357320233591327, 'support': 1132}
 
----------
Epoch 4/40
time = 427.78 secondes

Train loss 0.23718372143927838 accuracy 0.934492290019989 macro_avg {'precision': 0.9309684603719027, 'recall': 0.9307206063811447, 'f1-score': 0.9307764034135342, 'support': 10182} weighted_avg {'precision': 0.9346418247014313, 'recall': 0.9344922412099784, 'f1-score': 0.9345020930868237, 'support': 10182}
 
time = 11.55 secondes

Val loss 0.6057704825308436 accuracy 0.8648409843444824 macro_avg {'precision': 0.871898803601168, 'recall': 0.8614033371630816, 'f1-score': 0.8609702364892364, 'support': 1132} weighted_avg {'precision': 0.8730987709608068, 'recall': 0.8648409893992933, 'f1-score': 0.8638902409378557, 'support': 1132}
 
----------
Epoch 5/40
time = 427.62 secondes

Train loss 0.18785470461157067 accuracy 0.9518758654594421 macro_avg {'precision': 0.9497692939119119, 'recall': 0.9495254232459482, 'f1-score': 0.9495463168291984, 'support': 10182} weighted_avg {'precision': 0.9520204351917332, 'recall': 0.9518758593596542, 'f1-score': 0.9518459759507875, 'support': 10182}
 
time = 11.55 secondes

Val loss 0.6104143584625874 accuracy 0.880742073059082 macro_avg {'precision': 0.883790006131459, 'recall': 0.8804765847078269, 'f1-score': 0.8807520446493955, 'support': 1132} weighted_avg {'precision': 0.883425286835813, 'recall': 0.8807420494699647, 'f1-score': 0.8806420014541381, 'support': 1132}
 
----------
Epoch 6/40
time = 428.08 secondes

Train loss 0.17187872737499169 accuracy 0.9565901160240173 macro_avg {'precision': 0.955069226043339, 'recall': 0.9546217980781643, 'f1-score': 0.9547737365400157, 'support': 10182} weighted_avg {'precision': 0.9567479326039636, 'recall': 0.9565900608917698, 'f1-score': 0.9565979632852899, 'support': 10182}
 
time = 11.59 secondes

Val loss 0.7660681830471526 accuracy 0.8674911856651306 macro_avg {'precision': 0.8704564887357812, 'recall': 0.8667536472593689, 'f1-score': 0.8649352321871835, 'support': 1132} weighted_avg {'precision': 0.8734040935719546, 'recall': 0.8674911660777385, 'f1-score': 0.8667595707213334, 'support': 1132}
 
----------
Epoch 7/40
time = 427.09 secondes

Train loss 0.12999167149993218 accuracy 0.9691612720489502 macro_avg {'precision': 0.968790819990035, 'recall': 0.9683829872741949, 'f1-score': 0.9685614647898191, 'support': 10182} weighted_avg {'precision': 0.9691899780129134, 'recall': 0.9691612649774111, 'f1-score': 0.9691512237196906, 'support': 10182}
 
time = 11.60 secondes

Val loss 0.7364814959140167 accuracy 0.8727915287017822 macro_avg {'precision': 0.8770294720794143, 'recall': 0.8702187663698764, 'f1-score': 0.8701185757532197, 'support': 1132} weighted_avg {'precision': 0.8785162930971553, 'recall': 0.872791519434629, 'f1-score': 0.8724882517555386, 'support': 1132}
 
----------
Epoch 8/40
time = 428.42 secondes

Train loss 0.12843641860118526 accuracy 0.9701434373855591 macro_avg {'precision': 0.9690181985806463, 'recall': 0.9692298336124466, 'f1-score': 0.9691050608214656, 'support': 10182} weighted_avg {'precision': 0.9701963471665978, 'recall': 0.9701433902966018, 'f1-score': 0.9701506336591652, 'support': 10182}
 
time = 12.02 secondes

Val loss 0.7827693656452565 accuracy 0.8754417300224304 macro_avg {'precision': 0.8856227467768092, 'recall': 0.8769021516950071, 'f1-score': 0.8775247097546073, 'support': 1132} weighted_avg {'precision': 0.8842648247638063, 'recall': 0.8754416961130742, 'f1-score': 0.8761133482741695, 'support': 1132}
 
----------
Epoch 9/40
time = 427.64 secondes

Train loss 0.13578993493995922 accuracy 0.9713219404220581 macro_avg {'precision': 0.9708842183012278, 'recall': 0.970405092603921, 'f1-score': 0.9705998228149599, 'support': 10182} weighted_avg {'precision': 0.9713410523682582, 'recall': 0.9713219406796307, 'f1-score': 0.9712885691730148, 'support': 10182}
 
time = 11.89 secondes

Val loss 0.7707435238047201 accuracy 0.8842756152153015 macro_avg {'precision': 0.8873065644834481, 'recall': 0.8849849859908858, 'f1-score': 0.8841939933940933, 'support': 1132} weighted_avg {'precision': 0.8881335646641428, 'recall': 0.8842756183745583, 'f1-score': 0.8843005455504848, 'support': 1132}
 
----------
Epoch 10/40
time = 427.72 secondes

Train loss 0.11353706584909266 accuracy 0.975446879863739 macro_avg {'precision': 0.9744730405943495, 'recall': 0.9745893479932672, 'f1-score': 0.9745029402034471, 'support': 10182} weighted_avg {'precision': 0.9755253535366786, 'recall': 0.9754468670202318, 'f1-score': 0.9754607920783431, 'support': 10182}
 
time = 12.03 secondes

Val loss 0.8384959423184086 accuracy 0.8754417300224304 macro_avg {'precision': 0.8797092110963902, 'recall': 0.8720832105671061, 'f1-score': 0.8721040802956924, 'support': 1132} weighted_avg {'precision': 0.8813138879329543, 'recall': 0.8754416961130742, 'f1-score': 0.8748940255484157, 'support': 1132}
 
----------
Epoch 11/40
time = 427.26 secondes

Train loss 0.11070492402462177 accuracy 0.9766254425048828 macro_avg {'precision': 0.9760853918975352, 'recall': 0.9754905662383357, 'f1-score': 0.9757379838102646, 'support': 10182} weighted_avg {'precision': 0.9766660869519701, 'recall': 0.9766254174032607, 'f1-score': 0.976605992148783, 'support': 10182}
 
time = 12.10 secondes

Val loss 0.8553651419052573 accuracy 0.8833922147750854 macro_avg {'precision': 0.8906317990812207, 'recall': 0.884629649320533, 'f1-score': 0.8821356401482834, 'support': 1132} weighted_avg {'precision': 0.895454394147608, 'recall': 0.8833922261484098, 'f1-score': 0.8842883416763773, 'support': 1132}
 
----------
Epoch 12/40
time = 428.30 secondes

Train loss 0.11130101218757664 accuracy 0.9770182967185974 macro_avg {'precision': 0.9754477957151501, 'recall': 0.9756085083163079, 'f1-score': 0.9755072421026243, 'support': 10182} weighted_avg {'precision': 0.9770375779246085, 'recall': 0.9770182675309369, 'f1-score': 0.9770079298467411, 'support': 10182}
 
time = 12.24 secondes

Val loss 0.8636139771885905 accuracy 0.8842756152153015 macro_avg {'precision': 0.887042289806088, 'recall': 0.8830038164196269, 'f1-score': 0.8832091970491185, 'support': 1132} weighted_avg {'precision': 0.8885342501489151, 'recall': 0.8842756183745583, 'f1-score': 0.8846363509471772, 'support': 1132}
 
----------
Epoch 13/40
time = 427.81 secondes

Train loss 0.10139130377248141 accuracy 0.9792771935462952 macro_avg {'precision': 0.9790970852136451, 'recall': 0.9787537945316659, 'f1-score': 0.9788730009667248, 'support': 10182} weighted_avg {'precision': 0.9794257204351607, 'recall': 0.9792771557650756, 'f1-score': 0.9792978434526461, 'support': 10182}
 
time = 11.46 secondes

Val loss 0.7941169067692588 accuracy 0.8966431021690369 macro_avg {'precision': 0.8997790994448798, 'recall': 0.8986451019707692, 'f1-score': 0.8965974311634428, 'support': 1132} weighted_avg {'precision': 0.9037298202658083, 'recall': 0.8966431095406361, 'f1-score': 0.8974524337605545, 'support': 1132}
 
----------
Epoch 14/40
time = 427.75 secondes

Train loss 0.08224130975708638 accuracy 0.9836967587471008 macro_avg {'precision': 0.9833846022401609, 'recall': 0.9836464031979334, 'f1-score': 0.9835062718702092, 'support': 10182} weighted_avg {'precision': 0.9837104981427786, 'recall': 0.9836967197014339, 'f1-score': 0.9836954015308669, 'support': 10182}
 
time = 11.38 secondes

Val loss 0.7912874791066533 accuracy 0.8939929604530334 macro_avg {'precision': 0.8976939998779907, 'recall': 0.8931534720517412, 'f1-score': 0.8927413362386506, 'support': 1132} weighted_avg {'precision': 0.900218691993807, 'recall': 0.8939929328621908, 'f1-score': 0.8947349211472664, 'support': 1132}
 
----------
Epoch 15/40
time = 427.19 secondes

Train loss 0.10979987994554906 accuracy 0.9801610708236694 macro_avg {'precision': 0.9790129741184787, 'recall': 0.9796697288503641, 'f1-score': 0.9792364601622898, 'support': 10182} weighted_avg {'precision': 0.9803510777226783, 'recall': 0.9801610685523473, 'f1-score': 0.9801764059103035, 'support': 10182}
 
time = 11.39 secondes

Val loss 0.9172498665522115 accuracy 0.8825088143348694 macro_avg {'precision': 0.8859073752070532, 'recall': 0.8830826565758458, 'f1-score': 0.8828109492357218, 'support': 1132} weighted_avg {'precision': 0.8858287492307401, 'recall': 0.8825088339222615, 'f1-score': 0.8824551147988665, 'support': 1132}
 
----------
Epoch 16/40
time = 427.94 secondes

Train loss 0.07638172546410849 accuracy 0.9861520528793335 macro_avg {'precision': 0.9857422656223, 'recall': 0.9856184007871402, 'f1-score': 0.985650409096903, 'support': 10182} weighted_avg {'precision': 0.9861236820556831, 'recall': 0.9861520329994107, 'f1-score': 0.9861078205694143, 'support': 10182}
 
time = 11.40 secondes

Val loss 0.8332773895487828 accuracy 0.880742073059082 macro_avg {'precision': 0.8871232980221757, 'recall': 0.8807892565500992, 'f1-score': 0.8819041569868921, 'support': 1132} weighted_avg {'precision': 0.8848294463745058, 'recall': 0.8807420494699647, 'f1-score': 0.8809597950850016, 'support': 1132}
 
----------
Epoch 17/40
time = 427.40 secondes

Train loss 0.08885789517226615 accuracy 0.9841877818107605 macro_avg {'precision': 0.9841624029101366, 'recall': 0.9840179707948498, 'f1-score': 0.984072067800744, 'support': 10182} weighted_avg {'precision': 0.9842119339795777, 'recall': 0.9841877823610292, 'f1-score': 0.9841815755088955, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.8634332965208467 accuracy 0.8825088143348694 macro_avg {'precision': 0.8852970294296247, 'recall': 0.8861228326519409, 'f1-score': 0.884349359227742, 'support': 1132} weighted_avg {'precision': 0.8844361132693666, 'recall': 0.8825088339222615, 'f1-score': 0.881974174094379, 'support': 1132}
 
----------
Epoch 18/40
time = 427.77 secondes

Train loss 0.07491812531380493 accuracy 0.9854645729064941 macro_avg {'precision': 0.9855126965092325, 'recall': 0.9857180669505515, 'f1-score': 0.9855974210810163, 'support': 10182} weighted_avg {'precision': 0.9854892536157652, 'recall': 0.9854645452759773, 'f1-score': 0.985458561164563, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.9244963035147725 accuracy 0.8869258165359497 macro_avg {'precision': 0.891913576627849, 'recall': 0.8921330564451585, 'f1-score': 0.8889775667676318, 'support': 1132} weighted_avg {'precision': 0.8949649265824753, 'recall': 0.8869257950530035, 'f1-score': 0.8877404970125115, 'support': 1132}
 
----------
Epoch 19/40
time = 427.24 secondes

Train loss 0.08850879221962724 accuracy 0.9848753213882446 macro_avg {'precision': 0.9844670359635754, 'recall': 0.9846313957502193, 'f1-score': 0.9845215864006611, 'support': 10182} weighted_avg {'precision': 0.9849743736043965, 'recall': 0.9848752700844627, 'f1-score': 0.9848981192111241, 'support': 10182}
 
time = 11.38 secondes

Val loss 0.953862212776431 accuracy 0.8833922147750854 macro_avg {'precision': 0.8921055172118054, 'recall': 0.8855940932387718, 'f1-score': 0.8832615863835944, 'support': 1132} weighted_avg {'precision': 0.8946021539998904, 'recall': 0.8833922261484098, 'f1-score': 0.8836965624261225, 'support': 1132}
 
----------
Epoch 20/40
time = 427.66 secondes

Train loss 0.06609615789279721 accuracy 0.9875270128250122 macro_avg {'precision': 0.9871621725005142, 'recall': 0.9872203079530589, 'f1-score': 0.9871732853149873, 'support': 10182} weighted_avg {'precision': 0.9875828366912651, 'recall': 0.9875270084462777, 'f1-score': 0.9875376846215578, 'support': 10182}
 
time = 11.37 secondes

Val loss 0.8354597227007616 accuracy 0.8992933034896851 macro_avg {'precision': 0.9010447624682557, 'recall': 0.9002306717612072, 'f1-score': 0.8993072282415862, 'support': 1132} weighted_avg {'precision': 0.9029656927004605, 'recall': 0.8992932862190812, 'f1-score': 0.8998107916295115, 'support': 1132}
 
----------
Epoch 21/40
time = 428.40 secondes

Train loss 0.05365573485468756 accuracy 0.9908662438392639 macro_avg {'precision': 0.9904102334612824, 'recall': 0.9901439395883601, 'f1-score': 0.9902658016778387, 'support': 10182} weighted_avg {'precision': 0.9908772028438799, 'recall': 0.9908662345315262, 'f1-score': 0.9908610029188061, 'support': 10182}
 
time = 11.39 secondes

Val loss 0.9764677615959544 accuracy 0.8789752721786499 macro_avg {'precision': 0.8843522793472705, 'recall': 0.8812714251116139, 'f1-score': 0.8806731949745339, 'support': 1132} weighted_avg {'precision': 0.8841659302218434, 'recall': 0.8789752650176679, 'f1-score': 0.8792556413973864, 'support': 1132}
 
----------
Epoch 22/40
time = 427.67 secondes

Train loss 0.06423353777500783 accuracy 0.9884109497070312 macro_avg {'precision': 0.9883041835489884, 'recall': 0.9884173719792159, 'f1-score': 0.9883542123248631, 'support': 10182} weighted_avg {'precision': 0.9884270491453871, 'recall': 0.9884109212335495, 'f1-score': 0.988412569002878, 'support': 10182}
 
time = 11.33 secondes

Val loss 0.9780410806066152 accuracy 0.8886925578117371 macro_avg {'precision': 0.8957077687555272, 'recall': 0.8896527824973985, 'f1-score': 0.8897789464610328, 'support': 1132} weighted_avg {'precision': 0.894844729793405, 'recall': 0.8886925795053003, 'f1-score': 0.8888213187246491, 'support': 1132}
 
----------
Epoch 23/40
time = 428.03 secondes

Train loss 0.053023171656950495 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913290952370859, 'recall': 0.9911515328640096, 'f1-score': 0.9912328585942582, 'support': 10182} weighted_avg {'precision': 0.9914744157482156, 'recall': 0.9914555097230406, 'f1-score': 0.9914576751488711, 'support': 10182}
 
time = 11.37 secondes

Val loss 0.8016802895636688 accuracy 0.898409903049469 macro_avg {'precision': 0.9021007649195572, 'recall': 0.9002264610447981, 'f1-score': 0.8992391446207126, 'support': 1132} weighted_avg {'precision': 0.9041894258446709, 'recall': 0.8984098939929329, 'f1-score': 0.8995048405154341, 'support': 1132}
 
----------
Epoch 24/40
time = 427.59 secondes

Train loss 0.04504103351461752 accuracy 0.9910627007484436 macro_avg {'precision': 0.9907331503974882, 'recall': 0.9907243375630035, 'f1-score': 0.9907223763063691, 'support': 10182} weighted_avg {'precision': 0.9910755953357486, 'recall': 0.9910626595953643, 'f1-score': 0.991062833198687, 'support': 10182}
 
time = 11.41 secondes

Val loss 0.897800261059671 accuracy 0.8931095600128174 macro_avg {'precision': 0.8964841904478285, 'recall': 0.8927684991462872, 'f1-score': 0.8930622614353781, 'support': 1132} weighted_avg {'precision': 0.8975592845319673, 'recall': 0.8931095406360424, 'f1-score': 0.8939519054123165, 'support': 1132}
 
----------
Epoch 25/40
time = 427.24 secondes

Train loss 0.052587208911671735 accuracy 0.9913573265075684 macro_avg {'precision': 0.9910152288128747, 'recall': 0.9907061526557305, 'f1-score': 0.9908460676634089, 'support': 10182} weighted_avg {'precision': 0.9913826599533708, 'recall': 0.9913572971911215, 'f1-score': 0.9913568342484942, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.9212889172878521 accuracy 0.8860424160957336 macro_avg {'precision': 0.8928149395879427, 'recall': 0.8862478408003567, 'f1-score': 0.8865381912356185, 'support': 1132} weighted_avg {'precision': 0.8928116581835716, 'recall': 0.8860424028268551, 'f1-score': 0.8868229389180312, 'support': 1132}
 
----------
Epoch 26/40
time = 427.84 secondes

Train loss 0.04117298126610201 accuracy 0.9928305149078369 macro_avg {'precision': 0.992617607683553, 'recall': 0.9927103610920591, 'f1-score': 0.9926573765992213, 'support': 10182} weighted_avg {'precision': 0.9928379876852336, 'recall': 0.9928304851699077, 'f1-score': 0.9928276020951711, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.9987777289082862 accuracy 0.8825088143348694 macro_avg {'precision': 0.89012312269116, 'recall': 0.8826910094087582, 'f1-score': 0.8798639129976612, 'support': 1132} weighted_avg {'precision': 0.8991718458273402, 'recall': 0.8825088339222615, 'f1-score': 0.8857519539967366, 'support': 1132}
 
----------
Epoch 27/40
time = 427.89 secondes

Train loss 0.04611591165789839 accuracy 0.9919465780258179 macro_avg {'precision': 0.9913452934532451, 'recall': 0.9918980729900804, 'f1-score': 0.9916001068766581, 'support': 10182} weighted_avg {'precision': 0.9920059231618441, 'recall': 0.9919465723826361, 'f1-score': 0.9919575856093906, 'support': 10182}
 
time = 11.38 secondes

Val loss 1.0776602086693279 accuracy 0.879858672618866 macro_avg {'precision': 0.8916681580338983, 'recall': 0.8835211683643734, 'f1-score': 0.8835516253667517, 'support': 1132} weighted_avg {'precision': 0.8914634898653223, 'recall': 0.8798586572438163, 'f1-score': 0.8814082244516853, 'support': 1132}
 
----------
Epoch 28/40
time = 426.83 secondes

Train loss 0.042004840758497926 accuracy 0.9930269122123718 macro_avg {'precision': 0.9928653223728514, 'recall': 0.992907374964107, 'f1-score': 0.9928776413143515, 'support': 10182} weighted_avg {'precision': 0.9930474170838842, 'recall': 0.9930269102337458, 'f1-score': 0.9930282343545482, 'support': 10182}
 
time = 11.38 secondes

Val loss 0.9603817917438943 accuracy 0.8948763608932495 macro_avg {'precision': 0.8994344245182229, 'recall': 0.8976553878507909, 'f1-score': 0.89710418870129, 'support': 1132} weighted_avg {'precision': 0.8988017530791296, 'recall': 0.8948763250883393, 'f1-score': 0.8953869147015281, 'support': 1132}
 
----------
Epoch 29/40
time = 427.55 secondes

Train loss 0.046341597286411754 accuracy 0.992634117603302 macro_avg {'precision': 0.9926933409152952, 'recall': 0.9926726858758788, 'f1-score': 0.9926765230813743, 'support': 10182} weighted_avg {'precision': 0.9926504884700036, 'recall': 0.9926340601060696, 'f1-score': 0.9926355622063174, 'support': 10182}
 
time = 11.39 secondes

Val loss 0.951539862832107 accuracy 0.8975265026092529 macro_avg {'precision': 0.9018935594605919, 'recall': 0.9008963729545785, 'f1-score': 0.8995970266019931, 'support': 1132} weighted_avg {'precision': 0.903215635677634, 'recall': 0.8975265017667845, 'f1-score': 0.8985627054336767, 'support': 1132}
 
----------
Epoch 30/40
time = 427.32 secondes

Train loss 0.027192396375434174 accuracy 0.9953840374946594 macro_avg {'precision': 0.9954480295928366, 'recall': 0.9954574659029701, 'f1-score': 0.9954483810199279, 'support': 10182} weighted_avg {'precision': 0.9953960068474869, 'recall': 0.9953840109998036, 'f1-score': 0.9953854898781149, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.9470162476233307 accuracy 0.8992933034896851 macro_avg {'precision': 0.9025578439080718, 'recall': 0.9005917493164703, 'f1-score': 0.8999216199386675, 'support': 1132} weighted_avg {'precision': 0.9037356738147192, 'recall': 0.8992932862190812, 'f1-score': 0.9000076934166187, 'support': 1132}
 
----------
Epoch 31/40
time = 427.41 secondes

Train loss 0.03435945636364818 accuracy 0.9943037033081055 macro_avg {'precision': 0.994363797903385, 'recall': 0.9942660271031653, 'f1-score': 0.9943110954224166, 'support': 10182} weighted_avg {'precision': 0.9943173503335483, 'recall': 0.9943036731486937, 'f1-score': 0.9943066644445727, 'support': 10182}
 
time = 11.36 secondes

Val loss 0.9044160550958469 accuracy 0.8975265026092529 macro_avg {'precision': 0.9020454316892197, 'recall': 0.8986143471285946, 'f1-score': 0.8980106394251626, 'support': 1132} weighted_avg {'precision': 0.9027363932876787, 'recall': 0.8975265017667845, 'f1-score': 0.8980088154144787, 'support': 1132}
 
----------
Epoch 32/40
time = 427.42 secondes

Train loss 0.023007996746074504 accuracy 0.995776891708374 macro_avg {'precision': 0.9958531654959428, 'recall': 0.9958498038284247, 'f1-score': 0.9958456693801363, 'support': 10182} weighted_avg {'precision': 0.9957911962144107, 'recall': 0.9957768611274799, 'f1-score': 0.9957781963326771, 'support': 10182}
 
time = 11.34 secondes

Val loss 0.8374805075331557 accuracy 0.9063604474067688 macro_avg {'precision': 0.9119886944124511, 'recall': 0.9078927803974786, 'f1-score': 0.9085454884311247, 'support': 1132} weighted_avg {'precision': 0.9119204530828815, 'recall': 0.9063604240282686, 'f1-score': 0.9075958005161132, 'support': 1132}
 
----------
Epoch 33/40
time = 426.99 secondes

Train loss 0.02330099495008983 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961759811985462, 'recall': 0.9961948284693152, 'f1-score': 0.9961818900331814, 'support': 10182} weighted_avg {'precision': 0.9960721010956762, 'recall': 0.9960714987232371, 'f1-score': 0.9960681307244265, 'support': 10182}
 
time = 11.34 secondes

Val loss 0.9358632125938936 accuracy 0.9010601043701172 macro_avg {'precision': 0.9048209077757792, 'recall': 0.9019749581833914, 'f1-score': 0.9022890852967865, 'support': 1132} weighted_avg {'precision': 0.9034778277877358, 'recall': 0.901060070671378, 'f1-score': 0.9011839863180686, 'support': 1132}
 
----------
Epoch 34/40
time = 428.51 secondes

Train loss 0.016226220870892726 accuracy 0.9974464774131775 macro_avg {'precision': 0.9974364985695626, 'recall': 0.9974859250630145, 'f1-score': 0.9974591788735532, 'support': 10182} weighted_avg {'precision': 0.99745287502688, 'recall': 0.9974464741701041, 'f1-score': 0.9974477124853708, 'support': 10182}
 
time = 11.33 secondes

Val loss 0.9548799397999945 accuracy 0.8957597017288208 macro_avg {'precision': 0.9010462000453303, 'recall': 0.8980045298636525, 'f1-score': 0.8973313559009426, 'support': 1132} weighted_avg {'precision': 0.901475425170537, 'recall': 0.8957597173144877, 'f1-score': 0.8964386654902292, 'support': 1132}
 
----------
Epoch 35/40
time = 427.60 secondes

Train loss 0.02389206856036199 accuracy 0.9962679743766785 macro_avg {'precision': 0.9961138760964019, 'recall': 0.9962374948702306, 'f1-score': 0.996171003821637, 'support': 10182} weighted_avg {'precision': 0.9962811021147016, 'recall': 0.9962679237870752, 'f1-score': 0.9962699218413038, 'support': 10182}
 
time = 11.33 secondes

Val loss 1.016223304300683 accuracy 0.8904593586921692 macro_avg {'precision': 0.8984659316442107, 'recall': 0.8921640490157625, 'f1-score': 0.8930295564884881, 'support': 1132} weighted_avg {'precision': 0.8982515218714455, 'recall': 0.8904593639575972, 'f1-score': 0.8919306332760432, 'support': 1132}
 
----------
Epoch 36/40
time = 430.43 secondes

Train loss 0.01664152257806883 accuracy 0.9976429343223572 macro_avg {'precision': 0.9975537217314624, 'recall': 0.9976304306628027, 'f1-score': 0.9975867750769195, 'support': 10182} weighted_avg {'precision': 0.9976513830293907, 'recall': 0.9976428992339422, 'f1-score': 0.9976416528934404, 'support': 10182}
 
time = 11.29 secondes

Val loss 0.945018317370802 accuracy 0.9010601043701172 macro_avg {'precision': 0.9034204750774958, 'recall': 0.9020928913233466, 'f1-score': 0.901034691960842, 'support': 1132} weighted_avg {'precision': 0.9051546076141447, 'recall': 0.901060070671378, 'f1-score': 0.901399512257893, 'support': 1132}
 
----------
Epoch 37/40
time = 426.74 secondes

Train loss 0.009409683717197852 accuracy 0.9981340169906616 macro_avg {'precision': 0.9980842381486209, 'recall': 0.998106946558274, 'f1-score': 0.9980941955914024, 'support': 10182} weighted_avg {'precision': 0.9981365877543472, 'recall': 0.9981339618935376, 'f1-score': 0.9981339066822321, 'support': 10182}
 
time = 11.31 secondes

Val loss 0.9303254008831777 accuracy 0.9001767039299011 macro_avg {'precision': 0.9027740031026033, 'recall': 0.9013130306252704, 'f1-score': 0.9009288201945738, 'support': 1132} weighted_avg {'precision': 0.9034878959444622, 'recall': 0.9001766784452296, 'f1-score': 0.9006326132134438, 'support': 1132}
 
----------
Epoch 38/40
time = 427.66 secondes

Train loss 0.004917797149379566 accuracy 0.998821496963501 macro_avg {'precision': 0.9987865046262856, 'recall': 0.9987070723492341, 'f1-score': 0.9987458839299984, 'support': 10182} weighted_avg {'precision': 0.9988232084188358, 'recall': 0.9988214496169712, 'f1-score': 0.9988214519486012, 'support': 10182}
 
time = 11.31 secondes

Val loss 0.9716934889912524 accuracy 0.898409903049469 macro_avg {'precision': 0.8991073691879554, 'recall': 0.8990206697384682, 'f1-score': 0.8973947172113039, 'support': 1132} weighted_avg {'precision': 0.90183840616372, 'recall': 0.8984098939929329, 'f1-score': 0.8985941446930018, 'support': 1132}
 
----------
Epoch 39/40
time = 427.52 secondes

Train loss 0.007032033273778326 accuracy 0.9990178942680359 macro_avg {'precision': 0.9988818314640229, 'recall': 0.9988230285564473, 'f1-score': 0.998851552986092, 'support': 10182} weighted_avg {'precision': 0.9990186306971393, 'recall': 0.9990178746808093, 'f1-score': 0.9990175537888526, 'support': 10182}
 
time = 11.33 secondes

Val loss 0.9373439819332111 accuracy 0.9010601043701172 macro_avg {'precision': 0.9013710055490611, 'recall': 0.9033580476236451, 'f1-score': 0.9015037401221149, 'support': 1132} weighted_avg {'precision': 0.9034421214836721, 'recall': 0.901060070671378, 'f1-score': 0.9014192527464946, 'support': 1132}
 
----------
Epoch 40/40
time = 427.64 secondes

Train loss 0.0035743169410739064 accuracy 0.9993125200271606 macro_avg {'precision': 0.999285788040592, 'recall': 0.9993159490899238, 'f1-score': 0.9993001540370148, 'support': 10182} weighted_avg {'precision': 0.9993141025842808, 'recall': 0.9993125122765665, 'f1-score': 0.9993126205732945, 'support': 10182}
 
time = 11.31 secondes

Val loss 0.9063229332014857 accuracy 0.9010601043701172 macro_avg {'precision': 0.9031643697311729, 'recall': 0.9031068118875971, 'f1-score': 0.902170489896392, 'support': 1132} weighted_avg {'precision': 0.9040572653002354, 'recall': 0.901060070671378, 'f1-score': 0.901593223900693, 'support': 1132}
 
----------
best_accuracy 0.9063604474067688 best_epoch 32 macro_avg {'precision': 0.9119886944124511, 'recall': 0.9078927803974786, 'f1-score': 0.9085454884311247, 'support': 1132} weighted_avg {'precision': 0.9119204530828815, 'recall': 0.9063604240282686, 'f1-score': 0.9075958005161132, 'support': 1132}

average train time 427.64933585524557

average val time 11.510938572883607
 
time = 73.72 secondes

test_accuracy 0.8365639448165894 macro_avg {'precision': 0.8360604549070482, 'recall': 0.8301999263504503, 'f1-score': 0.8312629725212306, 'support': 7532} weighted_avg {'precision': 0.8418276769086073, 'recall': 0.8365639936271907, 'f1-score': 0.8374216038798558, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_1
----------
Epoch 1/40
time = 1927.27 secondes

Train loss 1.4172701875399945 accuracy 0.6083284616470337 macro_avg {'precision': 0.6199947310405132, 'recall': 0.5920359738497828, 'f1-score': 0.5810228599863712, 'support': 10182} weighted_avg {'precision': 0.6209603294844913, 'recall': 0.6083284227067374, 'f1-score': 0.5951435125525303, 'support': 10182}
 
time = 26.33 secondes

Val loss 0.7889683355747814 accuracy 0.7579505443572998 macro_avg {'precision': 0.7394516257703965, 'recall': 0.7529963350665086, 'f1-score': 0.7361509698631704, 'support': 1132} weighted_avg {'precision': 0.7505182076700392, 'recall': 0.7579505300353356, 'f1-score': 0.7429069438126489, 'support': 1132}
 
----------
Epoch 2/40
time = 1924.23 secondes

Train loss 0.5678480452795044 accuracy 0.8269495368003845 macro_avg {'precision': 0.8127992498115253, 'recall': 0.8144725598234105, 'f1-score': 0.8097649938364958, 'support': 10182} weighted_avg {'precision': 0.8218235981335782, 'recall': 0.8269495187585936, 'f1-score': 0.8216336561762843, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.646820207087087 accuracy 0.8127208352088928 macro_avg {'precision': 0.8067288066486711, 'recall': 0.8115070561587719, 'f1-score': 0.8044637919015358, 'support': 1132} weighted_avg {'precision': 0.8161215864887186, 'recall': 0.8127208480565371, 'f1-score': 0.8095488604940495, 'support': 1132}
 
----------
Epoch 3/40
time = 1927.15 secondes

Train loss 0.33236096706679985 accuracy 0.9031624794006348 macro_avg {'precision': 0.8971895098279837, 'recall': 0.8964426876920774, 'f1-score': 0.896476102128935, 'support': 10182} weighted_avg {'precision': 0.9026597780371156, 'recall': 0.9031624435277942, 'f1-score': 0.9026234687696935, 'support': 10182}
 
time = 27.29 secondes

Val loss 0.6183752872207215 accuracy 0.843639612197876 macro_avg {'precision': 0.83827992836497, 'recall': 0.8440767924316767, 'f1-score': 0.8383938018417323, 'support': 1132} weighted_avg {'precision': 0.8465916805096663, 'recall': 0.8436395759717314, 'f1-score': 0.8420196338260519, 'support': 1132}
 
----------
Epoch 4/40
time = 1928.28 secondes

Train loss 0.1971768177570585 accuracy 0.944706380367279 macro_avg {'precision': 0.9421961646354632, 'recall': 0.9418001974624278, 'f1-score': 0.9419088986722073, 'support': 10182} weighted_avg {'precision': 0.9448795307749832, 'recall': 0.9447063445295619, 'f1-score': 0.9447064511020742, 'support': 10182}
 
time = 26.73 secondes

Val loss 0.6394425610336147 accuracy 0.8666077852249146 macro_avg {'precision': 0.8710623720939867, 'recall': 0.8642067716617703, 'f1-score': 0.8654670550637787, 'support': 1132} weighted_avg {'precision': 0.8723746445940092, 'recall': 0.8666077738515902, 'f1-score': 0.8671354779679552, 'support': 1132}
 
----------
Epoch 5/40
time = 1925.67 secondes

Train loss 0.15835856025076503 accuracy 0.9577686190605164 macro_avg {'precision': 0.9557251481230897, 'recall': 0.955811273698105, 'f1-score': 0.9557143777723223, 'support': 10182} weighted_avg {'precision': 0.9577774024729577, 'recall': 0.9577686112747986, 'f1-score': 0.9577207332114208, 'support': 10182}
 
time = 27.08 secondes

Val loss 0.8235576236243425 accuracy 0.8471731543540955 macro_avg {'precision': 0.8559892099284558, 'recall': 0.8503548396446098, 'f1-score': 0.8471905588360915, 'support': 1132} weighted_avg {'precision': 0.8600318268622826, 'recall': 0.8471731448763251, 'f1-score': 0.8479273899078233, 'support': 1132}
 
----------
Epoch 6/40
time = 1924.56 secondes

Train loss 0.13949489512618227 accuracy 0.9638578295707703 macro_avg {'precision': 0.9627947349602997, 'recall': 0.96234937816315, 'f1-score': 0.9624917420273839, 'support': 10182} weighted_avg {'precision': 0.9640742251250195, 'recall': 0.9638577882537812, 'f1-score': 0.9638847367522583, 'support': 10182}
 
time = 26.37 secondes

Val loss 0.7491586295458239 accuracy 0.8630741834640503 macro_avg {'precision': 0.8744870591857253, 'recall': 0.862539711000305, 'f1-score': 0.8644005710378163, 'support': 1132} weighted_avg {'precision': 0.8712707098646433, 'recall': 0.8630742049469965, 'f1-score': 0.8632092122238546, 'support': 1132}
 
----------
Epoch 7/40
time = 1929.33 secondes

Train loss 0.120702593728609 accuracy 0.9686702489852905 macro_avg {'precision': 0.9676644602772294, 'recall': 0.9678638870456835, 'f1-score': 0.9677352569969173, 'support': 10182} weighted_avg {'precision': 0.9687629764360316, 'recall': 0.9686702023178158, 'f1-score': 0.9686879295143817, 'support': 10182}
 
time = 27.23 secondes

Val loss 0.8406782874724382 accuracy 0.862190842628479 macro_avg {'precision': 0.8700695065947661, 'recall': 0.863942380934757, 'f1-score': 0.8641880958742775, 'support': 1132} weighted_avg {'precision': 0.8717597002277286, 'recall': 0.8621908127208481, 'f1-score': 0.8642738418498657, 'support': 1132}
 
----------
Epoch 8/40
time = 1926.05 secondes

Train loss 0.126260329580232 accuracy 0.9713219404220581 macro_avg {'precision': 0.9701839931608776, 'recall': 0.9698463149308865, 'f1-score': 0.9699458230184413, 'support': 10182} weighted_avg {'precision': 0.9714100463503396, 'recall': 0.9713219406796307, 'f1-score': 0.9713069171688615, 'support': 10182}
 
time = 26.67 secondes

Val loss 0.8307685472110522 accuracy 0.8674911856651306 macro_avg {'precision': 0.8745706607220016, 'recall': 0.8678791578986692, 'f1-score': 0.8690891650478451, 'support': 1132} weighted_avg {'precision': 0.8754654328804995, 'recall': 0.8674911660777385, 'f1-score': 0.8693089818471591, 'support': 1132}
 
----------
Epoch 9/40
time = 1929.66 secondes

Train loss 0.09725341471416504 accuracy 0.9783932566642761 macro_avg {'precision': 0.9776575200484745, 'recall': 0.9771085494828391, 'f1-score': 0.9773416213580773, 'support': 10182} weighted_avg {'precision': 0.9784470007792989, 'recall': 0.978393242977804, 'f1-score': 0.978384315010525, 'support': 10182}
 
time = 26.33 secondes

Val loss 0.8657260477390389 accuracy 0.8639575839042664 macro_avg {'precision': 0.8680080060532973, 'recall': 0.867603480545668, 'f1-score': 0.8659931046133214, 'support': 1132} weighted_avg {'precision': 0.8700575319528779, 'recall': 0.8639575971731449, 'f1-score': 0.8654039038372817, 'support': 1132}
 
----------
Epoch 10/40
time = 1926.83 secondes

Train loss 0.10913502190032173 accuracy 0.978295087814331 macro_avg {'precision': 0.9780320553328166, 'recall': 0.9779980470423121, 'f1-score': 0.9779954808557763, 'support': 10182} weighted_avg {'precision': 0.9783086467912139, 'recall': 0.978295030445885, 'f1-score': 0.9782829990805049, 'support': 10182}
 
time = 26.31 secondes

Val loss 1.0158078970672877 accuracy 0.8577738404273987 macro_avg {'precision': 0.8628341881866458, 'recall': 0.8619838170286738, 'f1-score': 0.8573126321421489, 'support': 1132} weighted_avg {'precision': 0.8678576628919392, 'recall': 0.857773851590106, 'f1-score': 0.8576113304284599, 'support': 1132}
 
----------
Epoch 11/40
time = 1929.13 secondes

Train loss 0.09692589954156546 accuracy 0.9798664450645447 macro_avg {'precision': 0.9792520328907504, 'recall': 0.979499733424934, 'f1-score': 0.9793380670580122, 'support': 10182} weighted_avg {'precision': 0.979970660290143, 'recall': 0.9798664309565901, 'f1-score': 0.979881406201314, 'support': 10182}
 
time = 26.32 secondes

Val loss 1.1169637040842593 accuracy 0.8595406413078308 macro_avg {'precision': 0.8710831371941369, 'recall': 0.8600406552712163, 'f1-score': 0.857835184458532, 'support': 1132} weighted_avg {'precision': 0.8754401589659229, 'recall': 0.8595406360424028, 'f1-score': 0.8612185335895866, 'support': 1132}
 
----------
Epoch 12/40
time = 1926.58 secondes

Train loss 0.09704674898460909 accuracy 0.980455756187439 macro_avg {'precision': 0.9796410183493087, 'recall': 0.9800733267299917, 'f1-score': 0.9798203909941815, 'support': 10182} weighted_avg {'precision': 0.9805351152317234, 'recall': 0.9804557061481045, 'f1-score': 0.9804610732526409, 'support': 10182}
 
time = 26.53 secondes

Val loss 1.02724491400008 accuracy 0.8692579865455627 macro_avg {'precision': 0.8786942059509439, 'recall': 0.8740273016288664, 'f1-score': 0.8694179515431802, 'support': 1132} weighted_avg {'precision': 0.8824534388467606, 'recall': 0.8692579505300353, 'f1-score': 0.8681212010746473, 'support': 1132}
 
----------
Epoch 13/40
time = 1925.81 secondes

Train loss 0.08717846642523837 accuracy 0.9829110503196716 macro_avg {'precision': 0.9823404802888838, 'recall': 0.9824306375798375, 'f1-score': 0.98237434893849, 'support': 10182} weighted_avg {'precision': 0.9829418252109261, 'recall': 0.9829110194460813, 'f1-score': 0.982915228510263, 'support': 10182}
 
time = 26.29 secondes

Val loss 0.8988234621760006 accuracy 0.8745583295822144 macro_avg {'precision': 0.8821061476780528, 'recall': 0.8777240775110597, 'f1-score': 0.8778441258106326, 'support': 1132} weighted_avg {'precision': 0.8810459085995664, 'recall': 0.8745583038869258, 'f1-score': 0.8755889590260573, 'support': 1132}
 
----------
Epoch 14/40
time = 1925.25 secondes

Train loss 0.10610789757421506 accuracy 0.9813396334648132 macro_avg {'precision': 0.9815153226478369, 'recall': 0.9812154069201234, 'f1-score': 0.9812995799069519, 'support': 10182} weighted_avg {'precision': 0.9814365777395628, 'recall': 0.9813396189353761, 'f1-score': 0.9813202717444102, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.9773818545305198 accuracy 0.8772084712982178 macro_avg {'precision': 0.8879454070187105, 'recall': 0.881006275641423, 'f1-score': 0.8806088417870994, 'support': 1132} weighted_avg {'precision': 0.884951762214428, 'recall': 0.877208480565371, 'f1-score': 0.8768356131687689, 'support': 1132}
 
----------
Epoch 15/40
time = 1926.91 secondes

Train loss 0.08209190138227906 accuracy 0.9832056760787964 macro_avg {'precision': 0.9831996610958592, 'recall': 0.9834235965361614, 'f1-score': 0.9832849583157197, 'support': 10182} weighted_avg {'precision': 0.9832366895926941, 'recall': 0.9832056570418385, 'f1-score': 0.983193977910215, 'support': 10182}
 
time = 26.45 secondes

Val loss 1.0578550904969566 accuracy 0.8727915287017822 macro_avg {'precision': 0.8791192702698595, 'recall': 0.8762820444353512, 'f1-score': 0.8741026980193108, 'support': 1132} weighted_avg {'precision': 0.880737597428051, 'recall': 0.872791519434629, 'f1-score': 0.8729596346527322, 'support': 1132}
 
----------
Epoch 16/40
time = 1937.41 secondes

Train loss 0.08385209693970498 accuracy 0.9838931560516357 macro_avg {'precision': 0.9840034990097349, 'recall': 0.983959379043819, 'f1-score': 0.9839668027467257, 'support': 10182} weighted_avg {'precision': 0.9839221207416665, 'recall': 0.983893144765272, 'f1-score': 0.9838930508704778, 'support': 10182}
 
time = 29.75 secondes

Val loss 1.0351700621639037 accuracy 0.8657243847846985 macro_avg {'precision': 0.8851725003623535, 'recall': 0.8721003555318502, 'f1-score': 0.8712545047382679, 'support': 1132} weighted_avg {'precision': 0.8885182433767407, 'recall': 0.8657243816254417, 'f1-score': 0.8701947665508514, 'support': 1132}
 
----------
Epoch 17/40
time = 1943.68 secondes

Train loss 0.08298805510869953 accuracy 0.9853663444519043 macro_avg {'precision': 0.9849930336525716, 'recall': 0.9847862219602173, 'f1-score': 0.9848638666146007, 'support': 10182} weighted_avg {'precision': 0.9853976213152155, 'recall': 0.9853663327440582, 'f1-score': 0.9853560445671222, 'support': 10182}
 
time = 27.03 secondes

Val loss 1.139276833941219 accuracy 0.8427562117576599 macro_avg {'precision': 0.8687578157254681, 'recall': 0.849142305196563, 'f1-score': 0.8477098038983973, 'support': 1132} weighted_avg {'precision': 0.8716990046682117, 'recall': 0.842756183745583, 'f1-score': 0.8454191734942054, 'support': 1132}
 
----------
Epoch 18/40
time = 1938.87 secondes

Train loss 0.07789165717893659 accuracy 0.9849734902381897 macro_avg {'precision': 0.9848894919842077, 'recall': 0.9848398422110376, 'f1-score': 0.9848101850383489, 'support': 10182} weighted_avg {'precision': 0.9850962439401564, 'recall': 0.9849734826163818, 'f1-score': 0.9849790331326694, 'support': 10182}
 
time = 30.87 secondes

Val loss 1.096505778017339 accuracy 0.8754417300224304 macro_avg {'precision': 0.8778724476229873, 'recall': 0.8762867837816961, 'f1-score': 0.8753493182737815, 'support': 1132} weighted_avg {'precision': 0.8794191233811727, 'recall': 0.8754416961130742, 'f1-score': 0.8756494338370285, 'support': 1132}
 
----------
Epoch 19/40
time = 1939.47 secondes

Train loss 0.080052314650347 accuracy 0.985562801361084 macro_avg {'precision': 0.9847723588493904, 'recall': 0.985226487661164, 'f1-score': 0.9849750564356923, 'support': 10182} weighted_avg {'precision': 0.9856387408189219, 'recall': 0.9855627578078963, 'f1-score': 0.9855810864487031, 'support': 10182}
 
time = 28.58 secondes

Val loss 0.9962769180910725 accuracy 0.8719081282615662 macro_avg {'precision': 0.8815939690251154, 'recall': 0.8777523151915334, 'f1-score': 0.8747498692455734, 'support': 1132} weighted_avg {'precision': 0.8839435813817855, 'recall': 0.8719081272084805, 'f1-score': 0.8729847350360131, 'support': 1132}
 
----------
Epoch 20/40
time = 1935.24 secondes

Train loss 0.07097302986881254 accuracy 0.9877234697341919 macro_avg {'precision': 0.9875288791313437, 'recall': 0.987758573494868, 'f1-score': 0.9876187584796163, 'support': 10182} weighted_avg {'precision': 0.9877649901592972, 'recall': 0.9877234335101159, 'f1-score': 0.9877214061034397, 'support': 10182}
 
time = 27.30 secondes

Val loss 0.8650062030355912 accuracy 0.8860424160957336 macro_avg {'precision': 0.8958478522442916, 'recall': 0.8875169255506667, 'f1-score': 0.889486481718875, 'support': 1132} weighted_avg {'precision': 0.8926416172938711, 'recall': 0.8860424028268551, 'f1-score': 0.8871600992131876, 'support': 1132}
 
----------
Epoch 21/40
time = 1936.39 secondes

Train loss 0.05340951810803902 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896961946187597, 'recall': 0.9898109526818699, 'f1-score': 0.9897468844020846, 'support': 10182} weighted_avg {'precision': 0.9899100288090394, 'recall': 0.9898841092123355, 'f1-score': 0.9898905952116893, 'support': 10182}
 
time = 27.05 secondes

Val loss 1.1076589801507997 accuracy 0.8674911856651306 macro_avg {'precision': 0.8824141556527072, 'recall': 0.8716259852954045, 'f1-score': 0.8730057816747696, 'support': 1132} weighted_avg {'precision': 0.8803278288354444, 'recall': 0.8674911660777385, 'f1-score': 0.8696909843661856, 'support': 1132}
 
----------
Epoch 22/40
time = 1935.69 secondes

Train loss 0.06327092344900066 accuracy 0.9890984296798706 macro_avg {'precision': 0.9887810346760189, 'recall': 0.9885985720499715, 'f1-score': 0.9886784474397989, 'support': 10182} weighted_avg {'precision': 0.989117843697105, 'recall': 0.9890984089569829, 'f1-score': 0.9890971292043738, 'support': 10182}
 
time = 27.73 secondes

Val loss 1.0155367785503162 accuracy 0.8710247278213501 macro_avg {'precision': 0.8829990751881965, 'recall': 0.8771544030471405, 'f1-score': 0.8759816390886632, 'support': 1132} weighted_avg {'precision': 0.8822434134533915, 'recall': 0.8710247349823321, 'f1-score': 0.8722563649463139, 'support': 1132}
 
----------
Epoch 23/40
time = 1936.61 secondes

Train loss 0.052336513002413494 accuracy 0.990669846534729 macro_avg {'precision': 0.9904870050397271, 'recall': 0.9903174809616067, 'f1-score': 0.9903792652689706, 'support': 10182} weighted_avg {'precision': 0.9907299905715254, 'recall': 0.9906698094676881, 'f1-score': 0.9906761958358453, 'support': 10182}
 
time = 27.09 secondes

Val loss 0.9944853478156007 accuracy 0.8745583295822144 macro_avg {'precision': 0.8802429575908806, 'recall': 0.8770662780240682, 'f1-score': 0.8769111435010399, 'support': 1132} weighted_avg {'precision': 0.8810283328827008, 'recall': 0.8745583038869258, 'f1-score': 0.8760079252238403, 'support': 1132}
 
----------
Epoch 24/40
time = 1936.13 secondes

Train loss 0.05077554056326186 accuracy 0.9916519522666931 macro_avg {'precision': 0.9917730314035496, 'recall': 0.9917389815470623, 'f1-score': 0.9917368120594071, 'support': 10182} weighted_avg {'precision': 0.9916894068088475, 'recall': 0.9916519347868789, 'f1-score': 0.9916515399913998, 'support': 10182}
 
time = 26.95 secondes

Val loss 1.0961152207287534 accuracy 0.8648409843444824 macro_avg {'precision': 0.8908002475080167, 'recall': 0.8692175151298347, 'f1-score': 0.87503406376472, 'support': 1132} weighted_avg {'precision': 0.8872913651002445, 'recall': 0.8648409893992933, 'f1-score': 0.8702633309407698, 'support': 1132}
 
----------
Epoch 25/40
time = 1934.33 secondes

Train loss 0.04363129239980229 accuracy 0.9923394322395325 macro_avg {'precision': 0.9923325538157911, 'recall': 0.9923011685269414, 'f1-score': 0.9923114439067312, 'support': 10182} weighted_avg {'precision': 0.9923492462823301, 'recall': 0.9923394225103123, 'f1-score': 0.9923388366387709, 'support': 10182}
 
time = 26.93 secondes

Val loss 1.2819272989054042 accuracy 0.8586572408676147 macro_avg {'precision': 0.8795240573115146, 'recall': 0.8648309247837511, 'f1-score': 0.8621827142470003, 'support': 1132} weighted_avg {'precision': 0.8816317472864225, 'recall': 0.8586572438162544, 'f1-score': 0.8589178404796353, 'support': 1132}
 
----------
Epoch 26/40
time = 1938.49 secondes

Train loss 0.046801028405884085 accuracy 0.9924376606941223 macro_avg {'precision': 0.9921284949755409, 'recall': 0.9922859390344693, 'f1-score': 0.9921913305484213, 'support': 10182} weighted_avg {'precision': 0.9924573866760782, 'recall': 0.9924376350422314, 'f1-score': 0.9924315444712474, 'support': 10182}
 
time = 26.84 secondes

Val loss 1.2101632142458956 accuracy 0.8674911856651306 macro_avg {'precision': 0.8820134281015972, 'recall': 0.8693506270506954, 'f1-score': 0.8704167655206427, 'support': 1132} weighted_avg {'precision': 0.882960248520725, 'recall': 0.8674911660777385, 'f1-score': 0.8699329796708589, 'support': 1132}
 
----------
Epoch 27/40
time = 1937.43 secondes

Train loss 0.04071013417712409 accuracy 0.9936162233352661 macro_avg {'precision': 0.9937055873179658, 'recall': 0.9937613561743353, 'f1-score': 0.993722261242613, 'support': 10182} weighted_avg {'precision': 0.9936431759177208, 'recall': 0.9936161854252603, 'f1-score': 0.9936181486509574, 'support': 10182}
 
time = 26.93 secondes

Val loss 0.9988336161360666 accuracy 0.8860424160957336 macro_avg {'precision': 0.8930795706124831, 'recall': 0.8877320363874375, 'f1-score': 0.8879934689804188, 'support': 1132} weighted_avg {'precision': 0.8920234475359592, 'recall': 0.8860424028268551, 'f1-score': 0.8865074656133403, 'support': 1132}
 
----------
Epoch 28/40
time = 1933.77 secondes

Train loss 0.031717777511932964 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945279410829171, 'recall': 0.9945704264858403, 'f1-score': 0.9945465390488912, 'support': 10182} weighted_avg {'precision': 0.9946009258399305, 'recall': 0.994598310744451, 'f1-score': 0.9945970130263182, 'support': 10182}
 
time = 27.36 secondes

Val loss 1.1340138891818512 accuracy 0.879858672618866 macro_avg {'precision': 0.8832993833671209, 'recall': 0.8830205354115407, 'f1-score': 0.8802637401264144, 'support': 1132} weighted_avg {'precision': 0.8878111891430892, 'recall': 0.8798586572438163, 'f1-score': 0.881157425834813, 'support': 1132}
 
----------
Epoch 29/40
time = 1936.01 secondes

Train loss 0.05142504385295245 accuracy 0.9918484091758728 macro_avg {'precision': 0.9913781695837077, 'recall': 0.9913711489208564, 'f1-score': 0.9913458223912137, 'support': 10182} weighted_avg {'precision': 0.9919008653298378, 'recall': 0.991848359850717, 'f1-score': 0.9918452348183082, 'support': 10182}
 
time = 27.05 secondes

Val loss 1.0288706680080972 accuracy 0.8895759582519531 macro_avg {'precision': 0.9000769585305939, 'recall': 0.8933040445877831, 'f1-score': 0.8939140304029145, 'support': 1132} weighted_avg {'precision': 0.8982974453917828, 'recall': 0.8895759717314488, 'f1-score': 0.8909265300478714, 'support': 1132}
 
----------
Epoch 30/40
time = 1936.51 secondes

Train loss 0.021069545846016474 accuracy 0.9962679743766785 macro_avg {'precision': 0.996174638065271, 'recall': 0.996229953210006, 'f1-score': 0.9961979956866299, 'support': 10182} weighted_avg {'precision': 0.9962760344203828, 'recall': 0.9962679237870752, 'f1-score': 0.9962678054708173, 'support': 10182}
 
time = 26.96 secondes

Val loss 1.1915657489488194 accuracy 0.8763250708580017 macro_avg {'precision': 0.8795647596996379, 'recall': 0.8797386157301957, 'f1-score': 0.877129838916427, 'support': 1132} weighted_avg {'precision': 0.8818042199873414, 'recall': 0.8763250883392226, 'f1-score': 0.8764554579372803, 'support': 1132}
 
----------
Epoch 31/40
time = 1933.12 secondes

Train loss 0.02989089164423759 accuracy 0.9956786632537842 macro_avg {'precision': 0.9956988751161988, 'recall': 0.9956621554252971, 'f1-score': 0.9956744030799074, 'support': 10182} weighted_avg {'precision': 0.9956977137212886, 'recall': 0.9956786485955608, 'f1-score': 0.9956820360154703, 'support': 10182}
 
time = 28.81 secondes

Val loss 1.064186005808103 accuracy 0.8895759582519531 macro_avg {'precision': 0.8910820175319133, 'recall': 0.8913420388477882, 'f1-score': 0.889207221650949, 'support': 1132} weighted_avg {'precision': 0.893999525972976, 'recall': 0.8895759717314488, 'f1-score': 0.8898744333942096, 'support': 1132}
 
----------
Epoch 32/40
time = 1935.86 secondes

Train loss 0.02633860749416183 accuracy 0.9958751201629639 macro_avg {'precision': 0.9957897068679478, 'recall': 0.9959148683071766, 'f1-score': 0.9958477233182175, 'support': 10182} weighted_avg {'precision': 0.9958826391901451, 'recall': 0.995875073659399, 'f1-score': 0.9958744779318645, 'support': 10182}
 
time = 27.28 secondes

Val loss 1.1471841780623666 accuracy 0.8869258165359497 macro_avg {'precision': 0.8892502594029732, 'recall': 0.8921884305899402, 'f1-score': 0.8884511358297604, 'support': 1132} weighted_avg {'precision': 0.892122541609864, 'recall': 0.8869257950530035, 'f1-score': 0.8872210517072644, 'support': 1132}
 
----------
Epoch 33/40
time = 1938.56 secondes

Train loss 0.0249032885640333 accuracy 0.9963661432266235 macro_avg {'precision': 0.9960266613323986, 'recall': 0.9957730831743247, 'f1-score': 0.9958945369553793, 'support': 10182} weighted_avg {'precision': 0.9963712153052944, 'recall': 0.9963661363189943, 'f1-score': 0.9963637635373106, 'support': 10182}
 
time = 27.16 secondes

Val loss 1.1933080631382145 accuracy 0.8789752721786499 macro_avg {'precision': 0.8807700253400232, 'recall': 0.8813465157639291, 'f1-score': 0.878211235876124, 'support': 1132} weighted_avg {'precision': 0.8854876835905765, 'recall': 0.8789752650176679, 'f1-score': 0.8796364896011556, 'support': 1132}
 
----------
Epoch 34/40
time = 1934.69 secondes

Train loss 0.024369392896209766 accuracy 0.9958751201629639 macro_avg {'precision': 0.9958194735377773, 'recall': 0.995644316132634, 'f1-score': 0.9957280535535717, 'support': 10182} weighted_avg {'precision': 0.9958809163489739, 'recall': 0.995875073659399, 'f1-score': 0.9958747904372622, 'support': 10182}
 
time = 27.11 secondes

Val loss 1.136046262081436 accuracy 0.8833922147750854 macro_avg {'precision': 0.8855868455976639, 'recall': 0.8873537520452874, 'f1-score': 0.8835052451016265, 'support': 1132} weighted_avg {'precision': 0.8885736110636859, 'recall': 0.8833922261484098, 'f1-score': 0.8830043569732046, 'support': 1132}
 
----------
Epoch 35/40
time = 1937.02 secondes

Train loss 0.01760812162557648 accuracy 0.9971518516540527 macro_avg {'precision': 0.9970768847323537, 'recall': 0.9971756065834981, 'f1-score': 0.9971233527108165, 'support': 10182} weighted_avg {'precision': 0.9971576926629545, 'recall': 0.9971518365743469, 'f1-score': 0.9971520426198989, 'support': 10182}
 
time = 27.32 secondes

Val loss 1.0595294858406779 accuracy 0.8860424160957336 macro_avg {'precision': 0.8895723795560351, 'recall': 0.8898067452119143, 'f1-score': 0.8880692115487948, 'support': 1132} weighted_avg {'precision': 0.8905943525621957, 'recall': 0.8860424028268551, 'f1-score': 0.8865231552291448, 'support': 1132}
 
----------
Epoch 36/40
time = 1935.29 secondes

Train loss 0.015790579075957104 accuracy 0.997741162776947 macro_avg {'precision': 0.9976877462447551, 'recall': 0.9977592306847335, 'f1-score': 0.997720112120715, 'support': 10182} weighted_avg {'precision': 0.9977505830863589, 'recall': 0.9977411117658613, 'f1-score': 0.9977424467719331, 'support': 10182}
 
time = 27.29 secondes

Val loss 1.201787515290075 accuracy 0.8869258165359497 macro_avg {'precision': 0.892217357575199, 'recall': 0.8891479925448573, 'f1-score': 0.8883054976618594, 'support': 1132} weighted_avg {'precision': 0.8910279482560494, 'recall': 0.8869257950530035, 'f1-score': 0.8864922353262297, 'support': 1132}
 
----------
Epoch 37/40
time = 1936.03 secondes

Train loss 0.008548106780935896 accuracy 0.9985268115997314 macro_avg {'precision': 0.998584905775696, 'recall': 0.9985209416182835, 'f1-score': 0.998551484516304, 'support': 10182} weighted_avg {'precision': 0.9985292316773128, 'recall': 0.998526812021214, 'f1-score': 0.9985265872167454, 'support': 10182}
 
time = 27.41 secondes

Val loss 1.1922159700744603 accuracy 0.8842756152153015 macro_avg {'precision': 0.8981448633263, 'recall': 0.8884811550417903, 'f1-score': 0.8897770402666222, 'support': 1132} weighted_avg {'precision': 0.897467538041832, 'recall': 0.8842756183745583, 'f1-score': 0.8867479156956489, 'support': 1132}
 
----------
Epoch 38/40
time = 1937.25 secondes

Train loss 0.011702841771286866 accuracy 0.9980357885360718 macro_avg {'precision': 0.9980307746448716, 'recall': 0.9980504067251974, 'f1-score': 0.9980373472945298, 'support': 10182} weighted_avg {'precision': 0.9980422863655678, 'recall': 0.9980357493616185, 'f1-score': 0.9980356663827719, 'support': 10182}
 
time = 27.34 secondes

Val loss 1.1045727952424758 accuracy 0.8922261595726013 macro_avg {'precision': 0.8999556252683995, 'recall': 0.8945426863923764, 'f1-score': 0.8946826427633375, 'support': 1132} weighted_avg {'precision': 0.8989986575754078, 'recall': 0.892226148409894, 'f1-score': 0.8927803657613275, 'support': 1132}
 
----------
Epoch 39/40
time = 1937.81 secondes

Train loss 0.0077402398941975115 accuracy 0.998821496963501 macro_avg {'precision': 0.9988720905535191, 'recall': 0.9988688160928954, 'f1-score': 0.9988684924492961, 'support': 10182} weighted_avg {'precision': 0.9988254947256228, 'recall': 0.9988214496169712, 'f1-score': 0.9988214338173489, 'support': 10182}
 
time = 27.28 secondes

Val loss 1.0738430987316667 accuracy 0.8878092169761658 macro_avg {'precision': 0.8919302610632245, 'recall': 0.8893629289282542, 'f1-score': 0.8896545761151453, 'support': 1132} weighted_avg {'precision': 0.890033934768382, 'recall': 0.8878091872791519, 'f1-score': 0.8879295014067046, 'support': 1132}
 
----------
Epoch 40/40
time = 1937.37 secondes

Train loss 0.0018609809105008346 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996215263140737, 'recall': 0.999615444965549, 'f1-score': 0.9996182976353302, 'support': 10182} weighted_avg {'precision': 0.9996075244080129, 'recall': 0.9996071498723237, 'f1-score': 0.9996071468802523, 'support': 10182}
 
time = 27.27 secondes

Val loss 1.0886271112616746 accuracy 0.8886925578117371 macro_avg {'precision': 0.8947820089770724, 'recall': 0.8914279698050629, 'f1-score': 0.8911934833171046, 'support': 1132} weighted_avg {'precision': 0.8936686719828693, 'recall': 0.8886925795053003, 'f1-score': 0.8891292185167462, 'support': 1132}
 
----------
best_accuracy 0.8922261595726013 best_epoch 38 macro_avg {'precision': 0.8999556252683995, 'recall': 0.8945426863923764, 'f1-score': 0.8946826427633375, 'support': 1132} weighted_avg {'precision': 0.8989986575754078, 'recall': 0.892226148409894, 'f1-score': 0.8927803657613275, 'support': 1132}

average train time 1933.0430690646172

average val time 27.182408529520036
 
time = 181.88 secondes

test_accuracy 0.8325809836387634 macro_avg {'precision': 0.83091361839985, 'recall': 0.8268265530231925, 'f1-score': 0.8271208243450403, 'support': 7532} weighted_avg {'precision': 0.8360094882396911, 'recall': 0.8325809877854488, 'f1-score': 0.8326183974487973, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 1; 79.20 GiB total capacity; 75.39 GiB already allocated; 784.31 MiB free; 76.42 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 1; 79.20 GiB total capacity; 72.39 GiB already allocated; 226.31 MiB free; 76.96 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 1; 79.20 GiB total capacity; 75.62 GiB already allocated; 404.31 MiB free; 76.79 GiB reserved in total by PyTorch)
datasets imported
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_1024_256_1
----------
Epoch 1/40
time = 530.65 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Train loss 0.22592484707365165 micro_f1_score 0.6824656713864053 
 
time = 23.10 secondes

Val loss 0.2035463319205847 micro_f1_score 0.7001996007984032
 
----------
Epoch 2/40
time = 522.33 secondes

Train loss 0.15973390258580178 micro_f1_score 0.7844421699078813 
 
time = 24.87 secondes

Val loss 0.18565021491930134 micro_f1_score 0.7384978372001572
 
----------
Epoch 3/40
time = 522.01 secondes

Train loss 0.1370145833321117 micro_f1_score 0.8230977055526432 
 
time = 22.54 secondes

Val loss 0.1920242105595401 micro_f1_score 0.740598618572525
 
----------
Epoch 4/40
time = 526.88 secondes

Train loss 0.12022310769403571 micro_f1_score 0.8506722151088348 
 
time = 22.71 secondes

Val loss 0.19691698888286216 micro_f1_score 0.7479734708916728
 
----------
Epoch 5/40
time = 522.88 secondes

Train loss 0.10635886798100966 micro_f1_score 0.8716766681238326 
 
time = 22.77 secondes

Val loss 0.20131565459439013 micro_f1_score 0.7416636130450713
 
----------
Epoch 6/40
time = 523.71 secondes

Train loss 0.09394050175743597 micro_f1_score 0.8904342328815835 
 
time = 22.48 secondes

Val loss 0.2039423136681807 micro_f1_score 0.7562408223201176
 
----------
Epoch 7/40
time = 526.65 secondes

Train loss 0.08198535211451419 micro_f1_score 0.9075425790754258 
 
time = 22.57 secondes

Val loss 0.20775096069593899 micro_f1_score 0.7631675874769797
 
----------
Epoch 8/40
time = 531.52 secondes

Train loss 0.07153710609402608 micro_f1_score 0.9234022556390978 
 
time = 22.71 secondes

Val loss 0.23182954284988466 micro_f1_score 0.753054424287301
 
----------
Epoch 9/40
time = 529.72 secondes

Train loss 0.06262292103372044 micro_f1_score 0.9337534523670596 
 
time = 22.96 secondes

Val loss 0.2344643184151806 micro_f1_score 0.7582417582417583
 
----------
Epoch 10/40
time = 528.04 secondes

Train loss 0.05534354529536522 micro_f1_score 0.9417291043906983 
 
time = 22.94 secondes

Val loss 0.24450966288320353 micro_f1_score 0.7563506261180679
 
----------
Epoch 11/40
time = 523.70 secondes

Train loss 0.04730750515025008 micro_f1_score 0.9521416421833926 
 
time = 22.38 secondes

Val loss 0.27374705458517934 micro_f1_score 0.7529244948599787
 
----------
Epoch 12/40
time = 526.67 secondes

Train loss 0.04147690087263179 micro_f1_score 0.9583879170840719 
 
time = 22.54 secondes

Val loss 0.2747123224324867 micro_f1_score 0.7493689145329968
 
----------
Epoch 13/40
time = 527.36 secondes

Train loss 0.03623652552686598 micro_f1_score 0.9624042790626082 
 
time = 22.89 secondes

Val loss 0.28241045919598123 micro_f1_score 0.7546902654867257
 
----------
Epoch 14/40
time = 526.67 secondes

Train loss 0.03239006818427394 micro_f1_score 0.9674993284985227 
 
time = 22.75 secondes

Val loss 0.2930002029313416 micro_f1_score 0.7464183381088826
 
----------
Epoch 15/40
time = 525.87 secondes

Train loss 0.02851637183743118 micro_f1_score 0.9708871926661808 
 
time = 22.85 secondes

Val loss 0.299921914935112 micro_f1_score 0.7551240560949298
 
----------
Epoch 16/40
time = 527.17 secondes

Train loss 0.026036398416083004 micro_f1_score 0.974006116207951 
 
time = 22.77 secondes

Val loss 0.312392817657502 micro_f1_score 0.750638919313618
 
----------
Epoch 17/40
time = 526.52 secondes

Train loss 0.023373400819852848 micro_f1_score 0.9773309377269774 
 
time = 22.76 secondes

Val loss 0.32261954431162504 micro_f1_score 0.756832515767344
 
----------
Epoch 18/40
time = 526.33 secondes

Train loss 0.020674457361707716 micro_f1_score 0.9792048929663609 
 
time = 23.05 secondes

Val loss 0.33662572881725966 micro_f1_score 0.7529658060013956
 
----------
Epoch 19/40
time = 524.91 secondes

Train loss 0.018629847053618816 micro_f1_score 0.9816475256591248 
 
time = 22.49 secondes

Val loss 0.3439950627870247 micro_f1_score 0.7519014849692142
 
----------
Epoch 20/40
time = 528.09 secondes

Train loss 0.017144496515361794 micro_f1_score 0.9824293936044517 
 
time = 22.43 secondes

Val loss 0.3499333893910783 micro_f1_score 0.751330258957077
 
----------
Epoch 21/40
time = 528.21 secondes

Train loss 0.014375306832864209 micro_f1_score 0.9855017169019458 
 
time = 22.60 secondes

Val loss 0.3691385372496042 micro_f1_score 0.7452830188679245
 
----------
Epoch 22/40
time = 527.15 secondes

Train loss 0.012600310889978868 micro_f1_score 0.9875300308889143 
 
time = 22.48 secondes

Val loss 0.3766051883824536 micro_f1_score 0.7509605309116311
 
----------
Epoch 23/40
time = 529.72 secondes

Train loss 0.01259775899687828 micro_f1_score 0.9863733252131547 
 
time = 23.00 secondes

Val loss 0.37791102294062007 micro_f1_score 0.7462794918330308
 
----------
Epoch 24/40
time = 529.31 secondes

Train loss 0.011114332742222401 micro_f1_score 0.9884172826335441 
 
time = 22.71 secondes

Val loss 0.3811854246209879 micro_f1_score 0.750088370448922
 
----------
Epoch 25/40
time = 530.07 secondes

Train loss 0.0112672990705841 micro_f1_score 0.9886852832488856 
 
time = 22.93 secondes

Val loss 0.40701562386067186 micro_f1_score 0.7412882787750791
 
----------
Epoch 26/40
time = 527.56 secondes

Train loss 0.009205031972866179 micro_f1_score 0.9908689697154163 
 
time = 22.85 secondes

Val loss 0.3947780416881452 micro_f1_score 0.7501779359430606
 
----------
Epoch 27/40
time = 527.94 secondes

Train loss 0.008236105164391333 micro_f1_score 0.9909772718620322 
 
time = 22.68 secondes

Val loss 0.39035441897443085 micro_f1_score 0.7591985428051002
 
----------
Epoch 28/40
time = 528.73 secondes

Train loss 0.008239770025187403 micro_f1_score 0.9918179396430338 
 
time = 22.91 secondes

Val loss 0.39191059511704524 micro_f1_score 0.7587219977965479
 
----------
Epoch 29/40
time = 526.88 secondes

Train loss 0.006719817721199974 micro_f1_score 0.9933417037628884 
 
time = 22.78 secondes

Val loss 0.43623538034372644 micro_f1_score 0.7432574430823118
 
----------
Epoch 30/40
time = 526.14 secondes

Train loss 0.0067882790072765495 micro_f1_score 0.9936102236421724 
 
time = 22.54 secondes

Val loss 0.4151973155189733 micro_f1_score 0.7613469985358712
 
----------
Epoch 31/40
time = 528.86 secondes

Train loss 0.00540263184014842 micro_f1_score 0.9944877399733891 
 
time = 22.78 secondes

Val loss 0.4133974209916396 micro_f1_score 0.7628344179320318
 
----------
Epoch 32/40
time = 528.56 secondes

Train loss 0.0051039404142176024 micro_f1_score 0.9950203367924887 
 
time = 22.75 secondes

Val loss 0.4244934100596631 micro_f1_score 0.7552346570397113
 
----------
Epoch 33/40
time = 527.75 secondes

Train loss 0.006478848450337086 micro_f1_score 0.9935356300859381 
 
time = 23.15 secondes

Val loss 0.4182514757162235 micro_f1_score 0.7620071684587814
 
----------
Epoch 34/40
time = 532.38 secondes

Train loss 0.0046909536218057235 micro_f1_score 0.9959708073589782 
 
time = 22.76 secondes

Val loss 0.41996281508539546 micro_f1_score 0.7600725952813068
 
----------
Epoch 35/40
time = 529.56 secondes

Train loss 0.004061520911735086 micro_f1_score 0.9964661625565223 
 
time = 22.84 secondes

Val loss 0.432510640533244 micro_f1_score 0.757274662881476
 
----------
Epoch 36/40
time = 531.15 secondes

Train loss 0.0036786195880529966 micro_f1_score 0.9965787272865505 
 
time = 22.85 secondes

Val loss 0.4410126473082871 micro_f1_score 0.757267441860465
 
----------
Epoch 37/40
time = 528.17 secondes

Train loss 0.0022995002827998295 micro_f1_score 0.9980244662259706 
 
time = 22.61 secondes

Val loss 0.4350888423743795 micro_f1_score 0.759898292771522
 
----------
Epoch 38/40
time = 526.21 secondes

Train loss 0.002172863164230728 micro_f1_score 0.9981380856480602 
 
time = 22.37 secondes

Val loss 0.4504261187842635 micro_f1_score 0.7574679943100996
 
----------
Epoch 39/40
time = 529.86 secondes

Train loss 0.0022845670286482643 micro_f1_score 0.9979860926397386 
 
time = 22.84 secondes

Val loss 0.44738135120419203 micro_f1_score 0.7600849256900212
 
----------
Epoch 40/40
time = 527.24 secondes

Train loss 0.0016954608446204467 micro_f1_score 0.9985948121985492 
 
time = 22.96 secondes

Val loss 0.4430806491462911 micro_f1_score 0.7623157137720245
 
----------
best_f1_socre 0.7631675874769797 best_epoch 7

average train time 527.4785921752452

average val time 22.798672765493393
 
time = 28.41 secondes

test_f1_score 0.7726459004654492

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_1024_512_1
----------
Epoch 1/40
time = 692.16 secondes

Train loss 0.25411651462048024 micro_f1_score 0.6220676906826285 
 
time = 26.26 secondes

Val loss 0.217404697762161 micro_f1_score 0.690909090909091
 
----------
Epoch 2/40
time = 685.73 secondes

Train loss 0.17270123498128342 micro_f1_score 0.7641668378878159 
 
time = 25.50 secondes

Val loss 0.194433186508593 micro_f1_score 0.7227488151658767
 
----------
Epoch 3/40
time = 676.24 secondes

Train loss 0.15000721388706215 micro_f1_score 0.8044059285656434 
 
time = 25.76 secondes

Val loss 0.19009031709588942 micro_f1_score 0.7361384191899332
 
----------
Epoch 4/40
time = 687.57 secondes

Train loss 0.13397453109826055 micro_f1_score 0.8298068815995504 
 
time = 29.88 secondes

Val loss 0.19145682820531187 micro_f1_score 0.7431571053618298
 
----------
Epoch 5/40
time = 684.30 secondes

Train loss 0.12091103867535387 micro_f1_score 0.848499361430396 
 
time = 25.65 secondes

Val loss 0.19593118204445134 micro_f1_score 0.7436557557925709
 
----------
Epoch 6/40
time = 679.14 secondes

Train loss 0.10808438652673283 micro_f1_score 0.8671601400827762 
 
time = 25.87 secondes

Val loss 0.19852512806165415 micro_f1_score 0.7433369843008398
 
----------
Epoch 7/40
time = 688.33 secondes

Train loss 0.09571399094184509 micro_f1_score 0.886384236453202 
 
time = 25.85 secondes

Val loss 0.20421009425257072 micro_f1_score 0.7547989858746831
 
----------
Epoch 8/40
time = 683.77 secondes

Train loss 0.08498018628137337 micro_f1_score 0.9027826837787982 
 
time = 25.55 secondes

Val loss 0.2105288568456642 micro_f1_score 0.7610108303249098
 
----------
Epoch 9/40
time = 681.16 secondes

Train loss 0.07550680672766658 micro_f1_score 0.9177638004453647 
 
time = 25.65 secondes

Val loss 0.21843854960848075 micro_f1_score 0.7652297826861418
 
----------
Epoch 10/40
time = 687.40 secondes

Train loss 0.06576980729042008 micro_f1_score 0.9288051098301916 
 
time = 25.50 secondes

Val loss 0.23984067080939403 micro_f1_score 0.756254467476769
 
----------
Epoch 11/40
time = 681.00 secondes

Train loss 0.05834555001090373 micro_f1_score 0.93903619121347 
 
time = 25.86 secondes

Val loss 0.25859968901657665 micro_f1_score 0.7492018446257539
 
----------
Epoch 12/40
time = 681.39 secondes

Train loss 0.052136386789146574 micro_f1_score 0.9440197668133735 
 
time = 28.26 secondes

Val loss 0.25724286708186883 micro_f1_score 0.7595744680851064
 
----------
Epoch 13/40
time = 685.34 secondes

Train loss 0.04586674677300359 micro_f1_score 0.9527227818301107 
 
time = 25.74 secondes

Val loss 0.28055059457900094 micro_f1_score 0.7471224276246948
 
----------
Epoch 14/40
time = 675.45 secondes

Train loss 0.03864987131233352 micro_f1_score 0.9607699711260828 
 
time = 26.41 secondes

Val loss 0.2814367230309815 micro_f1_score 0.7609547559672247
 
----------
Epoch 15/40
time = 668.49 secondes

Train loss 0.035516205668734674 micro_f1_score 0.9642129540649624 
 
time = 25.45 secondes

Val loss 0.28920974460293036 micro_f1_score 0.7578872740163063
 
----------
Epoch 16/40
time = 685.61 secondes

Train loss 0.030432598854347997 micro_f1_score 0.9707087337749359 
 
time = 25.95 secondes

Val loss 0.3039974002320258 micro_f1_score 0.7600426590828298
 
----------
Epoch 17/40
time = 689.90 secondes

Train loss 0.0267992189728764 micro_f1_score 0.9735976123058085 
 
time = 25.91 secondes

Val loss 0.3063656554603186 micro_f1_score 0.7573371510379384
 
----------
Epoch 18/40
time = 678.60 secondes

Train loss 0.02476725165023225 micro_f1_score 0.974613855329561 
 
time = 25.58 secondes

Val loss 0.3096680313837333 micro_f1_score 0.7565435640014342
 
----------
Epoch 19/40
time = 666.91 secondes

Train loss 0.02281687768293662 micro_f1_score 0.9772475239952584 
 
time = 25.83 secondes

Val loss 0.3236220416719796 micro_f1_score 0.7597883597883599
 
----------
Epoch 20/40
time = 662.71 secondes

Train loss 0.02050411223836646 micro_f1_score 0.9802021743276751 
 
time = 27.71 secondes

Val loss 0.33089019113876783 micro_f1_score 0.7565623876303488
 
----------
Epoch 21/40
time = 665.54 secondes

Train loss 0.01769455563946132 micro_f1_score 0.9826611671249619 
 
time = 25.87 secondes

Val loss 0.35612292319047645 micro_f1_score 0.743437171858593
 
----------
Epoch 22/40
time = 666.48 secondes

Train loss 0.01693638969597675 micro_f1_score 0.9823329644751403 
 
time = 25.59 secondes

Val loss 0.35000809428633234 micro_f1_score 0.7544048903272204
 
----------
Epoch 23/40
time = 661.82 secondes

Train loss 0.014382982801757165 micro_f1_score 0.9857061177815895 
 
time = 26.67 secondes

Val loss 0.35346094812037515 micro_f1_score 0.7475832438238453
 
----------
Epoch 24/40
time = 662.32 secondes

Train loss 0.013385375708169597 micro_f1_score 0.9866666666666666 
 
time = 25.97 secondes

Val loss 0.37432334144584467 micro_f1_score 0.7507953340402969
 
----------
Epoch 25/40
time = 661.26 secondes

Train loss 0.011389067690653794 micro_f1_score 0.9884890989480103 
 
time = 26.08 secondes

Val loss 0.3590074449044759 micro_f1_score 0.7594287806664226
 
----------
Epoch 26/40
time = 664.21 secondes

Train loss 0.010596381527631803 micro_f1_score 0.9887366818873669 
 
time = 25.56 secondes

Val loss 0.4061886990656618 micro_f1_score 0.7385159010600707
 
----------
Epoch 27/40
time = 661.92 secondes

Train loss 0.009375063160005411 micro_f1_score 0.9909333333333333 
 
time = 26.95 secondes

Val loss 0.3866929919993291 micro_f1_score 0.7532751091703057
 
----------
Epoch 28/40
time = 666.27 secondes

Train loss 0.008828752649017727 micro_f1_score 0.9911322549952426 
 
time = 25.56 secondes

Val loss 0.40357439659658023 micro_f1_score 0.7503703703703704
 
----------
Epoch 29/40
time = 662.40 secondes

Train loss 0.008443048411559708 micro_f1_score 0.9913189156259519 
 
time = 26.05 secondes

Val loss 0.40830634155722917 micro_f1_score 0.7466857757076316
 
----------
Epoch 30/40
time = 668.33 secondes

Train loss 0.0074961160169861926 micro_f1_score 0.9930447341416138 
 
time = 29.42 secondes

Val loss 0.4103825706683221 micro_f1_score 0.7547035853745119
 
----------
Epoch 31/40
time = 664.86 secondes

Train loss 0.006644729354160813 micro_f1_score 0.9935743888065092 
 
time = 26.15 secondes

Val loss 0.3961962593383476 micro_f1_score 0.75377969762419
 
----------
Epoch 32/40
time = 663.89 secondes

Train loss 0.0056562877791358985 micro_f1_score 0.9946036330470472 
 
time = 26.25 secondes

Val loss 0.4128897795911695 micro_f1_score 0.7561151079136691
 
----------
Epoch 33/40
time = 664.62 secondes

Train loss 0.005209490904707235 micro_f1_score 0.9947934481054992 
 
time = 26.13 secondes

Val loss 0.4230678831456137 micro_f1_score 0.751624548736462
 
----------
Epoch 34/40
time = 663.19 secondes

Train loss 0.005121822644201808 micro_f1_score 0.9951679793022106 
 
time = 25.48 secondes

Val loss 0.43716192929471126 micro_f1_score 0.7525035765379112
 
----------
Epoch 35/40
time = 661.77 secondes

Train loss 0.004078880929559058 micro_f1_score 0.9963484214530239 
 
time = 25.36 secondes

Val loss 0.43745740051152276 micro_f1_score 0.7547169811320755
 
----------
Epoch 36/40
time = 667.47 secondes

Train loss 0.0030242639167972645 micro_f1_score 0.9974918294444023 
 
time = 25.55 secondes

Val loss 0.44278962690322127 micro_f1_score 0.7460881934566146
 
----------
Epoch 37/40
time = 661.97 secondes

Train loss 0.0033198748548858093 micro_f1_score 0.9972259167775034 
 
time = 25.66 secondes

Val loss 0.4413498879456129 micro_f1_score 0.7541213609259909
 
----------
Epoch 38/40
time = 661.74 secondes

Train loss 0.0023178916698508383 micro_f1_score 0.9977574214147249 
 
time = 26.19 secondes

Val loss 0.4369374789664003 micro_f1_score 0.75272599366866
 
----------
Epoch 39/40
time = 662.45 secondes

Train loss 0.0017952681487299782 micro_f1_score 0.9986699600988028 
 
time = 25.64 secondes

Val loss 0.4327153616019937 micro_f1_score 0.7558097962102251
 
----------
Epoch 40/40
time = 662.63 secondes

Train loss 0.0014894743956222203 micro_f1_score 0.9985559018013225 
 
time = 25.57 secondes

Val loss 0.44777486485535983 micro_f1_score 0.7489361702127659
 
----------
best_f1_socre 0.7652297826861418 best_epoch 9

average train time 672.4077492177487

average val time 26.14613224864006
 
time = 27.47 secondes

test_f1_score 0.7517289073305672

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_2048_256_1
----------
Epoch 1/40
time = 870.40 secondes

Train loss 0.22044507304021904 micro_f1_score 0.7011098354381936 
 
time = 31.47 secondes

Val loss 0.18689993109370842 micro_f1_score 0.7434312210200926
 
----------
Epoch 2/40
time = 870.05 secondes

Train loss 0.15140543291764752 micro_f1_score 0.8012162983985405 
 
time = 30.60 secondes

Val loss 0.16516110826222624 micro_f1_score 0.7679814385150812
 
----------
Epoch 3/40
time = 867.69 secondes

Train loss 0.12885613112903394 micro_f1_score 0.8376678020436786 
 
time = 30.57 secondes

Val loss 0.16264246025534926 micro_f1_score 0.7816443594646272
 
----------
Epoch 4/40
time = 869.94 secondes

Train loss 0.11470518188366483 micro_f1_score 0.8615323541087733 
 
time = 31.10 secondes

Val loss 0.1686681953609967 micro_f1_score 0.7863184994483267
 
----------
Epoch 5/40
time = 867.74 secondes

Train loss 0.10295312217193413 micro_f1_score 0.8780526357385601 
 
time = 30.49 secondes

Val loss 0.1753269967729928 micro_f1_score 0.7799628942486085
 
----------
Epoch 6/40
time = 865.16 secondes

Train loss 0.08981132290351229 micro_f1_score 0.8957923712151002 
 
time = 30.07 secondes

Val loss 0.18537744177413767 micro_f1_score 0.7635960044395116
 
----------
Epoch 7/40
time = 855.90 secondes

Train loss 0.07881888717010214 micro_f1_score 0.9110512129380054 
 
time = 29.91 secondes

Val loss 0.19323476947477605 micro_f1_score 0.7765726681127982
 
----------
Epoch 8/40
time = 851.94 secondes

Train loss 0.06947616204401261 micro_f1_score 0.922945338620636 
 
time = 30.14 secondes

Val loss 0.19247528428181274 micro_f1_score 0.784285194616224
 
----------
Epoch 9/40
time = 858.14 secondes

Train loss 0.061124744329198795 micro_f1_score 0.9341865425635059 
 
time = 30.17 secondes

Val loss 0.20691283657902576 micro_f1_score 0.7842441447835343
 
----------
Epoch 10/40
time = 850.96 secondes

Train loss 0.053611512816519484 micro_f1_score 0.9425056101524414 
 
time = 28.89 secondes

Val loss 0.22263240368395557 micro_f1_score 0.7846754168144732
 
----------
Epoch 11/40
time = 849.52 secondes

Train loss 0.047284015084759476 micro_f1_score 0.9525498207608988 
 
time = 29.07 secondes

Val loss 0.2271254799160801 micro_f1_score 0.7918454935622318
 
----------
Epoch 12/40
time = 848.34 secondes

Train loss 0.04106025237145389 micro_f1_score 0.9575818174825982 
 
time = 29.02 secondes

Val loss 0.24544858853103685 micro_f1_score 0.7850335333568655
 
----------
Epoch 13/40
time = 847.97 secondes

Train loss 0.036658955573498665 micro_f1_score 0.9628661489966941 
 
time = 28.95 secondes

Val loss 0.24395666118772302 micro_f1_score 0.7886435331230283
 
----------
Epoch 14/40
time = 849.13 secondes

Train loss 0.03240674590368898 micro_f1_score 0.9675018225070023 
 
time = 28.90 secondes

Val loss 0.2382868797075553 micro_f1_score 0.7976878612716762
 
----------
Epoch 15/40
time = 849.35 secondes

Train loss 0.028565245308191725 micro_f1_score 0.9714219954735509 
 
time = 28.98 secondes

Val loss 0.275299356181602 micro_f1_score 0.7769230769230769
 
----------
Epoch 16/40
time = 847.88 secondes

Train loss 0.025339263918713103 micro_f1_score 0.9746748278500382 
 
time = 29.03 secondes

Val loss 0.2715007017259715 micro_f1_score 0.7859922178988327
 
----------
Epoch 17/40
time = 847.89 secondes

Train loss 0.023722011219135378 micro_f1_score 0.9759847036328871 
 
time = 29.00 secondes

Val loss 0.2768418440198312 micro_f1_score 0.786508790814496
 
----------
Epoch 18/40
time = 849.27 secondes

Train loss 0.019556778329340656 micro_f1_score 0.981736206633043 
 
time = 28.92 secondes

Val loss 0.2784265142361649 micro_f1_score 0.7860481841064364
 
----------
Epoch 19/40
time = 851.68 secondes

Train loss 0.02014437635588619 micro_f1_score 0.9802588873191034 
 
time = 28.83 secondes

Val loss 0.27379283919686176 micro_f1_score 0.7994186046511629
 
----------
Epoch 20/40
time = 850.39 secondes

Train loss 0.01679709294762647 micro_f1_score 0.9828994579738911 
 
time = 28.80 secondes

Val loss 0.2925508874850195 micro_f1_score 0.7842293906810036
 
----------
Epoch 21/40
time = 847.05 secondes

Train loss 0.015124964301142976 micro_f1_score 0.9840918628161599 
 
time = 28.88 secondes

Val loss 0.29572891309613086 micro_f1_score 0.7951202009329028
 
----------
Epoch 22/40
time = 856.11 secondes

Train loss 0.013909186226439553 micro_f1_score 0.986112170927127 
 
time = 28.85 secondes

Val loss 0.3000040001800803 micro_f1_score 0.7934426229508197
 
----------
Epoch 23/40
time = 860.10 secondes

Train loss 0.012008539494205694 micro_f1_score 0.9883096607136057 
 
time = 28.91 secondes

Val loss 0.31329453370121657 micro_f1_score 0.7871107892831282
 
----------
Epoch 24/40
time = 884.01 secondes

Train loss 0.01128954550839734 micro_f1_score 0.9891498838847222 
 
time = 28.88 secondes

Val loss 0.3284498809791002 micro_f1_score 0.7871250914411121
 
----------
Epoch 25/40
time = 871.97 secondes

Train loss 0.009438602110320653 micro_f1_score 0.9902779366350224 
 
time = 29.00 secondes

Val loss 0.3249716788041787 micro_f1_score 0.7944606413994171
 
----------
Epoch 26/40
time = 873.98 secondes

Train loss 0.00922612047747411 micro_f1_score 0.9908536585365855 
 
time = 28.92 secondes

Val loss 0.34349323296156087 micro_f1_score 0.7858187134502925
 
----------
Epoch 27/40
time = 876.05 secondes

Train loss 0.008845486400254609 micro_f1_score 0.9913248611216803 
 
time = 29.22 secondes

Val loss 0.34432995392650856 micro_f1_score 0.7929385803604266
 
----------
Epoch 28/40
time = 871.02 secondes

Train loss 0.007854719463196219 micro_f1_score 0.9922032480127791 
 
time = 29.09 secondes

Val loss 0.34302436426037647 micro_f1_score 0.7899343544857769
 
----------
Epoch 29/40
time = 870.31 secondes

Train loss 0.007323974788714376 micro_f1_score 0.9936853317102861 
 
time = 28.98 secondes

Val loss 0.3610600374761175 micro_f1_score 0.784426820475847
 
----------
Epoch 30/40
time = 875.40 secondes

Train loss 0.007050119110237312 micro_f1_score 0.9928183303568037 
 
time = 29.06 secondes

Val loss 0.34632165070439946 micro_f1_score 0.7916514097400219
 
----------
Epoch 31/40
time = 915.83 secondes

Train loss 0.005808066257940571 micro_f1_score 0.9943313677002092 
 
time = 28.96 secondes

Val loss 0.35446900349171434 micro_f1_score 0.7926470588235294
 
----------
Epoch 32/40
time = 846.72 secondes

Train loss 0.0056808220141966875 micro_f1_score 0.9943696264171041 
 
time = 28.88 secondes

Val loss 0.3538606249895252 micro_f1_score 0.7927404718693285
 
----------
Epoch 33/40
time = 848.60 secondes

Train loss 0.004948456447150953 micro_f1_score 0.9953997642854427 
 
time = 28.93 secondes

Val loss 0.3647839251111765 micro_f1_score 0.791907514450867
 
----------
Epoch 34/40
time = 845.50 secondes

Train loss 0.004548163675481028 micro_f1_score 0.9960849899274012 
 
time = 28.97 secondes

Val loss 0.3643323836512253 micro_f1_score 0.7973713033953997
 
----------
Epoch 35/40
time = 846.00 secondes

Train loss 0.00361774976956915 micro_f1_score 0.996539266020156 
 
time = 28.90 secondes

Val loss 0.37050824642914243 micro_f1_score 0.7940644227289179
 
----------
Epoch 36/40
time = 846.37 secondes

Train loss 0.0030028816195939527 micro_f1_score 0.9975683890577508 
 
time = 28.90 secondes

Val loss 0.3878612004098345 micro_f1_score 0.7864678064750817
 
----------
Epoch 37/40
time = 844.60 secondes

Train loss 0.0027172726548202377 micro_f1_score 0.9971880224958201 
 
time = 28.94 secondes

Val loss 0.3753022746961625 micro_f1_score 0.7934426229508197
 
----------
Epoch 38/40
time = 846.45 secondes

Train loss 0.0022695969198311275 micro_f1_score 0.9980238656228624 
 
time = 28.88 secondes

Val loss 0.37910502147479136 micro_f1_score 0.7978181818181819
 
----------
Epoch 39/40
time = 847.98 secondes

Train loss 0.0017372922392062285 micro_f1_score 0.9984800121599027 
 
time = 28.85 secondes

Val loss 0.379057127432745 micro_f1_score 0.7991313789359392
 
----------
Epoch 40/40
time = 844.77 secondes

Train loss 0.0013519875975501374 micro_f1_score 0.9988218751187625 
 
time = 28.91 secondes

Val loss 0.3931053076855472 micro_f1_score 0.7924801156905278
 
----------
best_f1_socre 0.7994186046511629 best_epoch 19

average train time 858.4538825273514

average val time 29.295137667655943
 
time = 30.64 secondes

test_f1_score 0.7851851851851852

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_2048_512_1
----------
Epoch 1/40
time = 1689.83 secondes

Train loss 0.2262692908244627 micro_f1_score 0.687091222030981 
 
time = 35.88 secondes

Val loss 0.18877911189051924 micro_f1_score 0.7205468435866506
 
----------
Epoch 2/40
time = 1693.32 secondes

Train loss 0.15155969974291217 micro_f1_score 0.8015063168124393 
 
time = 35.77 secondes

Val loss 0.17476356957779557 micro_f1_score 0.7553107789142407
 
----------
Epoch 3/40
time = 1690.60 secondes

Train loss 0.13047038515744447 micro_f1_score 0.8377602297200288 
 
time = 35.39 secondes

Val loss 0.1710681853602167 micro_f1_score 0.7743668457405987
 
----------
Epoch 4/40
time = 1687.15 secondes

Train loss 0.11469560519431357 micro_f1_score 0.8601715102429729 
 
time = 35.35 secondes

Val loss 0.17101446813980087 micro_f1_score 0.7780285929270127
 
----------
Epoch 5/40
time = 1688.04 secondes

Train loss 0.09872484498296503 micro_f1_score 0.8861740402482899 
 
time = 35.30 secondes

Val loss 0.173746685818082 micro_f1_score 0.7772441817510158
 
----------
Epoch 6/40
time = 1685.74 secondes

Train loss 0.08713119680246523 micro_f1_score 0.9017944791298543 
 
time = 35.28 secondes

Val loss 0.1875484364076716 micro_f1_score 0.7744742567077592
 
----------
Epoch 7/40
time = 1686.60 secondes

Train loss 0.07690277914474676 micro_f1_score 0.9164156921031017 
 
time = 35.60 secondes

Val loss 0.18617448564924177 micro_f1_score 0.7858942065491185
 
----------
Epoch 8/40
time = 1686.95 secondes

Train loss 0.06756332810917819 micro_f1_score 0.9249336041243555 
 
time = 35.21 secondes

Val loss 0.20405058581076685 micro_f1_score 0.7745415318230852
 
----------
Epoch 9/40
time = 1685.70 secondes

Train loss 0.0591639948111061 micro_f1_score 0.9379036650844291 
 
time = 35.41 secondes

Val loss 0.22058204066802245 micro_f1_score 0.7759601706970128
 
----------
Epoch 10/40
time = 1687.65 secondes

Train loss 0.052563296526938946 micro_f1_score 0.9455882352941176 
 
time = 35.28 secondes

Val loss 0.2195717012051676 micro_f1_score 0.7863733144073812
 
----------
Epoch 11/40
time = 1686.07 secondes

Train loss 0.04558913445536483 micro_f1_score 0.9552365845165784 
 
time = 35.39 secondes

Val loss 0.24833719865953335 micro_f1_score 0.7773925104022191
 
----------
Epoch 12/40
time = 1688.69 secondes

Train loss 0.04143929474878016 micro_f1_score 0.9585807944465871 
 
time = 35.31 secondes

Val loss 0.2490166638229714 micro_f1_score 0.7809125740160223
 
----------
Epoch 13/40
time = 1686.05 secondes

Train loss 0.03664935618924262 micro_f1_score 0.9636594859146788 
 
time = 35.32 secondes

Val loss 0.25327716376937803 micro_f1_score 0.7850662944870901
 
----------
Epoch 14/40
time = 1687.04 secondes

Train loss 0.031976560585259516 micro_f1_score 0.9682198510785293 
 
time = 35.29 secondes

Val loss 0.26258752953077924 micro_f1_score 0.7855133614627287
 
----------
Epoch 15/40
time = 1686.60 secondes

Train loss 0.029238337809261907 micro_f1_score 0.9702186527302771 
 
time = 35.26 secondes

Val loss 0.26453399566597624 micro_f1_score 0.7839659453706987
 
----------
Epoch 16/40
time = 1687.53 secondes

Train loss 0.025909315289400922 micro_f1_score 0.9735015530927638 
 
time = 35.44 secondes

Val loss 0.2502041747946231 micro_f1_score 0.7932640630598352
 
----------
Epoch 17/40
time = 1685.90 secondes

Train loss 0.022337464956138788 micro_f1_score 0.9774424572019456 
 
time = 35.26 secondes

Val loss 0.26996200519507046 micro_f1_score 0.7890371438874865
 
----------
Epoch 18/40
time = 1684.81 secondes

Train loss 0.019662070030300367 micro_f1_score 0.9807957153787299 
 
time = 35.80 secondes

Val loss 0.27949955338825944 micro_f1_score 0.789492623245772
 
----------
Epoch 19/40
time = 1686.58 secondes

Train loss 0.019016785802097303 micro_f1_score 0.9813612405469406 
 
time = 35.15 secondes

Val loss 0.3040194876614164 micro_f1_score 0.7802079598422373
 
----------
Epoch 20/40
time = 1683.98 secondes

Train loss 0.016554331910840513 micro_f1_score 0.9833760079489433 
 
time = 35.32 secondes

Val loss 0.3158818883974044 micro_f1_score 0.7801570306923626
 
----------
Epoch 21/40
time = 1684.34 secondes

Train loss 0.01579654415438019 micro_f1_score 0.9835640468291195 
 
time = 35.17 secondes

Val loss 0.3096532965781259 micro_f1_score 0.7817445712182554
 
----------
Epoch 22/40
time = 1686.70 secondes

Train loss 0.014997065493518168 micro_f1_score 0.9848981771031957 
 
time = 35.31 secondes

Val loss 0.31533587760612614 micro_f1_score 0.7792678506705327
 
----------
Epoch 23/40
time = 1685.70 secondes

Train loss 0.011856829535440533 micro_f1_score 0.9880739188416842 
 
time = 35.20 secondes

Val loss 0.3009481622119907 micro_f1_score 0.7954545454545455
 
----------
Epoch 24/40
time = 1684.94 secondes

Train loss 0.011283476541745939 micro_f1_score 0.9882200449849415 
 
time = 35.19 secondes

Val loss 0.3372810319310329 micro_f1_score 0.7775781530722242
 
----------
Epoch 25/40
time = 1684.71 secondes

Train loss 0.011746285239057321 micro_f1_score 0.9885722992533902 
 
time = 35.23 secondes

Val loss 0.31873806578214053 micro_f1_score 0.7927536231884058
 
----------
Epoch 26/40
time = 1683.88 secondes

Train loss 0.010032600744602245 micro_f1_score 0.9904790920862213 
 
time = 36.08 secondes

Val loss 0.32982410783650445 micro_f1_score 0.7886597938144329
 
----------
Epoch 27/40
time = 1684.62 secondes

Train loss 0.008864785882991503 micro_f1_score 0.9908976653844689 
 
time = 35.23 secondes

Val loss 0.35477995622109193 micro_f1_score 0.7867195958137857
 
----------
Epoch 28/40
time = 1686.00 secondes

Train loss 0.008424436291632545 micro_f1_score 0.9917040870690312 
 
time = 35.28 secondes

Val loss 0.34580401001406497 micro_f1_score 0.7884057971014492
 
----------
Epoch 29/40
time = 1686.79 secondes

Train loss 0.007945404083652607 micro_f1_score 0.9927690668290455 
 
time = 35.27 secondes

Val loss 0.351462222269324 micro_f1_score 0.7816593886462883
 
----------
Epoch 30/40
time = 1683.73 secondes

Train loss 0.007171781151712796 micro_f1_score 0.9927373664397885 
 
time = 36.28 secondes

Val loss 0.3600018506900209 micro_f1_score 0.78421433743664
 
----------
Epoch 31/40
time = 1685.69 secondes

Train loss 0.006042401055985776 micro_f1_score 0.9939541427430701 
 
time = 35.35 secondes

Val loss 0.35803736593635355 micro_f1_score 0.7879884225759769
 
----------
Epoch 32/40
time = 1685.92 secondes

Train loss 0.0057564059246188815 micro_f1_score 0.994186709221475 
 
time = 35.32 secondes

Val loss 0.379942425511411 micro_f1_score 0.7738010021474588
 
----------
Epoch 33/40
time = 1688.65 secondes

Train loss 0.004650658803497995 micro_f1_score 0.9955112598904444 
 
time = 36.42 secondes

Val loss 0.3633488597439938 micro_f1_score 0.78625134264232
 
----------
Epoch 34/40
time = 1685.56 secondes

Train loss 0.003847850548304819 micro_f1_score 0.9966552641581149 
 
time = 36.54 secondes

Val loss 0.3687380740388495 micro_f1_score 0.7905982905982907
 
----------
Epoch 35/40
time = 1686.68 secondes

Train loss 0.0034927446248066434 micro_f1_score 0.9963138894166826 
 
time = 36.54 secondes

Val loss 0.3670914407025595 micro_f1_score 0.792008562254727
 
----------
Epoch 36/40
time = 1689.92 secondes

Train loss 0.003073551591961888 micro_f1_score 0.9969963119273032 
 
time = 36.01 secondes

Val loss 0.3687793740727862 micro_f1_score 0.7912638739706408
 
----------
Epoch 37/40
time = 1690.95 secondes

Train loss 0.0025406191198664996 micro_f1_score 0.9973787182312047 
 
time = 35.96 secondes

Val loss 0.38680397145083695 micro_f1_score 0.7850335333568655
 
----------
Epoch 38/40
time = 1689.62 secondes

Train loss 0.0020512917560883397 micro_f1_score 0.9980250664641094 
 
time = 37.00 secondes

Val loss 0.3874368161940184 micro_f1_score 0.7834757834757834
 
----------
Epoch 39/40
time = 1692.91 secondes

Train loss 0.0018072965118597756 micro_f1_score 0.9984042553191489 
 
time = 36.09 secondes

Val loss 0.373163746395072 micro_f1_score 0.7872878295413507
 
----------
Epoch 40/40
time = 1690.51 secondes

Train loss 0.001819711908260738 micro_f1_score 0.9983666957875944 
 
time = 36.05 secondes

Val loss 0.3864887905780409 micro_f1_score 0.7869907076483202
 
----------
best_f1_socre 0.7954545454545455 best_epoch 23

average train time 1687.0673985421658

average val time 35.587637239694594
 
time = 37.90 secondes

test_f1_score 0.7769477054429027

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 372.00 MiB (GPU 1; 79.20 GiB total capacity; 74.17 GiB already allocated; 332.31 MiB free; 76.86 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
ECtHR_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.50 GiB (GPU 1; 79.20 GiB total capacity; 74.48 GiB already allocated; 114.31 MiB free; 77.07 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Traceback (most recent call last):
  File "test_sparse.py", line 114, in <module>
    model = Bigbird(block_size=block_size,num_labels=len(set(data_train['target'])))
TypeError: unhashable type: 'list'
