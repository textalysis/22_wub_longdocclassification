[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_1
----------
Epoch 1/40
time = 51.01 secondes

Train loss 0.6484671542138765 accuracy 0.5988371968269348 macro_avg {'precision': 0.5110780423280423, 'recall': 0.5065341417031028, 'f1-score': 0.48207592457002096, 'support': 516} weighted_avg {'precision': 0.5468878173577786, 'recall': 0.5988372093023255, 'f1-score': 0.5497498120475199, 'support': 516}
 
time = 1.55 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.5683221146464348 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 44.12 secondes

Train loss 0.4316922918413625 accuracy 0.7926356792449951 macro_avg {'precision': 0.7960464015151515, 'recall': 0.743908782081498, 'f1-score': 0.757253338140314, 'support': 516} weighted_avg {'precision': 0.7941244751291989, 'recall': 0.7926356589147286, 'f1-score': 0.7827573460081663, 'support': 516}
 
time = 1.46 secondes

Val loss 0.449489651247859 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 3/40
time = 43.89 secondes

Train loss 0.2424559767047564 accuracy 0.9089147448539734 macro_avg {'precision': 0.9004681950274459, 'recall': 0.903182549615591, 'f1-score': 0.9017879198979488, 'support': 516} weighted_avg {'precision': 0.9092873698728202, 'recall': 0.9089147286821705, 'f1-score': 0.909068544699096, 'support': 516}
 
time = 1.55 secondes

Val loss 0.4411683026701212 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 44.17 secondes

Train loss 0.1529593360469197 accuracy 0.9457364082336426 macro_avg {'precision': 0.9422062545929616, 'recall': 0.9401362092225671, 'f1-score': 0.9411534701857283, 'support': 516} weighted_avg {'precision': 0.9456397168615254, 'recall': 0.9457364341085271, 'f1-score': 0.9456727818318217, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5802359767258167 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 45.27 secondes

Train loss 0.12945584704478583 accuracy 0.9554263353347778 macro_avg {'precision': 0.9496527777777778, 'recall': 0.9546592331323245, 'f1-score': 0.9520459660507421, 'support': 516} weighted_avg {'precision': 0.9558637489233419, 'recall': 0.9554263565891473, 'f1-score': 0.9555497285066072, 'support': 516}
 
time = 1.55 secondes

Val loss 0.7515546977519989 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 6/40
time = 44.18 secondes

Train loss 0.21710896671213437 accuracy 0.9379844665527344 macro_avg {'precision': 0.9294591283038685, 'recall': 0.9386733416770964, 'f1-score': 0.933641975308642, 'support': 516} weighted_avg {'precision': 0.939382097406025, 'recall': 0.937984496124031, 'f1-score': 0.9383134749736817, 'support': 516}
 
time = 1.55 secondes

Val loss 0.5084730144590139 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 7/40
time = 44.01 secondes

Train loss 0.10898110413020759 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9283211827278137 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 8/40
time = 44.55 secondes

Train loss 0.11305292753968388 accuracy 0.9709302186965942 macro_avg {'precision': 0.9634177215189874, 'recall': 0.9760496074638754, 'f1-score': 0.9689922480620154, 'support': 516} weighted_avg {'precision': 0.9726140712393289, 'recall': 0.9709302325581395, 'f1-score': 0.9711255333213148, 'support': 516}
 
time = 1.58 secondes

Val loss 0.7843436300754547 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 9/40
time = 44.00 secondes

Train loss 0.05085022477997524 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8264092803001404 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 44.06 secondes

Train loss 0.158899184715031 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.55 secondes

Val loss 0.9702771045267582 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 11/40
time = 44.35 secondes

Train loss 0.25782609717377153 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 1.57 secondes

Val loss 1.470630556344986 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 12/40
time = 43.90 secondes

Train loss 0.1689814520950401 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.55 secondes

Val loss 1.090615674853325 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 13/40
time = 43.92 secondes

Train loss 0.09597611122157876 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 1.59 secondes

Val loss 1.825234591960907 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 45.56 secondes

Train loss 0.2778898612613733 accuracy 0.9496123790740967 macro_avg {'precision': 0.9508524573771311, 'recall': 0.9397136030427644, 'f1-score': 0.9448246364414028, 'support': 516} weighted_avg {'precision': 0.9497654962213129, 'recall': 0.9496124031007752, 'f1-score': 0.9492974184521322, 'support': 516}
 
time = 1.56 secondes

Val loss 1.219543695449829 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 15/40
time = 44.01 secondes

Train loss 0.34743856010380003 accuracy 0.9282945990562439 macro_avg {'precision': 0.9255952380952381, 'recall': 0.9183801180046487, 'f1-score': 0.9217717317817705, 'support': 516} weighted_avg {'precision': 0.9280523255813954, 'recall': 0.9282945736434108, 'f1-score': 0.9279881314083002, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2637725472450256 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 43.99 secondes

Train loss 0.11533800290657603 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.45 secondes

Val loss 0.7785346657037735 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 17/40
time = 44.31 secondes

Train loss 0.0562764307198284 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5886543691158295 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 18/40
time = 43.99 secondes

Train loss 0.047533505874911716 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.55 secondes

Val loss 2.50537246465683 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 19/40
time = 44.07 secondes

Train loss 0.19089577305765654 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 1.58 secondes

Val loss 1.4012825787067413 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 20/40
time = 44.89 secondes

Train loss 0.11779450446413124 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 1.55 secondes

Val loss 1.0541197881102562 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 21/40
time = 44.36 secondes

Train loss 0.3096776276105436 accuracy 0.9418604373931885 macro_avg {'precision': 0.9308755760368663, 'recall': 0.9544072948328268, 'f1-score': 0.9389859368102416, 'support': 516} weighted_avg {'precision': 0.9498981888329225, 'recall': 0.9418604651162791, 'f1-score': 0.9426304280553963, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2989709228277206 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 22/40
time = 44.08 secondes

Train loss 0.037103814627643616 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4808869734406471 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 23/40
time = 43.88 secondes

Train loss 0.10719815791217667 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.57 secondes

Val loss 1.588595598936081 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 45.78 secondes

Train loss 0.0005445388616697693 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.1775003522634506 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 25/40
time = 43.48 secondes

Train loss 0.03956041625122342 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.4926774203777313 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 26/40
time = 44.06 secondes

Train loss 0.039494372762750245 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.47 secondes

Val loss 0.9543888717889786 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 27/40
time = 44.02 secondes

Train loss 0.20654129833300514 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1127036213874817 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 28/40
time = 44.38 secondes

Train loss 0.08597790196566193 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.56 secondes

Val loss 0.9251856654882431 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 29/40
time = 43.94 secondes

Train loss 0.05596733741527494 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.55 secondes

Val loss 1.495246946811676 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 30/40
time = 44.32 secondes

Train loss 0.0015362289687442226 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2893417179584503 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 31/40
time = 43.91 secondes

Train loss 0.032513707035060645 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.55 secondes

Val loss 1.5993940383195877 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 32/40
time = 45.50 secondes

Train loss 0.0002029587110772616 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0544578731060028 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 43.52 secondes

Train loss 0.029213577178201045 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.55 secondes

Val loss 1.403256580233574 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 34/40
time = 44.14 secondes

Train loss 0.009672270263598131 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1019640415906906 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 35/40
time = 44.15 secondes

Train loss 0.06142923340093782 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.55 secondes

Val loss 1.8624211996793747 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 36/40
time = 44.10 secondes

Train loss 0.08137650245396688 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.55 secondes

Val loss 1.3643712997436523 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 43.92 secondes

Train loss 0.00014526665957722193 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.829428106546402 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 38/40
time = 45.52 secondes

Train loss 0.017648513299002043 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4478777945041656 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 39/40
time = 43.93 secondes

Train loss 7.32476613793e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.1653912216424942 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 40/40
time = 43.80 secondes

Train loss 6.468607578867567e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.56 secondes

Val loss 1.0635102614760399 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 26 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}

average train time 44.42560328841209

average val time 1.5440983295440673
 
time = 1.87 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.975, 'recall': 0.962962962962963, 'f1-score': 0.9679487179487178, 'support': 65} weighted_avg {'precision': 0.9707692307692308, 'recall': 0.9692307692307692, 'f1-score': 0.969033530571992, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 38.10 secondes

Train loss 0.6118795040881995 accuracy 0.6705426573753357 macro_avg {'precision': 0.8036640898019697, 'recall': 0.5466085854070836, 'f1-score': 0.4844730717694351, 'support': 516} weighted_avg {'precision': 0.7641175490314387, 'recall': 0.6705426356589147, 'f1-score': 0.5697049365188096, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5209976881742477 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 37.85 secondes

Train loss 0.48955667289820587 accuracy 0.7965116500854492 macro_avg {'precision': 0.781183155080214, 'recall': 0.7734912146676852, 'f1-score': 0.7768965645035764, 'support': 516} weighted_avg {'precision': 0.7944553693570452, 'recall': 0.7965116279069767, 'f1-score': 0.7951013945903923, 'support': 516}
 
time = 1.08 secondes

Val loss 0.595069408416748 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 3/40
time = 37.81 secondes

Train loss 0.30316798772775766 accuracy 0.8895348906517029 macro_avg {'precision': 0.880791788856305, 'recall': 0.8799067015587667, 'f1-score': 0.8803451488362822, 'support': 516} weighted_avg {'precision': 0.8894134518478103, 'recall': 0.8895348837209303, 'f1-score': 0.889470619840618, 'support': 516}
 
time = 1.19 secondes

Val loss 0.5372880846261978 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 4/40
time = 37.85 secondes

Train loss 0.20889812222484386 accuracy 0.9224806427955627 macro_avg {'precision': 0.9218768328445748, 'recall': 0.9092046876777791, 'f1-score': 0.914900634946813, 'support': 516} weighted_avg {'precision': 0.9223933256041282, 'recall': 0.9224806201550387, 'f1-score': 0.9218899719569951, 'support': 516}
 
time = 1.20 secondes

Val loss 0.4207959845662117 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 5/40
time = 37.82 secondes

Train loss 0.18637056183069944 accuracy 0.9302325248718262 macro_avg {'precision': 0.9262541229754344, 'recall': 0.9222079547486306, 'f1-score': 0.9241610190250674, 'support': 516} weighted_avg {'precision': 0.930020374930783, 'recall': 0.9302325581395349, 'f1-score': 0.9300662146021522, 'support': 516}
 
time = 1.21 secondes

Val loss 0.6602529734373093 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 6/40
time = 37.79 secondes

Train loss 0.14330859389156103 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.21 secondes

Val loss 1.461461827158928 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 7/40
time = 37.87 secondes

Train loss 0.18790496054641675 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4476582985371351 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 8/40
time = 37.69 secondes

Train loss 0.09559408770733033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9785882661079099, 'recall': 0.9752043951042699, 'f1-score': 0.9768544759838682, 'support': 516} weighted_avg {'precision': 0.9786783636060927, 'recall': 0.9786821705426356, 'f1-score': 0.9786443561724543, 'support': 516}
 
time = 1.26 secondes

Val loss 0.5406880658119917 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 9/40
time = 37.75 secondes

Train loss 0.1151893291142628 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4370921105146408 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 10/40
time = 37.75 secondes

Train loss 0.07336072456867744 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 1.21 secondes

Val loss 0.702195331454277 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 11/40
time = 37.78 secondes

Train loss 0.3720530061594521 accuracy 0.9224806427955627 macro_avg {'precision': 0.9147160692710431, 'recall': 0.9184370072980836, 'f1-score': 0.9165089073345956, 'support': 516} weighted_avg {'precision': 0.9229441754316953, 'recall': 0.9224806201550387, 'f1-score': 0.9226537132802691, 'support': 516}
 
time = 1.20 secondes

Val loss 0.8342920988798141 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 12/40
time = 37.75 secondes

Train loss 0.07604224078717049 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.20 secondes

Val loss 1.607848584651947 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 37.72 secondes

Train loss 0.06278472877756665 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.12 secondes

Val loss 1.1636684089899063 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 37.88 secondes

Train loss 0.0886974026860006 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0803441554307938 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 15/40
time = 37.73 secondes

Train loss 0.18989273916249108 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1421115472912788 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 16/40
time = 37.75 secondes

Train loss 0.134410434301103 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 1.20 secondes

Val loss 0.840247965825256 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 17/40
time = 37.81 secondes

Train loss 0.2334456879268118 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.15 secondes

Val loss 1.9791456758975983 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 18/40
time = 37.81 secondes

Train loss 0.3454848953829655 accuracy 0.9321705102920532 macro_avg {'precision': 0.9218514328808447, 'recall': 0.9364221510654552, 'f1-score': 0.9279418747082364, 'support': 516} weighted_avg {'precision': 0.9354191512621743, 'recall': 0.9321705426356589, 'f1-score': 0.9327456414737882, 'support': 516}
 
time = 1.21 secondes

Val loss 1.0730529874563217 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 37.80 secondes

Train loss 0.5731687560927998 accuracy 0.893410861492157 macro_avg {'precision': 0.8810267995296157, 'recall': 0.9002568145246493, 'f1-score': 0.887839829902265, 'support': 516} weighted_avg {'precision': 0.901010158075819, 'recall': 0.8934108527131783, 'f1-score': 0.8947188319818274, 'support': 516}
 
time = 1.20 secondes

Val loss 1.6587252020835876 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 20/40
time = 37.78 secondes

Train loss 0.01211984952290853 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.20 secondes

Val loss 1.930421382188797 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 21/40
time = 37.77 secondes

Train loss 0.045483751377270724 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.21 secondes

Val loss 1.6416117027401924 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 22/40
time = 37.76 secondes

Train loss 0.29783655986389157 accuracy 0.9476743936538696 macro_avg {'precision': 0.9601904164051056, 'recall': 0.9289615265835541, 'f1-score': 0.9415523121908653, 'support': 516} weighted_avg {'precision': 0.9509337930318529, 'recall': 0.9476744186046512, 'f1-score': 0.9467579356085755, 'support': 516}
 
time = 1.20 secondes

Val loss 1.1994608283857815 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 23/40
time = 37.74 secondes

Train loss 0.14321513218932191 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.13 secondes

Val loss 2.326024055480957 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 24/40
time = 37.84 secondes

Train loss 0.13996493708779753 accuracy 0.9689922332763672 macro_avg {'precision': 0.9723513824308785, 'recall': 0.9606813711945126, 'f1-score': 0.9660459301177864, 'support': 516} weighted_avg {'precision': 0.9694069560087888, 'recall': 0.9689922480620154, 'f1-score': 0.9687984113551584, 'support': 516}
 
time = 1.21 secondes

Val loss 1.151353769004345 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 25/40
time = 37.77 secondes

Train loss 0.07647180854110047 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 1.20 secondes

Val loss 1.5654735565185547 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 26/40
time = 37.81 secondes

Train loss 0.06018229337959466 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.54 secondes

Val loss 2.059539884328842 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 27/40
time = 37.69 secondes

Train loss 0.007575753189898519 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 1.2836417332291603 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 28/40
time = 37.66 secondes

Train loss 0.013093511755648775 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.21 secondes

Val loss 1.4585321545600891 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 37.74 secondes

Train loss 0.002264237272108651 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.11 secondes

Val loss 0.7938464358448982 accuracy 0.890625 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}
 
----------
Epoch 30/40
time = 37.75 secondes

Train loss 0.03174836540512677 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.20 secondes

Val loss 2.0029105246067047 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 31/40
time = 37.73 secondes

Train loss 0.0012360489841243675 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.2074059695005417 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 32/40
time = 37.75 secondes

Train loss 0.02636931425667805 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.21 secondes

Val loss 1.9673902988433838 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 33/40
time = 37.83 secondes

Train loss 0.007728801291677607 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.21 secondes

Val loss 1.282075360417366 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 34/40
time = 37.73 secondes

Train loss 0.07562345547392563 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.21 secondes

Val loss 1.3651388138532639 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 35/40
time = 37.86 secondes

Train loss 0.030789600984655517 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4954889714717865 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 37.92 secondes

Train loss 0.007754079878698879 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.22 secondes

Val loss 2.5611753165721893 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 37/40
time = 37.74 secondes

Train loss 0.028849033851160624 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4328311383724213 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 38/40
time = 37.83 secondes

Train loss 0.0003410180462665404 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4899351298809052 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 37.80 secondes

Train loss 9.842868486444014e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.20 secondes

Val loss 1.4465883821249008 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 40/40
time = 37.73 secondes

Train loss 9.114195045461229e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.23 secondes

Val loss 1.4567785859107971 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 29 macro_avg {'precision': 0.8852216748768473, 'recall': 0.895748987854251, 'f1-score': 0.8884184308841843, 'support': 64} weighted_avg {'precision': 0.8960283251231527, 'recall': 0.890625, 'f1-score': 0.8913605230386052, 'support': 64}

average train time 37.78849007487297

average val time 1.206836348772049
 
time = 1.33 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_1
----------
Epoch 1/40
time = 110.88 secondes

Train loss 0.6208415446859418 accuracy 0.6744186282157898 macro_avg {'precision': 0.6623230428108478, 'recall': 0.5773450579458088, 'f1-score': 0.558974358974359, 'support': 516} weighted_avg {'precision': 0.6667727054567667, 'recall': 0.6744186046511628, 'f1-score': 0.6210693699065791, 'support': 516}
 
time = 3.19 secondes

Val loss 0.574383407831192 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 2/40
time = 109.91 secondes

Train loss 0.3958620198748328 accuracy 0.8449612259864807 macro_avg {'precision': 0.8415011809990377, 'recall': 0.81725533540302, 'f1-score': 0.8265779391006252, 'support': 516} weighted_avg {'precision': 0.8440338017318607, 'recall': 0.8449612403100775, 'f1-score': 0.8421162055990907, 'support': 516}
 
time = 3.28 secondes

Val loss 0.4010474197566509 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 3/40
time = 109.93 secondes

Train loss 0.3053324529618928 accuracy 0.8759689927101135 macro_avg {'precision': 0.8691565421728913, 'recall': 0.8600360840661216, 'f1-score': 0.8641837204711456, 'support': 516} weighted_avg {'precision': 0.8751279490289051, 'recall': 0.875968992248062, 'f1-score': 0.8751936454206333, 'support': 516}
 
time = 3.27 secondes

Val loss 0.38428428024053574 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 4/40
time = 109.08 secondes

Train loss 0.2765027183023366 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 3.26 secondes

Val loss 0.7334373593330383 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 110.76 secondes

Train loss 0.22509805762180776 accuracy 0.9147287011146545 macro_avg {'precision': 0.9085000408263249, 'recall': 0.9065877801797702, 'f1-score': 0.9075268817204302, 'support': 516} weighted_avg {'precision': 0.9145580344624819, 'recall': 0.9147286821705426, 'f1-score': 0.9146286571642912, 'support': 516}
 
time = 3.25 secondes

Val loss 0.7033235356211662 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 6/40
time = 110.85 secondes

Train loss 0.15903478742323138 accuracy 0.9418604373931885 macro_avg {'precision': 0.944808641871282, 'recall': 0.9290184158769891, 'f1-score': 0.9360119047619048, 'support': 516} weighted_avg {'precision': 0.9423460471700442, 'recall': 0.9418604651162791, 'f1-score': 0.9413355943152454, 'support': 516}
 
time = 3.25 secondes

Val loss 0.49331944435834885 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 7/40
time = 110.33 secondes

Train loss 0.12874467689261743 accuracy 0.9651162624359131 macro_avg {'precision': 0.9632726381971095, 'recall': 0.9611039773743153, 'f1-score': 0.9621700879765396, 'support': 516} weighted_avg {'precision': 0.9650657683609275, 'recall': 0.9651162790697675, 'f1-score': 0.9650753597490282, 'support': 516}
 
time = 3.25 secondes

Val loss 0.8076917231082916 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 8/40
time = 108.78 secondes

Train loss 0.33719487134790554 accuracy 0.9031007885932922 macro_avg {'precision': 0.8929307452671938, 'recall': 0.8997773190514117, 'f1-score': 0.896093435360451, 'support': 516} weighted_avg {'precision': 0.9043922075654308, 'recall': 0.9031007751937985, 'f1-score': 0.9035191238405655, 'support': 516}
 
time = 3.32 secondes

Val loss 0.5185783058404922 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 9/40
time = 111.68 secondes

Train loss 0.11759842450335396 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 3.27 secondes

Val loss 1.3767000436782837 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 110.36 secondes

Train loss 0.14430443289915496 accuracy 0.9651162624359131 macro_avg {'precision': 0.9724383422323926, 'recall': 0.9530256977065488, 'f1-score': 0.9615072194685277, 'support': 516} weighted_avg {'precision': 0.9664628653985261, 'recall': 0.9651162790697675, 'f1-score': 0.9647508046797686, 'support': 516}
 
time = 3.27 secondes

Val loss 1.8720239400863647 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 11/40
time = 110.00 secondes

Train loss 0.12741439464452647 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 3.22 secondes

Val loss 0.9112781442236155 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 12/40
time = 109.55 secondes

Train loss 0.22378833774674797 accuracy 0.9515503644943237 macro_avg {'precision': 0.9511904761904761, 'recall': 0.9435414397867464, 'f1-score': 0.9471430620147098, 'support': 516} weighted_avg {'precision': 0.9515180878552972, 'recall': 0.9515503875968992, 'f1-score': 0.9513433320326352, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4541483521461487 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 13/40
time = 111.18 secondes

Train loss 0.08695977868399385 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 3.38 secondes

Val loss 1.3499275147914886 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 14/40
time = 109.51 secondes

Train loss 0.04540810167831792 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.28 secondes

Val loss 1.129255250096321 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 109.35 secondes

Train loss 0.10000095951854195 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 3.24 secondes

Val loss 1.1267386078834534 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 16/40
time = 109.07 secondes

Train loss 0.1841409852671804 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 3.25 secondes

Val loss 1.2525547221302986 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 17/40
time = 111.61 secondes

Train loss 0.14371543455865432 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 3.25 secondes

Val loss 1.8017287254333496 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 110.01 secondes

Train loss 0.026182726556505782 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 3.17 secondes

Val loss 2.1328561305999756 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 19/40
time = 109.64 secondes

Train loss 0.05814073682422256 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 3.28 secondes

Val loss 1.7090198695659637 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 20/40
time = 111.29 secondes

Train loss 0.3225959445028848 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 3.34 secondes

Val loss 1.4081890285015106 accuracy 0.8125 macro_avg {'precision': 0.8293650793650793, 'recall': 0.8360323886639676, 'f1-score': 0.8123167155425219, 'support': 64} weighted_avg {'precision': 0.8546626984126984, 'recall': 0.8125, 'f1-score': 0.8134164222873901, 'support': 64}
 
----------
Epoch 21/40
time = 109.58 secondes

Train loss 0.18450812213510895 accuracy 0.9670542478561401 macro_avg {'precision': 0.9620949074074074, 'recall': 0.9672398940233733, 'f1-score': 0.9645557140375051, 'support': 516} weighted_avg {'precision': 0.9674299723657767, 'recall': 0.9670542635658915, 'f1-score': 0.9671454515048837, 'support': 516}
 
time = 3.34 secondes

Val loss 1.443152278661728 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 22/40
time = 109.29 secondes

Train loss 0.1166973254073651 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 3.29 secondes

Val loss 1.3189547210931778 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 23/40
time = 110.10 secondes

Train loss 0.03705972561764418 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.70 secondes

Val loss 0.9670058307237923 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 24/40
time = 108.54 secondes

Train loss 0.025352893767624417 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 3.23 secondes

Val loss 1.124589666724205 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 25/40
time = 111.11 secondes

Train loss 0.003198813354670578 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.26 secondes

Val loss 2.3936354517936707 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 26/40
time = 110.60 secondes

Train loss 0.4131214476651759 accuracy 0.9321705102920532 macro_avg {'precision': 0.9477564102564102, 'recall': 0.9087251922045414, 'f1-score': 0.9235804626640205, 'support': 516} weighted_avg {'precision': 0.9369074239713775, 'recall': 0.9321705426356589, 'f1-score': 0.9306312797505676, 'support': 516}
 
time = 3.22 secondes

Val loss 1.064063373953104 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 27/40
time = 110.08 secondes

Train loss 0.051691933078638445 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 2.3253433406352997 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 28/40
time = 109.66 secondes

Train loss 0.07212349785241355 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 3.28 secondes

Val loss 1.338636502623558 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 29/40
time = 109.71 secondes

Train loss 0.01786365759581906 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.81 secondes

Val loss 2.1446223855018616 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 30/40
time = 110.43 secondes

Train loss 0.03289659313811695 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 3.14 secondes

Val loss 2.208230972290039 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 31/40
time = 109.60 secondes

Train loss 0.12458896116379148 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 3.41 secondes

Val loss 1.610340178012848 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 32/40
time = 110.46 secondes

Train loss 0.08795193974087438 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 3.23 secondes

Val loss 1.4975502341985703 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 33/40
time = 110.99 secondes

Train loss 0.011843261595596701 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.22 secondes

Val loss 1.7452628016471863 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 109.94 secondes

Train loss 0.05261105974116645 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 3.23 secondes

Val loss 1.709677278995514 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 35/40
time = 111.28 secondes

Train loss 0.00017651771265787608 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.22 secondes

Val loss 1.3155423551797867 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 36/40
time = 110.01 secondes

Train loss 0.08733464148870994 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 3.22 secondes

Val loss 1.668299823999405 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 37/40
time = 110.29 secondes

Train loss 0.0001407871130857419 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.26 secondes

Val loss 2.0013616383075714 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 38/40
time = 111.20 secondes

Train loss 0.05291752666292296 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 3.27 secondes

Val loss 2.1024787425994873 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 39/40
time = 109.91 secondes

Train loss 0.00010726286101006818 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.24 secondes

Val loss 1.9849089980125427 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 40/40
time = 110.32 secondes

Train loss 0.00011339108084829411 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.27 secondes

Val loss 1.9019729495048523 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 23 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 110.17144976854324

average val time 3.2268829464912416
 
time = 3.95 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9366471734892787, 'recall': 0.9366471734892787, 'f1-score': 0.9366471734892787, 'support': 65} weighted_avg {'precision': 0.9384615384615385, 'recall': 0.9384615384615385, 'f1-score': 0.9384615384615385, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 75.91 GiB already allocated; 15.62 MiB free; 77.17 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 74.19 GiB already allocated; 333.62 MiB free; 76.86 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 835.62 MiB free; 76.37 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_1
----------
Epoch 1/40
time = 34.11 secondes

Train loss 0.6567783157030741 accuracy 0.5968992114067078 macro_avg {'precision': 0.506608419822477, 'recall': 0.503860344911659, 'f1-score': 0.4783318751822689, 'support': 516} weighted_avg {'precision': 0.5432406892730166, 'recall': 0.5968992248062015, 'f1-score': 0.5467731908188479, 'support': 516}
 
time = 1.72 secondes

Val loss 0.6483345180749893 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 30.15 secondes

Train loss 0.4736546386371959 accuracy 0.7674418687820435 macro_avg {'precision': 0.7691305157326382, 'recall': 0.7114575036978041, 'f1-score': 0.7233491198284336, 'support': 516} weighted_avg {'precision': 0.768242408147497, 'recall': 0.7674418604651163, 'f1-score': 0.7537431449275062, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4845489114522934 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 3/40
time = 30.09 secondes

Train loss 0.4114030446067001 accuracy 0.8217054009437561 macro_avg {'precision': 0.8068540362118344, 'recall': 0.8082505729564553, 'f1-score': 0.8075376232485729, 'support': 516} weighted_avg {'precision': 0.8221359014332488, 'recall': 0.8217054263565892, 'f1-score': 0.8219078235438464, 'support': 516}
 
time = 1.51 secondes

Val loss 0.4701610952615738 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 4/40
time = 30.33 secondes

Train loss 0.23988865823908287 accuracy 0.9089147448539734 macro_avg {'precision': 0.9011092371562014, 'recall': 0.9020285096630528, 'f1-score': 0.9015646879756469, 'support': 516} weighted_avg {'precision': 0.90902623570397, 'recall': 0.9089147286821705, 'f1-score': 0.9089668566304437, 'support': 516}
 
time = 1.54 secondes

Val loss 0.5063801445066929 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 5/40
time = 30.12 secondes

Train loss 0.19853529572543321 accuracy 0.9341084957122803 macro_avg {'precision': 0.9374523264683448, 'recall': 0.9194772686637518, 'f1-score': 0.9272914145516635, 'support': 516} weighted_avg {'precision': 0.9347234787339092, 'recall': 0.9341085271317829, 'f1-score': 0.9334181866173404, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6985029019415379 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 6/40
time = 29.68 secondes

Train loss 0.13120987192219633 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.53 secondes

Val loss 0.89257001131773 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 7/40
time = 30.08 secondes

Train loss 0.25928406263913284 accuracy 0.9244186282157898 macro_avg {'precision': 0.912962962962963, 'recall': 0.9349592835199845, 'f1-score': 0.9206113134006872, 'support': 516} weighted_avg {'precision': 0.9323284524834912, 'recall': 0.9244186046511628, 'f1-score': 0.9253956970959751, 'support': 516}
 
time = 1.52 secondes

Val loss 1.392895758152008 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 8/40
time = 30.36 secondes

Train loss 0.16238292923310038 accuracy 0.9476743936538696 macro_avg {'precision': 0.9520348837209303, 'recall': 0.9347317263462445, 'f1-score': 0.9423361078114459, 'support': 516} weighted_avg {'precision': 0.9484349648458626, 'recall': 0.9476744186046512, 'f1-score': 0.9471643889110329, 'support': 516}
 
time = 1.16 secondes

Val loss 1.112002745270729 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 9/40
time = 29.99 secondes

Train loss 0.17208194819095574 accuracy 0.9515503644943237 macro_avg {'precision': 0.9523801608935576, 'recall': 0.9423873998342083, 'f1-score': 0.9470127949723769, 'support': 516} weighted_avg {'precision': 0.9516437370927733, 'recall': 0.9515503875968992, 'f1-score': 0.951279935056365, 'support': 516}
 
time = 1.54 secondes

Val loss 1.9113911390304565 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 10/40
time = 30.00 secondes

Train loss 0.12845719239681563 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.44 secondes

Val loss 1.2405556738376617 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 11/40
time = 30.26 secondes

Train loss 0.12190856214235254 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.56 secondes

Val loss 1.4983333051204681 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 12/40
time = 30.20 secondes

Train loss 0.3027792275860327 accuracy 0.9437984228134155 macro_avg {'precision': 0.9372106481481481, 'recall': 0.9420785722412757, 'f1-score': 0.9395362180639792, 'support': 516} weighted_avg {'precision': 0.9442975254809073, 'recall': 0.9437984496124031, 'f1-score': 0.943954005508331, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6353834420442581 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 13/40
time = 30.58 secondes

Train loss 0.13359660844787757 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 1.51 secondes

Val loss 1.317705549299717 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 14/40
time = 30.22 secondes

Train loss 0.35118401451803616 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6398965418338776 accuracy 0.75 macro_avg {'precision': 0.7658730158730158, 'recall': 0.771255060728745, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.7896825396825398, 'recall': 0.75, 'f1-score': 0.7512218963831867, 'support': 64}
 
----------
Epoch 15/40
time = 30.09 secondes

Train loss 0.2099811704432465 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0730313323438168 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 16/40
time = 29.83 secondes

Train loss 0.1772331207202197 accuracy 0.9496123790740967 macro_avg {'precision': 0.9395900755124056, 'recall': 0.9570242023308356, 'f1-score': 0.9466289005935427, 'support': 516} weighted_avg {'precision': 0.9535427276452338, 'recall': 0.9496124031007752, 'f1-score': 0.9501015018724527, 'support': 516}
 
time = 1.52 secondes

Val loss 0.8848967030644417 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 30.43 secondes

Train loss 0.12311049633894017 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.54 secondes

Val loss 1.6023304760456085 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 18/40
time = 30.37 secondes

Train loss 0.1917411569946015 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6791450828313828 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 19/40
time = 30.56 secondes

Train loss 0.12897297652649065 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.25 secondes

Val loss 2.6572521924972534 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 20/40
time = 30.00 secondes

Train loss 0.060254706360865384 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5116469860076904 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 21/40
time = 30.25 secondes

Train loss 0.06364064671145046 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.53 secondes

Val loss 2.110848158597946 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 30.22 secondes

Train loss 0.12491783101281864 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.52 secondes

Val loss 1.531773641705513 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 23/40
time = 30.21 secondes

Train loss 0.012602947508143685 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 2.040704756975174 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 30.00 secondes

Train loss 0.05516036900812513 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.53 secondes

Val loss 1.7398687303066254 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 25/40
time = 29.99 secondes

Train loss 0.06968361505344299 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4831435531377792 accuracy 0.65625 macro_avg {'precision': 0.6916666666666667, 'recall': 0.6862348178137652, 'f1-score': 0.6559139784946237, 'support': 64} weighted_avg {'precision': 0.7182291666666667, 'recall': 0.65625, 'f1-score': 0.6538978494623656, 'support': 64}
 
----------
Epoch 26/40
time = 30.16 secondes

Train loss 0.26840145522785885 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 1.51 secondes

Val loss 2.416386902332306 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 27/40
time = 30.61 secondes

Train loss 0.1729861014719063 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.53 secondes

Val loss 1.3513858765363693 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 28/40
time = 30.34 secondes

Train loss 0.09652199355729284 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.52 secondes

Val loss 1.4449278712272644 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 29/40
time = 30.13 secondes

Train loss 0.06417314555338552 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6720838844776154 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 30/40
time = 30.15 secondes

Train loss 0.027461881629609376 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.54 secondes

Val loss 1.1987587958574295 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 31/40
time = 30.22 secondes

Train loss 0.019796533098115382 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.50 secondes

Val loss 1.758107453584671 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 32/40
time = 30.60 secondes

Train loss 0.0010739933647776277 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.749803751707077 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 33/40
time = 30.48 secondes

Train loss 0.0030313041213296606 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.52 secondes

Val loss 1.9742971658706665 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 34/40
time = 30.12 secondes

Train loss 0.04233543748920387 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6585697829723358 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 30.02 secondes

Train loss 0.03061917360294804 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9593395292758942 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 36/40
time = 30.42 secondes

Train loss 0.00010399735522999738 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5130765438079834 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 37/40
time = 29.91 secondes

Train loss 0.025205528952056105 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 1.288802832365036 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 38/40
time = 30.42 secondes

Train loss 0.0004712519331598852 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.54 secondes

Val loss 1.5494403094053268 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 39/40
time = 29.81 secondes

Train loss 0.011907795049685801 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5029142796993256 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 40/40
time = 29.96 secondes

Train loss 6.596711186416955e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.487855225801468 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 16 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 30.286575692892075

average val time 1.5072179853916168
 
time = 1.77 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_1
----------
Epoch 1/40
time = 42.42 secondes

Train loss 0.6250356182907567 accuracy 0.6705426573753357 macro_avg {'precision': 0.6828752642706131, 'recall': 0.5604570648375404, 'f1-score': 0.5244497452022119, 'support': 516} weighted_avg {'precision': 0.6788026287755872, 'recall': 0.6705426356589147, 'f1-score': 0.5969853761282671, 'support': 516}
 
time = 1.89 secondes

Val loss 0.6419084966182709 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 2/40
time = 39.83 secondes

Train loss 0.42234978328148526 accuracy 0.815891444683075 macro_avg {'precision': 0.8018849206349206, 'recall': 0.7967670627245096, 'f1-score': 0.7991436356558972, 'support': 516} weighted_avg {'precision': 0.8146344745908699, 'recall': 0.8158914728682171, 'f1-score': 0.8151046617240141, 'support': 516}
 
time = 1.70 secondes

Val loss 0.5241179391741753 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 3/40
time = 39.82 secondes

Train loss 0.23846285417675972 accuracy 0.9050387740135193 macro_avg {'precision': 0.897605083088954, 'recall': 0.8966809160801652, 'f1-score': 0.8971388121575057, 'support': 516} weighted_avg {'precision': 0.9049355141815757, 'recall': 0.9050387596899225, 'f1-score': 0.9049835153015839, 'support': 516}
 
time = 1.70 secondes

Val loss 0.6524151861667633 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 4/40
time = 40.28 secondes

Train loss 0.2745478278533979 accuracy 0.9069767594337463 macro_avg {'precision': 0.9153321706040907, 'recall': 0.883198153536076, 'f1-score': 0.8956504154097642, 'support': 516} weighted_avg {'precision': 0.9093398950921601, 'recall': 0.9069767441860465, 'f1-score': 0.9051112312111295, 'support': 516}
 
time = 1.73 secondes

Val loss 1.2008797079324722 accuracy 0.703125 macro_avg {'precision': 0.7232232232232232, 'recall': 0.7257085020242915, 'f1-score': 0.703052503052503, 'support': 64} weighted_avg {'precision': 0.7473410910910911, 'recall': 0.703125, 'f1-score': 0.7039224664224664, 'support': 64}
 
----------
Epoch 5/40
time = 40.08 secondes

Train loss 0.28934638497109216 accuracy 0.8798449635505676 macro_avg {'precision': 0.8689971808296415, 'recall': 0.8723079173642379, 'f1-score': 0.8705888063686229, 'support': 516} weighted_avg {'precision': 0.880492589921544, 'recall': 0.8798449612403101, 'f1-score': 0.8801132555844169, 'support': 516}
 
time = 1.70 secondes

Val loss 0.7955436855554581 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 39.92 secondes

Train loss 0.2750699918233846 accuracy 0.9418604373931885 macro_avg {'precision': 0.9309719704364803, 'recall': 0.9520992149277505, 'f1-score': 0.9387658227848101, 'support': 516} weighted_avg {'precision': 0.9481515953757185, 'recall': 0.9418604651162791, 'f1-score': 0.9425540918457462, 'support': 516}
 
time = 1.73 secondes

Val loss 1.878673255443573 accuracy 0.6875 macro_avg {'precision': 0.7678571428571428, 'recall': 0.6214574898785425, 'f1-score': 0.5994993742177722, 'support': 64} weighted_avg {'precision': 0.7477678571428572, 'recall': 0.6875, 'f1-score': 0.6346996245306633, 'support': 64}
 
----------
Epoch 7/40
time = 39.94 secondes

Train loss 0.28978963807193475 accuracy 0.9186046719551086 macro_avg {'precision': 0.9366415676313163, 'recall': 0.8911626546169725, 'f1-score': 0.9076104564909707, 'support': 516} weighted_avg {'precision': 0.9246731464232292, 'recall': 0.9186046511627907, 'f1-score': 0.9163811061729844, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1333815194666386 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 8/40
time = 39.81 secondes

Train loss 0.21337093538463567 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.72 secondes

Val loss 1.1721819788217545 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 9/40
time = 39.85 secondes

Train loss 0.0754368415981651 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.76 secondes

Val loss 2.0241373777389526 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 39.76 secondes

Train loss 0.08350599995262173 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.70 secondes

Val loss 2.0022046864032745 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 11/40
time = 39.74 secondes

Train loss 0.6093260882449668 accuracy 0.8798449635505676 macro_avg {'precision': 0.8726522222038029, 'recall': 0.8653836776490094, 'f1-score': 0.8687539999015408, 'support': 516} weighted_avg {'precision': 0.8791165826037017, 'recall': 0.8798449612403101, 'f1-score': 0.8792534433022423, 'support': 516}
 
time = 1.70 secondes

Val loss 2.404471606016159 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 12/40
time = 39.98 secondes

Train loss 0.3092179125083159 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.70 secondes

Val loss 1.633028268814087 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 13/40
time = 40.14 secondes

Train loss 0.13167497588526175 accuracy 0.9573643207550049 macro_avg {'precision': 0.9521224325412807, 'recall': 0.9561789899712303, 'f1-score': 0.9540798990340276, 'support': 516} weighted_avg {'precision': 0.9576772908490916, 'recall': 0.9573643410852714, 'f1-score': 0.957459542304148, 'support': 516}
 
time = 1.75 secondes

Val loss 1.672478049993515 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 14/40
time = 39.49 secondes

Train loss 0.4766141516663607 accuracy 0.9263566136360168 macro_avg {'precision': 0.9438772754280775, 'recall': 0.9007038018302098, 'f1-score': 0.9166609996599795, 'support': 516} weighted_avg {'precision': 0.9320299542286858, 'recall': 0.9263565891472868, 'f1-score': 0.9244835775417842, 'support': 516}
 
time = 1.69 secondes

Val loss 2.2375268042087555 accuracy 0.703125 macro_avg {'precision': 0.7808080808080808, 'recall': 0.6406882591093117, 'f1-score': 0.6264208909370199, 'support': 64} weighted_avg {'precision': 0.7605429292929293, 'recall': 0.703125, 'f1-score': 0.6581605222734255, 'support': 64}
 
----------
Epoch 15/40
time = 40.06 secondes

Train loss 0.05417639433069395 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.70 secondes

Val loss 2.018381655216217 accuracy 0.65625 macro_avg {'precision': 0.735632183908046, 'recall': 0.5829959514170041, 'f1-score': 0.5416666666666667, 'support': 64} weighted_avg {'precision': 0.7173132183908046, 'recall': 0.65625, 'f1-score': 0.5846354166666667, 'support': 64}
 
----------
Epoch 16/40
time = 40.26 secondes

Train loss 0.22395754638493987 accuracy 0.9670542478561401 macro_avg {'precision': 0.9613081897931741, 'recall': 0.9683939339759114, 'f1-score': 0.96463345307643, 'support': 516} weighted_avg {'precision': 0.9676827403847825, 'recall': 0.9670542635658915, 'f1-score': 0.9671797870727524, 'support': 516}
 
time = 1.74 secondes

Val loss 1.5666281580924988 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 17/40
time = 39.89 secondes

Train loss 0.11491544869810848 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.70 secondes

Val loss 1.9758648425340652 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 18/40
time = 40.18 secondes

Train loss 0.08700183632985996 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.70 secondes

Val loss 2.046614795923233 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 19/40
time = 39.76 secondes

Train loss 0.1932369931115924 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.71 secondes

Val loss 3.070172905921936 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 20/40
time = 39.60 secondes

Train loss 0.0617340229288278 accuracy 0.9844961166381836 macro_avg {'precision': 0.982185330809184, 'recall': 0.9843798254311396, 'f1-score': 0.9832641411520499, 'support': 516} weighted_avg {'precision': 0.9845631035446839, 'recall': 0.9844961240310077, 'f1-score': 0.9845137237864214, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9089334458112717 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 21/40
time = 39.93 secondes

Train loss 0.15142547276197796 accuracy 0.9670542478561401 macro_avg {'precision': 0.9723230490018149, 'recall': 0.9568535344505307, 'f1-score': 0.963786633420165, 'support': 516} weighted_avg {'precision': 0.9678696708357368, 'recall': 0.9670542635658915, 'f1-score': 0.9667802042633468, 'support': 516}
 
time = 1.68 secondes

Val loss 2.0300595462322235 accuracy 0.734375 macro_avg {'precision': 0.7292358803986712, 'recall': 0.7095141700404858, 'f1-score': 0.7142106645652745, 'support': 64} weighted_avg {'precision': 0.7320390365448506, 'recall': 0.734375, 'f1-score': 0.7284443131074336, 'support': 64}
 
----------
Epoch 22/40
time = 40.49 secondes

Train loss 0.025180068211105237 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.48 secondes

Val loss 2.083932340145111 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 23/40
time = 40.11 secondes

Train loss 0.10263278931729887 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.73 secondes

Val loss 2.140805721282959 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 24/40
time = 40.12 secondes

Train loss 0.09598735824847333 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.71 secondes

Val loss 1.9200657904148102 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 25/40
time = 39.90 secondes

Train loss 0.03630040398605739 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.71 secondes

Val loss 2.409125506877899 accuracy 0.6875 macro_avg {'precision': 0.7115384615384616, 'recall': 0.6336032388663968, 'f1-score': 0.6257309941520468, 'support': 64} weighted_avg {'precision': 0.7043269230769231, 'recall': 0.6875, 'f1-score': 0.6542397660818713, 'support': 64}
 
----------
Epoch 26/40
time = 40.28 secondes

Train loss 0.11398647684109164 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.70 secondes

Val loss 1.6969991028308868 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 27/40
time = 39.74 secondes

Train loss 0.03631438125398056 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.66 secondes

Val loss 2.0768578946590424 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 28/40
time = 40.67 secondes

Train loss 0.021378272981427002 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.70 secondes

Val loss 1.80338816344738 accuracy 0.734375 macro_avg {'precision': 0.7552552552552552, 'recall': 0.7580971659919028, 'f1-score': 0.7343101343101344, 'support': 64} weighted_avg {'precision': 0.7803115615615616, 'recall': 0.734375, 'f1-score': 0.7350885225885226, 'support': 64}
 
----------
Epoch 29/40
time = 42.45 secondes

Train loss 0.1305558308681198 accuracy 0.9593023061752319 macro_avg {'precision': 0.9502262443438914, 'recall': 0.9657770264779025, 'f1-score': 0.9567651248249418, 'support': 516} weighted_avg {'precision': 0.9621596104154244, 'recall': 0.9593023255813954, 'f1-score': 0.9596473848842729, 'support': 516}
 
time = 1.80 secondes

Val loss 2.1289318799972534 accuracy 0.71875 macro_avg {'precision': 0.7198067632850241, 'recall': 0.6842105263157895, 'f1-score': 0.6883116883116883, 'support': 64} weighted_avg {'precision': 0.7193538647342995, 'recall': 0.71875, 'f1-score': 0.7065746753246753, 'support': 64}
 
----------
Epoch 30/40
time = 44.53 secondes

Train loss 0.03969892109528177 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.48625186085701 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 31/40
time = 44.24 secondes

Train loss 0.04418978331175987 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.05 secondes

Val loss 3.244371175765991 accuracy 0.671875 macro_avg {'precision': 0.7161616161616162, 'recall': 0.6082995951417004, 'f1-score': 0.5870967741935483, 'support': 64} weighted_avg {'precision': 0.7046085858585858, 'recall': 0.671875, 'f1-score': 0.6221774193548386, 'support': 64}
 
----------
Epoch 32/40
time = 47.47 secondes

Train loss 0.16101114878675257 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.06 secondes

Val loss 2.9142743349075317 accuracy 0.703125 macro_avg {'precision': 0.7040050062578223, 'recall': 0.6649797570850202, 'f1-score': 0.6673050615595076, 'support': 64} weighted_avg {'precision': 0.7036530037546934, 'recall': 0.703125, 'f1-score': 0.6877735978112176, 'support': 64}
 
----------
Epoch 33/40
time = 47.88 secondes

Train loss 2.1954282078006532e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9673337638378143 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 34/40
time = 46.76 secondes

Train loss 0.03560937149769884 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.08 secondes

Val loss 1.7495750486850739 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 35/40
time = 47.76 secondes

Train loss 0.006746183475942499 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.98 secondes

Val loss 2.435919463634491 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 36/40
time = 48.03 secondes

Train loss 3.4828258514718264e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9676964730024338 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 37/40
time = 45.91 secondes

Train loss 0.016310500819958124 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.06 secondes

Val loss 2.0135097205638885 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 38/40
time = 47.30 secondes

Train loss 0.00013055886004374108 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 2.496764689683914 accuracy 0.71875 macro_avg {'precision': 0.7136363636363636, 'recall': 0.6902834008097165, 'f1-score': 0.6945917285259808, 'support': 64} weighted_avg {'precision': 0.7161931818181818, 'recall': 0.71875, 'f1-score': 0.7106972428419936, 'support': 64}
 
----------
Epoch 39/40
time = 47.50 secondes

Train loss 3.786359433654456e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.07 secondes

Val loss 2.6430184841156006 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 40/40
time = 46.40 secondes

Train loss 4.828717950052427e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 2.6777721643447876 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 3 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}

average train time 41.95685896277428

average val time 1.7974827766418457
 
time = 2.38 secondes

test_accuracy 0.9230769276618958 macro_avg {'precision': 0.9303861788617886, 'recall': 0.9127680311890838, 'f1-score': 0.9193348225366097, 'support': 65} weighted_avg {'precision': 0.9256566604127581, 'recall': 0.9230769230769231, 'f1-score': 0.9222750443897131, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_1
----------
Epoch 1/40
time = 61.82 secondes

Train loss 0.6339394504373724 accuracy 0.6782945990562439 macro_avg {'precision': 0.7138382541720154, 'recall': 0.5676901321457016, 'f1-score': 0.5327310814349306, 'support': 516} weighted_avg {'precision': 0.7022087550128867, 'recall': 0.6782945736434108, 'f1-score': 0.6045019699543897, 'support': 516}
 
time = 2.62 secondes

Val loss 0.4559163898229599 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 58.22 secondes

Train loss 0.4738170120752219 accuracy 0.786821722984314 macro_avg {'precision': 0.7700048074532102, 'recall': 0.7647383905206182, 'f1-score': 0.7671441933737015, 'support': 516} weighted_avg {'precision': 0.7851187284164176, 'recall': 0.7868217054263565, 'f1-score': 0.7857722381168817, 'support': 516}
 
time = 2.35 secondes

Val loss 0.38838502764701843 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 58.31 secondes

Train loss 0.3877472387570323 accuracy 0.8527131676673889 macro_avg {'precision': 0.8473997563612031, 'recall': 0.8291045625213335, 'f1-score': 0.8366081695915204, 'support': 516} weighted_avg {'precision': 0.8515453932542725, 'recall': 0.8527131782945736, 'f1-score': 0.8507249056151844, 'support': 516}
 
time = 2.36 secondes

Val loss 0.3989737406373024 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 58.86 secondes

Train loss 0.26272348845095345 accuracy 0.9069767594337463 macro_avg {'precision': 0.8986942381437795, 'recall': 0.9005087528241471, 'f1-score': 0.8995848469122989, 'support': 516} weighted_avg {'precision': 0.9072168168249528, 'recall': 0.9069767441860465, 'f1-score': 0.9070823427185286, 'support': 516}
 
time = 2.38 secondes

Val loss 0.4658821187913418 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 58.26 secondes

Train loss 0.23204717748431544 accuracy 0.9166666865348816 macro_avg {'precision': 0.9184121047262837, 'recall': 0.9000292573509094, 'f1-score': 0.9079240585122939, 'support': 516} weighted_avg {'precision': 0.9170038535645473, 'recall': 0.9166666666666666, 'f1-score': 0.915731922398589, 'support': 516}
 
time = 2.45 secondes

Val loss 0.4648912623524666 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 6/40
time = 59.51 secondes

Train loss 0.18294251295314592 accuracy 0.9437984228134155 macro_avg {'precision': 0.9396383186705768, 'recall': 0.9386164523836614, 'f1-score': 0.9391229704605646, 'support': 516} weighted_avg {'precision': 0.9437406700159889, 'recall': 0.9437984496124031, 'f1-score': 0.9437657539539986, 'support': 516}
 
time = 2.45 secondes

Val loss 0.5831400752067566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 7/40
time = 58.56 secondes

Train loss 0.11872421393601337 accuracy 0.963178277015686 macro_avg {'precision': 0.9639880952380953, 'recall': 0.9561221006777954, 'f1-score': 0.9598287271311794, 'support': 516} weighted_avg {'precision': 0.9632509689922482, 'recall': 0.9631782945736435, 'f1-score': 0.9630209323448028, 'support': 516}
 
time = 2.36 secondes

Val loss 0.7752330601215363 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 8/40
time = 58.48 secondes

Train loss 0.1414358509566889 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 2.45 secondes

Val loss 1.2355355620384216 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 9/40
time = 59.07 secondes

Train loss 0.33448161012986954 accuracy 0.9127907156944275 macro_avg {'precision': 0.9153325123152709, 'recall': 0.8946816637680217, 'f1-score': 0.9033848586348223, 'support': 516} weighted_avg {'precision': 0.9133273029874875, 'recall': 0.9127906976744186, 'f1-score': 0.9116806918250254, 'support': 516}
 
time = 2.40 secondes

Val loss 0.9954286515712738 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.31 secondes

Train loss 0.1268364178778773 accuracy 0.9689922332763672 macro_avg {'precision': 0.9630002396357537, 'recall': 0.9710677307673553, 'f1-score': 0.9667498993153444, 'support': 516} weighted_avg {'precision': 0.9697531380209059, 'recall': 0.9689922480620154, 'f1-score': 0.9691261196289811, 'support': 516}
 
time = 2.40 secondes

Val loss 1.954167127609253 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 58.91 secondes

Train loss 0.36159477563694853 accuracy 0.9360464811325073 macro_avg {'precision': 0.9484901685393259, 'recall': 0.9152268257399672, 'f1-score': 0.928361976482467, 'support': 516} weighted_avg {'precision': 0.9394748660830938, 'recall': 0.936046511627907, 'f1-score': 0.9348188048295232, 'support': 516}
 
time = 2.48 secondes

Val loss 1.4643760919570923 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 58.41 secondes

Train loss 0.21275364523965187 accuracy 0.9437984228134155 macro_avg {'precision': 0.9387649195640893, 'recall': 0.9397704923361995, 'f1-score': 0.9392633181126333, 'support': 516} weighted_avg {'precision': 0.9438703571845218, 'recall': 0.9437984496124031, 'f1-score': 0.943830613665593, 'support': 516}
 
time = 2.41 secondes

Val loss 1.2357655763626099 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 13/40
time = 58.06 secondes

Train loss 0.1287964549688199 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 2.42 secondes

Val loss 1.1264150738716125 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 14/40
time = 58.88 secondes

Train loss 0.10440204414286806 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 2.41 secondes

Val loss 1.4035854237154126 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 15/40
time = 58.88 secondes

Train loss 0.48789847710445017 accuracy 0.9108527302742004 macro_avg {'precision': 0.8991163131399716, 'recall': 0.9162427059798774, 'f1-score': 0.9057556699066133, 'support': 516} weighted_avg {'precision': 0.9161221172771334, 'recall': 0.9108527131782945, 'f1-score': 0.9117871711114361, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3586439620703459 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 16/40
time = 58.00 secondes

Train loss 0.0835169197272273 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.26 secondes

Val loss 1.465189978480339 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 17/40
time = 58.59 secondes

Train loss 0.20039999671897737 accuracy 0.9515503644943237 macro_avg {'precision': 0.9490243583027763, 'recall': 0.9458495196918226, 'f1-score': 0.9473965363269734, 'support': 516} weighted_avg {'precision': 0.9514479810038943, 'recall': 0.9515503875968992, 'f1-score': 0.9514644458464872, 'support': 516}
 
time = 2.42 secondes

Val loss 1.5267489701509476 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 59.03 secondes

Train loss 0.15735966191101453 accuracy 0.9689922332763672 macro_avg {'precision': 0.9737578550481776, 'recall': 0.9595273312419745, 'f1-score': 0.9659602539787252, 'support': 516} weighted_avg {'precision': 0.9696812514817016, 'recall': 0.9689922480620154, 'f1-score': 0.968755988782798, 'support': 516}
 
time = 2.16 secondes

Val loss 1.1849833708256483 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 19/40
time = 58.74 secondes

Train loss 0.16154145083507473 accuracy 0.9689922332763672 macro_avg {'precision': 0.9697699348561062, 'recall': 0.9629894510995888, 'f1-score': 0.966212676794133, 'support': 516} weighted_avg {'precision': 0.9690528470329837, 'recall': 0.9689922480620154, 'f1-score': 0.9688795627403446, 'support': 516}
 
time = 2.42 secondes

Val loss 1.720089614391327 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 20/40
time = 58.46 secondes

Train loss 0.004716151664483318 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.42 secondes

Val loss 2.0340465307235718 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 21/40
time = 58.66 secondes

Train loss 0.2387493375894282 accuracy 0.9534883499145508 macro_avg {'precision': 0.9593185863208746, 'recall': 0.9404450368155, 'f1-score': 0.9486762926247037, 'support': 516} weighted_avg {'precision': 0.9545605953992947, 'recall': 0.9534883720930233, 'f1-score': 0.953001072906358, 'support': 516}
 
time = 2.41 secondes

Val loss 1.6022708751261234 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 22/40
time = 58.13 secondes

Train loss 0.05865256421163918 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.14 secondes

Val loss 1.5636188238859177 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 23/40
time = 58.35 secondes

Train loss 0.07743679428963471 accuracy 0.9767441749572754 macro_avg {'precision': 0.9795766125690035, 'recall': 0.97022251840775, 'f1-score': 0.9745975483680402, 'support': 516} weighted_avg {'precision': 0.9770310140487893, 'recall': 0.9767441860465116, 'f1-score': 0.9766296987036599, 'support': 516}
 
time = 2.38 secondes

Val loss 1.8072308003902435 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 24/40
time = 58.15 secondes

Train loss 0.02226735371346656 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.2751631364226341 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 25/40
time = 58.87 secondes

Train loss 0.12391318097202615 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2276369780302048 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 26/40
time = 59.12 secondes

Train loss 0.32974892150455026 accuracy 0.9496123790740967 macro_avg {'precision': 0.9521407624633431, 'recall': 0.9385595630902264, 'f1-score': 0.9446854127154284, 'support': 516} weighted_avg {'precision': 0.9499779490327127, 'recall': 0.9496124031007752, 'f1-score': 0.9492284817720469, 'support': 516}
 
time = 2.35 secondes

Val loss 1.8140016496181488 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 27/40
time = 57.89 secondes

Train loss 0.1245776131483691 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3423852026462555 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 28/40
time = 59.42 secondes

Train loss 0.048813668804624205 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.25 secondes

Val loss 1.7185466327355243 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 29/40
time = 58.82 secondes

Train loss 0.12386098914584816 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.41 secondes

Val loss 1.7375836186110973 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 30/40
time = 57.85 secondes

Train loss 0.28565631554837717 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 2.42 secondes

Val loss 1.2771421447396278 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 59.25 secondes

Train loss 0.03930170394530499 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.38 secondes

Val loss 1.3815643042325974 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 32/40
time = 58.58 secondes

Train loss 0.04664655021770159 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.36 secondes

Val loss 1.896320316940546 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 33/40
time = 58.45 secondes

Train loss 0.05259972890042153 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.42 secondes

Val loss 1.584839090704918 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 34/40
time = 58.90 secondes

Train loss 0.0065927045802571665 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.40 secondes

Val loss 1.713086411356926 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 35/40
time = 58.26 secondes

Train loss 6.341708991165046e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.37 secondes

Val loss 1.5881700813770294 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 36/40
time = 59.00 secondes

Train loss 0.03260832701617443 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6551595330238342 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 37/40
time = 58.72 secondes

Train loss 4.282978018939806e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.42 secondes

Val loss 1.847426414489746 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 38/40
time = 58.59 secondes

Train loss 0.001748274674327783 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.44 secondes

Val loss 1.9580502212047577 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 39/40
time = 58.92 secondes

Train loss 2.799836141948066e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.43 secondes

Val loss 1.7082684509950923 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 40/40
time = 58.69 secondes

Train loss 2.625838103333742e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.23 secondes

Val loss 1.714829411037499 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 5 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 58.70047608613968

average val time 2.3862047672271727
 
time = 2.68 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9049707602339181, 'recall': 0.9049707602339181, 'f1-score': 0.9049707602339181, 'support': 65} weighted_avg {'precision': 0.9076923076923077, 'recall': 0.9076923076923077, 'f1-score': 0.9076923076923077, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_1
----------
Epoch 1/40
time = 106.88 secondes

Train loss 0.6526508042306611 accuracy 0.6279069781303406 macro_avg {'precision': 0.4541854185418542, 'recall': 0.4958633356630853, 'f1-score': 0.40004360148245044, 'support': 516} weighted_avg {'precision': 0.5041215749481925, 'recall': 0.627906976744186, 'f1-score': 0.5017939137062444, 'support': 516}
 
time = 3.11 secondes

Val loss 0.6721367835998535 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 106.89 secondes

Train loss 0.43885405948667816 accuracy 0.8062015771865845 macro_avg {'precision': 0.8098145330585675, 'recall': 0.7614713196690668, 'f1-score': 0.7750575434191254, 'support': 516} weighted_avg {'precision': 0.8076945184334525, 'recall': 0.8062015503875969, 'f1-score': 0.7980911319062242, 'support': 516}
 
time = 2.88 secondes

Val loss 0.4404994025826454 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 3/40
time = 106.60 secondes

Train loss 0.40031165674780356 accuracy 0.8217054009437561 macro_avg {'precision': 0.8062950527505053, 'recall': 0.8128667327666076, 'f1-score': 0.8092206790123456, 'support': 516} weighted_avg {'precision': 0.8242317171116847, 'recall': 0.8217054263565892, 'f1-score': 0.8226512405493349, 'support': 516}
 
time = 2.92 secondes

Val loss 0.391114741563797 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 4/40
time = 105.75 secondes

Train loss 0.28435496082811645 accuracy 0.8798449635505676 macro_avg {'precision': 0.8699998374591615, 'recall': 0.8699998374591615, 'f1-score': 0.8699998374591615, 'support': 516} weighted_avg {'precision': 0.8798449612403101, 'recall': 0.8798449612403101, 'f1-score': 0.8798449612403101, 'support': 516}
 
time = 2.95 secondes

Val loss 0.4086569473147392 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 5/40
time = 106.16 secondes

Train loss 0.20852691790258343 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 2.94 secondes

Val loss 0.5047884732484818 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 6/40
time = 106.52 secondes

Train loss 0.16236198668819712 accuracy 0.9476743936538696 macro_avg {'precision': 0.949331550802139, 'recall': 0.9370398062513207, 'f1-score': 0.9426305451580625, 'support': 516} weighted_avg {'precision': 0.9478967168262654, 'recall': 0.9476744186046512, 'f1-score': 0.9473117871803867, 'support': 516}
 
time = 2.58 secondes

Val loss 0.8151003122329712 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 105.54 secondes

Train loss 0.08078327928458086 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 2.92 secondes

Val loss 0.6999615952372551 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 8/40
time = 106.53 secondes

Train loss 0.11735291272458254 accuracy 0.9709302186965942 macro_avg {'precision': 0.9725198412698413, 'recall': 0.9645092079384945, 'f1-score': 0.9682858372088259, 'support': 516} weighted_avg {'precision': 0.9710728897502153, 'recall': 0.9709302325581395, 'f1-score': 0.9708059992195812, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2831183820962906 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 9/40
time = 106.23 secondes

Train loss 0.0728111248145896 accuracy 0.9864341020584106 macro_avg {'precision': 0.9870350969093766, 'recall': 0.9835915023649693, 'f1-score': 0.9852710301715525, 'support': 516} weighted_avg {'precision': 0.9864584729210066, 'recall': 0.9864341085271318, 'f1-score': 0.9864100448370163, 'support': 516}
 
time = 2.91 secondes

Val loss 0.9561516046524048 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 10/40
time = 105.93 secondes

Train loss 0.2727364226893494 accuracy 0.9379844665527344 macro_avg {'precision': 0.9270919120503458, 'recall': 0.9467516213448629, 'f1-score': 0.9345624019149374, 'support': 516} weighted_avg {'precision': 0.943546666714849, 'recall': 0.937984496124031, 'f1-score': 0.9386805152852027, 'support': 516}
 
time = 2.96 secondes

Val loss 1.4376361966133118 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 106.26 secondes

Train loss 0.12369245507447472 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 2.72 secondes

Val loss 1.1686341911554337 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 12/40
time = 106.88 secondes

Train loss 0.2239398792400166 accuracy 0.9573643207550049 macro_avg {'precision': 0.9570050300981281, 'recall': 0.9504087902085399, 'f1-score': 0.953542430591933, 'support': 516} weighted_avg {'precision': 0.9573363428265328, 'recall': 0.9573643410852714, 'f1-score': 0.9572093987679738, 'support': 516}
 
time = 2.86 secondes

Val loss 1.1280450572958216 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 13/40
time = 106.33 secondes

Train loss 0.3481568852316052 accuracy 0.9263566136360168 macro_avg {'precision': 0.9149700229644129, 'recall': 0.9376330803114283, 'f1-score': 0.9227155199596393, 'support': 516} weighted_avg {'precision': 0.9346882229396336, 'recall': 0.9263565891472868, 'f1-score': 0.9273318755368353, 'support': 516}
 
time = 2.95 secondes

Val loss 1.4471633285284042 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 106.67 secondes

Train loss 0.48193736072007043 accuracy 0.9050387740135193 macro_avg {'precision': 0.8969252724442138, 'recall': 0.8978349560327032, 'f1-score': 0.8973759512937596, 'support': 516} weighted_avg {'precision': 0.9051546666505755, 'recall': 0.9050387596899225, 'f1-score': 0.9050931058487606, 'support': 516}
 
time = 2.98 secondes

Val loss 0.9556056782603264 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 15/40
time = 107.11 secondes

Train loss 0.10950636746587628 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 2.92 secondes

Val loss 0.8155350387096405 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 16/40
time = 106.23 secondes

Train loss 0.06793631725612971 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 2.93 secondes

Val loss 1.228388026356697 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 17/40
time = 106.23 secondes

Train loss 0.05855598292758011 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 2.83 secondes

Val loss 1.8716845214366913 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 18/40
time = 107.01 secondes

Train loss 0.14278572121486033 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 2.84 secondes

Val loss 1.782495766878128 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 19/40
time = 106.10 secondes

Train loss 0.07426900208740721 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 2.93 secondes

Val loss 2.292722076177597 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 20/40
time = 106.35 secondes

Train loss 0.41266337134275644 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.85 secondes

Val loss 1.568615734577179 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 21/40
time = 106.13 secondes

Train loss 0.17685734642763043 accuracy 0.9689922332763672 macro_avg {'precision': 0.9752439373767674, 'recall': 0.9583732912894365, 'f1-score': 0.9658730158730159, 'support': 516} weighted_avg {'precision': 0.9700219380667982, 'recall': 0.9689922480620154, 'f1-score': 0.968712316968131, 'support': 516}
 
time = 2.93 secondes

Val loss 1.8788590763724642 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 22/40
time = 106.25 secondes

Train loss 0.12393657735017106 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 2.94 secondes

Val loss 1.6335791498422623 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 23/40
time = 105.71 secondes

Train loss 0.11917145702450811 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 2.95 secondes

Val loss 2.4499506056308746 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 106.71 secondes

Train loss 0.19166216588818122 accuracy 0.9670542478561401 macro_avg {'precision': 0.9629480142072974, 'recall': 0.9660858540708352, 'f1-score': 0.9644764816652156, 'support': 516} weighted_avg {'precision': 0.9672354216258294, 'recall': 0.9670542635658915, 'f1-score': 0.9671098991464816, 'support': 516}
 
time = 2.69 secondes

Val loss 1.499965339899063 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 25/40
time = 107.58 secondes

Train loss 0.10124347070990497 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 2.94 secondes

Val loss 1.2261934950947762 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 26/40
time = 106.31 secondes

Train loss 0.06265152328353107 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.82 secondes

Val loss 1.6787316799163818 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 27/40
time = 105.84 secondes

Train loss 0.1743168470257484 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 2.94 secondes

Val loss 1.4443295896053314 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 28/40
time = 106.49 secondes

Train loss 0.023845222142523253 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.92 secondes

Val loss 2.4346551597118378 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 29/40
time = 106.91 secondes

Train loss 0.39005585973350343 accuracy 0.9418604373931885 macro_avg {'precision': 0.958217270194986, 'recall': 0.9197860962566845, 'f1-score': 0.934593023255814, 'support': 516} weighted_avg {'precision': 0.9467189220703505, 'recall': 0.9418604651162791, 'f1-score': 0.9405928880475933, 'support': 516}
 
time = 2.92 secondes

Val loss 1.48084257543087 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 30/40
time = 106.69 secondes

Train loss 0.1493743916686402 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.86 secondes

Val loss 1.705119117628783 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 106.46 secondes

Train loss 0.0026505435958053126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.80 secondes

Val loss 1.864279255270958 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 32/40
time = 106.03 secondes

Train loss 0.11904445267789539 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.91 secondes

Val loss 1.48716489225626 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 33/40
time = 106.60 secondes

Train loss 0.0001673200391506367 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.95 secondes

Val loss 2.412769377231598 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 34/40
time = 106.07 secondes

Train loss 0.022556991701783387 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.98 secondes

Val loss 1.9907635897397995 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 35/40
time = 105.99 secondes

Train loss 0.0002379695541810978 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.75 secondes

Val loss 2.076480969786644 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 36/40
time = 106.13 secondes

Train loss 0.020897628651613504 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.87 secondes

Val loss 2.1474937796592712 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 106.13 secondes

Train loss 6.45406376641018e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.761106714606285 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 38/40
time = 105.97 secondes

Train loss 3.172502009406206e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.92 secondes

Val loss 1.883382573723793 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 39/40
time = 106.09 secondes

Train loss 0.0002561505991087126 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.94 secondes

Val loss 1.8005222529172897 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 40/40
time = 107.34 secondes

Train loss 2.7276694240616493e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.93 secondes

Val loss 1.7226413786411285 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 15 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 106.39002574682236

average val time 2.8956131041049957
 
time = 3.26 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 69.25 GiB already allocated; 718.62 MiB free; 74.20 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 70.56 GiB already allocated; 1.80 GiB free; 73.10 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_1
----------
Epoch 1/40
time = 755.49 secondes

Train loss 1.372331961638512 accuracy 0.6310155391693115 macro_avg {'precision': 0.6227990152221288, 'recall': 0.6155942767044172, 'f1-score': 0.6085424596125351, 'support': 10182} weighted_avg {'precision': 0.6352206755249442, 'recall': 0.6310155175800433, 'f1-score': 0.6229050349104075, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.7946031366435575 accuracy 0.7667844295501709 macro_avg {'precision': 0.7464748114842101, 'recall': 0.7624202961575086, 'f1-score': 0.7477227027896178, 'support': 1132} weighted_avg {'precision': 0.7591497875513612, 'recall': 0.7667844522968198, 'f1-score': 0.7563077766068933, 'support': 1132}
 
----------
Epoch 2/40
time = 754.78 secondes

Train loss 0.5510137719007171 accuracy 0.8354940414428711 macro_avg {'precision': 0.822608970862451, 'recall': 0.8234619063329716, 'f1-score': 0.8207997313937538, 'support': 10182} weighted_avg {'precision': 0.8317195020277058, 'recall': 0.8354940090355529, 'f1-score': 0.8319458919253531, 'support': 10182}
 
time = 23.78 secondes

Val loss 0.6106695998722399 accuracy 0.8162544369697571 macro_avg {'precision': 0.8211281532337369, 'recall': 0.8109693318799313, 'f1-score': 0.8100367090302376, 'support': 1132} weighted_avg {'precision': 0.8237026913105493, 'recall': 0.8162544169611308, 'f1-score': 0.8143292364742848, 'support': 1132}
 
----------
Epoch 3/40
time = 754.66 secondes

Train loss 0.31115727099989143 accuracy 0.9104301929473877 macro_avg {'precision': 0.904979919710013, 'recall': 0.9038584653721854, 'f1-score': 0.9040340139091496, 'support': 10182} weighted_avg {'precision': 0.910529177052902, 'recall': 0.9104301708898055, 'f1-score': 0.9101392321502128, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.6279412276754287 accuracy 0.8365724682807922 macro_avg {'precision': 0.8530049729151175, 'recall': 0.8441911531931096, 'f1-score': 0.8391021139442414, 'support': 1132} weighted_avg {'precision': 0.8585270263452727, 'recall': 0.8365724381625441, 'f1-score': 0.8375765214643205, 'support': 1132}
 
----------
Epoch 4/40
time = 754.37 secondes

Train loss 0.21366391299596552 accuracy 0.9412689208984375 macro_avg {'precision': 0.9377447098015473, 'recall': 0.9374400275467858, 'f1-score': 0.9374969290738285, 'support': 10182} weighted_avg {'precision': 0.940974003326342, 'recall': 0.9412689059123944, 'f1-score': 0.9410440233637504, 'support': 10182}
 
time = 24.28 secondes

Val loss 0.6924298346488619 accuracy 0.843639612197876 macro_avg {'precision': 0.8682274146955926, 'recall': 0.8342303827464101, 'f1-score': 0.8407482412610522, 'support': 1132} weighted_avg {'precision': 0.8709878243092795, 'recall': 0.8436395759717314, 'f1-score': 0.84865035955994, 'support': 1132}
 
----------
Epoch 5/40
time = 752.90 secondes

Train loss 0.16139613372109995 accuracy 0.9572775959968567 macro_avg {'precision': 0.9546306415889925, 'recall': 0.9544967785595271, 'f1-score': 0.9545189898105397, 'support': 10182} weighted_avg {'precision': 0.9574269291066994, 'recall': 0.9572775486152033, 'f1-score': 0.9573085003398356, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.7453474432662864 accuracy 0.8683745861053467 macro_avg {'precision': 0.8653046063444083, 'recall': 0.8638709351951821, 'f1-score': 0.8621702824770379, 'support': 1132} weighted_avg {'precision': 0.8708572071679808, 'recall': 0.8683745583038869, 'f1-score': 0.8670814269455164, 'support': 1132}
 
----------
Epoch 6/40
time = 751.19 secondes

Train loss 0.1632520506621574 accuracy 0.9606168270111084 macro_avg {'precision': 0.9593769843422366, 'recall': 0.959295033199024, 'f1-score': 0.9592826166285946, 'support': 10182} weighted_avg {'precision': 0.9607009086743692, 'recall': 0.9606167747004518, 'f1-score': 0.9606035512368668, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.8076046266770122 accuracy 0.8586572408676147 macro_avg {'precision': 0.8733611505879111, 'recall': 0.8603918737860127, 'f1-score': 0.8611976506316774, 'support': 1132} weighted_avg {'precision': 0.8745645268805701, 'recall': 0.8586572438162544, 'f1-score': 0.8610883425250137, 'support': 1132}
 
----------
Epoch 7/40
time = 752.98 secondes

Train loss 0.1319472046252457 accuracy 0.9680809378623962 macro_avg {'precision': 0.9667779673844444, 'recall': 0.9664714537450386, 'f1-score': 0.9665962629174363, 'support': 10182} weighted_avg {'precision': 0.9680453594040704, 'recall': 0.9680809271263013, 'f1-score': 0.9680377537003787, 'support': 10182}
 
time = 24.23 secondes

Val loss 0.7400198687330334 accuracy 0.8763250708580017 macro_avg {'precision': 0.882719054172991, 'recall': 0.8795807675518855, 'f1-score': 0.8765283658987331, 'support': 1132} weighted_avg {'precision': 0.8845500008690171, 'recall': 0.8763250883392226, 'f1-score': 0.8756405291375831, 'support': 1132}
 
----------
Epoch 8/40
time = 753.98 secondes

Train loss 0.11714227561021276 accuracy 0.9732862114906311 macro_avg {'precision': 0.9730610650496192, 'recall': 0.9731039324220108, 'f1-score': 0.9730458775072742, 'support': 10182} weighted_avg {'precision': 0.9733179267287682, 'recall': 0.9732861913180122, 'f1-score': 0.9732642852113152, 'support': 10182}
 
time = 24.06 secondes

Val loss 0.8056871728515778 accuracy 0.8745583295822144 macro_avg {'precision': 0.8798159382358636, 'recall': 0.8699355610932809, 'f1-score': 0.8694207096865416, 'support': 1132} weighted_avg {'precision': 0.8786456874570715, 'recall': 0.8745583038869258, 'f1-score': 0.8720014860472374, 'support': 1132}
 
----------
Epoch 9/40
time = 751.96 secondes

Train loss 0.11801415112559842 accuracy 0.9736790657043457 macro_avg {'precision': 0.972644628486076, 'recall': 0.9725788801775138, 'f1-score': 0.972562795589426, 'support': 10182} weighted_avg {'precision': 0.9738008963208308, 'recall': 0.9736790414456885, 'f1-score': 0.9736979908628413, 'support': 10182}
 
time = 24.35 secondes

Val loss 1.0753419020801003 accuracy 0.8533568978309631 macro_avg {'precision': 0.8679677448365062, 'recall': 0.8564901278422747, 'f1-score': 0.8529149614998224, 'support': 1132} weighted_avg {'precision': 0.8700975756978135, 'recall': 0.8533568904593639, 'f1-score': 0.8523570552222254, 'support': 1132}
 
----------
Epoch 10/40
time = 749.13 secondes

Train loss 0.10305417418138897 accuracy 0.9778040051460266 macro_avg {'precision': 0.9776383737383597, 'recall': 0.9776333215872335, 'f1-score': 0.977607878384223, 'support': 10182} weighted_avg {'precision': 0.9779062634343646, 'recall': 0.9778039677862895, 'f1-score': 0.9778262756359387, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.9331279173257685 accuracy 0.8683745861053467 macro_avg {'precision': 0.8768015519988897, 'recall': 0.8702840547955544, 'f1-score': 0.8702798287425673, 'support': 1132} weighted_avg {'precision': 0.8767348440272853, 'recall': 0.8683745583038869, 'f1-score': 0.8691743120305949, 'support': 1132}
 
----------
Epoch 11/40
time = 753.27 secondes

Train loss 0.11408827397798271 accuracy 0.976527214050293 macro_avg {'precision': 0.9760512242354531, 'recall': 0.9752069771980449, 'f1-score': 0.9755615259145831, 'support': 10182} weighted_avg {'precision': 0.9766349309311828, 'recall': 0.9765272048713416, 'f1-score': 0.976516826796692, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.8731713990548061 accuracy 0.8816254734992981 macro_avg {'precision': 0.8852490276105718, 'recall': 0.8813630113595456, 'f1-score': 0.8800319787214775, 'support': 1132} weighted_avg {'precision': 0.8892986528284939, 'recall': 0.8816254416961131, 'f1-score': 0.8827693127374225, 'support': 1132}
 
----------
Epoch 12/40
time = 745.70 secondes

Train loss 0.09350815200219639 accuracy 0.9817324876785278 macro_avg {'precision': 0.9811533373948553, 'recall': 0.9812864309053259, 'f1-score': 0.9811952368034825, 'support': 10182} weighted_avg {'precision': 0.9817763636396301, 'recall': 0.9817324690630524, 'f1-score': 0.9817327587328296, 'support': 10182}
 
time = 24.12 secondes

Val loss 0.6727751348406227 accuracy 0.898409903049469 macro_avg {'precision': 0.899681050613302, 'recall': 0.901665548309509, 'f1-score': 0.8990898194638367, 'support': 1132} weighted_avg {'precision': 0.9026512091959225, 'recall': 0.8984098939929329, 'f1-score': 0.8989089010985141, 'support': 1132}
 
----------
Epoch 13/40
time = 753.68 secondes

Train loss 0.08819657378679974 accuracy 0.9833039045333862 macro_avg {'precision': 0.9827605320841689, 'recall': 0.9826348888497225, 'f1-score': 0.9826756627843956, 'support': 10182} weighted_avg {'precision': 0.9833198066214602, 'recall': 0.9833038695737576, 'f1-score': 0.9832906199431807, 'support': 10182}
 
time = 25.46 secondes

Val loss 0.773803951294968 accuracy 0.8886925578117371 macro_avg {'precision': 0.8938634676689954, 'recall': 0.8931172197065278, 'f1-score': 0.8905624794033737, 'support': 1132} weighted_avg {'precision': 0.8958193315622673, 'recall': 0.8886925795053003, 'f1-score': 0.8892571244970706, 'support': 1132}
 
----------
Epoch 14/40
time = 752.32 secondes

Train loss 0.0932274632471103 accuracy 0.980553925037384 macro_avg {'precision': 0.9804310136897358, 'recall': 0.98020414388562, 'f1-score': 0.9802714302140234, 'support': 10182} weighted_avg {'precision': 0.980597048195714, 'recall': 0.9805539186800236, 'f1-score': 0.9805301347474901, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.7728160917353127 accuracy 0.8904593586921692 macro_avg {'precision': 0.8942876348892301, 'recall': 0.8898960402382146, 'f1-score': 0.890230523091845, 'support': 1132} weighted_avg {'precision': 0.8965893111519456, 'recall': 0.8904593639575972, 'f1-score': 0.8915145460515232, 'support': 1132}
 
----------
Epoch 15/40
time = 753.87 secondes

Train loss 0.0719670745086744 accuracy 0.9861520528793335 macro_avg {'precision': 0.9858527859212373, 'recall': 0.9852419916401732, 'f1-score': 0.9855118632423577, 'support': 10182} weighted_avg {'precision': 0.9861667119229981, 'recall': 0.9861520329994107, 'f1-score': 0.9861296046393095, 'support': 10182}
 
time = 24.21 secondes

Val loss 0.9237031098707287 accuracy 0.8860424160957336 macro_avg {'precision': 0.8955202697406713, 'recall': 0.8906077846906573, 'f1-score': 0.8892029419574626, 'support': 1132} weighted_avg {'precision': 0.8953263719726176, 'recall': 0.8860424028268551, 'f1-score': 0.8864554977098054, 'support': 1132}
 
----------
Epoch 16/40
time = 751.91 secondes

Train loss 0.09111707174977444 accuracy 0.9833039045333862 macro_avg {'precision': 0.9832043072807435, 'recall': 0.9829076347767767, 'f1-score': 0.9829997136447165, 'support': 10182} weighted_avg {'precision': 0.9833759323360373, 'recall': 0.9833038695737576, 'f1-score': 0.9832827748837946, 'support': 10182}
 
time = 24.17 secondes

Val loss 0.9377645152257378 accuracy 0.8789752721786499 macro_avg {'precision': 0.8930652443457742, 'recall': 0.8828843825303483, 'f1-score': 0.8838259068861909, 'support': 1132} weighted_avg {'precision': 0.8905908069390202, 'recall': 0.8789752650176679, 'f1-score': 0.8801836820631088, 'support': 1132}
 
----------
Epoch 17/40
time = 753.83 secondes

Train loss 0.08425878126803256 accuracy 0.9853663444519043 macro_avg {'precision': 0.9846060863228274, 'recall': 0.9844686300106302, 'f1-score': 0.9844948491595954, 'support': 10182} weighted_avg {'precision': 0.9854143644602418, 'recall': 0.9853663327440582, 'f1-score': 0.9853520739409795, 'support': 10182}
 
time = 24.16 secondes

Val loss 0.9657834803055919 accuracy 0.8772084712982178 macro_avg {'precision': 0.8925533149624533, 'recall': 0.8767410997234475, 'f1-score': 0.8793459031255132, 'support': 1132} weighted_avg {'precision': 0.8887904444433735, 'recall': 0.877208480565371, 'f1-score': 0.8775853051960477, 'support': 1132}
 
----------
Epoch 18/40
time = 752.53 secondes

Train loss 0.07976119425824882 accuracy 0.9853663444519043 macro_avg {'precision': 0.9844619872694128, 'recall': 0.9844023646004441, 'f1-score': 0.984414797763027, 'support': 10182} weighted_avg {'precision': 0.9853762106376384, 'recall': 0.9853663327440582, 'f1-score': 0.9853535442115765, 'support': 10182}
 
time = 23.92 secondes

Val loss 0.992117074271705 accuracy 0.870141327381134 macro_avg {'precision': 0.8812779685143189, 'recall': 0.8709005611704322, 'f1-score': 0.8700869466852816, 'support': 1132} weighted_avg {'precision': 0.8864467610957574, 'recall': 0.8701413427561837, 'f1-score': 0.8729543336143502, 'support': 1132}
 
----------
Epoch 19/40
time = 754.19 secondes

Train loss 0.07153822533315518 accuracy 0.9869377613067627 macro_avg {'precision': 0.9863034044808192, 'recall': 0.9863121378785034, 'f1-score': 0.9862765358079466, 'support': 10182} weighted_avg {'precision': 0.9870431902998108, 'recall': 0.9869377332547633, 'f1-score': 0.9869595653434582, 'support': 10182}
 
time = 24.15 secondes

Val loss 1.0845947651230259 accuracy 0.8630741834640503 macro_avg {'precision': 0.8914171758759473, 'recall': 0.8651150588094595, 'f1-score': 0.8684040236646009, 'support': 1132} weighted_avg {'precision': 0.8907204520585983, 'recall': 0.8630742049469965, 'f1-score': 0.8667269863309442, 'support': 1132}
 
----------
Epoch 20/40
time = 753.25 secondes

Train loss 0.05953320252072964 accuracy 0.9890002012252808 macro_avg {'precision': 0.9884552427468485, 'recall': 0.9880638701675956, 'f1-score': 0.988238361198521, 'support': 10182} weighted_avg {'precision': 0.9890085218145828, 'recall': 0.9890001964250639, 'f1-score': 0.9889867107018898, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8541200280906452 accuracy 0.8895759582519531 macro_avg {'precision': 0.9003426887178707, 'recall': 0.8931741703920248, 'f1-score': 0.8920724608782201, 'support': 1132} weighted_avg {'precision': 0.8998147142118282, 'recall': 0.8895759717314488, 'f1-score': 0.8898306106926647, 'support': 1132}
 
----------
Epoch 21/40
time = 750.66 secondes

Train loss 0.0641876879211967 accuracy 0.9891966581344604 macro_avg {'precision': 0.988963734983898, 'recall': 0.988961383182707, 'f1-score': 0.9889300115687074, 'support': 10182} weighted_avg {'precision': 0.9892470618587771, 'recall': 0.989196621488902, 'f1-score': 0.989188623316835, 'support': 10182}
 
time = 23.99 secondes

Val loss 0.9540071966604929 accuracy 0.8869258165359497 macro_avg {'precision': 0.8987006263142356, 'recall': 0.8883460023219281, 'f1-score': 0.8890146844100295, 'support': 1132} weighted_avg {'precision': 0.8978512785134412, 'recall': 0.8869257950530035, 'f1-score': 0.8875584304481257, 'support': 1132}
 
----------
Epoch 22/40
time = 753.34 secondes

Train loss 0.06019574741347833 accuracy 0.9892948865890503 macro_avg {'precision': 0.9890623680386547, 'recall': 0.9889867640602665, 'f1-score': 0.9890062111654334, 'support': 10182} weighted_avg {'precision': 0.9893163025733535, 'recall': 0.9892948340208211, 'f1-score': 0.9892872415353429, 'support': 10182}
 
time = 24.01 secondes

Val loss 0.8117108292869271 accuracy 0.8948763608932495 macro_avg {'precision': 0.9094741174817651, 'recall': 0.8977009907009121, 'f1-score': 0.9007949655864523, 'support': 1132} weighted_avg {'precision': 0.9066520601007092, 'recall': 0.8948763250883393, 'f1-score': 0.897736830091526, 'support': 1132}
 
----------
Epoch 23/40
time = 751.85 secondes

Train loss 0.046891239848781234 accuracy 0.9912590980529785 macro_avg {'precision': 0.9910942812121457, 'recall': 0.9910986806467094, 'f1-score': 0.9910815748197365, 'support': 10182} weighted_avg {'precision': 0.9912890290931287, 'recall': 0.9912590846592025, 'f1-score': 0.9912597869873107, 'support': 10182}
 
time = 24.30 secondes

Val loss 0.861574079609262 accuracy 0.8904593586921692 macro_avg {'precision': 0.8974093724344812, 'recall': 0.8940962135174175, 'f1-score': 0.8937967626774256, 'support': 1132} weighted_avg {'precision': 0.8954076185669162, 'recall': 0.8904593639575972, 'f1-score': 0.8909618234218524, 'support': 1132}
 
----------
Epoch 24/40
time = 753.34 secondes

Train loss 0.049776418264081024 accuracy 0.9920448064804077 macro_avg {'precision': 0.9918456049048275, 'recall': 0.9919515415120166, 'f1-score': 0.9918861996140059, 'support': 10182} weighted_avg {'precision': 0.9920642555785829, 'recall': 0.9920447849145551, 'f1-score': 0.9920429598966232, 'support': 10182}
 
time = 24.06 secondes

Val loss 1.080848942467128 accuracy 0.8683745861053467 macro_avg {'precision': 0.8831733072203105, 'recall': 0.8774287583732457, 'f1-score': 0.8701177522078671, 'support': 1132} weighted_avg {'precision': 0.8852145054137567, 'recall': 0.8683745583038869, 'f1-score': 0.8652123310618849, 'support': 1132}
 
----------
Epoch 25/40
time = 752.36 secondes

Train loss 0.04876870376791824 accuracy 0.9916519522666931 macro_avg {'precision': 0.9913750579598197, 'recall': 0.9914745311552249, 'f1-score': 0.9914163293884884, 'support': 10182} weighted_avg {'precision': 0.9916604006652592, 'recall': 0.9916519347868789, 'f1-score': 0.9916476377050246, 'support': 10182}
 
time = 23.90 secondes

Val loss 0.8584901109039288 accuracy 0.9010601043701172 macro_avg {'precision': 0.906664111515259, 'recall': 0.9039321342098422, 'f1-score': 0.9025330574532333, 'support': 1132} weighted_avg {'precision': 0.907080063437981, 'recall': 0.901060070671378, 'f1-score': 0.9013085333087916, 'support': 1132}
 
----------
Epoch 26/40
time = 752.67 secondes

Train loss 0.06092188786274371 accuracy 0.9907680749893188 macro_avg {'precision': 0.9902960777763882, 'recall': 0.9901684877515627, 'f1-score': 0.9902061139446289, 'support': 10182} weighted_avg {'precision': 0.9908022183772769, 'recall': 0.9907680219996071, 'f1-score': 0.9907594011698361, 'support': 10182}
 
time = 23.82 secondes

Val loss 0.8058353072652531 accuracy 0.8922261595726013 macro_avg {'precision': 0.9007005797570399, 'recall': 0.8977463799964355, 'f1-score': 0.8949957781346468, 'support': 1132} weighted_avg {'precision': 0.9039005456709617, 'recall': 0.892226148409894, 'f1-score': 0.8937555336541271, 'support': 1132}
 
----------
Epoch 27/40
time = 752.86 secondes

Train loss 0.051702512698568535 accuracy 0.9913573265075684 macro_avg {'precision': 0.9907966184798582, 'recall': 0.990612683320145, 'f1-score': 0.9906936862196385, 'support': 10182} weighted_avg {'precision': 0.9913793385484096, 'recall': 0.9913572971911215, 'f1-score': 0.9913591786920781, 'support': 10182}
 
time = 25.31 secondes

Val loss 0.8526200375970188 accuracy 0.8939929604530334 macro_avg {'precision': 0.9022921238290584, 'recall': 0.8971818502208588, 'f1-score': 0.8971399674248456, 'support': 1132} weighted_avg {'precision': 0.9011302072928531, 'recall': 0.8939929328621908, 'f1-score': 0.8949328188899834, 'support': 1132}
 
----------
Epoch 28/40
time = 751.36 secondes

Train loss 0.03535121138044459 accuracy 0.9940090775489807 macro_avg {'precision': 0.9939766947761284, 'recall': 0.9936788171249026, 'f1-score': 0.993813496075914, 'support': 10182} weighted_avg {'precision': 0.9940224143819081, 'recall': 0.9940090355529365, 'f1-score': 0.9940036751855822, 'support': 10182}
 
time = 24.41 secondes

Val loss 1.1391332672197088 accuracy 0.8736749291419983 macro_avg {'precision': 0.8927321653928899, 'recall': 0.8676111026509574, 'f1-score': 0.8737096387857376, 'support': 1132} weighted_avg {'precision': 0.8863971339958189, 'recall': 0.8736749116607774, 'f1-score': 0.8735081407763031, 'support': 1132}
 
----------
Epoch 29/40
time = 754.37 secondes

Train loss 0.03715499011462212 accuracy 0.9939108490943909 macro_avg {'precision': 0.993902243134484, 'recall': 0.9938488303088301, 'f1-score': 0.9938670676472212, 'support': 10182} weighted_avg {'precision': 0.9939322691752885, 'recall': 0.9939108230210175, 'f1-score': 0.9939128252095553, 'support': 10182}
 
time = 23.95 secondes

Val loss 1.067693534377687 accuracy 0.8683745861053467 macro_avg {'precision': 0.8850390007258714, 'recall': 0.8708386806164906, 'f1-score': 0.8728853808123708, 'support': 1132} weighted_avg {'precision': 0.882983007776834, 'recall': 0.8683745583038869, 'f1-score': 0.8701166865905084, 'support': 1132}
 
----------
Epoch 30/40
time = 754.63 secondes

Train loss 0.03644347898339869 accuracy 0.9939108490943909 macro_avg {'precision': 0.993760722179388, 'recall': 0.9939054746857945, 'f1-score': 0.9938271576707992, 'support': 10182} weighted_avg {'precision': 0.9939266251779809, 'recall': 0.9939108230210175, 'f1-score': 0.9939134313789806, 'support': 10182}
 
time = 23.98 secondes

Val loss 0.8739052489636122 accuracy 0.8957597017288208 macro_avg {'precision': 0.9001009851411821, 'recall': 0.8968236109848619, 'f1-score': 0.897262923002286, 'support': 1132} weighted_avg {'precision': 0.899072132739794, 'recall': 0.8957597173144877, 'f1-score': 0.8961455170153119, 'support': 1132}
 
----------
Epoch 31/40
time = 753.45 secondes

Train loss 0.025959832525053975 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953250005870793, 'recall': 0.9954097565633775, 'f1-score': 0.9953618758032269, 'support': 10182} weighted_avg {'precision': 0.9953871187961189, 'recall': 0.9953840109998036, 'f1-score': 0.9953801139582318, 'support': 10182}
 
time = 24.75 secondes

Val loss 0.8779223775988138 accuracy 0.8966431021690369 macro_avg {'precision': 0.9043230630068578, 'recall': 0.8988354828975277, 'f1-score': 0.9004111605597072, 'support': 1132} weighted_avg {'precision': 0.901194346969186, 'recall': 0.8966431095406361, 'f1-score': 0.8977860509808875, 'support': 1132}
 
----------
Epoch 32/40
time = 758.62 secondes

Train loss 0.0277228288420189 accuracy 0.9955804944038391 macro_avg {'precision': 0.995286567472126, 'recall': 0.9954263545153028, 'f1-score': 0.9953509225906689, 'support': 10182} weighted_avg {'precision': 0.9955943473834448, 'recall': 0.9955804360636418, 'f1-score': 0.9955822926445846, 'support': 10182}
 
time = 24.68 secondes

Val loss 0.9034856507832572 accuracy 0.9001767039299011 macro_avg {'precision': 0.9048637021085796, 'recall': 0.9033264056112049, 'f1-score': 0.9022439062009578, 'support': 1132} weighted_avg {'precision': 0.9033795517018438, 'recall': 0.9001766784452296, 'f1-score': 0.8999772359278706, 'support': 1132}
 
----------
Epoch 33/40
time = 757.29 secondes

Train loss 0.02274574027798915 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963307586288079, 'recall': 0.9961586202089784, 'f1-score': 0.9962361309740665, 'support': 10182} weighted_avg {'precision': 0.9962866130673353, 'recall': 0.9962679237870752, 'f1-score': 0.9962688876045266, 'support': 10182}
 
time = 24.38 secondes

Val loss 0.9153745993161734 accuracy 0.8904593586921692 macro_avg {'precision': 0.894230099447137, 'recall': 0.8954176026269571, 'f1-score': 0.8924236178395379, 'support': 1132} weighted_avg {'precision': 0.8976734824924806, 'recall': 0.8904593639575972, 'f1-score': 0.8918156718475612, 'support': 1132}
 
----------
Epoch 34/40
time = 755.53 secondes

Train loss 0.0196310529865408 accuracy 0.9962679743766785 macro_avg {'precision': 0.996221252384412, 'recall': 0.9962593320220797, 'f1-score': 0.9962367319673626, 'support': 10182} weighted_avg {'precision': 0.9962773393346889, 'recall': 0.9962679237870752, 'f1-score': 0.9962690892243178, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.952540274721658 accuracy 0.898409903049469 macro_avg {'precision': 0.9057842277530691, 'recall': 0.9010000842328447, 'f1-score': 0.901156343135351, 'support': 1132} weighted_avg {'precision': 0.904929523636246, 'recall': 0.8984098939929329, 'f1-score': 0.8993834992448966, 'support': 1132}
 
----------
Epoch 35/40
time = 755.48 secondes

Train loss 0.015508589382747863 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975190877969418, 'recall': 0.9974545048840687, 'f1-score': 0.9974853024850476, 'support': 10182} weighted_avg {'precision': 0.9975486329986448, 'recall': 0.9975446867020232, 'f1-score': 0.9975452542278265, 'support': 10182}
 
time = 24.48 secondes

Val loss 0.9013555614728317 accuracy 0.9028268456459045 macro_avg {'precision': 0.9084692932448064, 'recall': 0.9043041288912319, 'f1-score': 0.9047638500189679, 'support': 1132} weighted_avg {'precision': 0.9074167596953874, 'recall': 0.9028268551236749, 'f1-score': 0.9034216790751081, 'support': 1132}
 
----------
Epoch 36/40
time = 756.23 secondes

Train loss 0.01311352847341578 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977195787365696, 'recall': 0.99773183359121, 'f1-score': 0.9977242089918377, 'support': 10182} weighted_avg {'precision': 0.9976432963101047, 'recall': 0.9976428992339422, 'f1-score': 0.997641534596836, 'support': 10182}
 
time = 24.03 secondes

Val loss 0.8549421874387764 accuracy 0.9010601043701172 macro_avg {'precision': 0.9080053111380012, 'recall': 0.9036995578189959, 'f1-score': 0.9039883277153746, 'support': 1132} weighted_avg {'precision': 0.9081317789132044, 'recall': 0.901060070671378, 'f1-score': 0.9026620832775903, 'support': 1132}
 
----------
Epoch 37/40
time = 749.67 secondes

Train loss 0.011699782797074235 accuracy 0.997741162776947 macro_avg {'precision': 0.9977984990264328, 'recall': 0.9977821899592556, 'f1-score': 0.9977869008189482, 'support': 10182} weighted_avg {'precision': 0.997749217959591, 'recall': 0.9977411117658613, 'f1-score': 0.9977416244722362, 'support': 10182}
 
time = 24.26 secondes

Val loss 0.9261157800301076 accuracy 0.9019434452056885 macro_avg {'precision': 0.9059935992413385, 'recall': 0.9047054121594371, 'f1-score': 0.9044833680821153, 'support': 1132} weighted_avg {'precision': 0.9048351628181854, 'recall': 0.9019434628975265, 'f1-score': 0.9025225154597547, 'support': 1132}
 
----------
Epoch 38/40
time = 751.72 secondes

Train loss 0.008788656654223171 accuracy 0.9983304142951965 macro_avg {'precision': 0.9984002265102557, 'recall': 0.9983954854416333, 'f1-score': 0.9983962324272045, 'support': 10182} weighted_avg {'precision': 0.9983341028334072, 'recall': 0.9983303869573757, 'f1-score': 0.9983305700738241, 'support': 10182}
 
time = 24.25 secondes

Val loss 0.934349763100637 accuracy 0.8992933034896851 macro_avg {'precision': 0.9036948669274061, 'recall': 0.9017666057022637, 'f1-score': 0.9013226556836932, 'support': 1132} weighted_avg {'precision': 0.9038802477116822, 'recall': 0.8992932862190812, 'f1-score': 0.9001004984642382, 'support': 1132}
 
----------
Epoch 39/40
time = 752.52 secondes

Train loss 0.0065723362446275715 accuracy 0.998919665813446 macro_avg {'precision': 0.9989627855156149, 'recall': 0.9989661221551002, 'f1-score': 0.9989641871717895, 'support': 10182} weighted_avg {'precision': 0.9989200438405521, 'recall': 0.9989196621488902, 'f1-score': 0.9989195755867342, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.9459367514915664 accuracy 0.9028268456459045 macro_avg {'precision': 0.9070013583830117, 'recall': 0.9055171140746486, 'f1-score': 0.9054042451182214, 'support': 1132} weighted_avg {'precision': 0.9054935666872914, 'recall': 0.9028268551236749, 'f1-score': 0.9032424345292964, 'support': 1132}
 
----------
Epoch 40/40
time = 752.91 secondes

Train loss 0.002053271436787704 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996224065117731, 'recall': 0.9996220883649922, 'f1-score': 0.9996218870502203, 'support': 10182} weighted_avg {'precision': 0.9996078915605738, 'recall': 0.9996071498723237, 'f1-score': 0.9996071478785676, 'support': 10182}
 
time = 24.53 secondes

Val loss 0.9393784564454749 accuracy 0.9045936465263367 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}
 
----------
best_accuracy 0.9045936465263367 best_epoch 40 macro_avg {'precision': 0.9118146851521269, 'recall': 0.9074069700602273, 'f1-score': 0.9082361220495209, 'support': 1132} weighted_avg {'precision': 0.9084371498575853, 'recall': 0.9045936395759717, 'f1-score': 0.9051182959611742, 'support': 1132}

average train time 753.1714322268963

average val time 24.193848645687105
 
time = 155.53 secondes

test_accuracy 0.8394848704338074 macro_avg {'precision': 0.8360665862079324, 'recall': 0.8314777131359555, 'f1-score': 0.8318660812130627, 'support': 7532} weighted_avg {'precision': 0.8416371158070496, 'recall': 0.8394848645778014, 'f1-score': 0.8387477349344281, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_1
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 476.60 secondes

Train loss 1.4331473210355739 accuracy 0.6079356074333191 macro_avg {'precision': 0.595532368398952, 'recall': 0.5917237987707078, 'f1-score': 0.5790491296094726, 'support': 10182} weighted_avg {'precision': 0.6042763200476227, 'recall': 0.6079355725790611, 'f1-score': 0.593853690526893, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.7841680335326934 accuracy 0.7667844295501709 macro_avg {'precision': 0.739943149202323, 'recall': 0.7618544356319451, 'f1-score': 0.7458947088746772, 'support': 1132} weighted_avg {'precision': 0.75182844061862, 'recall': 0.7667844522968198, 'f1-score': 0.7541985476968371, 'support': 1132}
 
----------
Epoch 2/40
time = 476.04 secondes

Train loss 0.583929990013269 accuracy 0.8282263278961182 macro_avg {'precision': 0.8161602902699846, 'recall': 0.8165633833367003, 'f1-score': 0.8128140616937282, 'support': 10182} weighted_avg {'precision': 0.8244776185406745, 'recall': 0.8282262816735415, 'f1-score': 0.8237937923967038, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.5993993981203563 accuracy 0.8250883221626282 macro_avg {'precision': 0.8195563635230922, 'recall': 0.8193174818530942, 'f1-score': 0.8152797294673576, 'support': 1132} weighted_avg {'precision': 0.8230771856693206, 'recall': 0.8250883392226148, 'f1-score': 0.8202999495405455, 'support': 1132}
 
----------
Epoch 3/40
time = 476.00 secondes

Train loss 0.340324222538591 accuracy 0.9025731682777405 macro_avg {'precision': 0.8967596834557, 'recall': 0.8958669568700433, 'f1-score': 0.8958695376090751, 'support': 10182} weighted_avg {'precision': 0.9024620646147935, 'recall': 0.9025731683362798, 'f1-score': 0.9021430590220308, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.5815014537476318 accuracy 0.8560070991516113 macro_avg {'precision': 0.8634590795475925, 'recall': 0.8556529482332225, 'f1-score': 0.8552210975889697, 'support': 1132} weighted_avg {'precision': 0.8646713003522922, 'recall': 0.8560070671378092, 'f1-score': 0.8560157507643367, 'support': 1132}
 
----------
Epoch 4/40
time = 476.22 secondes

Train loss 0.23231736694578098 accuracy 0.9345904588699341 macro_avg {'precision': 0.9319368347980402, 'recall': 0.9317686101997366, 'f1-score': 0.9317570155734156, 'support': 10182} weighted_avg {'precision': 0.9348861108546099, 'recall': 0.9345904537418974, 'f1-score': 0.9346498251221417, 'support': 10182}
 
time = 18.96 secondes

Val loss 0.6259556379641446 accuracy 0.8551236987113953 macro_avg {'precision': 0.8609540977768008, 'recall': 0.8556226015645432, 'f1-score': 0.8544318344221775, 'support': 1132} weighted_avg {'precision': 0.8625570425443255, 'recall': 0.8551236749116607, 'f1-score': 0.8548984432087424, 'support': 1132}
 
----------
Epoch 5/40
time = 475.88 secondes

Train loss 0.1748830053386581 accuracy 0.9533490538597107 macro_avg {'precision': 0.9516033261806103, 'recall': 0.9514170434662741, 'f1-score': 0.9514570429770532, 'support': 10182} weighted_avg {'precision': 0.9534326157275188, 'recall': 0.9533490473384404, 'f1-score': 0.953336799730088, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.7272236547465633 accuracy 0.8630741834640503 macro_avg {'precision': 0.8708896460916961, 'recall': 0.8644282370593244, 'f1-score': 0.8641041655066886, 'support': 1132} weighted_avg {'precision': 0.8726354679099134, 'recall': 0.8630742049469965, 'f1-score': 0.8642412809883327, 'support': 1132}
 
----------
Epoch 6/40
time = 476.16 secondes

Train loss 0.1584024625383332 accuracy 0.9604203701019287 macro_avg {'precision': 0.9592065042520094, 'recall': 0.9592835233329247, 'f1-score': 0.9592294929828862, 'support': 10182} weighted_avg {'precision': 0.9604347813263789, 'recall': 0.9604203496366136, 'f1-score': 0.9604123345468925, 'support': 10182}
 
time = 18.86 secondes

Val loss 0.758953261697455 accuracy 0.8577738404273987 macro_avg {'precision': 0.8614111064327519, 'recall': 0.8589454743813493, 'f1-score': 0.8549817886692553, 'support': 1132} weighted_avg {'precision': 0.8660030040975224, 'recall': 0.857773851590106, 'f1-score': 0.856284031270566, 'support': 1132}
 
----------
Epoch 7/40
time = 475.84 secondes

Train loss 0.14216014674765656 accuracy 0.9653310179710388 macro_avg {'precision': 0.9645655522809855, 'recall': 0.9641619498612242, 'f1-score': 0.9642924550541008, 'support': 10182} weighted_avg {'precision': 0.9655337846443575, 'recall': 0.9653309762325673, 'f1-score': 0.9653611515450293, 'support': 10182}
 
time = 18.85 secondes

Val loss 0.7416990194010588 accuracy 0.8780918717384338 macro_avg {'precision': 0.8811785459790918, 'recall': 0.8804205108422221, 'f1-score': 0.8781174879349164, 'support': 1132} weighted_avg {'precision': 0.8849644983260769, 'recall': 0.8780918727915195, 'f1-score': 0.8787998994126525, 'support': 1132}
 
----------
Epoch 8/40
time = 476.10 secondes

Train loss 0.12067588076754429 accuracy 0.9725005030632019 macro_avg {'precision': 0.9722001082472236, 'recall': 0.9721257796000968, 'f1-score': 0.9721351711975579, 'support': 10182} weighted_avg {'precision': 0.9725739050575131, 'recall': 0.9725004910626596, 'f1-score': 0.9725087613223514, 'support': 10182}
 
time = 18.82 secondes

Val loss 0.7339283946235861 accuracy 0.8745583295822144 macro_avg {'precision': 0.8826095081904173, 'recall': 0.874568146580154, 'f1-score': 0.8769547797901808, 'support': 1132} weighted_avg {'precision': 0.8811637837674384, 'recall': 0.8745583038869258, 'f1-score': 0.8761188850333996, 'support': 1132}
 
----------
Epoch 9/40
time = 476.04 secondes

Train loss 0.10903065326039532 accuracy 0.9746611714363098 macro_avg {'precision': 0.9741865901387794, 'recall': 0.9742351137255751, 'f1-score': 0.9741962233526994, 'support': 10182} weighted_avg {'precision': 0.974724442373857, 'recall': 0.9746611667648792, 'f1-score': 0.9746785518769862, 'support': 10182}
 
time = 18.88 secondes

Val loss 0.8223847077159674 accuracy 0.8772084712982178 macro_avg {'precision': 0.8826345561067571, 'recall': 0.8770441957968472, 'f1-score': 0.8769333427693777, 'support': 1132} weighted_avg {'precision': 0.8831914359483808, 'recall': 0.877208480565371, 'f1-score': 0.8773411367960622, 'support': 1132}
 
----------
Epoch 10/40
time = 475.82 secondes

Train loss 0.11789070985461728 accuracy 0.9738755226135254 macro_avg {'precision': 0.9731961377927348, 'recall': 0.973200740770074, 'f1-score': 0.9731627640154048, 'support': 10182} weighted_avg {'precision': 0.9739487252486413, 'recall': 0.9738754665095266, 'f1-score': 0.9738776717658235, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.8175750739454755 accuracy 0.8825088143348694 macro_avg {'precision': 0.8913923704669908, 'recall': 0.883866773636696, 'f1-score': 0.8847052732973243, 'support': 1132} weighted_avg {'precision': 0.8909649461121127, 'recall': 0.8825088339222615, 'f1-score': 0.8837968176779287, 'support': 1132}
 
----------
Epoch 11/40
time = 475.91 secondes

Train loss 0.09919397233814671 accuracy 0.9790807366371155 macro_avg {'precision': 0.9790703489237936, 'recall': 0.9788592044062174, 'f1-score': 0.9789447022959307, 'support': 10182} weighted_avg {'precision': 0.9791428167988073, 'recall': 0.9790807307012375, 'f1-score': 0.9790913360341983, 'support': 10182}
 
time = 18.77 secondes

Val loss 0.8908824549281222 accuracy 0.8754417300224304 macro_avg {'precision': 0.8821615968382085, 'recall': 0.8794177991914369, 'f1-score': 0.8789325370424491, 'support': 1132} weighted_avg {'precision': 0.8815647475126456, 'recall': 0.8754416961130742, 'f1-score': 0.8765026701389428, 'support': 1132}
 
----------
Epoch 12/40
time = 475.88 secondes

Train loss 0.09129590717917549 accuracy 0.9806521534919739 macro_avg {'precision': 0.9800866581385748, 'recall': 0.9802607772683853, 'f1-score': 0.9801439160742735, 'support': 10182} weighted_avg {'precision': 0.9807138847737596, 'recall': 0.9806521312119426, 'f1-score': 0.9806558565390472, 'support': 10182}
 
time = 18.48 secondes

Val loss 0.9937783832445374 accuracy 0.8630741834640503 macro_avg {'precision': 0.8733898391893451, 'recall': 0.8670089084551453, 'f1-score': 0.8648809298645034, 'support': 1132} weighted_avg {'precision': 0.8755908746722945, 'recall': 0.8630742049469965, 'f1-score': 0.8639046796658957, 'support': 1132}
 
----------
Epoch 13/40
time = 476.11 secondes

Train loss 0.08980626681439609 accuracy 0.980455756187439 macro_avg {'precision': 0.9795998189242281, 'recall': 0.979604220809508, 'f1-score': 0.9795927062112714, 'support': 10182} weighted_avg {'precision': 0.9804728958930987, 'recall': 0.9804557061481045, 'f1-score': 0.9804549758499381, 'support': 10182}
 
time = 18.81 secondes

Val loss 0.8969723584669852 accuracy 0.8895759582519531 macro_avg {'precision': 0.8922436621638152, 'recall': 0.8912214320652373, 'f1-score': 0.8895649057737479, 'support': 1132} weighted_avg {'precision': 0.8935681143745808, 'recall': 0.8895759717314488, 'f1-score': 0.8893378676623295, 'support': 1132}
 
----------
Epoch 14/40
time = 475.84 secondes

Train loss 0.10348619175381762 accuracy 0.9797682762145996 macro_avg {'precision': 0.9789901199294879, 'recall': 0.9787463913066874, 'f1-score': 0.9788377776155285, 'support': 10182} weighted_avg {'precision': 0.9798523975319084, 'recall': 0.979768218424671, 'f1-score': 0.979779436900201, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9059342153333079 accuracy 0.8754417300224304 macro_avg {'precision': 0.8778813571448472, 'recall': 0.877441965291202, 'f1-score': 0.8741509322557416, 'support': 1132} weighted_avg {'precision': 0.8851415609220239, 'recall': 0.8754416961130742, 'f1-score': 0.8771474591746815, 'support': 1132}
 
----------
Epoch 15/40
time = 476.03 secondes

Train loss 0.08314088314661176 accuracy 0.9836967587471008 macro_avg {'precision': 0.9832150597916243, 'recall': 0.9831992157949017, 'f1-score': 0.983199031298537, 'support': 10182} weighted_avg {'precision': 0.9837254619249084, 'recall': 0.9836967197014339, 'f1-score': 0.9837026716596627, 'support': 10182}
 
time = 18.87 secondes

Val loss 0.9432870343968627 accuracy 0.8780918717384338 macro_avg {'precision': 0.8845226477766779, 'recall': 0.8791886345536408, 'f1-score': 0.8780385805480032, 'support': 1132} weighted_avg {'precision': 0.8873804611747138, 'recall': 0.8780918727915195, 'f1-score': 0.8791053029753878, 'support': 1132}
 
----------
Epoch 16/40
time = 476.35 secondes

Train loss 0.0940445225161075 accuracy 0.982518196105957 macro_avg {'precision': 0.9817548134222344, 'recall': 0.9816643902481731, 'f1-score': 0.9816593986344646, 'support': 10182} weighted_avg {'precision': 0.9826808035717151, 'recall': 0.9825181693184051, 'f1-score': 0.9825537198533938, 'support': 10182}
 
time = 18.84 secondes

Val loss 0.9672756871394239 accuracy 0.8789752721786499 macro_avg {'precision': 0.8884270418708559, 'recall': 0.8825164724944143, 'f1-score': 0.88057735833649, 'support': 1132} weighted_avg {'precision': 0.8906840871781373, 'recall': 0.8789752650176679, 'f1-score': 0.8797962694336531, 'support': 1132}
 
----------
Epoch 17/40
time = 476.65 secondes

Train loss 0.0818525345824826 accuracy 0.9848753213882446 macro_avg {'precision': 0.9849107728893282, 'recall': 0.9847533387775153, 'f1-score': 0.9848087326962881, 'support': 10182} weighted_avg {'precision': 0.9849143428672977, 'recall': 0.9848752700844627, 'f1-score': 0.9848711988006121, 'support': 10182}
 
time = 16.81 secondes

Val loss 0.8446089303164831 accuracy 0.8939929604530334 macro_avg {'precision': 0.9006322439249818, 'recall': 0.8984693505945536, 'f1-score': 0.895063622639484, 'support': 1132} weighted_avg {'precision': 0.901506280142878, 'recall': 0.8939929328621908, 'f1-score': 0.8927643861731265, 'support': 1132}
 
----------
Epoch 18/40
time = 476.49 secondes

Train loss 0.08235502529404037 accuracy 0.9848753213882446 macro_avg {'precision': 0.9843885036380129, 'recall': 0.9848336893572034, 'f1-score': 0.9845820441279723, 'support': 10182} weighted_avg {'precision': 0.9848976904712462, 'recall': 0.9848752700844627, 'f1-score': 0.9848594575484368, 'support': 10182}
 
time = 16.90 secondes

Val loss 0.8545968070694714 accuracy 0.8904593586921692 macro_avg {'precision': 0.8956289533222371, 'recall': 0.8935548211794837, 'f1-score': 0.8913272082898652, 'support': 1132} weighted_avg {'precision': 0.8996540634020332, 'recall': 0.8904593639575972, 'f1-score': 0.8916909484994318, 'support': 1132}
 
----------
Epoch 19/40
time = 476.27 secondes

Train loss 0.06282364381961082 accuracy 0.9881163239479065 macro_avg {'precision': 0.9875385327508319, 'recall': 0.9876985328735055, 'f1-score': 0.987598871641884, 'support': 10182} weighted_avg {'precision': 0.9881654007767301, 'recall': 0.9881162836377921, 'f1-score': 0.988122278611521, 'support': 10182}
 
time = 16.82 secondes

Val loss 0.8057548724572767 accuracy 0.8922261595726013 macro_avg {'precision': 0.8977223620467759, 'recall': 0.8933680720438512, 'f1-score': 0.8928635548307208, 'support': 1132} weighted_avg {'precision': 0.8974182953616768, 'recall': 0.892226148409894, 'f1-score': 0.892260650990808, 'support': 1132}
 
----------
Epoch 20/40
time = 476.61 secondes

Train loss 0.052562987162582 accuracy 0.98978590965271 macro_avg {'precision': 0.9891761708337553, 'recall': 0.9892604113527611, 'f1-score': 0.9892034050464359, 'support': 10182} weighted_avg {'precision': 0.9898173625653797, 'recall': 0.9897858966804164, 'f1-score': 0.9897878889952575, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.9763796942340929 accuracy 0.8745583295822144 macro_avg {'precision': 0.8959231728469849, 'recall': 0.8823246687327038, 'f1-score': 0.8784921639339665, 'support': 1132} weighted_avg {'precision': 0.9024436496660545, 'recall': 0.8745583038869258, 'f1-score': 0.8774899066285587, 'support': 1132}
 
----------
Epoch 21/40
time = 476.40 secondes

Train loss 0.07425018755057125 accuracy 0.9866431355476379 macro_avg {'precision': 0.9865689620766265, 'recall': 0.986778149810112, 'f1-score': 0.986658241498629, 'support': 10182} weighted_avg {'precision': 0.9866694270713218, 'recall': 0.9866430956590061, 'f1-score': 0.9866419029432296, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.8224266537015891 accuracy 0.8913427591323853 macro_avg {'precision': 0.8970380007732738, 'recall': 0.8939182246500144, 'f1-score': 0.8925762853483103, 'support': 1132} weighted_avg {'precision': 0.8982436703140954, 'recall': 0.8913427561837456, 'f1-score': 0.8918994657342718, 'support': 1132}
 
----------
Epoch 22/40
time = 476.26 secondes

Train loss 0.05776682668380844 accuracy 0.9899823665618896 macro_avg {'precision': 0.9898832208283483, 'recall': 0.9898323684349215, 'f1-score': 0.9898448652004305, 'support': 10182} weighted_avg {'precision': 0.9899877544583315, 'recall': 0.9899823217442546, 'f1-score': 0.9899717822955614, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8461720995633378 accuracy 0.8939929604530334 macro_avg {'precision': 0.9015471875027007, 'recall': 0.8932644188617118, 'f1-score': 0.8927044858621975, 'support': 1132} weighted_avg {'precision': 0.9017710974474212, 'recall': 0.8939929328621908, 'f1-score': 0.8937859038335254, 'support': 1132}
 
----------
Epoch 23/40
time = 476.22 secondes

Train loss 0.04697093484487074 accuracy 0.9911609292030334 macro_avg {'precision': 0.9910013300213396, 'recall': 0.9910493216952705, 'f1-score': 0.9910115989662931, 'support': 10182} weighted_avg {'precision': 0.9911955383611514, 'recall': 0.9911608721272834, 'f1-score': 0.9911641665669635, 'support': 10182}
 
time = 16.84 secondes

Val loss 0.7270659135557112 accuracy 0.9028268456459045 macro_avg {'precision': 0.9062091506547768, 'recall': 0.904765264201895, 'f1-score': 0.904517030128479, 'support': 1132} weighted_avg {'precision': 0.9059847331977929, 'recall': 0.9028268551236749, 'f1-score': 0.9034375725753206, 'support': 1132}
 
----------
Epoch 24/40
time = 476.30 secondes

Train loss 0.05323730014505181 accuracy 0.9914555549621582 macro_avg {'precision': 0.9911679139192643, 'recall': 0.9910527066005498, 'f1-score': 0.9910947134898889, 'support': 10182} weighted_avg {'precision': 0.9914771992689536, 'recall': 0.9914555097230406, 'f1-score': 0.9914527204680895, 'support': 10182}
 
time = 16.97 secondes

Val loss 0.8383258971479732 accuracy 0.8957597017288208 macro_avg {'precision': 0.9025643848897058, 'recall': 0.8990701955651718, 'f1-score': 0.8976995556023345, 'support': 1132} weighted_avg {'precision': 0.9017608386305206, 'recall': 0.8957597173144877, 'f1-score': 0.8956881652653363, 'support': 1132}
 
----------
Epoch 25/40
time = 476.33 secondes

Train loss 0.049769247696713995 accuracy 0.9921430349349976 macro_avg {'precision': 0.9922156831705223, 'recall': 0.9922917962845117, 'f1-score': 0.9922432922975473, 'support': 10182} weighted_avg {'precision': 0.9921478885978211, 'recall': 0.9921429974464742, 'f1-score': 0.9921349017016393, 'support': 10182}
 
time = 16.90 secondes

Val loss 1.2118418849469736 accuracy 0.8639575839042664 macro_avg {'precision': 0.8784330995646729, 'recall': 0.8666925028105087, 'f1-score': 0.8664674732898282, 'support': 1132} weighted_avg {'precision': 0.881337250102642, 'recall': 0.8639575971731449, 'f1-score': 0.8664615583449901, 'support': 1132}
 
----------
Epoch 26/40
time = 476.35 secondes

Train loss 0.04962862467934944 accuracy 0.991750180721283 macro_avg {'precision': 0.9908647049469523, 'recall': 0.9911753156672493, 'f1-score': 0.9909945533362012, 'support': 10182} weighted_avg {'precision': 0.9917978212614529, 'recall': 0.9917501473187978, 'f1-score': 0.991754284990792, 'support': 10182}
 
time = 17.10 secondes

Val loss 0.9946132900272652 accuracy 0.8780918717384338 macro_avg {'precision': 0.886844770451769, 'recall': 0.880248149772868, 'f1-score': 0.8784473175089064, 'support': 1132} weighted_avg {'precision': 0.890620579613345, 'recall': 0.8780918727915195, 'f1-score': 0.8802463425347955, 'support': 1132}
 
----------
Epoch 27/40
time = 476.24 secondes

Train loss 0.037443653197178337 accuracy 0.9928305149078369 macro_avg {'precision': 0.9923604881152501, 'recall': 0.9925993536713094, 'f1-score': 0.9924711511501763, 'support': 10182} weighted_avg {'precision': 0.992858005407245, 'recall': 0.9928304851699077, 'f1-score': 0.992835871514283, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8570922745954742 accuracy 0.8966431021690369 macro_avg {'precision': 0.8997127327141022, 'recall': 0.9016370238578795, 'f1-score': 0.8988682934835366, 'support': 1132} weighted_avg {'precision': 0.9010992175565485, 'recall': 0.8966431095406361, 'f1-score': 0.896947512131109, 'support': 1132}
 
----------
Epoch 28/40
time = 476.34 secondes

Train loss 0.043723354749204725 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919919339144008, 'recall': 0.9920220277396986, 'f1-score': 0.9920011773727777, 'support': 10182} weighted_avg {'precision': 0.9920538260037121, 'recall': 0.9920447849145551, 'f1-score': 0.9920434542402128, 'support': 10182}
 
time = 16.76 secondes

Val loss 0.8313640775060622 accuracy 0.898409903049469 macro_avg {'precision': 0.9061009294875714, 'recall': 0.9015306506607855, 'f1-score': 0.9021619417995221, 'support': 1132} weighted_avg {'precision': 0.9025417665778662, 'recall': 0.8984098939929329, 'f1-score': 0.8987797359314919, 'support': 1132}
 
----------
Epoch 29/40
time = 476.24 secondes

Train loss 0.031085909932283513 accuracy 0.9941073060035706 macro_avg {'precision': 0.9940725275169824, 'recall': 0.9941480105977402, 'f1-score': 0.9941061328427813, 'support': 10182} weighted_avg {'precision': 0.994114057034208, 'recall': 0.9941072480848556, 'f1-score': 0.9941066487754239, 'support': 10182}
 
time = 16.17 secondes

Val loss 0.992737110735132 accuracy 0.8886925578117371 macro_avg {'precision': 0.9009585520205844, 'recall': 0.8863641622063806, 'f1-score': 0.8886403409719144, 'support': 1132} weighted_avg {'precision': 0.8995411403023295, 'recall': 0.8886925795053003, 'f1-score': 0.8899843997219234, 'support': 1132}
 
----------
Epoch 30/40
time = 476.58 secondes

Train loss 0.03888092267498481 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934250948877779, 'recall': 0.9934886079499444, 'f1-score': 0.9934468610963197, 'support': 10182} weighted_avg {'precision': 0.9940202929890849, 'recall': 0.9940090355529365, 'f1-score': 0.9940050584084523, 'support': 10182}
 
time = 16.68 secondes

Val loss 0.886118140636337 accuracy 0.8922261595726013 macro_avg {'precision': 0.9006095908515904, 'recall': 0.8950692334630697, 'f1-score': 0.8936173151022802, 'support': 1132} weighted_avg {'precision': 0.8996652193836726, 'recall': 0.892226148409894, 'f1-score': 0.8920199450739377, 'support': 1132}
 
----------
Epoch 31/40
time = 476.22 secondes

Train loss 0.028713607613170544 accuracy 0.994892954826355 macro_avg {'precision': 0.9946646465126282, 'recall': 0.9946425407239985, 'f1-score': 0.9946491755579986, 'support': 10182} weighted_avg {'precision': 0.9949013888135394, 'recall': 0.9948929483402082, 'f1-score': 0.994892985163133, 'support': 10182}
 
time = 16.89 secondes

Val loss 0.8772494216123883 accuracy 0.9081271886825562 macro_avg {'precision': 0.9166574954576159, 'recall': 0.9118808200266096, 'f1-score': 0.9125847218581361, 'support': 1132} weighted_avg {'precision': 0.9127131316103466, 'recall': 0.9081272084805654, 'f1-score': 0.9087118330973951, 'support': 1132}
 
----------
Epoch 32/40
time = 476.12 secondes

Train loss 0.038586022712079684 accuracy 0.9936162233352661 macro_avg {'precision': 0.9937714285862491, 'recall': 0.9936985801093063, 'f1-score': 0.993728398576048, 'support': 10182} weighted_avg {'precision': 0.9936375960701547, 'recall': 0.9936161854252603, 'f1-score': 0.9936201772640636, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.8376955747209368 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126703005774628, 'recall': 0.91050410830889, 'f1-score': 0.9106161324321006, 'support': 1132} weighted_avg {'precision': 0.9103768495176995, 'recall': 0.9081272084805654, 'f1-score': 0.9082280056250128, 'support': 1132}
 
----------
Epoch 33/40
time = 477.06 secondes

Train loss 0.022106994634426086 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960348085684627, 'recall': 0.9959239975075697, 'f1-score': 0.9959766413322289, 'support': 10182} weighted_avg {'precision': 0.9960763174345807, 'recall': 0.9960714987232371, 'f1-score': 0.9960714828076999, 'support': 10182}
 
time = 16.86 secondes

Val loss 0.8938071656801595 accuracy 0.9054770469665527 macro_avg {'precision': 0.9089023322543677, 'recall': 0.907206830352122, 'f1-score': 0.9062887458539539, 'support': 1132} weighted_avg {'precision': 0.9098721753018832, 'recall': 0.9054770318021201, 'f1-score': 0.9059075922778872, 'support': 1132}
 
----------
Epoch 34/40
time = 476.11 secondes

Train loss 0.02002061514667016 accuracy 0.9962679743766785 macro_avg {'precision': 0.9963586041890611, 'recall': 0.9963882587223306, 'f1-score': 0.9963660536643802, 'support': 10182} weighted_avg {'precision': 0.9962904601872715, 'recall': 0.9962679237870752, 'f1-score': 0.9962715798892713, 'support': 10182}
 
time = 16.54 secondes

Val loss 0.9732385666069296 accuracy 0.8939929604530334 macro_avg {'precision': 0.9024351907424117, 'recall': 0.8994889048217717, 'f1-score': 0.8971986517749485, 'support': 1132} weighted_avg {'precision': 0.9046193260034942, 'recall': 0.8939929328621908, 'f1-score': 0.8956300749622467, 'support': 1132}
 
----------
Epoch 35/40
time = 476.38 secondes

Train loss 0.015641405498072445 accuracy 0.9970536828041077 macro_avg {'precision': 0.997186663684358, 'recall': 0.997134246896984, 'f1-score': 0.9971470633025602, 'support': 10182} weighted_avg {'precision': 0.9970814979283738, 'recall': 0.9970536240424278, 'f1-score': 0.9970537399642208, 'support': 10182}
 
time = 16.93 secondes

Val loss 0.8120080086814148 accuracy 0.9116607904434204 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}
 
----------
Epoch 36/40
time = 476.52 secondes

Train loss 0.015949043090050786 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975256556069297, 'recall': 0.9973727067699185, 'f1-score': 0.9974413372715596, 'support': 10182} weighted_avg {'precision': 0.9975572648351069, 'recall': 0.9975446867020232, 'f1-score': 0.9975438718809831, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9054440364443636 accuracy 0.9054770469665527 macro_avg {'precision': 0.9098100446437348, 'recall': 0.908338583070797, 'f1-score': 0.9079247398369761, 'support': 1132} weighted_avg {'precision': 0.909363568992873, 'recall': 0.9054770318021201, 'f1-score': 0.9062233633137983, 'support': 1132}
 
----------
Epoch 37/40
time = 476.33 secondes

Train loss 0.0065117422103141975 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986604452327945, 'recall': 0.9986403734244002, 'f1-score': 0.9986495940363275, 'support': 10182} weighted_avg {'precision': 0.9987247312286821, 'recall': 0.9987232370850521, 'f1-score': 0.9987231987033319, 'support': 10182}
 
time = 16.92 secondes

Val loss 0.9217688095203697 accuracy 0.9010601043701172 macro_avg {'precision': 0.9029670784735023, 'recall': 0.9040157579397295, 'f1-score': 0.9018182850077678, 'support': 1132} weighted_avg {'precision': 0.9056168332215249, 'recall': 0.901060070671378, 'f1-score': 0.9017167851383562, 'support': 1132}
 
----------
Epoch 38/40
time = 476.60 secondes

Train loss 0.009076425064661034 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986561952378381, 'recall': 0.9987010040805717, 'f1-score': 0.9986767750580696, 'support': 10182} weighted_avg {'precision': 0.9987254040347094, 'recall': 0.9987232370850521, 'f1-score': 0.9987224450350004, 'support': 10182}
 
time = 17.19 secondes

Val loss 1.1009912460943616 accuracy 0.8904593586921692 macro_avg {'precision': 0.8930635853249503, 'recall': 0.8951290034856629, 'f1-score': 0.8915758679621119, 'support': 1132} weighted_avg {'precision': 0.8973040338994697, 'recall': 0.8904593639575972, 'f1-score': 0.8914447556334754, 'support': 1132}
 
----------
Epoch 39/40
time = 476.36 secondes

Train loss 0.004712479369310978 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992373015787427, 'recall': 0.9992411211620341, 'f1-score': 0.9992389826265702, 'support': 10182} weighted_avg {'precision': 0.9993127050759184, 'recall': 0.9993125122765665, 'f1-score': 0.9993123996889289, 'support': 10182}
 
time = 16.87 secondes

Val loss 0.9440119815970601 accuracy 0.8992933034896851 macro_avg {'precision': 0.9043786351635557, 'recall': 0.9034703667960795, 'f1-score': 0.901970580444825, 'support': 1132} weighted_avg {'precision': 0.904949066983656, 'recall': 0.8992932862190812, 'f1-score': 0.8999977322225842, 'support': 1132}
 
----------
Epoch 40/40
time = 476.27 secondes

Train loss 0.0029121377023918088 accuracy 0.9994107484817505 macro_avg {'precision': 0.999418394131815, 'recall': 0.9993780990979012, 'f1-score': 0.9993977770860285, 'support': 10182} weighted_avg {'precision': 0.9994115870018708, 'recall': 0.9994107248084856, 'f1-score': 0.9994106819482753, 'support': 10182}
 
time = 16.91 secondes

Val loss 0.9745304558480609 accuracy 0.9001767039299011 macro_avg {'precision': 0.9058208282388479, 'recall': 0.9037579696344862, 'f1-score': 0.902814940267515, 'support': 1132} weighted_avg {'precision': 0.9059259916519704, 'recall': 0.9001766784452296, 'f1-score': 0.900934748385834, 'support': 1132}
 
----------
best_accuracy 0.9116607904434204 best_epoch 35 macro_avg {'precision': 0.9162692491350419, 'recall': 0.9151781891248714, 'f1-score': 0.9145389107947752, 'support': 1132} weighted_avg {'precision': 0.9144915992449129, 'recall': 0.911660777385159, 'f1-score': 0.9119133165496397, 'support': 1132}

average train time 476.2516987025738

average val time 17.631594270467758
 
time = 107.53 secondes

test_accuracy 0.8348379731178284 macro_avg {'precision': 0.8316073449511627, 'recall': 0.8290983707098822, 'f1-score': 0.8284636763392512, 'support': 7532} weighted_avg {'precision': 0.8375247937439214, 'recall': 0.8348380244291025, 'f1-score': 0.8343998913511087, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_1
----------
Epoch 1/40
time = 1922.63 secondes

Train loss 1.3563601410650945 accuracy 0.6342565417289734 macro_avg {'precision': 0.6311249056630124, 'recall': 0.6183001475305336, 'f1-score': 0.6069341533632095, 'support': 10182} weighted_avg {'precision': 0.6394093685392014, 'recall': 0.6342565311333727, 'f1-score': 0.6219575282769404, 'support': 10182}
 
time = 52.82 secondes

Val loss 0.7800213056550899 accuracy 0.7614840865135193 macro_avg {'precision': 0.7543278013263962, 'recall': 0.7587375685957276, 'f1-score': 0.7454669955773282, 'support': 1132} weighted_avg {'precision': 0.7669285197252486, 'recall': 0.7614840989399293, 'f1-score': 0.7520640590829529, 'support': 1132}
 
----------
Epoch 2/40
time = 1917.88 secondes

Train loss 0.5498222497231919 accuracy 0.8326458930969238 macro_avg {'precision': 0.8194822777281006, 'recall': 0.8198686414206552, 'f1-score': 0.8160250599070608, 'support': 10182} weighted_avg {'precision': 0.8289016402609096, 'recall': 0.8326458456098998, 'f1-score': 0.8281176786290024, 'support': 10182}
 
time = 53.45 secondes

Val loss 0.6661390110220707 accuracy 0.7959364056587219 macro_avg {'precision': 0.8078255781927763, 'recall': 0.79421757987355, 'f1-score': 0.7926226676191326, 'support': 1132} weighted_avg {'precision': 0.8157289939906799, 'recall': 0.7959363957597173, 'f1-score': 0.7967029108383243, 'support': 1132}
 
----------
Epoch 3/40
time = 1921.35 secondes

Train loss 0.32057227810707345 accuracy 0.9056177735328674 macro_avg {'precision': 0.9001688138780143, 'recall': 0.8995811872248136, 'f1-score': 0.8996746042331776, 'support': 10182} weighted_avg {'precision': 0.9056635843204324, 'recall': 0.905617756825771, 'f1-score': 0.9054525271801049, 'support': 10182}
 
time = 53.00 secondes

Val loss 0.5940035742930543 accuracy 0.851590096950531 macro_avg {'precision': 0.8549678790264492, 'recall': 0.8489949452380243, 'f1-score': 0.8491355095612892, 'support': 1132} weighted_avg {'precision': 0.8529812738975073, 'recall': 0.8515901060070671, 'f1-score': 0.8495391534753041, 'support': 1132}
 
----------
Epoch 4/40
time = 1923.23 secondes

Train loss 0.22492251191449059 accuracy 0.9388136267662048 macro_avg {'precision': 0.9351679169472039, 'recall': 0.9348968995233135, 'f1-score': 0.9349479551161674, 'support': 10182} weighted_avg {'precision': 0.9390748474958273, 'recall': 0.9388135926144175, 'f1-score': 0.9388596497932974, 'support': 10182}
 
time = 52.26 secondes

Val loss 0.6839744140931838 accuracy 0.8454063534736633 macro_avg {'precision': 0.8578191346968701, 'recall': 0.8419427275782103, 'f1-score': 0.8434235817190616, 'support': 1132} weighted_avg {'precision': 0.8564730236320933, 'recall': 0.8454063604240283, 'f1-score': 0.8446783177814201, 'support': 1132}
 
----------
Epoch 5/40
time = 1922.14 secondes

Train loss 0.16780832892881772 accuracy 0.9569829106330872 macro_avg {'precision': 0.9544422617033348, 'recall': 0.9543776813274839, 'f1-score': 0.9543436729105828, 'support': 10182} weighted_avg {'precision': 0.957082899244578, 'recall': 0.9569829110194461, 'f1-score': 0.956971829480186, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.7324177780267324 accuracy 0.862190842628479 macro_avg {'precision': 0.8700550486432188, 'recall': 0.862658951325076, 'f1-score': 0.8618377666814778, 'support': 1132} weighted_avg {'precision': 0.873109662625358, 'recall': 0.8621908127208481, 'f1-score': 0.8630627353570113, 'support': 1132}
 
----------
Epoch 6/40
time = 1923.40 secondes

Train loss 0.15209646134844176 accuracy 0.9624828696250916 macro_avg {'precision': 0.960568671406927, 'recall': 0.9608502644411872, 'f1-score': 0.9606605022504654, 'support': 10182} weighted_avg {'precision': 0.9625860675937754, 'recall': 0.9624828128069142, 'f1-score': 0.9624869699524449, 'support': 10182}
 
time = 53.30 secondes

Val loss 0.7910824491098051 accuracy 0.8630741834640503 macro_avg {'precision': 0.8739048415669337, 'recall': 0.8649658670323206, 'f1-score': 0.8652424836198026, 'support': 1132} weighted_avg {'precision': 0.8734628770828299, 'recall': 0.8630742049469965, 'f1-score': 0.864391520109176, 'support': 1132}
 
----------
Epoch 7/40
time = 1919.33 secondes

Train loss 0.13056213132912087 accuracy 0.9688666462898254 macro_avg {'precision': 0.9679842675373426, 'recall': 0.9678890453720749, 'f1-score': 0.9679058774256072, 'support': 10182} weighted_avg {'precision': 0.9688315105119321, 'recall': 0.9688666273816539, 'f1-score': 0.9688183985908866, 'support': 10182}
 
time = 53.03 secondes

Val loss 0.8152730234924861 accuracy 0.8586572408676147 macro_avg {'precision': 0.8618898470234162, 'recall': 0.8578494890896333, 'f1-score': 0.8564586708214851, 'support': 1132} weighted_avg {'precision': 0.8626374034537093, 'recall': 0.8586572438162544, 'f1-score': 0.8569071639887107, 'support': 1132}
 
----------
Epoch 8/40
time = 1921.80 secondes

Train loss 0.11953015721076295 accuracy 0.9719112515449524 macro_avg {'precision': 0.9708811688815364, 'recall': 0.970867716324298, 'f1-score': 0.9708578367637344, 'support': 10182} weighted_avg {'precision': 0.9719537730489218, 'recall': 0.9719112158711452, 'f1-score': 0.9719167378769186, 'support': 10182}
 
time = 47.72 secondes

Val loss 0.723524037891225 accuracy 0.870141327381134 macro_avg {'precision': 0.8746950269223799, 'recall': 0.8721629700856346, 'f1-score': 0.8711095389842092, 'support': 1132} weighted_avg {'precision': 0.8719913764890239, 'recall': 0.8701413427561837, 'f1-score': 0.86854589786337, 'support': 1132}
 
----------
Epoch 9/40
time = 1918.96 secondes

Train loss 0.13171000592310048 accuracy 0.972304105758667 macro_avg {'precision': 0.9717382670856548, 'recall': 0.9712567131204042, 'f1-score': 0.9714287478747371, 'support': 10182} weighted_avg {'precision': 0.9723688042388928, 'recall': 0.9723040659988215, 'f1-score': 0.9722685409838638, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.9472246942312037 accuracy 0.8613074421882629 macro_avg {'precision': 0.8645305687267678, 'recall': 0.8658064686955044, 'f1-score': 0.8625773274148827, 'support': 1132} weighted_avg {'precision': 0.8679684289177609, 'recall': 0.8613074204946997, 'f1-score': 0.8621420085395792, 'support': 1132}
 
----------
Epoch 10/40
time = 1923.81 secondes

Train loss 0.11088613241697476 accuracy 0.9764290452003479 macro_avg {'precision': 0.9752179625554758, 'recall': 0.9757292537258643, 'f1-score': 0.9754248844175107, 'support': 10182} weighted_avg {'precision': 0.9765642114085306, 'recall': 0.9764289923394225, 'f1-score': 0.9764529073533446, 'support': 10182}
 
time = 53.15 secondes

Val loss 0.9061960216282053 accuracy 0.8630741834640503 macro_avg {'precision': 0.8696380771859384, 'recall': 0.8629405265607378, 'f1-score': 0.8641900206670261, 'support': 1132} weighted_avg {'precision': 0.8670442748293664, 'recall': 0.8630742049469965, 'f1-score': 0.8629459112608805, 'support': 1132}
 
----------
Epoch 11/40
time = 1926.41 secondes

Train loss 0.12593862606340242 accuracy 0.9740719199180603 macro_avg {'precision': 0.97320767702232, 'recall': 0.9730492711817892, 'f1-score': 0.9730752685218379, 'support': 10182} weighted_avg {'precision': 0.9741435792867559, 'recall': 0.9740718915733647, 'f1-score': 0.9740558624456227, 'support': 10182}
 
time = 52.65 secondes

Val loss 0.988449477814638 accuracy 0.8586572408676147 macro_avg {'precision': 0.8704122690058755, 'recall': 0.862907702325314, 'f1-score': 0.8612213325199256, 'support': 1132} weighted_avg {'precision': 0.8731343707645367, 'recall': 0.8586572438162544, 'f1-score': 0.8603554732585362, 'support': 1132}
 
----------
Epoch 12/40
time = 1925.91 secondes

Train loss 0.09780363976829587 accuracy 0.9790807366371155 macro_avg {'precision': 0.9789912996390843, 'recall': 0.9786940928669632, 'f1-score': 0.9788103392987646, 'support': 10182} weighted_avg {'precision': 0.9791057645519969, 'recall': 0.9790807307012375, 'f1-score': 0.9790608398837547, 'support': 10182}
 
time = 53.57 secondes

Val loss 0.9447666060695552 accuracy 0.8692579865455627 macro_avg {'precision': 0.8822035510822925, 'recall': 0.870140490982644, 'f1-score': 0.8715210373253462, 'support': 1132} weighted_avg {'precision': 0.8796936638294879, 'recall': 0.8692579505300353, 'f1-score': 0.8696165541610031, 'support': 1132}
 
----------
Epoch 13/40
time = 1925.57 secondes

Train loss 0.09539037328187867 accuracy 0.9821253418922424 macro_avg {'precision': 0.9819608823115014, 'recall': 0.9816884186048762, 'f1-score': 0.9817998872982969, 'support': 10182} weighted_avg {'precision': 0.9821601583233321, 'recall': 0.9821253191907288, 'f1-score': 0.9821184038666043, 'support': 10182}
 
time = 45.94 secondes

Val loss 1.0016799879794889 accuracy 0.8586572408676147 macro_avg {'precision': 0.8684059091195225, 'recall': 0.8608938541306881, 'f1-score': 0.860962575838778, 'support': 1132} weighted_avg {'precision': 0.8701210110355243, 'recall': 0.8586572438162544, 'f1-score': 0.8611124521960787, 'support': 1132}
 
----------
Epoch 14/40
time = 1926.82 secondes

Train loss 0.11129338205935016 accuracy 0.9789825677871704 macro_avg {'precision': 0.9784174033921422, 'recall': 0.9785844470958601, 'f1-score': 0.9784459855069632, 'support': 10182} weighted_avg {'precision': 0.9790609670846595, 'recall': 0.9789825181693184, 'f1-score': 0.9789691467485602, 'support': 10182}
 
time = 52.47 secondes

Val loss 0.9710275931283832 accuracy 0.8780918717384338 macro_avg {'precision': 0.8846317515333902, 'recall': 0.8787632844145318, 'f1-score': 0.8792075248447777, 'support': 1132} weighted_avg {'precision': 0.8832890099271713, 'recall': 0.8780918727915195, 'f1-score': 0.8782152057655278, 'support': 1132}
 
----------
Epoch 15/40
time = 1924.49 secondes

Train loss 0.08928665776178807 accuracy 0.98448246717453 macro_avg {'precision': 0.9839703015806924, 'recall': 0.9836706278261932, 'f1-score': 0.9837949825103255, 'support': 10182} weighted_avg {'precision': 0.9844939578968811, 'recall': 0.9844824199567865, 'f1-score': 0.9844649200208041, 'support': 10182}
 
time = 53.13 secondes

Val loss 0.8860850506654816 accuracy 0.8736749291419983 macro_avg {'precision': 0.8755093733853874, 'recall': 0.8773560619391303, 'f1-score': 0.8736251287469301, 'support': 1132} weighted_avg {'precision': 0.8807208340134238, 'recall': 0.8736749116607774, 'f1-score': 0.8747173575783868, 'support': 1132}
 
----------
Epoch 16/40
time = 1923.23 secondes

Train loss 0.07685961915589277 accuracy 0.9863485097885132 macro_avg {'precision': 0.9863689821094754, 'recall': 0.9864582943156721, 'f1-score': 0.9864041617136952, 'support': 10182} weighted_avg {'precision': 0.9863482048486378, 'recall': 0.9863484580632489, 'f1-score': 0.9863388154446698, 'support': 10182}
 
time = 53.15 secondes

Val loss 1.0277355745044114 accuracy 0.862190842628479 macro_avg {'precision': 0.8685718206044944, 'recall': 0.8659779453270373, 'f1-score': 0.8640419867507088, 'support': 1132} weighted_avg {'precision': 0.869050366035999, 'recall': 0.8621908127208481, 'f1-score': 0.8622182386974463, 'support': 1132}
 
----------
Epoch 17/40
time = 1923.90 secondes

Train loss 0.07368812286173693 accuracy 0.9861520528793335 macro_avg {'precision': 0.9862564145756009, 'recall': 0.9860893933386711, 'f1-score': 0.9861586219834747, 'support': 10182} weighted_avg {'precision': 0.9861647238005923, 'recall': 0.9861520329994107, 'f1-score': 0.9861442141611498, 'support': 10182}
 
time = 52.52 secondes

Val loss 0.8700165179774123 accuracy 0.8869258165359497 macro_avg {'precision': 0.8931426906995149, 'recall': 0.8876121128460899, 'f1-score': 0.8884694447619121, 'support': 1132} weighted_avg {'precision': 0.8935023600343338, 'recall': 0.8869257950530035, 'f1-score': 0.8884043120449301, 'support': 1132}
 
----------
Epoch 18/40
time = 1924.82 secondes

Train loss 0.07652928455529173 accuracy 0.9865449070930481 macro_avg {'precision': 0.9863488721926548, 'recall': 0.9857695342716145, 'f1-score': 0.9860421402531097, 'support': 10182} weighted_avg {'precision': 0.9865619322924669, 'recall': 0.986544883127087, 'f1-score': 0.986538407053708, 'support': 10182}
 
time = 52.99 secondes

Val loss 0.9044486876418503 accuracy 0.8842756152153015 macro_avg {'precision': 0.8937313516046311, 'recall': 0.8858495780447873, 'f1-score': 0.8869339654307481, 'support': 1132} weighted_avg {'precision': 0.8935036054082099, 'recall': 0.8842756183745583, 'f1-score': 0.886007217329685, 'support': 1132}
 
----------
Epoch 19/40
time = 1926.83 secondes

Train loss 0.058053445491742496 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893489618120093, 'recall': 0.9892613929212845, 'f1-score': 0.9892885189261232, 'support': 10182} weighted_avg {'precision': 0.9894263616148029, 'recall': 0.9893930465527401, 'f1-score': 0.9893926587968289, 'support': 10182}
 
time = 53.42 secondes

Val loss 0.9706725447357084 accuracy 0.8772084712982178 macro_avg {'precision': 0.8814805948713327, 'recall': 0.879018767882501, 'f1-score': 0.877464054413893, 'support': 1132} weighted_avg {'precision': 0.8824810592201481, 'recall': 0.877208480565371, 'f1-score': 0.8771666246351415, 'support': 1132}
 
----------
Epoch 20/40
time = 1924.45 secondes

Train loss 0.06300680484962916 accuracy 0.9882145524024963 macro_avg {'precision': 0.9877677264913267, 'recall': 0.9880019096493753, 'f1-score': 0.9878743323204955, 'support': 10182} weighted_avg {'precision': 0.9882439270756346, 'recall': 0.9882144961697112, 'f1-score': 0.9882203170945527, 'support': 10182}
 
time = 53.21 secondes

Val loss 0.9521126986446816 accuracy 0.8780918717384338 macro_avg {'precision': 0.8798887704165328, 'recall': 0.8782878167631981, 'f1-score': 0.8777599651068119, 'support': 1132} weighted_avg {'precision': 0.8809338736239282, 'recall': 0.8780918727915195, 'f1-score': 0.878421345252993, 'support': 1132}
 
----------
Epoch 21/40
time = 1923.15 secondes

Train loss 0.07824257556795877 accuracy 0.9857591986656189 macro_avg {'precision': 0.985840597304418, 'recall': 0.984086487438633, 'f1-score': 0.9848382511506582, 'support': 10182} weighted_avg {'precision': 0.9859228773977913, 'recall': 0.9857591828717345, 'f1-score': 0.9857402985938656, 'support': 10182}
 
time = 52.70 secondes

Val loss 0.9927527360153068 accuracy 0.8772084712982178 macro_avg {'precision': 0.8835282917005148, 'recall': 0.8820352740659377, 'f1-score': 0.8804827005671392, 'support': 1132} weighted_avg {'precision': 0.8848160537524499, 'recall': 0.877208480565371, 'f1-score': 0.8787463172878207, 'support': 1132}
 
----------
Epoch 22/40
time = 1926.16 secondes

Train loss 0.05917944625622938 accuracy 0.9901787638664246 macro_avg {'precision': 0.9898743945996505, 'recall': 0.989740317913465, 'f1-score': 0.9897991293985544, 'support': 10182} weighted_avg {'precision': 0.9901890500679325, 'recall': 0.9901787468080927, 'f1-score': 0.9901759445840763, 'support': 10182}
 
time = 49.55 secondes

Val loss 0.9722528517900878 accuracy 0.8816254734992981 macro_avg {'precision': 0.8844381453628462, 'recall': 0.8849774814053759, 'f1-score': 0.8818433196642932, 'support': 1132} weighted_avg {'precision': 0.8893295059654718, 'recall': 0.8816254416961131, 'f1-score': 0.8826534818694257, 'support': 1132}
 
----------
Epoch 23/40
time = 1925.36 secondes

Train loss 0.05707894403375186 accuracy 0.9904733896255493 macro_avg {'precision': 0.9900934967659655, 'recall': 0.9903033550474338, 'f1-score': 0.9901789164534873, 'support': 10182} weighted_avg {'precision': 0.9905138277826692, 'recall': 0.9904733844038499, 'f1-score': 0.9904751217906759, 'support': 10182}
 
time = 50.76 secondes

Val loss 0.9718114211376507 accuracy 0.8719081282615662 macro_avg {'precision': 0.8833144234525211, 'recall': 0.8777655854007431, 'f1-score': 0.876947930317454, 'support': 1132} weighted_avg {'precision': 0.881913225723505, 'recall': 0.8719081272084805, 'f1-score': 0.8731597823037501, 'support': 1132}
 
----------
Epoch 24/40
time = 1925.71 secondes

Train loss 0.04441417406164952 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925075816579714, 'recall': 0.9925122621835454, 'f1-score': 0.9925008763457207, 'support': 10182} weighted_avg {'precision': 0.992449699274889, 'recall': 0.9924376350422314, 'f1-score': 0.9924343666725506, 'support': 10182}
 
time = 53.57 secondes

Val loss 1.007799237595361 accuracy 0.8745583295822144 macro_avg {'precision': 0.8799363695774852, 'recall': 0.8766669179769615, 'f1-score': 0.8763303706917125, 'support': 1132} weighted_avg {'precision': 0.8820500544723547, 'recall': 0.8745583038869258, 'f1-score': 0.876077307803354, 'support': 1132}
 
----------
Epoch 25/40
time = 1926.13 secondes

Train loss 0.04336232122994809 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915988010549031, 'recall': 0.99140053169114, 'f1-score': 0.9914934443229579, 'support': 10182} weighted_avg {'precision': 0.9919537961292039, 'recall': 0.9919465723826361, 'f1-score': 0.9919454015576321, 'support': 10182}
 
time = 53.25 secondes

Val loss 1.0714047893014422 accuracy 0.8763250708580017 macro_avg {'precision': 0.8803821672825437, 'recall': 0.8773740867016034, 'f1-score': 0.8761304546576433, 'support': 1132} weighted_avg {'precision': 0.8818467373045039, 'recall': 0.8763250883392226, 'f1-score': 0.8762557273842883, 'support': 1132}
 
----------
Epoch 26/40
time = 1926.06 secondes

Train loss 0.04405674952443004 accuracy 0.9920448064804077 macro_avg {'precision': 0.9917129657906509, 'recall': 0.9916486585460671, 'f1-score': 0.9916777101722516, 'support': 10182} weighted_avg {'precision': 0.9920473994322461, 'recall': 0.9920447849145551, 'f1-score': 0.9920429739459726, 'support': 10182}
 
time = 53.62 secondes

Val loss 0.9922698019086761 accuracy 0.8710247278213501 macro_avg {'precision': 0.8770376594655487, 'recall': 0.8725879163545269, 'f1-score': 0.8724271771412498, 'support': 1132} weighted_avg {'precision': 0.8779787702852488, 'recall': 0.8710247349823321, 'f1-score': 0.8720216575380861, 'support': 1132}
 
----------
Epoch 27/40
time = 1923.80 secondes

Train loss 0.04048159152341187 accuracy 0.993714451789856 macro_avg {'precision': 0.9930176239382298, 'recall': 0.99316472392157, 'f1-score': 0.9930853193862438, 'support': 10182} weighted_avg {'precision': 0.9937346682143964, 'recall': 0.9937143979571793, 'f1-score': 0.9937187122428861, 'support': 10182}
 
time = 51.45 secondes

Val loss 1.0452644777747402 accuracy 0.8683745861053467 macro_avg {'precision': 0.8766248069718794, 'recall': 0.8717888101025875, 'f1-score': 0.8661161066207091, 'support': 1132} weighted_avg {'precision': 0.8830330714568839, 'recall': 0.8683745583038869, 'f1-score': 0.8688581565330564, 'support': 1132}
 
----------
Epoch 28/40
time = 1929.63 secondes

Train loss 0.030535827016240573 accuracy 0.9942054748535156 macro_avg {'precision': 0.9937993440574834, 'recall': 0.9936505876274806, 'f1-score': 0.9937188787148183, 'support': 10182} weighted_avg {'precision': 0.9942101680466461, 'recall': 0.9942054606167747, 'f1-score': 0.9942021326525127, 'support': 10182}
 
time = 52.65 secondes

Val loss 1.0851200424765177 accuracy 0.8674911856651306 macro_avg {'precision': 0.8797832042382016, 'recall': 0.8692305690711069, 'f1-score': 0.8704689642891641, 'support': 1132} weighted_avg {'precision': 0.879810926535638, 'recall': 0.8674911660777385, 'f1-score': 0.8694007591733018, 'support': 1132}
 
----------
Epoch 29/40
time = 1925.39 secondes

Train loss 0.030600916608801675 accuracy 0.9945983290672302 macro_avg {'precision': 0.9942783728606294, 'recall': 0.9942634538467681, 'f1-score': 0.9942622562237384, 'support': 10182} weighted_avg {'precision': 0.9946120873584051, 'recall': 0.994598310744451, 'f1-score': 0.9945974359884104, 'support': 10182}
 
time = 51.39 secondes

Val loss 1.0528666132771654 accuracy 0.8789752721786499 macro_avg {'precision': 0.8813937472817669, 'recall': 0.8800530262753788, 'f1-score': 0.8781674462065501, 'support': 1132} weighted_avg {'precision': 0.8831588111594484, 'recall': 0.8789752650176679, 'f1-score': 0.8787804730826417, 'support': 1132}
 
----------
Epoch 30/40
time = 1923.95 secondes

Train loss 0.03010589234865757 accuracy 0.994892954826355 macro_avg {'precision': 0.9948017621494252, 'recall': 0.9948835609585036, 'f1-score': 0.9948398842379668, 'support': 10182} weighted_avg {'precision': 0.9949038204950252, 'recall': 0.9948929483402082, 'f1-score': 0.9948956174304118, 'support': 10182}
 
time = 53.18 secondes

Val loss 1.049861646002785 accuracy 0.8860424160957336 macro_avg {'precision': 0.8879239719981712, 'recall': 0.8898785262282825, 'f1-score': 0.8871081927103696, 'support': 1132} weighted_avg {'precision': 0.8903102616499255, 'recall': 0.8860424028268551, 'f1-score': 0.8862392747210929, 'support': 1132}
 
----------
Epoch 31/40
time = 1925.34 secondes

Train loss 0.031239954956912144 accuracy 0.9949911832809448 macro_avg {'precision': 0.9949259949187338, 'recall': 0.9949012063151168, 'f1-score': 0.9949056155895963, 'support': 10182} weighted_avg {'precision': 0.9950095092910202, 'recall': 0.9949911608721272, 'f1-score': 0.9949921864766119, 'support': 10182}
 
time = 51.59 secondes

Val loss 0.9067690765463032 accuracy 0.8816254734992981 macro_avg {'precision': 0.8900480519188705, 'recall': 0.8848260367040772, 'f1-score': 0.8848908093622733, 'support': 1132} weighted_avg {'precision': 0.8911637600368186, 'recall': 0.8816254416961131, 'f1-score': 0.8839344924266814, 'support': 1132}
 
----------
Epoch 32/40
time = 1924.65 secondes

Train loss 0.02606130519045532 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955498132941709, 'recall': 0.995574787569074, 'f1-score': 0.9955590027536465, 'support': 10182} weighted_avg {'precision': 0.995583354417422, 'recall': 0.9955804360636418, 'f1-score': 0.9955785276215163, 'support': 10182}
 
time = 47.48 secondes

Val loss 1.0529112987019225 accuracy 0.8860424160957336 macro_avg {'precision': 0.8909394111948714, 'recall': 0.888534480745846, 'f1-score': 0.8875710963744359, 'support': 1132} weighted_avg {'precision': 0.8912025951065586, 'recall': 0.8860424028268551, 'f1-score': 0.8863777126629514, 'support': 1132}
 
----------
Epoch 33/40
time = 1924.26 secondes

Train loss 0.019704478370709304 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959369396216406, 'recall': 0.9958711815793823, 'f1-score': 0.9958976668196142, 'support': 10182} weighted_avg {'precision': 0.9958892736588832, 'recall': 0.995875073659399, 'f1-score': 0.9958760532402782, 'support': 10182}
 
time = 52.87 secondes

Val loss 1.0400636622685904 accuracy 0.8851590156555176 macro_avg {'precision': 0.8911848613651605, 'recall': 0.8889798150428788, 'f1-score': 0.8877332855538261, 'support': 1132} weighted_avg {'precision': 0.8904328323813739, 'recall': 0.8851590106007067, 'f1-score': 0.8853210391553842, 'support': 1132}
 
----------
Epoch 34/40
time = 1925.76 secondes

Train loss 0.01887077924283185 accuracy 0.9965626001358032 macro_avg {'precision': 0.9966108245646031, 'recall': 0.9966706007732787, 'f1-score': 0.9966347272092528, 'support': 10182} weighted_avg {'precision': 0.9965741231950103, 'recall': 0.9965625613828325, 'f1-score': 0.9965621465340625, 'support': 10182}
 
time = 54.28 secondes

Val loss 1.0790454606800446 accuracy 0.879858672618866 macro_avg {'precision': 0.888118672919707, 'recall': 0.8833889789116706, 'f1-score': 0.883754840702724, 'support': 1132} weighted_avg {'precision': 0.8860430951362872, 'recall': 0.8798586572438163, 'f1-score': 0.8808052664943157, 'support': 1132}
 
----------
Epoch 35/40
time = 1926.79 secondes

Train loss 0.014778358710219654 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972162445227143, 'recall': 0.9972785872464612, 'f1-score': 0.9972443093858636, 'support': 10182} weighted_avg {'precision': 0.9973565146195259, 'recall': 0.997348261638185, 'f1-score': 0.9973493773789662, 'support': 10182}
 
time = 54.69 secondes

Val loss 1.0786697066205435 accuracy 0.8886925578117371 macro_avg {'precision': 0.8959009612291744, 'recall': 0.8899114974130269, 'f1-score': 0.8908720786253719, 'support': 1132} weighted_avg {'precision': 0.8946432941143623, 'recall': 0.8886925795053003, 'f1-score': 0.8894511111357427, 'support': 1132}
 
----------
Epoch 36/40
time = 1925.42 secondes

Train loss 0.01220237803720933 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974277131818313, 'recall': 0.9974008406522369, 'f1-score': 0.9974062434480224, 'support': 10182} weighted_avg {'precision': 0.9973678705435329, 'recall': 0.997348261638185, 'f1-score': 0.9973499140052285, 'support': 10182}
 
time = 52.76 secondes

Val loss 1.0539087854689517 accuracy 0.8939929604530334 macro_avg {'precision': 0.8958798770744021, 'recall': 0.8981414944716875, 'f1-score': 0.8952873443112443, 'support': 1132} weighted_avg {'precision': 0.8971607431497904, 'recall': 0.8939929328621908, 'f1-score': 0.8937159348690917, 'support': 1132}
 
----------
Epoch 37/40
time = 1926.21 secondes

Train loss 0.009664884859855623 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984908428383779, 'recall': 0.9983198279417973, 'f1-score': 0.998402181345482, 'support': 10182} weighted_avg {'precision': 0.9984330610506704, 'recall': 0.9984285994892949, 'f1-score': 0.9984279306000589, 'support': 10182}
 
time = 52.74 secondes

Val loss 1.129610355541688 accuracy 0.8878092169761658 macro_avg {'precision': 0.8923239460506778, 'recall': 0.8898042306114557, 'f1-score': 0.8890304484021764, 'support': 1132} weighted_avg {'precision': 0.8937366734051472, 'recall': 0.8878091872791519, 'f1-score': 0.8885696007261187, 'support': 1132}
 
----------
Epoch 38/40
time = 1925.75 secondes

Train loss 0.007589568203100789 accuracy 0.9983304142951965 macro_avg {'precision': 0.9983669476266931, 'recall': 0.9983627998577298, 'f1-score': 0.9983641997127103, 'support': 10182} weighted_avg {'precision': 0.9983309902814754, 'recall': 0.9983303869573757, 'f1-score': 0.9983300171454224, 'support': 10182}
 
time = 49.04 secondes

Val loss 1.1061923502577973 accuracy 0.8904593586921692 macro_avg {'precision': 0.89884907294286, 'recall': 0.891867345420696, 'f1-score': 0.8935320328213084, 'support': 1132} weighted_avg {'precision': 0.8963860370343055, 'recall': 0.8904593639575972, 'f1-score': 0.8913690098553065, 'support': 1132}
 
----------
Epoch 39/40
time = 1929.13 secondes

Train loss 0.007862999214065062 accuracy 0.998821496963501 macro_avg {'precision': 0.998862820977471, 'recall': 0.9988432610494009, 'f1-score': 0.9988511332337288, 'support': 10182} weighted_avg {'precision': 0.9988240631875992, 'recall': 0.9988214496169712, 'f1-score': 0.9988207930402909, 'support': 10182}
 
time = 52.97 secondes

Val loss 1.0694306313768502 accuracy 0.8931095600128174 macro_avg {'precision': 0.8951089535840115, 'recall': 0.8958892082524024, 'f1-score': 0.894471172056261, 'support': 1132} weighted_avg {'precision': 0.8961022608526231, 'recall': 0.8931095406360424, 'f1-score': 0.8935923295626962, 'support': 1132}
 
----------
Epoch 40/40
time = 1923.09 secondes

Train loss 0.00139931480836302 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992924742294085, 'recall': 0.9993102389281765, 'f1-score': 0.9993006996513566, 'support': 10182} weighted_avg {'precision': 0.9993139020345132, 'recall': 0.9993125122765665, 'f1-score': 0.9993125425696948, 'support': 10182}
 
time = 53.29 secondes

Val loss 1.0966424070061613 accuracy 0.8922261595726013 macro_avg {'precision': 0.8940231384011208, 'recall': 0.894137447579635, 'f1-score': 0.8928719143902357, 'support': 1132} weighted_avg {'precision': 0.8953994341185428, 'recall': 0.892226148409894, 'f1-score': 0.8925203626413257, 'support': 1132}
 
----------
best_accuracy 0.8939929604530334 best_epoch 36 macro_avg {'precision': 0.8958798770744021, 'recall': 0.8981414944716875, 'f1-score': 0.8952873443112443, 'support': 1132} weighted_avg {'precision': 0.8971607431497904, 'recall': 0.8939929328621908, 'f1-score': 0.8937159348690917, 'support': 1132}

average train time 1924.466408675909

average val time 52.29433569908142
 
time = 341.87 secondes

test_accuracy 0.8178438544273376 macro_avg {'precision': 0.8155176182049638, 'recall': 0.8116830788520085, 'f1-score': 0.81019355211842, 'support': 7532} weighted_avg {'precision': 0.8237974198027052, 'recall': 0.8178438661710037, 'f1-score': 0.8175809962052483, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 76.01 GiB already allocated; 53.62 MiB free; 77.13 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.39 GiB already allocated; 611.62 MiB free; 76.59 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 491.62 MiB free; 76.70 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_1
----------
Epoch 1/40
time = 581.21 secondes

Train loss 1.0997844924404632 accuracy 0.6861127614974976 macro_avg {'precision': 0.6878223629508194, 'recall': 0.6729178962543869, 'f1-score': 0.6721297509404207, 'support': 10182} weighted_avg {'precision': 0.6956524222591759, 'recall': 0.6861127479866431, 'f1-score': 0.6840004088255723, 'support': 10182}
 
time = 18.82 secondes

Val loss 0.5717216832956797 accuracy 0.833038866519928 macro_avg {'precision': 0.8386367628487523, 'recall': 0.8245681382101415, 'f1-score': 0.8207821860571547, 'support': 1132} weighted_avg {'precision': 0.8378692369447163, 'recall': 0.8330388692579506, 'f1-score': 0.8270416372844065, 'support': 1132}
 
----------
Epoch 2/40
time = 566.75 secondes

Train loss 0.40704016378690344 accuracy 0.8822432160377502 macro_avg {'precision': 0.8752735792271855, 'recall': 0.8745541897813902, 'f1-score': 0.8745763031441725, 'support': 10182} weighted_avg {'precision': 0.8816789860809193, 'recall': 0.8822431742290316, 'f1-score': 0.8816711831440355, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.4574692384143111 accuracy 0.8736749291419983 macro_avg {'precision': 0.881415959764826, 'recall': 0.8741984461779699, 'f1-score': 0.8705682918666191, 'support': 1132} weighted_avg {'precision': 0.8851687665051708, 'recall': 0.8736749116607774, 'f1-score': 0.8718099374204078, 'support': 1132}
 
----------
Epoch 3/40
time = 568.96 secondes

Train loss 0.2454467580552846 accuracy 0.9308584332466125 macro_avg {'precision': 0.927630674171642, 'recall': 0.9272972056209188, 'f1-score': 0.9273796603674984, 'support': 10182} weighted_avg {'precision': 0.9309349970556781, 'recall': 0.9308583775289727, 'f1-score': 0.9308123761028597, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.46486418503402194 accuracy 0.8904593586921692 macro_avg {'precision': 0.8994531005694231, 'recall': 0.8897539196848097, 'f1-score': 0.8882109704176395, 'support': 1132} weighted_avg {'precision': 0.9014696443224971, 'recall': 0.8904593639575972, 'f1-score': 0.888976916863139, 'support': 1132}
 
----------
Epoch 4/40
time = 571.70 secondes

Train loss 0.18130900196583424 accuracy 0.9511883854866028 macro_avg {'precision': 0.94903760794517, 'recall': 0.948972217985596, 'f1-score': 0.9489514067251463, 'support': 10182} weighted_avg {'precision': 0.9514490924990217, 'recall': 0.9511883716362208, 'f1-score': 0.9512675676613145, 'support': 10182}
 
time = 22.31 secondes

Val loss 0.5223398927999267 accuracy 0.9001767039299011 macro_avg {'precision': 0.9037222448145432, 'recall': 0.8952700161461056, 'f1-score': 0.8963815749080849, 'support': 1132} weighted_avg {'precision': 0.9029071593106182, 'recall': 0.9001766784452296, 'f1-score': 0.8990242975910558, 'support': 1132}
 
----------
Epoch 5/40
time = 568.88 secondes

Train loss 0.15910032841529012 accuracy 0.9578668475151062 macro_avg {'precision': 0.9558232171618899, 'recall': 0.9562655842105297, 'f1-score': 0.9559723967517655, 'support': 10182} weighted_avg {'precision': 0.9581461275314505, 'recall': 0.9578668238067177, 'f1-score': 0.9579463864388865, 'support': 10182}
 
time = 21.52 secondes

Val loss 0.5856672568987845 accuracy 0.8922261595726013 macro_avg {'precision': 0.8997137958281142, 'recall': 0.8891268024479665, 'f1-score': 0.8893412214279248, 'support': 1132} weighted_avg {'precision': 0.9011749976596474, 'recall': 0.892226148409894, 'f1-score': 0.8918931685279649, 'support': 1132}
 
----------
Epoch 6/40
time = 569.56 secondes

Train loss 0.13620848548627829 accuracy 0.9667059779167175 macro_avg {'precision': 0.965756837524688, 'recall': 0.9658960181756789, 'f1-score': 0.9657949575553163, 'support': 10182} weighted_avg {'precision': 0.9667920417903485, 'recall': 0.9667059516794343, 'f1-score': 0.9667172703136984, 'support': 10182}
 
time = 22.99 secondes

Val loss 0.6211046260038824 accuracy 0.9001767039299011 macro_avg {'precision': 0.9097708305076235, 'recall': 0.9003060140788355, 'f1-score': 0.9004568033453528, 'support': 1132} weighted_avg {'precision': 0.9077751284901967, 'recall': 0.9001766784452296, 'f1-score': 0.899516949997132, 'support': 1132}
 
----------
Epoch 7/40
time = 568.58 secondes

Train loss 0.14060994152168288 accuracy 0.9674916863441467 macro_avg {'precision': 0.9657636934158909, 'recall': 0.9659428998488201, 'f1-score': 0.9657854557103047, 'support': 10182} weighted_avg {'precision': 0.9675845261329659, 'recall': 0.9674916519347869, 'f1-score': 0.9674697746364863, 'support': 10182}
 
time = 22.47 secondes

Val loss 0.6259111564386715 accuracy 0.8939929604530334 macro_avg {'precision': 0.8969172167054127, 'recall': 0.8933137607148727, 'f1-score': 0.8935809854286839, 'support': 1132} weighted_avg {'precision': 0.8979980680296133, 'recall': 0.8939929328621908, 'f1-score': 0.8944690031342328, 'support': 1132}
 
----------
Epoch 8/40
time = 566.88 secondes

Train loss 0.12771233250257258 accuracy 0.9722058773040771 macro_avg {'precision': 0.9712930916106481, 'recall': 0.9713612746614052, 'f1-score': 0.9712988374532783, 'support': 10182} weighted_avg {'precision': 0.9722540032180205, 'recall': 0.9722058534669024, 'f1-score': 0.9722027082206208, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.5971771128611757 accuracy 0.9054770469665527 macro_avg {'precision': 0.9077629076248632, 'recall': 0.9058117275971055, 'f1-score': 0.9050505492257284, 'support': 1132} weighted_avg {'precision': 0.9098739258728, 'recall': 0.9054770318021201, 'f1-score': 0.9058584177959661, 'support': 1132}
 
----------
Epoch 9/40
time = 569.27 secondes

Train loss 0.11264855949065773 accuracy 0.9746611714363098 macro_avg {'precision': 0.9739610485905796, 'recall': 0.9744113720523837, 'f1-score': 0.9741632925494711, 'support': 10182} weighted_avg {'precision': 0.9747671867878094, 'recall': 0.9746611667648792, 'f1-score': 0.9746959832376051, 'support': 10182}
 
time = 19.98 secondes

Val loss 0.5857540229831422 accuracy 0.9098939895629883 macro_avg {'precision': 0.9151304347258045, 'recall': 0.9098693990078022, 'f1-score': 0.9112148759651747, 'support': 1132} weighted_avg {'precision': 0.913024851243534, 'recall': 0.9098939929328622, 'f1-score': 0.9103827329880712, 'support': 1132}
 
----------
Epoch 10/40
time = 570.71 secondes

Train loss 0.11006642056957473 accuracy 0.9761343598365784 macro_avg {'precision': 0.9755068972550086, 'recall': 0.9747584223271473, 'f1-score': 0.9750624507457555, 'support': 10182} weighted_avg {'precision': 0.976132781160238, 'recall': 0.9761343547436653, 'f1-score': 0.976068707268918, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6262095260428114 accuracy 0.9098939895629883 macro_avg {'precision': 0.912360188045789, 'recall': 0.910753869803209, 'f1-score': 0.9099619377241446, 'support': 1132} weighted_avg {'precision': 0.9132089063022603, 'recall': 0.9098939929328622, 'f1-score': 0.9101099412482753, 'support': 1132}
 
----------
Epoch 11/40
time = 571.36 secondes

Train loss 0.10754663762127509 accuracy 0.978491485118866 macro_avg {'precision': 0.9778355232559915, 'recall': 0.9778824417236158, 'f1-score': 0.9778155073811925, 'support': 10182} weighted_avg {'precision': 0.9785173990910035, 'recall': 0.978491455509723, 'f1-score': 0.9784619337493538, 'support': 10182}
 
time = 23.09 secondes

Val loss 0.7612517384589244 accuracy 0.9019434452056885 macro_avg {'precision': 0.9124614369007716, 'recall': 0.8960991220487523, 'f1-score': 0.8976232884462869, 'support': 1132} weighted_avg {'precision': 0.9098837526415684, 'recall': 0.9019434628975265, 'f1-score': 0.9004680581764399, 'support': 1132}
 
----------
Epoch 12/40
time = 567.28 secondes

Train loss 0.09653138334164213 accuracy 0.9802592992782593 macro_avg {'precision': 0.9792459332568859, 'recall': 0.979399304997498, 'f1-score': 0.9792997853621499, 'support': 10182} weighted_avg {'precision': 0.9803020057989634, 'recall': 0.9802592810842663, 'f1-score': 0.9802576528219215, 'support': 10182}
 
time = 21.97 secondes

Val loss 0.6487794487551019 accuracy 0.9054770469665527 macro_avg {'precision': 0.9087437615091417, 'recall': 0.9048731067367475, 'f1-score': 0.905231778875294, 'support': 1132} weighted_avg {'precision': 0.9080026868659407, 'recall': 0.9054770318021201, 'f1-score': 0.9051446489513533, 'support': 1132}
 
----------
Epoch 13/40
time = 569.78 secondes

Train loss 0.09991124910759806 accuracy 0.9801610708236694 macro_avg {'precision': 0.9798032510074283, 'recall': 0.9799536088097793, 'f1-score': 0.9798268194934746, 'support': 10182} weighted_avg {'precision': 0.9803190081697329, 'recall': 0.9801610685523473, 'f1-score': 0.980189552748413, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.8331731364492108 accuracy 0.8886925578117371 macro_avg {'precision': 0.9099100103909891, 'recall': 0.8941205797277842, 'f1-score': 0.8917505922606492, 'support': 1132} weighted_avg {'precision': 0.9137066256465101, 'recall': 0.8886925795053003, 'f1-score': 0.8897393659258223, 'support': 1132}
 
----------
Epoch 14/40
time = 569.20 secondes

Train loss 0.08957526916527907 accuracy 0.982518196105957 macro_avg {'precision': 0.9819867767028739, 'recall': 0.9819425588172415, 'f1-score': 0.9819311124190329, 'support': 10182} weighted_avg {'precision': 0.9825746384243267, 'recall': 0.9825181693184051, 'f1-score': 0.9825130912895955, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.6198957062387449 accuracy 0.9116607904434204 macro_avg {'precision': 0.9134349767672948, 'recall': 0.9100723979251372, 'f1-score': 0.9088721685778911, 'support': 1132} weighted_avg {'precision': 0.9140991481012057, 'recall': 0.911660777385159, 'f1-score': 0.9105650086600348, 'support': 1132}
 
----------
Epoch 15/40
time = 569.76 secondes

Train loss 0.08130494207590622 accuracy 0.9845806360244751 macro_avg {'precision': 0.9840898004902654, 'recall': 0.9840411981837857, 'f1-score': 0.9840478204553623, 'support': 10182} weighted_avg {'precision': 0.9846198394993596, 'recall': 0.9845806324887055, 'f1-score': 0.9845826195583136, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.736500205383878 accuracy 0.9081271886825562 macro_avg {'precision': 0.9124411749476702, 'recall': 0.9121352855358502, 'f1-score': 0.9100584693671229, 'support': 1132} weighted_avg {'precision': 0.9124594309393222, 'recall': 0.9081272084805654, 'f1-score': 0.9078527377867529, 'support': 1132}
 
----------
Epoch 16/40
time = 567.40 secondes

Train loss 0.07226363240243276 accuracy 0.9861520528793335 macro_avg {'precision': 0.9862162055633202, 'recall': 0.9861244912895429, 'f1-score': 0.9861322053963884, 'support': 10182} weighted_avg {'precision': 0.9862858951762472, 'recall': 0.9861520329994107, 'f1-score': 0.9861800981490159, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.6699839285138296 accuracy 0.9143109321594238 macro_avg {'precision': 0.919009887218945, 'recall': 0.9180488745409587, 'f1-score': 0.9164457886366538, 'support': 1132} weighted_avg {'precision': 0.9173797317646774, 'recall': 0.9143109540636042, 'f1-score': 0.9133762741460606, 'support': 1132}
 
----------
Epoch 17/40
time = 569.99 secondes

Train loss 0.08442813955509931 accuracy 0.9838931560516357 macro_avg {'precision': 0.9837005833034109, 'recall': 0.9830349654779068, 'f1-score': 0.9833334517521821, 'support': 10182} weighted_avg {'precision': 0.9839366444689909, 'recall': 0.983893144765272, 'f1-score': 0.9838838444844287, 'support': 10182}
 
time = 23.12 secondes

Val loss 0.5684089975224146 accuracy 0.9231448769569397 macro_avg {'precision': 0.9275263087349108, 'recall': 0.9224495408941145, 'f1-score': 0.9237667346418574, 'support': 1132} weighted_avg {'precision': 0.9272330022050027, 'recall': 0.9231448763250883, 'f1-score': 0.9239894149203999, 'support': 1132}
 
----------
Epoch 18/40
time = 568.24 secondes

Train loss 0.06837783576344263 accuracy 0.9872323870658875 macro_avg {'precision': 0.9869274373258211, 'recall': 0.9866682103813756, 'f1-score': 0.9867699357841211, 'support': 10182} weighted_avg {'precision': 0.9872889657639354, 'recall': 0.9872323708505205, 'f1-score': 0.9872370432704687, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.7245235085793981 accuracy 0.9019434452056885 macro_avg {'precision': 0.9103656795901724, 'recall': 0.9055475240669517, 'f1-score': 0.9045226453658828, 'support': 1132} weighted_avg {'precision': 0.9104162037090102, 'recall': 0.9019434628975265, 'f1-score': 0.902612953649647, 'support': 1132}
 
----------
Epoch 19/40
time = 567.23 secondes

Train loss 0.06162013111984101 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881464693884302, 'recall': 0.9880874514230653, 'f1-score': 0.9880946116906395, 'support': 10182} weighted_avg {'precision': 0.9886681964847601, 'recall': 0.9886073462973876, 'f1-score': 0.9886157439385127, 'support': 10182}
 
time = 22.87 secondes

Val loss 0.6461030066257849 accuracy 0.916077733039856 macro_avg {'precision': 0.9222679725385026, 'recall': 0.9157488432392521, 'f1-score': 0.9175853248123097, 'support': 1132} weighted_avg {'precision': 0.9190664101156943, 'recall': 0.916077738515901, 'f1-score': 0.9160948459810878, 'support': 1132}
 
----------
Epoch 20/40
time = 568.61 secondes

Train loss 0.06008451648484247 accuracy 0.9890984296798706 macro_avg {'precision': 0.98874886151684, 'recall': 0.9887605574919547, 'f1-score': 0.9887489411941054, 'support': 10182} weighted_avg {'precision': 0.989121544417881, 'recall': 0.9890984089569829, 'f1-score': 0.9891039599151528, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6826558990370601 accuracy 0.916077733039856 macro_avg {'precision': 0.9213986751742551, 'recall': 0.9159593516187297, 'f1-score': 0.9174591064194658, 'support': 1132} weighted_avg {'precision': 0.9193517622238973, 'recall': 0.916077738515901, 'f1-score': 0.9165032112474463, 'support': 1132}
 
----------
Epoch 21/40
time = 570.98 secondes

Train loss 0.07264790180803743 accuracy 0.9883127212524414 macro_avg {'precision': 0.9882600986131267, 'recall': 0.988292285424785, 'f1-score': 0.9882634871463777, 'support': 10182} weighted_avg {'precision': 0.9883421597300297, 'recall': 0.9883127087016303, 'f1-score': 0.9883143358434967, 'support': 10182}
 
time = 22.53 secondes

Val loss 0.7115465479812332 accuracy 0.916077733039856 macro_avg {'precision': 0.9180924077298851, 'recall': 0.9203140810930895, 'f1-score': 0.9172304573723012, 'support': 1132} weighted_avg {'precision': 0.9197443915952173, 'recall': 0.916077738515901, 'f1-score': 0.9157364139538529, 'support': 1132}
 
----------
Epoch 22/40
time = 567.57 secondes

Train loss 0.04627847142944164 accuracy 0.990669846534729 macro_avg {'precision': 0.9906670496917711, 'recall': 0.9906100764986853, 'f1-score': 0.990629723707789, 'support': 10182} weighted_avg {'precision': 0.9906914782148939, 'recall': 0.9906698094676881, 'f1-score': 0.9906723223391357, 'support': 10182}
 
time = 22.47 secondes

Val loss 0.7149649650467401 accuracy 0.9072438478469849 macro_avg {'precision': 0.914228594271189, 'recall': 0.9064139816869741, 'f1-score': 0.9078804801969493, 'support': 1132} weighted_avg {'precision': 0.9109863264063237, 'recall': 0.907243816254417, 'f1-score': 0.9067905086601493, 'support': 1132}
 
----------
Epoch 23/40
time = 565.67 secondes

Train loss 0.05535319043619508 accuracy 0.9901787638664246 macro_avg {'precision': 0.990186951100212, 'recall': 0.990124147630481, 'f1-score': 0.9901497003195704, 'support': 10182} weighted_avg {'precision': 0.9901917663371294, 'recall': 0.9901787468080927, 'f1-score': 0.9901792908721005, 'support': 10182}
 
time = 22.96 secondes

Val loss 0.6508283611105404 accuracy 0.9240282773971558 macro_avg {'precision': 0.9366664094952825, 'recall': 0.9259534090111563, 'f1-score': 0.9288168137690798, 'support': 1132} weighted_avg {'precision': 0.9342302780459693, 'recall': 0.9240282685512368, 'f1-score': 0.9261973176748851, 'support': 1132}
 
----------
Epoch 24/40
time = 568.55 secondes

Train loss 0.06327921495516081 accuracy 0.98978590965271 macro_avg {'precision': 0.9898740157385616, 'recall': 0.989846709156674, 'f1-score': 0.9898421761775588, 'support': 10182} weighted_avg {'precision': 0.9898389475204836, 'recall': 0.9897858966804164, 'f1-score': 0.9897938642701466, 'support': 10182}
 
time = 21.87 secondes

Val loss 0.5872606872270436 accuracy 0.9240282773971558 macro_avg {'precision': 0.9278130874820842, 'recall': 0.9248879966636677, 'f1-score': 0.9250840209268002, 'support': 1132} weighted_avg {'precision': 0.9283898956116178, 'recall': 0.9240282685512368, 'f1-score': 0.9249206197611685, 'support': 1132}
 
----------
Epoch 25/40
time = 568.38 secondes

Train loss 0.055695615151800305 accuracy 0.9902769923210144 macro_avg {'precision': 0.989638540545163, 'recall': 0.9899676315543582, 'f1-score': 0.9897862839603734, 'support': 10182} weighted_avg {'precision': 0.9903207138817037, 'recall': 0.9902769593400118, 'f1-score': 0.9902846998738876, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.6996566899744695 accuracy 0.9178445339202881 macro_avg {'precision': 0.9228005448663922, 'recall': 0.9191730097156443, 'f1-score': 0.9198230069121912, 'support': 1132} weighted_avg {'precision': 0.9210933833101572, 'recall': 0.9178445229681979, 'f1-score': 0.9182307356314999, 'support': 1132}
 
----------
Epoch 26/40
time = 567.84 secondes

Train loss 0.05720731950577186 accuracy 0.9898841381072998 macro_avg {'precision': 0.9898395035750791, 'recall': 0.9893704645747586, 'f1-score': 0.9895835952250518, 'support': 10182} weighted_avg {'precision': 0.9899250104888522, 'recall': 0.9898841092123355, 'f1-score': 0.9898851433263859, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.745639404899098 accuracy 0.9116607904434204 macro_avg {'precision': 0.9194050032652497, 'recall': 0.9131450484667027, 'f1-score': 0.9144200376384657, 'support': 1132} weighted_avg {'precision': 0.9152045567947985, 'recall': 0.911660777385159, 'f1-score': 0.911415288268597, 'support': 1132}
 
----------
Epoch 27/40
time = 570.83 secondes

Train loss 0.03986610048967728 accuracy 0.9918484091758728 macro_avg {'precision': 0.9919231049033768, 'recall': 0.991785135863292, 'f1-score': 0.9918458545143632, 'support': 10182} weighted_avg {'precision': 0.9918595256574687, 'recall': 0.991848359850717, 'f1-score': 0.9918455083480605, 'support': 10182}
 
time = 22.49 secondes

Val loss 0.6731796365278006 accuracy 0.9178445339202881 macro_avg {'precision': 0.9208235796663387, 'recall': 0.9190095045331848, 'f1-score': 0.9181915026624416, 'support': 1132} weighted_avg {'precision': 0.9209932670079181, 'recall': 0.9178445229681979, 'f1-score': 0.9176805744553524, 'support': 1132}
 
----------
Epoch 28/40
time = 568.50 secondes

Train loss 0.032457609364185486 accuracy 0.9933215975761414 macro_avg {'precision': 0.9928703029951341, 'recall': 0.9927731606546549, 'f1-score': 0.9928084945106965, 'support': 10182} weighted_avg {'precision': 0.993347949064254, 'recall': 0.993321547829503, 'f1-score': 0.9933224560846786, 'support': 10182}
 
time = 22.99 secondes

Val loss 0.6252692301897415 accuracy 0.9222614765167236 macro_avg {'precision': 0.9244180129375724, 'recall': 0.9239414973762999, 'f1-score': 0.9229170114160116, 'support': 1132} weighted_avg {'precision': 0.9250430125543274, 'recall': 0.9222614840989399, 'f1-score': 0.9223270133362111, 'support': 1132}
 
----------
Epoch 29/40
time = 568.54 secondes

Train loss 0.033094426515419925 accuracy 0.9944019317626953 macro_avg {'precision': 0.994266865963646, 'recall': 0.9944099948202224, 'f1-score': 0.9943267563565771, 'support': 10182} weighted_avg {'precision': 0.9944343699938575, 'recall': 0.9944018856806128, 'f1-score': 0.994407527818004, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.6935569354699651 accuracy 0.916077733039856 macro_avg {'precision': 0.9191349646753567, 'recall': 0.9199074823319904, 'f1-score': 0.9179013286697536, 'support': 1132} weighted_avg {'precision': 0.9194420309525343, 'recall': 0.916077738515901, 'f1-score': 0.9160193615350452, 'support': 1132}
 
----------
Epoch 30/40
time = 570.31 secondes

Train loss 0.02754991813643794 accuracy 0.9953840374946594 macro_avg {'precision': 0.9951300532390805, 'recall': 0.9951662566650572, 'f1-score': 0.9951445103633233, 'support': 10182} weighted_avg {'precision': 0.9953912520521064, 'recall': 0.9953840109998036, 'f1-score': 0.9953838635348673, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.8568371036420962 accuracy 0.9054770469665527 macro_avg {'precision': 0.9145535951779165, 'recall': 0.9107899892302747, 'f1-score': 0.9092286228580473, 'support': 1132} weighted_avg {'precision': 0.9160403352328731, 'recall': 0.9054770318021201, 'f1-score': 0.9071584973952783, 'support': 1132}
 
----------
Epoch 31/40
time = 566.75 secondes

Train loss 0.030780450883074743 accuracy 0.9947947859764099 macro_avg {'precision': 0.9945845669913982, 'recall': 0.9949203821561211, 'f1-score': 0.9947385138220188, 'support': 10182} weighted_avg {'precision': 0.9948274471324077, 'recall': 0.9947947358082891, 'f1-score': 0.9947991777831807, 'support': 10182}
 
time = 21.46 secondes

Val loss 0.640830552365412 accuracy 0.9204947352409363 macro_avg {'precision': 0.9206119024416003, 'recall': 0.922666832475801, 'f1-score': 0.9208566674404374, 'support': 1132} weighted_avg {'precision': 0.9224254223788018, 'recall': 0.9204946996466431, 'f1-score': 0.9206773631391556, 'support': 1132}
 
----------
Epoch 32/40
time = 569.22 secondes

Train loss 0.02501534679010677 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959612091258544, 'recall': 0.9959994597358144, 'f1-score': 0.9959732117381881, 'support': 10182} weighted_avg {'precision': 0.9958879975482428, 'recall': 0.995875073659399, 'f1-score': 0.9958741771530268, 'support': 10182}
 
time = 23.05 secondes

Val loss 0.730176873688193 accuracy 0.9125441908836365 macro_avg {'precision': 0.9190780866840615, 'recall': 0.9177783618009501, 'f1-score': 0.9161540633403641, 'support': 1132} weighted_avg {'precision': 0.9198549743026266, 'recall': 0.9125441696113075, 'f1-score': 0.9137067885166853, 'support': 1132}
 
----------
Epoch 33/40
time = 569.17 secondes

Train loss 0.02540881446326336 accuracy 0.9959732890129089 macro_avg {'precision': 0.9960479369506793, 'recall': 0.995878459398868, 'f1-score': 0.9959595869896158, 'support': 10182} weighted_avg {'precision': 0.9959795809782355, 'recall': 0.995973286191318, 'f1-score': 0.9959731031817924, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.6662445256722133 accuracy 0.9275618195533752 macro_avg {'precision': 0.9336782565302391, 'recall': 0.9300994181729199, 'f1-score': 0.9300195454945219, 'support': 1132} weighted_avg {'precision': 0.9313546021075164, 'recall': 0.9275618374558304, 'f1-score': 0.9274345345013225, 'support': 1132}
 
----------
Epoch 34/40
time = 568.89 secondes

Train loss 0.022051664146526307 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961429014884177, 'recall': 0.9960567308486814, 'f1-score': 0.9960966677107267, 'support': 10182} weighted_avg {'precision': 0.9961748919567782, 'recall': 0.9961697112551562, 'f1-score': 0.9961691038634074, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.6422726279879882 accuracy 0.9257950782775879 macro_avg {'precision': 0.9270609073772021, 'recall': 0.927334133542189, 'f1-score': 0.9263920139445634, 'support': 1132} weighted_avg {'precision': 0.9285323346284616, 'recall': 0.9257950530035336, 'f1-score': 0.9263256754760463, 'support': 1132}
 
----------
Epoch 35/40
time = 569.13 secondes

Train loss 0.023852976278935876 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967579748735433, 'recall': 0.9968296127425121, 'f1-score': 0.9967919630907008, 'support': 10182} weighted_avg {'precision': 0.9967647868615698, 'recall': 0.9967589864466706, 'f1-score': 0.9967600652448388, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.7615392201561251 accuracy 0.9187279343605042 macro_avg {'precision': 0.9211051131337198, 'recall': 0.9218576191198921, 'f1-score': 0.9195387567184776, 'support': 1132} weighted_avg {'precision': 0.9238320603744885, 'recall': 0.9187279151943463, 'f1-score': 0.9192571856841164, 'support': 1132}
 
----------
Epoch 36/40
time = 567.32 secondes

Train loss 0.01369270134272536 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977032552777985, 'recall': 0.9976916292537913, 'f1-score': 0.9976964188037002, 'support': 10182} weighted_avg {'precision': 0.9976454979759907, 'recall': 0.9976428992339422, 'f1-score': 0.9976431610623315, 'support': 10182}
 
time = 21.89 secondes

Val loss 0.7570653648613893 accuracy 0.9178445339202881 macro_avg {'precision': 0.9205535380787901, 'recall': 0.9215436539892039, 'f1-score': 0.9195183530830746, 'support': 1132} weighted_avg {'precision': 0.9218094958718972, 'recall': 0.9178445229681979, 'f1-score': 0.9182585164764622, 'support': 1132}
 
----------
Epoch 37/40
time = 567.43 secondes

Train loss 0.00997892185016664 accuracy 0.9982321858406067 macro_avg {'precision': 0.9982460861740521, 'recall': 0.9982607131334602, 'f1-score': 0.9982491342914181, 'support': 10182} weighted_avg {'precision': 0.9982419307037276, 'recall': 0.9982321744254566, 'f1-score': 0.9982327240097675, 'support': 10182}
 
time = 22.95 secondes

Val loss 0.7021187144034652 accuracy 0.9213780760765076 macro_avg {'precision': 0.9274487700382018, 'recall': 0.9250196409626212, 'f1-score': 0.924276953604703, 'support': 1132} weighted_avg {'precision': 0.928108178508317, 'recall': 0.9213780918727915, 'f1-score': 0.9227715392228071, 'support': 1132}
 
----------
Epoch 38/40
time = 568.35 secondes

Train loss 0.007034634148214045 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986823890283881, 'recall': 0.9986385616001732, 'f1-score': 0.9986594091860332, 'support': 10182} weighted_avg {'precision': 0.9986266755670796, 'recall': 0.998625024553133, 'f1-score': 0.9986247926292628, 'support': 10182}
 
time = 23.03 secondes

Val loss 0.7297383999649983 accuracy 0.9213780760765076 macro_avg {'precision': 0.9273215708110456, 'recall': 0.9244346094494826, 'f1-score': 0.9236617758271011, 'support': 1132} weighted_avg {'precision': 0.9279772669766249, 'recall': 0.9213780918727915, 'f1-score': 0.9223094224211992, 'support': 1132}
 
----------
Epoch 39/40
time = 567.33 secondes

Train loss 0.0038555220481002535 accuracy 0.998919665813446 macro_avg {'precision': 0.9989550398228026, 'recall': 0.9989585218583039, 'f1-score': 0.9989563442116005, 'support': 10182} weighted_avg {'precision': 0.9989209513446808, 'recall': 0.9989196621488902, 'f1-score': 0.9989198480450608, 'support': 10182}
 
time = 23.10 secondes

Val loss 0.6610273372210377 accuracy 0.926678478717804 macro_avg {'precision': 0.931425210021635, 'recall': 0.9288085050576769, 'f1-score': 0.928744926798486, 'support': 1132} weighted_avg {'precision': 0.9312726613707057, 'recall': 0.926678445229682, 'f1-score': 0.9275206493644735, 'support': 1132}
 
----------
Epoch 40/40
time = 566.85 secondes

Train loss 0.001980297838251276 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994290350638242, 'recall': 0.9994295411549491, 'f1-score': 0.9994284700236122, 'support': 10182} weighted_avg {'precision': 0.9994122226199517, 'recall': 0.9994107248084856, 'f1-score': 0.9994106317396382, 'support': 10182}
 
time = 22.79 secondes

Val loss 0.6384202894389321 accuracy 0.9337455630302429 macro_avg {'precision': 0.9356420141771536, 'recall': 0.9364045709811245, 'f1-score': 0.934549535413906, 'support': 1132} weighted_avg {'precision': 0.9374851619329218, 'recall': 0.9337455830388692, 'f1-score': 0.9340527406543453, 'support': 1132}
 
----------
best_accuracy 0.9337455630302429 best_epoch 40 macro_avg {'precision': 0.9356420141771536, 'recall': 0.9364045709811245, 'f1-score': 0.934549535413906, 'support': 1132} weighted_avg {'precision': 0.9374851619329218, 'recall': 0.9337455830388692, 'f1-score': 0.9340527406543453, 'support': 1132}

average train time 568.973794388771

average val time 22.61776723265648
 
time = 135.37 secondes

test_accuracy 0.8571428060531616 macro_avg {'precision': 0.852638320366168, 'recall': 0.8505574077051123, 'f1-score': 0.8501829177548832, 'support': 7532} weighted_avg {'precision': 0.8603521296097905, 'recall': 0.8571428571428571, 'f1-score': 0.8576074944622527, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_1
----------
Epoch 1/40
time = 757.44 secondes

Train loss 1.067798031344893 accuracy 0.7016303539276123 macro_avg {'precision': 0.689415715612215, 'recall': 0.6873953178033035, 'f1-score': 0.6813353605589858, 'support': 10182} weighted_avg {'precision': 0.6985808428468387, 'recall': 0.7016303280298566, 'f1-score': 0.6942105389661598, 'support': 10182}
 
time = 27.12 secondes

Val loss 0.6049767572065474 accuracy 0.8197879791259766 macro_avg {'precision': 0.8000029032443076, 'recall': 0.8064661812888614, 'f1-score': 0.7945626610029521, 'support': 1132} weighted_avg {'precision': 0.8118149894148093, 'recall': 0.8197879858657244, 'f1-score': 0.8081064907337447, 'support': 1132}
 
----------
Epoch 2/40
time = 741.15 secondes

Train loss 0.4077547368516026 accuracy 0.8780200481414795 macro_avg {'precision': 0.870404540927687, 'recall': 0.8691917050025317, 'f1-score': 0.8688421552855854, 'support': 10182} weighted_avg {'precision': 0.8766509772448181, 'recall': 0.8780200353565115, 'f1-score': 0.876601743382305, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.48729738514398185 accuracy 0.8745583295822144 macro_avg {'precision': 0.8769273775755242, 'recall': 0.8787816769406641, 'f1-score': 0.872815410815921, 'support': 1132} weighted_avg {'precision': 0.8806972839958443, 'recall': 0.8745583038869258, 'f1-score': 0.8718304747764215, 'support': 1132}
 
----------
Epoch 3/40
time = 741.75 secondes

Train loss 0.24104407903836278 accuracy 0.9345904588699341 macro_avg {'precision': 0.9308374427709826, 'recall': 0.9306607443701169, 'f1-score': 0.9306834539630184, 'support': 10182} weighted_avg {'precision': 0.9347949329092828, 'recall': 0.9345904537418974, 'f1-score': 0.9346334951694397, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.5053113101076492 accuracy 0.8789752721786499 macro_avg {'precision': 0.8874284098661713, 'recall': 0.8825021677097402, 'f1-score': 0.878670691712248, 'support': 1132} weighted_avg {'precision': 0.8851961714552051, 'recall': 0.8789752650176679, 'f1-score': 0.8746082308992357, 'support': 1132}
 
----------
Epoch 4/40
time = 741.20 secondes

Train loss 0.18862622271341623 accuracy 0.9517776966094971 macro_avg {'precision': 0.9491331330812077, 'recall': 0.9491934063633485, 'f1-score': 0.9491056183875667, 'support': 10182} weighted_avg {'precision': 0.9517881990343844, 'recall': 0.9517776468277352, 'f1-score': 0.9517269059898908, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.47849033646036304 accuracy 0.9037102460861206 macro_avg {'precision': 0.9064522498775689, 'recall': 0.903021260865628, 'f1-score': 0.9025512358044846, 'support': 1132} weighted_avg {'precision': 0.9068567752098445, 'recall': 0.9037102473498233, 'f1-score': 0.9030229745179893, 'support': 1132}
 
----------
Epoch 5/40
time = 741.94 secondes

Train loss 0.1570842513628889 accuracy 0.9607149958610535 macro_avg {'precision': 0.9590935258319517, 'recall': 0.9592323627386905, 'f1-score': 0.9591047836515774, 'support': 10182} weighted_avg {'precision': 0.9608061731015225, 'recall': 0.9607149872323708, 'f1-score': 0.9607030377387079, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.4913541349356102 accuracy 0.9134275913238525 macro_avg {'precision': 0.9171615251855905, 'recall': 0.9133468571773822, 'f1-score': 0.9133161864822743, 'support': 1132} weighted_avg {'precision': 0.9170058604104768, 'recall': 0.9134275618374559, 'f1-score': 0.9131924362827103, 'support': 1132}
 
----------
Epoch 6/40
time = 739.46 secondes

Train loss 0.14387712991570548 accuracy 0.9650363922119141 macro_avg {'precision': 0.9644483074996104, 'recall': 0.9639398180333252, 'f1-score': 0.9641373466839761, 'support': 10182} weighted_avg {'precision': 0.9651564569770116, 'recall': 0.96503633863681, 'f1-score': 0.9650399736606838, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.5941956521070917 accuracy 0.9010601043701172 macro_avg {'precision': 0.9087130626164951, 'recall': 0.904106062241468, 'f1-score': 0.9020721243246707, 'support': 1132} weighted_avg {'precision': 0.9110418150152381, 'recall': 0.901060070671378, 'f1-score': 0.9012349700227741, 'support': 1132}
 
----------
Epoch 7/40
time = 740.34 secondes

Train loss 0.1268328278786225 accuracy 0.9711255431175232 macro_avg {'precision': 0.9698964663775718, 'recall': 0.9699187050218538, 'f1-score': 0.969887022683349, 'support': 10182} weighted_avg {'precision': 0.9711429816988653, 'recall': 0.9711255156157925, 'f1-score': 0.9711136218923345, 'support': 10182}
 
time = 26.25 secondes

Val loss 0.6087041122873288 accuracy 0.9001767039299011 macro_avg {'precision': 0.9010504480137825, 'recall': 0.9018885770338209, 'f1-score': 0.899518362023127, 'support': 1132} weighted_avg {'precision': 0.9048404257681146, 'recall': 0.9001766784452296, 'f1-score': 0.9005891660784079, 'support': 1132}
 
----------
Epoch 8/40
time = 741.28 secondes

Train loss 0.12267424219932693 accuracy 0.9727951288223267 macro_avg {'precision': 0.9718982569062966, 'recall': 0.9720439141144359, 'f1-score': 0.971942871547804, 'support': 10182} weighted_avg {'precision': 0.9728877353027319, 'recall': 0.9727951286584168, 'f1-score': 0.9728157699428968, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.7390257180537242 accuracy 0.8772084712982178 macro_avg {'precision': 0.8947629361430172, 'recall': 0.8793656261027577, 'f1-score': 0.8764685992162213, 'support': 1132} weighted_avg {'precision': 0.8959454185051968, 'recall': 0.877208480565371, 'f1-score': 0.8752764375775305, 'support': 1132}
 
----------
Epoch 9/40
time = 739.56 secondes

Train loss 0.10797943744127306 accuracy 0.9750540256500244 macro_avg {'precision': 0.974545506609506, 'recall': 0.9747651665969486, 'f1-score': 0.9746316201061417, 'support': 10182} weighted_avg {'precision': 0.9750917306914992, 'recall': 0.9750540168925554, 'f1-score': 0.9750492939097616, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.6898673409087793 accuracy 0.8931095600128174 macro_avg {'precision': 0.8969710111571981, 'recall': 0.8953717822494559, 'f1-score': 0.89382870907819, 'support': 1132} weighted_avg {'precision': 0.8979701368656378, 'recall': 0.8931095406360424, 'f1-score': 0.8930800472332661, 'support': 1132}
 
----------
Epoch 10/40
time = 738.80 secondes

Train loss 0.11189251246354419 accuracy 0.9760361909866333 macro_avg {'precision': 0.9754492627051926, 'recall': 0.9756425731229251, 'f1-score': 0.9755221451747831, 'support': 10182} weighted_avg {'precision': 0.9761050241731488, 'recall': 0.9760361422117462, 'f1-score': 0.9760487238585813, 'support': 10182}
 
time = 25.58 secondes

Val loss 0.6636729107648676 accuracy 0.9054770469665527 macro_avg {'precision': 0.9088054598813938, 'recall': 0.9068251659899687, 'f1-score': 0.905353969448546, 'support': 1132} weighted_avg {'precision': 0.9080374590342742, 'recall': 0.9054770318021201, 'f1-score': 0.9042233349822986, 'support': 1132}
 
----------
Epoch 11/40
time = 738.28 secondes

Train loss 0.11567561895711921 accuracy 0.9772146940231323 macro_avg {'precision': 0.9768793978402586, 'recall': 0.9767335666253425, 'f1-score': 0.9767920544436299, 'support': 10182} weighted_avg {'precision': 0.9772425450326749, 'recall': 0.9772146925947751, 'f1-score': 0.9772141093347688, 'support': 10182}
 
time = 26.29 secondes

Val loss 0.8265081515790268 accuracy 0.8842756152153015 macro_avg {'precision': 0.9029671822847629, 'recall': 0.8887484523746976, 'f1-score': 0.8886394404409476, 'support': 1132} weighted_avg {'precision': 0.9001169007102447, 'recall': 0.8842756183745583, 'f1-score': 0.8838538945298537, 'support': 1132}
 
----------
Epoch 12/40
time = 741.21 secondes

Train loss 0.09651679695758686 accuracy 0.9776075482368469 macro_avg {'precision': 0.9767307007138275, 'recall': 0.9767740991880428, 'f1-score': 0.9767121791895915, 'support': 10182} weighted_avg {'precision': 0.9776567980682875, 'recall': 0.9776075427224514, 'f1-score': 0.9775945693256013, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.7057185967302796 accuracy 0.9028268456459045 macro_avg {'precision': 0.9119201211053405, 'recall': 0.9050814109134716, 'f1-score': 0.9047944394179981, 'support': 1132} weighted_avg {'precision': 0.9106397920822509, 'recall': 0.9028268551236749, 'f1-score': 0.9031768082140432, 'support': 1132}
 
----------
Epoch 13/40
time = 741.89 secondes

Train loss 0.0914899179829998 accuracy 0.9817324876785278 macro_avg {'precision': 0.9808155208506436, 'recall': 0.9806251332649193, 'f1-score': 0.9807021507235454, 'support': 10182} weighted_avg {'precision': 0.9817422267753262, 'recall': 0.9817324690630524, 'f1-score': 0.9817202808088199, 'support': 10182}
 
time = 26.36 secondes

Val loss 0.7198496686920203 accuracy 0.8939929604530334 macro_avg {'precision': 0.905193419412373, 'recall': 0.8945004097507139, 'f1-score': 0.8965854329068469, 'support': 1132} weighted_avg {'precision': 0.902465658438745, 'recall': 0.8939929328621908, 'f1-score': 0.8949362891991499, 'support': 1132}
 
----------
Epoch 14/40
time = 741.40 secondes

Train loss 0.08021377659931134 accuracy 0.9835003018379211 macro_avg {'precision': 0.98352976282507, 'recall': 0.983429661311743, 'f1-score': 0.9834665350982938, 'support': 10182} weighted_avg {'precision': 0.9835243517991831, 'recall': 0.9835002946375958, 'f1-score': 0.9834990932826536, 'support': 10182}
 
time = 26.70 secondes

Val loss 0.7022605328004918 accuracy 0.9054770469665527 macro_avg {'precision': 0.9082206715100117, 'recall': 0.9045674406018878, 'f1-score': 0.9043507389329871, 'support': 1132} weighted_avg {'precision': 0.9093112365325018, 'recall': 0.9054770318021201, 'f1-score': 0.9053941134629477, 'support': 1132}
 
----------
Epoch 15/40
time = 741.82 secondes

Train loss 0.0790946289721611 accuracy 0.9839913845062256 macro_avg {'precision': 0.983434350194518, 'recall': 0.9833472495411666, 'f1-score': 0.9833685104709591, 'support': 10182} weighted_avg {'precision': 0.9840417513531857, 'recall': 0.9839913572971911, 'f1-score': 0.9839951398787784, 'support': 10182}
 
time = 26.66 secondes

Val loss 0.742345088355622 accuracy 0.8975265026092529 macro_avg {'precision': 0.9084385328930861, 'recall': 0.9000980199530375, 'f1-score': 0.9014797196933234, 'support': 1132} weighted_avg {'precision': 0.9070391224516714, 'recall': 0.8975265017667845, 'f1-score': 0.899290309320324, 'support': 1132}
 
----------
Epoch 16/40
time = 741.65 secondes

Train loss 0.08041946146893471 accuracy 0.985660970211029 macro_avg {'precision': 0.9856194615547731, 'recall': 0.9850751147582638, 'f1-score': 0.985323247579873, 'support': 10182} weighted_avg {'precision': 0.9856764666022644, 'recall': 0.9856609703398154, 'f1-score': 0.985647899550956, 'support': 10182}
 
time = 26.52 secondes

Val loss 0.769576097836531 accuracy 0.9037102460861206 macro_avg {'precision': 0.9068528839497777, 'recall': 0.9053150481951061, 'f1-score': 0.9028945254021863, 'support': 1132} weighted_avg {'precision': 0.9121460600617717, 'recall': 0.9037102473498233, 'f1-score': 0.9053154300903647, 'support': 1132}
 
----------
Epoch 17/40
time = 739.88 secondes

Train loss 0.08199295089703022 accuracy 0.9843842387199402 macro_avg {'precision': 0.9839996172202279, 'recall': 0.9838387656725741, 'f1-score': 0.9838822683010452, 'support': 10182} weighted_avg {'precision': 0.9844269472042982, 'recall': 0.9843842074248674, 'f1-score': 0.9843679668682467, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.7372903117996519 accuracy 0.9054770469665527 macro_avg {'precision': 0.9120023222328577, 'recall': 0.9067428365018685, 'f1-score': 0.9076047656091356, 'support': 1132} weighted_avg {'precision': 0.9109331477884002, 'recall': 0.9054770318021201, 'f1-score': 0.9063305675357956, 'support': 1132}
 
----------
Epoch 18/40
time = 740.74 secondes

Train loss 0.07239913372410411 accuracy 0.9866431355476379 macro_avg {'precision': 0.9858954866972613, 'recall': 0.9859583950976148, 'f1-score': 0.9859224639008856, 'support': 10182} weighted_avg {'precision': 0.9866642342375027, 'recall': 0.9866430956590061, 'f1-score': 0.9866493265396147, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.6861671443846614 accuracy 0.9090105891227722 macro_avg {'precision': 0.9127632989568417, 'recall': 0.9102842402810751, 'f1-score': 0.9093280172921888, 'support': 1132} weighted_avg {'precision': 0.9134039445898802, 'recall': 0.9090106007067138, 'f1-score': 0.9091041899072085, 'support': 1132}
 
----------
Epoch 19/40
time = 738.37 secondes

Train loss 0.06984597953873037 accuracy 0.985562801361084 macro_avg {'precision': 0.98533777249865, 'recall': 0.985311776637209, 'f1-score': 0.9853048527155084, 'support': 10182} weighted_avg {'precision': 0.9856540620623843, 'recall': 0.9855627578078963, 'f1-score': 0.9855883157343173, 'support': 10182}
 
time = 26.63 secondes

Val loss 0.6924549462039041 accuracy 0.916077733039856 macro_avg {'precision': 0.9202099043302393, 'recall': 0.9195242837868183, 'f1-score': 0.9175606425781451, 'support': 1132} weighted_avg {'precision': 0.9212210884517269, 'recall': 0.916077738515901, 'f1-score': 0.9163553080387207, 'support': 1132}
 
----------
Epoch 20/40
time = 741.87 secondes

Train loss 0.05960764062768261 accuracy 0.9889020323753357 macro_avg {'precision': 0.9889904292166264, 'recall': 0.9888139177566625, 'f1-score': 0.9888876332920307, 'support': 10182} weighted_avg {'precision': 0.9889328856205835, 'recall': 0.9889019838931448, 'f1-score': 0.9889027163760898, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.803423566248454 accuracy 0.8992933034896851 macro_avg {'precision': 0.9110905595391937, 'recall': 0.9008805228219268, 'f1-score': 0.9018995167338888, 'support': 1132} weighted_avg {'precision': 0.9109057465043133, 'recall': 0.8992932862190812, 'f1-score': 0.9007011097203244, 'support': 1132}
 
----------
Epoch 21/40
time = 741.00 secondes

Train loss 0.06990170718090152 accuracy 0.987625241279602 macro_avg {'precision': 0.9875345238523895, 'recall': 0.9874866263078026, 'f1-score': 0.9875001570044841, 'support': 10182} weighted_avg {'precision': 0.9876471953310395, 'recall': 0.9876252209781968, 'f1-score': 0.9876262640324085, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.6673800612403334 accuracy 0.9151943325996399 macro_avg {'precision': 0.9162917830525578, 'recall': 0.9150399117287342, 'f1-score': 0.9148216850611461, 'support': 1132} weighted_avg {'precision': 0.9177255489919146, 'recall': 0.9151943462897526, 'f1-score': 0.9156309148219633, 'support': 1132}
 
----------
Epoch 22/40
time = 738.51 secondes

Train loss 0.0603438206285097 accuracy 0.9894912838935852 macro_avg {'precision': 0.9891432796650415, 'recall': 0.9892950628494843, 'f1-score': 0.9892011211073545, 'support': 10182} weighted_avg {'precision': 0.9895282727046321, 'recall': 0.9894912590846592, 'f1-score': 0.989493811728639, 'support': 10182}
 
time = 26.25 secondes

Val loss 0.6747164836486033 accuracy 0.9151943325996399 macro_avg {'precision': 0.9170414508360965, 'recall': 0.9160886874918981, 'f1-score': 0.9150041167005958, 'support': 1132} weighted_avg {'precision': 0.9189854188021072, 'recall': 0.9151943462897526, 'f1-score': 0.915681508816901, 'support': 1132}
 
----------
Epoch 23/40
time = 740.28 secondes

Train loss 0.04946355698713139 accuracy 0.9910627007484436 macro_avg {'precision': 0.990923219199398, 'recall': 0.9910935628481324, 'f1-score': 0.991000887336741, 'support': 10182} weighted_avg {'precision': 0.9910762974295053, 'recall': 0.9910626595953643, 'f1-score': 0.9910628047612561, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.6650558603356894 accuracy 0.9125441908836365 macro_avg {'precision': 0.9153826219095352, 'recall': 0.9150549698631691, 'f1-score': 0.913675770313057, 'support': 1132} weighted_avg {'precision': 0.918230788594679, 'recall': 0.9125441696113075, 'f1-score': 0.9139862238245208, 'support': 1132}
 
----------
Epoch 24/40
time = 740.27 secondes

Train loss 0.052766339043718656 accuracy 0.9908662438392639 macro_avg {'precision': 0.9907926013721167, 'recall': 0.9906270979786591, 'f1-score': 0.9906934524776357, 'support': 10182} weighted_avg {'precision': 0.9908706467046494, 'recall': 0.9908662345315262, 'f1-score': 0.9908526961480695, 'support': 10182}
 
time = 23.64 secondes

Val loss 0.657197671531065 accuracy 0.9204947352409363 macro_avg {'precision': 0.9260149249062577, 'recall': 0.9207762954249082, 'f1-score': 0.9221204507028384, 'support': 1132} weighted_avg {'precision': 0.9239464152651099, 'recall': 0.9204946996466431, 'f1-score': 0.920915201980197, 'support': 1132}
 
----------
Epoch 25/40
time = 740.30 secondes

Train loss 0.059204727546806266 accuracy 0.9889020323753357 macro_avg {'precision': 0.9888869132805848, 'recall': 0.9887595055213557, 'f1-score': 0.9887831356245611, 'support': 10182} weighted_avg {'precision': 0.9889915182621664, 'recall': 0.9889019838931448, 'f1-score': 0.9889057062056977, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.7011238908911969 accuracy 0.9098939895629883 macro_avg {'precision': 0.9145265498540385, 'recall': 0.9138268047137597, 'f1-score': 0.912098840550885, 'support': 1132} weighted_avg {'precision': 0.9148943048924367, 'recall': 0.9098939929328622, 'f1-score': 0.9103216210774013, 'support': 1132}
 
----------
Epoch 26/40
time = 741.31 secondes

Train loss 0.04673843390219547 accuracy 0.9929287433624268 macro_avg {'precision': 0.9925480788181538, 'recall': 0.9924104668513885, 'f1-score': 0.9924619902747309, 'support': 10182} weighted_avg {'precision': 0.9929375995355554, 'recall': 0.9929286977018268, 'f1-score': 0.9929170895513297, 'support': 10182}
 
time = 26.34 secondes

Val loss 0.6461966410902342 accuracy 0.9196113348007202 macro_avg {'precision': 0.9190376672570583, 'recall': 0.9201189236131475, 'f1-score': 0.9175895654175417, 'support': 1132} weighted_avg {'precision': 0.9230444943936457, 'recall': 0.9196113074204947, 'f1-score': 0.9193898715384634, 'support': 1132}
 
----------
Epoch 27/40
time = 739.79 secondes

Train loss 0.03241056676628635 accuracy 0.9941073060035706 macro_avg {'precision': 0.9939833983816335, 'recall': 0.9941516150528752, 'f1-score': 0.9940607898708617, 'support': 10182} weighted_avg {'precision': 0.9941270993023057, 'recall': 0.9941072480848556, 'f1-score': 0.9941104602613525, 'support': 10182}
 
time = 25.33 secondes

Val loss 0.7210868510913533 accuracy 0.9134275913238525 macro_avg {'precision': 0.9142484223869836, 'recall': 0.9153470683859558, 'f1-score': 0.9132207807274412, 'support': 1132} weighted_avg {'precision': 0.9181906589929572, 'recall': 0.9134275618374559, 'f1-score': 0.9142962802950307, 'support': 1132}
 
----------
Epoch 28/40
time = 740.80 secondes

Train loss 0.03714516977087266 accuracy 0.9942054748535156 macro_avg {'precision': 0.9942320106443902, 'recall': 0.9940894919658811, 'f1-score': 0.9941538490268845, 'support': 10182} weighted_avg {'precision': 0.9942095224602665, 'recall': 0.9942054606167747, 'f1-score': 0.994200727502615, 'support': 10182}
 
time = 26.35 secondes

Val loss 0.727250716769869 accuracy 0.916077733039856 macro_avg {'precision': 0.9167778236910429, 'recall': 0.9173629614199392, 'f1-score': 0.915686194541179, 'support': 1132} weighted_avg {'precision': 0.9183370029426168, 'recall': 0.916077738515901, 'f1-score': 0.9157528157842735, 'support': 1132}
 
----------
Epoch 29/40
time = 739.80 secondes

Train loss 0.03338839421875958 accuracy 0.9931251406669617 macro_avg {'precision': 0.9925239514861086, 'recall': 0.9928720766310292, 'f1-score': 0.9926885197645431, 'support': 10182} weighted_avg {'precision': 0.9931559893934012, 'recall': 0.9931251227656649, 'f1-score': 0.9931325755829903, 'support': 10182}
 
time = 26.41 secondes

Val loss 0.6895060297676127 accuracy 0.9187279343605042 macro_avg {'precision': 0.9219513941469861, 'recall': 0.9195959618656726, 'f1-score': 0.9185471360024984, 'support': 1132} weighted_avg {'precision': 0.9238932221029444, 'recall': 0.9187279151943463, 'f1-score': 0.9189589859309414, 'support': 1132}
 
----------
Epoch 30/40
time = 739.06 secondes

Train loss 0.029190190497586282 accuracy 0.9945001006126404 macro_avg {'precision': 0.9943866651165274, 'recall': 0.9943215973648867, 'f1-score': 0.9943508009063484, 'support': 10182} weighted_avg {'precision': 0.9945040315542736, 'recall': 0.9945000982125319, 'f1-score': 0.9944988472155075, 'support': 10182}
 
time = 26.70 secondes

Val loss 0.7396101179780397 accuracy 0.916077733039856 macro_avg {'precision': 0.9167691753138234, 'recall': 0.9182768458707022, 'f1-score': 0.9162172599627197, 'support': 1132} weighted_avg {'precision': 0.9206499007889762, 'recall': 0.916077738515901, 'f1-score': 0.9171578913104284, 'support': 1132}
 
----------
Epoch 31/40
time = 739.93 secondes

Train loss 0.027109427578541376 accuracy 0.9951876401901245 macro_avg {'precision': 0.9949895872052503, 'recall': 0.9950413954405116, 'f1-score': 0.9950063417646706, 'support': 10182} weighted_avg {'precision': 0.9952071052449616, 'recall': 0.9951875859359655, 'f1-score': 0.9951890306190915, 'support': 10182}
 
time = 26.53 secondes

Val loss 0.8120902511089068 accuracy 0.9098939895629883 macro_avg {'precision': 0.9130010329943273, 'recall': 0.912081165898336, 'f1-score': 0.9112192888731186, 'support': 1132} weighted_avg {'precision': 0.9136964255422609, 'recall': 0.9098939929328622, 'f1-score': 0.9104842866137749, 'support': 1132}
 
----------
Epoch 32/40
time = 740.85 secondes

Train loss 0.02384930686628427 accuracy 0.9956786632537842 macro_avg {'precision': 0.9956538574188082, 'recall': 0.9956480498857134, 'f1-score': 0.9956455940699842, 'support': 10182} weighted_avg {'precision': 0.9956899435800555, 'recall': 0.9956786485955608, 'f1-score': 0.9956787972167519, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.8175571015999081 accuracy 0.9125441908836365 macro_avg {'precision': 0.9130971272685177, 'recall': 0.9133825305249337, 'f1-score': 0.9108379900103266, 'support': 1132} weighted_avg {'precision': 0.9172564985842215, 'recall': 0.9125441696113075, 'f1-score': 0.9127354836661481, 'support': 1132}
 
----------
Epoch 33/40
time = 739.35 secondes

Train loss 0.026375233416319543 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953367399467815, 'recall': 0.9953794863201114, 'f1-score': 0.9953522968401238, 'support': 10182} weighted_avg {'precision': 0.995390371648045, 'recall': 0.9953840109998036, 'f1-score': 0.9953813112753177, 'support': 10182}
 
time = 26.26 secondes

Val loss 0.7233253677900201 accuracy 0.9116607904434204 macro_avg {'precision': 0.9142741648563633, 'recall': 0.9111500250967792, 'f1-score': 0.9112245726401287, 'support': 1132} weighted_avg {'precision': 0.9159137529952537, 'recall': 0.911660777385159, 'f1-score': 0.9123331181774936, 'support': 1132}
 
----------
Epoch 34/40
time = 740.15 secondes

Train loss 0.025712768454448472 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959007497516538, 'recall': 0.995880436563537, 'f1-score': 0.9958888761394367, 'support': 10182} weighted_avg {'precision': 0.9958837509148133, 'recall': 0.995875073659399, 'f1-score': 0.9958776463279092, 'support': 10182}
 
time = 22.70 secondes

Val loss 0.7438799435163469 accuracy 0.916077733039856 macro_avg {'precision': 0.9176371525202146, 'recall': 0.9170617030456473, 'f1-score': 0.9158393086581338, 'support': 1132} weighted_avg {'precision': 0.9191453985752768, 'recall': 0.916077738515901, 'f1-score': 0.9161227697614773, 'support': 1132}
 
----------
Epoch 35/40
time = 738.90 secondes

Train loss 0.023817625896026727 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963580412947628, 'recall': 0.9964386227422732, 'f1-score': 0.9963928615950387, 'support': 10182} weighted_avg {'precision': 0.9963679270756913, 'recall': 0.9963661363189943, 'f1-score': 0.9963614843192848, 'support': 10182}
 
time = 26.30 secondes

Val loss 0.7840364932625574 accuracy 0.9072438478469849 macro_avg {'precision': 0.9106305479408265, 'recall': 0.9101035957225235, 'f1-score': 0.9087039330445617, 'support': 1132} weighted_avg {'precision': 0.9122961653453384, 'recall': 0.907243816254417, 'f1-score': 0.9079768426669993, 'support': 1132}
 
----------
Epoch 36/40
time = 740.89 secondes

Train loss 0.018018320269304805 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971243322083077, 'recall': 0.9971953062242752, 'f1-score': 0.9971556500577439, 'support': 10182} weighted_avg {'precision': 0.9971594675151301, 'recall': 0.9971518365743469, 'f1-score': 0.9971513735443994, 'support': 10182}
 
time = 26.40 secondes

Val loss 0.725838111334359 accuracy 0.9151943325996399 macro_avg {'precision': 0.9164335369932074, 'recall': 0.9168996797563137, 'f1-score': 0.9155931824776327, 'support': 1132} weighted_avg {'precision': 0.9185444641095326, 'recall': 0.9151943462897526, 'f1-score': 0.9158920286179242, 'support': 1132}
 
----------
Epoch 37/40
time = 738.68 secondes

Train loss 0.00976412360589788 accuracy 0.9985268115997314 macro_avg {'precision': 0.998500742059156, 'recall': 0.9985793814898003, 'f1-score': 0.9985392553556908, 'support': 10182} weighted_avg {'precision': 0.9985278999819355, 'recall': 0.998526812021214, 'f1-score': 0.9985265749682621, 'support': 10182}
 
time = 26.29 secondes

Val loss 0.7364242106342432 accuracy 0.916077733039856 macro_avg {'precision': 0.9177379845910192, 'recall': 0.9168168323873906, 'f1-score': 0.9161720322525255, 'support': 1132} weighted_avg {'precision': 0.9195279313251004, 'recall': 0.916077738515901, 'f1-score': 0.9165914193763598, 'support': 1132}
 
----------
Epoch 38/40
time = 738.30 secondes

Train loss 0.00913411911748411 accuracy 0.9984286427497864 macro_avg {'precision': 0.9985031571860066, 'recall': 0.998440342463088, 'f1-score': 0.9984688304127944, 'support': 10182} weighted_avg {'precision': 0.9984341760037645, 'recall': 0.9984285994892949, 'f1-score': 0.9984283536093479, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7219096824802095 accuracy 0.9098939895629883 macro_avg {'precision': 0.9154098450303522, 'recall': 0.9117638931213733, 'f1-score': 0.9111083212738571, 'support': 1132} weighted_avg {'precision': 0.9195739779073222, 'recall': 0.9098939929328622, 'f1-score': 0.9123235627748953, 'support': 1132}
 
----------
Epoch 39/40
time = 738.53 secondes

Train loss 0.005906547227136705 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990947479849261, 'recall': 0.9991440811883082, 'f1-score': 0.9991190777505532, 'support': 10182} weighted_avg {'precision': 0.9991163778365768, 'recall': 0.9991160872127284, 'f1-score': 0.9991159258406755, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.718827218840962 accuracy 0.9134275913238525 macro_avg {'precision': 0.9136026979394847, 'recall': 0.9154091315280066, 'f1-score': 0.9133300873557838, 'support': 1132} weighted_avg {'precision': 0.9159357704759735, 'recall': 0.9134275618374559, 'f1-score': 0.9134775033893502, 'support': 1132}
 
----------
Epoch 40/40
time = 739.24 secondes

Train loss 0.005780669942423471 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990265749348868, 'recall': 0.9991463890745791, 'f1-score': 0.9990853072726438, 'support': 10182} weighted_avg {'precision': 0.9991185752901142, 'recall': 0.9991160872127284, 'f1-score': 0.9991162878656017, 'support': 10182}
 
time = 26.31 secondes

Val loss 0.736280445923115 accuracy 0.9204947352409363 macro_avg {'precision': 0.9219199705417429, 'recall': 0.9215476334594381, 'f1-score': 0.9203826526178835, 'support': 1132} weighted_avg {'precision': 0.9238507094838615, 'recall': 0.9204946996466431, 'f1-score': 0.9208397671869567, 'support': 1132}
 
----------
best_accuracy 0.9204947352409363 best_epoch 24 macro_avg {'precision': 0.9260149249062577, 'recall': 0.9207762954249082, 'f1-score': 0.9221204507028384, 'support': 1132} weighted_avg {'precision': 0.9239464152651099, 'recall': 0.9204946996466431, 'f1-score': 0.920915201980197, 'support': 1132}

average train time 740.6495288848877

average val time 26.20484483242035
 
time = 172.78 secondes

test_accuracy 0.845724880695343 macro_avg {'precision': 0.8532066722717243, 'recall': 0.8377080461963533, 'f1-score': 0.8406472891327885, 'support': 7532} weighted_avg {'precision': 0.8558311960373348, 'recall': 0.845724907063197, 'f1-score': 0.8461164063018622, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_1
----------
Epoch 1/40
time = 1024.73 secondes

Train loss 1.0764871449962703 accuracy 0.6921037435531616 macro_avg {'precision': 0.6989353558920762, 'recall': 0.6786177804249685, 'f1-score': 0.6743226744744403, 'support': 10182} weighted_avg {'precision': 0.70754554828902, 'recall': 0.6921037124337065, 'f1-score': 0.6880747486713723, 'support': 10182}
 
time = 33.39 secondes

Val loss 0.5713264046000762 accuracy 0.8180211782455444 macro_avg {'precision': 0.8109526498545913, 'recall': 0.8146258637086656, 'f1-score': 0.8016251461389331, 'support': 1132} weighted_avg {'precision': 0.8133134601000619, 'recall': 0.8180212014134276, 'f1-score': 0.8051901952751507, 'support': 1132}
 
----------
Epoch 2/40
time = 1024.88 secondes

Train loss 0.40039510071991097 accuracy 0.8826360702514648 macro_avg {'precision': 0.8758733773066554, 'recall': 0.8742138797621607, 'f1-score': 0.8741973631673231, 'support': 10182} weighted_avg {'precision': 0.881403436162132, 'recall': 0.882636024356708, 'f1-score': 0.8813563793482955, 'support': 10182}
 
time = 32.13 secondes

Val loss 0.4230448785959415 accuracy 0.8789752721786499 macro_avg {'precision': 0.8788910042158777, 'recall': 0.8813849615033627, 'f1-score': 0.8763149826366614, 'support': 1132} weighted_avg {'precision': 0.8819612400735175, 'recall': 0.8789752650176679, 'f1-score': 0.8762303693288115, 'support': 1132}
 
----------
Epoch 3/40
time = 1024.56 secondes

Train loss 0.2420178523062022 accuracy 0.9332154989242554 macro_avg {'precision': 0.92946100192798, 'recall': 0.9292492778904551, 'f1-score': 0.9292890871333093, 'support': 10182} weighted_avg {'precision': 0.9332812868300278, 'recall': 0.9332154782950305, 'f1-score': 0.933186765997232, 'support': 10182}
 
time = 32.88 secondes

Val loss 0.5215500641194447 accuracy 0.8754417300224304 macro_avg {'precision': 0.8859820120760912, 'recall': 0.8741572627149308, 'f1-score': 0.8731580006970427, 'support': 1132} weighted_avg {'precision': 0.8850048095596816, 'recall': 0.8754416961130742, 'f1-score': 0.8735646808714558, 'support': 1132}
 
----------
Epoch 4/40
time = 1023.80 secondes

Train loss 0.18833751894469306 accuracy 0.9514830112457275 macro_avg {'precision': 0.949836997565812, 'recall': 0.9497692062983422, 'f1-score': 0.9497581244605877, 'support': 10182} weighted_avg {'precision': 0.9516857887679225, 'recall': 0.951483009231978, 'f1-score': 0.9515411981086018, 'support': 10182}
 
time = 32.37 secondes

Val loss 0.5048644639302412 accuracy 0.8957597017288208 macro_avg {'precision': 0.8994287948279396, 'recall': 0.8975256073643303, 'f1-score': 0.8957028425472228, 'support': 1132} weighted_avg {'precision': 0.9030830093196656, 'recall': 0.8957597173144877, 'f1-score': 0.8968656724809984, 'support': 1132}
 
----------
Epoch 5/40
time = 1023.62 secondes

Train loss 0.16764402912042925 accuracy 0.9563936591148376 macro_avg {'precision': 0.9548907326756815, 'recall': 0.9546959294228488, 'f1-score': 0.9547561068155591, 'support': 10182} weighted_avg {'precision': 0.9564483977281206, 'recall': 0.9563936358279317, 'f1-score': 0.9563839811531614, 'support': 10182}
 
time = 32.12 secondes

Val loss 0.4989143911745845 accuracy 0.9037102460861206 macro_avg {'precision': 0.9116752640438224, 'recall': 0.9078492079918238, 'f1-score': 0.9059647927742119, 'support': 1132} weighted_avg {'precision': 0.9108301997182671, 'recall': 0.9037102473498233, 'f1-score': 0.9029797676950134, 'support': 1132}
 
----------
Epoch 6/40
time = 1023.31 secondes

Train loss 0.1337077824113411 accuracy 0.967197060585022 macro_avg {'precision': 0.9662199351030918, 'recall': 0.9661776152779131, 'f1-score': 0.9661655569653327, 'support': 10182} weighted_avg {'precision': 0.9672937677541613, 'recall': 0.9671970143390297, 'f1-score': 0.9672127133947387, 'support': 10182}
 
time = 31.97 secondes

Val loss 0.5888678016613277 accuracy 0.9001767039299011 macro_avg {'precision': 0.9021497043225967, 'recall': 0.9019262738947169, 'f1-score': 0.898988420300643, 'support': 1132} weighted_avg {'precision': 0.9018684865446347, 'recall': 0.9001766784452296, 'f1-score': 0.8978217976281426, 'support': 1132}
 
----------
Epoch 7/40
time = 1024.31 secondes

Train loss 0.13921104858088815 accuracy 0.9680809378623962 macro_avg {'precision': 0.9673034889477906, 'recall': 0.967623358851216, 'f1-score': 0.9674127527477898, 'support': 10182} weighted_avg {'precision': 0.9682930249412235, 'recall': 0.9680809271263013, 'f1-score': 0.9681376640224285, 'support': 10182}
 
time = 32.21 secondes

Val loss 0.5170876113328965 accuracy 0.9125441908836365 macro_avg {'precision': 0.913673221245927, 'recall': 0.9149591568131509, 'f1-score': 0.912488553097554, 'support': 1132} weighted_avg {'precision': 0.9150097998980778, 'recall': 0.9125441696113075, 'f1-score': 0.911683042082315, 'support': 1132}
 
----------
Epoch 8/40
time = 1025.47 secondes

Train loss 0.11626573737997276 accuracy 0.9730898141860962 macro_avg {'precision': 0.9723350677871645, 'recall': 0.9722601852915472, 'f1-score': 0.972263023039569, 'support': 10182} weighted_avg {'precision': 0.9731247521410942, 'recall': 0.973089766254174, 'f1-score': 0.9730718018811687, 'support': 10182}
 
time = 32.35 secondes

Val loss 0.5456302823120905 accuracy 0.916077733039856 macro_avg {'precision': 0.9193781441528728, 'recall': 0.9163604414353875, 'f1-score': 0.9156069427943929, 'support': 1132} weighted_avg {'precision': 0.9202814937487964, 'recall': 0.916077738515901, 'f1-score': 0.9159545993975302, 'support': 1132}
 
----------
Epoch 9/40
time = 1026.01 secondes

Train loss 0.11917532363765232 accuracy 0.9742683172225952 macro_avg {'precision': 0.9736690191122819, 'recall': 0.9735052843706165, 'f1-score': 0.9735500079234717, 'support': 10182} weighted_avg {'precision': 0.9742855222952774, 'recall': 0.9742683166372029, 'f1-score': 0.9742393061479586, 'support': 10182}
 
time = 31.37 secondes

Val loss 0.5794078572194131 accuracy 0.9090105891227722 macro_avg {'precision': 0.9103936069843879, 'recall': 0.908889471199801, 'f1-score': 0.9075193690068566, 'support': 1132} weighted_avg {'precision': 0.9138158359621101, 'recall': 0.9090106007067138, 'f1-score': 0.9093388870387071, 'support': 1132}
 
----------
Epoch 10/40
time = 1024.99 secondes

Train loss 0.10208787572402192 accuracy 0.9770182967185974 macro_avg {'precision': 0.9769046699231152, 'recall': 0.9767388802066215, 'f1-score': 0.9767831067505883, 'support': 10182} weighted_avg {'precision': 0.9770801096987111, 'recall': 0.9770182675309369, 'f1-score': 0.9770094624813929, 'support': 10182}
 
time = 32.14 secondes

Val loss 0.802321792209216 accuracy 0.8860424160957336 macro_avg {'precision': 0.9017795318988118, 'recall': 0.889982668480369, 'f1-score': 0.8878401607550638, 'support': 1132} weighted_avg {'precision': 0.9010901365422572, 'recall': 0.8860424028268551, 'f1-score': 0.8842115410745749, 'support': 1132}
 
----------
Epoch 11/40
time = 1023.54 secondes

Train loss 0.11900583090324772 accuracy 0.9766254425048828 macro_avg {'precision': 0.9759220936624328, 'recall': 0.9754643701611917, 'f1-score': 0.9756239153766586, 'support': 10182} weighted_avg {'precision': 0.9767299944829103, 'recall': 0.9766254174032607, 'f1-score': 0.9766143095190633, 'support': 10182}
 
time = 32.39 secondes

Val loss 0.7003994588608998 accuracy 0.9072438478469849 macro_avg {'precision': 0.9169625158842898, 'recall': 0.9022135512968706, 'f1-score': 0.9063577132710261, 'support': 1132} weighted_avg {'precision': 0.9134926586076244, 'recall': 0.907243816254417, 'f1-score': 0.9072182758298172, 'support': 1132}
 
----------
Epoch 12/40
time = 1023.69 secondes

Train loss 0.0948579298518333 accuracy 0.9803575277328491 macro_avg {'precision': 0.9799248106440437, 'recall': 0.9792507793314679, 'f1-score': 0.979544327525416, 'support': 10182} weighted_avg {'precision': 0.9803865695694135, 'recall': 0.9803574936161854, 'f1-score': 0.9803335041463639, 'support': 10182}
 
time = 32.05 secondes

Val loss 0.7162997829936885 accuracy 0.8975265026092529 macro_avg {'precision': 0.9096217770953745, 'recall': 0.9043810045872422, 'f1-score': 0.9019505673330327, 'support': 1132} weighted_avg {'precision': 0.9113000998310312, 'recall': 0.8975265017667845, 'f1-score': 0.8990503119632081, 'support': 1132}
 
----------
Epoch 13/40
time = 1024.37 secondes

Train loss 0.08759451265084255 accuracy 0.9834021329879761 macro_avg {'precision': 0.9828528838566075, 'recall': 0.982548556309561, 'f1-score': 0.9826839435784056, 'support': 10182} weighted_avg {'precision': 0.9834082355559699, 'recall': 0.9834020821056767, 'f1-score': 0.9833890809469851, 'support': 10182}
 
time = 32.19 secondes

Val loss 0.6333463275610407 accuracy 0.9116607904434204 macro_avg {'precision': 0.9144524622705832, 'recall': 0.9128713759201726, 'f1-score': 0.9114515951900162, 'support': 1132} weighted_avg {'precision': 0.9160664960753082, 'recall': 0.911660777385159, 'f1-score': 0.9118002493452724, 'support': 1132}
 
----------
Epoch 14/40
time = 1022.93 secondes

Train loss 0.07619648648108765 accuracy 0.9863485097885132 macro_avg {'precision': 0.9859986146533031, 'recall': 0.9862264685357068, 'f1-score': 0.986095438956885, 'support': 10182} weighted_avg {'precision': 0.986376968929731, 'recall': 0.9863484580632489, 'f1-score': 0.9863460049264852, 'support': 10182}
 
time = 32.39 secondes

Val loss 0.6455491539834864 accuracy 0.9107773900032043 macro_avg {'precision': 0.9131196935254653, 'recall': 0.9102782780721868, 'f1-score': 0.9105239967706436, 'support': 1132} weighted_avg {'precision': 0.9146643433437743, 'recall': 0.9107773851590106, 'f1-score': 0.9114657033383425, 'support': 1132}
 
----------
Epoch 15/40
time = 1023.83 secondes

Train loss 0.08517470872267702 accuracy 0.9838931560516357 macro_avg {'precision': 0.9833933455486872, 'recall': 0.983380465534473, 'f1-score': 0.9833730826419075, 'support': 10182} weighted_avg {'precision': 0.9839035861370429, 'recall': 0.983893144765272, 'f1-score': 0.9838847052142307, 'support': 10182}
 
time = 31.44 secondes

Val loss 0.7082462010007027 accuracy 0.9037102460861206 macro_avg {'precision': 0.9081686981855771, 'recall': 0.904097424430278, 'f1-score': 0.9035471839636419, 'support': 1132} weighted_avg {'precision': 0.9092821241804081, 'recall': 0.9037102473498233, 'f1-score': 0.9041944468252558, 'support': 1132}
 
----------
Epoch 16/40
time = 1022.52 secondes

Train loss 0.07840290349383938 accuracy 0.9847770929336548 macro_avg {'precision': 0.9845098830512576, 'recall': 0.9844287530118118, 'f1-score': 0.984459791822436, 'support': 10182} weighted_avg {'precision': 0.9848135757333448, 'recall': 0.9847770575525437, 'f1-score': 0.9847858137163709, 'support': 10182}
 
time = 27.38 secondes

Val loss 0.7684039675231373 accuracy 0.9019434452056885 macro_avg {'precision': 0.9100004327471769, 'recall': 0.904821488953624, 'f1-score': 0.9031367300777513, 'support': 1132} weighted_avg {'precision': 0.9150503220765733, 'recall': 0.9019434628975265, 'f1-score': 0.9040074225574136, 'support': 1132}
 
----------
Epoch 17/40
time = 1024.98 secondes

Train loss 0.08607077978776542 accuracy 0.9847770929336548 macro_avg {'precision': 0.9846597977138695, 'recall': 0.9847014285800911, 'f1-score': 0.9846705905871749, 'support': 10182} weighted_avg {'precision': 0.9848100785405829, 'recall': 0.9847770575525437, 'f1-score': 0.9847832513969191, 'support': 10182}
 
time = 32.01 secondes

Val loss 0.7243563837698057 accuracy 0.9090105891227722 macro_avg {'precision': 0.9106598171721997, 'recall': 0.9066930096813891, 'f1-score': 0.906390704053465, 'support': 1132} weighted_avg {'precision': 0.9121019375082015, 'recall': 0.9090106007067138, 'f1-score': 0.9083999941659323, 'support': 1132}
 
----------
Epoch 18/40
time = 1024.89 secondes

Train loss 0.0871782258107821 accuracy 0.9840896129608154 macro_avg {'precision': 0.9839252750337076, 'recall': 0.9835773936975519, 'f1-score': 0.9837085594122131, 'support': 10182} weighted_avg {'precision': 0.9841583823497522, 'recall': 0.9840895698291102, 'f1-score': 0.9840867751411763, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.8798971516736062 accuracy 0.8886925578117371 macro_avg {'precision': 0.9056214489619334, 'recall': 0.8815948840071794, 'f1-score': 0.8826733483555099, 'support': 1132} weighted_avg {'precision': 0.9036010418090042, 'recall': 0.8886925795053003, 'f1-score': 0.8872738334330628, 'support': 1132}
 
----------
Epoch 19/40
time = 1023.49 secondes

Train loss 0.08396983491434791 accuracy 0.985660970211029 macro_avg {'precision': 0.9855351618181224, 'recall': 0.9853002327324688, 'f1-score': 0.9853638042093793, 'support': 10182} weighted_avg {'precision': 0.9857298528103167, 'recall': 0.9856609703398154, 'f1-score': 0.9856440589921959, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.7885613369810375 accuracy 0.9054770469665527 macro_avg {'precision': 0.9141753950991817, 'recall': 0.9048764966759221, 'f1-score': 0.9065057751072862, 'support': 1132} weighted_avg {'precision': 0.9119084971595932, 'recall': 0.9054770318021201, 'f1-score': 0.9057179635513991, 'support': 1132}
 
----------
Epoch 20/40
time = 1022.01 secondes

Train loss 0.06521608722985353 accuracy 0.9880180954933167 macro_avg {'precision': 0.9878408008143629, 'recall': 0.9878430246478539, 'f1-score': 0.9878218811575475, 'support': 10182} weighted_avg {'precision': 0.9880566754410776, 'recall': 0.9880180711058731, 'f1-score': 0.9880182396920765, 'support': 10182}
 
time = 29.96 secondes

Val loss 0.7892391096108222 accuracy 0.9010601043701172 macro_avg {'precision': 0.9049833292933496, 'recall': 0.9046196876335573, 'f1-score': 0.9019367974695571, 'support': 1132} weighted_avg {'precision': 0.9078830952655106, 'recall': 0.901060070671378, 'f1-score': 0.9015470221879509, 'support': 1132}
 
----------
Epoch 21/40
time = 1021.26 secondes

Train loss 0.05363096450391065 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893936497157068, 'recall': 0.9892291643738365, 'f1-score': 0.9893042463429733, 'support': 10182} weighted_avg {'precision': 0.9893939293803005, 'recall': 0.9893930465527401, 'f1-score': 0.9893865680849641, 'support': 10182}
 
time = 32.29 secondes

Val loss 0.6728296002164453 accuracy 0.9081271886825562 macro_avg {'precision': 0.9133416761702664, 'recall': 0.910485402002621, 'f1-score': 0.9101630683453182, 'support': 1132} weighted_avg {'precision': 0.9129775920756867, 'recall': 0.9081272084805654, 'f1-score': 0.9086213477597148, 'support': 1132}
 
----------
Epoch 22/40
time = 1023.61 secondes

Train loss 0.05319750729750997 accuracy 0.98978590965271 macro_avg {'precision': 0.9892031194918856, 'recall': 0.9894409932576554, 'f1-score': 0.9893029882605173, 'support': 10182} weighted_avg {'precision': 0.9898360916610388, 'recall': 0.9897858966804164, 'f1-score': 0.9897949757731386, 'support': 10182}
 
time = 31.86 secondes

Val loss 0.6254858621378703 accuracy 0.9151943325996399 macro_avg {'precision': 0.9265359487121005, 'recall': 0.9158014832220314, 'f1-score': 0.9182005604578786, 'support': 1132} weighted_avg {'precision': 0.9230379317991607, 'recall': 0.9151943462897526, 'f1-score': 0.9160990686902539, 'support': 1132}
 
----------
Epoch 23/40
time = 1023.53 secondes

Train loss 0.052342122080309125 accuracy 0.9900805354118347 macro_avg {'precision': 0.9899369822816826, 'recall': 0.9897464084948181, 'f1-score': 0.989833037251865, 'support': 10182} weighted_avg {'precision': 0.9900906150484255, 'recall': 0.9900805342761736, 'f1-score': 0.9900770090388121, 'support': 10182}
 
time = 32.15 secondes

Val loss 0.7347447222514155 accuracy 0.9090105891227722 macro_avg {'precision': 0.914712483385436, 'recall': 0.9105420957684445, 'f1-score': 0.910023156960127, 'support': 1132} weighted_avg {'precision': 0.9155791237871072, 'recall': 0.9090106007067138, 'f1-score': 0.9096436630715687, 'support': 1132}
 
----------
Epoch 24/40
time = 1023.31 secondes

Train loss 0.05032281281491062 accuracy 0.9908662438392639 macro_avg {'precision': 0.9906778736034367, 'recall': 0.9908040264347958, 'f1-score': 0.9907309672227707, 'support': 10182} weighted_avg {'precision': 0.9908999346708558, 'recall': 0.9908662345315262, 'f1-score': 0.9908732262356009, 'support': 10182}
 
time = 32.33 secondes

Val loss 0.6937136523085147 accuracy 0.9107773900032043 macro_avg {'precision': 0.9173381742673131, 'recall': 0.91141970086484, 'f1-score': 0.9114140823846395, 'support': 1132} weighted_avg {'precision': 0.9172641329512923, 'recall': 0.9107773851590106, 'f1-score': 0.9111317237858253, 'support': 1132}
 
----------
Epoch 25/40
time = 1023.42 secondes

Train loss 0.05059528794895364 accuracy 0.9910627007484436 macro_avg {'precision': 0.9910399681188113, 'recall': 0.9908526413466433, 'f1-score': 0.9909393757838029, 'support': 10182} weighted_avg {'precision': 0.9910786345650375, 'recall': 0.9910626595953643, 'f1-score': 0.9910638165527865, 'support': 10182}
 
time = 32.35 secondes

Val loss 0.6318720468167465 accuracy 0.9222614765167236 macro_avg {'precision': 0.9263564499513233, 'recall': 0.9254998028334643, 'f1-score': 0.9247504879146774, 'support': 1132} weighted_avg {'precision': 0.9261497212395516, 'recall': 0.9222614840989399, 'f1-score': 0.9230779030990901, 'support': 1132}
 
----------
Epoch 26/40
time = 1020.10 secondes

Train loss 0.04826078841197416 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925334785646791, 'recall': 0.9925898436881884, 'f1-score': 0.9925498554360583, 'support': 10182} weighted_avg {'precision': 0.9924587940857116, 'recall': 0.9924376350422314, 'f1-score': 0.992436165450382, 'support': 10182}
 
time = 32.85 secondes

Val loss 0.781056670097519 accuracy 0.9037102460861206 macro_avg {'precision': 0.9117605694543827, 'recall': 0.9065991570316484, 'f1-score': 0.9049555568221322, 'support': 1132} weighted_avg {'precision': 0.9138754068374562, 'recall': 0.9037102473498233, 'f1-score': 0.9048172138321514, 'support': 1132}
 
----------
Epoch 27/40
time = 1023.53 secondes

Train loss 0.04693756652963048 accuracy 0.9915537238121033 macro_avg {'precision': 0.9915586792065868, 'recall': 0.9916186563177811, 'f1-score': 0.9915739933213648, 'support': 10182} weighted_avg {'precision': 0.991583298803238, 'recall': 0.9915537222549597, 'f1-score': 0.991554975669787, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.7433063546169494 accuracy 0.9116607904434204 macro_avg {'precision': 0.9195482081091615, 'recall': 0.9157739566737311, 'f1-score': 0.9141116771702971, 'support': 1132} weighted_avg {'precision': 0.9202397461922291, 'recall': 0.911660777385159, 'f1-score': 0.9124206618080247, 'support': 1132}
 
----------
Epoch 28/40
time = 1022.67 secondes

Train loss 0.03352071545165729 accuracy 0.9942054748535156 macro_avg {'precision': 0.9940638515455344, 'recall': 0.9938380850640949, 'f1-score': 0.9939410843752011, 'support': 10182} weighted_avg {'precision': 0.9942223934270951, 'recall': 0.9942054606167747, 'f1-score': 0.9942050699699828, 'support': 10182}
 
time = 29.84 secondes

Val loss 0.6136548646771215 accuracy 0.9257950782775879 macro_avg {'precision': 0.9261890387781962, 'recall': 0.927527474329113, 'f1-score': 0.9258986065261141, 'support': 1132} weighted_avg {'precision': 0.9282907866147594, 'recall': 0.9257950530035336, 'f1-score': 0.9261871154353502, 'support': 1132}
 
----------
Epoch 29/40
time = 1025.33 secondes

Train loss 0.03794319252154587 accuracy 0.9940090775489807 macro_avg {'precision': 0.9940288545245842, 'recall': 0.9940976841958514, 'f1-score': 0.9940580107573715, 'support': 10182} weighted_avg {'precision': 0.9940203922734654, 'recall': 0.9940090355529365, 'f1-score': 0.9940093761842484, 'support': 10182}
 
time = 32.16 secondes

Val loss 0.8497533677983087 accuracy 0.898409903049469 macro_avg {'precision': 0.9094989341187137, 'recall': 0.9013542881636225, 'f1-score': 0.9007917410850789, 'support': 1132} weighted_avg {'precision': 0.9088848367793927, 'recall': 0.8984098939929329, 'f1-score': 0.8988418114816893, 'support': 1132}
 
----------
Epoch 30/40
time = 1021.84 secondes

Train loss 0.03229315254807896 accuracy 0.9941073060035706 macro_avg {'precision': 0.9941060671956461, 'recall': 0.9942003284438146, 'f1-score': 0.994149623443892, 'support': 10182} weighted_avg {'precision': 0.9941150955698097, 'recall': 0.9941072480848556, 'f1-score': 0.9941076820260373, 'support': 10182}
 
time = 32.00 secondes

Val loss 0.7707429613283111 accuracy 0.9090105891227722 macro_avg {'precision': 0.9102810005403663, 'recall': 0.9133509245035059, 'f1-score': 0.909894421116301, 'support': 1132} weighted_avg {'precision': 0.9150273805420497, 'recall': 0.9090106007067138, 'f1-score': 0.9103721593768063, 'support': 1132}
 
----------
Epoch 31/40
time = 1021.77 secondes

Train loss 0.028931595027913048 accuracy 0.9946965575218201 macro_avg {'precision': 0.9943452192097464, 'recall': 0.9945492956856523, 'f1-score': 0.9944428486979742, 'support': 10182} weighted_avg {'precision': 0.994714773790324, 'recall': 0.99469652327637, 'f1-score': 0.9947017309683652, 'support': 10182}
 
time = 32.09 secondes

Val loss 0.6980843476486486 accuracy 0.926678478717804 macro_avg {'precision': 0.9290148260773934, 'recall': 0.9280001124588309, 'f1-score': 0.9269605044843872, 'support': 1132} weighted_avg {'precision': 0.9294689815228299, 'recall': 0.926678445229682, 'f1-score': 0.9265211179030904, 'support': 1132}
 
----------
Epoch 32/40
time = 1022.71 secondes

Train loss 0.027609420178314723 accuracy 0.9951876401901245 macro_avg {'precision': 0.9947826102728874, 'recall': 0.9948554440038295, 'f1-score': 0.9948156256473327, 'support': 10182} weighted_avg {'precision': 0.9951995880631027, 'recall': 0.9951875859359655, 'f1-score': 0.9951900733474559, 'support': 10182}
 
time = 31.84 secondes

Val loss 0.6637529068428475 accuracy 0.9249116778373718 macro_avg {'precision': 0.9298462396672985, 'recall': 0.9274962085894514, 'f1-score': 0.9275663791894517, 'support': 1132} weighted_avg {'precision': 0.9296648332725056, 'recall': 0.9249116607773852, 'f1-score': 0.9262263390407763, 'support': 1132}
 
----------
Epoch 33/40
time = 1023.67 secondes

Train loss 0.020966692196621117 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963536611214172, 'recall': 0.9963261282384058, 'f1-score': 0.9963372981336466, 'support': 10182} weighted_avg {'precision': 0.996373596408241, 'recall': 0.9963661363189943, 'f1-score': 0.9963672295221706, 'support': 10182}
 
time = 32.06 secondes

Val loss 0.6737364090669717 accuracy 0.9222614765167236 macro_avg {'precision': 0.9230647144304166, 'recall': 0.925935109054147, 'f1-score': 0.9226002375884583, 'support': 1132} weighted_avg {'precision': 0.9263850375947325, 'recall': 0.9222614840989399, 'f1-score': 0.9223991253656294, 'support': 1132}
 
----------
Epoch 34/40
time = 1023.92 secondes

Train loss 0.01736722682300403 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970576672908406, 'recall': 0.996860718946271, 'f1-score': 0.9969547627935643, 'support': 10182} weighted_avg {'precision': 0.9970627707997125, 'recall': 0.9970536240424278, 'f1-score': 0.9970543058014356, 'support': 10182}
 
time = 31.73 secondes

Val loss 0.673796150401986 accuracy 0.9293286204338074 macro_avg {'precision': 0.9299768617851454, 'recall': 0.9315996543959338, 'f1-score': 0.9302742390965264, 'support': 1132} weighted_avg {'precision': 0.9304241448829335, 'recall': 0.9293286219081273, 'f1-score': 0.9293400499691428, 'support': 1132}
 
----------
Epoch 35/40
time = 1019.83 secondes

Train loss 0.01447960056464001 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974159039329888, 'recall': 0.9974839430322107, 'f1-score': 0.9974478303652583, 'support': 10182} weighted_avg {'precision': 0.9975478677892999, 'recall': 0.9975446867020232, 'f1-score': 0.9975441790571511, 'support': 10182}
 
time = 32.10 secondes

Val loss 0.6800740208553846 accuracy 0.9231448769569397 macro_avg {'precision': 0.9260764015335804, 'recall': 0.9251093431543002, 'f1-score': 0.9244193833771333, 'support': 1132} weighted_avg {'precision': 0.9273594221585976, 'recall': 0.9231448763250883, 'f1-score': 0.9240520418342951, 'support': 1132}
 
----------
Epoch 36/40
time = 1025.23 secondes

Train loss 0.015896143655050675 accuracy 0.9974464774131775 macro_avg {'precision': 0.9973569231090554, 'recall': 0.9972952701392976, 'f1-score': 0.9973240042159082, 'support': 10182} weighted_avg {'precision': 0.9974505490993197, 'recall': 0.9974464741701041, 'f1-score': 0.9974465183593655, 'support': 10182}
 
time = 31.90 secondes

Val loss 0.6662674955925826 accuracy 0.926678478717804 macro_avg {'precision': 0.9301860572142472, 'recall': 0.9296967992957695, 'f1-score': 0.9285908529627112, 'support': 1132} weighted_avg {'precision': 0.9311983969843084, 'recall': 0.926678445229682, 'f1-score': 0.9274622436561737, 'support': 1132}
 
----------
Epoch 37/40
time = 1021.97 secondes

Train loss 0.013099403011266638 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979486218250646, 'recall': 0.9979970627581303, 'f1-score': 0.9979720700420248, 'support': 10182} weighted_avg {'precision': 0.9979394735508683, 'recall': 0.9979375368296994, 'f1-score': 0.9979377406047404, 'support': 10182}
 
time = 32.24 secondes

Val loss 0.6471279403573955 accuracy 0.9293286204338074 macro_avg {'precision': 0.929011195241902, 'recall': 0.9314181471854551, 'f1-score': 0.929466130963081, 'support': 1132} weighted_avg {'precision': 0.9305399754034203, 'recall': 0.9293286219081273, 'f1-score': 0.9291355635277382, 'support': 1132}
 
----------
Epoch 38/40
time = 1023.10 secondes

Train loss 0.006901817827863372 accuracy 0.998821496963501 macro_avg {'precision': 0.9987674010496406, 'recall': 0.9988156465219026, 'f1-score': 0.9987895956898504, 'support': 10182} weighted_avg {'precision': 0.9988260711924489, 'recall': 0.9988214496169712, 'f1-score': 0.9988219604946775, 'support': 10182}
 
time = 32.37 secondes

Val loss 0.6256438842882116 accuracy 0.9293286204338074 macro_avg {'precision': 0.9316416419171178, 'recall': 0.9314050869651889, 'f1-score': 0.9306949557452026, 'support': 1132} weighted_avg {'precision': 0.9312202264227943, 'recall': 0.9293286219081273, 'f1-score': 0.9294039472553818, 'support': 1132}
 
----------
Epoch 39/40
time = 1021.24 secondes

Train loss 0.0063288639659525815 accuracy 0.9986250400543213 macro_avg {'precision': 0.998606797307352, 'recall': 0.9985914825240249, 'f1-score': 0.9985986376511177, 'support': 10182} weighted_avg {'precision': 0.9986259830449353, 'recall': 0.998625024553133, 'f1-score': 0.9986250138321305, 'support': 10182}
 
time = 32.03 secondes

Val loss 0.6061988778854126 accuracy 0.9310954213142395 macro_avg {'precision': 0.933987495217897, 'recall': 0.9321895747423883, 'f1-score': 0.9320592735262041, 'support': 1132} weighted_avg {'precision': 0.9341731535538638, 'recall': 0.931095406360424, 'f1-score': 0.9315568966794563, 'support': 1132}
 
----------
Epoch 40/40
time = 1020.74 secondes

Train loss 0.004333297478742493 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990591229477446, 'recall': 0.9989439235377358, 'f1-score': 0.9990007140303611, 'support': 10182} weighted_avg {'precision': 0.9990187988262491, 'recall': 0.9990178746808093, 'f1-score': 0.9990176671201049, 'support': 10182}
 
time = 32.13 secondes

Val loss 0.5915937128540437 accuracy 0.9319788217544556 macro_avg {'precision': 0.9326777394132142, 'recall': 0.9328893226306914, 'f1-score': 0.9318583708818962, 'support': 1132} weighted_avg {'precision': 0.9341479903319505, 'recall': 0.9319787985865724, 'f1-score': 0.9321455803184886, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 40 macro_avg {'precision': 0.9326777394132142, 'recall': 0.9328893226306914, 'f1-score': 0.9318583708818962, 'support': 1132} weighted_avg {'precision': 0.9341479903319505, 'recall': 0.9319787985865724, 'f1-score': 0.9321455803184886, 'support': 1132}

average train time 1023.3677491486072

average val time 31.93425275683403
 
time = 210.42 secondes

test_accuracy 0.8617897033691406 macro_avg {'precision': 0.858259258985367, 'recall': 0.8556613697009052, 'f1-score': 0.8556487069878284, 'support': 7532} weighted_avg {'precision': 0.8645963733802579, 'recall': 0.8617896972915561, 'f1-score': 0.8620557420766171, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_1
----------
Epoch 1/40
time = 1905.07 secondes

Train loss 1.1205053262330673 accuracy 0.6849341988563538 macro_avg {'precision': 0.6888700275608535, 'recall': 0.6719184649134656, 'f1-score': 0.6702189229652065, 'support': 10182} weighted_avg {'precision': 0.696145916669827, 'recall': 0.6849341976036142, 'f1-score': 0.6821807466822836, 'support': 10182}
 
time = 38.53 secondes

Val loss 0.5259604499163762 accuracy 0.8462897539138794 macro_avg {'precision': 0.8367901759190604, 'recall': 0.8376149208962568, 'f1-score': 0.833020872390934, 'support': 1132} weighted_avg {'precision': 0.8416703214825941, 'recall': 0.8462897526501767, 'f1-score': 0.8404629809666786, 'support': 1132}
 
----------
Epoch 2/40
time = 1905.53 secondes

Train loss 0.38995731358227775 accuracy 0.8863681554794312 macro_avg {'precision': 0.8804857545631689, 'recall': 0.8786709073741467, 'f1-score': 0.8787179719134949, 'support': 10182} weighted_avg {'precision': 0.8854661250052038, 'recall': 0.8863681005696327, 'f1-score': 0.8852457743350424, 'support': 10182}
 
time = 39.58 secondes

Val loss 0.48555777106486575 accuracy 0.8692579865455627 macro_avg {'precision': 0.8738400226857996, 'recall': 0.8695366426114199, 'f1-score': 0.8647704544126741, 'support': 1132} weighted_avg {'precision': 0.8782375537764225, 'recall': 0.8692579505300353, 'f1-score': 0.8664370533106831, 'support': 1132}
 
----------
Epoch 3/40
time = 1905.91 secondes

Train loss 0.22789580522841968 accuracy 0.9375368356704712 macro_avg {'precision': 0.9340760918132711, 'recall': 0.9336831210564339, 'f1-score': 0.9337983421859388, 'support': 10182} weighted_avg {'precision': 0.9375134595167559, 'recall': 0.9375368296994696, 'f1-score': 0.9374489549532355, 'support': 10182}
 
time = 38.71 secondes

Val loss 0.5257196729596127 accuracy 0.8851590156555176 macro_avg {'precision': 0.8890661953349468, 'recall': 0.884321286541543, 'f1-score': 0.8811081083333757, 'support': 1132} weighted_avg {'precision': 0.8932114375858254, 'recall': 0.8851590106007067, 'f1-score': 0.8837593318086477, 'support': 1132}
 
----------
Epoch 4/40
time = 1903.76 secondes

Train loss 0.17593539886547946 accuracy 0.9538401365280151 macro_avg {'precision': 0.9518463495929002, 'recall': 0.9516120219152876, 'f1-score': 0.951653304294213, 'support': 10182} weighted_avg {'precision': 0.9540765773918135, 'recall': 0.9538401099980357, 'f1-score': 0.9538840825797064, 'support': 10182}
 
time = 40.17 secondes

Val loss 0.4766560439381119 accuracy 0.8966431021690369 macro_avg {'precision': 0.8994398928742463, 'recall': 0.8964093662380032, 'f1-score': 0.8955930955579803, 'support': 1132} weighted_avg {'precision': 0.9001403842839368, 'recall': 0.8966431095406361, 'f1-score': 0.8959481066941135, 'support': 1132}
 
----------
Epoch 5/40
time = 1902.50 secondes

Train loss 0.15017285644335546 accuracy 0.9606168270111084 macro_avg {'precision': 0.9588979738570582, 'recall': 0.9591811855853214, 'f1-score': 0.9589876665039189, 'support': 10182} weighted_avg {'precision': 0.9607438154655036, 'recall': 0.9606167747004518, 'f1-score': 0.960633843466138, 'support': 10182}
 
time = 39.28 secondes

Val loss 0.5888939439417453 accuracy 0.8975265026092529 macro_avg {'precision': 0.8972340263178988, 'recall': 0.8973326652149988, 'f1-score': 0.8955003597018326, 'support': 1132} weighted_avg {'precision': 0.9003165691833224, 'recall': 0.8975265017667845, 'f1-score': 0.8972247371013566, 'support': 1132}
 
----------
Epoch 6/40
time = 1902.15 secondes

Train loss 0.13933931167779878 accuracy 0.9666077494621277 macro_avg {'precision': 0.9649204993127185, 'recall': 0.9650847901950976, 'f1-score': 0.9649487887022928, 'support': 10182} weighted_avg {'precision': 0.9667006581816554, 'recall': 0.9666077391475152, 'f1-score': 0.9666004788194609, 'support': 10182}
 
time = 38.08 secondes

Val loss 0.5884069170061709 accuracy 0.9037102460861206 macro_avg {'precision': 0.9044684064344904, 'recall': 0.9002979219888735, 'f1-score': 0.8988389768119178, 'support': 1132} weighted_avg {'precision': 0.9067598164649491, 'recall': 0.9037102473498233, 'f1-score': 0.9022873602126934, 'support': 1132}
 
----------
Epoch 7/40
time = 1902.28 secondes

Train loss 0.13373836576439707 accuracy 0.9702416062355042 macro_avg {'precision': 0.9695934944949238, 'recall': 0.9695216011698411, 'f1-score': 0.9695187626001831, 'support': 10182} weighted_avg {'precision': 0.9702842839409753, 'recall': 0.9702416028285209, 'f1-score': 0.9702249932457309, 'support': 10182}
 
time = 37.85 secondes

Val loss 0.5814524267654223 accuracy 0.9072438478469849 macro_avg {'precision': 0.9110691186336666, 'recall': 0.9053487194530371, 'f1-score': 0.9061455681080244, 'support': 1132} weighted_avg {'precision': 0.9115102233649242, 'recall': 0.907243816254417, 'f1-score': 0.9072576158955372, 'support': 1132}
 
----------
Epoch 8/40
time = 1903.59 secondes

Train loss 0.10812582822129667 accuracy 0.9767236709594727 macro_avg {'precision': 0.9764423492231575, 'recall': 0.9763487018184236, 'f1-score': 0.9763804710587598, 'support': 10182} weighted_avg {'precision': 0.9767560548427489, 'recall': 0.9767236299351797, 'f1-score': 0.9767246651099624, 'support': 10182}
 
time = 38.27 secondes

Val loss 0.5138284770934186 accuracy 0.9143109321594238 macro_avg {'precision': 0.9188695008251632, 'recall': 0.9174555280046507, 'f1-score': 0.9156176480802515, 'support': 1132} weighted_avg {'precision': 0.9183297475897167, 'recall': 0.9143109540636042, 'f1-score': 0.9135160916436184, 'support': 1132}
 
----------
Epoch 9/40
time = 1980.54 secondes

Train loss 0.11244370048120764 accuracy 0.9760361909866333 macro_avg {'precision': 0.9750860114069727, 'recall': 0.9745868006380786, 'f1-score': 0.9747866616954818, 'support': 10182} weighted_avg {'precision': 0.9761296697564137, 'recall': 0.9760361422117462, 'f1-score': 0.9760355398517749, 'support': 10182}
 
time = 37.99 secondes

Val loss 0.6065358025207132 accuracy 0.9116607904434204 macro_avg {'precision': 0.9184957979721613, 'recall': 0.9125899320156516, 'f1-score': 0.9127350174153268, 'support': 1132} weighted_avg {'precision': 0.9176068514709099, 'recall': 0.911660777385159, 'f1-score': 0.9118209173392098, 'support': 1132}
 
----------
Epoch 10/40
time = 1919.79 secondes

Train loss 0.10695423956569708 accuracy 0.9781968593597412 macro_avg {'precision': 0.977527483450835, 'recall': 0.9776261227283228, 'f1-score': 0.9775673477335257, 'support': 10182} weighted_avg {'precision': 0.978206628455565, 'recall': 0.9781968179139658, 'f1-score': 0.978192828358459, 'support': 10182}
 
time = 38.13 secondes

Val loss 0.7047820852398807 accuracy 0.8913427591323853 macro_avg {'precision': 0.9043754559144397, 'recall': 0.8924242112734466, 'f1-score': 0.8940625821663948, 'support': 1132} weighted_avg {'precision': 0.8981796068338481, 'recall': 0.8913427561837456, 'f1-score': 0.8901482914400568, 'support': 1132}
 
----------
Epoch 11/40
time = 1900.42 secondes

Train loss 0.10113796948463406 accuracy 0.9773129224777222 macro_avg {'precision': 0.9770845803308109, 'recall': 0.9771694613391926, 'f1-score': 0.9771017026734075, 'support': 10182} weighted_avg {'precision': 0.9774434620067302, 'recall': 0.9773129051266942, 'f1-score': 0.9773537275139177, 'support': 10182}
 
time = 37.60 secondes

Val loss 0.6287051244820452 accuracy 0.9054770469665527 macro_avg {'precision': 0.9080986235736856, 'recall': 0.9068819152330818, 'f1-score': 0.9054338244641593, 'support': 1132} weighted_avg {'precision': 0.9103726183973925, 'recall': 0.9054770318021201, 'f1-score': 0.9060057071547207, 'support': 1132}
 
----------
Epoch 12/40
time = 2040.07 secondes

Train loss 0.08617716367733687 accuracy 0.9817324876785278 macro_avg {'precision': 0.9811334698522989, 'recall': 0.9811672103192759, 'f1-score': 0.9811267362499132, 'support': 10182} weighted_avg {'precision': 0.9817720074582165, 'recall': 0.9817324690630524, 'f1-score': 0.9817292221112568, 'support': 10182}
 
time = 48.06 secondes

Val loss 0.585300954819975 accuracy 0.9125441908836365 macro_avg {'precision': 0.9179873366170479, 'recall': 0.9150478423393975, 'f1-score': 0.9146974958869085, 'support': 1132} weighted_avg {'precision': 0.9163932432776302, 'recall': 0.9125441696113075, 'f1-score': 0.9125454362587012, 'support': 1132}
 
----------
Epoch 13/40
time = 2124.19 secondes

Train loss 0.10819553624578347 accuracy 0.9795718193054199 macro_avg {'precision': 0.9792336384201275, 'recall': 0.9786047609840143, 'f1-score': 0.978853858040171, 'support': 10182} weighted_avg {'precision': 0.9796528007033156, 'recall': 0.9795717933608329, 'f1-score': 0.9795540549150478, 'support': 10182}
 
time = 48.14 secondes

Val loss 0.7345305131492122 accuracy 0.9001767039299011 macro_avg {'precision': 0.9061084479370063, 'recall': 0.9056800992331097, 'f1-score': 0.9032773380046851, 'support': 1132} weighted_avg {'precision': 0.9076859213914781, 'recall': 0.9001766784452296, 'f1-score': 0.9012842574979977, 'support': 1132}
 
----------
Epoch 14/40
time = 2122.03 secondes

Train loss 0.09124500429026747 accuracy 0.9819289445877075 macro_avg {'precision': 0.9817926380488, 'recall': 0.9815666461929895, 'f1-score': 0.9816565644823282, 'support': 10182} weighted_avg {'precision': 0.9819740030293084, 'recall': 0.9819288941268906, 'f1-score': 0.9819291341264594, 'support': 10182}
 
time = 48.96 secondes

Val loss 0.6810643338126091 accuracy 0.9134275913238525 macro_avg {'precision': 0.9198825708113905, 'recall': 0.9140672107936686, 'f1-score': 0.9153541274370427, 'support': 1132} weighted_avg {'precision': 0.9182135776156307, 'recall': 0.9134275618374559, 'f1-score': 0.914202745038032, 'support': 1132}
 
----------
Epoch 15/40
time = 2060.85 secondes

Train loss 0.09871532943805997 accuracy 0.9808486104011536 macro_avg {'precision': 0.9806494110454527, 'recall': 0.9804752619523667, 'f1-score': 0.9805179669351421, 'support': 10182} weighted_avg {'precision': 0.9810222602464229, 'recall': 0.9808485562757808, 'f1-score': 0.9808895812415336, 'support': 10182}
 
time = 47.80 secondes

Val loss 0.553848441905206 accuracy 0.9222614765167236 macro_avg {'precision': 0.9250074117225351, 'recall': 0.9253214580331746, 'f1-score': 0.9237605855983511, 'support': 1132} weighted_avg {'precision': 0.9246153199288919, 'recall': 0.9222614840989399, 'f1-score': 0.9219209810363115, 'support': 1132}
 
----------
Epoch 16/40
time = 2127.40 secondes

Train loss 0.08201466460904695 accuracy 0.985660970211029 macro_avg {'precision': 0.9854104141884402, 'recall': 0.9855020709317894, 'f1-score': 0.9854212639256842, 'support': 10182} weighted_avg {'precision': 0.9857433806092081, 'recall': 0.9856609703398154, 'f1-score': 0.9856694574470957, 'support': 10182}
 
time = 47.74 secondes

Val loss 0.7002011709481734 accuracy 0.9072438478469849 macro_avg {'precision': 0.9142125660777587, 'recall': 0.9107055992792995, 'f1-score': 0.9099038256277934, 'support': 1132} weighted_avg {'precision': 0.9140386785165261, 'recall': 0.907243816254417, 'f1-score': 0.9079017991039653, 'support': 1132}
 
----------
Epoch 17/40
time = 2044.43 secondes

Train loss 0.08366531127825257 accuracy 0.9840896129608154 macro_avg {'precision': 0.9839680135077906, 'recall': 0.9836171316926595, 'f1-score': 0.983766664835765, 'support': 10182} weighted_avg {'precision': 0.9841096443277013, 'recall': 0.9840895698291102, 'f1-score': 0.9840750776638535, 'support': 10182}
 
time = 37.92 secondes

Val loss 0.6603569410299442 accuracy 0.9116607904434204 macro_avg {'precision': 0.9144224309513618, 'recall': 0.9143972684781614, 'f1-score': 0.9129792045827033, 'support': 1132} weighted_avg {'precision': 0.914757328042731, 'recall': 0.911660777385159, 'f1-score': 0.9117791169230579, 'support': 1132}
 
----------
Epoch 18/40
time = 2149.18 secondes

Train loss 0.0714174468829207 accuracy 0.9870359897613525 macro_avg {'precision': 0.9861649931172108, 'recall': 0.9860975294336933, 'f1-score': 0.9861151642441296, 'support': 10182} weighted_avg {'precision': 0.9870591458271288, 'recall': 0.9870359457866824, 'f1-score': 0.9870319883930724, 'support': 10182}
 
time = 47.33 secondes

Val loss 0.6291328434363863 accuracy 0.916077733039856 macro_avg {'precision': 0.9190846236148609, 'recall': 0.9177412212306795, 'f1-score': 0.9164666404428555, 'support': 1132} weighted_avg {'precision': 0.9198893737867287, 'recall': 0.916077738515901, 'f1-score': 0.9160512583121256, 'support': 1132}
 
----------
Epoch 19/40
time = 2154.60 secondes

Train loss 0.07241392521006004 accuracy 0.9869377613067627 macro_avg {'precision': 0.9867328391570425, 'recall': 0.9867226200844085, 'f1-score': 0.9867133765342645, 'support': 10182} weighted_avg {'precision': 0.9869518919041432, 'recall': 0.9869377332547633, 'f1-score': 0.986930454843812, 'support': 10182}
 
time = 47.85 secondes

Val loss 0.8314769241680525 accuracy 0.8957597017288208 macro_avg {'precision': 0.9081525515649419, 'recall': 0.9009193539735241, 'f1-score': 0.899145759023663, 'support': 1132} weighted_avg {'precision': 0.9102577922846292, 'recall': 0.8957597173144877, 'f1-score': 0.8974559847735232, 'support': 1132}
 
----------
Epoch 20/40
time = 2152.42 secondes

Train loss 0.0717819512752995 accuracy 0.9873306155204773 macro_avg {'precision': 0.986738217244765, 'recall': 0.9871639173330363, 'f1-score': 0.9869278333886701, 'support': 10182} weighted_avg {'precision': 0.9873924521754223, 'recall': 0.9873305833824396, 'f1-score': 0.9873427083141749, 'support': 10182}
 
time = 46.84 secondes

Val loss 0.6780765880168577 accuracy 0.9081271886825562 macro_avg {'precision': 0.9140136671453563, 'recall': 0.9103852618091353, 'f1-score': 0.9102431530924001, 'support': 1132} weighted_avg {'precision': 0.9131416877524424, 'recall': 0.9081272084805654, 'f1-score': 0.9085898257464095, 'support': 1132}
 
----------
Epoch 21/40
time = 2158.41 secondes

Train loss 0.06320664156228761 accuracy 0.9882145524024963 macro_avg {'precision': 0.9879479344602291, 'recall': 0.988016137809986, 'f1-score': 0.9879692396290652, 'support': 10182} weighted_avg {'precision': 0.9882278172258595, 'recall': 0.9882144961697112, 'f1-score': 0.9882089880889836, 'support': 10182}
 
time = 47.92 secondes

Val loss 0.6760288282388962 accuracy 0.9090105891227722 macro_avg {'precision': 0.9102182010245858, 'recall': 0.9093904892962712, 'f1-score': 0.9080974296603694, 'support': 1132} weighted_avg {'precision': 0.9117076556166245, 'recall': 0.9090106007067138, 'f1-score': 0.9088287214596937, 'support': 1132}
 
----------
Epoch 22/40
time = 2111.69 secondes

Train loss 0.07758028933092295 accuracy 0.9883127212524414 macro_avg {'precision': 0.9882669111236826, 'recall': 0.988278734386111, 'f1-score': 0.98823127711681, 'support': 10182} weighted_avg {'precision': 0.9883981464302051, 'recall': 0.9883127087016303, 'f1-score': 0.9883134348230969, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.6356262355173027 accuracy 0.9125441908836365 macro_avg {'precision': 0.9158009618817584, 'recall': 0.9134573290680716, 'f1-score': 0.9131806014194627, 'support': 1132} weighted_avg {'precision': 0.9161095885069024, 'recall': 0.9125441696113075, 'f1-score': 0.9129070644588356, 'support': 1132}
 
----------
Epoch 23/40
time = 1911.08 secondes

Train loss 0.059018114147842325 accuracy 0.989589512348175 macro_avg {'precision': 0.9892973645375879, 'recall': 0.9893006063837072, 'f1-score': 0.9892849053411107, 'support': 10182} weighted_avg {'precision': 0.9896339405313096, 'recall': 0.9895894716165783, 'f1-score': 0.989597550455413, 'support': 10182}
 
time = 39.30 secondes

Val loss 0.7092625546889317 accuracy 0.9063604474067688 macro_avg {'precision': 0.9102901015741267, 'recall': 0.9064624350595313, 'f1-score': 0.9058580432952711, 'support': 1132} weighted_avg {'precision': 0.9134579169436569, 'recall': 0.9063604240282686, 'f1-score': 0.9073786253323705, 'support': 1132}
 
----------
Epoch 24/40
time = 1913.02 secondes

Train loss 0.052221872190530635 accuracy 0.9911609292030334 macro_avg {'precision': 0.9908799169053703, 'recall': 0.9909411310418763, 'f1-score': 0.9908990599520393, 'support': 10182} weighted_avg {'precision': 0.9911760504026889, 'recall': 0.9911608721272834, 'f1-score': 0.9911567900236038, 'support': 10182}
 
time = 39.66 secondes

Val loss 0.7643609443362999 accuracy 0.9028268456459045 macro_avg {'precision': 0.9071735146036503, 'recall': 0.8984901590483663, 'f1-score': 0.8996492739471835, 'support': 1132} weighted_avg {'precision': 0.9077772867330666, 'recall': 0.9028268551236749, 'f1-score': 0.9022424010264417, 'support': 1132}
 
----------
Epoch 25/40
time = 1911.04 secondes

Train loss 0.04230558340462336 accuracy 0.9927322864532471 macro_avg {'precision': 0.9926758165910871, 'recall': 0.9924986163960637, 'f1-score': 0.9925763378794054, 'support': 10182} weighted_avg {'precision': 0.9927473833937369, 'recall': 0.9927322726379886, 'f1-score': 0.9927292399914478, 'support': 10182}
 
time = 39.50 secondes

Val loss 0.7817445465130527 accuracy 0.9054770469665527 macro_avg {'precision': 0.906861639202741, 'recall': 0.9090966453829517, 'f1-score': 0.9058034704678682, 'support': 1132} weighted_avg {'precision': 0.9106944175961698, 'recall': 0.9054770318021201, 'f1-score': 0.9058285569210767, 'support': 1132}
 
----------
Epoch 26/40
time = 1911.51 secondes

Train loss 0.04851724282365341 accuracy 0.9913573265075684 macro_avg {'precision': 0.9911691638401893, 'recall': 0.9910470127700695, 'f1-score': 0.9910998140300921, 'support': 10182} weighted_avg {'precision': 0.9913825735140195, 'recall': 0.9913572971911215, 'f1-score': 0.9913614515544082, 'support': 10182}
 
time = 48.89 secondes

Val loss 0.856581264329602 accuracy 0.8957597017288208 macro_avg {'precision': 0.9026637212038187, 'recall': 0.8994316098851278, 'f1-score': 0.8971259217873193, 'support': 1132} weighted_avg {'precision': 0.905213740177932, 'recall': 0.8957597173144877, 'f1-score': 0.8965282060933666, 'support': 1132}
 
----------
Epoch 27/40
time = 2159.98 secondes

Train loss 0.04223478866164559 accuracy 0.9928305149078369 macro_avg {'precision': 0.9930527683176236, 'recall': 0.9928317158219346, 'f1-score': 0.9929228388517896, 'support': 10182} weighted_avg {'precision': 0.9928898416673239, 'recall': 0.9928304851699077, 'f1-score': 0.992840286368866, 'support': 10182}
 
time = 48.04 secondes

Val loss 0.8138090606896096 accuracy 0.9037102460861206 macro_avg {'precision': 0.9160669887478445, 'recall': 0.9087021155813024, 'f1-score': 0.9090472390304548, 'support': 1132} weighted_avg {'precision': 0.9161039850187296, 'recall': 0.9037102473498233, 'f1-score': 0.9062746934099546, 'support': 1132}
 
----------
Epoch 28/40
time = 2156.46 secondes

Train loss 0.04451652782687687 accuracy 0.9920448064804077 macro_avg {'precision': 0.9915857331658426, 'recall': 0.991499499881337, 'f1-score': 0.9915318710115402, 'support': 10182} weighted_avg {'precision': 0.9920658571569596, 'recall': 0.9920447849145551, 'f1-score': 0.9920445162170827, 'support': 10182}
 
time = 47.18 secondes

Val loss 0.808506310186562 accuracy 0.9010601043701172 macro_avg {'precision': 0.9187251178217698, 'recall': 0.9050638282506009, 'f1-score': 0.907410414698812, 'support': 1132} weighted_avg {'precision': 0.916517413579897, 'recall': 0.901060070671378, 'f1-score': 0.9041290028936136, 'support': 1132}
 
----------
Epoch 29/40
time = 2156.88 secondes

Train loss 0.04444346560509072 accuracy 0.9930269122123718 macro_avg {'precision': 0.9925024635047617, 'recall': 0.9925295307270803, 'f1-score': 0.9924984992933817, 'support': 10182} weighted_avg {'precision': 0.9930437515203543, 'recall': 0.9930269102337458, 'f1-score': 0.9930202574542651, 'support': 10182}
 
time = 47.81 secondes

Val loss 0.7298810416133664 accuracy 0.9107773900032043 macro_avg {'precision': 0.9187140411393342, 'recall': 0.9119797804180759, 'f1-score': 0.9116871687865553, 'support': 1132} weighted_avg {'precision': 0.9182528210282341, 'recall': 0.9107773851590106, 'f1-score': 0.9110596808578899, 'support': 1132}
 
----------
Epoch 30/40
time = 2159.81 secondes

Train loss 0.03122448402588889 accuracy 0.9946965575218201 macro_avg {'precision': 0.9946951213505522, 'recall': 0.9947376682720112, 'f1-score': 0.9947095878863543, 'support': 10182} weighted_avg {'precision': 0.9947062919689105, 'recall': 0.99469652327637, 'f1-score': 0.9946945112157918, 'support': 10182}
 
time = 48.17 secondes

Val loss 0.7394343704986632 accuracy 0.9098939895629883 macro_avg {'precision': 0.9121503780674329, 'recall': 0.9127817757345456, 'f1-score': 0.9097171413292587, 'support': 1132} weighted_avg {'precision': 0.9172676935363232, 'recall': 0.9098939929328622, 'f1-score': 0.9111258401972475, 'support': 1132}
 
----------
Epoch 31/40
time = 2181.05 secondes

Train loss 0.026095411540594356 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955694337324429, 'recall': 0.9956061725410871, 'f1-score': 0.9955836570987024, 'support': 10182} weighted_avg {'precision': 0.9955878701458087, 'recall': 0.9955804360636418, 'f1-score': 0.9955799824849897, 'support': 10182}
 
time = 47.94 secondes

Val loss 0.7603093923482934 accuracy 0.9116607904434204 macro_avg {'precision': 0.9167729996295618, 'recall': 0.9135815426882001, 'f1-score': 0.9126206617316075, 'support': 1132} weighted_avg {'precision': 0.9181617758343101, 'recall': 0.911660777385159, 'f1-score': 0.9123596745279325, 'support': 1132}
 
----------
Epoch 32/40
time = 2160.61 secondes

Train loss 0.024942817518566293 accuracy 0.9960715174674988 macro_avg {'precision': 0.9960234861604732, 'recall': 0.9960104271999383, 'f1-score': 0.9960137584487907, 'support': 10182} weighted_avg {'precision': 0.9960767311775123, 'recall': 0.9960714987232371, 'f1-score': 0.9960712105678028, 'support': 10182}
 
time = 48.03 secondes

Val loss 0.708478327377826 accuracy 0.9134275913238525 macro_avg {'precision': 0.9176187796777009, 'recall': 0.9160699960914288, 'f1-score': 0.9148099008525907, 'support': 1132} weighted_avg {'precision': 0.9162965206357123, 'recall': 0.9134275618374559, 'f1-score': 0.9128717788785847, 'support': 1132}
 
----------
Epoch 33/40
time = 2159.53 secondes

Train loss 0.024676660401774044 accuracy 0.9958751201629639 macro_avg {'precision': 0.9958605500233269, 'recall': 0.9958005364688945, 'f1-score': 0.9958276699902884, 'support': 10182} weighted_avg {'precision': 0.9958855614596863, 'recall': 0.995875073659399, 'f1-score': 0.9958774096691759, 'support': 10182}
 
time = 47.78 secondes

Val loss 0.7168481043000086 accuracy 0.9143109321594238 macro_avg {'precision': 0.9152315023921702, 'recall': 0.9174024081453833, 'f1-score': 0.9152533378073121, 'support': 1132} weighted_avg {'precision': 0.9160662371042418, 'recall': 0.9143109540636042, 'f1-score': 0.9141187513978153, 'support': 1132}
 
----------
Epoch 34/40
time = 2161.25 secondes

Train loss 0.02235577041920953 accuracy 0.9961697459220886 macro_avg {'precision': 0.9958472059764686, 'recall': 0.9958269195932635, 'f1-score': 0.9958318400419902, 'support': 10182} weighted_avg {'precision': 0.9961813613027164, 'recall': 0.9961697112551562, 'f1-score': 0.9961704081240912, 'support': 10182}
 
time = 47.62 secondes

Val loss 0.683466312304415 accuracy 0.9222614765167236 macro_avg {'precision': 0.9271007985380668, 'recall': 0.9254099586956412, 'f1-score': 0.9254256415666481, 'support': 1132} weighted_avg {'precision': 0.9235688538751108, 'recall': 0.9222614840989399, 'f1-score': 0.9220570623830887, 'support': 1132}
 
----------
Epoch 35/40
time = 2162.55 secondes

Train loss 0.016322639307937283 accuracy 0.9966608285903931 macro_avg {'precision': 0.9965307362504399, 'recall': 0.9965999562083953, 'f1-score': 0.9965619697596431, 'support': 10182} weighted_avg {'precision': 0.996666278157454, 'recall': 0.9966607739147515, 'f1-score': 0.9966605081800972, 'support': 10182}
 
time = 48.43 secondes

Val loss 0.6464281499974673 accuracy 0.9293286204338074 macro_avg {'precision': 0.9332490013212367, 'recall': 0.933119560782318, 'f1-score': 0.9323966395091825, 'support': 1132} weighted_avg {'precision': 0.9312757414431184, 'recall': 0.9293286219081273, 'f1-score': 0.9294655883429623, 'support': 1132}
 
----------
Epoch 36/40
time = 2161.56 secondes

Train loss 0.01171362398999518 accuracy 0.9974464774131775 macro_avg {'precision': 0.997242163401531, 'recall': 0.9972211542176371, 'f1-score': 0.9972294795114826, 'support': 10182} weighted_avg {'precision': 0.9974506436898356, 'recall': 0.9974464741701041, 'f1-score': 0.99744636412729, 'support': 10182}
 
time = 48.13 secondes

Val loss 0.6981696736473962 accuracy 0.926678478717804 macro_avg {'precision': 0.9265650246452107, 'recall': 0.9304126761455873, 'f1-score': 0.9275804013571266, 'support': 1132} weighted_avg {'precision': 0.9282975357135458, 'recall': 0.926678445229682, 'f1-score': 0.9265386486689217, 'support': 1132}
 
----------
Epoch 37/40
time = 2059.34 secondes

Train loss 0.010138371551352459 accuracy 0.9985268115997314 macro_avg {'precision': 0.9983998079667403, 'recall': 0.998464724023777, 'f1-score': 0.998430028944702, 'support': 10182} weighted_avg {'precision': 0.9985315462264761, 'recall': 0.998526812021214, 'f1-score': 0.9985271147355406, 'support': 10182}
 
time = 39.36 secondes

Val loss 0.6816274705532277 accuracy 0.9284452199935913 macro_avg {'precision': 0.9301206538591066, 'recall': 0.9320159622986788, 'f1-score': 0.9299139492552964, 'support': 1132} weighted_avg {'precision': 0.9299374594464477, 'recall': 0.9284452296819788, 'f1-score': 0.9278821956520056, 'support': 1132}
 
----------
Epoch 38/40
time = 1907.94 secondes

Train loss 0.007738084421096579 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985862099406975, 'recall': 0.9985588905807307, 'f1-score': 0.998571461502092, 'support': 10182} weighted_avg {'precision': 0.9985285984497417, 'recall': 0.998526812021214, 'f1-score': 0.998526586307973, 'support': 10182}
 
time = 40.21 secondes

Val loss 0.5945624369344931 accuracy 0.9363957643508911 macro_avg {'precision': 0.9399203473006688, 'recall': 0.9384499900655767, 'f1-score': 0.9384928286758492, 'support': 1132} weighted_avg {'precision': 0.938331470837759, 'recall': 0.9363957597173145, 'f1-score': 0.9366085038010538, 'support': 1132}
 
----------
Epoch 39/40
time = 1908.33 secondes

Train loss 0.011908268075491477 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979749083901759, 'recall': 0.9979908081335045, 'f1-score': 0.9979781676883823, 'support': 10182} weighted_avg {'precision': 0.9979428408421454, 'recall': 0.9979375368296994, 'f1-score': 0.9979354491127322, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6279981948686788 accuracy 0.9319788217544556 macro_avg {'precision': 0.9359320002317313, 'recall': 0.9349507219114569, 'f1-score': 0.9344379397801701, 'support': 1132} weighted_avg {'precision': 0.9338410483286432, 'recall': 0.9319787985865724, 'f1-score': 0.9318385667317426, 'support': 1132}
 
----------
Epoch 40/40
time = 1908.01 secondes

Train loss 0.004059259332616863 accuracy 0.9992143511772156 macro_avg {'precision': 0.9991850610390396, 'recall': 0.9992302543749861, 'f1-score': 0.9992065952408312, 'support': 10182} weighted_avg {'precision': 0.999216101086216, 'recall': 0.9992142997446474, 'f1-score': 0.9992141469464708, 'support': 10182}
 
time = 39.84 secondes

Val loss 0.6197170782537617 accuracy 0.9302120208740234 macro_avg {'precision': 0.9340925491746171, 'recall': 0.9331618993583726, 'f1-score': 0.9326572599277279, 'support': 1132} weighted_avg {'precision': 0.931636130149612, 'recall': 0.9302120141342756, 'f1-score': 0.9299353822194143, 'support': 1132}
 
----------
best_accuracy 0.9363957643508911 best_epoch 38 macro_avg {'precision': 0.9399203473006688, 'recall': 0.9384499900655767, 'f1-score': 0.9384928286758492, 'support': 1132} weighted_avg {'precision': 0.938331470837759, 'recall': 0.9363957597173145, 'f1-score': 0.9366085038010538, 'support': 1132}

average train time 2033.1693645000457

average val time 43.43557958006859
 
time = 259.38 secondes

test_accuracy 0.8639139533042908 macro_avg {'precision': 0.866037351750699, 'recall': 0.8557117391725685, 'f1-score': 0.8574969597245664, 'support': 7532} weighted_avg {'precision': 0.871757103253119, 'recall': 0.8639139670738184, 'f1-score': 0.8645714593713931, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 772.00 MiB (GPU 0; 79.21 GiB total capacity; 70.37 GiB already allocated; 294.62 MiB free; 75.04 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_1
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 70.56 GiB already allocated; 2.25 GiB free; 73.08 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_2
----------
Epoch 1/40
time = 34.87 secondes

Train loss 0.6107581411347245 accuracy 0.6860464811325073 macro_avg {'precision': 0.8168598045898658, 'recall': 0.5679989597386343, 'f1-score': 0.5224733222128282, 'support': 516} weighted_avg {'precision': 0.7766531214716882, 'recall': 0.686046511627907, 'f1-score': 0.5993852192225673, 'support': 516}
 
time = 1.50 secondes

Val loss 0.49588315933942795 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 2/40
time = 34.77 secondes

Train loss 0.4357805053393046 accuracy 0.7984496355056763 macro_avg {'precision': 0.7825513317390946, 'recall': 0.7784730913642053, 'f1-score': 0.7803823991618648, 'support': 516} weighted_avg {'precision': 0.7972107853383729, 'recall': 0.7984496124031008, 'f1-score': 0.7977171578122398, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4898282662034035 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 33.97 secondes

Train loss 0.26846230639652774 accuracy 0.8914728760719299 macro_avg {'precision': 0.8839167035888347, 'recall': 0.8802724184451344, 'f1-score': 0.8820282518167715, 'support': 516} weighted_avg {'precision': 0.8910698727702159, 'recall': 0.8914728682170543, 'f1-score': 0.8912141116033478, 'support': 516}
 
time = 1.51 secondes

Val loss 0.40541649237275124 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 4/40
time = 34.18 secondes

Train loss 0.1592753194836956 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.51 secondes

Val loss 0.38632142543792725 accuracy 0.90625 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}
 
----------
Epoch 5/40
time = 34.18 secondes

Train loss 0.17247542645782232 accuracy 0.9418604373931885 macro_avg {'precision': 0.933040597308308, 'recall': 0.9440209352599841, 'f1-score': 0.937920082131571, 'support': 516} weighted_avg {'precision': 0.9436543365348494, 'recall': 0.9418604651162791, 'f1-score': 0.942224192776406, 'support': 516}
 
time = 1.50 secondes

Val loss 0.45868580788373947 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 6/40
time = 34.30 secondes

Train loss 0.32523808801885357 accuracy 0.895348846912384 macro_avg {'precision': 0.8834416657485953, 'recall': 0.8960063716008647, 'f1-score': 0.8887131560028756, 'support': 516} weighted_avg {'precision': 0.8988127416342353, 'recall': 0.8953488372093024, 'f1-score': 0.8961914633942454, 'support': 516}
 
time = 1.54 secondes

Val loss 0.6355594284832478 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 7/40
time = 34.04 secondes

Train loss 0.11072410329837691 accuracy 0.9689922332763672 macro_avg {'precision': 0.9710226613397874, 'recall': 0.9618354111470506, 'f1-score': 0.9661300644907203, 'support': 516} weighted_avg {'precision': 0.9691978595331823, 'recall': 0.9689922480620154, 'f1-score': 0.9688395982715464, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9443796724081039 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 8/40
time = 34.19 secondes

Train loss 0.09683909679932351 accuracy 0.9651162624359131 macro_avg {'precision': 0.9655149666034468, 'recall': 0.9587958974692392, 'f1-score': 0.9619892613933996, 'support': 516} weighted_avg {'precision': 0.9651473456308333, 'recall': 0.9651162790697675, 'f1-score': 0.9649895080828875, 'support': 516}
 
time = 1.48 secondes

Val loss 0.8127479278482497 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 9/40
time = 34.10 secondes

Train loss 0.2704446563906403 accuracy 0.9302325248718262 macro_avg {'precision': 0.9293535323233839, 'recall': 0.9187458348910164, 'f1-score': 0.9236033427650194, 'support': 516} weighted_avg {'precision': 0.9301240364338372, 'recall': 0.9302325581395349, 'f1-score': 0.9297964255491064, 'support': 516}
 
time = 1.51 secondes

Val loss 0.5891431677155197 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 10/40
time = 34.10 secondes

Train loss 0.18111762638330797 accuracy 0.9534883499145508 macro_avg {'precision': 0.9447998104714522, 'recall': 0.9577556361035711, 'f1-score': 0.9504386245757828, 'support': 516} weighted_avg {'precision': 0.9556224047720056, 'recall': 0.9534883720930233, 'f1-score': 0.9538219382277215, 'support': 516}
 
time = 1.57 secondes

Val loss 1.3484899550676346 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 11/40
time = 34.62 secondes

Train loss 0.2402300181019007 accuracy 0.9457364082336426 macro_avg {'precision': 0.9465526723663817, 'recall': 0.935520049412415, 'f1-score': 0.9405803777061261, 'support': 516} weighted_avg {'precision': 0.9458372042638178, 'recall': 0.9457364341085271, 'f1-score': 0.945397219871527, 'support': 516}
 
time = 1.57 secondes

Val loss 0.6374709606170654 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 12/40
time = 33.97 secondes

Train loss 0.045062111350213825 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3050492703914642 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 13/40
time = 33.94 secondes

Train loss 0.11939008744560521 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.44 secondes

Val loss 0.9848721772432327 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 14/40
time = 33.92 secondes

Train loss 0.2913572263496462 accuracy 0.9437984228134155 macro_avg {'precision': 0.9476744186046512, 'recall': 0.9305381727158948, 'f1-score': 0.9380647083900715, 'support': 516} weighted_avg {'precision': 0.9444744907157022, 'recall': 0.9437984496124031, 'f1-score': 0.9432506399414797, 'support': 516}
 
time = 1.48 secondes

Val loss 1.1201077327132225 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 15/40
time = 34.03 secondes

Train loss 0.36632283535436727 accuracy 0.9224806427955627 macro_avg {'precision': 0.9243325705568268, 'recall': 0.9068966077727029, 'f1-score': 0.9144604877078395, 'support': 516} weighted_avg {'precision': 0.922821208734678, 'recall': 0.9224806201550387, 'f1-score': 0.92166845484393, 'support': 516}
 
time = 1.50 secondes

Val loss 1.13884936273098 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 16/40
time = 34.13 secondes

Train loss 0.052836215072382016 accuracy 0.9844961166381836 macro_avg {'precision': 0.982185330809184, 'recall': 0.9843798254311396, 'f1-score': 0.9832641411520499, 'support': 516} weighted_avg {'precision': 0.9845631035446839, 'recall': 0.9844961240310077, 'f1-score': 0.9845137237864214, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3301789313554764 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 34.59 secondes

Train loss 0.33300172169004905 accuracy 0.9437984228134155 macro_avg {'precision': 0.9328703703703703, 'recall': 0.9559270516717325, 'f1-score': 0.9409673868876904, 'support': 516} weighted_avg {'precision': 0.9513440281366637, 'recall': 0.9437984496124031, 'f1-score': 0.9445250055329046, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9965019971132278 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 18/40
time = 34.13 secondes

Train loss 0.4197355931418398 accuracy 0.9263566136360168 macro_avg {'precision': 0.9482288828337875, 'recall': 0.8983957219251337, 'f1-score': 0.9161535303776682, 'support': 516} weighted_avg {'precision': 0.9339817924508376, 'recall': 0.9263565891472868, 'f1-score': 0.9242026100737006, 'support': 516}
 
time = 1.51 secondes

Val loss 1.5774069279432297 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 34.65 secondes

Train loss 0.21415513989102858 accuracy 0.961240291595459 macro_avg {'precision': 0.954091943414541, 'recall': 0.9638346634591941, 'f1-score': 0.9585262345679012, 'support': 516} weighted_avg {'precision': 0.9624121734648929, 'recall': 0.9612403100775194, 'f1-score': 0.961445921858551, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6707407236099243 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 20/40
time = 33.96 secondes

Train loss 0.02310774569129783 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6526921689510345 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 21/40
time = 34.21 secondes

Train loss 0.0768780970587007 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.50 secondes

Val loss 1.703554093837738 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 22/40
time = 34.10 secondes

Train loss 0.07030590908481937 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.55 secondes

Val loss 1.500977709889412 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 23/40
time = 34.15 secondes

Train loss 0.11323480788842337 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.51 secondes

Val loss 1.509798675775528 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 24/40
time = 33.92 secondes

Train loss 0.022001946979964323 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.52 secondes

Val loss 1.2816107720136642 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 25/40
time = 34.78 secondes

Train loss 0.04268207642775396 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5122756510972977 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 34.19 secondes

Train loss 0.02142661197682504 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6555854976177216 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 27/40
time = 34.01 secondes

Train loss 0.07036008313761241 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.33 secondes

Val loss 2.6913294196128845 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 28/40
time = 33.98 secondes

Train loss 0.0898894755133149 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.53 secondes

Val loss 1.6057852804660797 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 29/40
time = 34.84 secondes

Train loss 0.11133792869937183 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4230136722326279 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 30/40
time = 34.06 secondes

Train loss 0.04395649281319824 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.49 secondes

Val loss 1.2934226095676422 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 31/40
time = 34.22 secondes

Train loss 0.03373657888710802 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.47 secondes

Val loss 1.39627193659544 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 32/40
time = 34.05 secondes

Train loss 0.0017817309102004704 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.48 secondes

Val loss 2.2256408631801605 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 33/40
time = 34.12 secondes

Train loss 0.16150784425002657 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4890313297510147 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 34/40
time = 34.68 secondes

Train loss 0.0008754433264116277 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.6566524074878544 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 35/40
time = 34.22 secondes

Train loss 0.006783406547611142 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.41 secondes

Val loss 2.014328509569168 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 36/40
time = 34.14 secondes

Train loss 0.056957905013625736 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4628697335720062 accuracy 0.734375 macro_avg {'precision': 0.7571428571428571, 'recall': 0.6912955465587045, 'f1-score': 0.694981777403981, 'support': 64} weighted_avg {'precision': 0.7491071428571429, 'recall': 0.734375, 'f1-score': 0.7155347631062519, 'support': 64}
 
----------
Epoch 37/40
time = 33.61 secondes

Train loss 0.00012023055916704999 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.523040845990181 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 38/40
time = 34.64 secondes

Train loss 7.210184853509858e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.58 secondes

Val loss 1.490858182311058 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 33.74 secondes

Train loss 8.158302906932394e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.53 secondes

Val loss 1.3377542436737713 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 40/40
time = 34.08 secondes

Train loss 0.00029813356178982014 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.3483676348814697 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
best_accuracy 0.90625 best_epoch 4 macro_avg {'precision': 0.902834008097166, 'recall': 0.902834008097166, 'f1-score': 0.902834008097166, 'support': 64} weighted_avg {'precision': 0.90625, 'recall': 0.90625, 'f1-score': 0.90625, 'support': 64}

average train time 34.208909338712694

average val time 1.4956054151058198
 
time = 1.72 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9425, 'recall': 0.9312865497076024, 'f1-score': 0.9358974358974359, 'support': 65} weighted_avg {'precision': 0.9395384615384614, 'recall': 0.9384615384615385, 'f1-score': 0.9380670611439843, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_2
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 22.67 secondes

Train loss 0.6167737236528685 accuracy 0.6744186282157898 macro_avg {'precision': 0.7272727272727273, 'recall': 0.5588804187051997, 'f1-score': 0.5147335423197492, 'support': 516} weighted_avg {'precision': 0.710594315245478, 'recall': 0.6744186046511628, 'f1-score': 0.5913392141138732, 'support': 516}
 
time = 1.09 secondes

Val loss 0.5244618356227875 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 2/40
time = 22.39 secondes

Train loss 0.435084421526302 accuracy 0.8003876209259033 macro_avg {'precision': 0.7868242094525671, 'recall': 0.7742226484404207, 'f1-score': 0.7794460006224712, 'support': 516} weighted_avg {'precision': 0.7977673970515751, 'recall': 0.8003875968992248, 'f1-score': 0.7981485583035971, 'support': 516}
 
time = 1.13 secondes

Val loss 0.46717724204063416 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 22.46 secondes

Train loss 0.2983296414216359 accuracy 0.8856589198112488 macro_avg {'precision': 0.8812764670296431, 'recall': 0.8687889082131885, 'f1-score': 0.8743183159876315, 'support': 516} weighted_avg {'precision': 0.8849806787752594, 'recall': 0.8856589147286822, 'f1-score': 0.8847077677374973, 'support': 516}
 
time = 1.14 secondes

Val loss 0.6183440908789635 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 4/40
time = 22.42 secondes

Train loss 0.2524723759429021 accuracy 0.9166666865348816 macro_avg {'precision': 0.908179012345679, 'recall': 0.9127236968288283, 'f1-score': 0.9103468060948656, 'support': 516} weighted_avg {'precision': 0.917309670781893, 'recall': 0.9166666666666666, 'f1-score': 0.9168973185123528, 'support': 516}
 
time = 1.15 secondes

Val loss 0.8304944038391113 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 5/40
time = 22.54 secondes

Train loss 0.23848583842768814 accuracy 0.9205426573753357 macro_avg {'precision': 0.9152370350969093, 'recall': 0.9123010906490255, 'f1-score': 0.9137303195762363, 'support': 516} weighted_avg {'precision': 0.9203275437442389, 'recall': 0.9205426356589147, 'f1-score': 0.9204016911882387, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7162928432226181 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 6/40
time = 22.36 secondes

Train loss 0.1536944911561229 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.11 secondes

Val loss 0.8266520500183105 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 7/40
time = 22.40 secondes

Train loss 0.13110328520732847 accuracy 0.963178277015686 macro_avg {'precision': 0.9606549364613881, 'recall': 0.9595842205354095, 'f1-score': 0.960115049612094, 'support': 516} weighted_avg {'precision': 0.9631432479331955, 'recall': 0.9631782945736435, 'f1-score': 0.9631568732802058, 'support': 516}
 
time = 1.13 secondes

Val loss 0.7191703170537949 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 8/40
time = 22.41 secondes

Train loss 0.36044774259525264 accuracy 0.8972868323326111 macro_avg {'precision': 0.8855868070883521, 'recall': 0.8975261284397705, 'f1-score': 0.8906635429201966, 'support': 516} weighted_avg {'precision': 0.9004207541921426, 'recall': 0.8972868217054264, 'f1-score': 0.898069098727304, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0168915092945099 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 9/40
time = 22.44 secondes

Train loss 0.12554533697424852 accuracy 0.9573643207550049 macro_avg {'precision': 0.9581917344959634, 'recall': 0.9492547502560018, 'f1-score': 0.9534288386747403, 'support': 516} weighted_avg {'precision': 0.9574481277597718, 'recall': 0.9573643410852714, 'f1-score': 0.9571544476233763, 'support': 516}
 
time = 1.15 secondes

Val loss 1.3144756704568863 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 10/40
time = 22.44 secondes

Train loss 0.09364884840253966 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2429487332701683 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 11/40
time = 22.48 secondes

Train loss 0.15311901879877868 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 1.08 secondes

Val loss 1.0324603170156479 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 12/40
time = 22.41 secondes

Train loss 0.14248338292324633 accuracy 0.9651162624359131 macro_avg {'precision': 0.9596239914018512, 'recall': 0.9657201371844676, 'f1-score': 0.9625121084920891, 'support': 516} weighted_avg {'precision': 0.9656232594698828, 'recall': 0.9651162790697675, 'f1-score': 0.9652311689481944, 'support': 516}
 
time = 1.15 secondes

Val loss 1.675163060426712 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 13/40
time = 22.44 secondes

Train loss 0.12471018949608234 accuracy 0.9593023061752319 macro_avg {'precision': 0.9622660427807486, 'recall': 0.9496204671423696, 'f1-score': 0.9553793129007152, 'support': 516} weighted_avg {'precision': 0.9596998974008207, 'recall': 0.9593023255813954, 'f1-score': 0.9590202789180785, 'support': 516}
 
time = 1.15 secondes

Val loss 1.0459697991609573 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 14/40
time = 22.52 secondes

Train loss 0.13607965282051626 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7980930507183075 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 15/40
time = 22.80 secondes

Train loss 0.08037947558367511 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2590135633945465 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 16/40
time = 22.45 secondes

Train loss 0.051105541512229 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.14 secondes

Val loss 1.205783188343048 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 17/40
time = 22.48 secondes

Train loss 0.2287309629733279 accuracy 0.9554263353347778 macro_avg {'precision': 0.9470886075949367, 'recall': 0.9592753929424769, 'f1-score': 0.9524547803617571, 'support': 516} weighted_avg {'precision': 0.9572951623981946, 'recall': 0.9554263565891473, 'f1-score': 0.9557258177593495, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4767717123031616 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 18/40
time = 22.46 secondes

Train loss 0.1379061563577235 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1209143879823387 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 19/40
time = 22.51 secondes

Train loss 0.384863747811213 accuracy 0.9379844665527344 macro_avg {'precision': 0.9556786703601108, 'recall': 0.9144385026737968, 'f1-score': 0.9300279684719044, 'support': 516} weighted_avg {'precision': 0.9434817153041722, 'recall': 0.937984496124031, 'f1-score': 0.9365212266707664, 'support': 516}
 
time = 1.14 secondes

Val loss 0.965694934129715 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 20/40
time = 22.48 secondes

Train loss 0.4903039717341237 accuracy 0.9108527302742004 macro_avg {'precision': 0.8990033222591363, 'recall': 0.9197048258374917, 'f1-score': 0.9062781331438048, 'support': 516} weighted_avg {'precision': 0.9185685956372814, 'recall': 0.9108527131782945, 'f1-score': 0.9119762942393973, 'support': 516}
 
time = 1.15 secondes

Val loss 2.3952926099300385 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 21/40
time = 22.41 secondes

Train loss 0.12148973315594379 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.15 secondes

Val loss 0.6598966401070356 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 22/40
time = 22.40 secondes

Train loss 0.07964720045900762 accuracy 0.9786821603775024 macro_avg {'precision': 0.9810515873015873, 'recall': 0.9728963151991938, 'f1-score': 0.9767429472864724, 'support': 516} weighted_avg {'precision': 0.9788948105081826, 'recall': 0.9786821705426356, 'f1-score': 0.9785910660943596, 'support': 516}
 
time = 1.15 secondes

Val loss 1.2253367006778717 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 23/40
time = 22.45 secondes

Train loss 0.057591520821337 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.11 secondes

Val loss 1.5710323452949524 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 24/40
time = 22.67 secondes

Train loss 0.03446070773475874 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.6608185172080994 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 25/40
time = 22.38 secondes

Train loss 0.09677309625928474 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4285009801387787 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 26/40
time = 22.43 secondes

Train loss 0.0001630657151867071 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.15 secondes

Val loss 1.1869536936283112 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 27/40
time = 22.42 secondes

Train loss 0.03373741787623713 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.15 secondes

Val loss 2.4898957312107086 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 28/40
time = 22.63 secondes

Train loss 0.1520137002908362 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4145686626434326 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 29/40
time = 22.43 secondes

Train loss 0.0604176648211609 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9188126623630524 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 30/40
time = 22.45 secondes

Train loss 0.009569180952508539 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.14 secondes

Val loss 1.3491852134466171 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 22.40 secondes

Train loss 0.03699352401886382 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.387839525938034 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 32/40
time = 22.45 secondes

Train loss 0.0891150056731104 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7806488573551178 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 33/40
time = 22.37 secondes

Train loss 0.02626541508608639 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.15 secondes

Val loss 1.4844457507133484 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 34/40
time = 22.49 secondes

Train loss 0.02267914373916221 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7631206512451172 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 35/40
time = 22.40 secondes

Train loss 0.0013142807563946751 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.5328086018562317 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 36/40
time = 22.58 secondes

Train loss 9.359126786214553e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.16 secondes

Val loss 1.8098794519901276 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 37/40
time = 22.40 secondes

Train loss 0.00018376635588620874 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.08 secondes

Val loss 1.9785844385623932 accuracy 0.71875 macro_avg {'precision': 0.7137254901960783, 'recall': 0.7206477732793521, 'f1-score': 0.7142857142857142, 'support': 64} weighted_avg {'precision': 0.7287990196078431, 'recall': 0.71875, 'f1-score': 0.7209821428571428, 'support': 64}
 
----------
Epoch 38/40
time = 22.43 secondes

Train loss 6.832664671078832e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4581730961799622 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 39/40
time = 22.47 secondes

Train loss 5.085709055878617e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.5829847157001495 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 40/40
time = 23.13 secondes

Train loss 4.722524130501728e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.13 secondes

Val loss 1.5780180990695953 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 21 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}

average train time 22.48459569811821

average val time 1.1368390560150146
 
time = 1.27 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 79.21 GiB total capacity; 73.85 GiB already allocated; 240.62 MiB free; 75.10 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 72.48 GiB already allocated; 18.62 MiB free; 75.31 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 79.21 GiB total capacity; 70.25 GiB already allocated; 864.62 MiB free; 74.49 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 73.98 GiB already allocated; 166.62 MiB free; 75.17 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_2
----------
Epoch 1/40
time = 33.51 secondes

Train loss 0.6475304627057278 accuracy 0.5930232405662537 macro_avg {'precision': 0.4676408411526908, 'recall': 0.48581831185085256, 'f1-score': 0.43958294544777515, 'support': 516} weighted_avg {'precision': 0.5123752705041966, 'recall': 0.5930232558139535, 'f1-score': 0.520281182751469, 'support': 516}
 
time = 1.59 secondes

Val loss 0.7083943486213684 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 29.50 secondes

Train loss 0.42203118381175125 accuracy 0.8217054009437561 macro_avg {'precision': 0.8196135353352083, 'recall': 0.7863238138582318, 'f1-score': 0.7976229046945074, 'support': 516} weighted_avg {'precision': 0.821001612555003, 'recall': 0.8217054263565892, 'f1-score': 0.8168348039979659, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4099496230483055 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 3/40
time = 29.66 secondes

Train loss 0.35895142856646667 accuracy 0.8662790656089783 macro_avg {'precision': 0.858038029386344, 'recall': 0.8501292199665167, 'f1-score': 0.8537553141237602, 'support': 516} weighted_avg {'precision': 0.8653519527245684, 'recall': 0.8662790697674418, 'f1-score': 0.8655326207555667, 'support': 516}
 
time = 1.50 secondes

Val loss 0.4666159972548485 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 4/40
time = 29.48 secondes

Train loss 0.26389843598008156 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 1.50 secondes

Val loss 0.45101945102214813 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 5/40
time = 30.42 secondes

Train loss 0.3361745086131674 accuracy 0.8740310072898865 macro_avg {'precision': 0.8666145867960906, 'recall': 0.8585163272272158, 'f1-score': 0.8622332669281797, 'support': 516} weighted_avg {'precision': 0.8731966603944052, 'recall': 0.874031007751938, 'f1-score': 0.8733278311465482, 'support': 516}
 
time = 1.50 secondes

Val loss 0.7286281734704971 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 6/40
time = 29.62 secondes

Train loss 0.14450984333895825 accuracy 0.9496123790740967 macro_avg {'precision': 0.9464195313137911, 'recall': 0.9443297628529168, 'f1-score': 0.9453567937438906, 'support': 516} weighted_avg {'precision': 0.9495249271614058, 'recall': 0.9496124031007752, 'f1-score': 0.949553297415263, 'support': 516}
 
time = 1.54 secondes

Val loss 1.100200206041336 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 7/40
time = 29.72 secondes

Train loss 0.23602946410943387 accuracy 0.9399224519729614 macro_avg {'precision': 0.9383928571428571, 'recall': 0.9309607788956975, 'f1-score': 0.9344573968982401, 'support': 516} weighted_avg {'precision': 0.9397852067183463, 'recall': 0.939922480620155, 'f1-score': 0.9396657317204679, 'support': 516}
 
time = 1.46 secondes

Val loss 0.7699343338608742 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 8/40
time = 30.30 secondes

Train loss 0.14147428501482037 accuracy 0.9496123790740967 macro_avg {'precision': 0.9496377832667473, 'recall': 0.9408676429953026, 'f1-score': 0.9449613547974203, 'support': 516} weighted_avg {'precision': 0.9496149732441648, 'recall': 0.9496124031007752, 'f1-score': 0.9493643471912628, 'support': 516}
 
time = 1.49 secondes

Val loss 0.7722413912415504 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 9/40
time = 29.41 secondes

Train loss 0.23634909218967412 accuracy 0.9360464811325073 macro_avg {'precision': 0.9266772151898734, 'recall': 0.9383076247907287, 'f1-score': 0.931782945736434, 'support': 516} weighted_avg {'precision': 0.9381465263467766, 'recall': 0.936046511627907, 'f1-score': 0.9364761733068926, 'support': 516}
 
time = 1.51 secondes

Val loss 2.0838717222213745 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 10/40
time = 29.63 secondes

Train loss 0.28145725717309467 accuracy 0.9437984228134155 macro_avg {'precision': 0.9426587301587301, 'recall': 0.9351543325260472, 'f1-score': 0.9386859519370634, 'support': 516} weighted_avg {'precision': 0.9436961670973298, 'recall': 0.9437984496124031, 'f1-score': 0.9435582651578568, 'support': 516}
 
time = 1.49 secondes

Val loss 1.5464751422405243 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 30.40 secondes

Train loss 0.07481547386851162 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9185861051082611 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 12/40
time = 29.57 secondes

Train loss 0.04924594718878242 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 1.49 secondes

Val loss 1.582143098115921 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 13/40
time = 29.62 secondes

Train loss 0.2810587146668695 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.49 secondes

Val loss 1.9639479517936707 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 14/40
time = 29.42 secondes

Train loss 0.2577873559282373 accuracy 0.9496123790740967 macro_avg {'precision': 0.9438099073701167, 'recall': 0.9477918827105309, 'f1-score': 0.945730789767487, 'support': 516} weighted_avg {'precision': 0.9499588207563369, 'recall': 0.9496124031007752, 'f1-score': 0.9497249136321749, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7793902158737183 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 15/40
time = 29.66 secondes

Train loss 0.8498475341281543 accuracy 0.8391472697257996 macro_avg {'precision': 0.8274801587301588, 'recall': 0.8219283845066073, 'f1-score': 0.8245149658888365, 'support': 516} weighted_avg {'precision': 0.8381002368647718, 'recall': 0.8391472868217055, 'f1-score': 0.8384598623483492, 'support': 516}
 
time = 1.35 secondes

Val loss 1.4469317197799683 accuracy 0.734375 macro_avg {'precision': 0.7831389183457051, 'recall': 0.7702429149797572, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.815648197242842, 'recall': 0.734375, 'f1-score': 0.7314503303156348, 'support': 64}
 
----------
Epoch 16/40
time = 29.14 secondes

Train loss 0.17465578574355636 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2758662402629852 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 17/40
time = 29.24 secondes

Train loss 0.11771224275280749 accuracy 0.9593023061752319 macro_avg {'precision': 0.9574711891042431, 'recall': 0.9542366269525218, 'f1-score': 0.9558130905146576, 'support': 516} weighted_avg {'precision': 0.9592280903188081, 'recall': 0.9593023255813954, 'f1-score': 0.959230134511049, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3625833839178085 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 18/40
time = 29.85 secondes

Train loss 0.18607385589910502 accuracy 0.9534883499145508 macro_avg {'precision': 0.9465132997843277, 'recall': 0.9542935162459568, 'f1-score': 0.9501248489730165, 'support': 516} weighted_avg {'precision': 0.9543740955607941, 'recall': 0.9534883720930233, 'f1-score': 0.9536891794434714, 'support': 516}
 
time = 1.49 secondes

Val loss 1.7884128093719482 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 19/40
time = 29.86 secondes

Train loss 0.015877145777763377 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 1.1756044030189514 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 20/40
time = 29.48 secondes

Train loss 0.2552405175229069 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.49 secondes

Val loss 1.8118287175893784 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 21/40
time = 29.67 secondes

Train loss 0.03961147017914548 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.52 secondes

Val loss 1.0463383793830872 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 22/40
time = 29.79 secondes

Train loss 0.05133507452939574 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.51 secondes

Val loss 1.6739418804645538 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 23/40
time = 30.30 secondes

Train loss 0.05230777274956574 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4711760580539703 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 24/40
time = 29.20 secondes

Train loss 0.15117053577242504 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8639224469661713 accuracy 0.734375 macro_avg {'precision': 0.7831389183457051, 'recall': 0.7702429149797572, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.815648197242842, 'recall': 0.734375, 'f1-score': 0.7314503303156348, 'support': 64}
 
----------
Epoch 25/40
time = 29.31 secondes

Train loss 0.19051371277733284 accuracy 0.963178277015686 macro_avg {'precision': 0.9616946045049765, 'recall': 0.9584301805828714, 'f1-score': 0.9600213676084998, 'support': 516} weighted_avg {'precision': 0.963118144976265, 'recall': 0.9631782945736435, 'f1-score': 0.9631129788433301, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8302887082099915 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 26/40
time = 29.69 secondes

Train loss 0.3512852616230234 accuracy 0.9476743936538696 macro_avg {'precision': 0.9369158878504673, 'recall': 0.958966565349544, 'f1-score': 0.9449395528611119, 'support': 516} weighted_avg {'precision': 0.9542762442947186, 'recall': 0.9476744186046512, 'f1-score': 0.9483165175183517, 'support': 516}
 
time = 1.50 secondes

Val loss 2.512796938419342 accuracy 0.6875 macro_avg {'precision': 0.7125506072874495, 'recall': 0.7125506072874495, 'f1-score': 0.6875, 'support': 64} weighted_avg {'precision': 0.7376012145748988, 'recall': 0.6875, 'f1-score': 0.6875, 'support': 64}
 
----------
Epoch 27/40
time = 30.10 secondes

Train loss 0.127518662728879 accuracy 0.9767441749572754 macro_avg {'precision': 0.9759124683595983, 'recall': 0.9736846382653641, 'f1-score': 0.9747800586510263, 'support': 516} weighted_avg {'precision': 0.9767213992605689, 'recall': 0.9767441860465116, 'f1-score': 0.9767169064993521, 'support': 516}
 
time = 1.49 secondes

Val loss 1.9411473274230957 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 29.57 secondes

Train loss 0.023900695492171286 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 2.4101785868406296 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 29/40
time = 29.63 secondes

Train loss 0.09125459259226001 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 1.41 secondes

Val loss 1.828465074300766 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 30/40
time = 29.96 secondes

Train loss 0.02837956353610163 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.42 secondes

Val loss 1.6108421087265015 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 31/40
time = 29.56 secondes

Train loss 0.058269222108664864 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.50 secondes

Val loss 2.103816479444504 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 32/40
time = 29.43 secondes

Train loss 0.0001987830980920769 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5849519670009613 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 33/40
time = 29.65 secondes

Train loss 0.03568422019485628 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.41 secondes

Val loss 1.7188564240932465 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 34/40
time = 29.95 secondes

Train loss 0.02700615874478403 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5791853815317154 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 35/40
time = 29.60 secondes

Train loss 0.032690027961397194 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5868118852376938 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 36/40
time = 29.59 secondes

Train loss 7.612257347015354e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.40 secondes

Val loss 1.8571529984474182 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 37/40
time = 29.93 secondes

Train loss 0.053658525528810445 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.50 secondes

Val loss 1.9650072157382965 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 38/40
time = 29.53 secondes

Train loss 9.3332518714085e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.44 secondes

Val loss 1.5446757525205612 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 29.24 secondes

Train loss 0.0011272098829177787 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.51 secondes

Val loss 1.593379721045494 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 40/40
time = 29.58 secondes

Train loss 9.441589855035117e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5509000271558762 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 8 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}

average train time 29.769939368963243

average val time 1.4873810946941375
 
time = 1.76 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_2
----------
Epoch 1/40
time = 42.18 secondes

Train loss 0.6555672152475878 accuracy 0.6104651093482971 macro_avg {'precision': 0.430690737833595, 'recall': 0.4856476439705476, 'f1-score': 0.4054583913738844, 'support': 516} weighted_avg {'precision': 0.48570789675440845, 'recall': 0.6104651162790697, 'f1-score': 0.5015341502403409, 'support': 516}
 
time = 1.87 secondes

Val loss 0.6241297423839569 accuracy 0.609375 macro_avg {'precision': 0.8015873015873016, 'recall': 0.5192307692307693, 'f1-score': 0.4132746607994132, 'support': 64} weighted_avg {'precision': 0.7643849206349207, 'recall': 0.609375, 'f1-score': 0.47687477081041435, 'support': 64}
 
----------
Epoch 2/40
time = 39.11 secondes

Train loss 0.4623080442349116 accuracy 0.7945736646652222 macro_avg {'precision': 0.7978169968000942, 'recall': 0.7465825788729419, 'f1-score': 0.759936797752809, 'support': 516} weighted_avg {'precision': 0.795974772075005, 'recall': 0.7945736434108527, 'f1-score': 0.785030838994861, 'support': 516}
 
time = 1.68 secondes

Val loss 0.475628562271595 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 3/40
time = 38.93 secondes

Train loss 0.35720553000768024 accuracy 0.856589138507843 macro_avg {'precision': 0.8437414780474503, 'recall': 0.848300635534678, 'f1-score': 0.8458831126896997, 'support': 516} weighted_avg {'precision': 0.8577750859858406, 'recall': 0.8565891472868217, 'f1-score': 0.8570614723425772, 'support': 516}
 
time = 1.68 secondes

Val loss 0.443993978202343 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 4/40
time = 39.11 secondes

Train loss 0.33298397560914356 accuracy 0.8585271239280701 macro_avg {'precision': 0.8467176959003633, 'recall': 0.8475123124685078, 'f1-score': 0.8471111111111111, 'support': 516} weighted_avg {'precision': 0.8586958380098398, 'recall': 0.8585271317829457, 'f1-score': 0.8586080964685617, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7837258130311966 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 5/40
time = 39.46 secondes

Train loss 0.23290079860298923 accuracy 0.9050387740135193 macro_avg {'precision': 0.8957368827160495, 'recall': 0.9001430359377793, 'f1-score': 0.8978370581081027, 'support': 516} weighted_avg {'precision': 0.9057434473394583, 'recall': 0.9050387596899225, 'f1-score': 0.9053015955140765, 'support': 516}
 
time = 1.68 secondes

Val loss 0.5245716944336891 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 6/40
time = 39.03 secondes

Train loss 0.1942745461128652 accuracy 0.9399224519729614 macro_avg {'precision': 0.9407085561497326, 'recall': 0.9286526989906214, 'f1-score': 0.9341313666629606, 'support': 516} weighted_avg {'precision': 0.9400279297765618, 'recall': 0.939922480620155, 'f1-score': 0.9395061260219253, 'support': 516}
 
time = 1.68 secondes

Val loss 0.5026249848306179 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 7/40
time = 39.04 secondes

Train loss 0.07058443783810645 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1306364983320236 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 8/40
time = 39.57 secondes

Train loss 0.26600922409543826 accuracy 0.9515503644943237 macro_avg {'precision': 0.9578884733083985, 'recall': 0.9377712400240561, 'f1-score': 0.9464674758792405, 'support': 516} weighted_avg {'precision': 0.9527747905184388, 'recall': 0.9515503875968992, 'f1-score': 0.9510069316270866, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2687376290559769 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 9/40
time = 38.95 secondes

Train loss 0.18545627389385394 accuracy 0.9457364082336426 macro_avg {'precision': 0.9376700666740926, 'recall': 0.9470604489377956, 'f1-score': 0.9419367283950617, 'support': 516} weighted_avg {'precision': 0.9470587894256475, 'recall': 0.9457364341085271, 'f1-score': 0.9460242906019716, 'support': 516}
 
time = 1.69 secondes

Val loss 0.9364564269781113 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 10/40
time = 39.09 secondes

Train loss 0.20767450123446796 accuracy 0.9496123790740967 macro_avg {'precision': 0.9446143391097519, 'recall': 0.9466378427579929, 'f1-score': 0.945608458744162, 'support': 516} weighted_avg {'precision': 0.9497572745208048, 'recall': 0.9496124031007752, 'f1-score': 0.9496696023058697, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8848605304956436 accuracy 0.6875 macro_avg {'precision': 0.759090909090909, 'recall': 0.7307692307692308, 'f1-score': 0.6847290640394088, 'support': 64} weighted_avg {'precision': 0.7948863636363637, 'recall': 0.6875, 'f1-score': 0.6791871921182266, 'support': 64}
 
----------
Epoch 11/40
time = 38.95 secondes

Train loss 0.2100696270583395 accuracy 0.9457364082336426 macro_avg {'precision': 0.9376700666740926, 'recall': 0.9470604489377956, 'f1-score': 0.9419367283950617, 'support': 516} weighted_avg {'precision': 0.9470587894256475, 'recall': 0.9457364341085271, 'f1-score': 0.9460242906019716, 'support': 516}
 
time = 1.68 secondes

Val loss 1.0696163177490234 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 12/40
time = 39.41 secondes

Train loss 0.06660915913137917 accuracy 0.9806201457977295 macro_avg {'precision': 0.9790322318482518, 'recall': 0.9790322318482518, 'f1-score': 0.9790322318482518, 'support': 516} weighted_avg {'precision': 0.9806201550387597, 'recall': 0.9806201550387597, 'f1-score': 0.9806201550387597, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5876917243003845 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 13/40
time = 38.95 secondes

Train loss 0.1793901840252202 accuracy 0.9515503644943237 macro_avg {'precision': 0.9536430481283422, 'recall': 0.9412333598816702, 'f1-score': 0.9468801344056134, 'support': 516} weighted_avg {'precision': 0.9518311103511171, 'recall': 0.9515503875968992, 'f1-score': 0.9512146177596172, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4049699306488037 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 14/40
time = 38.97 secondes

Train loss 0.34415544388475333 accuracy 0.9302325248718262 macro_avg {'precision': 0.934467881929642, 'recall': 0.9141296750808641, 'f1-score': 0.9228109833122797, 'support': 516} weighted_avg {'precision': 0.9310891404791071, 'recall': 0.9302325581395349, 'f1-score': 0.9293976309714688, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5579393655061722 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 15/40
time = 38.90 secondes

Train loss 0.2563078854108233 accuracy 0.9573643207550049 macro_avg {'precision': 0.9480040781115207, 'recall': 0.9642572696389968, 'f1-score': 0.9547512755102041, 'support': 516} weighted_avg {'precision': 0.9605432983216394, 'recall': 0.9573643410852714, 'f1-score': 0.9577436570558456, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1268788501620293 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 16/40
time = 38.82 secondes

Train loss 0.19371314242633877 accuracy 0.9418604373931885 macro_avg {'precision': 0.9347920242544796, 'recall': 0.9405588154023699, 'f1-score': 0.9375201808201485, 'support': 516} weighted_avg {'precision': 0.9425129365804452, 'recall': 0.9418604651162791, 'f1-score': 0.9420519482469907, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0940574407577515 accuracy 0.703125 macro_avg {'precision': 0.7348717948717949, 'recall': 0.7317813765182186, 'f1-score': 0.703052503052503, 'support': 64} weighted_avg {'precision': 0.7620833333333333, 'recall': 0.703125, 'f1-score': 0.7021825396825396, 'support': 64}
 
----------
Epoch 17/40
time = 39.34 secondes

Train loss 0.16121363794037746 accuracy 0.961240291595459 macro_avg {'precision': 0.9590593614762799, 'recall': 0.9569104237439656, 'f1-score': 0.9579667644183774, 'support': 516} weighted_avg {'precision': 0.9611805580610471, 'recall': 0.9612403100775194, 'f1-score': 0.9611948441655869, 'support': 516}
 
time = 1.70 secondes

Val loss 1.3676226884126663 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 18/40
time = 39.11 secondes

Train loss 0.20731974554258736 accuracy 0.961240291595459 macro_avg {'precision': 0.9696638985045103, 'recall': 0.947678104123661, 'f1-score': 0.9571172129512666, 'support': 516} weighted_avg {'precision': 0.9629439571751132, 'recall': 0.9612403100775194, 'f1-score': 0.960776461650816, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5335567891597748 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 19/40
time = 39.69 secondes

Train loss 0.009458745214501643 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.66 secondes

Val loss 1.3708432167768478 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 20/40
time = 38.90 secondes

Train loss 0.052204695358258585 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 1.59 secondes

Val loss 1.0896385461091995 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 21/40
time = 38.87 secondes

Train loss 0.05444419103503495 accuracy 0.9883720874786377 macro_avg {'precision': 0.9874193391089512, 'recall': 0.9874193391089512, 'f1-score': 0.9874193391089512, 'support': 516} weighted_avg {'precision': 0.9883720930232558, 'recall': 0.9883720930232558, 'f1-score': 0.9883720930232558, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8378577306866646 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 22/40
time = 39.06 secondes

Train loss 0.18807474224696774 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 1.69 secondes

Val loss 1.5025874078273773 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 23/40
time = 39.42 secondes

Train loss 0.05493548797169227 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.69 secondes

Val loss 2.6201913952827454 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 24/40
time = 39.04 secondes

Train loss 0.09378782977199246 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.69 secondes

Val loss 1.306048035621643 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 25/40
time = 38.95 secondes

Train loss 0.001589335169476478 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 2.103917270898819 accuracy 0.671875 macro_avg {'precision': 0.6822660098522167, 'recall': 0.687246963562753, 'f1-score': 0.6711524345485687, 'support': 64} weighted_avg {'precision': 0.7030480295566502, 'recall': 0.671875, 'f1-score': 0.6740426963542941, 'support': 64}
 
----------
Epoch 26/40
time = 39.07 secondes

Train loss 0.12223833685791098 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5069844126701355 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 27/40
time = 39.57 secondes

Train loss 0.0005898199070185055 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8067156642573536 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 28/40
time = 38.96 secondes

Train loss 0.11718871032071272 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0857377350330353 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 29/40
time = 39.10 secondes

Train loss 0.17772504432871233 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2420360028918367 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 30/40
time = 38.98 secondes

Train loss 0.1693459220204011 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.69 secondes

Val loss 2.5796729922294617 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 31/40
time = 39.49 secondes

Train loss 0.07465762542729366 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.68 secondes

Val loss 1.5371061116456985 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 32/40
time = 38.90 secondes

Train loss 0.08386265135402826 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 1.69 secondes

Val loss 1.659396767616272 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 33/40
time = 38.92 secondes

Train loss 0.01044204055550367 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 2.0651585310697556 accuracy 0.734375 macro_avg {'precision': 0.7252252252252251, 'recall': 0.7277327935222673, 'f1-score': 0.7262893081761006, 'support': 64} weighted_avg {'precision': 0.736204954954955, 'recall': 0.734375, 'f1-score': 0.7351100628930818, 'support': 64}
 
----------
Epoch 34/40
time = 39.27 secondes

Train loss 5.9012645027850695e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8369644284248352 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 35/40
time = 38.90 secondes

Train loss 0.046226227718734386 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8239893317222595 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 39.01 secondes

Train loss 0.06501754248093869 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.69 secondes

Val loss 2.023897707462311 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 37/40
time = 39.27 secondes

Train loss 0.012795402774413973 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7853127121925354 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 38.86 secondes

Train loss 0.003434390439272675 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.68 secondes

Val loss 1.9607832431793213 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 39/40
time = 38.90 secondes

Train loss 3.448791269902634e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.784013107419014 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 40/40
time = 38.66 secondes

Train loss 2.9361412364806078e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8619033992290497 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 6 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}

average train time 39.166828972101214

average val time 1.689553564786911
 
time = 1.95 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_2
----------
Epoch 1/40
time = 53.09 secondes

Train loss 0.5833969901908528 accuracy 0.6841084957122803 macro_avg {'precision': 0.7242873651771957, 'recall': 0.5757115225200332, 'f1-score': 0.5454383319551859, 'support': 516} weighted_avg {'precision': 0.7109570030219419, 'recall': 0.6841085271317829, 'f1-score': 0.614530148499315, 'support': 516}
 
time = 2.22 secondes

Val loss 0.6091241240501404 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 52.25 secondes

Train loss 0.36270364667430066 accuracy 0.8449612259864807 macro_avg {'precision': 0.832257854786015, 'recall': 0.832257854786015, 'f1-score': 0.832257854786015, 'support': 516} weighted_avg {'precision': 0.8449612403100775, 'recall': 0.8449612403100775, 'f1-score': 0.8449612403100775, 'support': 516}
 
time = 1.96 secondes

Val loss 0.48631010204553604 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 3/40
time = 52.41 secondes

Train loss 0.23433682909517578 accuracy 0.9069767594337463 macro_avg {'precision': 0.9008516713434747, 'recall': 0.8970466329665329, 'f1-score': 0.8988813587000898, 'support': 516} weighted_avg {'precision': 0.9066500736344427, 'recall': 0.9069767441860465, 'f1-score': 0.9067549528028697, 'support': 516}
 
time = 2.01 secondes

Val loss 0.6130590289831161 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 4/40
time = 52.38 secondes

Train loss 0.1298781200029859 accuracy 0.963178277015686 macro_avg {'precision': 0.9587826929286407, 'recall': 0.9618923004404857, 'f1-score': 0.9602972442140645, 'support': 516} weighted_avg {'precision': 0.9633722181756288, 'recall': 0.9631782945736435, 'f1-score': 0.9632404755166558, 'support': 516}
 
time = 2.00 secondes

Val loss 0.847844734787941 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 5/40
time = 52.36 secondes

Train loss 0.11252477818704916 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.98 secondes

Val loss 0.8415037021040916 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 6/40
time = 52.78 secondes

Train loss 0.0797471240141683 accuracy 0.9767441749572754 macro_avg {'precision': 0.9770590262393541, 'recall': 0.9725305983128261, 'f1-score': 0.9747203396750224, 'support': 516} weighted_avg {'precision': 0.9767609775234631, 'recall': 0.9767441860465116, 'f1-score': 0.9766887382007174, 'support': 516}
 
time = 2.02 secondes

Val loss 1.1072355508804321 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 7/40
time = 52.15 secondes

Train loss 0.35272751956698345 accuracy 0.9263566136360168 macro_avg {'precision': 0.9315066142786061, 'recall': 0.9087820814979763, 'f1-score': 0.9183040847957602, 'support': 516} weighted_avg {'precision': 0.927488462802522, 'recall': 0.9263565891472868, 'f1-score': 0.9253624528075922, 'support': 516}
 
time = 2.01 secondes

Val loss 2.12711963057518 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 8/40
time = 52.20 secondes

Train loss 0.11378850685044502 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 2.00 secondes

Val loss 2.061117708683014 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 52.48 secondes

Train loss 0.12384556586656606 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.98 secondes

Val loss 1.29923215508461 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 10/40
time = 52.17 secondes

Train loss 0.1949585756078842 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 2.02 secondes

Val loss 1.0354160368442535 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 11/40
time = 52.48 secondes

Train loss 0.1907080349769923 accuracy 0.9515503644943237 macro_avg {'precision': 0.9523801608935576, 'recall': 0.9423873998342083, 'f1-score': 0.9470127949723769, 'support': 516} weighted_avg {'precision': 0.9516437370927733, 'recall': 0.9515503875968992, 'f1-score': 0.951279935056365, 'support': 516}
 
time = 2.02 secondes

Val loss 1.6785454452037811 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 12/40
time = 52.69 secondes

Train loss 0.35345037005467794 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.02 secondes

Val loss 1.7714714407920837 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 13/40
time = 52.16 secondes

Train loss 0.052914088795660064 accuracy 0.9844961166381836 macro_avg {'precision': 0.9843390218012575, 'recall': 0.9820717455260635, 'f1-score': 0.9831867057673509, 'support': 516} weighted_avg {'precision': 0.9844918198603297, 'recall': 0.9844961240310077, 'f1-score': 0.9844779376662347, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9337725937366486 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 52.34 secondes

Train loss 0.1472338330296969 accuracy 0.9728682041168213 macro_avg {'precision': 0.9679013137843084, 'recall': 0.9741072444451668, 'f1-score': 0.9708427510494027, 'support': 516} weighted_avg {'precision': 0.9733267004330286, 'recall': 0.9728682170542635, 'f1-score': 0.9729575758485957, 'support': 516}
 
time = 2.01 secondes

Val loss 1.0379770547151566 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 15/40
time = 52.24 secondes

Train loss 0.31382875656312204 accuracy 0.9379844665527344 macro_avg {'precision': 0.9536397991590227, 'recall': 0.9155925426263349, 'f1-score': 0.930232558139535, 'support': 516} weighted_avg {'precision': 0.9426345861344245, 'recall': 0.937984496124031, 'f1-score': 0.9366324139174329, 'support': 516}
 
time = 2.02 secondes

Val loss 1.1665081232786179 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 16/40
time = 51.95 secondes

Train loss 0.08019948772870879 accuracy 0.9806201457977295 macro_avg {'precision': 0.9770600080547724, 'recall': 0.981340311753328, 'f1-score': 0.9791272268336488, 'support': 516} weighted_avg {'precision': 0.980832701127356, 'recall': 0.9806201550387597, 'f1-score': 0.9806634283200673, 'support': 516}
 
time = 2.02 secondes

Val loss 1.4316941797733307 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 17/40
time = 52.18 secondes

Train loss 0.4010231781155171 accuracy 0.9205426573753357 macro_avg {'precision': 0.9422737955346651, 'recall': 0.8915283715033402, 'f1-score': 0.9093942054433715, 'support': 516} weighted_avg {'precision': 0.9282473196148625, 'recall': 0.9205426356589147, 'f1-score': 0.9181404877119193, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7091509774327278 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 18/40
time = 52.26 secondes

Train loss 0.39845155684231554 accuracy 0.9244186282157898 macro_avg {'precision': 0.9130151439920556, 'recall': 0.9326512036149082, 'f1-score': 0.9203221323450808, 'support': 516} weighted_avg {'precision': 0.9306161376180688, 'recall': 0.9244186046511628, 'f1-score': 0.9252939192464795, 'support': 516}
 
time = 2.02 secondes

Val loss 2.2788559198379517 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 19/40
time = 52.22 secondes

Train loss 0.041362368322690156 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.01 secondes

Val loss 2.4088056683540344 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 20/40
time = 52.41 secondes

Train loss 0.2596123782625937 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 2.06 secondes

Val loss 1.6195314526557922 accuracy 0.71875 macro_avg {'precision': 0.71875, 'recall': 0.7267206477732794, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.736328125, 'recall': 0.71875, 'f1-score': 0.7212438423645322, 'support': 64}
 
----------
Epoch 21/40
time = 52.19 secondes

Train loss 0.06865998973477293 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 2.02 secondes

Val loss 1.3441333025693893 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 22/40
time = 52.62 secondes

Train loss 0.06940425779039013 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.02 secondes

Val loss 1.9734576046466827 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 23/40
time = 53.30 secondes

Train loss 0.025542320336447148 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.02 secondes

Val loss 1.3643543124198914 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 24/40
time = 52.07 secondes

Train loss 0.01352803500600258 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.01 secondes

Val loss 2.4524176120758057 accuracy 0.6875 macro_avg {'precision': 0.6785714285714286, 'recall': 0.6821862348178138, 'f1-score': 0.6796796796796798, 'support': 64} weighted_avg {'precision': 0.6919642857142857, 'recall': 0.6875, 'f1-score': 0.6890640640640642, 'support': 64}
 
----------
Epoch 25/40
time = 52.39 secondes

Train loss 0.049532211827957355 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 2.03 secondes

Val loss 2.8765435218811035 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 26/40
time = 51.89 secondes

Train loss 0.0514389947021493 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.02 secondes

Val loss 1.415438286960125 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 27/40
time = 52.41 secondes

Train loss 0.04499867034808796 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.01 secondes

Val loss 1.9735614508390427 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 28/40
time = 52.24 secondes

Train loss 0.13563564800422295 accuracy 0.9670542478561401 macro_avg {'precision': 0.9583333333333333, 'recall': 0.9741641337386018, 'f1-score': 0.9650003391440005, 'support': 516} weighted_avg {'precision': 0.9697997416020671, 'recall': 0.9670542635658915, 'f1-score': 0.9673335972872688, 'support': 516}
 
time = 2.02 secondes

Val loss 3.001997709274292 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 29/40
time = 52.14 secondes

Train loss 0.17342427447913383 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7675100266933441 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 30/40
time = 52.40 secondes

Train loss 0.131379376133268 accuracy 0.9709302186965942 macro_avg {'precision': 0.9628712871287128, 'recall': 0.9772036474164134, 'f1-score': 0.9690557196943952, 'support': 516} weighted_avg {'precision': 0.9730888786553075, 'recall': 0.9709302325581395, 'f1-score': 0.9711516317152747, 'support': 516}
 
time = 2.01 secondes

Val loss 1.710803936352022 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 31/40
time = 52.19 secondes

Train loss 0.07621385476660648 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 2.01 secondes

Val loss 2.9281861186027527 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 32/40
time = 52.28 secondes

Train loss 0.0054895701102368275 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.01 secondes

Val loss 2.015319302678108 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 33/40
time = 52.34 secondes

Train loss 0.008955868980068992 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.01 secondes

Val loss 1.9089668095111847 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 34/40
time = 52.57 secondes

Train loss 0.11316054986210392 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 2.02 secondes

Val loss 2.71492663025856 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 35/40
time = 52.67 secondes

Train loss 0.0412375432826979 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.01 secondes

Val loss 1.8236069232225418 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 52.45 secondes

Train loss 0.04948113863026789 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7146564573049545 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 52.40 secondes

Train loss 0.0038976439149833327 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.91 secondes

Val loss 2.6327152252197266 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 38/40
time = 52.11 secondes

Train loss 0.005813561608110004 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.02 secondes

Val loss 2.1486160457134247 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 39/40
time = 52.48 secondes

Train loss 2.1948599114142724e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.02 secondes

Val loss 1.824658527970314 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 40/40
time = 52.06 secondes

Train loss 2.0531253484836213e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.7083893418312073 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 5 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}

average train time 52.360049152374266

average val time 2.014763057231903
 
time = 2.26 secondes

test_accuracy 0.9846153855323792 macro_avg {'precision': 0.9821428571428572, 'recall': 0.986842105263158, 'f1-score': 0.9842424242424241, 'support': 65} weighted_avg {'precision': 0.985164835164835, 'recall': 0.9846153846153847, 'f1-score': 0.9846526806526806, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_2
----------
Epoch 1/40
time = 98.91 secondes

Train loss 0.6024269262949625 accuracy 0.6647287011146545 macro_avg {'precision': 0.6590656799259944, 'recall': 0.5558977943208231, 'f1-score': 0.5204950394001084, 'support': 516} weighted_avg {'precision': 0.6609622514324233, 'recall': 0.6647286821705426, 'f1-score': 0.5928666905428704, 'support': 516}
 
time = 2.64 secondes

Val loss 0.6430978029966354 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 2/40
time = 98.33 secondes

Train loss 0.36249683887669537 accuracy 0.8352712988853455 macro_avg {'precision': 0.8237317997473572, 'recall': 0.8165807909237196, 'f1-score': 0.8198435029060813, 'support': 516} weighted_avg {'precision': 0.833973122045221, 'recall': 0.8352713178294574, 'f1-score': 0.8343517791916404, 'support': 516}
 
time = 2.45 secondes

Val loss 0.41042762622237206 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 3/40
time = 99.02 secondes

Train loss 0.22579158591388754 accuracy 0.9147287011146545 macro_avg {'precision': 0.9093191552207945, 'recall': 0.9054337402272321, 'f1-score': 0.907307912141749, 'support': 516} weighted_avg {'precision': 0.9144401740665561, 'recall': 0.9147286821705426, 'f1-score': 0.9145253734026304, 'support': 516}
 
time = 2.43 secondes

Val loss 0.5109597258269787 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 4/40
time = 98.16 secondes

Train loss 0.2133080643234831 accuracy 0.9108527302742004 macro_avg {'precision': 0.9124703715703495, 'recall': 0.8931619069291159, 'f1-score': 0.901369589787913, 'support': 516} weighted_avg {'precision': 0.9111798800441034, 'recall': 0.9108527131782945, 'f1-score': 0.9097858617968768, 'support': 516}
 
time = 2.38 secondes

Val loss 0.879143238067627 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 5/40
time = 98.70 secondes

Train loss 0.15221554476584337 accuracy 0.9476743936538696 macro_avg {'precision': 0.9400191326530613, 'recall': 0.9485802057767014, 'f1-score': 0.9439507255589037, 'support': 516} weighted_avg {'precision': 0.9487856697911722, 'recall': 0.9476744186046512, 'f1-score': 0.9479263978333107, 'support': 516}
 
time = 2.43 secondes

Val loss 0.988392099738121 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 6/40
time = 98.42 secondes

Train loss 0.2377275975004798 accuracy 0.9321705102920532 macro_avg {'precision': 0.934593023255814, 'recall': 0.917957511824846, 'f1-score': 0.9252505101259483, 'support': 516} weighted_avg {'precision': 0.9325930683252208, 'recall': 0.9321705426356589, 'f1-score': 0.9315093930328202, 'support': 516}
 
time = 2.46 secondes

Val loss 1.018186055123806 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 7/40
time = 98.22 secondes

Train loss 0.07895018553333075 accuracy 0.9748061895370483 macro_avg {'precision': 0.9681246426529446, 'recall': 0.9790891211416868, 'f1-score': 0.9730705152652603, 'support': 516} weighted_avg {'precision': 0.9760311540149189, 'recall': 0.9748062015503876, 'f1-score': 0.9749519462002839, 'support': 516}
 
time = 2.45 secondes

Val loss 1.0385638177394867 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 8/40
time = 98.07 secondes

Train loss 0.0588014733265013 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 2.45 secondes

Val loss 1.439433068037033 accuracy 0.71875 macro_avg {'precision': 0.7099567099567099, 'recall': 0.6963562753036436, 'f1-score': 0.7, 'support': 64} weighted_avg {'precision': 0.715232683982684, 'recall': 0.71875, 'f1-score': 0.7140624999999999, 'support': 64}
 
----------
Epoch 9/40
time = 98.33 secondes

Train loss 0.04361056499306649 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 2.44 secondes

Val loss 1.4392589330673218 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 10/40
time = 98.01 secondes

Train loss 0.09356870301461172 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 2.45 secondes

Val loss 1.420652523636818 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 11/40
time = 98.05 secondes

Train loss 0.07416208411715078 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 2.45 secondes

Val loss 0.9790362119674683 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 12/40
time = 97.98 secondes

Train loss 0.20156166314678337 accuracy 0.9534883499145508 macro_avg {'precision': 0.9472080078281653, 'recall': 0.9531394762934187, 'f1-score': 0.9500161446561188, 'support': 516} weighted_avg {'precision': 0.954068098025164, 'recall': 0.9534883720930233, 'f1-score': 0.9536415585975925, 'support': 516}
 
time = 2.38 secondes

Val loss 2.284541040658951 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 97.98 secondes

Train loss 0.08632578116212795 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 2.45 secondes

Val loss 1.8178586959838867 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 14/40
time = 98.07 secondes

Train loss 0.08351632171693243 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1441345730054309 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 15/40
time = 98.14 secondes

Train loss 0.11480961798048211 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 2.45 secondes

Val loss 1.64809550344944 accuracy 0.71875 macro_avg {'precision': 0.7137254901960783, 'recall': 0.7206477732793521, 'f1-score': 0.7142857142857142, 'support': 64} weighted_avg {'precision': 0.7287990196078431, 'recall': 0.71875, 'f1-score': 0.7209821428571428, 'support': 64}
 
----------
Epoch 16/40
time = 97.98 secondes

Train loss 0.03821758329264192 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 2.41 secondes

Val loss 1.1895389966666698 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 17/40
time = 97.87 secondes

Train loss 0.18665564705059462 accuracy 0.9670542478561401 macro_avg {'precision': 0.9754335260115607, 'recall': 0.9545454545454546, 'f1-score': 0.9635978835978836, 'support': 516} weighted_avg {'precision': 0.9686729847201685, 'recall': 0.9670542635658915, 'f1-score': 0.9666847135064188, 'support': 516}
 
time = 2.46 secondes

Val loss 1.8395435959100723 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 18/40
time = 98.42 secondes

Train loss 0.2255554021367888 accuracy 0.9593023061752319 macro_avg {'precision': 0.9555007784120395, 'recall': 0.956544706857598, 'f1-score': 0.9560182648401826, 'support': 516} weighted_avg {'precision': 0.9593566333981004, 'recall': 0.9593023255813954, 'f1-score': 0.959325616792326, 'support': 516}
 
time = 2.46 secondes

Val loss 1.6018936932086945 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 19/40
time = 98.18 secondes

Train loss 0.17259653278465106 accuracy 0.9709302186965942 macro_avg {'precision': 0.9634177215189874, 'recall': 0.9760496074638754, 'f1-score': 0.9689922480620154, 'support': 516} weighted_avg {'precision': 0.9726140712393289, 'recall': 0.9709302325581395, 'f1-score': 0.9711255333213148, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6698111295700073 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 20/40
time = 98.01 secondes

Train loss 0.13350400302795495 accuracy 0.9767441749572754 macro_avg {'precision': 0.9712437095614666, 'recall': 0.9794548380280546, 'f1-score': 0.9750624244865083, 'support': 516} weighted_avg {'precision': 0.9774426592509617, 'recall': 0.9767441860465116, 'f1-score': 0.9768445897217357, 'support': 516}
 
time = 3.13 secondes

Val loss 1.7129133939743042 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 21/40
time = 98.04 secondes

Train loss 0.03695104888439263 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6833245158195496 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 22/40
time = 97.91 secondes

Train loss 0.03257010011833644 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.714388132095337 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 23/40
time = 98.68 secondes

Train loss 0.030647415792455748 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.42 secondes

Val loss 1.4659121483564377 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 24/40
time = 98.16 secondes

Train loss 0.21972589120967756 accuracy 0.9534883499145508 macro_avg {'precision': 0.9431279620853081, 'recall': 0.9635258358662614, 'f1-score': 0.9509218014362031, 'support': 516} weighted_avg {'precision': 0.9587787942246224, 'recall': 0.9534883720930233, 'f1-score': 0.9540103864639019, 'support': 516}
 
time = 2.42 secondes

Val loss 2.2653622031211853 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 25/40
time = 98.00 secondes

Train loss 0.23635321306353557 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1281770281493664 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 26/40
time = 98.45 secondes

Train loss 0.045909477865886096 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.46 secondes

Val loss 1.7962218523025513 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 27/40
time = 98.03 secondes

Train loss 0.04409828166723001 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6856117695569992 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 28/40
time = 98.08 secondes

Train loss 0.002576150226421746 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.45 secondes

Val loss 1.2452254984527826 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 29/40
time = 98.05 secondes

Train loss 0.016584523124258725 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.44 secondes

Val loss 2.6514423489570618 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 30/40
time = 98.19 secondes

Train loss 0.06720089920351958 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 2.46 secondes

Val loss 2.3989083096385 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 31/40
time = 97.96 secondes

Train loss 0.10148110103314552 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.45 secondes

Val loss 2.186294049024582 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 32/40
time = 98.53 secondes

Train loss 0.2520188182689074 accuracy 0.963178277015686 macro_avg {'precision': 0.9727011494252873, 'recall': 0.9491978609625669, 'f1-score': 0.9592069403124805, 'support': 516} weighted_avg {'precision': 0.9651886750423238, 'recall': 0.9631782945736435, 'f1-score': 0.962709625437233, 'support': 516}
 
time = 2.45 secondes

Val loss 2.074417859315872 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 33/40
time = 97.93 secondes

Train loss 0.0023512114859675585 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.42 secondes

Val loss 2.248430870473385 accuracy 0.703125 macro_avg {'precision': 0.7003910068426198, 'recall': 0.7074898785425101, 'f1-score': 0.6995305164319249, 'support': 64} weighted_avg {'precision': 0.7167949657869013, 'recall': 0.703125, 'f1-score': 0.7056924882629108, 'support': 64}
 
----------
Epoch 34/40
time = 97.79 secondes

Train loss 5.55346748363015e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.44 secondes

Val loss 1.8767977058887482 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 35/40
time = 98.01 secondes

Train loss 0.09549594673830364 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 2.46 secondes

Val loss 1.7408701181411743 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 36/40
time = 97.86 secondes

Train loss 0.00021810277295034294 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6516127735376358 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 37/40
time = 98.04 secondes

Train loss 0.0004332988444895653 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.46 secondes

Val loss 1.4425709396600723 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 98.42 secondes

Train loss 5.8261231143577873e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.45 secondes

Val loss 2.17784920334816 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 39/40
time = 98.26 secondes

Train loss 0.026134299623663537 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.45 secondes

Val loss 2.281267136335373 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 40/40
time = 98.05 secondes

Train loss 0.002723809409596442 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.46 secondes

Val loss 2.1472451388835907 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 28 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}

average train time 98.18187269568443

average val time 2.4612273931503297
 
time = 2.67 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.05 GiB already allocated; 359.62 MiB free; 76.83 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 1.43 GiB free; 75.75 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_2
----------
Epoch 1/40
time = 641.32 secondes

Train loss 1.3743937719654251 accuracy 0.6254174113273621 macro_avg {'precision': 0.6207999980874489, 'recall': 0.6098394237592502, 'f1-score': 0.5987962838819725, 'support': 10182} weighted_avg {'precision': 0.629954055502062, 'recall': 0.6254174032606561, 'f1-score': 0.6135133416582608, 'support': 10182}
 
time = 24.32 secondes

Val loss 0.7873054495160009 accuracy 0.7667844295501709 macro_avg {'precision': 0.7479607145214444, 'recall': 0.7615485924839616, 'f1-score': 0.7475525254502291, 'support': 1132} weighted_avg {'precision': 0.756964447749439, 'recall': 0.7667844522968198, 'f1-score': 0.7540061432927142, 'support': 1132}
 
----------
Epoch 2/40
time = 640.01 secondes

Train loss 0.54269981340416 accuracy 0.8362797498703003 macro_avg {'precision': 0.8253405580789938, 'recall': 0.8252530123471671, 'f1-score': 0.8228703806016766, 'support': 10182} weighted_avg {'precision': 0.8331609286052729, 'recall': 0.8362797092909056, 'f1-score': 0.8329175483871702, 'support': 10182}
 
time = 23.40 secondes

Val loss 0.5993480531262679 accuracy 0.8295053243637085 macro_avg {'precision': 0.8264152516675425, 'recall': 0.8257395755153117, 'f1-score': 0.8229507223449701, 'support': 1132} weighted_avg {'precision': 0.8306994959167684, 'recall': 0.8295053003533569, 'f1-score': 0.8269484007592944, 'support': 1132}
 
----------
Epoch 3/40
time = 641.36 secondes

Train loss 0.3152994331779482 accuracy 0.9113141298294067 macro_avg {'precision': 0.9070556168139217, 'recall': 0.9060762176915166, 'f1-score': 0.9063188008714362, 'support': 10182} weighted_avg {'precision': 0.9112173273274752, 'recall': 0.9113140836770772, 'f1-score': 0.9110414440298951, 'support': 10182}
 
time = 23.53 secondes

Val loss 0.6457513648439461 accuracy 0.8356890678405762 macro_avg {'precision': 0.8399762059843964, 'recall': 0.8301471791988911, 'f1-score': 0.8291548806881577, 'support': 1132} weighted_avg {'precision': 0.8448806270795217, 'recall': 0.8356890459363958, 'f1-score': 0.8346448469012424, 'support': 1132}
 
----------
Epoch 4/40
time = 641.34 secondes

Train loss 0.21090251133372215 accuracy 0.9419564008712769 macro_avg {'precision': 0.9399356674154472, 'recall': 0.9393860384681327, 'f1-score': 0.9394987749534833, 'support': 10182} weighted_avg {'precision': 0.9423451075164403, 'recall': 0.941956393635828, 'f1-score': 0.9419882408961141, 'support': 10182}
 
time = 23.36 secondes

Val loss 0.6724121720057873 accuracy 0.8533568978309631 macro_avg {'precision': 0.863750622255391, 'recall': 0.8484350218888126, 'f1-score': 0.8508449338519706, 'support': 1132} weighted_avg {'precision': 0.8641741327723131, 'recall': 0.8533568904593639, 'f1-score': 0.8535080147831696, 'support': 1132}
 
----------
Epoch 5/40
time = 640.77 secondes

Train loss 0.16500134181028037 accuracy 0.9575722217559814 macro_avg {'precision': 0.9562800795268652, 'recall': 0.9562072855645107, 'f1-score': 0.9562203527143895, 'support': 10182} weighted_avg {'precision': 0.9576358958250323, 'recall': 0.9575721862109605, 'f1-score': 0.9575805149238045, 'support': 10182}
 
time = 23.57 secondes

Val loss 0.7424329212328917 accuracy 0.8586572408676147 macro_avg {'precision': 0.870560040211552, 'recall': 0.858041913414619, 'f1-score': 0.8575629351350573, 'support': 1132} weighted_avg {'precision': 0.8695717097197081, 'recall': 0.8586572438162544, 'f1-score': 0.8576914449198932, 'support': 1132}
 
----------
Epoch 6/40
time = 640.88 secondes

Train loss 0.14552043945553422 accuracy 0.9638578295707703 macro_avg {'precision': 0.9633301823638731, 'recall': 0.9633927424950242, 'f1-score': 0.963306075042906, 'support': 10182} weighted_avg {'precision': 0.9639875866695266, 'recall': 0.9638577882537812, 'f1-score': 0.9638673429346658, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.6845272604300654 accuracy 0.8772084712982178 macro_avg {'precision': 0.8864887264964135, 'recall': 0.872337605211488, 'f1-score': 0.8755004801893828, 'support': 1132} weighted_avg {'precision': 0.8849071085277007, 'recall': 0.877208480565371, 'f1-score': 0.8771761698920191, 'support': 1132}
 
----------
Epoch 7/40
time = 641.35 secondes

Train loss 0.1327383387037933 accuracy 0.9700452089309692 macro_avg {'precision': 0.9693465555897586, 'recall': 0.9692612140780209, 'f1-score': 0.9692765870378898, 'support': 10182} weighted_avg {'precision': 0.9701082640417572, 'recall': 0.9700451777646828, 'f1-score': 0.9700489795419378, 'support': 10182}
 
time = 23.39 secondes

Val loss 0.8889208629278099 accuracy 0.8489399552345276 macro_avg {'precision': 0.8517478780138955, 'recall': 0.8524983935654632, 'f1-score': 0.8483487835568498, 'support': 1132} weighted_avg {'precision': 0.8566275890944571, 'recall': 0.848939929328622, 'f1-score': 0.849178327862589, 'support': 1132}
 
----------
Epoch 8/40
time = 787.77 secondes

Train loss 0.1312422520478126 accuracy 0.9707326889038086 macro_avg {'precision': 0.9705385568194174, 'recall': 0.9705186853546394, 'f1-score': 0.9704971780492111, 'support': 10182} weighted_avg {'precision': 0.9708620825794664, 'recall': 0.9707326654881163, 'f1-score': 0.9707655323968435, 'support': 10182}
 
time = 26.16 secondes

Val loss 0.7226198210502306 accuracy 0.870141327381134 macro_avg {'precision': 0.8708614395790162, 'recall': 0.8713848698935228, 'f1-score': 0.8693761657309759, 'support': 1132} weighted_avg {'precision': 0.8729089331805177, 'recall': 0.8701413427561837, 'f1-score': 0.8701387135278044, 'support': 1132}
 
----------
Epoch 9/40
time = 837.05 secondes

Train loss 0.1156830641769459 accuracy 0.9746611714363098 macro_avg {'precision': 0.9745525344951625, 'recall': 0.9744737071931852, 'f1-score': 0.9744764387183246, 'support': 10182} weighted_avg {'precision': 0.9747430014650953, 'recall': 0.9746611667648792, 'f1-score': 0.9746656180136798, 'support': 10182}
 
time = 25.96 secondes

Val loss 0.8705467145765384 accuracy 0.8630741834640503 macro_avg {'precision': 0.8701514381160662, 'recall': 0.8648049904967483, 'f1-score': 0.863691512182367, 'support': 1132} weighted_avg {'precision': 0.8734150502480255, 'recall': 0.8630742049469965, 'f1-score': 0.8643676633168985, 'support': 1132}
 
----------
Epoch 10/40
time = 838.06 secondes

Train loss 0.11355060124656498 accuracy 0.9761343598365784 macro_avg {'precision': 0.9754471893685371, 'recall': 0.9750520765142239, 'f1-score': 0.9752060400169323, 'support': 10182} weighted_avg {'precision': 0.9761736336494541, 'recall': 0.9761343547436653, 'f1-score': 0.9761189826101938, 'support': 10182}
 
time = 26.02 secondes

Val loss 0.8756576360010256 accuracy 0.8692579865455627 macro_avg {'precision': 0.8776181395865074, 'recall': 0.8721087591965102, 'f1-score': 0.8704396769255031, 'support': 1132} weighted_avg {'precision': 0.8816503327013967, 'recall': 0.8692579505300353, 'f1-score': 0.8710740470544799, 'support': 1132}
 
----------
Epoch 11/40
time = 837.66 secondes

Train loss 0.10617609211611302 accuracy 0.9775093793869019 macro_avg {'precision': 0.977538718349677, 'recall': 0.9772289112566673, 'f1-score': 0.9773697670928418, 'support': 10182} weighted_avg {'precision': 0.9775149832789348, 'recall': 0.9775093301905323, 'f1-score': 0.9774994762125223, 'support': 10182}
 
time = 26.05 secondes

Val loss 0.9611990161073676 accuracy 0.8648409843444824 macro_avg {'precision': 0.8770506212707753, 'recall': 0.8640129568775118, 'f1-score': 0.866214878747871, 'support': 1132} weighted_avg {'precision': 0.8781365005906817, 'recall': 0.8648409893992933, 'f1-score': 0.8670213126603833, 'support': 1132}
 
----------
Epoch 12/40
time = 835.52 secondes

Train loss 0.09463980655337383 accuracy 0.9808486104011536 macro_avg {'precision': 0.9809932123719356, 'recall': 0.9809425976107102, 'f1-score': 0.9809384604874165, 'support': 10182} weighted_avg {'precision': 0.980853907886144, 'recall': 0.9808485562757808, 'f1-score': 0.9808208449821441, 'support': 10182}
 
time = 25.86 secondes

Val loss 0.9174645882031002 accuracy 0.8736749291419983 macro_avg {'precision': 0.8743525205611787, 'recall': 0.870163025428693, 'f1-score': 0.8687193048497773, 'support': 1132} weighted_avg {'precision': 0.8776903671736073, 'recall': 0.8736749116607774, 'f1-score': 0.8728125846396697, 'support': 1132}
 
----------
Epoch 13/40
time = 837.00 secondes

Train loss 0.11175556105454276 accuracy 0.978295087814331 macro_avg {'precision': 0.9786328604950926, 'recall': 0.9786475512368286, 'f1-score': 0.9785980129455355, 'support': 10182} weighted_avg {'precision': 0.9784768940605688, 'recall': 0.978295030445885, 'f1-score': 0.9783425604685464, 'support': 10182}
 
time = 25.45 secondes

Val loss 0.9927065817440014 accuracy 0.8604240417480469 macro_avg {'precision': 0.8769641991139032, 'recall': 0.8641370154753665, 'f1-score': 0.8661844522014368, 'support': 1132} weighted_avg {'precision': 0.8761393965251432, 'recall': 0.8604240282685512, 'f1-score': 0.8636989740585369, 'support': 1132}
 
----------
Epoch 14/40
time = 836.82 secondes

Train loss 0.10366895973799915 accuracy 0.9813396334648132 macro_avg {'precision': 0.9798089720628406, 'recall': 0.9798977842149753, 'f1-score': 0.9798281433625101, 'support': 10182} weighted_avg {'precision': 0.9813920571501208, 'recall': 0.9813396189353761, 'f1-score': 0.9813423274712456, 'support': 10182}
 
time = 25.45 secondes

Val loss 0.9724630708207743 accuracy 0.8674911856651306 macro_avg {'precision': 0.8746871756895345, 'recall': 0.8600148412253942, 'f1-score': 0.8597599007614314, 'support': 1132} weighted_avg {'precision': 0.87357120576156, 'recall': 0.8674911660777385, 'f1-score': 0.864474835786315, 'support': 1132}
 
----------
Epoch 15/40
time = 832.96 secondes

Train loss 0.09316526724072119 accuracy 0.9822235703468323 macro_avg {'precision': 0.9816155842815588, 'recall': 0.9814443093470887, 'f1-score': 0.9814931604500188, 'support': 10182} weighted_avg {'precision': 0.9822594947651405, 'recall': 0.9822235317226478, 'f1-score': 0.9822050880187012, 'support': 10182}
 
time = 25.53 secondes

Val loss 1.1260967991801805 accuracy 0.8630741834640503 macro_avg {'precision': 0.8841012896285472, 'recall': 0.8640307986204027, 'f1-score': 0.8648174693635902, 'support': 1132} weighted_avg {'precision': 0.8806157466821105, 'recall': 0.8630742049469965, 'f1-score': 0.8627788518613921, 'support': 1132}
 
----------
Epoch 16/40
time = 837.71 secondes

Train loss 0.08060992584564751 accuracy 0.9849734902381897 macro_avg {'precision': 0.9842698935065657, 'recall': 0.9843649161260221, 'f1-score': 0.9843006958719647, 'support': 10182} weighted_avg {'precision': 0.9850019893364226, 'recall': 0.9849734826163818, 'f1-score': 0.9849705327106564, 'support': 10182}
 
time = 25.98 secondes

Val loss 0.9158615016497952 accuracy 0.8772084712982178 macro_avg {'precision': 0.8893542302416856, 'recall': 0.8792573582413347, 'f1-score': 0.8803179863934423, 'support': 1132} weighted_avg {'precision': 0.8887202091014308, 'recall': 0.877208480565371, 'f1-score': 0.878830348053801, 'support': 1132}
 
----------
Epoch 17/40
time = 836.10 secondes

Train loss 0.07923141300407409 accuracy 0.9860538244247437 macro_avg {'precision': 0.9862305111550622, 'recall': 0.9858897528597051, 'f1-score': 0.9860245447506649, 'support': 10182} weighted_avg {'precision': 0.9861789801137762, 'recall': 0.9860538204674917, 'f1-score': 0.9860802520630646, 'support': 10182}
 
time = 25.62 secondes

Val loss 0.8938685422515231 accuracy 0.8869258165359497 macro_avg {'precision': 0.8935427594427706, 'recall': 0.8901451853894644, 'f1-score': 0.8895678867770765, 'support': 1132} weighted_avg {'precision': 0.8949359545526747, 'recall': 0.8869257950530035, 'f1-score': 0.8887462025829816, 'support': 1132}
 
----------
Epoch 18/40
time = 838.47 secondes

Train loss 0.08319271065736006 accuracy 0.9845806360244751 macro_avg {'precision': 0.9846152965407102, 'recall': 0.9843694770783756, 'f1-score': 0.9844711316318262, 'support': 10182} weighted_avg {'precision': 0.9846026620567924, 'recall': 0.9845806324887055, 'f1-score': 0.9845701177161026, 'support': 10182}
 
time = 25.89 secondes

Val loss 0.9057115840444401 accuracy 0.8895759582519531 macro_avg {'precision': 0.8942787861076276, 'recall': 0.8931888098733289, 'f1-score': 0.8919486714424283, 'support': 1132} weighted_avg {'precision': 0.8944543472285617, 'recall': 0.8895759717314488, 'f1-score': 0.8902188542552565, 'support': 1132}
 
----------
Epoch 19/40
time = 837.20 secondes

Train loss 0.07601610734437005 accuracy 0.9852681756019592 macro_avg {'precision': 0.9844603151410551, 'recall': 0.9847334091426987, 'f1-score': 0.9845620805041435, 'support': 10182} weighted_avg {'precision': 0.9853574667728118, 'recall': 0.985268120212139, 'f1-score': 0.9852816122111708, 'support': 10182}
 
time = 26.08 secondes

Val loss 0.9073039649729125 accuracy 0.8886925578117371 macro_avg {'precision': 0.8915067146620064, 'recall': 0.8902018697311871, 'f1-score': 0.8886763628145996, 'support': 1132} weighted_avg {'precision': 0.8943883021006185, 'recall': 0.8886925795053003, 'f1-score': 0.8892977000921026, 'support': 1132}
 
----------
Epoch 20/40
time = 836.79 secondes

Train loss 0.06786750769910845 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881799973406107, 'recall': 0.9886124392926261, 'f1-score': 0.9883585970666507, 'support': 10182} weighted_avg {'precision': 0.9886729832216284, 'recall': 0.9886073462973876, 'f1-score': 0.9886091939255275, 'support': 10182}
 
time = 25.57 secondes

Val loss 0.9216227587723398 accuracy 0.8816254734992981 macro_avg {'precision': 0.8842874549224206, 'recall': 0.8847048594026656, 'f1-score': 0.8823608132726948, 'support': 1132} weighted_avg {'precision': 0.884860107462588, 'recall': 0.8816254416961131, 'f1-score': 0.8809332483844815, 'support': 1132}
 
----------
Epoch 21/40
time = 837.66 secondes

Train loss 0.06867338805865843 accuracy 0.9875270128250122 macro_avg {'precision': 0.9873690842860267, 'recall': 0.9870481888191198, 'f1-score': 0.9871964964888893, 'support': 10182} weighted_avg {'precision': 0.9875662806424296, 'recall': 0.9875270084462777, 'f1-score': 0.9875348111884352, 'support': 10182}
 
time = 25.88 secondes

Val loss 1.0431820057196424 accuracy 0.8736749291419983 macro_avg {'precision': 0.9009845807571757, 'recall': 0.875733765979726, 'f1-score': 0.8771964838580887, 'support': 1132} weighted_avg {'precision': 0.8963444105688528, 'recall': 0.8736749116607774, 'f1-score': 0.872691912395025, 'support': 1132}
 
----------
Epoch 22/40
time = 827.37 secondes

Train loss 0.0540032207424346 accuracy 0.98978590965271 macro_avg {'precision': 0.9899928571751492, 'recall': 0.990062980315671, 'f1-score': 0.9900057108860085, 'support': 10182} weighted_avg {'precision': 0.9898364502634802, 'recall': 0.9897858966804164, 'f1-score': 0.9897883628799112, 'support': 10182}
 
time = 23.25 secondes

Val loss 0.8020806166105231 accuracy 0.9019434452056885 macro_avg {'precision': 0.9052598465812232, 'recall': 0.9016280173194591, 'f1-score': 0.9024467713101005, 'support': 1132} weighted_avg {'precision': 0.9049834172473205, 'recall': 0.9019434628975265, 'f1-score': 0.9023924028192993, 'support': 1132}
 
----------
Epoch 23/40
time = 639.41 secondes

Train loss 0.054076517074387806 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896140765000292, 'recall': 0.9896042564360273, 'f1-score': 0.9895966448181728, 'support': 10182} weighted_avg {'precision': 0.989905913410055, 'recall': 0.9898841092123355, 'f1-score': 0.9898824064274162, 'support': 10182}
 
time = 23.63 secondes

Val loss 0.823391070404245 accuracy 0.9019434452056885 macro_avg {'precision': 0.9056072801871107, 'recall': 0.9018479180328987, 'f1-score': 0.9015873832212055, 'support': 1132} weighted_avg {'precision': 0.9077448184588971, 'recall': 0.9019434628975265, 'f1-score': 0.9030627386185328, 'support': 1132}
 
----------
Epoch 24/40
time = 638.78 secondes

Train loss 0.06165873431409194 accuracy 0.9890984296798706 macro_avg {'precision': 0.9887301098646508, 'recall': 0.9883080775512486, 'f1-score': 0.9884886487201564, 'support': 10182} weighted_avg {'precision': 0.9891151324786456, 'recall': 0.9890984089569829, 'f1-score': 0.9890819838232102, 'support': 10182}
 
time = 21.93 secondes

Val loss 0.8249663097255545 accuracy 0.9019434452056885 macro_avg {'precision': 0.9081451836524558, 'recall': 0.9022773540237568, 'f1-score': 0.9036393391714667, 'support': 1132} weighted_avg {'precision': 0.906463499731577, 'recall': 0.9019434628975265, 'f1-score': 0.9025310705396843, 'support': 1132}
 
----------
Epoch 25/40
time = 640.08 secondes

Train loss 0.042235242178474415 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915424752009733, 'recall': 0.9912906370297913, 'f1-score': 0.9913932248575479, 'support': 10182} weighted_avg {'precision': 0.9919737419845336, 'recall': 0.9919465723826361, 'f1-score': 0.9919394001952633, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.8793593217097866 accuracy 0.8904593586921692 macro_avg {'precision': 0.900676615667358, 'recall': 0.8918028642967102, 'f1-score': 0.8921830899990069, 'support': 1132} weighted_avg {'precision': 0.8997567582581208, 'recall': 0.8904593639575972, 'f1-score': 0.891748230216904, 'support': 1132}
 
----------
Epoch 26/40
time = 640.09 secondes

Train loss 0.04696438047307699 accuracy 0.9915537238121033 macro_avg {'precision': 0.9906586162044494, 'recall': 0.9909579782948349, 'f1-score': 0.9907892757066395, 'support': 10182} weighted_avg {'precision': 0.9916025669629606, 'recall': 0.9915537222549597, 'f1-score': 0.9915613791689488, 'support': 10182}
 
time = 23.49 secondes

Val loss 1.0078850205161511 accuracy 0.8833922147750854 macro_avg {'precision': 0.8846721498546921, 'recall': 0.8873490057678968, 'f1-score': 0.8822614298680167, 'support': 1132} weighted_avg {'precision': 0.8919391263858424, 'recall': 0.8833922261484098, 'f1-score': 0.8843886505945395, 'support': 1132}
 
----------
Epoch 27/40
time = 637.33 secondes

Train loss 0.041386545059611354 accuracy 0.9930269122123718 macro_avg {'precision': 0.9926696496806213, 'recall': 0.9928325906522373, 'f1-score': 0.9927440834653943, 'support': 10182} weighted_avg {'precision': 0.9930528290356434, 'recall': 0.9930269102337458, 'f1-score': 0.9930327956373979, 'support': 10182}
 
time = 23.40 secondes

Val loss 1.0143320002723453 accuracy 0.8948763608932495 macro_avg {'precision': 0.9033699327506355, 'recall': 0.897364945004784, 'f1-score': 0.8977440342649963, 'support': 1132} weighted_avg {'precision': 0.9022690138489569, 'recall': 0.8948763250883393, 'f1-score': 0.8957960002837481, 'support': 1132}
 
----------
Epoch 28/40
time = 638.23 secondes

Train loss 0.04992398067682458 accuracy 0.9927322864532471 macro_avg {'precision': 0.9927053788795396, 'recall': 0.9926731665329542, 'f1-score': 0.9926822927101349, 'support': 10182} weighted_avg {'precision': 0.9927369692592197, 'recall': 0.9927322726379886, 'f1-score': 0.9927276717822284, 'support': 10182}
 
time = 22.21 secondes

Val loss 0.809547954855563 accuracy 0.9054770469665527 macro_avg {'precision': 0.9114032350935073, 'recall': 0.9066966415107608, 'f1-score': 0.9080433958266149, 'support': 1132} weighted_avg {'precision': 0.9086497525398427, 'recall': 0.9054770318021201, 'f1-score': 0.9060532155937443, 'support': 1132}
 
----------
Epoch 29/40
time = 638.64 secondes

Train loss 0.0374347791728658 accuracy 0.9941073060035706 macro_avg {'precision': 0.9942380773889801, 'recall': 0.9940589030160819, 'f1-score': 0.9941429199427019, 'support': 10182} weighted_avg {'precision': 0.994112273857776, 'recall': 0.9941072480848556, 'f1-score': 0.9941044145092717, 'support': 10182}
 
time = 23.42 secondes

Val loss 0.9885589961798962 accuracy 0.8975265026092529 macro_avg {'precision': 0.9020113275686432, 'recall': 0.9009716394824661, 'f1-score': 0.8993834385602846, 'support': 1132} weighted_avg {'precision': 0.9020660509730407, 'recall': 0.8975265017667845, 'f1-score': 0.8976793844638904, 'support': 1132}
 
----------
Epoch 30/40
time = 705.41 secondes

Train loss 0.042311823512621916 accuracy 0.9936162233352661 macro_avg {'precision': 0.9935377033379227, 'recall': 0.993750939508063, 'f1-score': 0.9936314129061723, 'support': 10182} weighted_avg {'precision': 0.9936267750544493, 'recall': 0.9936161854252603, 'f1-score': 0.9936090841816292, 'support': 10182}
 
time = 23.94 secondes

Val loss 0.8852098450616197 accuracy 0.8992933034896851 macro_avg {'precision': 0.9064757659073834, 'recall': 0.9000698669034601, 'f1-score': 0.9010142185734467, 'support': 1132} weighted_avg {'precision': 0.9068482180303824, 'recall': 0.8992932862190812, 'f1-score': 0.9008537847772174, 'support': 1132}
 
----------
Epoch 31/40
time = 717.64 secondes

Train loss 0.035865038700098044 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945390843363595, 'recall': 0.9946758954199986, 'f1-score': 0.9946027514979789, 'support': 10182} weighted_avg {'precision': 0.9946071631348953, 'recall': 0.994598310744451, 'f1-score': 0.9945981723390306, 'support': 10182}
 
time = 23.96 secondes

Val loss 0.8857434673952578 accuracy 0.898409903049469 macro_avg {'precision': 0.9076609217972255, 'recall': 0.9017255685142642, 'f1-score': 0.9020470769018992, 'support': 1132} weighted_avg {'precision': 0.9056896935223729, 'recall': 0.8984098939929329, 'f1-score': 0.8992160004657599, 'support': 1132}
 
----------
Epoch 32/40
time = 718.93 secondes

Train loss 0.01737048085757478 accuracy 0.996857225894928 macro_avg {'precision': 0.9965922851027459, 'recall': 0.9965964850830387, 'f1-score': 0.9965930030441983, 'support': 10182} weighted_avg {'precision': 0.9968601725240651, 'recall': 0.9968571989785897, 'f1-score': 0.9968573292278397, 'support': 10182}
 
time = 23.99 secondes

Val loss 0.8673109349010317 accuracy 0.9045936465263367 macro_avg {'precision': 0.9123126860329072, 'recall': 0.9067933867916921, 'f1-score': 0.907815800814461, 'support': 1132} weighted_avg {'precision': 0.9104437722268408, 'recall': 0.9045936395759717, 'f1-score': 0.905686201653122, 'support': 1132}
 
----------
Epoch 33/40
time = 719.85 secondes

Train loss 0.01908183911271428 accuracy 0.9962679743766785 macro_avg {'precision': 0.9962302748102676, 'recall': 0.9962026006022846, 'f1-score': 0.9962125626342841, 'support': 10182} weighted_avg {'precision': 0.9962726890305023, 'recall': 0.9962679237870752, 'f1-score': 0.9962664657690165, 'support': 10182}
 
time = 23.39 secondes

Val loss 0.960587005702468 accuracy 0.8975265026092529 macro_avg {'precision': 0.9084874781130571, 'recall': 0.8987659339428424, 'f1-score': 0.9006215780084339, 'support': 1132} weighted_avg {'precision': 0.9067867513105893, 'recall': 0.8975265017667845, 'f1-score': 0.899081119210979, 'support': 1132}
 
----------
Epoch 34/40
time = 720.44 secondes

Train loss 0.015326959784097784 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971738178892906, 'recall': 0.9972178766427492, 'f1-score': 0.9971943351554661, 'support': 10182} weighted_avg {'precision': 0.9971537453979965, 'recall': 0.9971518365743469, 'f1-score': 0.9971512750777651, 'support': 10182}
 
time = 24.20 secondes

Val loss 0.9240026213122126 accuracy 0.8957597017288208 macro_avg {'precision': 0.8972603826468395, 'recall': 0.8977690074949845, 'f1-score': 0.8959372856115027, 'support': 1132} weighted_avg {'precision': 0.9001916249699762, 'recall': 0.8957597173144877, 'f1-score': 0.8964161573982706, 'support': 1132}
 
----------
Epoch 35/40
time = 720.81 secondes

Train loss 0.02142309530165301 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971848591651806, 'recall': 0.9972031475103492, 'f1-score': 0.9971915895045431, 'support': 10182} weighted_avg {'precision': 0.9971563130324574, 'recall': 0.9971518365743469, 'f1-score': 0.9971516276297803, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.944493991353892 accuracy 0.8992933034896851 macro_avg {'precision': 0.9084956005116294, 'recall': 0.9032534204469396, 'f1-score': 0.9036668290907661, 'support': 1132} weighted_avg {'precision': 0.9061107420090534, 'recall': 0.8992932862190812, 'f1-score': 0.9003103841532892, 'support': 1132}
 
----------
Epoch 36/40
time = 719.31 secondes

Train loss 0.008777782325476614 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986539652285844, 'recall': 0.9986605999620022, 'f1-score': 0.9986558564277835, 'support': 10182} weighted_avg {'precision': 0.9986265551114746, 'recall': 0.998625024553133, 'f1-score': 0.9986243543818654, 'support': 10182}
 
time = 24.10 secondes

Val loss 0.8363662594547863 accuracy 0.9178445339202881 macro_avg {'precision': 0.9225881451332301, 'recall': 0.9200313723256354, 'f1-score': 0.920076210141573, 'support': 1132} weighted_avg {'precision': 0.921054087789988, 'recall': 0.9178445229681979, 'f1-score': 0.9181434047132578, 'support': 1132}
 
----------
Epoch 37/40
time = 720.96 secondes

Train loss 0.011582849999878355 accuracy 0.9981340169906616 macro_avg {'precision': 0.9982104027736064, 'recall': 0.9981998379879009, 'f1-score': 0.9982023150416698, 'support': 10182} weighted_avg {'precision': 0.9981400629681199, 'recall': 0.9981339618935376, 'f1-score': 0.9981341220971424, 'support': 10182}
 
time = 24.15 secondes

Val loss 0.9052395592850996 accuracy 0.9090105891227722 macro_avg {'precision': 0.9121052382666441, 'recall': 0.9122253194207304, 'f1-score': 0.9103837758286785, 'support': 1132} weighted_avg {'precision': 0.9136721134779537, 'recall': 0.9090106007067138, 'f1-score': 0.9096023537617903, 'support': 1132}
 
----------
Epoch 38/40
time = 720.33 secondes

Train loss 0.008313302486978038 accuracy 0.998821496963501 macro_avg {'precision': 0.9988512663391287, 'recall': 0.9988559482871772, 'f1-score': 0.998852332008763, 'support': 10182} weighted_avg {'precision': 0.9988246018295892, 'recall': 0.9988214496169712, 'f1-score': 0.9988217171558444, 'support': 10182}
 
time = 24.38 secondes

Val loss 0.9017778550646461 accuracy 0.9098939895629883 macro_avg {'precision': 0.9114992824115538, 'recall': 0.9117584308945362, 'f1-score': 0.9108806845659838, 'support': 1132} weighted_avg {'precision': 0.9127114504068359, 'recall': 0.9098939929328622, 'f1-score': 0.9105542915437483, 'support': 1132}
 
----------
Epoch 39/40
time = 720.35 secondes

Train loss 0.004415794848718403 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990556175849136, 'recall': 0.9990557948559132, 'f1-score': 0.9990548141045735, 'support': 10182} weighted_avg {'precision': 0.9990197198847299, 'recall': 0.9990178746808093, 'f1-score': 0.999017870763278, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.9412181954181172 accuracy 0.9090105891227722 macro_avg {'precision': 0.9115841138472375, 'recall': 0.9112732849315629, 'f1-score': 0.9103448842231285, 'support': 1132} weighted_avg {'precision': 0.9118296183706455, 'recall': 0.9090106007067138, 'f1-score': 0.9093206892378543, 'support': 1132}
 
----------
Epoch 40/40
time = 719.43 secondes

Train loss 0.005215827239922957 accuracy 0.9992143511772156 macro_avg {'precision': 0.9992450804989627, 'recall': 0.9992364998161716, 'f1-score': 0.9992392636668296, 'support': 10182} weighted_avg {'precision': 0.999218555129631, 'recall': 0.9992142997446474, 'f1-score': 0.9992148536231642, 'support': 10182}
 
time = 24.80 secondes

Val loss 0.9346085568990353 accuracy 0.9107773900032043 macro_avg {'precision': 0.9144943890123194, 'recall': 0.9128575032692463, 'f1-score': 0.9125734070381759, 'support': 1132} weighted_avg {'precision': 0.9138476734713233, 'recall': 0.9107773851590106, 'f1-score': 0.911190810940502, 'support': 1132}
 
----------
best_accuracy 0.9178445339202881 best_epoch 36 macro_avg {'precision': 0.9225881451332301, 'recall': 0.9200313723256354, 'f1-score': 0.920076210141573, 'support': 1132} weighted_avg {'precision': 0.921054087789988, 'recall': 0.9178445229681979, 'f1-score': 0.9181434047132578, 'support': 1132}

average train time 733.9297438800335

average val time 24.39423597455025
 
time = 155.35 secondes

test_accuracy 0.8275358080863953 macro_avg {'precision': 0.8260559319249452, 'recall': 0.8221825512176645, 'f1-score': 0.8222292337917094, 'support': 7532} weighted_avg {'precision': 0.832600867866986, 'recall': 0.8275358470525757, 'f1-score': 0.8284608665428768, 'support': 7532}

----------
/vol/fob-vol3/nebenf20/wubingti/data/22_wub_longdocclassification/trainer.py:82: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_2
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 427.31 secondes

Train loss 1.3944869267884379 accuracy 0.6181496977806091 macro_avg {'precision': 0.6045006226210984, 'recall': 0.6023568057655814, 'f1-score': 0.5899182731107757, 'support': 10182} weighted_avg {'precision': 0.6117337902996466, 'recall': 0.6181496758986447, 'f1-score': 0.6039109376752558, 'support': 10182}
 
time = 18.86 secondes

Val loss 0.788058576029791 accuracy 0.7623674869537354 macro_avg {'precision': 0.7472090891743186, 'recall': 0.7588656075897282, 'f1-score': 0.7421309130196391, 'support': 1132} weighted_avg {'precision': 0.7592242975126788, 'recall': 0.7623674911660777, 'f1-score': 0.7494949316621431, 'support': 1132}
 
----------
Epoch 2/40
time = 426.86 secondes

Train loss 0.5850483487174499 accuracy 0.8245924711227417 macro_avg {'precision': 0.8122776845412082, 'recall': 0.8131538194869453, 'f1-score': 0.8098732518066617, 'support': 10182} weighted_avg {'precision': 0.8204633086580889, 'recall': 0.8245924179925358, 'f1-score': 0.8204472778701701, 'support': 10182}
 
time = 19.03 secondes

Val loss 0.596053410373943 accuracy 0.8242049813270569 macro_avg {'precision': 0.8223741335017405, 'recall': 0.8181435430972808, 'f1-score': 0.8120008259362381, 'support': 1132} weighted_avg {'precision': 0.8276198653027891, 'recall': 0.8242049469964664, 'f1-score': 0.8188381949377425, 'support': 1132}
 
----------
Epoch 3/40
time = 427.36 secondes

Train loss 0.3575606437318109 accuracy 0.8985464572906494 macro_avg {'precision': 0.8933212892312646, 'recall': 0.8929839811862802, 'f1-score': 0.8929051815745856, 'support': 10182} weighted_avg {'precision': 0.8986419047575008, 'recall': 0.8985464545275977, 'f1-score': 0.8983564043106278, 'support': 10182}
 
time = 18.85 secondes

Val loss 0.5565338725040496 accuracy 0.8480565547943115 macro_avg {'precision': 0.8528758698680713, 'recall': 0.8477144025007576, 'f1-score': 0.8465388153138983, 'support': 1132} weighted_avg {'precision': 0.8552435632693681, 'recall': 0.8480565371024735, 'f1-score': 0.8476463890366434, 'support': 1132}
 
----------
Epoch 4/40
time = 426.68 secondes

Train loss 0.237381704627526 accuracy 0.9332154989242554 macro_avg {'precision': 0.930445629520219, 'recall': 0.9305066848475727, 'f1-score': 0.9303990640736878, 'support': 10182} weighted_avg {'precision': 0.9331704294143961, 'recall': 0.9332154782950305, 'f1-score': 0.933117835503915, 'support': 10182}
 
time = 18.56 secondes

Val loss 0.5852532469287095 accuracy 0.8736749291419983 macro_avg {'precision': 0.8776755776564509, 'recall': 0.8688361355115003, 'f1-score': 0.8696246691971175, 'support': 1132} weighted_avg {'precision': 0.8775439916697695, 'recall': 0.8736749116607774, 'f1-score': 0.8724567757484273, 'support': 1132}
 
----------
Epoch 5/40
time = 427.00 secondes

Train loss 0.17320953996660512 accuracy 0.95403653383255 macro_avg {'precision': 0.951707244460119, 'recall': 0.9517939456996107, 'f1-score': 0.9517229055027492, 'support': 10182} weighted_avg {'precision': 0.9541145581682021, 'recall': 0.9540365350618739, 'f1-score': 0.9540477064468614, 'support': 10182}
 
time = 18.67 secondes

Val loss 0.6530555817856073 accuracy 0.8763250708580017 macro_avg {'precision': 0.8875437649454596, 'recall': 0.8761900024143024, 'f1-score': 0.8781754998462954, 'support': 1132} weighted_avg {'precision': 0.8844696027439095, 'recall': 0.8763250883392226, 'f1-score': 0.8767880792855786, 'support': 1132}
 
----------
Epoch 6/40
time = 426.68 secondes

Train loss 0.1499853816716398 accuracy 0.9607149958610535 macro_avg {'precision': 0.9591360875080956, 'recall': 0.9592451188755666, 'f1-score': 0.9591433502451634, 'support': 10182} weighted_avg {'precision': 0.9609027966544885, 'recall': 0.9607149872323708, 'f1-score': 0.9607610887085988, 'support': 10182}
 
time = 18.09 secondes

Val loss 0.7074301727476832 accuracy 0.870141327381134 macro_avg {'precision': 0.8746033563183581, 'recall': 0.8710008207731071, 'f1-score': 0.8708220130576209, 'support': 1132} weighted_avg {'precision': 0.8752996486161535, 'recall': 0.8701413427561837, 'f1-score': 0.8706692570800069, 'support': 1132}
 
----------
Epoch 7/40
time = 426.04 secondes

Train loss 0.13629770623297055 accuracy 0.9678845405578613 macro_avg {'precision': 0.9664717062297828, 'recall': 0.9663277860561555, 'f1-score': 0.9663610212735894, 'support': 10182} weighted_avg {'precision': 0.9679270475444599, 'recall': 0.9678845020624631, 'f1-score': 0.9678682620281933, 'support': 10182}
 
time = 18.74 secondes

Val loss 0.7419142454828161 accuracy 0.8754417300224304 macro_avg {'precision': 0.8842747702719503, 'recall': 0.8764918851701544, 'f1-score': 0.8761088224777025, 'support': 1132} weighted_avg {'precision': 0.8846427210283666, 'recall': 0.8754416961130742, 'f1-score': 0.8759983589118007, 'support': 1132}
 
----------
Epoch 8/40
time = 426.50 secondes

Train loss 0.14834782267031385 accuracy 0.9676880836486816 macro_avg {'precision': 0.967121411813664, 'recall': 0.9668541421399324, 'f1-score': 0.9669416756162594, 'support': 10182} weighted_avg {'precision': 0.9676985893406989, 'recall': 0.967688076998625, 'f1-score': 0.9676485382233034, 'support': 10182}
 
time = 18.66 secondes

Val loss 0.9086899811739731 accuracy 0.8604240417480469 macro_avg {'precision': 0.8670106136329319, 'recall': 0.8615929771446554, 'f1-score': 0.8592571192966693, 'support': 1132} weighted_avg {'precision': 0.8696750623046163, 'recall': 0.8604240282685512, 'f1-score': 0.8601631210354338, 'support': 1132}
 
----------
Epoch 9/40
time = 426.37 secondes

Train loss 0.13137833078732142 accuracy 0.9725005030632019 macro_avg {'precision': 0.9720151576817531, 'recall': 0.971437653868921, 'f1-score': 0.9716862263128666, 'support': 10182} weighted_avg {'precision': 0.9724324476363007, 'recall': 0.9725004910626596, 'f1-score': 0.9724316753338268, 'support': 10182}
 
time = 18.68 secondes

Val loss 0.7998119518857673 accuracy 0.8789752721786499 macro_avg {'precision': 0.8879375515442411, 'recall': 0.877886114332326, 'f1-score': 0.8782433580770077, 'support': 1132} weighted_avg {'precision': 0.891058425140966, 'recall': 0.8789752650176679, 'f1-score': 0.88114296794068, 'support': 1132}
 
----------
Epoch 10/40
time = 427.19 secondes

Train loss 0.11925029340039302 accuracy 0.9744647741317749 macro_avg {'precision': 0.973440949820958, 'recall': 0.97359871301659, 'f1-score': 0.973487547668449, 'support': 10182} weighted_avg {'precision': 0.9745241718167451, 'recall': 0.974464741701041, 'f1-score': 0.974462297641218, 'support': 10182}
 
time = 18.49 secondes

Val loss 0.7808534845781125 accuracy 0.8825088143348694 macro_avg {'precision': 0.8868047564617708, 'recall': 0.8853518605353179, 'f1-score': 0.8835108788619813, 'support': 1132} weighted_avg {'precision': 0.888260858610339, 'recall': 0.8825088339222615, 'f1-score': 0.8826601189510983, 'support': 1132}
 
----------
Epoch 11/40
time = 428.50 secondes

Train loss 0.11701830308108585 accuracy 0.9752504825592041 macro_avg {'precision': 0.9750317882795846, 'recall': 0.9748261806906324, 'f1-score': 0.9749115164214164, 'support': 10182} weighted_avg {'precision': 0.9752820207947129, 'recall': 0.9752504419563937, 'f1-score': 0.9752482758621236, 'support': 10182}
 
time = 18.63 secondes

Val loss 0.7985545295056179 accuracy 0.879858672618866 macro_avg {'precision': 0.8848967198962313, 'recall': 0.8841142044478563, 'f1-score': 0.8800696985767693, 'support': 1132} weighted_avg {'precision': 0.8897030243905966, 'recall': 0.8798586572438163, 'f1-score': 0.880167748091954, 'support': 1132}
 
----------
Epoch 12/40
time = 427.04 secondes

Train loss 0.09020881973644422 accuracy 0.9808486104011536 macro_avg {'precision': 0.9806664243515517, 'recall': 0.9807692078478463, 'f1-score': 0.9806822634500525, 'support': 10182} weighted_avg {'precision': 0.9808985264497452, 'recall': 0.9808485562757808, 'f1-score': 0.9808372711420434, 'support': 10182}
 
time = 18.33 secondes

Val loss 0.8482931855054323 accuracy 0.8833922147750854 macro_avg {'precision': 0.887591686606602, 'recall': 0.8865967573786374, 'f1-score': 0.8848982868404478, 'support': 1132} weighted_avg {'precision': 0.8886467518272586, 'recall': 0.8833922261484098, 'f1-score': 0.8837899194909417, 'support': 1132}
 
----------
Epoch 13/40
time = 426.97 secondes

Train loss 0.09110393500773092 accuracy 0.9814378619194031 macro_avg {'precision': 0.9811586521147048, 'recall': 0.9808376155275319, 'f1-score': 0.9809426355577786, 'support': 10182} weighted_avg {'precision': 0.9815287905216034, 'recall': 0.9814378314672952, 'f1-score': 0.9814264878872099, 'support': 10182}
 
time = 18.30 secondes

Val loss 0.9327451979940672 accuracy 0.8710247278213501 macro_avg {'precision': 0.8781609115720521, 'recall': 0.8735901511007793, 'f1-score': 0.871934160526812, 'support': 1132} weighted_avg {'precision': 0.8806922230375215, 'recall': 0.8710247349823321, 'f1-score': 0.8718955173915479, 'support': 1132}
 
----------
Epoch 14/40
time = 427.86 secondes

Train loss 0.07938389505928213 accuracy 0.9834021329879761 macro_avg {'precision': 0.9834453078126719, 'recall': 0.9831931163322976, 'f1-score': 0.9832883621303885, 'support': 10182} weighted_avg {'precision': 0.9834271118775184, 'recall': 0.9834020821056767, 'f1-score': 0.983384118496638, 'support': 10182}
 
time = 18.77 secondes

Val loss 0.7628874563477592 accuracy 0.8913427591323853 macro_avg {'precision': 0.8977923199827755, 'recall': 0.8945243434939127, 'f1-score': 0.8945411728032946, 'support': 1132} weighted_avg {'precision': 0.8958691583497893, 'recall': 0.8913427561837456, 'f1-score': 0.891849923099418, 'support': 1132}
 
----------
Epoch 15/40
time = 427.19 secondes

Train loss 0.07602018751505789 accuracy 0.9846788644790649 macro_avg {'precision': 0.9846202710671946, 'recall': 0.9844197563032925, 'f1-score': 0.9845092076429147, 'support': 10182} weighted_avg {'precision': 0.984692214061963, 'recall': 0.9846788450206246, 'f1-score': 0.9846751652287741, 'support': 10182}
 
time = 18.73 secondes

Val loss 0.9119916264134587 accuracy 0.880742073059082 macro_avg {'precision': 0.8842946538606092, 'recall': 0.8835589762303402, 'f1-score': 0.8827416732109562, 'support': 1132} weighted_avg {'precision': 0.8848097430398214, 'recall': 0.8807420494699647, 'f1-score': 0.8815321353607817, 'support': 1132}
 
----------
Epoch 16/40
time = 426.93 secondes

Train loss 0.08259360741776532 accuracy 0.9843842387199402 macro_avg {'precision': 0.9837348465870284, 'recall': 0.9838818972906047, 'f1-score': 0.9837939466486694, 'support': 10182} weighted_avg {'precision': 0.9844258665525611, 'recall': 0.9843842074248674, 'f1-score': 0.9843910337324336, 'support': 10182}
 
time = 18.94 secondes

Val loss 0.8845736283151446 accuracy 0.8860424160957336 macro_avg {'precision': 0.8883999402241397, 'recall': 0.8888392586923484, 'f1-score': 0.8856627739400755, 'support': 1132} weighted_avg {'precision': 0.8912251673204233, 'recall': 0.8860424028268551, 'f1-score': 0.8857509061910637, 'support': 1132}
 
----------
Epoch 17/40
time = 427.45 secondes

Train loss 0.07498923799879151 accuracy 0.9857591986656189 macro_avg {'precision': 0.9852400366293516, 'recall': 0.985517855040748, 'f1-score': 0.9853670895153737, 'support': 10182} weighted_avg {'precision': 0.9857697466191391, 'recall': 0.9857591828717345, 'f1-score': 0.985753648853807, 'support': 10182}
 
time = 18.42 secondes

Val loss 0.7881237364047811 accuracy 0.8895759582519531 macro_avg {'precision': 0.8946488473168974, 'recall': 0.8921448009308399, 'f1-score': 0.8920979699744335, 'support': 1132} weighted_avg {'precision': 0.8927891165473598, 'recall': 0.8895759717314488, 'f1-score': 0.88984537103151, 'support': 1132}
 
----------
Epoch 18/40
time = 433.00 secondes

Train loss 0.06202199371863124 accuracy 0.9879198670387268 macro_avg {'precision': 0.9876474491089278, 'recall': 0.9876703226209267, 'f1-score': 0.9876486534852432, 'support': 10182} weighted_avg {'precision': 0.9879528686027453, 'recall': 0.987919858573954, 'f1-score': 0.9879258677404208, 'support': 10182}
 
time = 18.64 secondes

Val loss 0.9623970465870282 accuracy 0.8648409843444824 macro_avg {'precision': 0.8816679349603291, 'recall': 0.870846891235375, 'f1-score': 0.8707818192105693, 'support': 1132} weighted_avg {'precision': 0.880645383618342, 'recall': 0.8648409893992933, 'f1-score': 0.8666617259269059, 'support': 1132}
 
----------
Epoch 19/40
time = 426.56 secondes

Train loss 0.0677374617840239 accuracy 0.9869377613067627 macro_avg {'precision': 0.9867769289836282, 'recall': 0.9863990683830363, 'f1-score': 0.98656364598944, 'support': 10182} weighted_avg {'precision': 0.9869782294594618, 'recall': 0.9869377332547633, 'f1-score': 0.9869356693536722, 'support': 10182}
 
time = 19.00 secondes

Val loss 0.905616300331095 accuracy 0.8878092169761658 macro_avg {'precision': 0.8903850960633128, 'recall': 0.8929304059871962, 'f1-score': 0.8889787013354281, 'support': 1132} weighted_avg {'precision': 0.8938476582795393, 'recall': 0.8878091872791519, 'f1-score': 0.8881530432731333, 'support': 1132}
 
----------
Epoch 20/40
time = 426.70 secondes

Train loss 0.07014421330095044 accuracy 0.9873306155204773 macro_avg {'precision': 0.9873460270446376, 'recall': 0.9872685308386755, 'f1-score': 0.9872988793729724, 'support': 10182} weighted_avg {'precision': 0.9873357460619406, 'recall': 0.9873305833824396, 'f1-score': 0.9873249668992754, 'support': 10182}
 
time = 17.95 secondes

Val loss 0.9245256907493122 accuracy 0.8816254734992981 macro_avg {'precision': 0.8852891085519443, 'recall': 0.8869970639007159, 'f1-score': 0.8821162547527678, 'support': 1132} weighted_avg {'precision': 0.8895385281757208, 'recall': 0.8816254416961131, 'f1-score': 0.8815427504449098, 'support': 1132}
 
----------
Epoch 21/40
time = 426.18 secondes

Train loss 0.057022561286858904 accuracy 0.9893930554389954 macro_avg {'precision': 0.9893378627560742, 'recall': 0.9893626247541162, 'f1-score': 0.989334031401486, 'support': 10182} weighted_avg {'precision': 0.9894168410047235, 'recall': 0.9893930465527401, 'f1-score': 0.9893889079726764, 'support': 10182}
 
time = 18.36 secondes

Val loss 0.8241545651888911 accuracy 0.8895759582519531 macro_avg {'precision': 0.8953562342109379, 'recall': 0.8918124651644262, 'f1-score': 0.8926665793052058, 'support': 1132} weighted_avg {'precision': 0.8936473588096309, 'recall': 0.8895759717314488, 'f1-score': 0.8906280895138791, 'support': 1132}
 
----------
Epoch 22/40
time = 426.99 secondes

Train loss 0.05812775582255408 accuracy 0.9894912838935852 macro_avg {'precision': 0.9896047939496411, 'recall': 0.9893884408214936, 'f1-score': 0.9894813273092277, 'support': 10182} weighted_avg {'precision': 0.9895298889564399, 'recall': 0.9894912590846592, 'f1-score': 0.989495600720612, 'support': 10182}
 
time = 18.74 secondes

Val loss 0.9095124921246602 accuracy 0.8833922147750854 macro_avg {'precision': 0.8879979221528123, 'recall': 0.8863466686297047, 'f1-score': 0.8848879495511939, 'support': 1132} weighted_avg {'precision': 0.8892548234236863, 'recall': 0.8833922261484098, 'f1-score': 0.8840605766749731, 'support': 1132}
 
----------
Epoch 23/40
time = 426.39 secondes

Train loss 0.04169038312657322 accuracy 0.9908662438392639 macro_avg {'precision': 0.9907101686278816, 'recall': 0.9907347715789898, 'f1-score': 0.9907160062168721, 'support': 10182} weighted_avg {'precision': 0.9908696308269275, 'recall': 0.9908662345315262, 'f1-score': 0.9908619034008569, 'support': 10182}
 
time = 19.11 secondes

Val loss 1.0273031553388392 accuracy 0.8586572408676147 macro_avg {'precision': 0.875394848507335, 'recall': 0.8667456872108785, 'f1-score': 0.8625773783643356, 'support': 1132} weighted_avg {'precision': 0.8768700028147991, 'recall': 0.8586572438162544, 'f1-score': 0.8587815159162229, 'support': 1132}
 
----------
Epoch 24/40
time = 426.52 secondes

Train loss 0.04430176816815071 accuracy 0.9924376606941223 macro_avg {'precision': 0.9924035060138975, 'recall': 0.9923118910648941, 'f1-score': 0.9923535726778251, 'support': 10182} weighted_avg {'precision': 0.9924487534123582, 'recall': 0.9924376350422314, 'f1-score': 0.992439290267036, 'support': 10182}
 
time = 19.05 secondes

Val loss 1.1557206330924115 accuracy 0.8710247278213501 macro_avg {'precision': 0.8772429866178504, 'recall': 0.8747271218739069, 'f1-score': 0.8711978193907293, 'support': 1132} weighted_avg {'precision': 0.8825432578461917, 'recall': 0.8710247349823321, 'f1-score': 0.8720002122301741, 'support': 1132}
 
----------
Epoch 25/40
time = 426.81 secondes

Train loss 0.07214749126611349 accuracy 0.9884109497070312 macro_avg {'precision': 0.9881437784790201, 'recall': 0.9884769191044912, 'f1-score': 0.988293566538734, 'support': 10182} weighted_avg {'precision': 0.988465432064931, 'recall': 0.9884109212335495, 'f1-score': 0.9884227931006876, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.8703565084411103 accuracy 0.8913427591323853 macro_avg {'precision': 0.8939708453646091, 'recall': 0.8967030885350038, 'f1-score': 0.8925369295699873, 'support': 1132} weighted_avg {'precision': 0.8967230758186376, 'recall': 0.8913427561837456, 'f1-score': 0.8910646120682261, 'support': 1132}
 
----------
Epoch 26/40
time = 425.75 secondes

Train loss 0.04745961950775353 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915073586874149, 'recall': 0.9915140337383775, 'f1-score': 0.9915012171200965, 'support': 10182} weighted_avg {'precision': 0.9919701218185927, 'recall': 0.9919465723826361, 'f1-score': 0.991949922477341, 'support': 10182}
 
time = 19.07 secondes

Val loss 0.8690545192723323 accuracy 0.8948763608932495 macro_avg {'precision': 0.9022120240509196, 'recall': 0.8978221002950827, 'f1-score': 0.897832307328294, 'support': 1132} weighted_avg {'precision': 0.900670595207782, 'recall': 0.8948763250883393, 'f1-score': 0.8953793087506162, 'support': 1132}
 
----------
Epoch 27/40
time = 426.06 secondes

Train loss 0.041583240879719464 accuracy 0.9927322864532471 macro_avg {'precision': 0.9925269197109348, 'recall': 0.9922288299278295, 'f1-score': 0.9923516912995762, 'support': 10182} weighted_avg {'precision': 0.9927853461157194, 'recall': 0.9927322726379886, 'f1-score': 0.9927364722911269, 'support': 10182}
 
time = 19.09 secondes

Val loss 1.2035920749207127 accuracy 0.8586572408676147 macro_avg {'precision': 0.8769976111556549, 'recall': 0.8616841737070124, 'f1-score': 0.8633512925140743, 'support': 1132} weighted_avg {'precision': 0.8763109447215587, 'recall': 0.8586572438162544, 'f1-score': 0.861226206528085, 'support': 1132}
 
----------
Epoch 28/40
time = 426.73 secondes

Train loss 0.040594573515012784 accuracy 0.9936162233352661 macro_avg {'precision': 0.9935913200631491, 'recall': 0.9935565100621984, 'f1-score': 0.9935692247024915, 'support': 10182} weighted_avg {'precision': 0.9936282358671814, 'recall': 0.9936161854252603, 'f1-score': 0.9936176532703719, 'support': 10182}
 
time = 18.31 secondes

Val loss 0.944949869870009 accuracy 0.8904593586921692 macro_avg {'precision': 0.8926181254976896, 'recall': 0.8926676999648893, 'f1-score': 0.8905797067033732, 'support': 1132} weighted_avg {'precision': 0.8949852675423717, 'recall': 0.8904593639575972, 'f1-score': 0.8907419316481088, 'support': 1132}
 
----------
Epoch 29/40
time = 426.34 secondes

Train loss 0.04400276573926744 accuracy 0.9924376606941223 macro_avg {'precision': 0.9923377285782928, 'recall': 0.9924724295619377, 'f1-score': 0.9923905179766006, 'support': 10182} weighted_avg {'precision': 0.9924527159814626, 'recall': 0.9924376350422314, 'f1-score': 0.9924304618441244, 'support': 10182}
 
time = 19.04 secondes

Val loss 0.9833480149251737 accuracy 0.8825088143348694 macro_avg {'precision': 0.8884369245109708, 'recall': 0.8861775306165107, 'f1-score': 0.8849164716317915, 'support': 1132} weighted_avg {'precision': 0.8907599367376277, 'recall': 0.8825088339222615, 'f1-score': 0.8842370662082859, 'support': 1132}
 
----------
Epoch 30/40
time = 426.23 secondes

Train loss 0.031844082074066006 accuracy 0.9946965575218201 macro_avg {'precision': 0.9947225132088858, 'recall': 0.9947545541406548, 'f1-score': 0.9947340428032355, 'support': 10182} weighted_avg {'precision': 0.9947104332827956, 'recall': 0.99469652327637, 'f1-score': 0.9946989626534372, 'support': 10182}
 
time = 19.06 secondes

Val loss 0.940710612721528 accuracy 0.8860424160957336 macro_avg {'precision': 0.8894782407212581, 'recall': 0.8905645808590433, 'f1-score': 0.888101816244386, 'support': 1132} weighted_avg {'precision': 0.8913551441985083, 'recall': 0.8860424028268551, 'f1-score': 0.8867444283056902, 'support': 1132}
 
----------
Epoch 31/40
time = 425.49 secondes

Train loss 0.03165554801254622 accuracy 0.994892954826355 macro_avg {'precision': 0.994667154382044, 'recall': 0.9946460142295266, 'f1-score': 0.9946524377807784, 'support': 10182} weighted_avg {'precision': 0.9949021354221078, 'recall': 0.9948929483402082, 'f1-score': 0.9948933361638173, 'support': 10182}
 
time = 19.11 secondes

Val loss 0.928568748897126 accuracy 0.8931095600128174 macro_avg {'precision': 0.8982822032106389, 'recall': 0.8981766485194049, 'f1-score': 0.8959304301923577, 'support': 1132} weighted_avg {'precision': 0.8985612422279412, 'recall': 0.8931095406360424, 'f1-score': 0.893578534819093, 'support': 1132}
 
----------
Epoch 32/40
time = 426.14 secondes

Train loss 0.03031601273644152 accuracy 0.9955804944038391 macro_avg {'precision': 0.9956526703773569, 'recall': 0.9956192163068474, 'f1-score': 0.9956308510196272, 'support': 10182} weighted_avg {'precision': 0.9955923657864651, 'recall': 0.9955804360636418, 'f1-score': 0.9955816018641301, 'support': 10182}
 
time = 18.71 secondes

Val loss 0.9372132644599384 accuracy 0.8931095600128174 macro_avg {'precision': 0.8964893689554199, 'recall': 0.89573736338956, 'f1-score': 0.8943688593874313, 'support': 1132} weighted_avg {'precision': 0.8977879820445511, 'recall': 0.8931095406360424, 'f1-score': 0.8937944313855581, 'support': 1132}
 
----------
Epoch 33/40
time = 426.53 secondes

Train loss 0.020794112729821523 accuracy 0.9970536828041077 macro_avg {'precision': 0.9969938973186505, 'recall': 0.996896591190834, 'f1-score': 0.9969411129800451, 'support': 10182} weighted_avg {'precision': 0.9970589371310673, 'recall': 0.9970536240424278, 'f1-score': 0.9970524097307252, 'support': 10182}
 
time = 19.05 secondes

Val loss 0.9525722244173996 accuracy 0.8939929604530334 macro_avg {'precision': 0.8947483259208969, 'recall': 0.8993955605317782, 'f1-score': 0.8949880831938088, 'support': 1132} weighted_avg {'precision': 0.896809401415789, 'recall': 0.8939929328621908, 'f1-score': 0.893343097664538, 'support': 1132}
 
----------
Epoch 34/40
time = 426.06 secondes

Train loss 0.023359457895283563 accuracy 0.9959732890129089 macro_avg {'precision': 0.9954081142820677, 'recall': 0.9954159366010762, 'f1-score': 0.9954071659766685, 'support': 10182} weighted_avg {'precision': 0.9959858122666226, 'recall': 0.995973286191318, 'f1-score': 0.9959751356495137, 'support': 10182}
 
time = 19.03 secondes

Val loss 1.0343953092006801 accuracy 0.8922261595726013 macro_avg {'precision': 0.8952090813458018, 'recall': 0.893755825491543, 'f1-score': 0.8920311452597242, 'support': 1132} weighted_avg {'precision': 0.8989875218411926, 'recall': 0.892226148409894, 'f1-score': 0.8934443932821606, 'support': 1132}
 
----------
Epoch 35/40
time = 426.55 secondes

Train loss 0.021573402412605063 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970888024798121, 'recall': 0.9970510282145885, 'f1-score': 0.9970661744287529, 'support': 10182} weighted_avg {'precision': 0.9970610136668834, 'recall': 0.9970536240424278, 'f1-score': 0.9970535369876667, 'support': 10182}
 
time = 18.60 secondes

Val loss 0.9567452537322796 accuracy 0.8966431021690369 macro_avg {'precision': 0.9004785950170943, 'recall': 0.9006100464897806, 'f1-score': 0.8989713986024706, 'support': 1132} weighted_avg {'precision': 0.9002745750735334, 'recall': 0.8966431095406361, 'f1-score': 0.8967467148155048, 'support': 1132}
 
----------
Epoch 36/40
time = 426.96 secondes

Train loss 0.013004058093643361 accuracy 0.9978393316268921 macro_avg {'precision': 0.99788450120662, 'recall': 0.9978472585058231, 'f1-score': 0.9978635717040033, 'support': 10182} weighted_avg {'precision': 0.9978452671922962, 'recall': 0.9978393242977804, 'f1-score': 0.9978399501073051, 'support': 10182}
 
time = 19.01 secondes

Val loss 0.975105778936242 accuracy 0.8895759582519531 macro_avg {'precision': 0.8957427620760136, 'recall': 0.89515355161586, 'f1-score': 0.8938557757460595, 'support': 1132} weighted_avg {'precision': 0.8940092483359533, 'recall': 0.8895759717314488, 'f1-score': 0.8902290953256888, 'support': 1132}
 
----------
Epoch 37/40
time = 425.70 secondes

Train loss 0.00943229364545363 accuracy 0.9978393316268921 macro_avg {'precision': 0.9978402652714896, 'recall': 0.9977902738212254, 'f1-score': 0.9978138306914316, 'support': 10182} weighted_avg {'precision': 0.997841175262175, 'recall': 0.9978393242977804, 'f1-score': 0.997838813092588, 'support': 10182}
 
time = 19.07 secondes

Val loss 0.8825586544512781 accuracy 0.9028268456459045 macro_avg {'precision': 0.9066912895376058, 'recall': 0.9063720007865237, 'f1-score': 0.9053038847563236, 'support': 1132} weighted_avg {'precision': 0.9066068628639302, 'recall': 0.9028268551236749, 'f1-score': 0.9036168425523176, 'support': 1132}
 
----------
Epoch 38/40
time = 426.34 secondes

Train loss 0.008212427005386833 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985669614949311, 'recall': 0.9985539290336503, 'f1-score': 0.9985588856317591, 'support': 10182} weighted_avg {'precision': 0.9985314018322542, 'recall': 0.998526812021214, 'f1-score': 0.9985275159459209, 'support': 10182}
 
time = 18.90 secondes

Val loss 1.0047870648534845 accuracy 0.8957597017288208 macro_avg {'precision': 0.8989015172834132, 'recall': 0.8997662283043093, 'f1-score': 0.8977058688918685, 'support': 1132} weighted_avg {'precision': 0.8988992949578809, 'recall': 0.8957597173144877, 'f1-score': 0.8956337635069176, 'support': 1132}
 
----------
Epoch 39/40
time = 426.30 secondes

Train loss 0.004246219980333042 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990221364868519, 'recall': 0.9990014225863947, 'f1-score': 0.9990107862531905, 'support': 10182} weighted_avg {'precision': 0.9990199885757575, 'recall': 0.9990178746808093, 'f1-score': 0.9990179610584898, 'support': 10182}
 
time = 18.99 secondes

Val loss 0.9655810541983901 accuracy 0.8957597017288208 macro_avg {'precision': 0.8988581660235795, 'recall': 0.8995579643276101, 'f1-score': 0.8979800657565861, 'support': 1132} weighted_avg {'precision': 0.8972290555673637, 'recall': 0.8957597173144877, 'f1-score': 0.8952950919514423, 'support': 1132}
 
----------
Epoch 40/40
time = 426.85 secondes

Train loss 0.002261904084737764 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994090211675507, 'recall': 0.9993959958128634, 'f1-score': 0.9994018590493725, 'support': 10182} weighted_avg {'precision': 0.9994120259254384, 'recall': 0.9994107248084856, 'f1-score': 0.9994107138218524, 'support': 10182}
 
time = 19.03 secondes

Val loss 0.9742311146264142 accuracy 0.8992933034896851 macro_avg {'precision': 0.9021331399349644, 'recall': 0.9021143514647747, 'f1-score': 0.9011006422174637, 'support': 1132} weighted_avg {'precision': 0.9012405242466696, 'recall': 0.8992932862190812, 'f1-score': 0.8991827040177136, 'support': 1132}
 
----------
best_accuracy 0.9028268456459045 best_epoch 37 macro_avg {'precision': 0.9066912895376058, 'recall': 0.9063720007865237, 'f1-score': 0.9053038847563236, 'support': 1132} weighted_avg {'precision': 0.9066068628639302, 'recall': 0.9028268551236749, 'f1-score': 0.9036168425523176, 'support': 1132}

average train time 426.8266421914101

average val time 18.758907002210616
 
time = 119.87 secondes

test_accuracy 0.8300583958625793 macro_avg {'precision': 0.8303379544591627, 'recall': 0.8244955353573701, 'f1-score': 0.8240983181494551, 'support': 7532} weighted_avg {'precision': 0.8371012545924373, 'recall': 0.8300584174190122, 'f1-score': 0.83065317143114, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 73.33 GiB already allocated; 96.62 MiB free; 74.17 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 72.04 GiB already allocated; 318.62 MiB free; 73.95 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 79.21 GiB total capacity; 70.25 GiB already allocated; 566.62 MiB free; 73.71 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 72.00 GiB already allocated; 1006.62 MiB free; 73.28 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_2
----------
Epoch 1/40
time = 689.95 secondes

Train loss 1.0648636397097138 accuracy 0.7029070854187012 macro_avg {'precision': 0.7011784761765527, 'recall': 0.6888957237089472, 'f1-score': 0.6879746866403693, 'support': 10182} weighted_avg {'precision': 0.7121661622260655, 'recall': 0.7029070909448045, 'f1-score': 0.7011805198374493, 'support': 10182}
 
time = 28.53 secondes

Val loss 0.5944061526949976 accuracy 0.8286219239234924 macro_avg {'precision': 0.8403907593100776, 'recall': 0.8186808732339557, 'f1-score': 0.8071948192433973, 'support': 1132} weighted_avg {'precision': 0.8404758544124027, 'recall': 0.8286219081272085, 'f1-score': 0.817153755650542, 'support': 1132}
 
----------
Epoch 2/40
time = 677.25 secondes

Train loss 0.3923913303710041 accuracy 0.8847967386245728 macro_avg {'precision': 0.877454725507589, 'recall': 0.8759333221331561, 'f1-score': 0.8756781359873835, 'support': 10182} weighted_avg {'precision': 0.8837190345907199, 'recall': 0.8847967000589275, 'f1-score': 0.8834618651860512, 'support': 10182}
 
time = 27.89 secondes

Val loss 0.4297343905962689 accuracy 0.8878092169761658 macro_avg {'precision': 0.8909356644516613, 'recall': 0.8848946476291246, 'f1-score': 0.8832463885285147, 'support': 1132} weighted_avg {'precision': 0.893898221994255, 'recall': 0.8878091872791519, 'f1-score': 0.8863322997021555, 'support': 1132}
 
----------
Epoch 3/40
time = 676.24 secondes

Train loss 0.2255007883327687 accuracy 0.9363583326339722 macro_avg {'precision': 0.933138816466658, 'recall': 0.9326930439598973, 'f1-score': 0.9328081328954847, 'support': 10182} weighted_avg {'precision': 0.9367353408118962, 'recall': 0.9363582793164408, 'f1-score': 0.9364425072731885, 'support': 10182}
 
time = 27.41 secondes

Val loss 0.5017609025653399 accuracy 0.8851590156555176 macro_avg {'precision': 0.8909737334370218, 'recall': 0.8888125079406736, 'f1-score': 0.8838399785874144, 'support': 1132} weighted_avg {'precision': 0.8948380275214426, 'recall': 0.8851590106007067, 'f1-score': 0.8833920593582453, 'support': 1132}
 
----------
Epoch 4/40
time = 673.99 secondes

Train loss 0.17995120184729974 accuracy 0.9533490538597107 macro_avg {'precision': 0.9516245248484004, 'recall': 0.9513785199253764, 'f1-score': 0.9514563957108418, 'support': 10182} weighted_avg {'precision': 0.9534831099316328, 'recall': 0.9533490473384404, 'f1-score': 0.9533710863857153, 'support': 10182}
 
time = 27.57 secondes

Val loss 0.4457086962713322 accuracy 0.9072438478469849 macro_avg {'precision': 0.909498653620432, 'recall': 0.910128074030822, 'f1-score': 0.9078904178832925, 'support': 1132} weighted_avg {'precision': 0.9129032598469732, 'recall': 0.907243816254417, 'f1-score': 0.9081906706552095, 'support': 1132}
 
----------
Epoch 5/40
time = 689.29 secondes

Train loss 0.15065501185698402 accuracy 0.9607149958610535 macro_avg {'precision': 0.9595333950135109, 'recall': 0.9596436360531433, 'f1-score': 0.9595368717240443, 'support': 10182} weighted_avg {'precision': 0.960944530747199, 'recall': 0.9607149872323708, 'f1-score': 0.9607822916595203, 'support': 10182}
 
time = 27.97 secondes

Val loss 0.6421103626096123 accuracy 0.8851590156555176 macro_avg {'precision': 0.895872338532358, 'recall': 0.8889142262372818, 'f1-score': 0.8880039947460097, 'support': 1132} weighted_avg {'precision': 0.895581227081082, 'recall': 0.8851590106007067, 'f1-score': 0.8856563794965019, 'support': 1132}
 
----------
Epoch 6/40
time = 678.99 secondes

Train loss 0.1337366630575434 accuracy 0.967197060585022 macro_avg {'precision': 0.9665892639759651, 'recall': 0.9663698522952842, 'f1-score': 0.9664557137904515, 'support': 10182} weighted_avg {'precision': 0.9672817479885735, 'recall': 0.9671970143390297, 'f1-score': 0.9672149366987187, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.5651973541727631 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116147655684672, 'recall': 0.904817486523457, 'f1-score': 0.9054242887139864, 'support': 1132} weighted_avg {'precision': 0.9106131943346604, 'recall': 0.9054770318021201, 'f1-score': 0.9053814872378658, 'support': 1132}
 
----------
Epoch 7/40
time = 678.40 secondes

Train loss 0.12546591963447204 accuracy 0.9707326889038086 macro_avg {'precision': 0.9696318573163593, 'recall': 0.9695742465791491, 'f1-score': 0.9695722468076766, 'support': 10182} weighted_avg {'precision': 0.9708045650273542, 'recall': 0.9707326654881163, 'f1-score': 0.9707373293961113, 'support': 10182}
 
time = 28.53 secondes

Val loss 0.6232601411367642 accuracy 0.8966431021690369 macro_avg {'precision': 0.9021039660937387, 'recall': 0.894391623778378, 'f1-score': 0.893286647378495, 'support': 1132} weighted_avg {'precision': 0.9008673021644747, 'recall': 0.8966431095406361, 'f1-score': 0.8941434372795116, 'support': 1132}
 
----------
Epoch 8/40
time = 679.09 secondes

Train loss 0.11500833312890549 accuracy 0.9745630025863647 macro_avg {'precision': 0.973758158455278, 'recall': 0.973649932534628, 'f1-score': 0.9736499692689463, 'support': 10182} weighted_avg {'precision': 0.9746880956584338, 'recall': 0.9745629542329601, 'f1-score': 0.9745712249859729, 'support': 10182}
 
time = 28.09 secondes

Val loss 0.6538066652412428 accuracy 0.898409903049469 macro_avg {'precision': 0.9032010245856963, 'recall': 0.8997767358236033, 'f1-score': 0.8984549679001969, 'support': 1132} weighted_avg {'precision': 0.9040950382000954, 'recall': 0.8984098939929329, 'f1-score': 0.8980228872442687, 'support': 1132}
 
----------
Epoch 9/40
time = 679.34 secondes

Train loss 0.10809380609274029 accuracy 0.9760361909866333 macro_avg {'precision': 0.975400321638985, 'recall': 0.9755657325093239, 'f1-score': 0.9754542131920158, 'support': 10182} weighted_avg {'precision': 0.9760641591229584, 'recall': 0.9760361422117462, 'f1-score': 0.9760245665542596, 'support': 10182}
 
time = 28.55 secondes

Val loss 0.6726221283487844 accuracy 0.8992933034896851 macro_avg {'precision': 0.9029044320051683, 'recall': 0.9007506457614015, 'f1-score': 0.8987814054334148, 'support': 1132} weighted_avg {'precision': 0.9051025635811462, 'recall': 0.8992932862190812, 'f1-score': 0.8990838639239018, 'support': 1132}
 
----------
Epoch 10/40
time = 677.53 secondes

Train loss 0.11171707793383266 accuracy 0.9760361909866333 macro_avg {'precision': 0.9756776069172026, 'recall': 0.9756097349852386, 'f1-score': 0.9756210926614284, 'support': 10182} weighted_avg {'precision': 0.9760461309532492, 'recall': 0.9760361422117462, 'f1-score': 0.9760185231057372, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.485126080717006 accuracy 0.9249116778373718 macro_avg {'precision': 0.9252584585473258, 'recall': 0.9260725503120598, 'f1-score': 0.9251255648610066, 'support': 1132} weighted_avg {'precision': 0.9263473335376424, 'recall': 0.9249116607773852, 'f1-score': 0.9251312912208374, 'support': 1132}
 
----------
Epoch 11/40
time = 678.55 secondes

Train loss 0.09127712438789122 accuracy 0.980553925037384 macro_avg {'precision': 0.9799932209349818, 'recall': 0.980105403852526, 'f1-score': 0.9800316880361202, 'support': 10182} weighted_avg {'precision': 0.9806075006246813, 'recall': 0.9805539186800236, 'f1-score': 0.980563519280867, 'support': 10182}
 
time = 28.42 secondes

Val loss 0.7193589428979592 accuracy 0.898409903049469 macro_avg {'precision': 0.9068626300279703, 'recall': 0.9027874791642757, 'f1-score': 0.9003866197464004, 'support': 1132} weighted_avg {'precision': 0.9057758988416492, 'recall': 0.8984098939929329, 'f1-score': 0.8970528256072564, 'support': 1132}
 
----------
Epoch 12/40
time = 679.06 secondes

Train loss 0.0939806016084184 accuracy 0.980455756187439 macro_avg {'precision': 0.9800643102496144, 'recall': 0.9799538088668204, 'f1-score': 0.9799920196171458, 'support': 10182} weighted_avg {'precision': 0.9804969063462616, 'recall': 0.9804557061481045, 'f1-score': 0.9804589140933532, 'support': 10182}
 
time = 23.16 secondes

Val loss 0.7151397453142662 accuracy 0.9090105891227722 macro_avg {'precision': 0.9127627041418942, 'recall': 0.9120094859399834, 'f1-score': 0.909514057215068, 'support': 1132} weighted_avg {'precision': 0.9167135913667567, 'recall': 0.9090106007067138, 'f1-score': 0.909807654306905, 'support': 1132}
 
----------
Epoch 13/40
time = 679.56 secondes

Train loss 0.09801928723980988 accuracy 0.9810450077056885 macro_avg {'precision': 0.9810174748292406, 'recall': 0.9808918955668622, 'f1-score': 0.9809366020900911, 'support': 10182} weighted_avg {'precision': 0.9811085157326482, 'recall': 0.9810449813396189, 'f1-score': 0.9810582562885013, 'support': 10182}
 
time = 28.23 secondes

Val loss 0.6729797816127834 accuracy 0.9196113348007202 macro_avg {'precision': 0.9269560780298993, 'recall': 0.9166600547167937, 'f1-score': 0.9184911168744717, 'support': 1132} weighted_avg {'precision': 0.92628146411116, 'recall': 0.9196113074204947, 'f1-score': 0.9199546684598544, 'support': 1132}
 
----------
Epoch 14/40
time = 679.82 secondes

Train loss 0.08948837547288471 accuracy 0.9834021329879761 macro_avg {'precision': 0.9831847455740415, 'recall': 0.9829615180323934, 'f1-score': 0.9830576254866564, 'support': 10182} weighted_avg {'precision': 0.9834211065490392, 'recall': 0.9834020821056767, 'f1-score': 0.9833964902264297, 'support': 10182}
 
time = 28.09 secondes

Val loss 0.6134303797139502 accuracy 0.916961133480072 macro_avg {'precision': 0.9161903029460159, 'recall': 0.9190987813372891, 'f1-score': 0.9167080890199457, 'support': 1132} weighted_avg {'precision': 0.9175305009728836, 'recall': 0.9169611307420494, 'f1-score': 0.9163374633281215, 'support': 1132}
 
----------
Epoch 15/40
time = 680.56 secondes

Train loss 0.09384367837376384 accuracy 0.9824199676513672 macro_avg {'precision': 0.9824325277099109, 'recall': 0.9821987255545837, 'f1-score': 0.9822826364043793, 'support': 10182} weighted_avg {'precision': 0.982481410794599, 'recall': 0.982419956786486, 'f1-score': 0.9824169331041297, 'support': 10182}
 
time = 28.39 secondes

Val loss 0.7773786429367044 accuracy 0.9010601043701172 macro_avg {'precision': 0.9070996720907416, 'recall': 0.9027617683669646, 'f1-score': 0.9019056628313932, 'support': 1132} weighted_avg {'precision': 0.9076476162133977, 'recall': 0.901060070671378, 'f1-score': 0.9012523598327445, 'support': 1132}
 
----------
Epoch 16/40
time = 678.19 secondes

Train loss 0.0794803458437522 accuracy 0.9843842387199402 macro_avg {'precision': 0.9840698632856976, 'recall': 0.9839957545366744, 'f1-score': 0.9840204080896104, 'support': 10182} weighted_avg {'precision': 0.984414334987115, 'recall': 0.9843842074248674, 'f1-score': 0.9843879041347853, 'support': 10182}
 
time = 27.96 secondes

Val loss 0.6479874177770091 accuracy 0.9090105891227722 macro_avg {'precision': 0.9168563410713227, 'recall': 0.9104937269765617, 'f1-score': 0.9112369452767094, 'support': 1132} weighted_avg {'precision': 0.9167337549316272, 'recall': 0.9090106007067138, 'f1-score': 0.9103752927085841, 'support': 1132}
 
----------
Epoch 17/40
time = 677.32 secondes

Train loss 0.07316496025141904 accuracy 0.9861520528793335 macro_avg {'precision': 0.9856568949372502, 'recall': 0.9855399548737287, 'f1-score': 0.9855872940019854, 'support': 10182} weighted_avg {'precision': 0.9861396678936386, 'recall': 0.9861520329994107, 'f1-score': 0.9861353977023423, 'support': 10182}
 
time = 28.12 secondes

Val loss 0.7175711176101353 accuracy 0.9072438478469849 macro_avg {'precision': 0.9121688953437485, 'recall': 0.9092541353176016, 'f1-score': 0.9089475128843784, 'support': 1132} weighted_avg {'precision': 0.9111644581259689, 'recall': 0.907243816254417, 'f1-score': 0.9072473211806718, 'support': 1132}
 
----------
Epoch 18/40
time = 677.14 secondes

Train loss 0.0652009693033076 accuracy 0.987625241279602 macro_avg {'precision': 0.9872784287845591, 'recall': 0.987135461380318, 'f1-score': 0.9872012210392151, 'support': 10182} weighted_avg {'precision': 0.9876240345073292, 'recall': 0.9876252209781968, 'f1-score': 0.9876194507955603, 'support': 10182}
 
time = 28.11 secondes

Val loss 0.671513566831545 accuracy 0.9090105891227722 macro_avg {'precision': 0.9119657952212534, 'recall': 0.9106435889312555, 'f1-score': 0.9103550007153313, 'support': 1132} weighted_avg {'precision': 0.9126961901842592, 'recall': 0.9090106007067138, 'f1-score': 0.9098745452508873, 'support': 1132}
 
----------
Epoch 19/40
time = 679.41 secondes

Train loss 0.05456547916037951 accuracy 0.9891966581344604 macro_avg {'precision': 0.9883782808742471, 'recall': 0.9882126761245038, 'f1-score': 0.9882759313943449, 'support': 10182} weighted_avg {'precision': 0.9892325569183982, 'recall': 0.989196621488902, 'f1-score': 0.9891950307811724, 'support': 10182}
 
time = 28.18 secondes

Val loss 0.7175183505029745 accuracy 0.9116607904434204 macro_avg {'precision': 0.9207975104580701, 'recall': 0.9104174267336314, 'f1-score': 0.9128947360655755, 'support': 1132} weighted_avg {'precision': 0.9166067395961752, 'recall': 0.911660777385159, 'f1-score': 0.9114610332492935, 'support': 1132}
 
----------
Epoch 20/40
time = 678.11 secondes

Train loss 0.061901185965602554 accuracy 0.9886073470115662 macro_avg {'precision': 0.9878116135560602, 'recall': 0.988198287759616, 'f1-score': 0.9879907636080537, 'support': 10182} weighted_avg {'precision': 0.9886366000265374, 'recall': 0.9886073462973876, 'f1-score': 0.9886098636313682, 'support': 10182}
 
time = 28.12 secondes

Val loss 0.7314097603575903 accuracy 0.9134275913238525 macro_avg {'precision': 0.9165785422906332, 'recall': 0.914084455785123, 'f1-score': 0.9134136170958549, 'support': 1132} weighted_avg {'precision': 0.9175154753961594, 'recall': 0.9134275618374559, 'f1-score': 0.9136807591034821, 'support': 1132}
 
----------
Epoch 21/40
time = 678.41 secondes

Train loss 0.054353855628257265 accuracy 0.9901787638664246 macro_avg {'precision': 0.9902167678123119, 'recall': 0.9900944830009666, 'f1-score': 0.9901493505434024, 'support': 10182} weighted_avg {'precision': 0.990209054354457, 'recall': 0.9901787468080927, 'f1-score': 0.9901876240100392, 'support': 10182}
 
time = 28.07 secondes

Val loss 0.7552122951251157 accuracy 0.9107773900032043 macro_avg {'precision': 0.9151794567853528, 'recall': 0.9126758780971997, 'f1-score': 0.9124130286287138, 'support': 1132} weighted_avg {'precision': 0.9145444333957059, 'recall': 0.9107773851590106, 'f1-score': 0.911090971022533, 'support': 1132}
 
----------
Epoch 22/40
time = 678.24 secondes

Train loss 0.06367194060062552 accuracy 0.9885091781616211 macro_avg {'precision': 0.9881704399847117, 'recall': 0.9887012992476301, 'f1-score': 0.9884043603327125, 'support': 10182} weighted_avg {'precision': 0.9885764333643812, 'recall': 0.9885091337654685, 'f1-score': 0.9885165405984639, 'support': 10182}
 
time = 28.06 secondes

Val loss 0.7499723480136132 accuracy 0.9090105891227722 macro_avg {'precision': 0.9144878621063801, 'recall': 0.9101998245341486, 'f1-score': 0.9110239183653311, 'support': 1132} weighted_avg {'precision': 0.914760241818829, 'recall': 0.9090106007067138, 'f1-score': 0.9105367570179281, 'support': 1132}
 
----------
Epoch 23/40
time = 598.82 secondes

Train loss 0.057264648153911225 accuracy 0.9893930554389954 macro_avg {'precision': 0.9892617955095802, 'recall': 0.9892371328300756, 'f1-score': 0.98923164950552, 'support': 10182} weighted_avg {'precision': 0.9894201361354653, 'recall': 0.9893930465527401, 'f1-score': 0.9893883881956556, 'support': 10182}
 
time = 18.15 secondes

Val loss 0.6979011791067741 accuracy 0.9151943325996399 macro_avg {'precision': 0.9187930909483898, 'recall': 0.9163989579631366, 'f1-score': 0.9165672392602744, 'support': 1132} weighted_avg {'precision': 0.9179966024329519, 'recall': 0.9151943462897526, 'f1-score': 0.9156264149995865, 'support': 1132}
 
----------
Epoch 24/40
time = 574.65 secondes

Train loss 0.06842237078276833 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881245546604356, 'recall': 0.9880673993935414, 'f1-score': 0.9880861580429035, 'support': 10182} weighted_avg {'precision': 0.988613820692359, 'recall': 0.9886073462973876, 'f1-score': 0.9886011962789569, 'support': 10182}
 
time = 23.06 secondes

Val loss 0.6583629628379205 accuracy 0.9213780760765076 macro_avg {'precision': 0.92438288472696, 'recall': 0.923571676603893, 'f1-score': 0.9226161194956868, 'support': 1132} weighted_avg {'precision': 0.9250527394457707, 'recall': 0.9213780918727915, 'f1-score': 0.9218703299897453, 'support': 1132}
 
----------
Epoch 25/40
time = 576.80 secondes

Train loss 0.04682012442327152 accuracy 0.9907680749893188 macro_avg {'precision': 0.9904557747334405, 'recall': 0.99069437021588, 'f1-score': 0.9905557911209696, 'support': 10182} weighted_avg {'precision': 0.9907991986413701, 'recall': 0.9907680219996071, 'f1-score': 0.9907676518331444, 'support': 10182}
 
time = 23.00 secondes

Val loss 0.7499318534053754 accuracy 0.9054770469665527 macro_avg {'precision': 0.9107943377269606, 'recall': 0.9104876273653311, 'f1-score': 0.9087806282479794, 'support': 1132} weighted_avg {'precision': 0.9106039692109619, 'recall': 0.9054770318021201, 'f1-score': 0.9060365700564128, 'support': 1132}
 
----------
Epoch 26/40
time = 576.24 secondes

Train loss 0.049328991466175254 accuracy 0.9916519522666931 macro_avg {'precision': 0.9915544187438023, 'recall': 0.9916841768447119, 'f1-score': 0.9916118877150826, 'support': 10182} weighted_avg {'precision': 0.9916624714597965, 'recall': 0.9916519347868789, 'f1-score': 0.991649786030057, 'support': 10182}
 
time = 22.96 secondes

Val loss 0.8515955820309923 accuracy 0.8975265026092529 macro_avg {'precision': 0.9064868883018239, 'recall': 0.9000609254082208, 'f1-score': 0.9001858368013623, 'support': 1132} weighted_avg {'precision': 0.9052772179663046, 'recall': 0.8975265017667845, 'f1-score': 0.8983094457610403, 'support': 1132}
 
----------
Epoch 27/40
time = 574.81 secondes

Train loss 0.0517714156308295 accuracy 0.9915537238121033 macro_avg {'precision': 0.9918519347454744, 'recall': 0.9917350403386134, 'f1-score': 0.9917651499271317, 'support': 10182} weighted_avg {'precision': 0.9915897922866741, 'recall': 0.9915537222549597, 'f1-score': 0.9915426037377291, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.7531595680968525 accuracy 0.9125441908836365 macro_avg {'precision': 0.9165873859019051, 'recall': 0.9152243949746133, 'f1-score': 0.9146677106405955, 'support': 1132} weighted_avg {'precision': 0.9148699350497063, 'recall': 0.9125441696113075, 'f1-score': 0.9124470772160663, 'support': 1132}
 
----------
Epoch 28/40
time = 577.18 secondes

Train loss 0.03385872828021293 accuracy 0.9928305149078369 macro_avg {'precision': 0.9927954076106676, 'recall': 0.9928954843034207, 'f1-score': 0.9928358280154217, 'support': 10182} weighted_avg {'precision': 0.992842080719854, 'recall': 0.9928304851699077, 'f1-score': 0.9928265244558131, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.6918095506137011 accuracy 0.9116607904434204 macro_avg {'precision': 0.9160674583712719, 'recall': 0.9154466700171012, 'f1-score': 0.9134833935275696, 'support': 1132} weighted_avg {'precision': 0.9199854213242903, 'recall': 0.911660777385159, 'f1-score': 0.9136399354766995, 'support': 1132}
 
----------
Epoch 29/40
time = 577.02 secondes

Train loss 0.03569428820578415 accuracy 0.993812620639801 macro_avg {'precision': 0.9936287490232351, 'recall': 0.9937711249122412, 'f1-score': 0.9936896486194214, 'support': 10182} weighted_avg {'precision': 0.9938391743543115, 'recall': 0.9938126104890984, 'f1-score': 0.9938157320479074, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.6827330803659004 accuracy 0.9196113348007202 macro_avg {'precision': 0.9218130209833028, 'recall': 0.9208911977723917, 'f1-score': 0.9209537619215027, 'support': 1132} weighted_avg {'precision': 0.92036793932817, 'recall': 0.9196113074204947, 'f1-score': 0.919574893574247, 'support': 1132}
 
----------
Epoch 30/40
time = 577.40 secondes

Train loss 0.022579545892580745 accuracy 0.9949911832809448 macro_avg {'precision': 0.9948492663055737, 'recall': 0.9947488784095002, 'f1-score': 0.9947918675325086, 'support': 10182} weighted_avg {'precision': 0.9950017729960694, 'recall': 0.9949911608721272, 'f1-score': 0.9949894387110673, 'support': 10182}
 
time = 22.26 secondes

Val loss 0.7605256792997698 accuracy 0.9134275913238525 macro_avg {'precision': 0.9194234218743714, 'recall': 0.9155627053289278, 'f1-score': 0.9161893842714568, 'support': 1132} weighted_avg {'precision': 0.9177389612457473, 'recall': 0.9134275618374559, 'f1-score': 0.9141122293935133, 'support': 1132}
 
----------
Epoch 31/40
time = 576.78 secondes

Train loss 0.029525759259922207 accuracy 0.994892954826355 macro_avg {'precision': 0.9947463470090296, 'recall': 0.9943300293789628, 'f1-score': 0.9945247110562472, 'support': 10182} weighted_avg {'precision': 0.9949231203033001, 'recall': 0.9948929483402082, 'f1-score': 0.99489662381005, 'support': 10182}
 
time = 23.40 secondes

Val loss 0.7419200460825149 accuracy 0.9116607904434204 macro_avg {'precision': 0.9136073479969417, 'recall': 0.9162135166465217, 'f1-score': 0.9128714398363199, 'support': 1132} weighted_avg {'precision': 0.918781776346413, 'recall': 0.911660777385159, 'f1-score': 0.9132602131443638, 'support': 1132}
 
----------
Epoch 32/40
time = 576.88 secondes

Train loss 0.022615470910005146 accuracy 0.9955804944038391 macro_avg {'precision': 0.995469066247146, 'recall': 0.9954943440664161, 'f1-score': 0.9954737855479916, 'support': 10182} weighted_avg {'precision': 0.9955974776883576, 'recall': 0.9955804360636418, 'f1-score': 0.9955808550752876, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.749269838988997 accuracy 0.916077733039856 macro_avg {'precision': 0.9218911028959157, 'recall': 0.9190524191973302, 'f1-score': 0.9186425283983484, 'support': 1132} weighted_avg {'precision': 0.920088842107591, 'recall': 0.916077738515901, 'f1-score': 0.916004658256601, 'support': 1132}
 
----------
Epoch 33/40
time = 573.78 secondes

Train loss 0.020340808968320967 accuracy 0.9964643716812134 macro_avg {'precision': 0.9962979677260769, 'recall': 0.9964143039826234, 'f1-score': 0.9963505360481051, 'support': 10182} weighted_avg {'precision': 0.9964739609311525, 'recall': 0.9964643488509134, 'f1-score': 0.996463512016655, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.7350900558177131 accuracy 0.9151943325996399 macro_avg {'precision': 0.9173868902975506, 'recall': 0.9184319382602221, 'f1-score': 0.9167857741785653, 'support': 1132} weighted_avg {'precision': 0.9188815067745779, 'recall': 0.9151943462897526, 'f1-score': 0.9158744417952057, 'support': 1132}
 
----------
Epoch 34/40
time = 573.36 secondes

Train loss 0.018005855267143756 accuracy 0.9967589974403381 macro_avg {'precision': 0.996662991865884, 'recall': 0.996653305017527, 'f1-score': 0.996654236410986, 'support': 10182} weighted_avg {'precision': 0.996766945749664, 'recall': 0.9967589864466706, 'f1-score': 0.9967589964265415, 'support': 10182}
 
time = 23.05 secondes

Val loss 0.6948523349332851 accuracy 0.9213780760765076 macro_avg {'precision': 0.9245932861159808, 'recall': 0.9231347453012134, 'f1-score': 0.9228615229151028, 'support': 1132} weighted_avg {'precision': 0.9241203363915182, 'recall': 0.9213780918727915, 'f1-score': 0.9216643881932206, 'support': 1132}
 
----------
Epoch 35/40
time = 574.28 secondes

Train loss 0.019400686105846363 accuracy 0.996857225894928 macro_avg {'precision': 0.9969005178972148, 'recall': 0.9969189837602285, 'f1-score': 0.9969063192880212, 'support': 10182} weighted_avg {'precision': 0.9968620158702369, 'recall': 0.9968571989785897, 'f1-score': 0.9968560293057103, 'support': 10182}
 
time = 21.07 secondes

Val loss 0.768560814370624 accuracy 0.9178445339202881 macro_avg {'precision': 0.9222224806867949, 'recall': 0.9213830633684484, 'f1-score': 0.9200304014936066, 'support': 1132} weighted_avg {'precision': 0.9228816731810083, 'recall': 0.9178445229681979, 'f1-score': 0.9184570557562751, 'support': 1132}
 
----------
Epoch 36/40
time = 572.79 secondes

Train loss 0.01697044402216459 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970103294425551, 'recall': 0.9971215238079795, 'f1-score': 0.9970602387599368, 'support': 10182} weighted_avg {'precision': 0.9970671984370202, 'recall': 0.9970536240424278, 'f1-score': 0.9970546681820002, 'support': 10182}
 
time = 23.04 secondes

Val loss 0.6933600196535082 accuracy 0.9204947352409363 macro_avg {'precision': 0.9265402753374626, 'recall': 0.9229979630426384, 'f1-score': 0.9234658813627477, 'support': 1132} weighted_avg {'precision': 0.9240388138493385, 'recall': 0.9204946996466431, 'f1-score': 0.9208837140847499, 'support': 1132}
 
----------
Epoch 37/40
time = 574.16 secondes

Train loss 0.01202016773688337 accuracy 0.9980357885360718 macro_avg {'precision': 0.9980353719856687, 'recall': 0.9980368880127314, 'f1-score': 0.9980339570244509, 'support': 10182} weighted_avg {'precision': 0.99803801368565, 'recall': 0.9980357493616185, 'f1-score': 0.9980346858907279, 'support': 10182}
 
time = 22.06 secondes

Val loss 0.6790642933365362 accuracy 0.9231448769569397 macro_avg {'precision': 0.9271279095113709, 'recall': 0.9256551001819895, 'f1-score': 0.9255013641597433, 'support': 1132} weighted_avg {'precision': 0.925610220379282, 'recall': 0.9231448763250883, 'f1-score': 0.9234237070167496, 'support': 1132}
 
----------
Epoch 38/40
time = 575.07 secondes

Train loss 0.006404565581446723 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986649182664651, 'recall': 0.9986675968291501, 'f1-score': 0.9986660723923491, 'support': 10182} weighted_avg {'precision': 0.9986250181387363, 'recall': 0.998625024553133, 'f1-score': 0.998624832783119, 'support': 10182}
 
time = 22.98 secondes

Val loss 0.7174773767153607 accuracy 0.9196113348007202 macro_avg {'precision': 0.9249212056455465, 'recall': 0.9216959150327162, 'f1-score': 0.9224262241490784, 'support': 1132} weighted_avg {'precision': 0.9225727238910092, 'recall': 0.9196113074204947, 'f1-score': 0.9201292126106125, 'support': 1132}
 
----------
Epoch 39/40
time = 577.44 secondes

Train loss 0.006736417593616591 accuracy 0.9987232685089111 macro_avg {'precision': 0.9987730511221006, 'recall': 0.9987300913460364, 'f1-score': 0.9987507130267858, 'support': 10182} weighted_avg {'precision': 0.9987249203018544, 'recall': 0.9987232370850521, 'f1-score': 0.9987232196014509, 'support': 10182}
 
time = 23.12 secondes

Val loss 0.7458333123439984 accuracy 0.9196113348007202 macro_avg {'precision': 0.9229628382901852, 'recall': 0.9212910922538431, 'f1-score': 0.9211198424990619, 'support': 1132} weighted_avg {'precision': 0.9216257294515989, 'recall': 0.9196113074204947, 'f1-score': 0.9195337970123669, 'support': 1132}
 
----------
Epoch 40/40
time = 573.91 secondes

Train loss 0.0030785780706367575 accuracy 0.9994107484817505 macro_avg {'precision': 0.999434812358697, 'recall': 0.9994288822000879, 'f1-score': 0.9994313963298971, 'support': 10182} weighted_avg {'precision': 0.9994114594094216, 'recall': 0.9994107248084856, 'f1-score': 0.9994106262127407, 'support': 10182}
 
time = 22.81 secondes

Val loss 0.7324529361520702 accuracy 0.9187279343605042 macro_avg {'precision': 0.9240401268485614, 'recall': 0.9199129295574571, 'f1-score': 0.9208257644681387, 'support': 1132} weighted_avg {'precision': 0.921774326295631, 'recall': 0.9187279151943463, 'f1-score': 0.9190190839288818, 'support': 1132}
 
----------
best_accuracy 0.9249116778373718 best_epoch 10 macro_avg {'precision': 0.9252584585473258, 'recall': 0.9260725503120598, 'f1-score': 0.9251255648610066, 'support': 1132} weighted_avg {'precision': 0.9263473335376424, 'recall': 0.9249116607773852, 'f1-score': 0.9251312912208374, 'support': 1132}

average train time 633.1461006164551

average val time 25.49382752776146
 
time = 149.97 secondes

test_accuracy 0.8469197750091553 macro_avg {'precision': 0.8459519244672362, 'recall': 0.8408163362472422, 'f1-score': 0.8406223261245171, 'support': 7532} weighted_avg {'precision': 0.8527882872613329, 'recall': 0.8469198088157196, 'f1-score': 0.8475454026582592, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_2
----------
Epoch 1/40
time = 752.61 secondes

Train loss 1.0864784701067949 accuracy 0.6898448467254639 macro_avg {'precision': 0.688709638746441, 'recall': 0.6757629256844186, 'f1-score': 0.6723254043802215, 'support': 10182} weighted_avg {'precision': 0.6961512613496823, 'recall': 0.6898448241995678, 'f1-score': 0.6848255101616522, 'support': 10182}
 
time = 27.18 secondes

Val loss 0.5516903954492488 accuracy 0.8401060104370117 macro_avg {'precision': 0.8602963372117568, 'recall': 0.8301542514879177, 'f1-score': 0.8177621073096436, 'support': 1132} weighted_avg {'precision': 0.8529001544701343, 'recall': 0.8401060070671378, 'f1-score': 0.8260151045849802, 'support': 1132}
 
----------
Epoch 2/40
time = 741.28 secondes

Train loss 0.38870213574655293 accuracy 0.8860734701156616 macro_avg {'precision': 0.878744130257, 'recall': 0.8776528171193027, 'f1-score': 0.8775222691559875, 'support': 10182} weighted_avg {'precision': 0.8847692488414601, 'recall': 0.8860734629738755, 'f1-score': 0.8848926752878391, 'support': 10182}
 
time = 26.54 secondes

Val loss 0.4479339871503098 accuracy 0.879858672618866 macro_avg {'precision': 0.8838666850911634, 'recall': 0.877483730786801, 'f1-score': 0.8729286441187991, 'support': 1132} weighted_avg {'precision': 0.8837110663469817, 'recall': 0.8798586572438163, 'f1-score': 0.8741908073346033, 'support': 1132}
 
----------
Epoch 3/40
time = 738.28 secondes

Train loss 0.23009972864823355 accuracy 0.9365547299385071 macro_avg {'precision': 0.9334939704535842, 'recall': 0.9332707371575678, 'f1-score': 0.9332305028704431, 'support': 10182} weighted_avg {'precision': 0.9367047811888429, 'recall': 0.9365547043802789, 'f1-score': 0.9364860519317351, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.5927967406402697 accuracy 0.8727915287017822 macro_avg {'precision': 0.8757679926746809, 'recall': 0.8739917032682285, 'f1-score': 0.8704150977701992, 'support': 1132} weighted_avg {'precision': 0.8812959875857554, 'recall': 0.872791519434629, 'f1-score': 0.8720450444525198, 'support': 1132}
 
----------
Epoch 4/40
time = 738.95 secondes

Train loss 0.1929792137845789 accuracy 0.9498134255409241 macro_avg {'precision': 0.9483548167022727, 'recall': 0.9477762859636124, 'f1-score': 0.9480004289110591, 'support': 10182} weighted_avg {'precision': 0.9498167301608033, 'recall': 0.9498133961893538, 'f1-score': 0.949752606036593, 'support': 10182}
 
time = 26.37 secondes

Val loss 0.47181424146360706 accuracy 0.9054770469665527 macro_avg {'precision': 0.907260821950415, 'recall': 0.9015793086885786, 'f1-score': 0.9030195438776001, 'support': 1132} weighted_avg {'precision': 0.9077826818610277, 'recall': 0.9054770318021201, 'f1-score': 0.9053163187710142, 'support': 1132}
 
----------
Epoch 5/40
time = 739.24 secondes

Train loss 0.16577308091519216 accuracy 0.9604203701019287 macro_avg {'precision': 0.9595127278581407, 'recall': 0.9590746674613702, 'f1-score': 0.9592131523088578, 'support': 10182} weighted_avg {'precision': 0.9606249928331574, 'recall': 0.9604203496366136, 'f1-score': 0.9604405941677476, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.5521321361917267 accuracy 0.8957597017288208 macro_avg {'precision': 0.9045827990693514, 'recall': 0.8934755375325713, 'f1-score': 0.8956907579555772, 'support': 1132} weighted_avg {'precision': 0.9024105487863646, 'recall': 0.8957597173144877, 'f1-score': 0.8958663440840913, 'support': 1132}
 
----------
Epoch 6/40
time = 739.07 secondes

Train loss 0.16285113811553595 accuracy 0.9611078500747681 macro_avg {'precision': 0.9596491672662113, 'recall': 0.9597758391191364, 'f1-score': 0.9596591181969254, 'support': 10182} weighted_avg {'precision': 0.9612975122935965, 'recall': 0.9611078373600471, 'f1-score': 0.9611573115914399, 'support': 10182}
 
time = 21.66 secondes

Val loss 0.6608560504121247 accuracy 0.8922261595726013 macro_avg {'precision': 0.9022586792211623, 'recall': 0.8900645312441269, 'f1-score': 0.8920941824406908, 'support': 1132} weighted_avg {'precision': 0.9016503100283775, 'recall': 0.892226148409894, 'f1-score': 0.8928749484429125, 'support': 1132}
 
----------
Epoch 7/40
time = 739.20 secondes

Train loss 0.13606278022226337 accuracy 0.9700452089309692 macro_avg {'precision': 0.9685610768840821, 'recall': 0.9687084522047641, 'f1-score': 0.9685713497414117, 'support': 10182} weighted_avg {'precision': 0.9702731252577695, 'recall': 0.9700451777646828, 'f1-score': 0.970102839183492, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6909955107552839 accuracy 0.8957597017288208 macro_avg {'precision': 0.9046949006706807, 'recall': 0.8964246931939244, 'f1-score': 0.8974611968994581, 'support': 1132} weighted_avg {'precision': 0.902108206001251, 'recall': 0.8957597173144877, 'f1-score': 0.8956796121842594, 'support': 1132}
 
----------
Epoch 8/40
time = 737.12 secondes

Train loss 0.13098238633866635 accuracy 0.972304105758667 macro_avg {'precision': 0.9716171905482854, 'recall': 0.9716222614254333, 'f1-score': 0.9715636039422171, 'support': 10182} weighted_avg {'precision': 0.9724909522715653, 'recall': 0.9723040659988215, 'f1-score': 0.9723435438191882, 'support': 10182}
 
time = 26.46 secondes

Val loss 0.5717095155088546 accuracy 0.9143109321594238 macro_avg {'precision': 0.918106180204958, 'recall': 0.9165550082134937, 'f1-score': 0.9153714908498192, 'support': 1132} weighted_avg {'precision': 0.9183570890429122, 'recall': 0.9143109540636042, 'f1-score': 0.9141911016892242, 'support': 1132}
 
----------
Epoch 9/40
time = 738.73 secondes

Train loss 0.12698343873306892 accuracy 0.9722058773040771 macro_avg {'precision': 0.9712853397620588, 'recall': 0.9711904520727803, 'f1-score': 0.9712081141996333, 'support': 10182} weighted_avg {'precision': 0.9722633591664649, 'recall': 0.9722058534669024, 'f1-score': 0.9722069467902626, 'support': 10182}
 
time = 26.47 secondes

Val loss 0.6018765576451879 accuracy 0.9090105891227722 macro_avg {'precision': 0.9142349754802298, 'recall': 0.9084778561477576, 'f1-score': 0.90986360458337, 'support': 1132} weighted_avg {'precision': 0.912624092716338, 'recall': 0.9090106007067138, 'f1-score': 0.909130456677194, 'support': 1132}
 
----------
Epoch 10/40
time = 737.00 secondes

Train loss 0.1263305998043712 accuracy 0.9755451083183289 macro_avg {'precision': 0.9753353703668705, 'recall': 0.9756025355400662, 'f1-score': 0.9754431406784377, 'support': 10182} weighted_avg {'precision': 0.9755816094253635, 'recall': 0.9755450795521509, 'f1-score': 0.9755391568332448, 'support': 10182}
 
time = 26.33 secondes

Val loss 0.7000068480179245 accuracy 0.898409903049469 macro_avg {'precision': 0.9078023373977014, 'recall': 0.9010118054098868, 'f1-score': 0.901038103229169, 'support': 1132} weighted_avg {'precision': 0.9047328180931291, 'recall': 0.8984098939929329, 'f1-score': 0.897941314089152, 'support': 1132}
 
----------
Epoch 11/40
time = 738.77 secondes

Train loss 0.09825171547882651 accuracy 0.9789825677871704 macro_avg {'precision': 0.9785369673898202, 'recall': 0.9785796495928725, 'f1-score': 0.9785488907943829, 'support': 10182} weighted_avg {'precision': 0.9790251500995634, 'recall': 0.9789825181693184, 'f1-score': 0.978994649586723, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6376551042112496 accuracy 0.9037102460861206 macro_avg {'precision': 0.9117344920096151, 'recall': 0.9022301809305219, 'f1-score': 0.9043679148656812, 'support': 1132} weighted_avg {'precision': 0.9086555359510174, 'recall': 0.9037102473498233, 'f1-score': 0.9037826013165955, 'support': 1132}
 
----------
Epoch 12/40
time = 739.62 secondes

Train loss 0.08249325049879615 accuracy 0.9829110503196716 macro_avg {'precision': 0.9824444136045315, 'recall': 0.9824888089383437, 'f1-score': 0.9824473102078585, 'support': 10182} weighted_avg {'precision': 0.982961519319646, 'recall': 0.9829110194460813, 'f1-score': 0.9829188620790048, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.6650568432771866 accuracy 0.9063604474067688 macro_avg {'precision': 0.9106499618534768, 'recall': 0.9069385702729453, 'f1-score': 0.9068718243839063, 'support': 1132} weighted_avg {'precision': 0.9105725819171943, 'recall': 0.9063604240282686, 'f1-score': 0.9065400534814894, 'support': 1132}
 
----------
Epoch 13/40
time = 926.94 secondes

Train loss 0.08834486232578971 accuracy 0.9822235703468323 macro_avg {'precision': 0.9814461333543054, 'recall': 0.9813502104789992, 'f1-score': 0.9813832095164978, 'support': 10182} weighted_avg {'precision': 0.9822479751598793, 'recall': 0.9822235317226478, 'f1-score': 0.9822203171585907, 'support': 10182}
 
time = 35.65 secondes

Val loss 0.6149100920668734 accuracy 0.9125441908836365 macro_avg {'precision': 0.914061059822259, 'recall': 0.9111505562081119, 'f1-score': 0.9106597129096995, 'support': 1132} weighted_avg {'precision': 0.9163971474348492, 'recall': 0.9125441696113075, 'f1-score': 0.912557368231023, 'support': 1132}
 
----------
Epoch 14/40
time = 998.84 secondes

Train loss 0.08939934446542831 accuracy 0.9835003018379211 macro_avg {'precision': 0.9823543379511213, 'recall': 0.9828896826163591, 'f1-score': 0.9825520488718922, 'support': 10182} weighted_avg {'precision': 0.9836509969472067, 'recall': 0.9835002946375958, 'f1-score': 0.9835202773492898, 'support': 10182}
 
time = 33.81 secondes

Val loss 0.6130739108683512 accuracy 0.9151943325996399 macro_avg {'precision': 0.923308241392367, 'recall': 0.917252193810078, 'f1-score': 0.9167313696138546, 'support': 1132} weighted_avg {'precision': 0.9212000017641433, 'recall': 0.9151943462897526, 'f1-score': 0.914646356799592, 'support': 1132}
 
----------
Epoch 15/40
time = 995.71 secondes

Train loss 0.08967642098324581 accuracy 0.9831074476242065 macro_avg {'precision': 0.9824369189773842, 'recall': 0.98274247173642, 'f1-score': 0.9825584561729122, 'support': 10182} weighted_avg {'precision': 0.9832003534817864, 'recall': 0.9831074445099195, 'f1-score': 0.9831273609644177, 'support': 10182}
 
time = 34.26 secondes

Val loss 0.7265222535247695 accuracy 0.9045936465263367 macro_avg {'precision': 0.9100804244017213, 'recall': 0.9066854712714525, 'f1-score': 0.9068330970494525, 'support': 1132} weighted_avg {'precision': 0.9081547801554255, 'recall': 0.9045936395759717, 'f1-score': 0.904921761066301, 'support': 1132}
 
----------
Epoch 16/40
time = 996.13 secondes

Train loss 0.07394998417691612 accuracy 0.9858574271202087 macro_avg {'precision': 0.9852328313315322, 'recall': 0.9854305209678704, 'f1-score': 0.9852989708160317, 'support': 10182} weighted_avg {'precision': 0.9859124931773807, 'recall': 0.9858573954036535, 'f1-score': 0.9858531979216519, 'support': 10182}
 
time = 33.90 secondes

Val loss 0.7146698933375121 accuracy 0.9063604474067688 macro_avg {'precision': 0.9100033623397021, 'recall': 0.904982476304174, 'f1-score': 0.9049885275946666, 'support': 1132} weighted_avg {'precision': 0.9096525016987779, 'recall': 0.9063604240282686, 'f1-score': 0.9054424709999817, 'support': 1132}
 
----------
Epoch 17/40
time = 994.75 secondes

Train loss 0.07152641811240881 accuracy 0.9861520528793335 macro_avg {'precision': 0.985857627133616, 'recall': 0.9859559840613297, 'f1-score': 0.9858707062439592, 'support': 10182} weighted_avg {'precision': 0.986260908953075, 'recall': 0.9861520329994107, 'f1-score': 0.9861703374184925, 'support': 10182}
 
time = 33.52 secondes

Val loss 0.6849757260023976 accuracy 0.9090105891227722 macro_avg {'precision': 0.9150387262054107, 'recall': 0.9158846436714672, 'f1-score': 0.9117270185292433, 'support': 1132} weighted_avg {'precision': 0.9179693837832417, 'recall': 0.9090106007067138, 'f1-score': 0.9099464038764857, 'support': 1132}
 
----------
Epoch 18/40
time = 995.99 secondes

Train loss 0.08286015596711355 accuracy 0.9843842387199402 macro_avg {'precision': 0.9841160643905831, 'recall': 0.9843586680121568, 'f1-score': 0.9842198481679839, 'support': 10182} weighted_avg {'precision': 0.9844168801992192, 'recall': 0.9843842074248674, 'f1-score': 0.9843830873268156, 'support': 10182}
 
time = 32.62 secondes

Val loss 0.6174911147090697 accuracy 0.9213780760765076 macro_avg {'precision': 0.9277291109543573, 'recall': 0.9238186383809504, 'f1-score': 0.9243363277859655, 'support': 1132} weighted_avg {'precision': 0.9260384946516375, 'recall': 0.9213780918727915, 'f1-score': 0.9222024606112866, 'support': 1132}
 
----------
Epoch 19/40
time = 993.08 secondes

Train loss 0.07701825029165535 accuracy 0.9866431355476379 macro_avg {'precision': 0.9863510900790222, 'recall': 0.9861043036716808, 'f1-score': 0.9862079651080974, 'support': 10182} weighted_avg {'precision': 0.9866791842289641, 'recall': 0.9866430956590061, 'f1-score': 0.9866414253335399, 'support': 10182}
 
time = 33.76 secondes

Val loss 0.7937350979120541 accuracy 0.9028268456459045 macro_avg {'precision': 0.9115413808735141, 'recall': 0.9038485559796271, 'f1-score': 0.9034612363462798, 'support': 1132} weighted_avg {'precision': 0.9116013647920284, 'recall': 0.9028268551236749, 'f1-score': 0.9029702852360755, 'support': 1132}
 
----------
Epoch 20/40
time = 995.99 secondes

Train loss 0.0639310936056911 accuracy 0.988705575466156 macro_avg {'precision': 0.9884239648755682, 'recall': 0.9880820446245606, 'f1-score': 0.9882247132275618, 'support': 10182} weighted_avg {'precision': 0.9887639920660419, 'recall': 0.9887055588293067, 'f1-score': 0.9887061868943879, 'support': 10182}
 
time = 33.80 secondes

Val loss 0.624860404502407 accuracy 0.9178445339202881 macro_avg {'precision': 0.9237281616161903, 'recall': 0.9192789744444179, 'f1-score': 0.9181758551149521, 'support': 1132} weighted_avg {'precision': 0.9258301102747301, 'recall': 0.9178445229681979, 'f1-score': 0.9188916010983093, 'support': 1132}
 
----------
Epoch 21/40
time = 992.13 secondes

Train loss 0.06303396749088284 accuracy 0.988705575466156 macro_avg {'precision': 0.988688458243588, 'recall': 0.9885421277888401, 'f1-score': 0.9886009312026556, 'support': 10182} weighted_avg {'precision': 0.9887336471614171, 'recall': 0.9887055588293067, 'f1-score': 0.9887048560348297, 'support': 10182}
 
time = 34.18 secondes

Val loss 0.7339044662959411 accuracy 0.9001767039299011 macro_avg {'precision': 0.8978006269437794, 'recall': 0.9002722340357003, 'f1-score': 0.8964234607784913, 'support': 1132} weighted_avg {'precision': 0.9040604564445324, 'recall': 0.9001766784452296, 'f1-score': 0.8996608897348495, 'support': 1132}
 
----------
Epoch 22/40
time = 991.97 secondes

Train loss 0.07091611471192803 accuracy 0.9885091781616211 macro_avg {'precision': 0.9884307353869657, 'recall': 0.9884264207792764, 'f1-score': 0.9884131596986903, 'support': 10182} weighted_avg {'precision': 0.9885173355254822, 'recall': 0.9885091337654685, 'f1-score': 0.9884974867539345, 'support': 10182}
 
time = 34.21 secondes

Val loss 0.6948364922694016 accuracy 0.916961133480072 macro_avg {'precision': 0.9201936469962432, 'recall': 0.9211713507772583, 'f1-score': 0.9189665342380426, 'support': 1132} weighted_avg {'precision': 0.9225546284432417, 'recall': 0.9169611307420494, 'f1-score': 0.918006535024266, 'support': 1132}
 
----------
Epoch 23/40
time = 994.21 secondes

Train loss 0.051877272318670065 accuracy 0.9909644722938538 macro_avg {'precision': 0.9907690792827498, 'recall': 0.9909048448007782, 'f1-score': 0.9908300336754623, 'support': 10182} weighted_avg {'precision': 0.9909762419732443, 'recall': 0.9909644470634453, 'f1-score': 0.9909639512208378, 'support': 10182}
 
time = 33.99 secondes

Val loss 0.7309458913106527 accuracy 0.9054770469665527 macro_avg {'precision': 0.912595499377128, 'recall': 0.9101375522074575, 'f1-score': 0.9085247298655051, 'support': 1132} weighted_avg {'precision': 0.9120374484031276, 'recall': 0.9054770318021201, 'f1-score': 0.9060531812390703, 'support': 1132}
 
----------
Epoch 24/40
time = 992.99 secondes

Train loss 0.044022838703481504 accuracy 0.991750180721283 macro_avg {'precision': 0.9917328680187578, 'recall': 0.9917585859727025, 'f1-score': 0.9917374679018811, 'support': 10182} weighted_avg {'precision': 0.9917763694041105, 'recall': 0.9917501473187978, 'f1-score': 0.9917547272450077, 'support': 10182}
 
time = 33.93 secondes

Val loss 0.7127971179963911 accuracy 0.9134275913238525 macro_avg {'precision': 0.9177965598628857, 'recall': 0.9172773289061041, 'f1-score': 0.9157834373829393, 'support': 1132} weighted_avg {'precision': 0.9171049300422921, 'recall': 0.9134275618374559, 'f1-score': 0.913447278788055, 'support': 1132}
 
----------
Epoch 25/40
time = 897.39 secondes

Train loss 0.04731089458917359 accuracy 0.9928305149078369 macro_avg {'precision': 0.9926694918699412, 'recall': 0.9928772796420532, 'f1-score': 0.9927601296185168, 'support': 10182} weighted_avg {'precision': 0.9928614637030125, 'recall': 0.9928304851699077, 'f1-score': 0.9928328196113871, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7808682031193289 accuracy 0.9072438478469849 macro_avg {'precision': 0.9169267630450341, 'recall': 0.9081407440407933, 'f1-score': 0.9101698152025571, 'support': 1132} weighted_avg {'precision': 0.9130704447442665, 'recall': 0.907243816254417, 'f1-score': 0.9079046352251591, 'support': 1132}
 
----------
Epoch 26/40
time = 737.51 secondes

Train loss 0.0491679084081976 accuracy 0.9924376606941223 macro_avg {'precision': 0.9920089435487689, 'recall': 0.9922952430965575, 'f1-score': 0.9921355965206903, 'support': 10182} weighted_avg {'precision': 0.9924653383462452, 'recall': 0.9924376350422314, 'f1-score': 0.9924370080390258, 'support': 10182}
 
time = 26.81 secondes

Val loss 0.6817966160314439 accuracy 0.9178445339202881 macro_avg {'precision': 0.9208524558233604, 'recall': 0.9210334981089459, 'f1-score': 0.919698905698346, 'support': 1132} weighted_avg {'precision': 0.9210013192238163, 'recall': 0.9178445229681979, 'f1-score': 0.9181056588062939, 'support': 1132}
 
----------
Epoch 27/40
time = 738.18 secondes

Train loss 0.04239041538567736 accuracy 0.9929287433624268 macro_avg {'precision': 0.9929966905047154, 'recall': 0.9927364979299741, 'f1-score': 0.9928575123413317, 'support': 10182} weighted_avg {'precision': 0.9929404907484445, 'recall': 0.9929286977018268, 'f1-score': 0.992926900735819, 'support': 10182}
 
time = 26.81 secondes

Val loss 0.722466159656211 accuracy 0.916077733039856 macro_avg {'precision': 0.9197074025025447, 'recall': 0.9176856175923798, 'f1-score': 0.9170660137206468, 'support': 1132} weighted_avg {'precision': 0.918089482965903, 'recall': 0.916077738515901, 'f1-score': 0.9154490084655779, 'support': 1132}
 
----------
Epoch 28/40
time = 740.39 secondes

Train loss 0.04192011910034488 accuracy 0.9927322864532471 macro_avg {'precision': 0.9924839300711742, 'recall': 0.9925544408024436, 'f1-score': 0.9925134520483567, 'support': 10182} weighted_avg {'precision': 0.992744421431618, 'recall': 0.9927322726379886, 'f1-score': 0.9927330042603736, 'support': 10182}
 
time = 24.76 secondes

Val loss 0.6668844974034508 accuracy 0.9178445339202881 macro_avg {'precision': 0.924514704862526, 'recall': 0.9179668909022339, 'f1-score': 0.9199242600608246, 'support': 1132} weighted_avg {'precision': 0.920685386936284, 'recall': 0.9178445229681979, 'f1-score': 0.9179308364977526, 'support': 1132}
 
----------
Epoch 29/40
time = 739.95 secondes

Train loss 0.03868839255184775 accuracy 0.993714451789856 macro_avg {'precision': 0.9933068714889325, 'recall': 0.9932341554439894, 'f1-score': 0.9932645357361827, 'support': 10182} weighted_avg {'precision': 0.9937176993070567, 'recall': 0.9937143979571793, 'f1-score': 0.9937105559161286, 'support': 10182}
 
time = 26.64 secondes

Val loss 0.7240595026478716 accuracy 0.9204947352409363 macro_avg {'precision': 0.923227327227807, 'recall': 0.9239762091750185, 'f1-score': 0.9219502219334924, 'support': 1132} weighted_avg {'precision': 0.9228234170883239, 'recall': 0.9204946996466431, 'f1-score': 0.9199649852145455, 'support': 1132}
 
----------
Epoch 30/40
time = 738.88 secondes

Train loss 0.025692558039725047 accuracy 0.994892954826355 macro_avg {'precision': 0.9946680484139023, 'recall': 0.9947154313227984, 'f1-score': 0.9946890623998998, 'support': 10182} weighted_avg {'precision': 0.9948944381063517, 'recall': 0.9948929483402082, 'f1-score': 0.994891073158736, 'support': 10182}
 
time = 26.59 secondes

Val loss 0.7580771711799456 accuracy 0.9196113348007202 macro_avg {'precision': 0.9235439480323091, 'recall': 0.9222427857834073, 'f1-score': 0.9216091790167666, 'support': 1132} weighted_avg {'precision': 0.9223219281521321, 'recall': 0.9196113074204947, 'f1-score': 0.9196788139971669, 'support': 1132}
 
----------
Epoch 31/40
time = 740.73 secondes

Train loss 0.032355391263990896 accuracy 0.9942054748535156 macro_avg {'precision': 0.9942752774275693, 'recall': 0.9941951966430189, 'f1-score': 0.9942321572581584, 'support': 10182} weighted_avg {'precision': 0.9942057721892216, 'recall': 0.9942054606167747, 'f1-score': 0.9942025762667904, 'support': 10182}
 
time = 26.27 secondes

Val loss 0.6622242062266721 accuracy 0.926678478717804 macro_avg {'precision': 0.9290529276940805, 'recall': 0.9279023411928998, 'f1-score': 0.927831636476955, 'support': 1132} weighted_avg {'precision': 0.9279276219407703, 'recall': 0.926678445229682, 'f1-score': 0.9266311312718792, 'support': 1132}
 
----------
Epoch 32/40
time = 738.94 secondes

Train loss 0.03821109611050517 accuracy 0.9940090775489807 macro_avg {'precision': 0.9941544418697641, 'recall': 0.9939592412974294, 'f1-score': 0.9940377700144621, 'support': 10182} weighted_avg {'precision': 0.9940590589893007, 'recall': 0.9940090355529365, 'f1-score': 0.9940148528666589, 'support': 10182}
 
time = 26.17 secondes

Val loss 0.646027602401171 accuracy 0.9249116778373718 macro_avg {'precision': 0.928910550687473, 'recall': 0.9265376702339703, 'f1-score': 0.9268094648727209, 'support': 1132} weighted_avg {'precision': 0.9265479471310116, 'recall': 0.9249116607773852, 'f1-score': 0.9247156997694181, 'support': 1132}
 
----------
Epoch 33/40
time = 740.55 secondes

Train loss 0.022280626948269294 accuracy 0.9964643716812134 macro_avg {'precision': 0.9965778847556577, 'recall': 0.9964354413340413, 'f1-score': 0.996502541709931, 'support': 10182} weighted_avg {'precision': 0.9964743375396133, 'recall': 0.9964643488509134, 'f1-score': 0.9964652675113547, 'support': 10182}
 
time = 26.00 secondes

Val loss 0.7273582160041642 accuracy 0.9151943325996399 macro_avg {'precision': 0.9244603856503396, 'recall': 0.9182024630618351, 'f1-score': 0.9180863202564092, 'support': 1132} weighted_avg {'precision': 0.9242321080917832, 'recall': 0.9151943462897526, 'f1-score': 0.9164139224525298, 'support': 1132}
 
----------
Epoch 34/40
time = 738.82 secondes

Train loss 0.02021439096379725 accuracy 0.9967589974403381 macro_avg {'precision': 0.9967924631819386, 'recall': 0.9966197935011317, 'f1-score': 0.9967007357837707, 'support': 10182} weighted_avg {'precision': 0.996768382958757, 'recall': 0.9967589864466706, 'f1-score': 0.9967585037376983, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7445546385711617 accuracy 0.9204947352409363 macro_avg {'precision': 0.9234647104694839, 'recall': 0.9225583970371634, 'f1-score': 0.9208253948624247, 'support': 1132} weighted_avg {'precision': 0.9244063246504619, 'recall': 0.9204946996466431, 'f1-score': 0.9201993677550028, 'support': 1132}
 
----------
Epoch 35/40
time = 738.97 secondes

Train loss 0.01905403306404 accuracy 0.996857225894928 macro_avg {'precision': 0.9968458270909517, 'recall': 0.9968566495705191, 'f1-score': 0.9968491519261351, 'support': 10182} weighted_avg {'precision': 0.9968622527530216, 'recall': 0.9968571989785897, 'f1-score': 0.9968576875603293, 'support': 10182}
 
time = 26.53 secondes

Val loss 0.6538155574790566 accuracy 0.9284452199935913 macro_avg {'precision': 0.9316580199017886, 'recall': 0.9309213322319486, 'f1-score': 0.9301224535300919, 'support': 1132} weighted_avg {'precision': 0.9310642568106168, 'recall': 0.9284452296819788, 'f1-score': 0.9285168080202073, 'support': 1132}
 
----------
Epoch 36/40
time = 738.24 secondes

Train loss 0.013378286444161662 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975441520045409, 'recall': 0.9975498883713412, 'f1-score': 0.9975451939071809, 'support': 10182} weighted_avg {'precision': 0.9975487559183014, 'recall': 0.9975446867020232, 'f1-score': 0.9975448509341326, 'support': 10182}
 
time = 26.49 secondes

Val loss 0.6407367818353289 accuracy 0.9293286204338074 macro_avg {'precision': 0.9306373927843554, 'recall': 0.9314911631992336, 'f1-score': 0.930071346853208, 'support': 1132} weighted_avg {'precision': 0.9316022434544768, 'recall': 0.9293286219081273, 'f1-score': 0.9294337957305251, 'support': 1132}
 
----------
Epoch 37/40
time = 738.57 secondes

Train loss 0.01465774472059679 accuracy 0.9978393316268921 macro_avg {'precision': 0.9977666345606432, 'recall': 0.9979157735361757, 'f1-score': 0.9978342368595327, 'support': 10182} weighted_avg {'precision': 0.9978553474183683, 'recall': 0.9978393242977804, 'f1-score': 0.9978409080319927, 'support': 10182}
 
time = 26.37 secondes

Val loss 0.6615774498085826 accuracy 0.9319788217544556 macro_avg {'precision': 0.9347333703269743, 'recall': 0.9342680596547529, 'f1-score': 0.933316909237576, 'support': 1132} weighted_avg {'precision': 0.9342529394678395, 'recall': 0.9319787985865724, 'f1-score': 0.9318829004548708, 'support': 1132}
 
----------
Epoch 38/40
time = 738.00 secondes

Train loss 0.006889319195041174 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984367376667459, 'recall': 0.9984061801117672, 'f1-score': 0.9984194639910908, 'support': 10182} weighted_avg {'precision': 0.9984312822787231, 'recall': 0.9984285994892949, 'f1-score': 0.9984279935448825, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.6337201250974777 accuracy 0.9275618195533752 macro_avg {'precision': 0.9308037705224871, 'recall': 0.9302419288464716, 'f1-score': 0.9291844621371185, 'support': 1132} weighted_avg {'precision': 0.9291210067130447, 'recall': 0.9275618374558304, 'f1-score': 0.9269235894218392, 'support': 1132}
 
----------
Epoch 39/40
time = 738.86 secondes

Train loss 0.006831785116754954 accuracy 0.9987232685089111 macro_avg {'precision': 0.998714276581221, 'recall': 0.9986982686505639, 'f1-score': 0.9987039843067158, 'support': 10182} weighted_avg {'precision': 0.9987269863398945, 'recall': 0.9987232370850521, 'f1-score': 0.9987228701148524, 'support': 10182}
 
time = 26.49 secondes

Val loss 0.6578070168377219 accuracy 0.9293286204338074 macro_avg {'precision': 0.9309299925343189, 'recall': 0.930664275183436, 'f1-score': 0.9295642025862814, 'support': 1132} weighted_avg {'precision': 0.9324360812276838, 'recall': 0.9293286219081273, 'f1-score': 0.9296239326141966, 'support': 1132}
 
----------
Epoch 40/40
time = 737.38 secondes

Train loss 0.001284631520429056 accuracy 0.9996072053909302 macro_avg {'precision': 0.99956617536331, 'recall': 0.9996219073039747, 'f1-score': 0.9995937073584875, 'support': 10182} weighted_avg {'precision': 0.9996078152968031, 'recall': 0.9996071498723237, 'f1-score': 0.9996071773056836, 'support': 10182}
 
time = 26.38 secondes

Val loss 0.6641196095528434 accuracy 0.9302120208740234 macro_avg {'precision': 0.9323305111534564, 'recall': 0.9317271510404362, 'f1-score': 0.930790495464219, 'support': 1132} weighted_avg {'precision': 0.932386590508397, 'recall': 0.9302120141342756, 'f1-score': 0.9299802203026147, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 37 macro_avg {'precision': 0.9347333703269743, 'recall': 0.9342680596547529, 'f1-score': 0.933316909237576, 'support': 1132} weighted_avg {'precision': 0.9342529394678395, 'recall': 0.9319787985865724, 'f1-score': 0.9318829004548708, 'support': 1132}

average train time 818.2491247832775

average val time 28.502375841140747
 
time = 172.77 secondes

test_accuracy 0.8604620099067688 macro_avg {'precision': 0.8580322116594037, 'recall': 0.8539583593507099, 'f1-score': 0.8541044548755401, 'support': 7532} weighted_avg {'precision': 0.8646526628955732, 'recall': 0.8604620286776421, 'f1-score': 0.8608210347121381, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_2
----------
Epoch 1/40
time = 981.16 secondes

Train loss 1.0547005530897078 accuracy 0.7048713564872742 macro_avg {'precision': 0.692424870761104, 'recall': 0.690423110602643, 'f1-score': 0.6868076541697761, 'support': 10182} weighted_avg {'precision': 0.7047801645939359, 'recall': 0.704871341583186, 'f1-score': 0.7002903935093981, 'support': 10182}
 
time = 32.82 secondes

Val loss 0.5667930741755056 accuracy 0.8286219239234924 macro_avg {'precision': 0.8216627988102131, 'recall': 0.8213825672930769, 'f1-score': 0.8148078600991797, 'support': 1132} weighted_avg {'precision': 0.8260518605376143, 'recall': 0.8286219081272085, 'f1-score': 0.8213796718193396, 'support': 1132}
 
----------
Epoch 2/40
time = 980.19 secondes

Train loss 0.3912757411072823 accuracy 0.8812610507011414 macro_avg {'precision': 0.8735153135796881, 'recall': 0.8719855223591946, 'f1-score': 0.8715828848379152, 'support': 10182} weighted_avg {'precision': 0.8799853943209274, 'recall': 0.8812610489098409, 'f1-score': 0.8797206621809145, 'support': 10182}
 
time = 31.94 secondes

Val loss 0.4708802367652386 accuracy 0.8745583295822144 macro_avg {'precision': 0.8808978459495655, 'recall': 0.8708093649741487, 'f1-score': 0.8698173401089295, 'support': 1132} weighted_avg {'precision': 0.882239250417987, 'recall': 0.8745583038869258, 'f1-score': 0.8726900592758567, 'support': 1132}
 
----------
Epoch 3/40
time = 981.34 secondes

Train loss 0.22831605895008641 accuracy 0.9347869157791138 macro_avg {'precision': 0.9310740013688308, 'recall': 0.930881794157969, 'f1-score': 0.930888784502006, 'support': 10182} weighted_avg {'precision': 0.9349949249239496, 'recall': 0.9347868788057356, 'f1-score': 0.9348080628507505, 'support': 10182}
 
time = 31.70 secondes

Val loss 0.4358914404923857 accuracy 0.8948763608932495 macro_avg {'precision': 0.8983502484904703, 'recall': 0.8949291134838966, 'f1-score': 0.8933351494048083, 'support': 1132} weighted_avg {'precision': 0.899443700750067, 'recall': 0.8948763250883393, 'f1-score': 0.8937749067378299, 'support': 1132}
 
----------
Epoch 4/40
time = 981.18 secondes

Train loss 0.1655177861884137 accuracy 0.9545276165008545 macro_avg {'precision': 0.9520706817062667, 'recall': 0.9520658704751395, 'f1-score': 0.951985449539421, 'support': 10182} weighted_avg {'precision': 0.9547612176827308, 'recall': 0.9545275977214692, 'f1-score': 0.9545662596726793, 'support': 10182}
 
time = 32.07 secondes

Val loss 0.5446290204721228 accuracy 0.8869258165359497 macro_avg {'precision': 0.8943818660734546, 'recall': 0.8810067749497152, 'f1-score': 0.8827343877381612, 'support': 1132} weighted_avg {'precision': 0.8921153393551489, 'recall': 0.8869257950530035, 'f1-score': 0.8850649632263683, 'support': 1132}
 
----------
Epoch 5/40
time = 980.82 secondes

Train loss 0.15323189299427897 accuracy 0.9612060785293579 macro_avg {'precision': 0.9597583511675397, 'recall': 0.9599871006427341, 'f1-score': 0.9598069629630533, 'support': 10182} weighted_avg {'precision': 0.9613905233150392, 'recall': 0.9612060498919662, 'f1-score': 0.9612377943427467, 'support': 10182}
 
time = 32.21 secondes

Val loss 0.5032299433074052 accuracy 0.9010601043701172 macro_avg {'precision': 0.9061980386235918, 'recall': 0.904123750039403, 'f1-score': 0.9023532521358069, 'support': 1132} weighted_avg {'precision': 0.9058343406416947, 'recall': 0.901060070671378, 'f1-score': 0.9003486279310298, 'support': 1132}
 
----------
Epoch 6/40
time = 981.36 secondes

Train loss 0.13971542446067034 accuracy 0.964152455329895 macro_avg {'precision': 0.9627850499839598, 'recall': 0.9627770687332824, 'f1-score': 0.9627715889131157, 'support': 10182} weighted_avg {'precision': 0.9642162074281821, 'recall': 0.9641524258495384, 'f1-score': 0.9641746204570731, 'support': 10182}
 
time = 32.14 secondes

Val loss 0.563846891099082 accuracy 0.9010601043701172 macro_avg {'precision': 0.906063095731023, 'recall': 0.9025098730712859, 'f1-score': 0.9012049463401395, 'support': 1132} weighted_avg {'precision': 0.9054510593497033, 'recall': 0.901060070671378, 'f1-score': 0.8999463747553172, 'support': 1132}
 
----------
Epoch 7/40
time = 979.99 secondes

Train loss 0.11498355607765696 accuracy 0.9716166257858276 macro_avg {'precision': 0.9711558252506391, 'recall': 0.9710862296581633, 'f1-score': 0.9711067301387111, 'support': 10182} weighted_avg {'precision': 0.9716296723520964, 'recall': 0.9716165782753879, 'f1-score': 0.971609010906919, 'support': 10182}
 
time = 32.20 secondes

Val loss 0.599229288216136 accuracy 0.9019434452056885 macro_avg {'precision': 0.9070523112299625, 'recall': 0.9065923940053239, 'f1-score': 0.9042637636185453, 'support': 1132} weighted_avg {'precision': 0.9068636826699332, 'recall': 0.9019434628975265, 'f1-score': 0.9016972866521769, 'support': 1132}
 
----------
Epoch 8/40
time = 978.78 secondes

Train loss 0.11898033900426377 accuracy 0.973384439945221 macro_avg {'precision': 0.9724916943214428, 'recall': 0.9722824359602861, 'f1-score': 0.972362723071291, 'support': 10182} weighted_avg {'precision': 0.9734254132336706, 'recall': 0.9733844038499313, 'f1-score': 0.9733820356322257, 'support': 10182}
 
time = 32.19 secondes

Val loss 0.5592887303947707 accuracy 0.9151943325996399 macro_avg {'precision': 0.9181082883453462, 'recall': 0.9136138109795213, 'f1-score': 0.9133636331734178, 'support': 1132} weighted_avg {'precision': 0.9181344676302581, 'recall': 0.9151943462897526, 'f1-score': 0.9144188416855835, 'support': 1132}
 
----------
Epoch 9/40
time = 978.86 secondes

Train loss 0.10544576687326916 accuracy 0.978491485118866 macro_avg {'precision': 0.9780552316623803, 'recall': 0.9781105872643951, 'f1-score': 0.9780529204459745, 'support': 10182} weighted_avg {'precision': 0.978517670016262, 'recall': 0.978491455509723, 'f1-score': 0.9784763551698453, 'support': 10182}
 
time = 32.04 secondes

Val loss 0.6371112851348941 accuracy 0.9072438478469849 macro_avg {'precision': 0.9110936463982645, 'recall': 0.9085581131094447, 'f1-score': 0.9073320595022409, 'support': 1132} weighted_avg {'precision': 0.9116096720274616, 'recall': 0.907243816254417, 'f1-score': 0.9071021890345189, 'support': 1132}
 
----------
Epoch 10/40
time = 1384.04 secondes

Train loss 0.11097088614918235 accuracy 0.9759379625320435 macro_avg {'precision': 0.9751262452450836, 'recall': 0.9750401070544111, 'f1-score': 0.9750256911824936, 'support': 10182} weighted_avg {'precision': 0.9760382083094303, 'recall': 0.9759379296798272, 'f1-score': 0.9759297111740233, 'support': 10182}
 
time = 41.18 secondes

Val loss 0.5650467651524798 accuracy 0.916077733039856 macro_avg {'precision': 0.9184497786267751, 'recall': 0.9175219263793378, 'f1-score': 0.9166821782525506, 'support': 1132} weighted_avg {'precision': 0.9186097112201331, 'recall': 0.916077738515901, 'f1-score': 0.9159583859840655, 'support': 1132}
 
----------
Epoch 11/40
time = 1422.17 secondes

Train loss 0.09257517249636944 accuracy 0.980553925037384 macro_avg {'precision': 0.9801654523616279, 'recall': 0.9798512513550927, 'f1-score': 0.9799880714161816, 'support': 10182} weighted_avg {'precision': 0.9805650361307909, 'recall': 0.9805539186800236, 'f1-score': 0.9805413592582043, 'support': 10182}
 
time = 40.14 secondes

Val loss 0.7517188138932704 accuracy 0.8975265026092529 macro_avg {'precision': 0.9079682063555504, 'recall': 0.9018351495946575, 'f1-score': 0.9012175187634245, 'support': 1132} weighted_avg {'precision': 0.9068855669091259, 'recall': 0.8975265017667845, 'f1-score': 0.8981125676562498, 'support': 1132}
 
----------
Epoch 12/40
time = 1409.79 secondes

Train loss 0.09207274496108354 accuracy 0.9812414646148682 macro_avg {'precision': 0.9809853512918119, 'recall': 0.9808258349910675, 'f1-score': 0.9808977975759567, 'support': 10182} weighted_avg {'precision': 0.9812541572981184, 'recall': 0.981241406403457, 'f1-score': 0.9812400845566748, 'support': 10182}
 
time = 37.32 secondes

Val loss 0.6567912130861734 accuracy 0.9028268456459045 macro_avg {'precision': 0.9148712107443968, 'recall': 0.9092718608288977, 'f1-score': 0.9089778585642885, 'support': 1132} weighted_avg {'precision': 0.9118569518548477, 'recall': 0.9028268551236749, 'f1-score': 0.9039210270875869, 'support': 1132}
 
----------
Epoch 13/40
time = 1409.64 secondes

Train loss 0.09847071221834992 accuracy 0.9799646735191345 macro_avg {'precision': 0.9798149873710248, 'recall': 0.97975091954725, 'f1-score': 0.9797584585792276, 'support': 10182} weighted_avg {'precision': 0.9800334062202475, 'recall': 0.9799646434885091, 'f1-score': 0.9799736921158825, 'support': 10182}
 
time = 36.93 secondes

Val loss 0.7423883201865952 accuracy 0.9098939895629883 macro_avg {'precision': 0.9178391007709819, 'recall': 0.9109969448002555, 'f1-score': 0.9121815767951397, 'support': 1132} weighted_avg {'precision': 0.9161556376733343, 'recall': 0.9098939929328622, 'f1-score': 0.9105783149946958, 'support': 1132}
 
----------
Epoch 14/40
time = 1406.24 secondes

Train loss 0.07422327145798546 accuracy 0.9854645729064941 macro_avg {'precision': 0.9849581073073159, 'recall': 0.9849370766970731, 'f1-score': 0.984940099079991, 'support': 10182} weighted_avg {'precision': 0.9854775814113865, 'recall': 0.9854645452759773, 'f1-score': 0.9854632754462345, 'support': 10182}
 
time = 36.80 secondes

Val loss 0.7363474444520224 accuracy 0.9019434452056885 macro_avg {'precision': 0.90967029466293, 'recall': 0.9045863834722747, 'f1-score': 0.9040320113075705, 'support': 1132} weighted_avg {'precision': 0.9079227809475044, 'recall': 0.9019434628975265, 'f1-score': 0.9016973761162551, 'support': 1132}
 
----------
Epoch 15/40
time = 1405.99 secondes

Train loss 0.10884946317513983 accuracy 0.9803575277328491 macro_avg {'precision': 0.9799423326447838, 'recall': 0.9795751045034257, 'f1-score': 0.9797063664057883, 'support': 10182} weighted_avg {'precision': 0.9804058386853179, 'recall': 0.9803574936161854, 'f1-score': 0.9803349175478682, 'support': 10182}
 
time = 38.26 secondes

Val loss 0.7037257165852999 accuracy 0.9063604474067688 macro_avg {'precision': 0.9104147666600483, 'recall': 0.9097771615018233, 'f1-score': 0.9081143189987255, 'support': 1132} weighted_avg {'precision': 0.9100068130322492, 'recall': 0.9063604240282686, 'f1-score': 0.9060100209960379, 'support': 1132}
 
----------
Epoch 16/40
time = 1406.50 secondes

Train loss 0.09690308585723274 accuracy 0.9814378619194031 macro_avg {'precision': 0.9810677464603398, 'recall': 0.9811123659277134, 'f1-score': 0.9810733710503508, 'support': 10182} weighted_avg {'precision': 0.9814516371222601, 'recall': 0.9814378314672952, 'f1-score': 0.9814275098662303, 'support': 10182}
 
time = 37.51 secondes

Val loss 0.6180400164757116 accuracy 0.9090105891227722 macro_avg {'precision': 0.9090808250278993, 'recall': 0.9107783413671404, 'f1-score': 0.9082472089758097, 'support': 1132} weighted_avg {'precision': 0.9135344383902245, 'recall': 0.9090106007067138, 'f1-score': 0.9097081923952675, 'support': 1132}
 
----------
Epoch 17/40
time = 1409.43 secondes

Train loss 0.06937161077916547 accuracy 0.9867413640022278 macro_avg {'precision': 0.986470548856131, 'recall': 0.986384881820527, 'f1-score': 0.9864151432282975, 'support': 10182} weighted_avg {'precision': 0.986747371245201, 'recall': 0.9867413081909252, 'f1-score': 0.9867315427916997, 'support': 10182}
 
time = 37.61 secondes

Val loss 0.5683057757921912 accuracy 0.916077733039856 macro_avg {'precision': 0.9200219818338061, 'recall': 0.9166373971535181, 'f1-score': 0.9174156558467281, 'support': 1132} weighted_avg {'precision': 0.9173557548263727, 'recall': 0.916077738515901, 'f1-score': 0.9157685922580376, 'support': 1132}
 
----------
Epoch 18/40
time = 1409.03 secondes

Train loss 0.07847863100966665 accuracy 0.9852681756019592 macro_avg {'precision': 0.98490962048366, 'recall': 0.9847725404137868, 'f1-score': 0.9848148796408871, 'support': 10182} weighted_avg {'precision': 0.9853296291957712, 'recall': 0.985268120212139, 'f1-score': 0.985272493014773, 'support': 10182}
 
time = 37.27 secondes

Val loss 0.6999966242515833 accuracy 0.9081271886825562 macro_avg {'precision': 0.9131085930946666, 'recall': 0.9084707792945219, 'f1-score': 0.9085614494049155, 'support': 1132} weighted_avg {'precision': 0.9127866186765916, 'recall': 0.9081272084805654, 'f1-score': 0.9082768709596032, 'support': 1132}
 
----------
Epoch 19/40
time = 1407.95 secondes

Train loss 0.07265006550694397 accuracy 0.9864466786384583 macro_avg {'precision': 0.9865592475116115, 'recall': 0.9863490106125591, 'f1-score': 0.9864405197681257, 'support': 10182} weighted_avg {'precision': 0.9864739603124705, 'recall': 0.986446670595168, 'f1-score': 0.9864469763974709, 'support': 10182}
 
time = 38.15 secondes

Val loss 0.5367001939115473 accuracy 0.9302120208740234 macro_avg {'precision': 0.9299250910655275, 'recall': 0.930438750313835, 'f1-score': 0.9295936366181158, 'support': 1132} weighted_avg {'precision': 0.9316283456122801, 'recall': 0.9302120141342756, 'f1-score': 0.9303210201818433, 'support': 1132}
 
----------
Epoch 20/40
time = 1407.62 secondes

Train loss 0.05199332548564631 accuracy 0.9893930554389954 macro_avg {'precision': 0.9894058246096169, 'recall': 0.9893625041640689, 'f1-score': 0.9893631262528786, 'support': 10182} weighted_avg {'precision': 0.9894353161853985, 'recall': 0.9893930465527401, 'f1-score': 0.989392496142461, 'support': 10182}
 
time = 37.57 secondes

Val loss 0.5609121798465116 accuracy 0.9302120208740234 macro_avg {'precision': 0.929860041796536, 'recall': 0.9322216516412107, 'f1-score': 0.929684093862323, 'support': 1132} weighted_avg {'precision': 0.9319056423952493, 'recall': 0.9302120141342756, 'f1-score': 0.9296209296506105, 'support': 1132}
 
----------
Epoch 21/40
time = 1407.41 secondes

Train loss 0.05415894210468714 accuracy 0.9899823665618896 macro_avg {'precision': 0.9901824564279418, 'recall': 0.9901918358048414, 'f1-score': 0.9901681897439228, 'support': 10182} weighted_avg {'precision': 0.9899922013017849, 'recall': 0.9899823217442546, 'f1-score': 0.9899678487259478, 'support': 10182}
 
time = 37.57 secondes

Val loss 0.6091317243614393 accuracy 0.916961133480072 macro_avg {'precision': 0.9247314459155496, 'recall': 0.9212012494464877, 'f1-score': 0.9199231109070386, 'support': 1132} weighted_avg {'precision': 0.9253211129471347, 'recall': 0.9169611307420494, 'f1-score': 0.9178572755133306, 'support': 1132}
 
----------
Epoch 22/40
time = 1408.07 secondes

Train loss 0.05144619845889234 accuracy 0.9904733896255493 macro_avg {'precision': 0.9903576289867706, 'recall': 0.990334549792306, 'f1-score': 0.9903154344024825, 'support': 10182} weighted_avg {'precision': 0.990516451797931, 'recall': 0.9904733844038499, 'f1-score': 0.9904667925879389, 'support': 10182}
 
time = 37.46 secondes

Val loss 0.6539902405636664 accuracy 0.9213780760765076 macro_avg {'precision': 0.9277193234004443, 'recall': 0.9218003860650053, 'f1-score': 0.9211402207016712, 'support': 1132} weighted_avg {'precision': 0.9246335576006464, 'recall': 0.9213780918727915, 'f1-score': 0.9195588113151788, 'support': 1132}
 
----------
Epoch 23/40
time = 1405.97 secondes

Train loss 0.053009115097980036 accuracy 0.9902769923210144 macro_avg {'precision': 0.9902561372336965, 'recall': 0.9902551121845056, 'f1-score': 0.9902456079663986, 'support': 10182} weighted_avg {'precision': 0.9902941652685113, 'recall': 0.9902769593400118, 'f1-score': 0.9902758245896067, 'support': 10182}
 
time = 37.38 secondes

Val loss 0.6232526465185363 accuracy 0.9240282773971558 macro_avg {'precision': 0.9268710136726103, 'recall': 0.9258429808877292, 'f1-score': 0.9241061796853668, 'support': 1132} weighted_avg {'precision': 0.9272464396838407, 'recall': 0.9240282685512368, 'f1-score': 0.9233570264313541, 'support': 1132}
 
----------
Epoch 24/40
time = 1409.10 secondes

Train loss 0.05513187618072014 accuracy 0.9907680749893188 macro_avg {'precision': 0.9903268882212565, 'recall': 0.9905277314930696, 'f1-score': 0.9903941959028563, 'support': 10182} weighted_avg {'precision': 0.9908341586067696, 'recall': 0.9907680219996071, 'f1-score': 0.9907707351859165, 'support': 10182}
 
time = 36.81 secondes

Val loss 0.6519463044293241 accuracy 0.9143109321594238 macro_avg {'precision': 0.917900410028546, 'recall': 0.9165896912596108, 'f1-score': 0.914624233520158, 'support': 1132} weighted_avg {'precision': 0.9207658494937556, 'recall': 0.9143109540636042, 'f1-score': 0.9150884247472401, 'support': 1132}
 
----------
Epoch 25/40
time = 1408.79 secondes

Train loss 0.052331396676833904 accuracy 0.9911609292030334 macro_avg {'precision': 0.9905244091743318, 'recall': 0.9909907966310803, 'f1-score': 0.9907266852536519, 'support': 10182} weighted_avg {'precision': 0.9912325361100235, 'recall': 0.9911608721272834, 'f1-score': 0.9911702986232844, 'support': 10182}
 
time = 40.74 secondes

Val loss 0.7152657072748669 accuracy 0.9037102460861206 macro_avg {'precision': 0.9071492219858099, 'recall': 0.9027226669322852, 'f1-score': 0.902704952276854, 'support': 1132} weighted_avg {'precision': 0.9087360176125796, 'recall': 0.9037102473498233, 'f1-score': 0.9044935265452106, 'support': 1132}
 
----------
Epoch 26/40
time = 1415.09 secondes

Train loss 0.039978432949414514 accuracy 0.9925358891487122 macro_avg {'precision': 0.9922782827691987, 'recall': 0.9920301886028989, 'f1-score': 0.9921481144285844, 'support': 10182} weighted_avg {'precision': 0.9925388385137933, 'recall': 0.9925358475741505, 'f1-score': 0.9925320454439677, 'support': 10182}
 
time = 37.26 secondes

Val loss 0.6738148277025329 accuracy 0.9187279343605042 macro_avg {'precision': 0.9218781849953223, 'recall': 0.9219164657296236, 'f1-score': 0.9203701517540501, 'support': 1132} weighted_avg {'precision': 0.9208112131884383, 'recall': 0.9187279151943463, 'f1-score': 0.9182330797976492, 'support': 1132}
 
----------
Epoch 27/40
time = 1423.91 secondes

Train loss 0.03770366667518126 accuracy 0.992634117603302 macro_avg {'precision': 0.9923945738089287, 'recall': 0.9925041847423545, 'f1-score': 0.9924254017622365, 'support': 10182} weighted_avg {'precision': 0.9926810562618081, 'recall': 0.9926340601060696, 'f1-score': 0.9926366888886975, 'support': 10182}
 
time = 42.90 secondes

Val loss 0.57171463038849 accuracy 0.9249116778373718 macro_avg {'precision': 0.9261077737600886, 'recall': 0.9266949252449509, 'f1-score': 0.9253650295298048, 'support': 1132} weighted_avg {'precision': 0.9269547128121214, 'recall': 0.9249116607773852, 'f1-score': 0.9249881133716747, 'support': 1132}
 
----------
Epoch 28/40
time = 1415.91 secondes

Train loss 0.03185992245059226 accuracy 0.9945001006126404 macro_avg {'precision': 0.9944722866754023, 'recall': 0.9944756904835549, 'f1-score': 0.9944598044891212, 'support': 10182} weighted_avg {'precision': 0.9945236534860822, 'recall': 0.9945000982125319, 'f1-score': 0.9944984027401397, 'support': 10182}
 
time = 40.34 secondes

Val loss 0.6007401038296452 accuracy 0.9249116778373718 macro_avg {'precision': 0.9278868737169239, 'recall': 0.9271972980126636, 'f1-score': 0.9269107691266589, 'support': 1132} weighted_avg {'precision': 0.9265356920970259, 'recall': 0.9249116607773852, 'f1-score': 0.9250944103817687, 'support': 1132}
 
----------
Epoch 29/40
time = 1408.44 secondes

Train loss 0.03642897476029633 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934510283833022, 'recall': 0.9938654465789062, 'f1-score': 0.9936407007077419, 'support': 10182} weighted_avg {'precision': 0.9940517740595779, 'recall': 0.9940090355529365, 'f1-score': 0.9940151791570347, 'support': 10182}
 
time = 37.77 secondes

Val loss 0.7130533025919134 accuracy 0.9178445339202881 macro_avg {'precision': 0.9234284867551474, 'recall': 0.9213608794009488, 'f1-score': 0.9196822568030839, 'support': 1132} weighted_avg {'precision': 0.9231643335378904, 'recall': 0.9178445229681979, 'f1-score': 0.917493655259149, 'support': 1132}
 
----------
Epoch 30/40
time = 1415.36 secondes

Train loss 0.030329900270524752 accuracy 0.9952858090400696 macro_avg {'precision': 0.9949495161442258, 'recall': 0.994706319019793, 'f1-score': 0.9948217805508845, 'support': 10182} weighted_avg {'precision': 0.9952920646034026, 'recall': 0.9952857984678845, 'f1-score': 0.9952832950487494, 'support': 10182}
 
time = 40.98 secondes

Val loss 0.5761175955082929 accuracy 0.9284452199935913 macro_avg {'precision': 0.9330230091880558, 'recall': 0.9287279301860544, 'f1-score': 0.9296514919877561, 'support': 1132} weighted_avg {'precision': 0.9303436668065724, 'recall': 0.9284452296819788, 'f1-score': 0.9281885334727354, 'support': 1132}
 
----------
Epoch 31/40
time = 1422.75 secondes

Train loss 0.021053200754194874 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960914974215612, 'recall': 0.9960647775283278, 'f1-score': 0.9960763276829763, 'support': 10182} weighted_avg {'precision': 0.9961752468074184, 'recall': 0.9961697112551562, 'f1-score': 0.9961706191757974, 'support': 10182}
 
time = 37.98 secondes

Val loss 0.7054938470315443 accuracy 0.9204947352409363 macro_avg {'precision': 0.926826774963595, 'recall': 0.922783926589787, 'f1-score': 0.9233649865022595, 'support': 1132} weighted_avg {'precision': 0.9252106701746141, 'recall': 0.9204946996466431, 'f1-score': 0.9211603167060798, 'support': 1132}
 
----------
Epoch 32/40
time = 1403.73 secondes

Train loss 0.022547656826565877 accuracy 0.9960715174674988 macro_avg {'precision': 0.9962272459705039, 'recall': 0.9961482691685715, 'f1-score': 0.9961810924968537, 'support': 10182} weighted_avg {'precision': 0.9960891625522915, 'recall': 0.9960714987232371, 'f1-score': 0.9960734705036454, 'support': 10182}
 
time = 36.57 secondes

Val loss 0.8069392129798384 accuracy 0.9187279343605042 macro_avg {'precision': 0.921406117434714, 'recall': 0.9225851711964218, 'f1-score': 0.9197061481559612, 'support': 1132} weighted_avg {'precision': 0.9218560676836637, 'recall': 0.9187279151943463, 'f1-score': 0.9180879953740924, 'support': 1132}
 
----------
Epoch 33/40
time = 1407.51 secondes

Train loss 0.01885050387213389 accuracy 0.9959732890129089 macro_avg {'precision': 0.996059527323782, 'recall': 0.9961046280409949, 'f1-score': 0.9960799066462076, 'support': 10182} weighted_avg {'precision': 0.995977898874605, 'recall': 0.995973286191318, 'f1-score': 0.9959734113813857, 'support': 10182}
 
time = 41.08 secondes

Val loss 0.6694604474134752 accuracy 0.9213780760765076 macro_avg {'precision': 0.9240132359987877, 'recall': 0.9244686196722057, 'f1-score': 0.923428614791869, 'support': 1132} weighted_avg {'precision': 0.9224422338309252, 'recall': 0.9213780918727915, 'f1-score': 0.9210897590358823, 'support': 1132}
 
----------
Epoch 34/40
time = 1413.15 secondes

Train loss 0.013819132621288555 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977532515825753, 'recall': 0.9977317064561705, 'f1-score': 0.9977403869371674, 'support': 10182} weighted_avg {'precision': 0.9976470271188237, 'recall': 0.9976428992339422, 'f1-score': 0.9976427674321803, 'support': 10182}
 
time = 37.49 secondes

Val loss 0.698508399996953 accuracy 0.916077733039856 macro_avg {'precision': 0.9201007590234583, 'recall': 0.9209162278311489, 'f1-score': 0.9183184364850959, 'support': 1132} weighted_avg {'precision': 0.9206234119657956, 'recall': 0.916077738515901, 'f1-score': 0.9159934403752039, 'support': 1132}
 
----------
Epoch 35/40
time = 1401.28 secondes

Train loss 0.01927510648502379 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972089791826455, 'recall': 0.9973400064803257, 'f1-score': 0.9972726324697458, 'support': 10182} weighted_avg {'precision': 0.9972514019920963, 'recall': 0.9972500491062659, 'f1-score': 0.9972490084322179, 'support': 10182}
 
time = 37.09 secondes

Val loss 0.7358649390135071 accuracy 0.9196113348007202 macro_avg {'precision': 0.9229123590838061, 'recall': 0.9235574660761877, 'f1-score': 0.9215881629751166, 'support': 1132} weighted_avg {'precision': 0.9225218893069677, 'recall': 0.9196113074204947, 'f1-score': 0.9193028773496301, 'support': 1132}
 
----------
Epoch 36/40
time = 1407.22 secondes

Train loss 0.014573513909678211 accuracy 0.9975447058677673 macro_avg {'precision': 0.9974443582658254, 'recall': 0.9975566295060512, 'f1-score': 0.9974981713331197, 'support': 10182} weighted_avg {'precision': 0.9975518929682365, 'recall': 0.9975446867020232, 'f1-score': 0.9975460535863608, 'support': 10182}
 
time = 37.79 secondes

Val loss 0.6050498466229072 accuracy 0.9178445339202881 macro_avg {'precision': 0.9219023339725855, 'recall': 0.9217445060119225, 'f1-score': 0.920431044930995, 'support': 1132} weighted_avg {'precision': 0.9210921463508137, 'recall': 0.9178445229681979, 'f1-score': 0.9179757513657782, 'support': 1132}
 
----------
Epoch 37/40
time = 1411.02 secondes

Train loss 0.01277389375972344 accuracy 0.9978393316268921 macro_avg {'precision': 0.9977050856305242, 'recall': 0.9977006963179841, 'f1-score': 0.9977010523523505, 'support': 10182} weighted_avg {'precision': 0.9978411591755649, 'recall': 0.9978393242977804, 'f1-score': 0.9978384615599097, 'support': 10182}
 
time = 41.99 secondes

Val loss 0.6600217325010074 accuracy 0.9249116778373718 macro_avg {'precision': 0.9281208839825424, 'recall': 0.92661069549078, 'f1-score': 0.9262471112945454, 'support': 1132} weighted_avg {'precision': 0.927570296354773, 'recall': 0.9249116607773852, 'f1-score': 0.9250490797300792, 'support': 1132}
 
----------
Epoch 38/40
time = 1411.10 secondes

Train loss 0.006551882621292012 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986285546638236, 'recall': 0.9986591294615197, 'f1-score': 0.9986425045287074, 'support': 10182} weighted_avg {'precision': 0.9986275109217599, 'recall': 0.998625024553133, 'f1-score': 0.9986249345178381, 'support': 10182}
 
time = 37.39 secondes

Val loss 0.6634192922066292 accuracy 0.9240282773971558 macro_avg {'precision': 0.9264560484365862, 'recall': 0.9261359332858168, 'f1-score': 0.9249877584017179, 'support': 1132} weighted_avg {'precision': 0.9261633960110086, 'recall': 0.9240282685512368, 'f1-score': 0.9237635256859261, 'support': 1132}
 
----------
Epoch 39/40
time = 1408.93 secondes

Train loss 0.004548948203072152 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991494349028116, 'recall': 0.9990992493049669, 'f1-score': 0.9991235702110647, 'support': 10182} weighted_avg {'precision': 0.9991173754004641, 'recall': 0.9991160872127284, 'f1-score': 0.9991159671309826, 'support': 10182}
 
time = 41.45 secondes

Val loss 0.6325059754914728 accuracy 0.9337455630302429 macro_avg {'precision': 0.9373568380850757, 'recall': 0.935263470761446, 'f1-score': 0.9350815154845542, 'support': 1132} weighted_avg {'precision': 0.9357091297845037, 'recall': 0.9337455830388692, 'f1-score': 0.9334192575741498, 'support': 1132}
 
----------
Epoch 40/40
time = 1417.08 secondes

Train loss 0.003169068324110538 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995282445532044, 'recall': 0.9995294591887074, 'f1-score': 0.9995280480518616, 'support': 10182} weighted_avg {'precision': 0.9995102304510135, 'recall': 0.9995089373404047, 'f1-score': 0.9995087486691167, 'support': 10182}
 
time = 32.16 secondes

Val loss 0.6614473465879073 accuracy 0.9249116778373718 macro_avg {'precision': 0.9287197704696514, 'recall': 0.9278920904285499, 'f1-score': 0.9269808829663921, 'support': 1132} weighted_avg {'precision': 0.9275277471280706, 'recall': 0.9249116607773852, 'f1-score': 0.9248887113480301, 'support': 1132}
 
----------
best_accuracy 0.9337455630302429 best_epoch 39 macro_avg {'precision': 0.9373568380850757, 'recall': 0.935263470761446, 'f1-score': 0.9350815154845542, 'support': 1132} weighted_avg {'precision': 0.9357091297845037, 'recall': 0.9337455830388692, 'f1-score': 0.9334192575741498, 'support': 1132}

average train time 1313.0982891619205

average val time 36.95630005002022
 
time = 210.49 secondes

test_accuracy 0.8613913655281067 macro_avg {'precision': 0.860704708232951, 'recall': 0.8535895104301169, 'f1-score': 0.8551791836858758, 'support': 7532} weighted_avg {'precision': 0.8646702708359337, 'recall': 0.8613913967073819, 'f1-score': 0.8612093207951979, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_2
----------
Epoch 1/40
time = 1909.33 secondes

Train loss 1.001104614540958 accuracy 0.7303084135055542 macro_avg {'precision': 0.7268182303772096, 'recall': 0.717091745702702, 'f1-score': 0.7135565798057553, 'support': 10182} weighted_avg {'precision': 0.734279158696775, 'recall': 0.7303083873502259, 'f1-score': 0.7251663471642821, 'support': 10182}
 
time = 41.04 secondes

Val loss 0.5004134648282763 accuracy 0.8489399552345276 macro_avg {'precision': 0.8484632083993807, 'recall': 0.8443336476700545, 'f1-score': 0.8332444586018694, 'support': 1132} weighted_avg {'precision': 0.8508454430556123, 'recall': 0.848939929328622, 'f1-score': 0.8383638162128532, 'support': 1132}
 
----------
Epoch 2/40
time = 1909.31 secondes

Train loss 0.35199462669189535 accuracy 0.900019645690918 macro_avg {'precision': 0.8942297927958236, 'recall': 0.8928018822476605, 'f1-score': 0.892882558411171, 'support': 10182} weighted_avg {'precision': 0.8991646131627186, 'recall': 0.9000196425063838, 'f1-score': 0.8991028381262853, 'support': 10182}
 
time = 38.53 secondes

Val loss 0.46088602286304386 accuracy 0.879858672618866 macro_avg {'precision': 0.8875062529057969, 'recall': 0.8822480999464245, 'f1-score': 0.8795967697034286, 'support': 1132} weighted_avg {'precision': 0.889120811512215, 'recall': 0.8798586572438163, 'f1-score': 0.8787755001185383, 'support': 1132}
 
----------
Epoch 3/40
time = 1908.75 secondes

Train loss 0.21830159423615508 accuracy 0.9377332925796509 macro_avg {'precision': 0.9348357908777258, 'recall': 0.9346115524525966, 'f1-score': 0.9346213899426671, 'support': 10182} weighted_avg {'precision': 0.9379128048724401, 'recall': 0.9377332547633078, 'f1-score': 0.9377234295003632, 'support': 10182}
 
time = 40.30 secondes

Val loss 0.40330390266837995 accuracy 0.9125441908836365 macro_avg {'precision': 0.9151314506570856, 'recall': 0.9132859449544026, 'f1-score': 0.9115277587624699, 'support': 1132} weighted_avg {'precision': 0.918239450917028, 'recall': 0.9125441696113075, 'f1-score': 0.9129926859358247, 'support': 1132}
 
----------
Epoch 4/40
time = 1910.55 secondes

Train loss 0.167170140167824 accuracy 0.9550186991691589 macro_avg {'precision': 0.9536289632681811, 'recall': 0.9533919455459738, 'f1-score': 0.9534677008940127, 'support': 10182} weighted_avg {'precision': 0.9550982768604888, 'recall': 0.9550186603810646, 'f1-score': 0.9550166191368876, 'support': 10182}
 
time = 39.53 secondes

Val loss 0.4390325243748777 accuracy 0.9134275913238525 macro_avg {'precision': 0.9169355119636023, 'recall': 0.9097197947556129, 'f1-score': 0.9110208669977735, 'support': 1132} weighted_avg {'precision': 0.9173543857790867, 'recall': 0.9134275618374559, 'f1-score': 0.913372395541853, 'support': 1132}
 
----------
Epoch 5/40
time = 1909.60 secondes

Train loss 0.13766327793318836 accuracy 0.9642506837844849 macro_avg {'precision': 0.963118858128422, 'recall': 0.9631424419101673, 'f1-score': 0.9631092218764822, 'support': 10182} weighted_avg {'precision': 0.9642493126222794, 'recall': 0.9642506383814575, 'f1-score': 0.9642282693279672, 'support': 10182}
 
time = 39.07 secondes

Val loss 0.4958603046039237 accuracy 0.9063604474067688 macro_avg {'precision': 0.9147731704836743, 'recall': 0.9001813440838987, 'f1-score': 0.9041274600929144, 'support': 1132} weighted_avg {'precision': 0.910536636433018, 'recall': 0.9063604240282686, 'f1-score': 0.9055773918772159, 'support': 1132}
 
----------
Epoch 6/40
time = 1909.55 secondes

Train loss 0.1278144653248374 accuracy 0.9690631031990051 macro_avg {'precision': 0.9686596155967532, 'recall': 0.9680645374398276, 'f1-score': 0.9683305985009312, 'support': 10182} weighted_avg {'precision': 0.9690691788868356, 'recall': 0.9690630524454921, 'f1-score': 0.9690384658343896, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.5983240878460339 accuracy 0.8957597017288208 macro_avg {'precision': 0.8988604543821859, 'recall': 0.893485503886828, 'f1-score': 0.8906676904446608, 'support': 1132} weighted_avg {'precision': 0.901278459917364, 'recall': 0.8957597173144877, 'f1-score': 0.8933252110511339, 'support': 1132}
 
----------
Epoch 7/40
time = 1909.55 secondes

Train loss 0.11343008143990155 accuracy 0.9741701483726501 macro_avg {'precision': 0.9734581454190623, 'recall': 0.9733428234755808, 'f1-score': 0.9733609823657987, 'support': 10182} weighted_avg {'precision': 0.9741800836047303, 'recall': 0.9741701041052838, 'f1-score': 0.9741361739617854, 'support': 10182}
 
time = 40.32 secondes

Val loss 0.7245520907593563 accuracy 0.8842756152153015 macro_avg {'precision': 0.8921837603679006, 'recall': 0.8824649986375734, 'f1-score': 0.8830002249698236, 'support': 1132} weighted_avg {'precision': 0.8927516897604317, 'recall': 0.8842756183745583, 'f1-score': 0.8841824872471611, 'support': 1132}
 
----------
Epoch 8/40
time = 1909.75 secondes

Train loss 0.11420395336982142 accuracy 0.9743665456771851 macro_avg {'precision': 0.9736746085123285, 'recall': 0.9735967049059632, 'f1-score': 0.9736070413765034, 'support': 10182} weighted_avg {'precision': 0.9743933178250752, 'recall': 0.974366529169122, 'f1-score': 0.9743509755131652, 'support': 10182}
 
time = 39.40 secondes

Val loss 0.8220701154516551 accuracy 0.8772084712982178 macro_avg {'precision': 0.8931567094223519, 'recall': 0.8796595857899442, 'f1-score': 0.8769076972731874, 'support': 1132} weighted_avg {'precision': 0.8964092997993786, 'recall': 0.877208480565371, 'f1-score': 0.8767397605845306, 'support': 1132}
 
----------
Epoch 9/40
time = 1908.64 secondes

Train loss 0.10956418195955406 accuracy 0.976527214050293 macro_avg {'precision': 0.9758390837401996, 'recall': 0.9752474093978613, 'f1-score': 0.975513415610919, 'support': 10182} weighted_avg {'precision': 0.9765352184736995, 'recall': 0.9765272048713416, 'f1-score': 0.9765060450163512, 'support': 10182}
 
time = 39.87 secondes

Val loss 0.6684241715450132 accuracy 0.9037102460861206 macro_avg {'precision': 0.9094810188055483, 'recall': 0.9069276435400001, 'f1-score': 0.9047205484351591, 'support': 1132} weighted_avg {'precision': 0.9131524080036927, 'recall': 0.9037102473498233, 'f1-score': 0.9048151870925867, 'support': 1132}
 
----------
Epoch 10/40
time = 1911.39 secondes

Train loss 0.11217753514205216 accuracy 0.976527214050293 macro_avg {'precision': 0.9759240042393355, 'recall': 0.9760177083631083, 'f1-score': 0.9759556171993735, 'support': 10182} weighted_avg {'precision': 0.9765537290318279, 'recall': 0.9765272048713416, 'f1-score': 0.9765254081639174, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.6058615799966632 accuracy 0.9196113348007202 macro_avg {'precision': 0.9254867841946485, 'recall': 0.9206464038480459, 'f1-score': 0.9213484843391189, 'support': 1132} weighted_avg {'precision': 0.9235494414918549, 'recall': 0.9196113074204947, 'f1-score': 0.9199250448184835, 'support': 1132}
 
----------
Epoch 11/40
time = 1909.38 secondes

Train loss 0.105935125544674 accuracy 0.9794735908508301 macro_avg {'precision': 0.9792262505708834, 'recall': 0.9789824731222689, 'f1-score': 0.9790758557165041, 'support': 10182} weighted_avg {'precision': 0.9795077261628403, 'recall': 0.9794735808289138, 'f1-score': 0.9794614471096068, 'support': 10182}
 
time = 39.80 secondes

Val loss 0.6887336041459413 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131388260501497, 'recall': 0.9030057634729145, 'f1-score': 0.9030767659571618, 'support': 1132} weighted_avg {'precision': 0.9124237577930264, 'recall': 0.9028268551236749, 'f1-score': 0.9027173087032963, 'support': 1132}
 
----------
Epoch 12/40
time = 1910.59 secondes

Train loss 0.10126284972074741 accuracy 0.9801610708236694 macro_avg {'precision': 0.9799271984653691, 'recall': 0.9796845580350422, 'f1-score': 0.9797675962891758, 'support': 10182} weighted_avg {'precision': 0.9802152144509437, 'recall': 0.9801610685523473, 'f1-score': 0.9801493808749597, 'support': 10182}
 
time = 39.41 secondes

Val loss 0.6459896137787671 accuracy 0.9143109321594238 macro_avg {'precision': 0.9157103822305702, 'recall': 0.9144947352945921, 'f1-score': 0.9127582917258609, 'support': 1132} weighted_avg {'precision': 0.9173351169190597, 'recall': 0.9143109540636042, 'f1-score': 0.9136932618714839, 'support': 1132}
 
----------
Epoch 13/40
time = 1909.05 secondes

Train loss 0.0875982368280223 accuracy 0.9819289445877075 macro_avg {'precision': 0.9818301701954004, 'recall': 0.9819811273114001, 'f1-score': 0.9818792144705011, 'support': 10182} weighted_avg {'precision': 0.9819602100045404, 'recall': 0.9819288941268906, 'f1-score': 0.9819178206400212, 'support': 10182}
 
time = 39.81 secondes

Val loss 0.7624087328401568 accuracy 0.8931095600128174 macro_avg {'precision': 0.9040608183235574, 'recall': 0.8969271258193945, 'f1-score': 0.8937118050777937, 'support': 1132} weighted_avg {'precision': 0.904697506071807, 'recall': 0.8931095406360424, 'f1-score': 0.891664838614371, 'support': 1132}
 
----------
Epoch 14/40
time = 1909.42 secondes

Train loss 0.09257202683793551 accuracy 0.9830092787742615 macro_avg {'precision': 0.9826512779654568, 'recall': 0.9821824873724999, 'f1-score': 0.9823760297986149, 'support': 10182} weighted_avg {'precision': 0.9831013007333228, 'recall': 0.9830092319780004, 'f1-score': 0.9830146041423804, 'support': 10182}
 
time = 39.56 secondes

Val loss 0.7581579574864623 accuracy 0.9001767039299011 macro_avg {'precision': 0.9065109577950599, 'recall': 0.9011436394494112, 'f1-score': 0.8998883673521407, 'support': 1132} weighted_avg {'precision': 0.90729463050907, 'recall': 0.9001766784452296, 'f1-score': 0.8996065480741485, 'support': 1132}
 
----------
Epoch 15/40
time = 1909.09 secondes

Train loss 0.09834036898601499 accuracy 0.9809467792510986 macro_avg {'precision': 0.9805949913703363, 'recall': 0.9807113900831637, 'f1-score': 0.9806040141181048, 'support': 10182} weighted_avg {'precision': 0.9810396061804113, 'recall': 0.9809467688076998, 'f1-score': 0.980947042952623, 'support': 10182}
 
time = 39.67 secondes

Val loss 0.932810813280066 accuracy 0.8833922147750854 macro_avg {'precision': 0.8968407366237179, 'recall': 0.8830862564001631, 'f1-score': 0.8831612496497632, 'support': 1132} weighted_avg {'precision': 0.8982580178210453, 'recall': 0.8833922261484098, 'f1-score': 0.8838959884376227, 'support': 1132}
 
----------
Epoch 16/40
time = 1909.64 secondes

Train loss 0.0835622027550289 accuracy 0.9841877818107605 macro_avg {'precision': 0.9838873889832682, 'recall': 0.9837288215154943, 'f1-score': 0.9837867423909172, 'support': 10182} weighted_avg {'precision': 0.9842345343148707, 'recall': 0.9841877823610292, 'f1-score': 0.9841896439313582, 'support': 10182}
 
time = 39.52 secondes

Val loss 0.6462081183413368 accuracy 0.9107773900032043 macro_avg {'precision': 0.9161806451353067, 'recall': 0.9120046104897254, 'f1-score': 0.9116412449479506, 'support': 1132} weighted_avg {'precision': 0.9178876153029559, 'recall': 0.9107773851590106, 'f1-score': 0.911765415774978, 'support': 1132}
 
----------
Epoch 17/40
time = 1908.91 secondes

Train loss 0.07318664751887073 accuracy 0.9860538244247437 macro_avg {'precision': 0.985656983038357, 'recall': 0.9858153253990105, 'f1-score': 0.9857076845423199, 'support': 10182} weighted_avg {'precision': 0.9861020002815191, 'recall': 0.9860538204674917, 'f1-score': 0.9860500233098616, 'support': 10182}
 
time = 39.45 secondes

Val loss 0.640288737626102 accuracy 0.9231448769569397 macro_avg {'precision': 0.9228961684572434, 'recall': 0.9251849298570347, 'f1-score': 0.9228934584917503, 'support': 1132} weighted_avg {'precision': 0.9253714681891915, 'recall': 0.9231448763250883, 'f1-score': 0.9232018798073667, 'support': 1132}
 
----------
Epoch 18/40
time = 1910.39 secondes

Train loss 0.05692877924826645 accuracy 0.9883127212524414 macro_avg {'precision': 0.9883374009978058, 'recall': 0.9883091933112956, 'f1-score': 0.9883133878042475, 'support': 10182} weighted_avg {'precision': 0.9883234521472538, 'recall': 0.9883127087016303, 'f1-score': 0.9883078571003645, 'support': 10182}
 
time = 38.51 secondes

Val loss 0.6313100691155521 accuracy 0.916077733039856 macro_avg {'precision': 0.9205280164673922, 'recall': 0.9160253060002838, 'f1-score': 0.9165933958882494, 'support': 1132} weighted_avg {'precision': 0.919403407416757, 'recall': 0.916077738515901, 'f1-score': 0.9160528710049072, 'support': 1132}
 
----------
Epoch 19/40
time = 1908.76 secondes

Train loss 0.06651908281616571 accuracy 0.9885091781616211 macro_avg {'precision': 0.9881430190383107, 'recall': 0.9881787716350449, 'f1-score': 0.9881475363711234, 'support': 10182} weighted_avg {'precision': 0.988511897330776, 'recall': 0.9885091337654685, 'f1-score': 0.9884969271959496, 'support': 10182}
 
time = 40.14 secondes

Val loss 0.6519750257813401 accuracy 0.9134275913238525 macro_avg {'precision': 0.9199459769938481, 'recall': 0.9123775681870023, 'f1-score': 0.9137288528138295, 'support': 1132} weighted_avg {'precision': 0.916339805233741, 'recall': 0.9134275618374559, 'f1-score': 0.912840242865839, 'support': 1132}
 
----------
Epoch 20/40
time = 1909.28 secondes

Train loss 0.07116249481564131 accuracy 0.9881163239479065 macro_avg {'precision': 0.9880998091944931, 'recall': 0.9880022143227833, 'f1-score': 0.9880066392047937, 'support': 10182} weighted_avg {'precision': 0.9881852468684843, 'recall': 0.9881162836377921, 'f1-score': 0.9881049122374974, 'support': 10182}
 
time = 39.41 secondes

Val loss 0.6846689393715794 accuracy 0.9178445339202881 macro_avg {'precision': 0.9201664317654707, 'recall': 0.9197884864604056, 'f1-score': 0.9183650364055739, 'support': 1132} weighted_avg {'precision': 0.9208512496792637, 'recall': 0.9178445229681979, 'f1-score': 0.9177736248355403, 'support': 1132}
 
----------
Epoch 21/40
time = 1909.19 secondes

Train loss 0.05300863722974897 accuracy 0.9896877408027649 macro_avg {'precision': 0.9892952563526238, 'recall': 0.989350198877851, 'f1-score': 0.9893142377391084, 'support': 10182} weighted_avg {'precision': 0.9897083355542613, 'recall': 0.9896876841484974, 'f1-score': 0.9896905033431957, 'support': 10182}
 
time = 39.95 secondes

Val loss 0.8383926647221018 accuracy 0.898409903049469 macro_avg {'precision': 0.9063466726303553, 'recall': 0.8973646742841833, 'f1-score': 0.8988896934755406, 'support': 1132} weighted_avg {'precision': 0.9047223856129665, 'recall': 0.8984098939929329, 'f1-score': 0.8985842153642164, 'support': 1132}
 
----------
Epoch 22/40
time = 1911.28 secondes

Train loss 0.06965116375790764 accuracy 0.9886073470115662 macro_avg {'precision': 0.9881676215096729, 'recall': 0.9868940967378398, 'f1-score': 0.9874301032100075, 'support': 10182} weighted_avg {'precision': 0.9886586506897446, 'recall': 0.9886073462973876, 'f1-score': 0.9885604977738306, 'support': 10182}
 
time = 39.38 secondes

Val loss 0.7193793235450178 accuracy 0.9125441908836365 macro_avg {'precision': 0.917491309835829, 'recall': 0.9119979607776211, 'f1-score': 0.9125201084867245, 'support': 1132} weighted_avg {'precision': 0.9177202387991072, 'recall': 0.9125441696113075, 'f1-score': 0.9129082479173948, 'support': 1132}
 
----------
Epoch 23/40
time = 1909.06 secondes

Train loss 0.048035009136118086 accuracy 0.9913573265075684 macro_avg {'precision': 0.9910465163522794, 'recall': 0.9910981373106011, 'f1-score': 0.9910643791955552, 'support': 10182} weighted_avg {'precision': 0.9913764394660936, 'recall': 0.9913572971911215, 'f1-score': 0.9913587306563644, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6402899378576171 accuracy 0.9213780760765076 macro_avg {'precision': 0.9274366491134497, 'recall': 0.9228166963586885, 'f1-score': 0.9236106246242672, 'support': 1132} weighted_avg {'precision': 0.9264131540301072, 'recall': 0.9213780918727915, 'f1-score': 0.9223859455862737, 'support': 1132}
 
----------
Epoch 24/40
time = 1909.22 secondes

Train loss 0.06083538519074004 accuracy 0.98978590965271 macro_avg {'precision': 0.9895304503712101, 'recall': 0.9895495686066548, 'f1-score': 0.9895263908042669, 'support': 10182} weighted_avg {'precision': 0.9898053456074727, 'recall': 0.9897858966804164, 'f1-score': 0.9897818585744753, 'support': 10182}
 
time = 39.34 secondes

Val loss 0.7233179955579595 accuracy 0.9090105891227722 macro_avg {'precision': 0.9161046582926714, 'recall': 0.9113504069028912, 'f1-score': 0.9105935742200995, 'support': 1132} weighted_avg {'precision': 0.9154776799805039, 'recall': 0.9090106007067138, 'f1-score': 0.9091087522825461, 'support': 1132}
 
----------
Epoch 25/40
time = 1909.07 secondes

Train loss 0.039563348141596046 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918336956256942, 'recall': 0.9916336169762061, 'f1-score': 0.9917221318965993, 'support': 10182} weighted_avg {'precision': 0.9921727133196265, 'recall': 0.9921429974464742, 'f1-score': 0.9921466006224027, 'support': 10182}
 
time = 40.17 secondes

Val loss 0.6303446873247031 accuracy 0.9231448769569397 macro_avg {'precision': 0.9314075403017965, 'recall': 0.9250527042591619, 'f1-score': 0.9258693500818433, 'support': 1132} weighted_avg {'precision': 0.9290963559400797, 'recall': 0.9231448763250883, 'f1-score': 0.923600842088214, 'support': 1132}
 
----------
Epoch 26/40
time = 1909.96 secondes

Train loss 0.04797554284569275 accuracy 0.9912590980529785 macro_avg {'precision': 0.9912095678789395, 'recall': 0.9908239963475902, 'f1-score': 0.9910094540964381, 'support': 10182} weighted_avg {'precision': 0.9912563747527677, 'recall': 0.9912590846592025, 'f1-score': 0.9912513256659231, 'support': 10182}
 
time = 39.19 secondes

Val loss 0.6050276190492273 accuracy 0.9275618195533752 macro_avg {'precision': 0.9302510342889931, 'recall': 0.9293476528646624, 'f1-score': 0.9286156491381921, 'support': 1132} weighted_avg {'precision': 0.9319015773406718, 'recall': 0.9275618374558304, 'f1-score': 0.92846789641746, 'support': 1132}
 
----------
Epoch 27/40
time = 1909.34 secondes

Train loss 0.037623642903953064 accuracy 0.992634117603302 macro_avg {'precision': 0.9925807778727632, 'recall': 0.992564290038837, 'f1-score': 0.9925655340195417, 'support': 10182} weighted_avg {'precision': 0.9926542708047015, 'recall': 0.9926340601060696, 'f1-score': 0.992637112821043, 'support': 10182}
 
time = 39.79 secondes

Val loss 0.6339351251003215 accuracy 0.9293286204338074 macro_avg {'precision': 0.9353044113446541, 'recall': 0.9299563894916206, 'f1-score': 0.9299468461676466, 'support': 1132} weighted_avg {'precision': 0.936027873800648, 'recall': 0.9293286219081273, 'f1-score': 0.9300308334653564, 'support': 1132}
 
----------
Epoch 28/40
time = 1909.05 secondes

Train loss 0.032646341550333795 accuracy 0.993714451789856 macro_avg {'precision': 0.9937246911993736, 'recall': 0.9936458791319266, 'f1-score': 0.9936804513640489, 'support': 10182} weighted_avg {'precision': 0.9937221453883613, 'recall': 0.9937143979571793, 'f1-score': 0.993713431200899, 'support': 10182}
 
time = 38.29 secondes

Val loss 0.6690042207819843 accuracy 0.9222614765167236 macro_avg {'precision': 0.9258793598045172, 'recall': 0.9233637652495338, 'f1-score': 0.9232805283307789, 'support': 1132} weighted_avg {'precision': 0.9260187243716778, 'recall': 0.9222614840989399, 'f1-score': 0.9227162617450433, 'support': 1132}
 
----------
Epoch 29/40
time = 1908.64 secondes

Train loss 0.03491280625829897 accuracy 0.9943037033081055 macro_avg {'precision': 0.9943444936358545, 'recall': 0.994083901376692, 'f1-score': 0.9942009611100051, 'support': 10182} weighted_avg {'precision': 0.9943269559885646, 'recall': 0.9943036731486937, 'f1-score': 0.9943033000109757, 'support': 10182}
 
time = 40.38 secondes

Val loss 0.6949095411685153 accuracy 0.916077733039856 macro_avg {'precision': 0.9215707163863709, 'recall': 0.9180254059301447, 'f1-score': 0.9174566541015358, 'support': 1132} weighted_avg {'precision': 0.9222765311077341, 'recall': 0.916077738515901, 'f1-score': 0.9167632515041262, 'support': 1132}
 
----------
Epoch 30/40
time = 1909.09 secondes

Train loss 0.03229863670169447 accuracy 0.9945983290672302 macro_avg {'precision': 0.9945541448522427, 'recall': 0.9940212389337522, 'f1-score': 0.9942669956451022, 'support': 10182} weighted_avg {'precision': 0.9946226466479359, 'recall': 0.994598310744451, 'f1-score': 0.9945931329603148, 'support': 10182}
 
time = 39.37 secondes

Val loss 0.6782469018012499 accuracy 0.9213780760765076 macro_avg {'precision': 0.9234129538994523, 'recall': 0.9223355896450613, 'f1-score': 0.9216596726909889, 'support': 1132} weighted_avg {'precision': 0.9244205081136757, 'recall': 0.9213780918727915, 'f1-score': 0.9216312969535241, 'support': 1132}
 
----------
Epoch 31/40
time = 1909.36 secondes

Train loss 0.02550504969776325 accuracy 0.9956786632537842 macro_avg {'precision': 0.9955803882293403, 'recall': 0.9956658400852305, 'f1-score': 0.9956199562977284, 'support': 10182} weighted_avg {'precision': 0.9956904691661012, 'recall': 0.9956786485955608, 'f1-score': 0.9956814668256424, 'support': 10182}
 
time = 40.02 secondes

Val loss 0.6430131894406477 accuracy 0.926678478717804 macro_avg {'precision': 0.9304651124722747, 'recall': 0.9282103145398658, 'f1-score': 0.9280789830433541, 'support': 1132} weighted_avg {'precision': 0.9292600535211959, 'recall': 0.926678445229682, 'f1-score': 0.9266675770889872, 'support': 1132}
 
----------
Epoch 32/40
time = 1908.88 secondes

Train loss 0.02821248961966774 accuracy 0.9949911832809448 macro_avg {'precision': 0.9948742212770648, 'recall': 0.9949433663675104, 'f1-score': 0.9948982510687484, 'support': 10182} weighted_avg {'precision': 0.9950094143897416, 'recall': 0.9949911608721272, 'f1-score': 0.9949894876168847, 'support': 10182}
 
time = 39.02 secondes

Val loss 0.6624094739029677 accuracy 0.9257950782775879 macro_avg {'precision': 0.93184871590975, 'recall': 0.9276566091978131, 'f1-score': 0.9279351175860615, 'support': 1132} weighted_avg {'precision': 0.9318658488026749, 'recall': 0.9257950530035336, 'f1-score': 0.9269023287375748, 'support': 1132}
 
----------
Epoch 33/40
time = 1909.52 secondes

Train loss 0.02004615105625978 accuracy 0.9965626001358032 macro_avg {'precision': 0.9964150881822272, 'recall': 0.996552136791377, 'f1-score': 0.9964700264955505, 'support': 10182} weighted_avg {'precision': 0.9965832191212305, 'recall': 0.9965625613828325, 'f1-score': 0.9965594361405176, 'support': 10182}
 
time = 39.80 secondes

Val loss 0.639866872846385 accuracy 0.9196113348007202 macro_avg {'precision': 0.9255752284528205, 'recall': 0.9216602065323081, 'f1-score': 0.9212465496441752, 'support': 1132} weighted_avg {'precision': 0.9269286127556876, 'recall': 0.9196113074204947, 'f1-score': 0.9208447448387884, 'support': 1132}
 
----------
Epoch 34/40
time = 1908.36 secondes

Train loss 0.020469085694647938 accuracy 0.9966608285903931 macro_avg {'precision': 0.9965687393142485, 'recall': 0.9964580640730734, 'f1-score': 0.9965097461461795, 'support': 10182} weighted_avg {'precision': 0.9966667251905952, 'recall': 0.9966607739147515, 'f1-score': 0.996660534634597, 'support': 10182}
 
time = 39.09 secondes

Val loss 0.5968756691197509 accuracy 0.9284452199935913 macro_avg {'precision': 0.9312284460228968, 'recall': 0.9301803714595648, 'f1-score': 0.9295810463108707, 'support': 1132} weighted_avg {'precision': 0.931915592810522, 'recall': 0.9284452296819788, 'f1-score': 0.9289514922368795, 'support': 1132}
 
----------
Epoch 35/40
time = 1908.24 secondes

Train loss 0.012203871144432627 accuracy 0.9972500801086426 macro_avg {'precision': 0.997226065579515, 'recall': 0.9971572445096024, 'f1-score': 0.9971888107012928, 'support': 10182} weighted_avg {'precision': 0.9972555869419738, 'recall': 0.9972500491062659, 'f1-score': 0.9972499666092575, 'support': 10182}
 
time = 39.23 secondes

Val loss 0.6195066794899362 accuracy 0.926678478717804 macro_avg {'precision': 0.9298107259966082, 'recall': 0.9283921311554708, 'f1-score': 0.9273330151144362, 'support': 1132} weighted_avg {'precision': 0.9315746896475453, 'recall': 0.926678445229682, 'f1-score': 0.9272636676997998, 'support': 1132}
 
----------
Epoch 36/40
time = 1909.27 secondes

Train loss 0.01824775704706702 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971618373279526, 'recall': 0.9971895549285748, 'f1-score': 0.9971737261492954, 'support': 10182} weighted_avg {'precision': 0.9971580950120631, 'recall': 0.9971518365743469, 'f1-score': 0.9971529804756388, 'support': 10182}
 
time = 39.34 secondes

Val loss 0.6467199377327144 accuracy 0.9284452199935913 macro_avg {'precision': 0.9348181807533835, 'recall': 0.9294793210424042, 'f1-score': 0.9303337756119173, 'support': 1132} weighted_avg {'precision': 0.9337467155385072, 'recall': 0.9284452296819788, 'f1-score': 0.9292228966674563, 'support': 1132}
 
----------
Epoch 37/40
time = 1907.79 secondes

Train loss 0.009721664404243891 accuracy 0.9981340169906616 macro_avg {'precision': 0.998184276211121, 'recall': 0.9981634617425795, 'f1-score': 0.9981703566774864, 'support': 10182} weighted_avg {'precision': 0.9981384889128613, 'recall': 0.9981339618935376, 'f1-score': 0.9981326522019919, 'support': 10182}
 
time = 39.40 secondes

Val loss 0.6048776923446856 accuracy 0.9310954213142395 macro_avg {'precision': 0.9323433091836245, 'recall': 0.930029615673749, 'f1-score': 0.9298989428218887, 'support': 1132} weighted_avg {'precision': 0.9327771368455564, 'recall': 0.931095406360424, 'f1-score': 0.9307076772049082, 'support': 1132}
 
----------
Epoch 38/40
time = 1908.64 secondes

Train loss 0.006326359854966901 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990525285964097, 'recall': 0.9990099778142989, 'f1-score': 0.9990306543694972, 'support': 10182} weighted_avg {'precision': 0.9990186296345368, 'recall': 0.9990178746808093, 'f1-score': 0.9990176702493204, 'support': 10182}
 
time = 39.42 secondes

Val loss 0.6266892918643657 accuracy 0.9319788217544556 macro_avg {'precision': 0.9348972837256839, 'recall': 0.9332731825797754, 'f1-score': 0.9326439593721213, 'support': 1132} weighted_avg {'precision': 0.9354200621783917, 'recall': 0.9319787985865724, 'f1-score': 0.932156609484244, 'support': 1132}
 
----------
Epoch 39/40
time = 1909.80 secondes

Train loss 0.008169731699238082 accuracy 0.9986250400543213 macro_avg {'precision': 0.998660362144226, 'recall': 0.9985589346768678, 'f1-score': 0.9986085531921413, 'support': 10182} weighted_avg {'precision': 0.9986265462565532, 'recall': 0.998625024553133, 'f1-score': 0.9986248310917379, 'support': 10182}
 
time = 39.43 secondes

Val loss 0.5921028292556566 accuracy 0.9319788217544556 macro_avg {'precision': 0.9350589491445861, 'recall': 0.9346573637579306, 'f1-score': 0.9340231011814026, 'support': 1132} weighted_avg {'precision': 0.9346340096577599, 'recall': 0.9319787985865724, 'f1-score': 0.9324318427169855, 'support': 1132}
 
----------
Epoch 40/40
time = 1907.59 secondes

Train loss 0.0033951027634054414 accuracy 0.9993125200271606 macro_avg {'precision': 0.9993473731774174, 'recall': 0.9992919811524137, 'f1-score': 0.9993191707889171, 'support': 10182} weighted_avg {'precision': 0.9993132492051352, 'recall': 0.9993125122765665, 'f1-score': 0.9993123929650052, 'support': 10182}
 
time = 39.52 secondes

Val loss 0.6252623127515569 accuracy 0.9319788217544556 macro_avg {'precision': 0.9336285320386436, 'recall': 0.9341665349908821, 'f1-score': 0.9330379804243488, 'support': 1132} weighted_avg {'precision': 0.933727039172477, 'recall': 0.9319787985865724, 'f1-score': 0.9319696077182962, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 38 macro_avg {'precision': 0.9348972837256839, 'recall': 0.9332731825797754, 'f1-score': 0.9326439593721213, 'support': 1132} weighted_avg {'precision': 0.9354200621783917, 'recall': 0.9319787985865724, 'f1-score': 0.932156609484244, 'support': 1132}

average train time 1909.307525497675

average val time 39.54058667421341
 
time = 258.98 secondes

test_accuracy 0.8663037419319153 macro_avg {'precision': 0.8656628464963416, 'recall': 0.8591149054203816, 'f1-score': 0.8598638394301966, 'support': 7532} weighted_avg {'precision': 0.8694824551205013, 'recall': 0.8663037705788635, 'f1-score': 0.865669260681477, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 72.05 GiB already allocated; 453.62 MiB free; 76.73 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_2
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 1.49 GiB free; 75.69 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_3
----------
Epoch 1/40
time = 35.94 secondes

Train loss 0.6427987506895354 accuracy 0.6375969052314758 macro_avg {'precision': 0.5829439252336448, 'recall': 0.5507777579116753, 'f1-score': 0.5364861294583884, 'support': 516} weighted_avg {'precision': 0.6057695790770122, 'recall': 0.6375968992248062, 'f1-score': 0.5960617697356968, 'support': 516}
 
time = 1.54 secondes

Val loss 0.627983033657074 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 2/40
time = 34.33 secondes

Train loss 0.41521984474225476 accuracy 0.8488371968269348 macro_avg {'precision': 0.8460152217653749, 'recall': 0.8214488890333697, 'f1-score': 0.8309134906231095, 'support': 516} weighted_avg {'precision': 0.8480808002718027, 'recall': 0.8488372093023255, 'f1-score': 0.8460633004591135, 'support': 516}
 
time = 1.51 secondes

Val loss 0.35225366055965424 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 3/40
time = 34.56 secondes

Train loss 0.3211212113048091 accuracy 0.8701550364494324 macro_avg {'precision': 0.8588149822408783, 'recall': 0.8612470133120946, 'f1-score': 0.8599955453864377, 'support': 516} weighted_avg {'precision': 0.8706553353708141, 'recall': 0.8701550387596899, 'f1-score': 0.8703743084008393, 'support': 516}
 
time = 1.53 secondes

Val loss 0.44073089584708214 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 4/40
time = 34.40 secondes

Train loss 0.23170202936638484 accuracy 0.8972868323326111 macro_avg {'precision': 0.8891984359726295, 'recall': 0.8882938088194658, 'f1-score': 0.8887419804968939, 'support': 516} weighted_avg {'precision': 0.897174483014693, 'recall': 0.8972868217054264, 'f1-score': 0.8972270675711009, 'support': 516}
 
time = 1.52 secondes

Val loss 0.8356140479445457 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 5/40
time = 34.98 secondes

Train loss 0.1612522087313912 accuracy 0.9515503644943237 macro_avg {'precision': 0.9462867290926703, 'recall': 0.9493116395494368, 'f1-score': 0.947759531860611, 'support': 516} weighted_avg {'precision': 0.951782607825027, 'recall': 0.9515503875968992, 'f1-score': 0.9516322046271788, 'support': 516}
 
time = 1.51 secondes

Val loss 0.40065275877714157 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 6/40
time = 34.42 secondes

Train loss 0.18590289204748292 accuracy 0.9399224519729614 macro_avg {'precision': 0.9494526053215078, 'recall': 0.9217284592753929, 'f1-score': 0.933079809731792, 'support': 516} weighted_avg {'precision': 0.9422543196428265, 'recall': 0.939922480620155, 'f1-score': 0.9389686537690499, 'support': 516}
 
time = 1.49 secondes

Val loss 1.0198391675949097 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 7/40
time = 34.44 secondes

Train loss 0.2496655656476364 accuracy 0.9263566136360168 macro_avg {'precision': 0.9229652840768533, 'recall': 0.9168603611657429, 'f1-score': 0.919755107386066, 'support': 516} weighted_avg {'precision': 0.926092331609331, 'recall': 0.9263565891472868, 'f1-score': 0.9260889615083184, 'support': 516}
 
time = 1.50 secondes

Val loss 1.0073904395103455 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 8/40
time = 34.44 secondes

Train loss 0.09712644319656785 accuracy 0.9709302186965942 macro_avg {'precision': 0.9654383044118588, 'recall': 0.972587487606261, 'f1-score': 0.9687942233027322, 'support': 516} weighted_avg {'precision': 0.9715309121991389, 'recall': 0.9709302325581395, 'f1-score': 0.9710409885936052, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0301872491836548 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 9/40
time = 34.59 secondes

Train loss 0.16457785826500956 accuracy 0.9554263353347778 macro_avg {'precision': 0.9532477737035097, 'recall': 0.9500430733221723, 'f1-score': 0.9516048134208155, 'support': 516} weighted_avg {'precision': 0.9553380356613511, 'recall': 0.9554263565891473, 'f1-score': 0.9553472901787681, 'support': 516}
 
time = 1.53 secondes

Val loss 1.7084228694438934 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 10/40
time = 34.74 secondes

Train loss 0.06565111438447441 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 1.51 secondes

Val loss 0.7497517317533493 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 11/40
time = 34.47 secondes

Train loss 0.13306954025756568 accuracy 0.9709302186965942 macro_avg {'precision': 0.9640270630836669, 'recall': 0.9748955675113372, 'f1-score': 0.9689275176137618, 'support': 516} weighted_avg {'precision': 0.9721958136284595, 'recall': 0.9709302325581395, 'f1-score': 0.9710983994618659, 'support': 516}
 
time = 1.51 secondes

Val loss 1.056972086429596 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 12/40
time = 34.43 secondes

Train loss 0.11943735280356398 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9265792965888977 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 13/40
time = 34.77 secondes

Train loss 0.652985708362945 accuracy 0.8740310072898865 macro_avg {'precision': 0.8621881115459883, 'recall': 0.8850592461355915, 'f1-score': 0.8685896305699543, 'support': 516} weighted_avg {'precision': 0.8869188653878244, 'recall': 0.874031007751938, 'f1-score': 0.8759484454255895, 'support': 516}
 
time = 1.52 secondes

Val loss 0.9831929951906204 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 14/40
time = 34.96 secondes

Train loss 0.27060735391128354 accuracy 0.9379844665527344 macro_avg {'precision': 0.9270919120503458, 'recall': 0.9467516213448629, 'f1-score': 0.9345624019149374, 'support': 516} weighted_avg {'precision': 0.943546666714849, 'recall': 0.937984496124031, 'f1-score': 0.9386805152852027, 'support': 516}
 
time = 1.50 secondes

Val loss 0.9303063675761223 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 15/40
time = 34.22 secondes

Train loss 0.5785835078797501 accuracy 0.9031007885932922 macro_avg {'precision': 0.9340369393139842, 'recall': 0.8663101604278075, 'f1-score': 0.8875287717095626, 'support': 516} weighted_avg {'precision': 0.9158843140864371, 'recall': 0.9031007751937985, 'f1-score': 0.8990455659531119, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4871693551540375 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 16/40
time = 34.41 secondes

Train loss 0.4743832769436818 accuracy 0.9011628031730652 macro_avg {'precision': 0.8915895061728395, 'recall': 0.8959494823074297, 'f1-score': 0.8936671421125151, 'support': 516} weighted_avg {'precision': 0.9018880395253135, 'recall': 0.9011627906976745, 'f1-score': 0.901436354514651, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3473591208457947 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 17/40
time = 34.57 secondes

Train loss 0.023122451233741067 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.53 secondes

Val loss 1.086848497390747 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 18/40
time = 34.74 secondes

Train loss 0.06081560684039935 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.51 secondes

Val loss 2.2231622636318207 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 19/40
time = 34.52 secondes

Train loss 0.04740368137197837 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.51 secondes

Val loss 1.3459680527448654 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 20/40
time = 34.35 secondes

Train loss 0.30731005633909564 accuracy 0.9457364082336426 macro_avg {'precision': 0.9607843137254901, 'recall': 0.9251336898395721, 'f1-score': 0.9391294089890292, 'support': 516} weighted_avg {'precision': 0.9499924000607995, 'recall': 0.9457364341085271, 'f1-score': 0.9446482182064923, 'support': 516}
 
time = 1.51 secondes

Val loss 0.821805733256042 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 21/40
time = 34.03 secondes

Train loss 0.009266755949338954 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4930856823921204 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 22/40
time = 35.02 secondes

Train loss 0.13188876525876395 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.51 secondes

Val loss 1.2625202387571335 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 23/40
time = 34.26 secondes

Train loss 0.10236564248087675 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.51 secondes

Val loss 1.284340888261795 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 24/40
time = 35.03 secondes

Train loss 0.03834887223417878 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.51 secondes

Val loss 1.3452790081501007 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 25/40
time = 34.24 secondes

Train loss 0.03126708064607528 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.51 secondes

Val loss 2.0385454893112183 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 34.22 secondes

Train loss 0.12682165308224008 accuracy 0.9806201457977295 macro_avg {'precision': 0.9852507374631269, 'recall': 0.9732620320855615, 'f1-score': 0.9787787063236165, 'support': 516} weighted_avg {'precision': 0.9811918318812741, 'recall': 0.9806201550387597, 'f1-score': 0.9804990070969739, 'support': 516}
 
time = 1.50 secondes

Val loss 1.06238953769207 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 34.21 secondes

Train loss 0.030288236914643538 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8955617845058441 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 28/40
time = 34.28 secondes

Train loss 0.013736556415096857 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5125191807746887 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 29/40
time = 34.34 secondes

Train loss 0.033706825374710286 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.51 secondes

Val loss 1.8462360799312592 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 30/40
time = 34.89 secondes

Train loss 0.1642352013234014 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.51 secondes

Val loss 1.1116810161620378 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 31/40
time = 34.17 secondes

Train loss 0.014838638520097558 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4958850145339966 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 32/40
time = 34.36 secondes

Train loss 0.005273106050784311 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 2.0199357867240906 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 33/40
time = 34.36 secondes

Train loss 6.159410380253878e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4170300886034966 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 34/40
time = 34.65 secondes

Train loss 0.03047764519192931 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.52 secondes

Val loss 1.0500876915175468 accuracy 0.890625 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}
 
----------
Epoch 35/40
time = 34.45 secondes

Train loss 0.0029360620650219394 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.51 secondes

Val loss 2.4636386930942535 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 36/40
time = 34.35 secondes

Train loss 0.052121528063170525 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.49 secondes

Val loss 2.4860389828681946 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 37/40
time = 34.19 secondes

Train loss 4.471662726824764e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5338240563869476 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 38/40
time = 35.09 secondes

Train loss 0.018431730405692095 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.54 secondes

Val loss 1.2899591773748398 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 39/40
time = 34.20 secondes

Train loss 8.354880838217495e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.5789024084806442 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 40/40
time = 34.26 secondes

Train loss 5.249976201219287e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.52 secondes

Val loss 1.6116719096899033 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 34 macro_avg {'precision': 0.8853853853853855, 'recall': 0.8896761133603239, 'f1-score': 0.8872955974842768, 'support': 64} weighted_avg {'precision': 0.891672922922923, 'recall': 0.890625, 'f1-score': 0.8909276729559749, 'support': 64}

average train time 34.52156611680984

average val time 1.510578691959381
 
time = 1.84 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_3
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 20.66 secondes

Train loss 0.6150850518183275 accuracy 0.6879844665527344 macro_avg {'precision': 0.8030864197530865, 'recall': 0.5718267964826163, 'f1-score': 0.5302592519295468, 'support': 516} weighted_avg {'precision': 0.7672432768685998, 'recall': 0.687984496124031, 'f1-score': 0.605165555192479, 'support': 516}
 
time = 1.14 secondes

Val loss 0.5449104681611061 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 20.35 secondes

Train loss 0.49243062553983746 accuracy 0.7926356792449951 macro_avg {'precision': 0.780236451140406, 'recall': 0.7612193813695691, 'f1-score': 0.7683739779415775, 'support': 516} weighted_avg {'precision': 0.7894066985568322, 'recall': 0.7926356589147286, 'f1-score': 0.7890036707450953, 'support': 516}
 
time = 1.15 secondes

Val loss 0.4986915737390518 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 3/40
time = 20.33 secondes

Train loss 0.29663675526777905 accuracy 0.8817829489707947 macro_avg {'precision': 0.8736757254721327, 'recall': 0.8692115143929913, 'f1-score': 0.8713411568504825, 'support': 516} weighted_avg {'precision': 0.8812495759822038, 'recall': 0.8817829457364341, 'f1-score': 0.8814277828491568, 'support': 516}
 
time = 1.14 secondes

Val loss 0.41714432276785374 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 4/40
time = 21.13 secondes

Train loss 0.24324111595298303 accuracy 0.9205426573753357 macro_avg {'precision': 0.913661131292164, 'recall': 0.9146091705541017, 'f1-score': 0.914130898021309, 'support': 516} weighted_avg {'precision': 0.9206409428641541, 'recall': 0.9205426356589147, 'f1-score': 0.9205881089754935, 'support': 516}
 
time = 1.14 secondes

Val loss 0.5154814347624779 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 5/40
time = 20.37 secondes

Train loss 0.2689566743193251 accuracy 0.8972868323326111 macro_avg {'precision': 0.8850925925925925, 'recall': 0.905604408107537, 'f1-score': 0.8921128105188826, 'support': 516} weighted_avg {'precision': 0.9057066465690496, 'recall': 0.8972868217054264, 'f1-score': 0.8986146652842738, 'support': 516}
 
time = 1.15 secondes

Val loss 0.9954583942890167 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 6/40
time = 20.41 secondes

Train loss 0.19110875559801405 accuracy 0.9399224519729614 macro_avg {'precision': 0.9407085561497326, 'recall': 0.9286526989906214, 'f1-score': 0.9341313666629606, 'support': 516} weighted_avg {'precision': 0.9400279297765618, 'recall': 0.939922480620155, 'f1-score': 0.9395061260219253, 'support': 516}
 
time = 1.14 secondes

Val loss 0.846051536500454 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 7/40
time = 20.35 secondes

Train loss 0.16133773791123973 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.14 secondes

Val loss 0.49940283223986626 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 20.36 secondes

Train loss 0.10577763073767225 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7077684327960014 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 9/40
time = 20.36 secondes

Train loss 0.10156771396710114 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 1.14 secondes

Val loss 0.8040197193622589 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 10/40
time = 21.21 secondes

Train loss 0.17812027470349814 accuracy 0.9437984228134155 macro_avg {'precision': 0.9365275020810655, 'recall': 0.9432326121938137, 'f1-score': 0.9396688317186157, 'support': 516} weighted_avg {'precision': 0.9445937094986431, 'recall': 0.9437984496124031, 'f1-score': 0.9440125779476365, 'support': 516}
 
time = 1.14 secondes

Val loss 0.6945641711354256 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 11/40
time = 20.36 secondes

Train loss 0.10064303960340719 accuracy 0.9709302186965942 macro_avg {'precision': 0.9738215544179243, 'recall': 0.9633551679859564, 'f1-score': 0.968207676983426, 'support': 516} weighted_avg {'precision': 0.9712555062673652, 'recall': 0.9709302325581395, 'f1-score': 0.9707679610338188, 'support': 516}
 
time = 1.15 secondes

Val loss 2.1196420192718506 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 12/40
time = 20.40 secondes

Train loss 0.2668800059014536 accuracy 0.9457364082336426 macro_avg {'precision': 0.9588662409238037, 'recall': 0.9262877297921103, 'f1-score': 0.9393022786852188, 'support': 516} weighted_avg {'precision': 0.9492557637703538, 'recall': 0.9457364341085271, 'f1-score': 0.9447406719596818, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2297129780054092 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 13/40
time = 20.39 secondes

Train loss 0.10754935715389861 accuracy 0.9748061895370483 macro_avg {'precision': 0.9688137755102041, 'recall': 0.9779350811891487, 'f1-score': 0.9730133123061389, 'support': 516} weighted_avg {'precision': 0.9756760698465433, 'recall': 0.9748062015503876, 'f1-score': 0.9749275248827052, 'support': 516}
 
time = 1.14 secondes

Val loss 1.2132937163114548 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 14/40
time = 20.39 secondes

Train loss 0.14855017428018266 accuracy 0.9651162624359131 macro_avg {'precision': 0.9565306347282772, 'recall': 0.9714903369471579, 'f1-score': 0.9629043853342919, 'support': 516} weighted_avg {'precision': 0.9676139210600191, 'recall': 0.9651162790697675, 'f1-score': 0.9653971544647485, 'support': 516}
 
time = 1.09 secondes

Val loss 1.4484840482473373 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 15/40
time = 20.88 secondes

Train loss 0.057867132794027304 accuracy 0.9825581312179565 macro_avg {'precision': 0.9806045666839647, 'recall': 0.9817060286396957, 'f1-score': 0.9811506849315069, 'support': 516} weighted_avg {'precision': 0.9825860477184684, 'recall': 0.9825581395348837, 'f1-score': 0.9825681214824254, 'support': 516}
 
time = 1.13 secondes

Val loss 1.1476810947060585 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 16/40
time = 20.58 secondes

Train loss 0.09303454872728749 accuracy 0.9825581312179565 macro_avg {'precision': 0.9816715542521994, 'recall': 0.9805519886871576, 'f1-score': 0.9811071287636235, 'support': 516} weighted_avg {'precision': 0.982545825850402, 'recall': 0.9825581395348837, 'f1-score': 0.9825479926064133, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0252512507140636 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 17/40
time = 20.38 secondes

Train loss 0.0669932525206329 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.15 secondes

Val loss 0.91978891970939 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 18/40
time = 20.34 secondes

Train loss 0.09030602267012 accuracy 0.9806201457977295 macro_avg {'precision': 0.9812927681780141, 'recall': 0.9767241519431757, 'f1-score': 0.978933616395852, 'support': 516} weighted_avg {'precision': 0.98065602773952, 'recall': 0.9806201550387597, 'f1-score': 0.9805739485005979, 'support': 516}
 
time = 1.15 secondes

Val loss 1.1071563363075256 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 19/40
time = 20.33 secondes

Train loss 0.10587729399258299 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 1.15 secondes

Val loss 1.7372808754444122 accuracy 0.75 macro_avg {'precision': 0.7916666666666667, 'recall': 0.7834008097165992, 'f1-score': 0.7497556207233627, 'support': 64} weighted_avg {'precision': 0.8229166666666667, 'recall': 0.75, 'f1-score': 0.7482893450635386, 'support': 64}
 
----------
Epoch 20/40
time = 20.34 secondes

Train loss 0.73957175303561 accuracy 0.8527131676673889 macro_avg {'precision': 0.8501780910443499, 'recall': 0.8787282804804708, 'f1-score': 0.8494471744471744, 'support': 516} weighted_avg {'precision': 0.8861763299975266, 'recall': 0.8527131782945736, 'f1-score': 0.8555494447936308, 'support': 516}
 
time = 1.09 secondes

Val loss 1.7515232563018799 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 21/40
time = 20.35 secondes

Train loss 0.033175966924649074 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.13 secondes

Val loss 1.1205361570464447 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 22/40
time = 20.34 secondes

Train loss 0.21441098638002365 accuracy 0.9573643207550049 macro_avg {'precision': 0.9473684210526316, 'recall': 0.9665653495440729, 'f1-score': 0.9549266247379455, 'support': 516} weighted_avg {'precision': 0.9618523051815586, 'recall': 0.9573643410852714, 'f1-score': 0.9578112557489479, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1600159681402147 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 23/40
time = 20.37 secondes

Train loss 0.0640839045006556 accuracy 0.9883720874786377 macro_avg {'precision': 0.9863598854424542, 'recall': 0.9885733790614892, 'f1-score': 0.9874481058640374, 'support': 516} weighted_avg {'precision': 0.9884304178806704, 'recall': 0.9883720930232558, 'f1-score': 0.988385292839816, 'support': 516}
 
time = 1.14 secondes

Val loss 2.094721406698227 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 24/40
time = 21.02 secondes

Train loss 0.14658576784087485 accuracy 0.9728682041168213 macro_avg {'precision': 0.9696616669093734, 'recall': 0.9717991645400907, 'f1-score': 0.9707122470160872, 'support': 516} weighted_avg {'precision': 0.9729611605367241, 'recall': 0.9728682170542635, 'f1-score': 0.9728990166262376, 'support': 516}
 
time = 1.15 secondes

Val loss 1.0376194594573462 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 25/40
time = 20.33 secondes

Train loss 0.11592590948743181 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 1.05 secondes

Val loss 1.4812840670347214 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 26/40
time = 20.34 secondes

Train loss 0.060767630633728746 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.15 secondes

Val loss 1.3490205744747072 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 27/40
time = 20.59 secondes

Train loss 0.03772304567092127 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.14 secondes

Val loss 1.1152153313159943 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 28/40
time = 20.80 secondes

Train loss 0.0146385838505177 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.418574720621109 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 29/40
time = 20.41 secondes

Train loss 0.033739897641653166 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9189156889915466 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 30/40
time = 20.39 secondes

Train loss 0.000292741288307518 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.13 secondes

Val loss 1.183428969066881 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 31/40
time = 20.35 secondes

Train loss 0.09065089437397987 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.17 secondes

Val loss 1.2033831626176834 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 32/40
time = 20.41 secondes

Train loss 0.1884422080053782 accuracy 0.9709302186965942 macro_avg {'precision': 0.9628712871287128, 'recall': 0.9772036474164134, 'f1-score': 0.9690557196943952, 'support': 516} weighted_avg {'precision': 0.9730888786553075, 'recall': 0.9709302325581395, 'f1-score': 0.9711516317152747, 'support': 516}
 
time = 1.15 secondes

Val loss 1.8796826303005219 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 33/40
time = 20.52 secondes

Train loss 0.19469474034540876 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.16 secondes

Val loss 1.5309618711471558 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 34/40
time = 20.45 secondes

Train loss 0.0022319404551209036 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.4264078810811043 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 35/40
time = 20.36 secondes

Train loss 0.0004439156797492284 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 2.5808774828910828 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 36/40
time = 20.40 secondes

Train loss 0.05661277513067806 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.14 secondes

Val loss 1.3911480009555817 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 37/40
time = 20.35 secondes

Train loss 0.002033620828032409 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.14 secondes

Val loss 1.0580894348677248 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 38/40
time = 20.97 secondes

Train loss 0.009768449010373319 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.13 secondes

Val loss 1.14921984821558 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 39/40
time = 20.35 secondes

Train loss 0.00024115803446902922 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.7932339906692505 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 40/40
time = 20.38 secondes

Train loss 0.00019269286889484096 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.14 secondes

Val loss 1.9437332153320312 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 3 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}

average train time 20.484560865163804

average val time 1.1382619917392731
 
time = 1.27 secondes

test_accuracy 0.8307692408561707 macro_avg {'precision': 0.8387949260042283, 'recall': 0.8123781676413255, 'f1-score': 0.819853867472915, 'support': 65} weighted_avg {'precision': 0.834590990404944, 'recall': 0.8307692307692308, 'f1-score': 0.8273581797391321, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_3
----------
Epoch 1/40
time = 96.55 secondes

Train loss 0.6236782959013274 accuracy 0.6492248177528381 macro_avg {'precision': 0.6137733574442434, 'recall': 0.5368154998943485, 'f1-score': 0.492101127322758, 'support': 516} weighted_avg {'precision': 0.6254263799524323, 'recall': 0.6492248062015504, 'f1-score': 0.5698417628655751, 'support': 516}
 
time = 3.19 secondes

Val loss 0.5558886229991913 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 2/40
time = 96.38 secondes

Train loss 0.42858401347290387 accuracy 0.817829430103302 macro_avg {'precision': 0.8046597670116493, 'recall': 0.7971327796108773, 'f1-score': 0.8005198394419951, 'support': 516} weighted_avg {'precision': 0.8162035696664779, 'recall': 0.8178294573643411, 'f1-score': 0.8166906667115551, 'support': 516}
 
time = 3.18 secondes

Val loss 0.5284586399793625 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 3/40
time = 97.40 secondes

Train loss 0.2707735714361523 accuracy 0.8972868323326111 macro_avg {'precision': 0.8976806239737274, 'recall': 0.8779074492466232, 'f1-score': 0.8862088335032351, 'support': 516} weighted_avg {'precision': 0.8973699577398455, 'recall': 0.8972868217054264, 'f1-score': 0.8959794814828075, 'support': 516}
 
time = 3.19 secondes

Val loss 0.3035033792257309 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 4/40
time = 96.87 secondes

Train loss 0.17210246289544034 accuracy 0.9379844665527344 macro_avg {'precision': 0.9404607425133554, 'recall': 0.9248248622466395, 'f1-score': 0.9317460317460317, 'support': 516} weighted_avg {'precision': 0.938392348470508, 'recall': 0.937984496124031, 'f1-score': 0.9374246339362619, 'support': 516}
 
time = 3.17 secondes

Val loss 0.4491608738899231 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 5/40
time = 96.89 secondes

Train loss 0.2384218110448935 accuracy 0.9263566136360168 macro_avg {'precision': 0.9176611550443325, 'recall': 0.9249386408335094, 'f1-score': 0.9210310108739428, 'support': 516} weighted_avg {'precision': 0.9274607712555984, 'recall': 0.9263565891472868, 'f1-score': 0.9266745341188296, 'support': 516}
 
time = 3.20 secondes

Val loss 1.5974602401256561 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 6/40
time = 98.15 secondes

Train loss 0.36979316790221317 accuracy 0.9089147448539734 macro_avg {'precision': 0.9302665679378008, 'recall': 0.8777936706597532, 'f1-score': 0.8958099730631919, 'support': 516} weighted_avg {'precision': 0.9167310269811065, 'recall': 0.9089147286821705, 'f1-score': 0.9059786905380277, 'support': 516}
 
time = 3.15 secondes

Val loss 0.5389043539762497 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 7/40
time = 96.82 secondes

Train loss 0.4002409873911264 accuracy 0.9031007885932922 macro_avg {'precision': 0.8909961418677079, 'recall': 0.9101636786242544, 'f1-score': 0.8979430379746836, 'support': 516} weighted_avg {'precision': 0.9100945633377618, 'recall': 0.9031007751937985, 'f1-score': 0.9042568197429104, 'support': 516}
 
time = 3.18 secondes

Val loss 0.7757201343774796 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 8/40
time = 96.59 secondes

Train loss 0.16939899839714848 accuracy 0.9593023061752319 macro_avg {'precision': 0.954617371649984, 'recall': 0.9576987468101361, 'f1-score': 0.9561180067629134, 'support': 516} weighted_avg {'precision': 0.9595090147254282, 'recall': 0.9593023255813954, 'f1-score': 0.9593710518868303, 'support': 516}
 
time = 3.17 secondes

Val loss 0.8188567534089088 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 9/40
time = 97.47 secondes

Train loss 0.0562212597014326 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 3.18 secondes

Val loss 0.7544961422681808 accuracy 0.84375 macro_avg {'precision': 0.84375, 'recall': 0.8562753036437247, 'f1-score': 0.8423645320197044, 'support': 64} weighted_avg {'precision': 0.861328125, 'recall': 0.84375, 'f1-score': 0.8451354679802956, 'support': 64}
 
----------
Epoch 10/40
time = 97.10 secondes

Train loss 0.19417538091356895 accuracy 0.9534883499145508 macro_avg {'precision': 0.9516565746073943, 'recall': 0.9473692765307284, 'f1-score': 0.949440679350045, 'support': 516} weighted_avg {'precision': 0.953390676227123, 'recall': 0.9534883720930233, 'f1-score': 0.9533774764014349, 'support': 516}
 
time = 3.02 secondes

Val loss 1.07413699477911 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 11/40
time = 97.32 secondes

Train loss 0.09315239075768852 accuracy 0.9806201457977295 macro_avg {'precision': 0.9825348396140843, 'recall': 0.9755701119906377, 'f1-score': 0.9788829229963332, 'support': 516} weighted_avg {'precision': 0.9807693512394343, 'recall': 0.9806201550387597, 'f1-score': 0.9805497267127153, 'support': 516}
 
time = 3.17 secondes

Val loss 1.1828903183341026 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 12/40
time = 97.01 secondes

Train loss 0.19093583229308328 accuracy 0.9554263353347778 macro_avg {'precision': 0.9461726998491704, 'recall': 0.961583472847553, 'f1-score': 0.9526475176654124, 'support': 516} weighted_avg {'precision': 0.9583395448221028, 'recall': 0.9554263565891473, 'f1-score': 0.9558042786827752, 'support': 516}
 
time = 3.17 secondes

Val loss 0.6163436425849795 accuracy 0.890625 macro_avg {'precision': 0.8880742913000977, 'recall': 0.9018218623481782, 'f1-score': 0.8893007165801828, 'support': 64} weighted_avg {'precision': 0.9033785434995112, 'recall': 0.890625, 'f1-score': 0.8915709167284409, 'support': 64}
 
----------
Epoch 13/40
time = 96.55 secondes

Train loss 0.059764649429725425 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 3.02 secondes

Val loss 1.5128589570522308 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 14/40
time = 97.12 secondes

Train loss 0.03146369578352085 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 3.18 secondes

Val loss 1.2298294007778168 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 15/40
time = 96.69 secondes

Train loss 0.07049027545673942 accuracy 0.9806201457977295 macro_avg {'precision': 0.9780107761759138, 'recall': 0.98018627180079, 'f1-score': 0.9790801764400623, 'support': 516} weighted_avg {'precision': 0.9806957892086973, 'recall': 0.9806201550387597, 'f1-score': 0.9806421547330268, 'support': 516}
 
time = 2.71 secondes

Val loss 1.0816927403211594 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 16/40
time = 96.84 secondes

Train loss 0.16310615005028067 accuracy 0.9689922332763672 macro_avg {'precision': 0.9654871122761031, 'recall': 0.9676056109097411, 'f1-score': 0.9665282823040997, 'support': 516} weighted_avg {'precision': 0.9690938462007376, 'recall': 0.9689922480620154, 'f1-score': 0.9690274475728429, 'support': 516}
 
time = 3.17 secondes

Val loss 2.073997139930725 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 17/40
time = 96.60 secondes

Train loss 0.08555275164315279 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 3.17 secondes

Val loss 2.4976694881916046 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 18/40
time = 96.57 secondes

Train loss 0.2658490116565107 accuracy 0.9534883499145508 macro_avg {'precision': 0.9487888937430222, 'recall': 0.9508313963883426, 'f1-score': 0.9497924234561494, 'support': 516} weighted_avg {'precision': 0.9536245888567914, 'recall': 0.9534883720930233, 'f1-score': 0.9535411713592644, 'support': 516}
 
time = 3.24 secondes

Val loss 1.3208747394382954 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 19/40
time = 96.63 secondes

Train loss 0.13803066529340646 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 3.17 secondes

Val loss 1.4083380922675133 accuracy 0.78125 macro_avg {'precision': 0.825, 'recall': 0.8157894736842105, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8578125000000001, 'recall': 0.78125, 'f1-score': 0.7797531769305963, 'support': 64}
 
----------
Epoch 20/40
time = 96.72 secondes

Train loss 0.39133616332070564 accuracy 0.9244186282157898 macro_avg {'precision': 0.9130133612462287, 'recall': 0.9361133234725225, 'f1-score': 0.9207513733829523, 'support': 516} weighted_avg {'precision': 0.9332576682899868, 'recall': 0.9244186046511628, 'f1-score': 0.9254427863566991, 'support': 516}
 
time = 3.17 secondes

Val loss 1.3415073156356812 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 21/40
time = 96.79 secondes

Train loss 0.0224448609276971 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.17 secondes

Val loss 2.3013035655021667 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 22/40
time = 96.88 secondes

Train loss 0.08892402659473715 accuracy 0.9825581312179565 macro_avg {'precision': 0.9840264525893269, 'recall': 0.9782439087820816, 'f1-score': 0.9810175477320384, 'support': 516} weighted_avg {'precision': 0.9826547390779392, 'recall': 0.9825581395348837, 'f1-score': 0.9825057384531543, 'support': 516}
 
time = 3.23 secondes

Val loss 1.5832591354846954 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 23/40
time = 96.73 secondes

Train loss 0.14849973116581555 accuracy 0.9728682041168213 macro_avg {'precision': 0.9728252843006941, 'recall': 0.9683370446824765, 'f1-score': 0.9705070629541928, 'support': 516} weighted_avg {'precision': 0.9728659273074065, 'recall': 0.9728682170542635, 'f1-score': 0.972803527900837, 'support': 516}
 
time = 3.16 secondes

Val loss 1.5667136758565903 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 96.72 secondes

Train loss 0.0190266961872112 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.16 secondes

Val loss 1.343783363699913 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 25/40
time = 95.97 secondes

Train loss 0.002718364582643985 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.19 secondes

Val loss 0.9181021526455879 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 26/40
time = 97.24 secondes

Train loss 0.035302754492449545 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 3.18 secondes

Val loss 0.9958551079034805 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
Epoch 27/40
time = 97.25 secondes

Train loss 0.0006871041197992974 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.17 secondes

Val loss 1.6797093003988266 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 96.77 secondes

Train loss 0.04140402851749748 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 3.17 secondes

Val loss 1.074525997042656 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 29/40
time = 96.49 secondes

Train loss 0.05204006498697157 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 3.17 secondes

Val loss 1.2177249491214752 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 30/40
time = 97.47 secondes

Train loss 0.0013258650913926292 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.14 secondes

Val loss 1.4259391874074936 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 31/40
time = 96.61 secondes

Train loss 0.06411416474535751 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 3.19 secondes

Val loss 1.2266603112220764 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 32/40
time = 96.59 secondes

Train loss 0.10607053857088569 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 3.17 secondes

Val loss 2.388211637735367 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 33/40
time = 96.55 secondes

Train loss 0.0174677814312886 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 3.18 secondes

Val loss 1.2151733189821243 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 34/40
time = 96.87 secondes

Train loss 9.973473788704723e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.18 secondes

Val loss 1.784604474902153 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 35/40
time = 96.83 secondes

Train loss 0.027095445907351943 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 3.15 secondes

Val loss 1.1196045577526093 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 36/40
time = 96.39 secondes

Train loss 0.018131293015330535 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 3.16 secondes

Val loss 1.6919010430574417 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 37/40
time = 96.46 secondes

Train loss 8.518239734588529e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 3.18 secondes

Val loss 1.5547788068652153 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 38/40
time = 96.68 secondes

Train loss 0.010307095052584455 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.16 secondes

Val loss 1.909068688750267 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 39/40
time = 97.30 secondes

Train loss 0.034877498759835195 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 3.16 secondes

Val loss 1.73294897377491 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 40/40
time = 96.59 secondes

Train loss 0.015398807317868694 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 3.16 secondes

Val loss 1.4566323161125183 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
best_accuracy 0.890625 best_epoch 12 macro_avg {'precision': 0.8880742913000977, 'recall': 0.9018218623481782, 'f1-score': 0.8893007165801828, 'support': 64} weighted_avg {'precision': 0.9033785434995112, 'recall': 0.890625, 'f1-score': 0.8915709167284409, 'support': 64}

average train time 96.83639701604844

average val time 3.1556310951709747
 
time = 3.89 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 75.73 GiB already allocated; 43.62 MiB free; 77.14 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 74.19 GiB already allocated; 265.62 MiB free; 76.92 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.62 GiB (GPU 0; 79.21 GiB total capacity; 75.62 GiB already allocated; 451.62 MiB free; 76.74 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_3
----------
Epoch 1/40
time = 33.75 secondes

Train loss 0.625626108863137 accuracy 0.6395348906517029 macro_avg {'precision': 0.5836008170411439, 'recall': 0.5419111551777385, 'f1-score': 0.5168733891752577, 'support': 516} weighted_avg {'precision': 0.6046130854764076, 'recall': 0.6395348837209303, 'f1-score': 0.5838654361963558, 'support': 516}
 
time = 1.51 secondes

Val loss 0.6982296705245972 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 2/40
time = 30.11 secondes

Train loss 0.382159088371378 accuracy 0.8585271239280701 macro_avg {'precision': 0.8535509031198687, 'recall': 0.8359719129431269, 'f1-score': 0.8432687706742672, 'support': 516} weighted_avg {'precision': 0.8574765946207407, 'recall': 0.8585271317829457, 'f1-score': 0.8567264556272631, 'support': 516}
 
time = 1.50 secondes

Val loss 0.5236067175865173 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 3/40
time = 30.82 secondes

Train loss 0.22959419272162698 accuracy 0.9127907156944275 macro_avg {'precision': 0.9085317460317461, 'recall': 0.9016059034832502, 'f1-score': 0.9048575116264777, 'support': 516} weighted_avg {'precision': 0.9124084840654608, 'recall': 0.9127906976744186, 'f1-score': 0.9124179976587435, 'support': 516}
 
time = 1.50 secondes

Val loss 0.6560925841331482 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 4/40
time = 30.23 secondes

Train loss 0.1929583439575226 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 1.49 secondes

Val loss 1.476532205939293 accuracy 0.671875 macro_avg {'precision': 0.7020512820512821, 'recall': 0.6993927125506073, 'f1-score': 0.6717948717948719, 'support': 64} weighted_avg {'precision': 0.7279166666666667, 'recall': 0.671875, 'f1-score': 0.6708333333333334, 'support': 64}
 
----------
Epoch 5/40
time = 30.52 secondes

Train loss 0.46417306394626695 accuracy 0.8449612259864807 macro_avg {'precision': 0.8347582620868956, 'recall': 0.8264876550233247, 'f1-score': 0.8302296505889322, 'support': 516} weighted_avg {'precision': 0.8437016133689439, 'recall': 0.8449612403100775, 'f1-score': 0.8439920567757917, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0404720455408096 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 6/40
time = 30.37 secondes

Train loss 0.10133519100032351 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8569167256355286 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 7/40
time = 30.11 secondes

Train loss 0.1767650766255842 accuracy 0.9593023061752319 macro_avg {'precision': 0.9622660427807486, 'recall': 0.9496204671423696, 'f1-score': 0.9553793129007152, 'support': 516} weighted_avg {'precision': 0.9596998974008207, 'recall': 0.9593023255813954, 'f1-score': 0.9590202789180785, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2650444135069847 accuracy 0.734375 macro_avg {'precision': 0.7246153846153847, 'recall': 0.7216599190283401, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7329807692307693, 'recall': 0.734375, 'f1-score': 0.733495670995671, 'support': 64}
 
----------
Epoch 8/40
time = 30.15 secondes

Train loss 0.22144800371747944 accuracy 0.9496123790740967 macro_avg {'precision': 0.9399105952474316, 'recall': 0.9558701623782976, 'f1-score': 0.9465242346938776, 'support': 516} weighted_avg {'precision': 0.9529073567113447, 'recall': 0.9496124031007752, 'f1-score': 0.950060685611454, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4288799464702606 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 9/40
time = 30.11 secondes

Train loss 0.2841227783047185 accuracy 0.9399224519729614 macro_avg {'precision': 0.9307594936708861, 'recall': 0.9425011784210784, 'f1-score': 0.9359173126614988, 'support': 516} weighted_avg {'precision': 0.9419762535570602, 'recall': 0.939922480620155, 'f1-score': 0.940326102197384, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7079083919525146 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 10/40
time = 30.25 secondes

Train loss 0.09328660189974912 accuracy 0.9748061895370483 macro_avg {'precision': 0.9781098331227976, 'recall': 0.9675487216163061, 'f1-score': 0.972446653385636, 'support': 516} weighted_avg {'precision': 0.9751778601022838, 'recall': 0.9748062015503876, 'f1-score': 0.9746655662293096, 'support': 516}
 
time = 1.50 secondes

Val loss 1.2738700211048126 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 11/40
time = 30.21 secondes

Train loss 0.2572881527113636 accuracy 0.9476743936538696 macro_avg {'precision': 0.9394415856680007, 'recall': 0.9497342457292395, 'f1-score': 0.9440695317047713, 'support': 516} weighted_avg {'precision': 0.9491837713097037, 'recall': 0.9476744186046512, 'f1-score': 0.9479771190313585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7568990588188171 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 12/40
time = 30.21 secondes

Train loss 0.13148416147283348 accuracy 0.9670542478561401 macro_avg {'precision': 0.9682539682539683, 'recall': 0.9603156543081449, 'f1-score': 0.9640572821700026, 'support': 516} weighted_avg {'precision': 0.9671619293712317, 'recall': 0.9670542635658915, 'f1-score': 0.9669134657821921, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4331865012645721 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 13/40
time = 31.07 secondes

Train loss 0.06832721539654868 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 1.50 secondes

Val loss 2.0870121717453003 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 14/40
time = 30.13 secondes

Train loss 0.2175860096868939 accuracy 0.9515503644943237 macro_avg {'precision': 0.9578884733083985, 'recall': 0.9377712400240561, 'f1-score': 0.9464674758792405, 'support': 516} weighted_avg {'precision': 0.9527747905184388, 'recall': 0.9515503875968992, 'f1-score': 0.9510069316270866, 'support': 516}
 
time = 1.49 secondes

Val loss 2.169286787509918 accuracy 0.703125 macro_avg {'precision': 0.749204665959703, 'recall': 0.7378542510121457, 'f1-score': 0.7024712503058479, 'support': 64} weighted_avg {'precision': 0.7799244432661717, 'recall': 0.703125, 'f1-score': 0.699856251529239, 'support': 64}
 
----------
Epoch 15/40
time = 30.19 secondes

Train loss 0.21709761677652062 accuracy 0.9534883499145508 macro_avg {'precision': 0.9551522423878807, 'recall': 0.9439071566731141, 'f1-score': 0.9490688951766797, 'support': 516} weighted_avg {'precision': 0.953693788178808, 'recall': 0.9534883720930233, 'f1-score': 0.9531976170327375, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4831441193819046 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 16/40
time = 30.26 secondes

Train loss 0.13878011181209746 accuracy 0.963178277015686 macro_avg {'precision': 0.9587826929286407, 'recall': 0.9618923004404857, 'f1-score': 0.9602972442140645, 'support': 516} weighted_avg {'precision': 0.9633722181756288, 'recall': 0.9631782945736435, 'f1-score': 0.9632404755166558, 'support': 516}
 
time = 1.50 secondes

Val loss 2.1992675960063934 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 17/40
time = 30.21 secondes

Train loss 0.05020497808635065 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7382535636425018 accuracy 0.703125 macro_avg {'precision': 0.7277526395173455, 'recall': 0.652834008097166, 'f1-score': 0.6496686833765485, 'support': 64} weighted_avg {'precision': 0.7199754901960784, 'recall': 0.703125, 'f1-score': 0.6753277153558052, 'support': 64}
 
----------
Epoch 18/40
time = 30.29 secondes

Train loss 0.03965134958994123 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.52 secondes

Val loss 1.7827331721782684 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 19/40
time = 30.81 secondes

Train loss 0.05649112775581395 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 1.48 secondes

Val loss 2.0047809779644012 accuracy 0.6875 macro_avg {'precision': 0.725, 'recall': 0.7186234817813766, 'f1-score': 0.6871945259042034, 'support': 64} weighted_avg {'precision': 0.753125, 'recall': 0.6875, 'f1-score': 0.6853616813294232, 'support': 64}
 
----------
Epoch 20/40
time = 30.12 secondes

Train loss 0.27739180960413773 accuracy 0.9379844665527344 macro_avg {'precision': 0.9268991877687529, 'recall': 0.9502137412024771, 'f1-score': 0.9349183325975909, 'support': 516} weighted_avg {'precision': 0.9460956973596003, 'recall': 0.937984496124031, 'f1-score': 0.938805789925756, 'support': 516}
 
time = 1.50 secondes

Val loss 1.6751444041728973 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 21/40
time = 30.14 secondes

Train loss 0.004300137421303203 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.49 secondes

Val loss 2.6756025552749634 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 22/40
time = 30.88 secondes

Train loss 0.0826095301034167 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 1.51 secondes

Val loss 1.989063024520874 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 23/40
time = 30.20 secondes

Train loss 0.0790824400403036 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.47 secondes

Val loss 1.8668419420719147 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 24/40
time = 30.91 secondes

Train loss 0.10543825667793333 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.50 secondes

Val loss 1.3192211389541626 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 25/40
time = 30.17 secondes

Train loss 0.018286236006105988 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 1.9932116270065308 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 26/40
time = 29.96 secondes

Train loss 0.03347690192067327 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.50 secondes

Val loss 1.918234795331955 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 27/40
time = 30.13 secondes

Train loss 0.00031919298139242034 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7011758089065552 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 28/40
time = 30.22 secondes

Train loss 0.06988515751816687 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 1.50 secondes

Val loss 2.487298548221588 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 29/40
time = 30.23 secondes

Train loss 0.09455356779212845 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 1.51 secondes

Val loss 2.217032015323639 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 30/40
time = 30.18 secondes

Train loss 0.01788237905522251 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.51 secondes

Val loss 1.4192169606685638 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 31/40
time = 30.62 secondes

Train loss 0.02329803276855576 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.50 secondes

Val loss 2.1601904332637787 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 32/40
time = 30.21 secondes

Train loss 0.00585778816027662 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 1.462239220738411 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 33/40
time = 30.19 secondes

Train loss 0.009014906732883184 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.50 secondes

Val loss 2.9580326080322266 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 34/40
time = 30.10 secondes

Train loss 0.0012350406097649477 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.7926853597164154 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 35/40
time = 30.04 secondes

Train loss 0.006170519318347391 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8376981914043427 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 36/40
time = 30.57 secondes

Train loss 0.0058649302861312844 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.50 secondes

Val loss 2.7295517325401306 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 37/40
time = 30.44 secondes

Train loss 3.225793212054255e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.50 secondes

Val loss 1.8883630335330963 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 38/40
time = 30.31 secondes

Train loss 0.014937608432030009 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.52 secondes

Val loss 1.9225796461105347 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 39/40
time = 29.87 secondes

Train loss 2.621215775654877e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.34 secondes

Val loss 1.7789057940244675 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 40/40
time = 30.11 secondes

Train loss 2.75427998227921e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.55 secondes

Val loss 1.824532225728035 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 30 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}

average train time 30.38502171039581

average val time 1.4982064723968507
 
time = 1.76 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9655172413793103, 'recall': 0.9736842105263157, 'f1-score': 0.9686293436293436, 'support': 65} weighted_avg {'precision': 0.9713527851458886, 'recall': 0.9692307692307692, 'f1-score': 0.9693644193644194, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_3
----------
Epoch 1/40
time = 42.43 secondes

Train loss 0.6262132480288997 accuracy 0.6317829489707947 macro_avg {'precision': 0.5560253699788583, 'recall': 0.5185215285340442, 'f1-score': 0.468502656402472, 'support': 516} weighted_avg {'precision': 0.5810429880197322, 'recall': 0.6317829457364341, 'f1-score': 0.5495718909668866, 'support': 516}
 
time = 1.87 secondes

Val loss 0.5721607729792595 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 2/40
time = 39.31 secondes

Train loss 0.45744808063362585 accuracy 0.7926356792449951 macro_avg {'precision': 0.7816102114419066, 'recall': 0.7589113014644929, 'f1-score': 0.7670527181823935, 'support': 516} weighted_avg {'precision': 0.7894382791476103, 'recall': 0.7926356589147286, 'f1-score': 0.7882970315390695, 'support': 516}
 
time = 1.68 secondes

Val loss 0.4254829064011574 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 3/40
time = 39.37 secondes

Train loss 0.3971727020812757 accuracy 0.8430232405662537 macro_avg {'precision': 0.8323083571571039, 'recall': 0.8249678981844188, 'f1-score': 0.828321455710501, 'support': 516} weighted_avg {'precision': 0.8418178297150579, 'recall': 0.8430232558139535, 'f1-score': 0.842146989582622, 'support': 516}
 
time = 1.62 secondes

Val loss 0.468410886824131 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 4/40
time = 39.56 secondes

Train loss 0.21912724493692318 accuracy 0.9166666865348816 macro_avg {'precision': 0.9159608792095181, 'recall': 0.9023373372559855, 'f1-score': 0.9084014845333587, 'support': 516} weighted_avg {'precision': 0.9165574376554412, 'recall': 0.9166666666666666, 'f1-score': 0.9159734578425828, 'support': 516}
 
time = 1.64 secondes

Val loss 0.45259037241339684 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 5/40
time = 39.38 secondes

Train loss 0.1473745360236728 accuracy 0.9534883499145508 macro_avg {'precision': 0.9472080078281653, 'recall': 0.9531394762934187, 'f1-score': 0.9500161446561188, 'support': 516} weighted_avg {'precision': 0.954068098025164, 'recall': 0.9534883720930233, 'f1-score': 0.9536415585975925, 'support': 516}
 
time = 1.64 secondes

Val loss 0.7436205148696899 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 6/40
time = 39.35 secondes

Train loss 0.16911207980504542 accuracy 0.9515503644943237 macro_avg {'precision': 0.9536430481283422, 'recall': 0.9412333598816702, 'f1-score': 0.9468801344056134, 'support': 516} weighted_avg {'precision': 0.9518311103511171, 'recall': 0.9515503875968992, 'f1-score': 0.9512146177596172, 'support': 516}
 
time = 1.68 secondes

Val loss 2.345307797193527 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 7/40
time = 39.72 secondes

Train loss 0.3738545427719752 accuracy 0.9147287011146545 macro_avg {'precision': 0.9182265840811215, 'recall': 0.8962014206069275, 'f1-score': 0.9054047297635117, 'support': 516} weighted_avg {'precision': 0.9154974518212192, 'recall': 0.9147286821705426, 'f1-score': 0.9135775769351066, 'support': 516}
 
time = 1.68 secondes

Val loss 0.8066237270832062 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 8/40
time = 39.38 secondes

Train loss 0.19839317968933645 accuracy 0.9399224519729614 macro_avg {'precision': 0.9419741883444243, 'recall': 0.9274986590380834, 'f1-score': 0.9339638609426538, 'support': 516} weighted_avg {'precision': 0.9402400068155776, 'recall': 0.939922480620155, 'f1-score': 0.9394227254213968, 'support': 516}
 
time = 1.69 secondes

Val loss 0.652794860303402 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 9/40
time = 39.24 secondes

Train loss 0.11072983908481106 accuracy 0.9651162624359131 macro_avg {'precision': 0.9667456857251795, 'recall': 0.9576418575167012, 'f1-score': 0.9618963225520603, 'support': 516} weighted_avg {'precision': 0.9652812822753787, 'recall': 0.9651162790697675, 'f1-score': 0.9649445480554899, 'support': 516}
 
time = 1.69 secondes

Val loss 1.0907388105988503 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 10/40
time = 39.37 secondes

Train loss 0.049423836669919896 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 1.52 secondes

Val loss 1.8846968710422516 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 11/40
time = 39.13 secondes

Train loss 0.22207301261721912 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7672073543071747 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 12/40
time = 39.08 secondes

Train loss 0.12697766198217517 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 1.61 secondes

Val loss 2.076639622449875 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 13/40
time = 39.23 secondes

Train loss 0.44278978018943843 accuracy 0.9089147448539734 macro_avg {'precision': 0.8971276399236501, 'recall': 0.919339108951124, 'f1-score': 0.9044952448461221, 'support': 516} weighted_avg {'precision': 0.9180497224700238, 'recall': 0.9089147286821705, 'f1-score': 0.9101489989426886, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6228834688663483 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 39.45 secondes

Train loss 0.30832243647124746 accuracy 0.9302325248718262 macro_avg {'precision': 0.9253531477096433, 'recall': 0.9233619947011686, 'f1-score': 0.9243401759530792, 'support': 516} weighted_avg {'precision': 0.9300988756620037, 'recall': 0.9302325581395349, 'f1-score': 0.9301507194980564, 'support': 516}
 
time = 1.70 secondes

Val loss 1.2950659543275833 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 15/40
time = 40.06 secondes

Train loss 0.5129475955433339 accuracy 0.9166666865348816 macro_avg {'precision': 0.9353551912568305, 'recall': 0.8884888578255287, 'f1-score': 0.9052665286168691, 'support': 516} weighted_avg {'precision': 0.9230692167577413, 'recall': 0.9166666666666666, 'f1-score': 0.914310213550228, 'support': 516}
 
time = 1.67 secondes

Val loss 1.1610345430672169 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 16/40
time = 39.51 secondes

Train loss 0.1982389162395989 accuracy 0.9476743936538696 macro_avg {'precision': 0.950645291389393, 'recall': 0.9358857662987825, 'f1-score': 0.9424846530790857, 'support': 516} weighted_avg {'precision': 0.9481341965356231, 'recall': 0.9476744186046512, 'f1-score': 0.9472391479476683, 'support': 516}
 
time = 1.69 secondes

Val loss 1.497447431087494 accuracy 0.796875 macro_avg {'precision': 0.8193193193193193, 'recall': 0.8228744939271255, 'f1-score': 0.7968253968253969, 'support': 64} weighted_avg {'precision': 0.8462525025025025, 'recall': 0.796875, 'f1-score': 0.797420634920635, 'support': 64}
 
----------
Epoch 17/40
time = 39.44 secondes

Train loss 0.1796050021595985 accuracy 0.9593023061752319 macro_avg {'precision': 0.9555007784120395, 'recall': 0.956544706857598, 'f1-score': 0.9560182648401826, 'support': 516} weighted_avg {'precision': 0.9593566333981004, 'recall': 0.9593023255813954, 'f1-score': 0.959325616792326, 'support': 516}
 
time = 1.69 secondes

Val loss 1.0516498237848282 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 18/40
time = 39.41 secondes

Train loss 0.10314677721445067 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 1.69 secondes

Val loss 1.883267730474472 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 19/40
time = 39.35 secondes

Train loss 0.014325863092601525 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6531489789485931 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 20/40
time = 39.41 secondes

Train loss 0.09135981864484634 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4012673795223236 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 21/40
time = 39.25 secondes

Train loss 0.041637909964871746 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8053558021783829 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 22/40
time = 39.34 secondes

Train loss 0.14084317500920873 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.69 secondes

Val loss 1.8922217190265656 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 23/40
time = 39.27 secondes

Train loss 0.056769452976533845 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4171417728066444 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 24/40
time = 39.33 secondes

Train loss 0.09201531931246405 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4038533121347427 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 25/40
time = 39.27 secondes

Train loss 0.1617579068754849 accuracy 0.9748061895370483 macro_avg {'precision': 0.9712786567646109, 'recall': 0.9744729613315346, 'f1-score': 0.9728349565675176, 'support': 516} weighted_avg {'precision': 0.9749618285262307, 'recall': 0.9748062015503876, 'f1-score': 0.9748487464061328, 'support': 516}
 
time = 1.69 secondes

Val loss 2.6036927103996277 accuracy 0.6875 macro_avg {'precision': 0.8275862068965517, 'recall': 0.6153846153846154, 'f1-score': 0.5833333333333333, 'support': 64} weighted_avg {'precision': 0.7952586206896551, 'recall': 0.6875, 'f1-score': 0.6223958333333333, 'support': 64}
 
----------
Epoch 26/40
time = 39.92 secondes

Train loss 0.14603611460882926 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1673257146030664 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 27/40
time = 39.43 secondes

Train loss 0.058479749631784 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.66 secondes

Val loss 1.480094313621521 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 28/40
time = 39.10 secondes

Train loss 0.03546970267427352 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.66 secondes

Val loss 1.211783453822136 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 29/40
time = 39.94 secondes

Train loss 0.029163341590681353 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.69 secondes

Val loss 1.212589979171753 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 30/40
time = 39.15 secondes

Train loss 0.0854684688926103 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.69 secondes

Val loss 1.1489645950496197 accuracy 0.859375 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}
 
----------
Epoch 31/40
time = 39.39 secondes

Train loss 0.002054126547150328 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.491396278142929 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 32/40
time = 39.39 secondes

Train loss 0.007782544322474154 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.72 secondes

Val loss 1.385601282119751 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 33/40
time = 39.82 secondes

Train loss 0.04436210980114111 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.70 secondes

Val loss 1.7520918399095535 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 34/40
time = 39.50 secondes

Train loss 0.005973262763291132 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.74 secondes

Val loss 1.2969504296779633 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 35/40
time = 39.34 secondes

Train loss 0.008765572931610443 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.4453338533639908 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 39.73 secondes

Train loss 0.0016910390353807475 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7241961658000946 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 37/40
time = 39.59 secondes

Train loss 2.5416877234061815e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.71 secondes

Val loss 1.9218558967113495 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 38/40
time = 39.66 secondes

Train loss 5.992705182782657e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.70 secondes

Val loss 1.9247906506061554 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 39/40
time = 39.28 secondes

Train loss 0.006033159507668725 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.69 secondes

Val loss 1.7615353465080261 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 40/40
time = 38.57 secondes

Train loss 2.162405957223558e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.69 secondes

Val loss 1.6307250559329987 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 30 macro_avg {'precision': 0.8567937438905181, 'recall': 0.8694331983805668, 'f1-score': 0.8576723498888065, 'support': 64} weighted_avg {'precision': 0.8722812805474096, 'recall': 0.859375, 'f1-score': 0.8605911786508524, 'support': 64}

average train time 39.486334425210956

average val time 1.684338140487671
 
time = 1.96 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_3
----------
Epoch 1/40
time = 51.84 secondes

Train loss 0.6486877943530227 accuracy 0.6143410801887512 macro_avg {'precision': 0.4509419152276295, 'recall': 0.4898411976008972, 'f1-score': 0.41137422827563674, 'support': 516} weighted_avg {'precision': 0.5009476957151376, 'recall': 0.6143410852713178, 'f1-score': 0.5064940094419297, 'support': 516}
 
time = 2.20 secondes

Val loss 0.5979201197624207 accuracy 0.625 macro_avg {'precision': 0.8064516129032258, 'recall': 0.5384615384615384, 'f1-score': 0.45142857142857146, 'support': 64} weighted_avg {'precision': 0.7701612903225806, 'recall': 0.625, 'f1-score': 0.5092857142857142, 'support': 64}
 
----------
Epoch 2/40
time = 49.31 secondes

Train loss 0.4691522992921598 accuracy 0.786821722984314 macro_avg {'precision': 0.7716863052708763, 'recall': 0.758968190757928, 'f1-score': 0.7641446712319659, 'support': 516} weighted_avg {'precision': 0.7837606132600796, 'recall': 0.7868217054263565, 'f1-score': 0.7842705390794876, 'support': 516}
 
time = 2.02 secondes

Val loss 0.39991746842861176 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 3/40
time = 49.81 secondes

Train loss 0.31748748356194206 accuracy 0.8779069781303406 macro_avg {'precision': 0.867637519460301, 'recall': 0.8684800806202558, 'f1-score': 0.868054794520548, 'support': 516} weighted_avg {'precision': 0.878053683276813, 'recall': 0.877906976744186, 'f1-score': 0.8779768503769778, 'support': 516}
 
time = 2.03 secondes

Val loss 0.3959294334053993 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 4/40
time = 49.14 secondes

Train loss 0.25548440771120967 accuracy 0.9186046719551086 macro_avg {'precision': 0.9099600571071079, 'recall': 0.915397493620272, 'f1-score': 0.912528253148208, 'support': 516} weighted_avg {'precision': 0.9194026136910076, 'recall': 0.9186046511627907, 'f1-score': 0.9188727275457869, 'support': 516}
 
time = 1.96 secondes

Val loss 0.5732985287904739 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 5/40
time = 49.82 secondes

Train loss 0.2367099921473048 accuracy 0.9166666865348816 macro_avg {'precision': 0.911874054089623, 'recall': 0.9069534970661379, 'f1-score': 0.9093060613864057, 'support': 516} weighted_avg {'precision': 0.9163513632076506, 'recall': 0.9166666666666666, 'f1-score': 0.9164163059428482, 'support': 516}
 
time = 2.01 secondes

Val loss 0.46788015216588974 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 6/40
time = 49.29 secondes

Train loss 0.20905013297769157 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 2.02 secondes

Val loss 0.6150469854474068 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 7/40
time = 49.28 secondes

Train loss 0.21290303792127155 accuracy 0.9205426573753357 macro_avg {'precision': 0.9152370350969093, 'recall': 0.9123010906490255, 'f1-score': 0.9137303195762363, 'support': 516} weighted_avg {'precision': 0.9203275437442389, 'recall': 0.9205426356589147, 'f1-score': 0.9204016911882387, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4583413898944855 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 8/40
time = 49.70 secondes

Train loss 0.10660008495236098 accuracy 0.961240291595459 macro_avg {'precision': 0.9601240584847142, 'recall': 0.9557563837914276, 'f1-score': 0.9578672327917039, 'support': 516} weighted_avg {'precision': 0.9611807766592364, 'recall': 0.9612403100775194, 'f1-score': 0.9611478970011955, 'support': 516}
 
time = 2.00 secondes

Val loss 2.035320967435837 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 9/40
time = 49.51 secondes

Train loss 0.2722540305553456 accuracy 0.9263566136360168 macro_avg {'precision': 0.927417044439576, 'recall': 0.9122442013555906, 'f1-score': 0.9189484126984127, 'support': 516} weighted_avg {'precision': 0.926531252371899, 'recall': 0.9263565891472868, 'f1-score': 0.9256917527993109, 'support': 516}
 
time = 2.03 secondes

Val loss 0.7877931296825409 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 10/40
time = 49.32 secondes

Train loss 0.10951718830267165 accuracy 0.9709302186965942 macro_avg {'precision': 0.9654383044118588, 'recall': 0.972587487606261, 'f1-score': 0.9687942233027322, 'support': 516} weighted_avg {'precision': 0.9715309121991389, 'recall': 0.9709302325581395, 'f1-score': 0.9710409885936052, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1239083036780357 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 11/40
time = 49.38 secondes

Train loss 0.3974452090827099 accuracy 0.8972868323326111 macro_avg {'precision': 0.8858544303797469, 'recall': 0.8963720884872324, 'f1-score': 0.8904392764857881, 'support': 516} weighted_avg {'precision': 0.8998492542439407, 'recall': 0.8972868217054264, 'f1-score': 0.897976884401979, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1260405629873276 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 12/40
time = 49.93 secondes

Train loss 0.07728660404664521 accuracy 0.9844961166381836 macro_avg {'precision': 0.9832257854786015, 'recall': 0.9832257854786015, 'f1-score': 0.9832257854786015, 'support': 516} weighted_avg {'precision': 0.9844961240310077, 'recall': 0.9844961240310077, 'f1-score': 0.9844961240310077, 'support': 516}
 
time = 2.04 secondes

Val loss 2.0661981403827667 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 13/40
time = 49.40 secondes

Train loss 0.3645772796907378 accuracy 0.8914728760719299 macro_avg {'precision': 0.8814659685863875, 'recall': 0.8848885782552867, 'f1-score': 0.8831124702684335, 'support': 516} weighted_avg {'precision': 0.8920702950606761, 'recall': 0.8914728682170543, 'f1-score': 0.8917151985923766, 'support': 516}
 
time = 2.04 secondes

Val loss 1.3463889509439468 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 14/40
time = 49.81 secondes

Train loss 0.3945751283846965 accuracy 0.9186046719551086 macro_avg {'precision': 0.9175534143276078, 'recall': 0.9050111340474294, 'f1-score': 0.9106456666941536, 'support': 516} weighted_avg {'precision': 0.9184526651143305, 'recall': 0.9186046511627907, 'f1-score': 0.917984470554845, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1533467867666332 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 15/40
time = 49.13 secondes

Train loss 0.25747944358700997 accuracy 0.9341084957122803 macro_avg {'precision': 0.9403599677435959, 'recall': 0.9171691887586756, 'f1-score': 0.9269036548172591, 'support': 516} weighted_avg {'precision': 0.9354824701233901, 'recall': 0.9341085271317829, 'f1-score': 0.9332190367225826, 'support': 516}
 
time = 2.03 secondes

Val loss 1.3853503987193108 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 16/40
time = 49.44 secondes

Train loss 0.022861844025266528 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.03 secondes

Val loss 1.1197438091039658 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 17/40
time = 49.82 secondes

Train loss 0.04687935988179313 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8437841534614563 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 18/40
time = 49.33 secondes

Train loss 0.10288021465010277 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.01 secondes

Val loss 0.7980420787353069 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 19/40
time = 48.99 secondes

Train loss 0.10282200488290982 accuracy 0.9825581312179565 macro_avg {'precision': 0.9840264525893269, 'recall': 0.9782439087820816, 'f1-score': 0.9810175477320384, 'support': 516} weighted_avg {'precision': 0.9826547390779392, 'recall': 0.9825581395348837, 'f1-score': 0.9825057384531543, 'support': 516}
 
time = 2.02 secondes

Val loss 2.40987628698349 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 20/40
time = 49.44 secondes

Train loss 0.3520119644893963 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 2.04 secondes

Val loss 1.120570670813322 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 21/40
time = 49.33 secondes

Train loss 0.22011452283428903 accuracy 0.963178277015686 macro_avg {'precision': 0.9542797888386123, 'recall': 0.9699705801082522, 'f1-score': 0.9608827319844713, 'support': 516} weighted_avg {'precision': 0.9659796760087458, 'recall': 0.9631782945736435, 'f1-score': 0.9634904910857709, 'support': 516}
 
time = 2.04 secondes

Val loss 1.5293855369091034 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 22/40
time = 49.87 secondes

Train loss 0.08344018792316395 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.03 secondes

Val loss 1.5211723297834396 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 23/40
time = 49.11 secondes

Train loss 0.07256370858301649 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.04 secondes

Val loss 2.6433530747890472 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 24/40
time = 49.44 secondes

Train loss 0.23891332999075088 accuracy 0.961240291595459 macro_avg {'precision': 0.9637518124093796, 'recall': 0.9522942639338134, 'f1-score': 0.957557412647233, 'support': 516} weighted_avg {'precision': 0.9615503720937983, 'recall': 0.9612403100775194, 'f1-score': 0.9609980141939479, 'support': 516}
 
time = 2.03 secondes

Val loss 2.18736831843853 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 25/40
time = 49.14 secondes

Train loss 0.21482251915288295 accuracy 0.9651162624359131 macro_avg {'precision': 0.9740634005763689, 'recall': 0.9518716577540107, 'f1-score': 0.9614054916561399, 'support': 516} weighted_avg {'precision': 0.9669258092621138, 'recall': 0.9651162790697675, 'f1-score': 0.9646988154857342, 'support': 516}
 
time = 2.03 secondes

Val loss 1.7550849658018706 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 26/40
time = 49.84 secondes

Train loss 0.0743913915759935 accuracy 0.9844961166381836 macro_avg {'precision': 0.985526510116674, 'recall': 0.9809177055735254, 'f1-score': 0.9831468931166816, 'support': 516} weighted_avg {'precision': 0.9845510779555766, 'recall': 0.9844961240310077, 'f1-score': 0.9844591588004783, 'support': 516}
 
time = 2.04 secondes

Val loss 1.7952998988330364 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 27/40
time = 49.26 secondes

Train loss 0.2868609506071648 accuracy 0.9651162624359131 macro_avg {'precision': 0.9560975609756097, 'recall': 0.9726443768996961, 'f1-score': 0.9629783163265306, 'support': 516} weighted_avg {'precision': 0.9681792399319343, 'recall': 0.9651162790697675, 'f1-score': 0.9654266285002373, 'support': 516}
 
time = 2.02 secondes

Val loss 2.4015322029590607 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 28/40
time = 49.68 secondes

Train loss 0.2844589106922892 accuracy 0.9554263353347778 macro_avg {'precision': 0.9470886075949367, 'recall': 0.9592753929424769, 'f1-score': 0.9524547803617571, 'support': 516} weighted_avg {'precision': 0.9572951623981946, 'recall': 0.9554263565891473, 'f1-score': 0.9557258177593495, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8804422970861197 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 29/40
time = 49.20 secondes

Train loss 0.01602347217119655 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4475029289787926 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 30/40
time = 49.55 secondes

Train loss 0.013532362230872615 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.02 secondes

Val loss 1.7765202969312668 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 31/40
time = 49.20 secondes

Train loss 0.03948413165882371 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.02 secondes

Val loss 1.6477696597576141 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 32/40
time = 50.01 secondes

Train loss 0.0541186015561283 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.03 secondes

Val loss 1.772340603172779 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 49.78 secondes

Train loss 0.1882956041396083 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8007608056650497 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 34/40
time = 49.46 secondes

Train loss 0.03387061659326939 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.03 secondes

Val loss 1.2410447392612696 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 35/40
time = 49.28 secondes

Train loss 0.00021999320564315315 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.914048746228218 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 36/40
time = 49.29 secondes

Train loss 0.08668372912176313 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 2.02 secondes

Val loss 2.357335388660431 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 37/40
time = 49.71 secondes

Train loss 0.006075638539738121 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.02 secondes

Val loss 2.060155540704727 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 38/40
time = 49.65 secondes

Train loss 1.9690951899754122e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.8338401913642883 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 49.32 secondes

Train loss 0.018500097940197906 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.6090283244848251 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 40/40
time = 49.02 secondes

Train loss 0.014089168152278227 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4111582329496741 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 18 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}

average train time 49.5204231441021

average val time 2.030049794912338
 
time = 2.28 secondes

test_accuracy 0.9846153855323792 macro_avg {'precision': 0.9871794871794872, 'recall': 0.9814814814814814, 'f1-score': 0.9840725312423425, 'support': 65} weighted_avg {'precision': 0.9850098619329388, 'recall': 0.9846153846153847, 'f1-score': 0.9845701468342976, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_3
----------
Epoch 1/40
time = 99.99 secondes

Train loss 0.6238068595077052 accuracy 0.5968992114067078 macro_avg {'precision': 0.5209113682452582, 'recall': 0.5142467044845017, 'f1-score': 0.49910394265232977, 'support': 516} weighted_avg {'precision': 0.5552753033779141, 'recall': 0.5968992248062015, 'f1-score': 0.5600115306604428, 'support': 516}
 
time = 2.64 secondes

Val loss 0.7094335407018661 accuracy 0.6875 macro_avg {'precision': 0.7678571428571428, 'recall': 0.6214574898785425, 'f1-score': 0.5994993742177722, 'support': 64} weighted_avg {'precision': 0.7477678571428572, 'recall': 0.6875, 'f1-score': 0.6346996245306633, 'support': 64}
 
----------
Epoch 2/40
time = 100.02 secondes

Train loss 0.3807537506024043 accuracy 0.854651153087616 macro_avg {'precision': 0.8458556149732621, 'recall': 0.8363945191229296, 'f1-score': 0.8406404032168402, 'support': 516} weighted_avg {'precision': 0.8534712722298221, 'recall': 0.8546511627906976, 'f1-score': 0.8536438532788516, 'support': 516}
 
time = 2.45 secondes

Val loss 0.4683801904320717 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 3/40
time = 99.91 secondes

Train loss 0.2442454183191964 accuracy 0.9127907156944275 macro_avg {'precision': 0.905293201868189, 'recall': 0.9062220632934024, 'f1-score': 0.9057534246575343, 'support': 516} weighted_avg {'precision': 0.9128978047573648, 'recall': 0.9127906976744186, 'f1-score': 0.912840607412127, 'support': 516}
 
time = 2.47 secondes

Val loss 0.578301414847374 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7226720647773279, 'f1-score': 0.7285259809119831, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.7428419936373276, 'support': 64}
 
----------
Epoch 4/40
time = 99.74 secondes

Train loss 0.14131592116741973 accuracy 0.9534883499145508 macro_avg {'precision': 0.9496773564358045, 'recall': 0.9496773564358045, 'f1-score': 0.9496773564358045, 'support': 516} weighted_avg {'precision': 0.9534883720930233, 'recall': 0.9534883720930233, 'f1-score': 0.9534883720930233, 'support': 516}
 
time = 2.34 secondes

Val loss 0.7308817803859711 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 5/40
time = 99.88 secondes

Train loss 0.327707010014406 accuracy 0.9244186282157898 macro_avg {'precision': 0.9246319822544868, 'recall': 0.9107244445166849, 'f1-score': 0.9169222766697904, 'support': 516} weighted_avg {'precision': 0.9244516273754867, 'recall': 0.9244186046511628, 'f1-score': 0.9237898803688541, 'support': 516}
 
time = 2.44 secondes

Val loss 1.256316602230072 accuracy 0.703125 macro_avg {'precision': 0.7003910068426198, 'recall': 0.7074898785425101, 'f1-score': 0.6995305164319249, 'support': 64} weighted_avg {'precision': 0.7167949657869013, 'recall': 0.703125, 'f1-score': 0.7056924882629108, 'support': 64}
 
----------
Epoch 6/40
time = 99.75 secondes

Train loss 0.25199151482207305 accuracy 0.9244186282157898 macro_avg {'precision': 0.9153380102040816, 'recall': 0.9234188839946036, 'f1-score': 0.9190399369184163, 'support': 516} weighted_avg {'precision': 0.9257367554579972, 'recall': 0.9244186046511628, 'f1-score': 0.9247825746481155, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2854207456111908 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 7/40
time = 99.79 secondes

Train loss 0.1330003262652705 accuracy 0.9651162624359131 macro_avg {'precision': 0.9613125576428329, 'recall': 0.9634120572793915, 'f1-score': 0.962344317592112, 'support': 516} weighted_avg {'precision': 0.9652265318647509, 'recall': 0.9651162790697675, 'f1-score': 0.9651558785194481, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5949057340621948 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 8/40
time = 100.32 secondes

Train loss 0.3521739606988955 accuracy 0.9127907156944275 macro_avg {'precision': 0.9076297953543462, 'recall': 0.9027599434357882, 'f1-score': 0.9050877386601921, 'support': 516} weighted_avg {'precision': 0.9124511646270455, 'recall': 0.9127906976744186, 'f1-score': 0.9125286922657715, 'support': 516}
 
time = 2.45 secondes

Val loss 1.657418131828308 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 9/40
time = 99.89 secondes

Train loss 0.13981471535887316 accuracy 0.963178277015686 macro_avg {'precision': 0.9665775401069518, 'recall': 0.9538140207727192, 'f1-score': 0.9596289021482662, 'support': 516} weighted_avg {'precision': 0.9636342909256727, 'recall': 0.9631782945736435, 'f1-score': 0.9629231094973091, 'support': 516}
 
time = 2.45 secondes

Val loss 1.8971561938524246 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 10/40
time = 99.90 secondes

Train loss 0.3259087157520381 accuracy 0.9205426573753357 macro_avg {'precision': 0.9094425305355465, 'recall': 0.9249955301269444, 'f1-score': 0.9157557729754269, 'support': 516} weighted_avg {'precision': 0.9245984433001454, 'recall': 0.9205426356589147, 'f1-score': 0.9212820697319739, 'support': 516}
 
time = 2.43 secondes

Val loss 1.4745250046253204 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 11/40
time = 99.82 secondes

Train loss 0.16115679025207294 accuracy 0.9689922332763672 macro_avg {'precision': 0.9630002396357537, 'recall': 0.9710677307673553, 'f1-score': 0.9667498993153444, 'support': 516} weighted_avg {'precision': 0.9697531380209059, 'recall': 0.9689922480620154, 'f1-score': 0.9691261196289811, 'support': 516}
 
time = 2.46 secondes

Val loss 2.06557434797287 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 12/40
time = 99.73 secondes

Train loss 0.1176640877908512 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 2.45 secondes

Val loss 1.3568861335515976 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 13/40
time = 99.83 secondes

Train loss 0.15563670639698324 accuracy 0.9728682041168213 macro_avg {'precision': 0.9651741293532339, 'recall': 0.9787234042553192, 'f1-score': 0.9710891976692066, 'support': 516} weighted_avg {'precision': 0.9747579929808323, 'recall': 0.9728682170542635, 'f1-score': 0.9730627972995041, 'support': 516}
 
time = 2.44 secondes

Val loss 2.0606918931007385 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 14/40
time = 99.84 secondes

Train loss 0.22614133693709984 accuracy 0.9573643207550049 macro_avg {'precision': 0.9538709100661541, 'recall': 0.9538709100661541, 'f1-score': 0.9538709100661541, 'support': 516} weighted_avg {'precision': 0.9573643410852714, 'recall': 0.9573643410852714, 'f1-score': 0.9573643410852714, 'support': 516}
 
time = 2.44 secondes

Val loss 1.6951093971729279 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 15/40
time = 99.84 secondes

Train loss 0.37929273710478534 accuracy 0.9244186282157898 macro_avg {'precision': 0.9144303797468354, 'recall': 0.9257269638996799, 'f1-score': 0.9193798449612404, 'support': 516} weighted_avg {'precision': 0.9266573447159259, 'recall': 0.9244186046511628, 'f1-score': 0.9249263866354186, 'support': 516}
 
time = 2.46 secondes

Val loss 1.56599660217762 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 16/40
time = 99.96 secondes

Train loss 0.16085558425490462 accuracy 0.9573643207550049 macro_avg {'precision': 0.9480040781115207, 'recall': 0.9642572696389968, 'f1-score': 0.9547512755102041, 'support': 516} weighted_avg {'precision': 0.9605432983216394, 'recall': 0.9573643410852714, 'f1-score': 0.9577436570558456, 'support': 516}
 
time = 2.45 secondes

Val loss 1.3545139729976654 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 17/40
time = 99.87 secondes

Train loss 0.8331401848179556 accuracy 0.8682170510292053 macro_avg {'precision': 0.9143576826196473, 'recall': 0.8181818181818181, 'f1-score': 0.8420569329660239, 'support': 516} weighted_avg {'precision': 0.8907894479917208, 'recall': 0.8682170542635659, 'f1-score': 0.8597461578434095, 'support': 516}
 
time = 2.46 secondes

Val loss 1.2562291473150253 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 18/40
time = 99.96 secondes

Train loss 0.3037922615392635 accuracy 0.9496123790740967 macro_avg {'precision': 0.9484950935928094, 'recall': 0.9420216829478407, 'f1-score': 0.9450955997904662, 'support': 516} weighted_avg {'precision': 0.9495253400222323, 'recall': 0.9496124031007752, 'f1-score': 0.9494292894530599, 'support': 516}
 
time = 2.45 secondes

Val loss 2.1254621744155884 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 19/40
time = 100.27 secondes

Train loss 0.06767933745096812 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.45 secondes

Val loss 2.254811465740204 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 20/40
time = 100.00 secondes

Train loss 0.17478690463273475 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 2.45 secondes

Val loss 2.140621393918991 accuracy 0.6875 macro_avg {'precision': 0.6875, 'recall': 0.6943319838056681, 'f1-score': 0.6847290640394088, 'support': 64} weighted_avg {'precision': 0.705078125, 'recall': 0.6875, 'f1-score': 0.6902709359605911, 'support': 64}
 
----------
Epoch 21/40
time = 99.83 secondes

Train loss 0.192142576244695 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.45 secondes

Val loss 1.449165627360344 accuracy 0.765625 macro_avg {'precision': 0.7572572572572573, 'recall': 0.7601214574898785, 'f1-score': 0.7584905660377359, 'support': 64} weighted_avg {'precision': 0.7672985485485486, 'recall': 0.765625, 'f1-score': 0.7662735849056603, 'support': 64}
 
----------
Epoch 22/40
time = 99.86 secondes

Train loss 0.03130004748902249 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.45 secondes

Val loss 1.414448767900467 accuracy 0.734375 macro_avg {'precision': 0.7316715542521994, 'recall': 0.7398785425101215, 'f1-score': 0.7311588831233011, 'support': 64} weighted_avg {'precision': 0.747892228739003, 'recall': 0.734375, 'f1-score': 0.7366722263404991, 'support': 64}
 
----------
Epoch 23/40
time = 100.02 secondes

Train loss 0.12439228223515922 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 2.45 secondes

Val loss 1.4911992996931076 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 24/40
time = 99.83 secondes

Train loss 0.06391137393956976 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.44 secondes

Val loss 1.579172044992447 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 25/40
time = 99.98 secondes

Train loss 0.037284239662271415 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 2.44 secondes

Val loss 1.5421727299690247 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 26/40
time = 99.91 secondes

Train loss 0.07884744906473454 accuracy 0.9786821603775024 macro_avg {'precision': 0.9722222222222222, 'recall': 0.9832826747720365, 'f1-score': 0.9772135129167587, 'support': 516} weighted_avg {'precision': 0.9798664944013781, 'recall': 0.9786821705426356, 'f1-score': 0.9788054929387017, 'support': 516}
 
time = 2.45 secondes

Val loss 1.1913505867123604 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 99.93 secondes

Train loss 0.05063684487443728 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.44 secondes

Val loss 1.2180385813117027 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 28/40
time = 100.23 secondes

Train loss 0.04535529875967327 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.44 secondes

Val loss 1.4883593916893005 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 29/40
time = 100.04 secondes

Train loss 0.12517923017863228 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 2.45 secondes

Val loss 1.6501441895961761 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 30/40
time = 100.00 secondes

Train loss 0.004819680489273389 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.31 secondes

Val loss 1.775810718536377 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 31/40
time = 99.74 secondes

Train loss 0.009513069953148564 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.45 secondes

Val loss 1.9464571177959442 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 32/40
time = 99.90 secondes

Train loss 0.07895299011827527 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.45 secondes

Val loss 2.6631231009960175 accuracy 0.71875 macro_avg {'precision': 0.7341269841269842, 'recall': 0.7388663967611335, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7571924603174602, 'recall': 0.71875, 'f1-score': 0.7201246334310851, 'support': 64}
 
----------
Epoch 33/40
time = 99.95 secondes

Train loss 0.050980795502916655 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.45 secondes

Val loss 1.9978840053081512 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 34/40
time = 99.83 secondes

Train loss 0.012836514831592054 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.29 secondes

Val loss 1.896503061056137 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 35/40
time = 99.67 secondes

Train loss 0.026611772760037584 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.44 secondes

Val loss 1.8002724051475525 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 36/40
time = 99.83 secondes

Train loss 0.037592361842502156 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 2.35 secondes

Val loss 1.459074206650257 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 37/40
time = 99.62 secondes

Train loss 5.995733072543799e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.48 secondes

Val loss 1.5881338119506836 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 38/40
time = 99.81 secondes

Train loss 0.00016996820274719292 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.29 secondes

Val loss 1.7582922279834747 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 39/40
time = 99.92 secondes

Train loss 9.83381805505787e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.43 secondes

Val loss 1.659583866596222 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 40/40
time = 100.08 secondes

Train loss 5.534277900578948e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.35 secondes

Val loss 1.6444981396198273 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 27 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 99.90668396949768

average val time 2.4340863645076753
 
time = 2.69 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 73.79 GiB already allocated; 109.62 MiB free; 77.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 72.41 GiB already allocated; 261.62 MiB free; 76.92 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_3
----------
Epoch 1/40
time = 638.00 secondes

Train loss 1.3663246573608374 accuracy 0.6325869560241699 macro_avg {'precision': 0.6219244107976625, 'recall': 0.6170472686856687, 'f1-score': 0.6078706013437868, 'support': 10182} weighted_avg {'precision': 0.6337523389772152, 'recall': 0.6325869180907484, 'f1-score': 0.6227423153518827, 'support': 10182}
 
time = 23.36 secondes

Val loss 0.762900624476688 accuracy 0.7623674869537354 macro_avg {'precision': 0.7427393243214512, 'recall': 0.7587799968988177, 'f1-score': 0.7424239627907878, 'support': 1132} weighted_avg {'precision': 0.7545673406816037, 'recall': 0.7623674911660777, 'f1-score': 0.7492858166334991, 'support': 1132}
 
----------
Epoch 2/40
time = 637.45 secondes

Train loss 0.563592788785275 accuracy 0.8302887678146362 macro_avg {'precision': 0.8191227035486349, 'recall': 0.819320992482292, 'f1-score': 0.8165775216180098, 'support': 10182} weighted_avg {'precision': 0.8268271887479978, 'recall': 0.8302887448438421, 'f1-score': 0.8266648263252249, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.6512423467258333 accuracy 0.814487636089325 macro_avg {'precision': 0.8238572083724485, 'recall': 0.8126163380777243, 'f1-score': 0.811000466084437, 'support': 1132} weighted_avg {'precision': 0.8250007614819014, 'recall': 0.8144876325088339, 'f1-score': 0.8130356318910162, 'support': 1132}
 
----------
Epoch 3/40
time = 638.02 secondes

Train loss 0.32695392700967785 accuracy 0.9046356678009033 macro_avg {'precision': 0.8995273967667863, 'recall': 0.8990992892075672, 'f1-score': 0.8991204360775125, 'support': 10182} weighted_avg {'precision': 0.9045908271970372, 'recall': 0.9046356315065802, 'f1-score': 0.9044374404272355, 'support': 10182}
 
time = 23.43 secondes

Val loss 0.5586402537957044 accuracy 0.8595406413078308 macro_avg {'precision': 0.869598836863771, 'recall': 0.8596240134848164, 'f1-score': 0.8601706097605486, 'support': 1132} weighted_avg {'precision': 0.8706505069738429, 'recall': 0.8595406360424028, 'f1-score': 0.8608130451510376, 'support': 1132}
 
----------
Epoch 4/40
time = 637.11 secondes

Train loss 0.21398477004387736 accuracy 0.9407778978347778 macro_avg {'precision': 0.9380647868845735, 'recall': 0.9379500651731524, 'f1-score': 0.937867777514807, 'support': 10182} weighted_avg {'precision': 0.9413900272552947, 'recall': 0.940777843252799, 'f1-score': 0.9409557104050408, 'support': 10182}
 
time = 23.59 secondes

Val loss 0.6368536510124383 accuracy 0.8613074421882629 macro_avg {'precision': 0.8677580979001668, 'recall': 0.8658578441706956, 'f1-score': 0.8639135776581528, 'support': 1132} weighted_avg {'precision': 0.8689118496275623, 'recall': 0.8613074204946997, 'f1-score': 0.8621068013154227, 'support': 1132}
 
----------
Epoch 5/40
time = 636.63 secondes

Train loss 0.18426567417192252 accuracy 0.9564918875694275 macro_avg {'precision': 0.9552623781662699, 'recall': 0.9551406340235579, 'f1-score': 0.9550926857185222, 'support': 10182} weighted_avg {'precision': 0.9567063612106648, 'recall': 0.9564918483598507, 'f1-score': 0.9564883829032563, 'support': 10182}
 
time = 23.49 secondes

Val loss 0.6597389964334351 accuracy 0.8595406413078308 macro_avg {'precision': 0.8672029314374579, 'recall': 0.8580462902489551, 'f1-score': 0.8576391454776757, 'support': 1132} weighted_avg {'precision': 0.8688844325163659, 'recall': 0.8595406360424028, 'f1-score': 0.8598571598976217, 'support': 1132}
 
----------
Epoch 6/40
time = 637.02 secondes

Train loss 0.16554490965206228 accuracy 0.9592418074607849 macro_avg {'precision': 0.9579309787524076, 'recall': 0.9575988977724945, 'f1-score': 0.9576898593147767, 'support': 10182} weighted_avg {'precision': 0.9593158898115484, 'recall': 0.9592417992535848, 'f1-score': 0.959210357212899, 'support': 10182}
 
time = 23.47 secondes

Val loss 0.7595683354654835 accuracy 0.851590096950531 macro_avg {'precision': 0.8586378264383854, 'recall': 0.854059343087305, 'f1-score': 0.853223658741577, 'support': 1132} weighted_avg {'precision': 0.8607404500018647, 'recall': 0.8515901060070671, 'f1-score': 0.8530441476303228, 'support': 1132}
 
----------
Epoch 7/40
time = 637.28 secondes

Train loss 0.13791962522160617 accuracy 0.9673934578895569 macro_avg {'precision': 0.9672271292786141, 'recall': 0.9672014033027503, 'f1-score': 0.9671962191372184, 'support': 10182} weighted_avg {'precision': 0.9674322851394486, 'recall': 0.9673934394028678, 'f1-score': 0.9673950345087149, 'support': 10182}
 
time = 23.71 secondes

Val loss 0.8368696063465084 accuracy 0.8586572408676147 macro_avg {'precision': 0.8664758942302789, 'recall': 0.85985926163818, 'f1-score': 0.859494706189105, 'support': 1132} weighted_avg {'precision': 0.8650061825320098, 'recall': 0.8586572438162544, 'f1-score': 0.8579610785275957, 'support': 1132}
 
----------
Epoch 8/40
time = 637.01 secondes

Train loss 0.13647122770193137 accuracy 0.9705362915992737 macro_avg {'precision': 0.9692980920410171, 'recall': 0.96958233909078, 'f1-score': 0.9693717382302708, 'support': 10182} weighted_avg {'precision': 0.9706296495104269, 'recall': 0.9705362404242781, 'f1-score': 0.970514473554642, 'support': 10182}
 
time = 23.42 secondes

Val loss 0.9310339822878235 accuracy 0.8524734973907471 macro_avg {'precision': 0.8605339598944765, 'recall': 0.8543177950749812, 'f1-score': 0.8542081170396892, 'support': 1132} weighted_avg {'precision': 0.8640416383134301, 'recall': 0.8524734982332155, 'f1-score': 0.8549982809805515, 'support': 1132}
 
----------
Epoch 9/40
time = 637.81 secondes

Train loss 0.1209269448156886 accuracy 0.9720094799995422 macro_avg {'precision': 0.9704399378770114, 'recall': 0.9705719035623815, 'f1-score': 0.9704507646867497, 'support': 10182} weighted_avg {'precision': 0.972159297509647, 'recall': 0.9720094284030643, 'f1-score': 0.9720303270470257, 'support': 10182}
 
time = 23.25 secondes

Val loss 0.8848030001698161 accuracy 0.8630741834640503 macro_avg {'precision': 0.8778548724966374, 'recall': 0.8670558069132488, 'f1-score': 0.8677762548458647, 'support': 1132} weighted_avg {'precision': 0.8776602017475639, 'recall': 0.8630742049469965, 'f1-score': 0.8652301323760689, 'support': 1132}
 
----------
Epoch 10/40
time = 637.36 secondes

Train loss 0.10729890415294013 accuracy 0.9780986309051514 macro_avg {'precision': 0.9779193309665043, 'recall': 0.9777973624573111, 'f1-score': 0.977827104067179, 'support': 10182} weighted_avg {'precision': 0.9781544695816492, 'recall': 0.9780986053820467, 'f1-score': 0.9780962318092582, 'support': 10182}
 
time = 23.47 secondes

Val loss 0.8722038868540885 accuracy 0.8683745861053467 macro_avg {'precision': 0.8788568575968252, 'recall': 0.8671364271546309, 'f1-score': 0.869171585900081, 'support': 1132} weighted_avg {'precision': 0.8792356518142838, 'recall': 0.8683745583038869, 'f1-score': 0.8701031408361998, 'support': 1132}
 
----------
Epoch 11/40
time = 636.30 secondes

Train loss 0.10940588439480851 accuracy 0.9786878824234009 macro_avg {'precision': 0.9780814467987001, 'recall': 0.9779639099711377, 'f1-score': 0.9780055610294751, 'support': 10182} weighted_avg {'precision': 0.9787088878596661, 'recall': 0.9786878805735612, 'f1-score': 0.978680910770696, 'support': 10182}
 
time = 23.66 secondes

Val loss 0.9348058769246563 accuracy 0.8657243847846985 macro_avg {'precision': 0.8769338370149541, 'recall': 0.8700992332595524, 'f1-score': 0.8686234488996428, 'support': 1132} weighted_avg {'precision': 0.8796644890862196, 'recall': 0.8657243816254417, 'f1-score': 0.867618342157461, 'support': 1132}
 
----------
Epoch 12/40
time = 636.71 secondes

Train loss 0.09386073000375178 accuracy 0.9812414646148682 macro_avg {'precision': 0.9811612543498638, 'recall': 0.9812501416462138, 'f1-score': 0.9811917594943853, 'support': 10182} weighted_avg {'precision': 0.9812658795116844, 'recall': 0.981241406403457, 'f1-score': 0.9812392852116406, 'support': 10182}
 
time = 23.43 secondes

Val loss 1.0074244355083966 accuracy 0.8586572408676147 macro_avg {'precision': 0.872185240022789, 'recall': 0.8631492566248147, 'f1-score': 0.8632551564976607, 'support': 1132} weighted_avg {'precision': 0.8718726443984014, 'recall': 0.8586572438162544, 'f1-score': 0.8604772716864025, 'support': 1132}
 
----------
Epoch 13/40
time = 636.91 secondes

Train loss 0.10075636638830646 accuracy 0.9798664450645447 macro_avg {'precision': 0.9796750542320316, 'recall': 0.9796406875009149, 'f1-score': 0.9796403203920201, 'support': 10182} weighted_avg {'precision': 0.9798598223214958, 'recall': 0.9798664309565901, 'f1-score': 0.9798452240629429, 'support': 10182}
 
time = 23.61 secondes

Val loss 0.9302929794265393 accuracy 0.8763250708580017 macro_avg {'precision': 0.880630908503187, 'recall': 0.8734750806257987, 'f1-score': 0.8730069429766327, 'support': 1132} weighted_avg {'precision': 0.8811918202774581, 'recall': 0.8763250883392226, 'f1-score': 0.875442169641582, 'support': 1132}
 
----------
Epoch 14/40
time = 637.45 secondes

Train loss 0.10318995838618147 accuracy 0.9803575277328491 macro_avg {'precision': 0.9796778873852764, 'recall': 0.9795366863229077, 'f1-score': 0.9795621021809863, 'support': 10182} weighted_avg {'precision': 0.9804508050672154, 'recall': 0.9803574936161854, 'f1-score': 0.9803575462071188, 'support': 10182}
 
time = 23.57 secondes

Val loss 1.121814567818713 accuracy 0.8507066965103149 macro_avg {'precision': 0.8740645708422266, 'recall': 0.8606368873439371, 'f1-score': 0.857934320144252, 'support': 1132} weighted_avg {'precision': 0.8774266120280462, 'recall': 0.8507067137809188, 'f1-score': 0.8536186015748248, 'support': 1132}
 
----------
Epoch 15/40
time = 637.10 secondes

Train loss 0.0883775396230552 accuracy 0.983598530292511 macro_avg {'precision': 0.982806449057534, 'recall': 0.9830085166616079, 'f1-score': 0.9828939162936084, 'support': 10182} weighted_avg {'precision': 0.983628112619103, 'recall': 0.9835985071695148, 'f1-score': 0.9836002151163471, 'support': 10182}
 
time = 23.51 secondes

Val loss 0.9732307663907191 accuracy 0.8763250708580017 macro_avg {'precision': 0.8844522107499359, 'recall': 0.8794653722317586, 'f1-score': 0.8776232744891471, 'support': 1132} weighted_avg {'precision': 0.8869701546612044, 'recall': 0.8763250883392226, 'f1-score': 0.8776974238198063, 'support': 1132}
 
----------
Epoch 16/40
time = 636.83 secondes

Train loss 0.08620290426213277 accuracy 0.9842860102653503 macro_avg {'precision': 0.984054022815589, 'recall': 0.9838713323347607, 'f1-score': 0.983941529924793, 'support': 10182} weighted_avg {'precision': 0.9843368334369751, 'recall': 0.9842859948929483, 'f1-score': 0.9842902872901395, 'support': 10182}
 
time = 23.24 secondes

Val loss 1.1640953554437352 accuracy 0.8586572408676147 macro_avg {'precision': 0.8691509147580023, 'recall': 0.863157342370779, 'f1-score': 0.8599031157789083, 'support': 1132} weighted_avg {'precision': 0.8737715133486278, 'recall': 0.8586572438162544, 'f1-score': 0.859912336786686, 'support': 1132}
 
----------
Epoch 17/40
time = 637.15 secondes

Train loss 0.07094283069677565 accuracy 0.9865449070930481 macro_avg {'precision': 0.9864809166308401, 'recall': 0.9866936679070053, 'f1-score': 0.9865656091330773, 'support': 10182} weighted_avg {'precision': 0.9865981182459334, 'recall': 0.986544883127087, 'f1-score': 0.9865507009642781, 'support': 10182}
 
time = 23.46 secondes

Val loss 0.9409400241871276 accuracy 0.8674911856651306 macro_avg {'precision': 0.8724135832588222, 'recall': 0.8696738516627557, 'f1-score': 0.8658776450801906, 'support': 1132} weighted_avg {'precision': 0.8790047542537752, 'recall': 0.8674911660777385, 'f1-score': 0.8681226063699965, 'support': 1132}
 
----------
Epoch 18/40
time = 634.68 secondes

Train loss 0.09432760256091209 accuracy 0.9838931560516357 macro_avg {'precision': 0.9836639744262078, 'recall': 0.9835474946622924, 'f1-score': 0.9835846796426482, 'support': 10182} weighted_avg {'precision': 0.9839555212654151, 'recall': 0.983893144765272, 'f1-score': 0.9839029133631051, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.985599982247255 accuracy 0.8825088143348694 macro_avg {'precision': 0.8863868348623433, 'recall': 0.8855250270101495, 'f1-score': 0.8846196301908273, 'support': 1132} weighted_avg {'precision': 0.8867605620850304, 'recall': 0.8825088339222615, 'f1-score': 0.8833853263591473, 'support': 1132}
 
----------
Epoch 19/40
time = 636.14 secondes

Train loss 0.09220760208645258 accuracy 0.9841877818107605 macro_avg {'precision': 0.9838936151302727, 'recall': 0.9839993909340867, 'f1-score': 0.9839129192058993, 'support': 10182} weighted_avg {'precision': 0.98426122683466, 'recall': 0.9841877823610292, 'f1-score': 0.9841920362757236, 'support': 10182}
 
time = 23.31 secondes

Val loss 0.9537898464209128 accuracy 0.8851590156555176 macro_avg {'precision': 0.8935605359786635, 'recall': 0.8852478650174366, 'f1-score': 0.8861237132687846, 'support': 1132} weighted_avg {'precision': 0.8923998461183206, 'recall': 0.8851590106007067, 'f1-score': 0.885389934020102, 'support': 1132}
 
----------
Epoch 20/40
time = 637.62 secondes

Train loss 0.06259232405638007 accuracy 0.9890984296798706 macro_avg {'precision': 0.9891644355460324, 'recall': 0.989134886309029, 'f1-score': 0.9891365059928772, 'support': 10182} weighted_avg {'precision': 0.9891159145124775, 'recall': 0.9890984089569829, 'f1-score': 0.9890949718707163, 'support': 10182}
 
time = 23.34 secondes

Val loss 0.981840782632197 accuracy 0.8719081282615662 macro_avg {'precision': 0.878350288226644, 'recall': 0.8771534704426633, 'f1-score': 0.873694322949307, 'support': 1132} weighted_avg {'precision': 0.8823075709949886, 'recall': 0.8719081272084805, 'f1-score': 0.8727384917388045, 'support': 1132}
 
----------
Epoch 21/40
time = 636.59 secondes

Train loss 0.06055157946901653 accuracy 0.9879198670387268 macro_avg {'precision': 0.9882452157003503, 'recall': 0.9881061799432102, 'f1-score': 0.9881709455063078, 'support': 10182} weighted_avg {'precision': 0.9879392524132122, 'recall': 0.987919858573954, 'f1-score': 0.987925100222785, 'support': 10182}
 
time = 23.51 secondes

Val loss 0.939514422498895 accuracy 0.8816254734992981 macro_avg {'precision': 0.8805130721241923, 'recall': 0.8835582157830564, 'f1-score': 0.8806356197318607, 'support': 1132} weighted_avg {'precision': 0.8862793862258675, 'recall': 0.8816254416961131, 'f1-score': 0.8826892088436007, 'support': 1132}
 
----------
Epoch 22/40
time = 636.48 secondes

Train loss 0.07209791640583477 accuracy 0.9886073470115662 macro_avg {'precision': 0.9883832269159434, 'recall': 0.9886824295490086, 'f1-score': 0.9884867928848549, 'support': 10182} weighted_avg {'precision': 0.9886884466481543, 'recall': 0.9886073462973876, 'f1-score': 0.988601821041708, 'support': 10182}
 
time = 23.45 secondes

Val loss 0.9167201660473464 accuracy 0.8851590156555176 macro_avg {'precision': 0.8907347827453174, 'recall': 0.8878301572688752, 'f1-score': 0.8868574865345744, 'support': 1132} weighted_avg {'precision': 0.8911218696269461, 'recall': 0.8851590106007067, 'f1-score': 0.8854039579675784, 'support': 1132}
 
----------
Epoch 23/40
time = 633.17 secondes

Train loss 0.05123979084694823 accuracy 0.9911609292030334 macro_avg {'precision': 0.9911650652528914, 'recall': 0.9911712478978151, 'f1-score': 0.9911607753490974, 'support': 10182} weighted_avg {'precision': 0.9911760671309302, 'recall': 0.9911608721272834, 'f1-score': 0.9911611958937704, 'support': 10182}
 
time = 22.97 secondes

Val loss 1.0210471871771365 accuracy 0.879858672618866 macro_avg {'precision': 0.883209608817418, 'recall': 0.8833397276911061, 'f1-score': 0.8807813786691568, 'support': 1132} weighted_avg {'precision': 0.8865573843863019, 'recall': 0.8798586572438163, 'f1-score': 0.8807622136574644, 'support': 1132}
 
----------
Epoch 24/40
time = 625.82 secondes

Train loss 0.05555288612558055 accuracy 0.9898841381072998 macro_avg {'precision': 0.9895198810362112, 'recall': 0.9894561663282644, 'f1-score': 0.9894787264899302, 'support': 10182} weighted_avg {'precision': 0.9899057088529866, 'recall': 0.9898841092123355, 'f1-score': 0.9898855649490615, 'support': 10182}
 
time = 22.18 secondes

Val loss 0.9524524252366051 accuracy 0.8886925578117371 macro_avg {'precision': 0.8924982823989384, 'recall': 0.8918732500277635, 'f1-score': 0.8908096245647336, 'support': 1132} weighted_avg {'precision': 0.8923932882161488, 'recall': 0.8886925795053003, 'f1-score': 0.8890710482846835, 'support': 1132}
 
----------
Epoch 25/40
time = 625.17 secondes

Train loss 0.047376461469191285 accuracy 0.9913573265075684 macro_avg {'precision': 0.9910186066003901, 'recall': 0.9910505426763132, 'f1-score': 0.9910257216593539, 'support': 10182} weighted_avg {'precision': 0.9913593294472642, 'recall': 0.9913572971911215, 'f1-score': 0.9913492654245937, 'support': 10182}
 
time = 22.49 secondes

Val loss 0.9153135482324934 accuracy 0.8878092169761658 macro_avg {'precision': 0.89668603025344, 'recall': 0.8896252177317516, 'f1-score': 0.8888708879189645, 'support': 1132} weighted_avg {'precision': 0.8993386746843978, 'recall': 0.8878091872791519, 'f1-score': 0.8896045739855447, 'support': 1132}
 
----------
Epoch 26/40
time = 625.96 secondes

Train loss 0.037665689207397 accuracy 0.9928305149078369 macro_avg {'precision': 0.9929040027094806, 'recall': 0.9928931643269412, 'f1-score': 0.9928923125906509, 'support': 10182} weighted_avg {'precision': 0.9928345572853038, 'recall': 0.9928304851699077, 'f1-score': 0.9928261067566823, 'support': 10182}
 
time = 22.85 secondes

Val loss 0.9118029288033476 accuracy 0.8948763608932495 macro_avg {'precision': 0.898958827715411, 'recall': 0.8944793402268317, 'f1-score': 0.8950655972868246, 'support': 1132} weighted_avg {'precision': 0.8988087915877275, 'recall': 0.8948763250883393, 'f1-score': 0.8951915948567148, 'support': 1132}
 
----------
Epoch 27/40
time = 625.00 secondes

Train loss 0.034870168610035154 accuracy 0.9933215975761414 macro_avg {'precision': 0.9927234592957139, 'recall': 0.9929084945736806, 'f1-score': 0.9928070642678553, 'support': 10182} weighted_avg {'precision': 0.9933280787390314, 'recall': 0.993321547829503, 'f1-score': 0.9933159033661506, 'support': 10182}
 
time = 22.29 secondes

Val loss 0.9690766965806534 accuracy 0.8851590156555176 macro_avg {'precision': 0.8914435163882741, 'recall': 0.8881951399220238, 'f1-score': 0.8873562662161895, 'support': 1132} weighted_avg {'precision': 0.8919904073711945, 'recall': 0.8851590106007067, 'f1-score': 0.8859986069381339, 'support': 1132}
 
----------
Epoch 28/40
time = 625.29 secondes

Train loss 0.0366353052619729 accuracy 0.993714451789856 macro_avg {'precision': 0.9934597352382321, 'recall': 0.9934958605050854, 'f1-score': 0.9934735588202992, 'support': 10182} weighted_avg {'precision': 0.9937261365621327, 'recall': 0.9937143979571793, 'f1-score': 0.993716111952377, 'support': 10182}
 
time = 23.05 secondes

Val loss 0.978625711349977 accuracy 0.8869258165359497 macro_avg {'precision': 0.8889244788982312, 'recall': 0.8911013887527289, 'f1-score': 0.8873415834056783, 'support': 1132} weighted_avg {'precision': 0.8929819089428606, 'recall': 0.8869257950530035, 'f1-score': 0.887605212658309, 'support': 1132}
 
----------
Epoch 29/40
time = 625.16 secondes

Train loss 0.044087056189528656 accuracy 0.9927322864532471 macro_avg {'precision': 0.9927691168561668, 'recall': 0.9921733217868921, 'f1-score': 0.9924393224968178, 'support': 10182} weighted_avg {'precision': 0.9927757561542454, 'recall': 0.9927322726379886, 'f1-score': 0.9927270884057484, 'support': 10182}
 
time = 22.43 secondes

Val loss 0.9702985242437931 accuracy 0.8869258165359497 macro_avg {'precision': 0.893361163924806, 'recall': 0.8884216886634044, 'f1-score': 0.8888590412848757, 'support': 1132} weighted_avg {'precision': 0.8909941607307461, 'recall': 0.8869257950530035, 'f1-score': 0.8867847167758296, 'support': 1132}
 
----------
Epoch 30/40
time = 625.03 secondes

Train loss 0.02504664637013187 accuracy 0.994892954826355 macro_avg {'precision': 0.9949021604463841, 'recall': 0.9948262578953534, 'f1-score': 0.9948594511944517, 'support': 10182} weighted_avg {'precision': 0.9949008713028296, 'recall': 0.9948929483402082, 'f1-score': 0.9948920479444489, 'support': 10182}
 
time = 23.06 secondes

Val loss 1.0188343281548493 accuracy 0.8869258165359497 macro_avg {'precision': 0.8937647981356369, 'recall': 0.8889730852746467, 'f1-score': 0.8889034390036679, 'support': 1132} weighted_avg {'precision': 0.8933969284954228, 'recall': 0.8869257950530035, 'f1-score': 0.8876029343456261, 'support': 1132}
 
----------
Epoch 31/40
time = 626.36 secondes

Train loss 0.021615594969299143 accuracy 0.9965626001358032 macro_avg {'precision': 0.9964760751017373, 'recall': 0.9964619543084157, 'f1-score': 0.9964645958437692, 'support': 10182} weighted_avg {'precision': 0.9965671312727664, 'recall': 0.9965625613828325, 'f1-score': 0.9965603929844112, 'support': 10182}
 
time = 22.94 secondes

Val loss 1.0050313754530527 accuracy 0.8833922147750854 macro_avg {'precision': 0.8929019547392774, 'recall': 0.8862541443472214, 'f1-score': 0.8868663656631881, 'support': 1132} weighted_avg {'precision': 0.8916275981972563, 'recall': 0.8833922261484098, 'f1-score': 0.8845864614131805, 'support': 1132}
 
----------
Epoch 32/40
time = 626.02 secondes

Train loss 0.02257864900731626 accuracy 0.9954822659492493 macro_avg {'precision': 0.9956117429539143, 'recall': 0.9955168407032394, 'f1-score': 0.9955615429584757, 'support': 10182} weighted_avg {'precision': 0.995490665928423, 'recall': 0.9954822235317227, 'f1-score': 0.9954836479254003, 'support': 10182}
 
time = 23.27 secondes

Val loss 1.1407110878650892 accuracy 0.8816254734992981 macro_avg {'precision': 0.8905953520934762, 'recall': 0.8863705148335063, 'f1-score': 0.8850120964335965, 'support': 1132} weighted_avg {'precision': 0.8929528490259977, 'recall': 0.8816254416961131, 'f1-score': 0.8838771728405026, 'support': 1132}
 
----------
Epoch 33/40
time = 624.70 secondes

Train loss 0.026248531586729434 accuracy 0.9955804944038391 macro_avg {'precision': 0.9955992835741618, 'recall': 0.9955949261524781, 'f1-score': 0.9955915876319436, 'support': 10182} weighted_avg {'precision': 0.9955842354173894, 'recall': 0.9955804360636418, 'f1-score': 0.9955766576628706, 'support': 10182}
 
time = 19.63 secondes

Val loss 1.0187273622079476 accuracy 0.8913427591323853 macro_avg {'precision': 0.8945466785945358, 'recall': 0.8924865357510141, 'f1-score': 0.8911114172663508, 'support': 1132} weighted_avg {'precision': 0.895180217530941, 'recall': 0.8913427561837456, 'f1-score': 0.8907520062762423, 'support': 1132}
 
----------
Epoch 34/40
time = 626.15 secondes

Train loss 0.021910039774558476 accuracy 0.9962679743766785 macro_avg {'precision': 0.9962386085182511, 'recall': 0.9961177534430883, 'f1-score': 0.996175588459683, 'support': 10182} weighted_avg {'precision': 0.9962776978906213, 'recall': 0.9962679237870752, 'f1-score': 0.9962702991204108, 'support': 10182}
 
time = 21.16 secondes

Val loss 0.9764743904004103 accuracy 0.8878092169761658 macro_avg {'precision': 0.8919811440526901, 'recall': 0.8920018493445523, 'f1-score': 0.8904648722495292, 'support': 1132} weighted_avg {'precision': 0.8923349615043767, 'recall': 0.8878091872791519, 'f1-score': 0.8882955326060409, 'support': 1132}
 
----------
Epoch 35/40
time = 625.31 secondes

Train loss 0.022189247743644412 accuracy 0.9961697459220886 macro_avg {'precision': 0.9963501862562453, 'recall': 0.9962085735888733, 'f1-score': 0.9962610473978474, 'support': 10182} weighted_avg {'precision': 0.9962089430578819, 'recall': 0.9961697112551562, 'f1-score': 0.9961704802794222, 'support': 10182}
 
time = 23.02 secondes

Val loss 0.9574516921278137 accuracy 0.8878092169761658 macro_avg {'precision': 0.8905022008155579, 'recall': 0.8926378815443871, 'f1-score': 0.8902761539586435, 'support': 1132} weighted_avg {'precision': 0.8899477853487977, 'recall': 0.8878091872791519, 'f1-score': 0.8874709213687723, 'support': 1132}
 
----------
Epoch 36/40
time = 626.25 secondes

Train loss 0.013261988914677222 accuracy 0.9975447058677673 macro_avg {'precision': 0.9976048557489381, 'recall': 0.9975813055156089, 'f1-score': 0.9975913497177888, 'support': 10182} weighted_avg {'precision': 0.997545026244796, 'recall': 0.9975446867020232, 'f1-score': 0.9975431275638326, 'support': 10182}
 
time = 23.10 secondes

Val loss 1.0305396613143207 accuracy 0.8913427591323853 macro_avg {'precision': 0.8981836608974497, 'recall': 0.8943802948393079, 'f1-score': 0.894608808840827, 'support': 1132} weighted_avg {'precision': 0.8980093013526351, 'recall': 0.8913427561837456, 'f1-score': 0.8929322235896535, 'support': 1132}
 
----------
Epoch 37/40
time = 626.92 secondes

Train loss 0.014830131881899147 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971540737194632, 'recall': 0.9970882625342214, 'f1-score': 0.9971195909499182, 'support': 10182} weighted_avg {'precision': 0.9971547132850943, 'recall': 0.9971518365743469, 'f1-score': 0.997151673119038, 'support': 10182}
 
time = 22.75 secondes

Val loss 1.0243478622992306 accuracy 0.8878092169761658 macro_avg {'precision': 0.890272680962924, 'recall': 0.8914224082347925, 'f1-score': 0.8887850004316646, 'support': 1132} weighted_avg {'precision': 0.8926508092918574, 'recall': 0.8878091872791519, 'f1-score': 0.8884100207815532, 'support': 1132}
 
----------
Epoch 38/40
time = 623.34 secondes

Train loss 0.00988247336367699 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983798077739221, 'recall': 0.9984415515606134, 'f1-score': 0.9984085495667998, 'support': 10182} weighted_avg {'precision': 0.9984346852997394, 'recall': 0.9984285994892949, 'f1-score': 0.9984295307359013, 'support': 10182}
 
time = 22.36 secondes

Val loss 1.0612362051841584 accuracy 0.8842756152153015 macro_avg {'precision': 0.8885077396694611, 'recall': 0.8888144890371693, 'f1-score': 0.8864559585680519, 'support': 1132} weighted_avg {'precision': 0.8897903689719493, 'recall': 0.8842756183745583, 'f1-score': 0.8847195180461888, 'support': 1132}
 
----------
Epoch 39/40
time = 623.62 secondes

Train loss 0.004632101772707245 accuracy 0.9993125200271606 macro_avg {'precision': 0.9993205802491465, 'recall': 0.9993300645313626, 'f1-score': 0.9993248488167948, 'support': 10182} weighted_avg {'precision': 0.9993134880030958, 'recall': 0.9993125122765665, 'f1-score': 0.9993125231014041, 'support': 10182}
 
time = 21.87 secondes

Val loss 0.9936009179047149 accuracy 0.8948763608932495 macro_avg {'precision': 0.8996097771081377, 'recall': 0.8993484949433224, 'f1-score': 0.897149994042393, 'support': 1132} weighted_avg {'precision': 0.9014844244574979, 'recall': 0.8948763250883393, 'f1-score': 0.8958934714697516, 'support': 1132}
 
----------
Epoch 40/40
time = 622.82 secondes

Train loss 0.0030362218759940017 accuracy 0.9993125200271606 macro_avg {'precision': 0.999314329235105, 'recall': 0.999284245019408, 'f1-score': 0.9992983844781704, 'support': 10182} weighted_avg {'precision': 0.9993148005203477, 'recall': 0.9993125122765665, 'f1-score': 0.9993127802245435, 'support': 10182}
 
time = 22.36 secondes

Val loss 1.0011800259158201 accuracy 0.8931095600128174 macro_avg {'precision': 0.8961345686013578, 'recall': 0.8974013663895309, 'f1-score': 0.8948772911782024, 'support': 1132} weighted_avg {'precision': 0.898379758825034, 'recall': 0.8931095406360424, 'f1-score': 0.8938504361064539, 'support': 1132}
 
----------
best_accuracy 0.8948763608932495 best_epoch 26 macro_avg {'precision': 0.898958827715411, 'recall': 0.8944793402268317, 'f1-score': 0.8950655972868246, 'support': 1132} weighted_avg {'precision': 0.8988087915877275, 'recall': 0.8948763250883393, 'f1-score': 0.8951915948567148, 'support': 1132}

average train time 631.893517100811

average val time 23.00001375079155
 
time = 141.86 secondes

test_accuracy 0.8120021224021912 macro_avg {'precision': 0.8098566183926224, 'recall': 0.8046968722168474, 'f1-score': 0.8044796914887042, 'support': 7532} weighted_avg {'precision': 0.8172100487683802, 'recall': 0.8120021242697822, 'f1-score': 0.811730910532516, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_3
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 431.18 secondes

Train loss 1.3941721706599979 accuracy 0.6178550720214844 macro_avg {'precision': 0.6269746275715498, 'recall': 0.6030838413200152, 'f1-score': 0.596446391824192, 'support': 10182} weighted_avg {'precision': 0.6322347544925099, 'recall': 0.6178550383028875, 'f1-score': 0.610210132968731, 'support': 10182}
 
time = 16.59 secondes

Val loss 0.8064426263453255 accuracy 0.75 macro_avg {'precision': 0.729331374171628, 'recall': 0.7463755235339702, 'f1-score': 0.7324574339740565, 'support': 1132} weighted_avg {'precision': 0.7350160422901081, 'recall': 0.75, 'f1-score': 0.7371435132920441, 'support': 1132}
 
----------
Epoch 2/40
time = 430.89 secondes

Train loss 0.6076678159402529 accuracy 0.8167354464530945 macro_avg {'precision': 0.8037251334360954, 'recall': 0.8051908952495568, 'f1-score': 0.8022066333795772, 'support': 10182} weighted_avg {'precision': 0.8124176234435875, 'recall': 0.8167354154390101, 'f1-score': 0.8128986473152422, 'support': 10182}
 
time = 15.72 secondes

Val loss 0.6005902475034687 accuracy 0.8224381804466248 macro_avg {'precision': 0.8240532560746656, 'recall': 0.8155490559511293, 'f1-score': 0.8135844414636807, 'support': 1132} weighted_avg {'precision': 0.8260024346429617, 'recall': 0.8224381625441696, 'f1-score': 0.818285764639021, 'support': 1132}
 
----------
Epoch 3/40
time = 430.93 secondes

Train loss 0.35767106065348236 accuracy 0.8975643515586853 macro_avg {'precision': 0.8930428226678512, 'recall': 0.8922963719683208, 'f1-score': 0.8923474894316973, 'support': 10182} weighted_avg {'precision': 0.8976291686847052, 'recall': 0.897564329208407, 'f1-score': 0.8972813500798323, 'support': 10182}
 
time = 16.45 secondes

Val loss 0.5490440520602213 accuracy 0.8507066965103149 macro_avg {'precision': 0.8523210745607457, 'recall': 0.8503759746515316, 'f1-score': 0.8489202203533349, 'support': 1132} weighted_avg {'precision': 0.8519945855602591, 'recall': 0.8507067137809188, 'f1-score': 0.8491557797071041, 'support': 1132}
 
----------
Epoch 4/40
time = 431.13 secondes

Train loss 0.24187183580353996 accuracy 0.9323316216468811 macro_avg {'precision': 0.9292813702156074, 'recall': 0.9290063102925711, 'f1-score': 0.9290631611099442, 'support': 10182} weighted_avg {'precision': 0.9324052632316803, 'recall': 0.9323315655077588, 'f1-score': 0.9322878276737354, 'support': 10182}
 
time = 15.97 secondes

Val loss 0.6409449531618033 accuracy 0.8586572408676147 macro_avg {'precision': 0.8617694087654412, 'recall': 0.8561134415124968, 'f1-score': 0.856105083168436, 'support': 1132} weighted_avg {'precision': 0.8611985583510984, 'recall': 0.8586572438162544, 'f1-score': 0.8572390812478403, 'support': 1132}
 
----------
Epoch 5/40
time = 431.12 secondes

Train loss 0.19059334350004206 accuracy 0.9507955312728882 macro_avg {'precision': 0.9493604867709442, 'recall': 0.9491990788073489, 'f1-score': 0.94920782044164, 'support': 10182} weighted_avg {'precision': 0.9509131670457945, 'recall': 0.9507955215085445, 'f1-score': 0.9507843103005544, 'support': 10182}
 
time = 16.27 secondes

Val loss 0.696948411313712 accuracy 0.8613074421882629 macro_avg {'precision': 0.8648350748769567, 'recall': 0.8640314303612637, 'f1-score': 0.8612798750518597, 'support': 1132} weighted_avg {'precision': 0.8671836210280565, 'recall': 0.8613074204946997, 'f1-score': 0.8610896848013598, 'support': 1132}
 
----------
Epoch 6/40
time = 431.07 secondes

Train loss 0.16007859670349472 accuracy 0.960125744342804 macro_avg {'precision': 0.9589526816829554, 'recall': 0.9586512715663499, 'f1-score': 0.9587556763579246, 'support': 10182} weighted_avg {'precision': 0.9601434613736319, 'recall': 0.9601257120408564, 'f1-score': 0.9600916702132021, 'support': 10182}
 
time = 16.47 secondes

Val loss 0.8432135139477216 accuracy 0.8524734973907471 macro_avg {'precision': 0.8599959530279844, 'recall': 0.8542031942111615, 'f1-score': 0.8522534939436307, 'support': 1132} weighted_avg {'precision': 0.861766917458529, 'recall': 0.8524734982332155, 'f1-score': 0.852373835338102, 'support': 1132}
 
----------
Epoch 7/40
time = 431.03 secondes

Train loss 0.14728140483867652 accuracy 0.9648399353027344 macro_avg {'precision': 0.9637541940403518, 'recall': 0.963823617042484, 'f1-score': 0.9637540940803907, 'support': 10182} weighted_avg {'precision': 0.9648586537124455, 'recall': 0.9648399135729719, 'f1-score': 0.96481297961008, 'support': 10182}
 
time = 16.76 secondes

Val loss 0.7758360224985845 accuracy 0.8613074421882629 macro_avg {'precision': 0.8748457039681723, 'recall': 0.862957405064851, 'f1-score': 0.8643685266524013, 'support': 1132} weighted_avg {'precision': 0.8735477776762705, 'recall': 0.8613074204946997, 'f1-score': 0.8625916266298445, 'support': 1132}
 
----------
Epoch 8/40
time = 430.77 secondes

Train loss 0.13108442460774888 accuracy 0.9696523547172546 macro_avg {'precision': 0.9688532275483253, 'recall': 0.9684901026269823, 'f1-score': 0.9686198249282283, 'support': 10182} weighted_avg {'precision': 0.9697227316829418, 'recall': 0.9696523276370065, 'f1-score': 0.9696357299079748, 'support': 10182}
 
time = 16.62 secondes

Val loss 0.7717393946335455 accuracy 0.8692579865455627 macro_avg {'precision': 0.8742006506501611, 'recall': 0.8685110824036852, 'f1-score': 0.867713407065691, 'support': 1132} weighted_avg {'precision': 0.8755223680581788, 'recall': 0.8692579505300353, 'f1-score': 0.8688707086788985, 'support': 1132}
 
----------
Epoch 9/40
time = 431.07 secondes

Train loss 0.13931496321321268 accuracy 0.9670988321304321 macro_avg {'precision': 0.9660386259581426, 'recall': 0.9663372992148249, 'f1-score': 0.9661367887549064, 'support': 10182} weighted_avg {'precision': 0.9672524284508556, 'recall': 0.9670988018071106, 'f1-score': 0.9671272895100577, 'support': 10182}
 
time = 16.17 secondes

Val loss 0.8768661233726036 accuracy 0.8533568978309631 macro_avg {'precision': 0.8684801229709823, 'recall': 0.8511789090916272, 'f1-score': 0.8538627372104347, 'support': 1132} weighted_avg {'precision': 0.8697044062643652, 'recall': 0.8533568904593639, 'f1-score': 0.856368382731698, 'support': 1132}
 
----------
Epoch 10/40
time = 431.18 secondes

Train loss 0.11675013851373839 accuracy 0.9750540256500244 macro_avg {'precision': 0.9741249194248482, 'recall': 0.974280950951765, 'f1-score': 0.9741774963650455, 'support': 10182} weighted_avg {'precision': 0.9750895012562061, 'recall': 0.9750540168925554, 'f1-score': 0.9750462048194027, 'support': 10182}
 
time = 16.25 secondes

Val loss 0.8194371585416096 accuracy 0.880742073059082 macro_avg {'precision': 0.8831227739849739, 'recall': 0.8848887188467701, 'f1-score': 0.8819937291729456, 'support': 1132} weighted_avg {'precision': 0.883498509434398, 'recall': 0.8807420494699647, 'f1-score': 0.8797492014747789, 'support': 1132}
 
----------
Epoch 11/40
time = 430.72 secondes

Train loss 0.10777966390229364 accuracy 0.9768218994140625 macro_avg {'precision': 0.9768311592167935, 'recall': 0.9764155235253948, 'f1-score': 0.9765859129522614, 'support': 10182} weighted_avg {'precision': 0.9768479885219927, 'recall': 0.9768218424670988, 'f1-score': 0.9767979266252927, 'support': 10182}
 
time = 16.06 secondes

Val loss 0.9154825592110208 accuracy 0.8674911856651306 macro_avg {'precision': 0.8727383769781454, 'recall': 0.8657420624135908, 'f1-score': 0.8661106174070878, 'support': 1132} weighted_avg {'precision': 0.8740205128126128, 'recall': 0.8674911660777385, 'f1-score': 0.8678395372293667, 'support': 1132}
 
----------
Epoch 12/40
time = 431.01 secondes

Train loss 0.11715770548548012 accuracy 0.9767236709594727 macro_avg {'precision': 0.9763384067737793, 'recall': 0.9763996921903558, 'f1-score': 0.9763518160800728, 'support': 10182} weighted_avg {'precision': 0.9767613177970901, 'recall': 0.9767236299351797, 'f1-score': 0.9767247897248432, 'support': 10182}
 
time = 16.34 secondes

Val loss 1.0136889127070006 accuracy 0.8657243847846985 macro_avg {'precision': 0.881599627822218, 'recall': 0.870532584356537, 'f1-score': 0.8712417598591362, 'support': 1132} weighted_avg {'precision': 0.8831763950969744, 'recall': 0.8657243816254417, 'f1-score': 0.8691245018372302, 'support': 1132}
 
----------
Epoch 13/40
time = 430.96 secondes

Train loss 0.10512654612485423 accuracy 0.9786878824234009 macro_avg {'precision': 0.9782985196058773, 'recall': 0.9783524272334578, 'f1-score': 0.978302855994586, 'support': 10182} weighted_avg {'precision': 0.9787638207102337, 'recall': 0.9786878805735612, 'f1-score': 0.9787031657755202, 'support': 10182}
 
time = 16.54 secondes

Val loss 1.3669903200696891 accuracy 0.8118374347686768 macro_avg {'precision': 0.8538846485601702, 'recall': 0.823788626399091, 'f1-score': 0.8110545916994605, 'support': 1132} weighted_avg {'precision': 0.8571934667531595, 'recall': 0.8118374558303887, 'f1-score': 0.8031502973609018, 'support': 1132}
 
----------
Epoch 14/40
time = 430.95 secondes

Train loss 0.09880925080010407 accuracy 0.9796700477600098 macro_avg {'precision': 0.9798396896364195, 'recall': 0.9796696024737631, 'f1-score': 0.97971759823266, 'support': 10182} weighted_avg {'precision': 0.9797709617832915, 'recall': 0.9796700058927519, 'f1-score': 0.9796820344742215, 'support': 10182}
 
time = 16.22 secondes

Val loss 1.0986489049980046 accuracy 0.8489399552345276 macro_avg {'precision': 0.8714431039325019, 'recall': 0.8499370163876758, 'f1-score': 0.8505965657264095, 'support': 1132} weighted_avg {'precision': 0.8679650111277868, 'recall': 0.848939929328622, 'f1-score': 0.8489019939997009, 'support': 1132}
 
----------
Epoch 15/40
time = 430.84 secondes

Train loss 0.07304692027597923 accuracy 0.9845806360244751 macro_avg {'precision': 0.9841760934686965, 'recall': 0.9844029464706561, 'f1-score': 0.9842670871180864, 'support': 10182} weighted_avg {'precision': 0.9846003274365911, 'recall': 0.9845806324887055, 'f1-score': 0.9845681140943396, 'support': 10182}
 
time = 16.31 secondes

Val loss 0.9098949607007302 accuracy 0.8754417300224304 macro_avg {'precision': 0.8806751268339432, 'recall': 0.8787039503830505, 'f1-score': 0.8759974909412376, 'support': 1132} weighted_avg {'precision': 0.8829831683875193, 'recall': 0.8754416961130742, 'f1-score': 0.875183048800248, 'support': 1132}
 
----------
Epoch 16/40
time = 430.89 secondes

Train loss 0.06918498378121972 accuracy 0.9866431355476379 macro_avg {'precision': 0.9857004981066968, 'recall': 0.985421149082617, 'f1-score': 0.9855450106316452, 'support': 10182} weighted_avg {'precision': 0.986637336125521, 'recall': 0.9866430956590061, 'f1-score': 0.9866260724538226, 'support': 10182}
 
time = 15.61 secondes

Val loss 0.9128277844326771 accuracy 0.8780918717384338 macro_avg {'precision': 0.884614855532402, 'recall': 0.8764819587503021, 'f1-score': 0.8788786664574637, 'support': 1132} weighted_avg {'precision': 0.881797014416557, 'recall': 0.8780918727915195, 'f1-score': 0.8783731753928958, 'support': 1132}
 
----------
Epoch 17/40
time = 430.93 secondes

Train loss 0.07808438005256224 accuracy 0.98448246717453 macro_avg {'precision': 0.9838245416466048, 'recall': 0.9833723425743719, 'f1-score': 0.9835549880804404, 'support': 10182} weighted_avg {'precision': 0.9845369168484603, 'recall': 0.9844824199567865, 'f1-score': 0.9844692451769085, 'support': 10182}
 
time = 16.33 secondes

Val loss 0.8832183657974434 accuracy 0.8886925578117371 macro_avg {'precision': 0.8940790435624167, 'recall': 0.8883516984052644, 'f1-score': 0.8886713661462832, 'support': 1132} weighted_avg {'precision': 0.8950371674331132, 'recall': 0.8886925795053003, 'f1-score': 0.8893362864172901, 'support': 1132}
 
----------
Epoch 18/40
time = 430.64 secondes

Train loss 0.07712581989739081 accuracy 0.9858574271202087 macro_avg {'precision': 0.9856625375206456, 'recall': 0.9857436107766511, 'f1-score': 0.9856818082749628, 'support': 10182} weighted_avg {'precision': 0.985904280206866, 'recall': 0.9858573954036535, 'f1-score': 0.9858600095213411, 'support': 10182}
 
time = 16.55 secondes

Val loss 1.0668817326274018 accuracy 0.8772084712982178 macro_avg {'precision': 0.8818264165294163, 'recall': 0.8815951409964494, 'f1-score': 0.8788001210273262, 'support': 1132} weighted_avg {'precision': 0.886993768817024, 'recall': 0.877208480565371, 'f1-score': 0.8792189653717809, 'support': 1132}
 
----------
Epoch 19/40
time = 430.62 secondes

Train loss 0.07646956550887575 accuracy 0.9866431355476379 macro_avg {'precision': 0.9860848513263802, 'recall': 0.9861685027753448, 'f1-score': 0.9861069601462258, 'support': 10182} weighted_avg {'precision': 0.9867001321931734, 'recall': 0.9866430956590061, 'f1-score': 0.9866519873980367, 'support': 10182}
 
time = 16.41 secondes

Val loss 0.9564719636056369 accuracy 0.879858672618866 macro_avg {'precision': 0.8859298538728162, 'recall': 0.8828835556445475, 'f1-score': 0.8823838397992464, 'support': 1132} weighted_avg {'precision': 0.8871770866415722, 'recall': 0.8798586572438163, 'f1-score': 0.8813174571006792, 'support': 1132}
 
----------
Epoch 20/40
time = 431.00 secondes

Train loss 0.06805014798472835 accuracy 0.9873306155204773 macro_avg {'precision': 0.9869818192490907, 'recall': 0.987105953259672, 'f1-score': 0.9870302754121656, 'support': 10182} weighted_avg {'precision': 0.9873664215837087, 'recall': 0.9873305833824396, 'f1-score': 0.9873346988160894, 'support': 10182}
 
time = 16.22 secondes

Val loss 0.9102873167682612 accuracy 0.8895759582519531 macro_avg {'precision': 0.8928761358976318, 'recall': 0.8945259284058977, 'f1-score': 0.8916246620784722, 'support': 1132} weighted_avg {'precision': 0.8953623364332253, 'recall': 0.8895759717314488, 'f1-score': 0.8905167856201096, 'support': 1132}
 
----------
Epoch 21/40
time = 430.89 secondes

Train loss 0.06896478379491769 accuracy 0.9878216981887817 macro_avg {'precision': 0.98734768589827, 'recall': 0.9874385757493279, 'f1-score': 0.9873763204036964, 'support': 10182} weighted_avg {'precision': 0.9878517361247379, 'recall': 0.9878216460420349, 'f1-score': 0.9878202515348763, 'support': 10182}
 
time = 16.33 secondes

Val loss 0.9121076620723331 accuracy 0.8833922147750854 macro_avg {'precision': 0.8918895893144793, 'recall': 0.8862629293151043, 'f1-score': 0.8867493576040844, 'support': 1132} weighted_avg {'precision': 0.8911157422993646, 'recall': 0.8833922261484098, 'f1-score': 0.8849827925739904, 'support': 1132}
 
----------
Epoch 22/40
time = 430.81 secondes

Train loss 0.06056921629840435 accuracy 0.9890984296798706 macro_avg {'precision': 0.9889366738481179, 'recall': 0.9889926855106076, 'f1-score': 0.9889575471915876, 'support': 10182} weighted_avg {'precision': 0.9891054379529924, 'recall': 0.9890984089569829, 'f1-score': 0.9890946127546726, 'support': 10182}
 
time = 16.91 secondes

Val loss 1.0426506588790827 accuracy 0.8789752721786499 macro_avg {'precision': 0.8849803978182725, 'recall': 0.8839169999137709, 'f1-score': 0.8811871193737192, 'support': 1132} weighted_avg {'precision': 0.8886241886675315, 'recall': 0.8789752650176679, 'f1-score': 0.8806477836112276, 'support': 1132}
 
----------
Epoch 23/40
time = 430.75 secondes

Train loss 0.07102141908350518 accuracy 0.9894912838935852 macro_avg {'precision': 0.9893831348005258, 'recall': 0.9889523362693096, 'f1-score': 0.9891532956027393, 'support': 10182} weighted_avg {'precision': 0.9895049813125043, 'recall': 0.9894912590846592, 'f1-score': 0.9894853003803503, 'support': 10182}
 
time = 16.71 secondes

Val loss 1.0435868068643301 accuracy 0.8736749291419983 macro_avg {'precision': 0.8792194445289278, 'recall': 0.8725266328680046, 'f1-score': 0.8716281092461626, 'support': 1132} weighted_avg {'precision': 0.880290712332152, 'recall': 0.8736749116607774, 'f1-score': 0.8733788162923162, 'support': 1132}
 
----------
Epoch 24/40
time = 431.10 secondes

Train loss 0.062415792489213445 accuracy 0.9892948865890503 macro_avg {'precision': 0.9893295400675512, 'recall': 0.9888391133889289, 'f1-score': 0.9890664709941943, 'support': 10182} weighted_avg {'precision': 0.9893269308005215, 'recall': 0.9892948340208211, 'f1-score': 0.9892964601864705, 'support': 10182}
 
time = 16.28 secondes

Val loss 0.9604135942452712 accuracy 0.8727915287017822 macro_avg {'precision': 0.8841949482741376, 'recall': 0.8763272657016454, 'f1-score': 0.8768823001651933, 'support': 1132} weighted_avg {'precision': 0.884859782653642, 'recall': 0.872791519434629, 'f1-score': 0.8752594523654138, 'support': 1132}
 
----------
Epoch 25/40
time = 430.85 secondes

Train loss 0.04340047695439915 accuracy 0.9932233691215515 macro_avg {'precision': 0.9932667280544261, 'recall': 0.9930664527752977, 'f1-score': 0.9931505823633724, 'support': 10182} weighted_avg {'precision': 0.993259324831623, 'recall': 0.993223335297584, 'f1-score': 0.9932255024092655, 'support': 10182}
 
time = 16.24 secondes

Val loss 0.8568672680150075 accuracy 0.8957597017288208 macro_avg {'precision': 0.8992371056328482, 'recall': 0.8989531238057868, 'f1-score': 0.896961164571945, 'support': 1132} weighted_avg {'precision': 0.9014319916264841, 'recall': 0.8957597173144877, 'f1-score': 0.8965285736157633, 'support': 1132}
 
----------
Epoch 26/40
time = 430.45 secondes

Train loss 0.04856351853279873 accuracy 0.9908662438392639 macro_avg {'precision': 0.9910680616193422, 'recall': 0.9909335302359829, 'f1-score': 0.9909894706160648, 'support': 10182} weighted_avg {'precision': 0.9908858841474524, 'recall': 0.9908662345315262, 'f1-score': 0.9908644597481105, 'support': 10182}
 
time = 16.83 secondes

Val loss 1.0170599157183307 accuracy 0.8772084712982178 macro_avg {'precision': 0.8807604508369853, 'recall': 0.8808053486173257, 'f1-score': 0.8777586099037393, 'support': 1132} weighted_avg {'precision': 0.8805960473035372, 'recall': 0.877208480565371, 'f1-score': 0.8760452958637374, 'support': 1132}
 
----------
Epoch 27/40
time = 430.80 secondes

Train loss 0.04651959279183027 accuracy 0.9923394322395325 macro_avg {'precision': 0.992334394441204, 'recall': 0.9924266146068386, 'f1-score': 0.9923688676041824, 'support': 10182} weighted_avg {'precision': 0.9923630099096991, 'recall': 0.9923394225103123, 'f1-score': 0.992339920562785, 'support': 10182}
 
time = 16.28 secondes

Val loss 0.8581516259034454 accuracy 0.8886925578117371 macro_avg {'precision': 0.8926845134225964, 'recall': 0.8922330263247925, 'f1-score': 0.8909300666763998, 'support': 1132} weighted_avg {'precision': 0.8918909376045329, 'recall': 0.8886925795053003, 'f1-score': 0.8886127682143511, 'support': 1132}
 
----------
Epoch 28/40
time = 430.88 secondes

Train loss 0.030972288606821656 accuracy 0.9943037033081055 macro_avg {'precision': 0.994042080691454, 'recall': 0.9941060950664624, 'f1-score': 0.994070370136121, 'support': 10182} weighted_avg {'precision': 0.9943168734360963, 'recall': 0.9943036731486937, 'f1-score': 0.9943065617889715, 'support': 10182}
 
time = 15.99 secondes

Val loss 0.9882006200917293 accuracy 0.8886925578117371 macro_avg {'precision': 0.8885795118827229, 'recall': 0.8924750251692659, 'f1-score': 0.8882821543585582, 'support': 1132} weighted_avg {'precision': 0.8943149234143735, 'recall': 0.8886925795053003, 'f1-score': 0.8895844255718514, 'support': 1132}
 
----------
Epoch 29/40
time = 430.93 secondes

Train loss 0.038979873180810795 accuracy 0.993812620639801 macro_avg {'precision': 0.9936427586875347, 'recall': 0.993695773117102, 'f1-score': 0.9936629267197506, 'support': 10182} weighted_avg {'precision': 0.9938315111471416, 'recall': 0.9938126104890984, 'f1-score': 0.9938155367884727, 'support': 10182}
 
time = 16.73 secondes

Val loss 1.055643889587936 accuracy 0.8772084712982178 macro_avg {'precision': 0.8826130229225664, 'recall': 0.88094212492464, 'f1-score': 0.87936613371785, 'support': 1132} weighted_avg {'precision': 0.8833648106380309, 'recall': 0.877208480565371, 'f1-score': 0.8778316487334047, 'support': 1132}
 
----------
Epoch 30/40
time = 430.99 secondes

Train loss 0.03381488989208626 accuracy 0.9942054748535156 macro_avg {'precision': 0.9943632698087363, 'recall': 0.9941821777063437, 'f1-score': 0.9942642445672689, 'support': 10182} weighted_avg {'precision': 0.9942205287692001, 'recall': 0.9942054606167747, 'f1-score': 0.9942044460663467, 'support': 10182}
 
time = 16.85 secondes

Val loss 0.964784057690132 accuracy 0.8851590156555176 macro_avg {'precision': 0.8887112623347404, 'recall': 0.8879229243699538, 'f1-score': 0.8869028846488437, 'support': 1132} weighted_avg {'precision': 0.8903102400543422, 'recall': 0.8851590106007067, 'f1-score': 0.8863390392180803, 'support': 1132}
 
----------
Epoch 31/40
time = 430.96 secondes

Train loss 0.03540923846535128 accuracy 0.9941073060035706 macro_avg {'precision': 0.9940512285501317, 'recall': 0.9940102608948225, 'f1-score': 0.9940281284215502, 'support': 10182} weighted_avg {'precision': 0.9941091937809585, 'recall': 0.9941072480848556, 'f1-score': 0.9941055820841928, 'support': 10182}
 
time = 16.36 secondes

Val loss 0.9734639241401631 accuracy 0.8904593586921692 macro_avg {'precision': 0.8947172730143542, 'recall': 0.8925521600639762, 'f1-score': 0.8915237381037702, 'support': 1132} weighted_avg {'precision': 0.8948734518839008, 'recall': 0.8904593639575972, 'f1-score': 0.8903931719781789, 'support': 1132}
 
----------
Epoch 32/40
time = 431.03 secondes

Train loss 0.02562717581440237 accuracy 0.9960715174674988 macro_avg {'precision': 0.996214813271538, 'recall': 0.9961099781603749, 'f1-score': 0.9961584687681577, 'support': 10182} weighted_avg {'precision': 0.9960732479988493, 'recall': 0.9960714987232371, 'f1-score': 0.9960684696447651, 'support': 10182}
 
time = 16.77 secondes

Val loss 0.9057155881959851 accuracy 0.8975265026092529 macro_avg {'precision': 0.8994411719560361, 'recall': 0.8995887416754748, 'f1-score': 0.8984197267964955, 'support': 1132} weighted_avg {'precision': 0.8997112438021228, 'recall': 0.8975265017667845, 'f1-score': 0.8974028225413124, 'support': 1132}
 
----------
Epoch 33/40
time = 430.88 secondes

Train loss 0.021227201907457804 accuracy 0.9955804944038391 macro_avg {'precision': 0.995370819455202, 'recall': 0.9952314511228355, 'f1-score': 0.9952941710092956, 'support': 10182} weighted_avg {'precision': 0.9955908187492969, 'recall': 0.9955804360636418, 'f1-score': 0.9955791859856145, 'support': 10182}
 
time = 15.99 secondes

Val loss 1.07753546057303 accuracy 0.8816254734992981 macro_avg {'precision': 0.8867536870404289, 'recall': 0.8835851809416917, 'f1-score': 0.8836890169135486, 'support': 1132} weighted_avg {'precision': 0.8867923735290539, 'recall': 0.8816254416961131, 'f1-score': 0.882876893335302, 'support': 1132}
 
----------
Epoch 34/40
time = 430.90 secondes

Train loss 0.01819043212180501 accuracy 0.9965626001358032 macro_avg {'precision': 0.996258541314667, 'recall': 0.9963947952275639, 'f1-score': 0.9963236987974721, 'support': 10182} weighted_avg {'precision': 0.9965690322343925, 'recall': 0.9965625613828325, 'f1-score': 0.9965630741433853, 'support': 10182}
 
time = 16.60 secondes

Val loss 1.0519526490367663 accuracy 0.8842756152153015 macro_avg {'precision': 0.8910263016631367, 'recall': 0.88551753104804, 'f1-score': 0.8862442072127434, 'support': 1132} weighted_avg {'precision': 0.8896185308144939, 'recall': 0.8842756183745583, 'f1-score': 0.8850342134849799, 'support': 1132}
 
----------
Epoch 35/40
time = 431.04 secondes

Train loss 0.01617124883693122 accuracy 0.9973483085632324 macro_avg {'precision': 0.9969917586242542, 'recall': 0.9972384422187275, 'f1-score': 0.9971055486834179, 'support': 10182} weighted_avg {'precision': 0.997370268243067, 'recall': 0.997348261638185, 'f1-score': 0.9973521910808285, 'support': 10182}
 
time = 16.41 secondes

Val loss 0.9838923588554472 accuracy 0.8975265026092529 macro_avg {'precision': 0.8991628603488762, 'recall': 0.9008073558878416, 'f1-score': 0.8987986911373467, 'support': 1132} weighted_avg {'precision': 0.9007105344172425, 'recall': 0.8975265017667845, 'f1-score': 0.8978781847599575, 'support': 1132}
 
----------
Epoch 36/40
time = 430.82 secondes

Train loss 0.016795792250455945 accuracy 0.9970536828041077 macro_avg {'precision': 0.9968574760870721, 'recall': 0.9970989647691502, 'f1-score': 0.9969713076528006, 'support': 10182} weighted_avg {'precision': 0.9970652524277771, 'recall': 0.9970536240424278, 'f1-score': 0.9970531689487983, 'support': 10182}
 
time = 16.35 secondes

Val loss 1.017324803653332 accuracy 0.8878092169761658 macro_avg {'precision': 0.8895418772856521, 'recall': 0.8918471744013609, 'f1-score': 0.8896115417140187, 'support': 1132} weighted_avg {'precision': 0.8913454607739972, 'recall': 0.8878091872791519, 'f1-score': 0.8884231178721971, 'support': 1132}
 
----------
Epoch 37/40
time = 430.62 secondes

Train loss 0.017265077994649016 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976752321229986, 'recall': 0.9976806299820291, 'f1-score': 0.9976766673442035, 'support': 10182} weighted_avg {'precision': 0.9976451462109713, 'recall': 0.9976428992339422, 'f1-score': 0.9976427164189501, 'support': 10182}
 
time = 16.30 secondes

Val loss 0.9372023882441309 accuracy 0.9001767039299011 macro_avg {'precision': 0.903351643730187, 'recall': 0.90271091296476, 'f1-score': 0.9020827780147498, 'support': 1132} weighted_avg {'precision': 0.9029082046034715, 'recall': 0.9001766784452296, 'f1-score': 0.9005071522653532, 'support': 1132}
 
----------
Epoch 38/40
time = 430.86 secondes

Train loss 0.008051343735623988 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986761804876932, 'recall': 0.9985991208084981, 'f1-score': 0.9986368556762703, 'support': 10182} weighted_avg {'precision': 0.9986257467278247, 'recall': 0.998625024553133, 'f1-score': 0.9986246111043194, 'support': 10182}
 
time = 16.76 secondes

Val loss 0.9552990370582233 accuracy 0.9001767039299011 macro_avg {'precision': 0.9013696929474285, 'recall': 0.9017425311039442, 'f1-score': 0.9009648817778034, 'support': 1132} weighted_avg {'precision': 0.9015944371125385, 'recall': 0.9001766784452296, 'f1-score': 0.9002798886246883, 'support': 1132}
 
----------
Epoch 39/40
time = 430.75 secondes

Train loss 0.005136718389464764 accuracy 0.998919665813446 macro_avg {'precision': 0.998918386378266, 'recall': 0.9989279278283947, 'f1-score': 0.9989227731942169, 'support': 10182} weighted_avg {'precision': 0.9989209925723153, 'recall': 0.9989196621488902, 'f1-score': 0.9989199439562289, 'support': 10182}
 
time = 16.24 secondes

Val loss 0.9837489549983832 accuracy 0.8992933034896851 macro_avg {'precision': 0.9040766526906859, 'recall': 0.8995178984910573, 'f1-score': 0.9010086280944348, 'support': 1132} weighted_avg {'precision': 0.901086449576281, 'recall': 0.8992932862190812, 'f1-score': 0.8994643209208465, 'support': 1132}
 
----------
Epoch 40/40
time = 430.57 secondes

Train loss 0.001865922446233249 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994382713001511, 'recall': 0.9993588422726785, 'f1-score': 0.9993981169357424, 'support': 10182} weighted_avg {'precision': 0.9994114575381275, 'recall': 0.9994107248084856, 'f1-score': 0.9994106857139181, 'support': 10182}
 
time = 16.32 secondes

Val loss 1.000962883551143 accuracy 0.9001767039299011 macro_avg {'precision': 0.9048104728420686, 'recall': 0.9013503344606925, 'f1-score': 0.9020559202961376, 'support': 1132} weighted_avg {'precision': 0.9027493841418762, 'recall': 0.9001766784452296, 'f1-score': 0.9004509535310146, 'support': 1132}
 
----------
best_accuracy 0.9001767039299011 best_epoch 37 macro_avg {'precision': 0.903351643730187, 'recall': 0.90271091296476, 'f1-score': 0.9020827780147498, 'support': 1132} weighted_avg {'precision': 0.9029082046034715, 'recall': 0.9001766784452296, 'f1-score': 0.9005071522653532, 'support': 1132}

average train time 430.89502800107005

average val time 16.37805222272873
 
time = 102.94 secondes

test_accuracy 0.8365639448165894 macro_avg {'precision': 0.8340250176378265, 'recall': 0.8299966214221633, 'f1-score': 0.8304882638500202, 'support': 7532} weighted_avg {'precision': 0.8392986282824482, 'recall': 0.8365639936271907, 'f1-score': 0.8364022665774113, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_3
----------
Epoch 1/40
time = 1948.21 secondes

Train loss 1.3519475730004453 accuracy 0.6373011469841003 macro_avg {'precision': 0.6391357282607555, 'recall': 0.622334160329525, 'f1-score': 0.6161040937319024, 'support': 10182} weighted_avg {'precision': 0.6474277510324052, 'recall': 0.6373011196228638, 'f1-score': 0.630081732038816, 'support': 10182}
 
time = 51.05 secondes

Val loss 0.8057405621233121 accuracy 0.7508834004402161 macro_avg {'precision': 0.7389870999525581, 'recall': 0.744969489608832, 'f1-score': 0.7310360854154409, 'support': 1132} weighted_avg {'precision': 0.7468535126125523, 'recall': 0.7508833922261484, 'f1-score': 0.7367907660765951, 'support': 1132}
 
----------
Epoch 2/40
time = 1943.83 secondes

Train loss 0.5435042563866783 accuracy 0.8373600840568542 macro_avg {'precision': 0.826250219394138, 'recall': 0.8265722278419899, 'f1-score': 0.8244924545947612, 'support': 10182} weighted_avg {'precision': 0.8339639417608508, 'recall': 0.8373600471420153, 'f1-score': 0.8342404787901411, 'support': 10182}
 
time = 51.56 secondes

Val loss 0.6040094893058421 accuracy 0.833038866519928 macro_avg {'precision': 0.832723174691853, 'recall': 0.8304457494208416, 'f1-score': 0.8270044086567292, 'support': 1132} weighted_avg {'precision': 0.8358035987365576, 'recall': 0.8330388692579506, 'f1-score': 0.8302243588432806, 'support': 1132}
 
----------
Epoch 3/40
time = 1948.89 secondes

Train loss 0.3096914701441557 accuracy 0.911117672920227 macro_avg {'precision': 0.9062207230112176, 'recall': 0.905530672900613, 'f1-score': 0.9056053786296354, 'support': 10182} weighted_avg {'precision': 0.9109648079372297, 'recall': 0.911117658613239, 'f1-score': 0.9107906671668712, 'support': 10182}
 
time = 50.42 secondes

Val loss 0.6078387302621989 accuracy 0.8524734973907471 macro_avg {'precision': 0.8616864826291799, 'recall': 0.8513219075666942, 'f1-score': 0.851722576061429, 'support': 1132} weighted_avg {'precision': 0.8655072192877804, 'recall': 0.8524734982332155, 'f1-score': 0.85426010612085, 'support': 1132}
 
----------
Epoch 4/40
time = 1943.05 secondes

Train loss 0.20859311009045206 accuracy 0.9441170692443848 macro_avg {'precision': 0.942059906173103, 'recall': 0.9413722412658464, 'f1-score': 0.9416123080025713, 'support': 10182} weighted_avg {'precision': 0.9441928841103199, 'recall': 0.9441170693380475, 'f1-score': 0.9440560100189546, 'support': 10182}
 
time = 50.57 secondes

Val loss 0.7392983427271247 accuracy 0.8480565547943115 macro_avg {'precision': 0.8511222954837285, 'recall': 0.8502673374201235, 'f1-score': 0.845333803019885, 'support': 1132} weighted_avg {'precision': 0.8578793768008041, 'recall': 0.8480565371024735, 'f1-score': 0.8480460070117983, 'support': 1132}
 
----------
Epoch 5/40
time = 1948.21 secondes

Train loss 0.16729456062386253 accuracy 0.9572775959968567 macro_avg {'precision': 0.9553062057061716, 'recall': 0.9550113787064122, 'f1-score': 0.9551189367329134, 'support': 10182} weighted_avg {'precision': 0.9572466530299014, 'recall': 0.9572775486152033, 'f1-score': 0.957223249508552, 'support': 10182}
 
time = 49.46 secondes

Val loss 0.7955456135604321 accuracy 0.8551236987113953 macro_avg {'precision': 0.869056115114541, 'recall': 0.8513001600952135, 'f1-score': 0.8517076051478712, 'support': 1132} weighted_avg {'precision': 0.8678999108472094, 'recall': 0.8551236749116607, 'f1-score': 0.8533618329363746, 'support': 1132}
 
----------
Epoch 6/40
time = 1947.35 secondes

Train loss 0.13341333759050183 accuracy 0.9668042063713074 macro_avg {'precision': 0.9656748123140563, 'recall': 0.9654984098128903, 'f1-score': 0.9655534937197888, 'support': 10182} weighted_avg {'precision': 0.9668641515869191, 'recall': 0.9668041642113534, 'f1-score': 0.9668022946963648, 'support': 10182}
 
time = 50.04 secondes

Val loss 0.7557045721242361 accuracy 0.879858672618866 macro_avg {'precision': 0.8902033726957355, 'recall': 0.8798676159124827, 'f1-score': 0.8817570618401174, 'support': 1132} weighted_avg {'precision': 0.8893326648033999, 'recall': 0.8798586572438163, 'f1-score': 0.8813536316730933, 'support': 1132}
 
----------
Epoch 7/40
time = 1949.56 secondes

Train loss 0.12777001653550107 accuracy 0.9685720205307007 macro_avg {'precision': 0.9677939578359736, 'recall': 0.9678398058817331, 'f1-score': 0.9677439499710283, 'support': 10182} weighted_avg {'precision': 0.9687208075558197, 'recall': 0.9685719897858966, 'f1-score': 0.9685770557225101, 'support': 10182}
 
time = 50.32 secondes

Val loss 0.7446155906827058 accuracy 0.8816254734992981 macro_avg {'precision': 0.8851979701475032, 'recall': 0.8836640316761836, 'f1-score': 0.8823953811930757, 'support': 1132} weighted_avg {'precision': 0.8890983826455413, 'recall': 0.8816254416961131, 'f1-score': 0.8835051428017927, 'support': 1132}
 
----------
Epoch 8/40
time = 1943.71 secondes

Train loss 0.12598294180254466 accuracy 0.971223771572113 macro_avg {'precision': 0.970375806488477, 'recall': 0.9707727170799231, 'f1-score': 0.9705403035427388, 'support': 10182} weighted_avg {'precision': 0.9713527511758577, 'recall': 0.9712237281477116, 'f1-score': 0.9712595786836924, 'support': 10182}
 
time = 49.93 secondes

Val loss 0.83839641347598 accuracy 0.8674911856651306 macro_avg {'precision': 0.8800666197065382, 'recall': 0.8679750507256887, 'f1-score': 0.8682635507159748, 'support': 1132} weighted_avg {'precision': 0.8796261243382263, 'recall': 0.8674911660777385, 'f1-score': 0.8684834252298587, 'support': 1132}
 
----------
Epoch 9/40
time = 1947.99 secondes

Train loss 0.12460999411694908 accuracy 0.9740719199180603 macro_avg {'precision': 0.9730978969963571, 'recall': 0.9732765423761398, 'f1-score': 0.9731717349928651, 'support': 10182} weighted_avg {'precision': 0.9741072986299135, 'recall': 0.9740718915733647, 'f1-score': 0.9740759321974062, 'support': 10182}
 
time = 50.35 secondes

Val loss 0.7695188967156074 accuracy 0.8789752721786499 macro_avg {'precision': 0.8789532284813237, 'recall': 0.8786807526053492, 'f1-score': 0.8762483224621038, 'support': 1132} weighted_avg {'precision': 0.8827665603896296, 'recall': 0.8789752650176679, 'f1-score': 0.8786361733697976, 'support': 1132}
 
----------
Epoch 10/40
time = 1946.40 secondes

Train loss 0.0905731846249916 accuracy 0.9790807366371155 macro_avg {'precision': 0.9788691799779498, 'recall': 0.9787690213418022, 'f1-score': 0.9788069305885158, 'support': 10182} weighted_avg {'precision': 0.979121916790957, 'recall': 0.9790807307012375, 'f1-score': 0.9790890248582174, 'support': 10182}
 
time = 50.28 secondes

Val loss 0.9826199839327773 accuracy 0.8648409843444824 macro_avg {'precision': 0.8740835753528723, 'recall': 0.8698821955971848, 'f1-score': 0.8685920982623401, 'support': 1132} weighted_avg {'precision': 0.8767863516358883, 'recall': 0.8648409893992933, 'f1-score': 0.8673243241451603, 'support': 1132}
 
----------
Epoch 11/40
time = 1951.31 secondes

Train loss 0.0946807809868258 accuracy 0.980553925037384 macro_avg {'precision': 0.9800476172350445, 'recall': 0.9804543488360574, 'f1-score': 0.9802306423580427, 'support': 10182} weighted_avg {'precision': 0.9806010094549379, 'recall': 0.9805539186800236, 'f1-score': 0.9805605216258312, 'support': 10182}
 
time = 50.98 secondes

Val loss 0.9135285181085199 accuracy 0.8745583295822144 macro_avg {'precision': 0.88358323002102, 'recall': 0.8788383372387274, 'f1-score': 0.8773994996036562, 'support': 1132} weighted_avg {'precision': 0.8871770249211169, 'recall': 0.8745583038869258, 'f1-score': 0.8770417288868282, 'support': 1132}
 
----------
Epoch 12/40
time = 1948.62 secondes

Train loss 0.1027494322169242 accuracy 0.978491485118866 macro_avg {'precision': 0.9774041004567037, 'recall': 0.977695797287533, 'f1-score': 0.9774600321162927, 'support': 10182} weighted_avg {'precision': 0.9786292675940977, 'recall': 0.978491455509723, 'f1-score': 0.9784804564333069, 'support': 10182}
 
time = 50.34 secondes

Val loss 0.9094462520256392 accuracy 0.8851590156555176 macro_avg {'precision': 0.8871893424457216, 'recall': 0.8903905973704658, 'f1-score': 0.8852360236331839, 'support': 1132} weighted_avg {'precision': 0.8908242309411967, 'recall': 0.8851590106007067, 'f1-score': 0.8841756545927221, 'support': 1132}
 
----------
Epoch 13/40
time = 1951.90 secondes

Train loss 0.09671862359325277 accuracy 0.9812414646148682 macro_avg {'precision': 0.9806788245373802, 'recall': 0.980402907237624, 'f1-score': 0.9805070738731667, 'support': 10182} weighted_avg {'precision': 0.9812941581265129, 'recall': 0.981241406403457, 'f1-score': 0.9812360076568151, 'support': 10182}
 
time = 53.27 secondes

Val loss 0.9424424395928468 accuracy 0.8710247278213501 macro_avg {'precision': 0.8774153108225613, 'recall': 0.8747386045328541, 'f1-score': 0.872236030831162, 'support': 1132} weighted_avg {'precision': 0.8826743274031505, 'recall': 0.8710247349823321, 'f1-score': 0.8727793056280264, 'support': 1132}
 
----------
Epoch 14/40
time = 1949.39 secondes

Train loss 0.08455068970398262 accuracy 0.9848753213882446 macro_avg {'precision': 0.9846565734148529, 'recall': 0.9844953505618047, 'f1-score': 0.9845595731089748, 'support': 10182} weighted_avg {'precision': 0.9849141033855041, 'recall': 0.9848752700844627, 'f1-score': 0.9848799206340102, 'support': 10182}
 
time = 50.61 secondes

Val loss 0.9390173607186536 accuracy 0.8745583295822144 macro_avg {'precision': 0.8765504489883525, 'recall': 0.8781245560073299, 'f1-score': 0.8746973449295018, 'support': 1132} weighted_avg {'precision': 0.8787438534212613, 'recall': 0.8745583038869258, 'f1-score': 0.8741460669637284, 'support': 1132}
 
----------
Epoch 15/40
time = 1949.41 secondes

Train loss 0.07789113842769364 accuracy 0.9852681756019592 macro_avg {'precision': 0.9852367651256092, 'recall': 0.9852102690762143, 'f1-score': 0.9852077028438447, 'support': 10182} weighted_avg {'precision': 0.9852716598172842, 'recall': 0.985268120212139, 'f1-score': 0.985253822177622, 'support': 10182}
 
time = 50.73 secondes

Val loss 0.801917948579833 accuracy 0.8966431021690369 macro_avg {'precision': 0.9029994172832987, 'recall': 0.8999248831789473, 'f1-score': 0.8987059803535231, 'support': 1132} weighted_avg {'precision': 0.9048072673006013, 'recall': 0.8966431095406361, 'f1-score': 0.8978409019584989, 'support': 1132}
 
----------
Epoch 16/40
time = 1951.44 secondes

Train loss 0.08911384850986422 accuracy 0.9845806360244751 macro_avg {'precision': 0.9845709261533264, 'recall': 0.983967801845498, 'f1-score': 0.984237884151973, 'support': 10182} weighted_avg {'precision': 0.9846312017883798, 'recall': 0.9845806324887055, 'f1-score': 0.9845774515441928, 'support': 10182}
 
time = 50.45 secondes

Val loss 0.9863509902837981 accuracy 0.8772084712982178 macro_avg {'precision': 0.8854181335032111, 'recall': 0.8774838694953189, 'f1-score': 0.8783353380723105, 'support': 1132} weighted_avg {'precision': 0.8839241002357046, 'recall': 0.877208480565371, 'f1-score': 0.877271164402043, 'support': 1132}
 
----------
Epoch 17/40
time = 1950.21 secondes

Train loss 0.09195940996346329 accuracy 0.9843842387199402 macro_avg {'precision': 0.9843851928638578, 'recall': 0.9841738627282497, 'f1-score': 0.9842613494687003, 'support': 10182} weighted_avg {'precision': 0.9844044783969246, 'recall': 0.9843842074248674, 'f1-score': 0.984375957873215, 'support': 10182}
 
time = 52.27 secondes

Val loss 0.8596495547064197 accuracy 0.8904593586921692 macro_avg {'precision': 0.8951828245742754, 'recall': 0.8940462140244602, 'f1-score': 0.8911907987979983, 'support': 1132} weighted_avg {'precision': 0.8995331138101784, 'recall': 0.8904593639575972, 'f1-score': 0.8913038828747953, 'support': 1132}
 
----------
Epoch 18/40
time = 1948.23 secondes

Train loss 0.0819103847773575 accuracy 0.9850717186927795 macro_avg {'precision': 0.9839800157224682, 'recall': 0.9847314523855368, 'f1-score': 0.9843068400631785, 'support': 10182} weighted_avg {'precision': 0.985193022672397, 'recall': 0.985071695148301, 'f1-score': 0.9850921789909052, 'support': 10182}
 
time = 51.70 secondes

Val loss 0.9453712920291418 accuracy 0.8763250708580017 macro_avg {'precision': 0.8908543509574212, 'recall': 0.8798730408198298, 'f1-score': 0.8799858373115098, 'support': 1132} weighted_avg {'precision': 0.8913397033131071, 'recall': 0.8763250883392226, 'f1-score': 0.8781689726497719, 'support': 1132}
 
----------
Epoch 19/40
time = 1947.60 secondes

Train loss 0.06735446730303213 accuracy 0.9881163239479065 macro_avg {'precision': 0.987534530131035, 'recall': 0.9878512216917713, 'f1-score': 0.9876670619407883, 'support': 10182} weighted_avg {'precision': 0.9881556886226144, 'recall': 0.9881162836377921, 'f1-score': 0.9881118288328726, 'support': 10182}
 
time = 51.02 secondes

Val loss 0.8526156730394446 accuracy 0.8886925578117371 macro_avg {'precision': 0.8976320802155545, 'recall': 0.8890867427654644, 'f1-score': 0.8883500057994336, 'support': 1132} weighted_avg {'precision': 0.9011630153395875, 'recall': 0.8886925795053003, 'f1-score': 0.8908503014516854, 'support': 1132}
 
----------
Epoch 20/40
time = 1955.57 secondes

Train loss 0.05080103229026707 accuracy 0.9907680749893188 macro_avg {'precision': 0.9904676497148411, 'recall': 0.9904916031192709, 'f1-score': 0.9904705943540053, 'support': 10182} weighted_avg {'precision': 0.9907845463542193, 'recall': 0.9907680219996071, 'f1-score': 0.9907671107474447, 'support': 10182}
 
time = 50.45 secondes

Val loss 0.9138651293936894 accuracy 0.8833922147750854 macro_avg {'precision': 0.8865966713993846, 'recall': 0.8896264758565089, 'f1-score': 0.8857368493377609, 'support': 1132} weighted_avg {'precision': 0.8880748588603844, 'recall': 0.8833922261484098, 'f1-score': 0.8831540043846673, 'support': 1132}
 
----------
Epoch 21/40
time = 1948.52 secondes

Train loss 0.06308977227457277 accuracy 0.9892948865890503 macro_avg {'precision': 0.9894447347730427, 'recall': 0.9893537546719726, 'f1-score': 0.9893720189798738, 'support': 10182} weighted_avg {'precision': 0.98936821068, 'recall': 0.9892948340208211, 'f1-score': 0.9893037899889234, 'support': 10182}
 
time = 52.92 secondes

Val loss 1.0593762236041047 accuracy 0.8763250708580017 macro_avg {'precision': 0.8952716664697142, 'recall': 0.8795187950636182, 'f1-score': 0.8822619390481448, 'support': 1132} weighted_avg {'precision': 0.8941648953080138, 'recall': 0.8763250883392226, 'f1-score': 0.8798257429554343, 'support': 1132}
 
----------
Epoch 22/40
time = 1952.57 secondes

Train loss 0.0572162780996991 accuracy 0.98978590965271 macro_avg {'precision': 0.989811415881683, 'recall': 0.9898489736899782, 'f1-score': 0.989816277503053, 'support': 10182} weighted_avg {'precision': 0.9897920701070047, 'recall': 0.9897858966804164, 'f1-score': 0.9897746477061801, 'support': 10182}
 
time = 52.31 secondes

Val loss 0.8588943715091684 accuracy 0.8833922147750854 macro_avg {'precision': 0.8991015608590128, 'recall': 0.8860397193942326, 'f1-score': 0.887857369549281, 'support': 1132} weighted_avg {'precision': 0.8976048360405268, 'recall': 0.8833922261484098, 'f1-score': 0.8856373730496693, 'support': 1132}
 
----------
Epoch 23/40
time = 1948.10 secondes

Train loss 0.06163214753241003 accuracy 0.9894912838935852 macro_avg {'precision': 0.9896387103093074, 'recall': 0.9895962326009325, 'f1-score': 0.9896026516731249, 'support': 10182} weighted_avg {'precision': 0.9895231456225906, 'recall': 0.9894912590846592, 'f1-score': 0.9894918492740976, 'support': 10182}
 
time = 49.96 secondes

Val loss 0.9798298067485826 accuracy 0.8763250708580017 macro_avg {'precision': 0.879220029073162, 'recall': 0.8801396289831432, 'f1-score': 0.8773371399802541, 'support': 1132} weighted_avg {'precision': 0.8801151400206413, 'recall': 0.8763250883392226, 'f1-score': 0.875825402556656, 'support': 1132}
 
----------
Epoch 24/40
time = 1947.28 secondes

Train loss 0.06057111026448369 accuracy 0.9905716180801392 macro_avg {'precision': 0.990756729352805, 'recall': 0.9907638055394024, 'f1-score': 0.9907370029941477, 'support': 10182} weighted_avg {'precision': 0.9905906247467684, 'recall': 0.990571596935769, 'f1-score': 0.9905570142781802, 'support': 10182}
 
time = 51.68 secondes

Val loss 1.0040921570278596 accuracy 0.8780918717384338 macro_avg {'precision': 0.8819495982215878, 'recall': 0.8830905669991791, 'f1-score': 0.8804007347006062, 'support': 1132} weighted_avg {'precision': 0.8822991410317262, 'recall': 0.8780918727915195, 'f1-score': 0.8779516280245102, 'support': 1132}
 
----------
Epoch 25/40
Exception
CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 79.21 GiB total capacity; 73.85 GiB already allocated; 42.62 MiB free; 75.58 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 72.90 GiB already allocated; 308.62 MiB free; 75.19 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 79.21 GiB total capacity; 70.25 GiB already allocated; 842.62 MiB free; 74.28 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_3
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 72.99 GiB already allocated; 160.62 MiB free; 74.01 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_3
----------
Epoch 1/40
time = 624.70 secondes

Train loss 1.1296360639261676 accuracy 0.672461211681366 macro_avg {'precision': 0.6892431754943539, 'recall': 0.6586110524567788, 'f1-score': 0.660553195683032, 'support': 10182} weighted_avg {'precision': 0.6965583853770664, 'recall': 0.672461206049892, 'f1-score': 0.6726823822001812, 'support': 10182}
 
time = 23.60 secondes

Val loss 0.5872284215940556 accuracy 0.8259717226028442 macro_avg {'precision': 0.8176163103276833, 'recall': 0.8211606031665507, 'f1-score': 0.811070375258482, 'support': 1132} weighted_avg {'precision': 0.8269180922249688, 'recall': 0.8259717314487632, 'f1-score': 0.8183729306029512, 'support': 1132}
 
----------
Epoch 2/40
time = 607.88 secondes

Train loss 0.4093942395067851 accuracy 0.8798860907554626 macro_avg {'precision': 0.8718437636187986, 'recall': 0.8713399066563037, 'f1-score': 0.8709792633938418, 'support': 10182} weighted_avg {'precision': 0.8784324183288847, 'recall': 0.8798860734629739, 'f1-score': 0.8786899143362334, 'support': 10182}
 
time = 22.29 secondes

Val loss 0.532405914660071 accuracy 0.8507066965103149 macro_avg {'precision': 0.8531581801808983, 'recall': 0.8531508061408012, 'f1-score': 0.8439075657260047, 'support': 1132} weighted_avg {'precision': 0.8630883320612118, 'recall': 0.8507067137809188, 'f1-score': 0.8463935189510919, 'support': 1132}
 
----------
Epoch 3/40
time = 606.55 secondes

Train loss 0.25715421263298116 accuracy 0.9285995364189148 macro_avg {'precision': 0.9251731932148818, 'recall': 0.9239655243959508, 'f1-score': 0.9243960792956025, 'support': 10182} weighted_avg {'precision': 0.9289017727837046, 'recall': 0.928599489294834, 'f1-score': 0.9285867807256017, 'support': 10182}
 
time = 22.61 secondes

Val loss 0.47116842422581895 accuracy 0.8869258165359497 macro_avg {'precision': 0.8909298004173282, 'recall': 0.8863392630861389, 'f1-score': 0.8850527199499003, 'support': 1132} weighted_avg {'precision': 0.8925351331095878, 'recall': 0.8869257950530035, 'f1-score': 0.8859254798888294, 'support': 1132}
 
----------
Epoch 4/40
time = 607.84 secondes

Train loss 0.19152009587667684 accuracy 0.9496170282363892 macro_avg {'precision': 0.9473055202027947, 'recall': 0.9468342952592504, 'f1-score': 0.9470010592575976, 'support': 10182} weighted_avg {'precision': 0.949707503459004, 'recall': 0.9496169711255156, 'f1-score': 0.9495962197198805, 'support': 10182}
 
time = 22.56 secondes

Val loss 0.45109765957647435 accuracy 0.9072438478469849 macro_avg {'precision': 0.9095146065162389, 'recall': 0.9068847342590546, 'f1-score': 0.9056580597063014, 'support': 1132} weighted_avg {'precision': 0.9085200700987176, 'recall': 0.907243816254417, 'f1-score': 0.9051350085848959, 'support': 1132}
 
----------
Epoch 5/40
time = 608.39 secondes

Train loss 0.17357369625043223 accuracy 0.9593400359153748 macro_avg {'precision': 0.9583205723843203, 'recall': 0.9583311822785076, 'f1-score': 0.9582750783464823, 'support': 10182} weighted_avg {'precision': 0.9594457371393408, 'recall': 0.9593400117855039, 'f1-score': 0.9593429779623608, 'support': 10182}
 
time = 22.72 secondes

Val loss 0.5761804952102543 accuracy 0.9019434452056885 macro_avg {'precision': 0.911068799302026, 'recall': 0.9015516203171267, 'f1-score': 0.9028996826669327, 'support': 1132} weighted_avg {'precision': 0.9099427348152747, 'recall': 0.9019434628975265, 'f1-score': 0.9027383058627687, 'support': 1132}
 
----------
Epoch 6/40
time = 607.85 secondes

Train loss 0.14842308205541435 accuracy 0.9648399353027344 macro_avg {'precision': 0.9640409143783758, 'recall': 0.9642228586822231, 'f1-score': 0.964063185390436, 'support': 10182} weighted_avg {'precision': 0.9651179724299924, 'recall': 0.9648399135729719, 'f1-score': 0.9649123667671287, 'support': 10182}
 
time = 22.88 secondes

Val loss 0.509161872174394 accuracy 0.9054770469665527 macro_avg {'precision': 0.9113767683902184, 'recall': 0.905814301141076, 'f1-score': 0.9055966876447255, 'support': 1132} weighted_avg {'precision': 0.9140309507568642, 'recall': 0.9054770318021201, 'f1-score': 0.9069618312066653, 'support': 1132}
 
----------
Epoch 7/40
time = 606.99 secondes

Train loss 0.12318765267254961 accuracy 0.9732862114906311 macro_avg {'precision': 0.9729733020033178, 'recall': 0.9729165609636693, 'f1-score': 0.9729207622208154, 'support': 10182} weighted_avg {'precision': 0.9733944914894881, 'recall': 0.9732861913180122, 'f1-score': 0.973316223477908, 'support': 10182}
 
time = 22.73 secondes

Val loss 0.6194517765645902 accuracy 0.9151943325996399 macro_avg {'precision': 0.9201911912074738, 'recall': 0.9136911292262194, 'f1-score': 0.9147919452630203, 'support': 1132} weighted_avg {'precision': 0.9189618020698219, 'recall': 0.9151943462897526, 'f1-score': 0.9149320042196954, 'support': 1132}
 
----------
Epoch 8/40
time = 606.42 secondes

Train loss 0.1409124617793435 accuracy 0.9697505831718445 macro_avg {'precision': 0.9691938430511924, 'recall': 0.969045250032339, 'f1-score': 0.9690693355143036, 'support': 10182} weighted_avg {'precision': 0.9699071530426513, 'recall': 0.9697505401689256, 'f1-score': 0.9697788750755154, 'support': 10182}
 
time = 22.96 secondes

Val loss 0.6605383522683939 accuracy 0.8966431021690369 macro_avg {'precision': 0.9084152122026014, 'recall': 0.8934356121792465, 'f1-score': 0.8953256160044625, 'support': 1132} weighted_avg {'precision': 0.9036776467486861, 'recall': 0.8966431095406361, 'f1-score': 0.8945091846776656, 'support': 1132}
 
----------
Epoch 9/40
time = 608.51 secondes

Train loss 0.12256223584336684 accuracy 0.9725987315177917 macro_avg {'precision': 0.9711673484799019, 'recall': 0.970904882902895, 'f1-score': 0.9710079514639162, 'support': 10182} weighted_avg {'precision': 0.9725800092006942, 'recall': 0.9725987035945787, 'f1-score': 0.9725645122139965, 'support': 10182}
 
time = 22.26 secondes

Val loss 0.5457008031646157 accuracy 0.9090105891227722 macro_avg {'precision': 0.9161013275775873, 'recall': 0.908904775367813, 'f1-score': 0.9104030467039198, 'support': 1132} weighted_avg {'precision': 0.9147437521314664, 'recall': 0.9090106007067138, 'f1-score': 0.9097543962080351, 'support': 1132}
 
----------
Epoch 10/40
time = 608.95 secondes

Train loss 0.10630443673497732 accuracy 0.9785897135734558 macro_avg {'precision': 0.9774345542984733, 'recall': 0.9775686559815788, 'f1-score': 0.9774903599983219, 'support': 10182} weighted_avg {'precision': 0.978630888164002, 'recall': 0.9785896680416422, 'f1-score': 0.9785994016158647, 'support': 10182}
 
time = 22.89 secondes

Val loss 0.5486353282840483 accuracy 0.9187279343605042 macro_avg {'precision': 0.9230076973870004, 'recall': 0.9192234700092781, 'f1-score': 0.9193604922253783, 'support': 1132} weighted_avg {'precision': 0.9217474031513752, 'recall': 0.9187279151943463, 'f1-score': 0.9186787239200558, 'support': 1132}
 
----------
Epoch 11/40
time = 607.96 secondes

Train loss 0.08559733887279887 accuracy 0.9801610708236694 macro_avg {'precision': 0.9793713139999772, 'recall': 0.9797070307748635, 'f1-score': 0.9795081835487991, 'support': 10182} weighted_avg {'precision': 0.9802615901857652, 'recall': 0.9801610685523473, 'f1-score': 0.9801856384666959, 'support': 10182}
 
time = 23.02 secondes

Val loss 0.785237927856555 accuracy 0.8948763608932495 macro_avg {'precision': 0.9081439754873342, 'recall': 0.8979646338635308, 'f1-score': 0.8982319386078229, 'support': 1132} weighted_avg {'precision': 0.9067374260008202, 'recall': 0.8948763250883393, 'f1-score': 0.8961605923010493, 'support': 1132}
 
----------
Epoch 12/40
time = 608.16 secondes

Train loss 0.10350268718208938 accuracy 0.978295087814331 macro_avg {'precision': 0.977951475127375, 'recall': 0.9782650294838326, 'f1-score': 0.9780859130397473, 'support': 10182} weighted_avg {'precision': 0.978427650159716, 'recall': 0.978295030445885, 'f1-score': 0.9783421705729626, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.7187873572832577 accuracy 0.9045936465263367 macro_avg {'precision': 0.91241788564667, 'recall': 0.9094702022438618, 'f1-score': 0.9065664389125503, 'support': 1132} weighted_avg {'precision': 0.9119872997926263, 'recall': 0.9045936395759717, 'f1-score': 0.9035625624013811, 'support': 1132}
 
----------
Epoch 13/40
time = 608.12 secondes

Train loss 0.10431381010508356 accuracy 0.9799646735191345 macro_avg {'precision': 0.9789969101409135, 'recall': 0.9794569105824815, 'f1-score': 0.9791805117131659, 'support': 10182} weighted_avg {'precision': 0.9800781281689346, 'recall': 0.9799646434885091, 'f1-score': 0.979978327659469, 'support': 10182}
 
time = 22.47 secondes

Val loss 0.6736015704270653 accuracy 0.9090105891227722 macro_avg {'precision': 0.9200306658292238, 'recall': 0.9119801559510643, 'f1-score': 0.9126848603552468, 'support': 1132} weighted_avg {'precision': 0.9209674459863502, 'recall': 0.9090106007067138, 'f1-score': 0.9115047912481253, 'support': 1132}
 
----------
Epoch 14/40
time = 606.91 secondes

Train loss 0.0817978731628867 accuracy 0.9837949872016907 macro_avg {'precision': 0.9830367710641875, 'recall': 0.9834056443417667, 'f1-score': 0.9831803113047133, 'support': 10182} weighted_avg {'precision': 0.9838921561527605, 'recall': 0.983794932233353, 'f1-score': 0.9838096761658017, 'support': 10182}
 
time = 22.12 secondes

Val loss 0.6774301983856327 accuracy 0.9081271886825562 macro_avg {'precision': 0.9133143032786665, 'recall': 0.907081128371731, 'f1-score': 0.9078785865155032, 'support': 1132} weighted_avg {'precision': 0.9122323273169258, 'recall': 0.9081272084805654, 'f1-score': 0.9076834039232446, 'support': 1132}
 
----------
Epoch 15/40
time = 607.68 secondes

Train loss 0.08624259054085939 accuracy 0.9835003018379211 macro_avg {'precision': 0.9830068514209623, 'recall': 0.9833211057377648, 'f1-score': 0.9831469044395037, 'support': 10182} weighted_avg {'precision': 0.983548942966297, 'recall': 0.9835002946375958, 'f1-score': 0.9835101239454456, 'support': 10182}
 
time = 21.44 secondes

Val loss 0.6889721766306074 accuracy 0.9037102460861206 macro_avg {'precision': 0.91212487532817, 'recall': 0.906658948860261, 'f1-score': 0.907380564043688, 'support': 1132} weighted_avg {'precision': 0.9101709299627384, 'recall': 0.9037102473498233, 'f1-score': 0.9047896802798425, 'support': 1132}
 
----------
Epoch 16/40
time = 607.22 secondes

Train loss 0.08432457135421252 accuracy 0.9842860102653503 macro_avg {'precision': 0.9843811932989981, 'recall': 0.9843468480678782, 'f1-score': 0.9843548821788859, 'support': 10182} weighted_avg {'precision': 0.9843003052558776, 'recall': 0.9842859948929483, 'f1-score': 0.9842838356064868, 'support': 10182}
 
time = 21.89 secondes

Val loss 0.7745096153671063 accuracy 0.8992933034896851 macro_avg {'precision': 0.9085841288458534, 'recall': 0.9015918713959034, 'f1-score': 0.9011836396780459, 'support': 1132} weighted_avg {'precision': 0.9054065976744896, 'recall': 0.8992932862190812, 'f1-score': 0.8981019853925417, 'support': 1132}
 
----------
Epoch 17/40
time = 607.36 secondes

Train loss 0.07865484084451888 accuracy 0.985562801361084 macro_avg {'precision': 0.9854369131229774, 'recall': 0.9855494524922811, 'f1-score': 0.9854714175439797, 'support': 10182} weighted_avg {'precision': 0.9855987429699059, 'recall': 0.9855627578078963, 'f1-score': 0.9855583910060057, 'support': 10182}
 
time = 21.96 secondes

Val loss 0.6277047487604596 accuracy 0.9143109321594238 macro_avg {'precision': 0.9167417047174713, 'recall': 0.9130386511290369, 'f1-score': 0.9130855373415763, 'support': 1132} weighted_avg {'precision': 0.9162795633562033, 'recall': 0.9143109540636042, 'f1-score': 0.9138120168560582, 'support': 1132}
 
----------
Epoch 18/40
time = 605.91 secondes

Train loss 0.08991394220766655 accuracy 0.9832056760787964 macro_avg {'precision': 0.9833268002547888, 'recall': 0.9832715955644895, 'f1-score': 0.9832242963333501, 'support': 10182} weighted_avg {'precision': 0.9832485172377267, 'recall': 0.9832056570418385, 'f1-score': 0.9831505015242716, 'support': 10182}
 
time = 22.42 secondes

Val loss 0.7069887546705603 accuracy 0.9098939895629883 macro_avg {'precision': 0.9154772308863123, 'recall': 0.9123482047573658, 'f1-score': 0.9118927691984094, 'support': 1132} weighted_avg {'precision': 0.9146655415422053, 'recall': 0.9098939929328622, 'f1-score': 0.9101178403084493, 'support': 1132}
 
----------
Epoch 19/40
time = 603.96 secondes

Train loss 0.07865817103448768 accuracy 0.9866431355476379 macro_avg {'precision': 0.9864214473983225, 'recall': 0.986491417261836, 'f1-score': 0.986439955588842, 'support': 10182} weighted_avg {'precision': 0.986634749442136, 'recall': 0.9866430956590061, 'f1-score': 0.9866224361169588, 'support': 10182}
 
time = 22.60 secondes

Val loss 0.6714167941466603 accuracy 0.9090105891227722 macro_avg {'precision': 0.9183970723347586, 'recall': 0.9124711207911806, 'f1-score': 0.9127546681772476, 'support': 1132} weighted_avg {'precision': 0.9168277385388711, 'recall': 0.9090106007067138, 'f1-score': 0.9100826006933285, 'support': 1132}
 
----------
Epoch 20/40
time = 608.00 secondes

Train loss 0.05900137946400504 accuracy 0.9884109497070312 macro_avg {'precision': 0.9884679016444144, 'recall': 0.9882558924794467, 'f1-score': 0.9883421380013806, 'support': 10182} weighted_avg {'precision': 0.9884471742292847, 'recall': 0.9884109212335495, 'f1-score': 0.9884091033779082, 'support': 10182}
 
time = 22.36 secondes

Val loss 0.5737775897957273 accuracy 0.9284452199935913 macro_avg {'precision': 0.932281505297691, 'recall': 0.9290153071401791, 'f1-score': 0.9298894450265486, 'support': 1132} weighted_avg {'precision': 0.9304983653332233, 'recall': 0.9284452296819788, 'f1-score': 0.9287312116356954, 'support': 1132}
 
----------
Epoch 21/40
time = 605.01 secondes

Train loss 0.05613569105902045 accuracy 0.989589512348175 macro_avg {'precision': 0.989575047952631, 'recall': 0.989694002989526, 'f1-score': 0.9896260061581106, 'support': 10182} weighted_avg {'precision': 0.9896112843002328, 'recall': 0.9895894716165783, 'f1-score': 0.9895919836351263, 'support': 10182}
 
time = 23.07 secondes

Val loss 0.7506401208111513 accuracy 0.9054770469665527 macro_avg {'precision': 0.9143360412980004, 'recall': 0.9073319820463117, 'f1-score': 0.908442689947476, 'support': 1132} weighted_avg {'precision': 0.9114742196914984, 'recall': 0.9054770318021201, 'f1-score': 0.9059873699578861, 'support': 1132}
 
----------
Epoch 22/40
time = 606.86 secondes

Train loss 0.05078908063667917 accuracy 0.9913573265075684 macro_avg {'precision': 0.9911084967303914, 'recall': 0.9912536900719445, 'f1-score': 0.9911711101781915, 'support': 10182} weighted_avg {'precision': 0.9913707549716818, 'recall': 0.9913572971911215, 'f1-score': 0.9913544727392437, 'support': 10182}
 
time = 21.98 secondes

Val loss 0.6931530716763415 accuracy 0.9187279343605042 macro_avg {'precision': 0.9224697182224443, 'recall': 0.9205773286681573, 'f1-score': 0.9197144839804491, 'support': 1132} weighted_avg {'precision': 0.9216375172590053, 'recall': 0.9187279151943463, 'f1-score': 0.918398914104874, 'support': 1132}
 
----------
Epoch 23/40
time = 605.83 secondes

Train loss 0.05756409641074655 accuracy 0.9899823665618896 macro_avg {'precision': 0.9898798462955, 'recall': 0.989825271334675, 'f1-score': 0.9898399945314557, 'support': 10182} weighted_avg {'precision': 0.990000780260338, 'recall': 0.9899823217442546, 'f1-score': 0.9899786347006809, 'support': 10182}
 
time = 23.01 secondes

Val loss 0.80883582945463 accuracy 0.9010601043701172 macro_avg {'precision': 0.9156450998032518, 'recall': 0.9037958806608481, 'f1-score': 0.9053295831990138, 'support': 1132} weighted_avg {'precision': 0.9151903871318311, 'recall': 0.901060070671378, 'f1-score': 0.9038803050360839, 'support': 1132}
 
----------
Epoch 24/40
time = 622.60 secondes

Train loss 0.0502477196525456 accuracy 0.98978590965271 macro_avg {'precision': 0.9891374690057381, 'recall': 0.9890246774172944, 'f1-score': 0.9890734872888558, 'support': 10182} weighted_avg {'precision': 0.989800028671693, 'recall': 0.9897858966804164, 'f1-score': 0.9897853773148025, 'support': 10182}
 
time = 22.26 secondes

Val loss 0.7385727118507673 accuracy 0.9098939895629883 macro_avg {'precision': 0.9174845963319578, 'recall': 0.9086650036151402, 'f1-score': 0.9108190746372484, 'support': 1132} weighted_avg {'precision': 0.913707035675899, 'recall': 0.9098939929328622, 'f1-score': 0.9095615735876544, 'support': 1132}
 
----------
Epoch 25/40
time = 635.02 secondes

Train loss 0.0434212130171281 accuracy 0.9915537238121033 macro_avg {'precision': 0.9911597160905729, 'recall': 0.991208834111848, 'f1-score': 0.9911753100561892, 'support': 10182} weighted_avg {'precision': 0.9915755916451781, 'recall': 0.9915537222549597, 'f1-score': 0.991556070632927, 'support': 10182}
 
time = 22.03 secondes

Val loss 0.7051846077762528 accuracy 0.9107773900032043 macro_avg {'precision': 0.9210268070747002, 'recall': 0.913188039736138, 'f1-score': 0.9150009895541105, 'support': 1132} weighted_avg {'precision': 0.9174609507784341, 'recall': 0.9107773851590106, 'f1-score': 0.9119216133312972, 'support': 1132}
 
----------
Epoch 26/40
time = 626.69 secondes

Train loss 0.04836193598540766 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913087211484933, 'recall': 0.9913007200768271, 'f1-score': 0.991288365291217, 'support': 10182} weighted_avg {'precision': 0.9915035403502359, 'recall': 0.9914555097230406, 'f1-score': 0.9914627216046927, 'support': 10182}
 
time = 21.99 secondes

Val loss 0.5513825062153559 accuracy 0.9293286204338074 macro_avg {'precision': 0.9324954479017438, 'recall': 0.9311089583835527, 'f1-score': 0.9311780234635616, 'support': 1132} weighted_avg {'precision': 0.9312830041365735, 'recall': 0.9293286219081273, 'f1-score': 0.9296425873687837, 'support': 1132}
 
----------
Epoch 27/40
time = 635.45 secondes

Train loss 0.034062000841880845 accuracy 0.9929287433624268 macro_avg {'precision': 0.9930204935287076, 'recall': 0.9928181451816045, 'f1-score': 0.9929095917726108, 'support': 10182} weighted_avg {'precision': 0.9929400831981758, 'recall': 0.9929286977018268, 'f1-score': 0.9929250424560151, 'support': 10182}
 
time = 22.50 secondes

Val loss 0.7494088627271351 accuracy 0.9116607904434204 macro_avg {'precision': 0.919541234405331, 'recall': 0.9144087129694084, 'f1-score': 0.9152795571664004, 'support': 1132} weighted_avg {'precision': 0.916923107725975, 'recall': 0.911660777385159, 'f1-score': 0.9124957532455992, 'support': 1132}
 
----------
Epoch 28/40
time = 627.21 secondes

Train loss 0.03559080068399929 accuracy 0.9927322864532471 macro_avg {'precision': 0.9921570567741037, 'recall': 0.9921267690759198, 'f1-score': 0.9921402855810253, 'support': 10182} weighted_avg {'precision': 0.992738963409742, 'recall': 0.9927322726379886, 'f1-score': 0.9927342189504205, 'support': 10182}
 
time = 22.51 secondes

Val loss 0.7758268737568255 accuracy 0.9045936465263367 macro_avg {'precision': 0.9124866451118677, 'recall': 0.9007153822726514, 'f1-score': 0.899534961241225, 'support': 1132} weighted_avg {'precision': 0.9142079518628317, 'recall': 0.9045936395759717, 'f1-score': 0.9037856528272038, 'support': 1132}
 
----------
Epoch 29/40
time = 616.83 secondes

Train loss 0.0329936793171569 accuracy 0.9945001006126404 macro_avg {'precision': 0.9946367227843618, 'recall': 0.9944522527459988, 'f1-score': 0.9945357768341946, 'support': 10182} weighted_avg {'precision': 0.9945201031885506, 'recall': 0.9945000982125319, 'f1-score': 0.9945013138529832, 'support': 10182}
 
time = 22.51 secondes

Val loss 0.611185247314238 accuracy 0.9284452199935913 macro_avg {'precision': 0.932978396062192, 'recall': 0.930191345100177, 'f1-score': 0.9309354232286557, 'support': 1132} weighted_avg {'precision': 0.9305527123708385, 'recall': 0.9284452296819788, 'f1-score': 0.9288722965021751, 'support': 1132}
 
----------
Epoch 30/40
time = 644.88 secondes

Train loss 0.03047928531680153 accuracy 0.9945983290672302 macro_avg {'precision': 0.9944844266537542, 'recall': 0.9942453131199926, 'f1-score': 0.9943453940962383, 'support': 10182} weighted_avg {'precision': 0.9946438174897665, 'recall': 0.994598310744451, 'f1-score': 0.9946028853308743, 'support': 10182}
 
time = 21.91 secondes

Val loss 0.7437799646339582 accuracy 0.9107773900032043 macro_avg {'precision': 0.9189482932908843, 'recall': 0.9155719326785526, 'f1-score': 0.9146786768200783, 'support': 1132} weighted_avg {'precision': 0.9196698211298747, 'recall': 0.9107773851590106, 'f1-score': 0.9125778684647416, 'support': 1132}
 
----------
Epoch 31/40
time = 637.62 secondes

Train loss 0.024068569839316184 accuracy 0.995776891708374 macro_avg {'precision': 0.9957456933106548, 'recall': 0.9957001882227317, 'f1-score': 0.9957177524418223, 'support': 10182} weighted_avg {'precision': 0.9957954820629981, 'recall': 0.9957768611274799, 'f1-score': 0.9957809776909731, 'support': 10182}
 
time = 22.43 secondes

Val loss 0.6088117327204267 accuracy 0.9240282773971558 macro_avg {'precision': 0.9290624038299496, 'recall': 0.9262244429338796, 'f1-score': 0.9266364586173701, 'support': 1132} weighted_avg {'precision': 0.9278625244256088, 'recall': 0.9240282685512368, 'f1-score': 0.9248551048488951, 'support': 1132}
 
----------
Epoch 32/40
time = 629.60 secondes

Train loss 0.034574431764086574 accuracy 0.9947947859764099 macro_avg {'precision': 0.9943538212615017, 'recall': 0.9941826861409974, 'f1-score': 0.9942595465499503, 'support': 10182} weighted_avg {'precision': 0.994804815147654, 'recall': 0.9947947358082891, 'f1-score': 0.994791705966277, 'support': 10182}
 
time = 22.38 secondes

Val loss 0.6803505894947104 accuracy 0.9240282773971558 macro_avg {'precision': 0.9282515684061803, 'recall': 0.9231044777813773, 'f1-score': 0.9241100065779145, 'support': 1132} weighted_avg {'precision': 0.9279451100712943, 'recall': 0.9240282685512368, 'f1-score': 0.9243763249675042, 'support': 1132}
 
----------
Epoch 33/40
time = 627.66 secondes

Train loss 0.015177073191850556 accuracy 0.9971518516540527 macro_avg {'precision': 0.9971600978109597, 'recall': 0.9971185631331915, 'f1-score': 0.9971350203995616, 'support': 10182} weighted_avg {'precision': 0.9971625234678131, 'recall': 0.9971518365743469, 'f1-score': 0.9971527485682558, 'support': 10182}
 
time = 21.98 secondes

Val loss 0.6825911004167645 accuracy 0.926678478717804 macro_avg {'precision': 0.9289097120916855, 'recall': 0.9290870290217803, 'f1-score': 0.9282449927980458, 'support': 1132} weighted_avg {'precision': 0.9287879209599129, 'recall': 0.926678445229682, 'f1-score': 0.9269580634186323, 'support': 1132}
 
----------
Epoch 34/40
time = 627.06 secondes

Train loss 0.0197902654331294 accuracy 0.9966608285903931 macro_avg {'precision': 0.9964854181104392, 'recall': 0.9967190408751769, 'f1-score': 0.9965953790572684, 'support': 10182} weighted_avg {'precision': 0.9966723958646087, 'recall': 0.9966607739147515, 'f1-score': 0.9966601524016567, 'support': 10182}
 
time = 22.25 secondes

Val loss 0.7045309063844503 accuracy 0.916077733039856 macro_avg {'precision': 0.9237206494972648, 'recall': 0.9178896652981893, 'f1-score': 0.9189619041138893, 'support': 1132} weighted_avg {'precision': 0.9216675472850855, 'recall': 0.916077738515901, 'f1-score': 0.9169604136478781, 'support': 1132}
 
----------
Epoch 35/40
time = 633.55 secondes

Train loss 0.014406537639210503 accuracy 0.9972500801086426 macro_avg {'precision': 0.997262490108122, 'recall': 0.9972302755793093, 'f1-score': 0.9972436490831722, 'support': 10182} weighted_avg {'precision': 0.9972595541526714, 'recall': 0.9972500491062659, 'f1-score': 0.9972520117593913, 'support': 10182}
 
time = 21.59 secondes

Val loss 0.682066107395117 accuracy 0.9196113348007202 macro_avg {'precision': 0.9267698580755855, 'recall': 0.922872272412539, 'f1-score': 0.9227051062054589, 'support': 1132} weighted_avg {'precision': 0.9263416102396369, 'recall': 0.9196113074204947, 'f1-score': 0.9210067321565992, 'support': 1132}
 
----------
Epoch 36/40
time = 630.97 secondes

Train loss 0.01578285908802642 accuracy 0.9979375600814819 macro_avg {'precision': 0.9979220820487651, 'recall': 0.9976543144787989, 'f1-score': 0.9977832340781339, 'support': 10182} weighted_avg {'precision': 0.9979437488218241, 'recall': 0.9979375368296994, 'f1-score': 0.9979365906627068, 'support': 10182}
 
time = 23.01 secondes

Val loss 0.6674015317019465 accuracy 0.9249116778373718 macro_avg {'precision': 0.9308352783928531, 'recall': 0.925302392137618, 'f1-score': 0.926764877634261, 'support': 1132} weighted_avg {'precision': 0.929085424459796, 'recall': 0.9249116607773852, 'f1-score': 0.9256604902799893, 'support': 1132}
 
----------
Epoch 37/40
time = 632.98 secondes

Train loss 0.007096481055327607 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984652481756451, 'recall': 0.9983906338126743, 'f1-score': 0.9984264249812982, 'support': 10182} weighted_avg {'precision': 0.9984308938498468, 'recall': 0.9984285994892949, 'f1-score': 0.9984283413152881, 'support': 10182}
 
time = 22.65 secondes

Val loss 0.6328358285686655 accuracy 0.9284452199935913 macro_avg {'precision': 0.9323972395538476, 'recall': 0.9296276749407115, 'f1-score': 0.9301334810240618, 'support': 1132} weighted_avg {'precision': 0.9303908100042377, 'recall': 0.9284452296819788, 'f1-score': 0.9284718812389822, 'support': 1132}
 
----------
Epoch 38/40
time = 631.48 secondes

Train loss 0.004967143875946532 accuracy 0.9992143511772156 macro_avg {'precision': 0.9991307006410564, 'recall': 0.9991602895625457, 'f1-score': 0.9991449488769157, 'support': 10182} weighted_avg {'precision': 0.9992159448953551, 'recall': 0.9992142997446474, 'f1-score': 0.99921461239945, 'support': 10182}
 
time = 22.37 secondes

Val loss 0.6556055671685819 accuracy 0.9319788217544556 macro_avg {'precision': 0.9378245480974143, 'recall': 0.9324263500982461, 'f1-score': 0.9339010101043103, 'support': 1132} weighted_avg {'precision': 0.9349030618700657, 'recall': 0.9319787985865724, 'f1-score': 0.9322196335448499, 'support': 1132}
 
----------
Epoch 39/40
time = 628.92 secondes

Train loss 0.002954016660582487 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991598197510662, 'recall': 0.9991300544713699, 'f1-score': 0.999144289438086, 'support': 10182} weighted_avg {'precision': 0.9991164369706145, 'recall': 0.9991160872127284, 'f1-score': 0.9991156020686208, 'support': 10182}
 
time = 22.52 secondes

Val loss 0.7277382286632108 accuracy 0.9240282773971558 macro_avg {'precision': 0.9275666730101522, 'recall': 0.9245006649721716, 'f1-score': 0.9245241077897097, 'support': 1132} weighted_avg {'precision': 0.926751051995227, 'recall': 0.9240282685512368, 'f1-score': 0.9238686393325711, 'support': 1132}
 
----------
Epoch 40/40
time = 629.10 secondes

Train loss 0.00291239663564477 accuracy 0.9993125200271606 macro_avg {'precision': 0.999344855436885, 'recall': 0.9993177533782825, 'f1-score': 0.9993306590566148, 'support': 10182} weighted_avg {'precision': 0.9993137980740716, 'recall': 0.9993125122765665, 'f1-score': 0.9993124967978347, 'support': 10182}
 
time = 22.23 secondes

Val loss 0.690301950249 accuracy 0.9293286204338074 macro_avg {'precision': 0.9335583827025244, 'recall': 0.9314832235199108, 'f1-score': 0.9314476278165872, 'support': 1132} weighted_avg {'precision': 0.9314890773073213, 'recall': 0.9293286219081273, 'f1-score': 0.9292669754648132, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 38 macro_avg {'precision': 0.9378245480974143, 'recall': 0.9324263500982461, 'f1-score': 0.9339010101043103, 'support': 1132} weighted_avg {'precision': 0.9349030618700657, 'recall': 0.9319787985865724, 'f1-score': 0.9322196335448499, 'support': 1132}

average train time 617.5173759996891

average val time 22.448190093040466
 
time = 146.23 secondes

test_accuracy 0.8601964712142944 macro_avg {'precision': 0.8603982191994847, 'recall': 0.8528622177402445, 'f1-score': 0.8536788636135073, 'support': 7532} weighted_avg {'precision': 0.8649589594582675, 'recall': 0.8601964949548593, 'f1-score': 0.8598899705032296, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_3
----------
Epoch 1/40
time = 782.29 secondes

Train loss 1.0810034597757472 accuracy 0.6992732286453247 macro_avg {'precision': 0.7012806217264921, 'recall': 0.6865084279693912, 'f1-score': 0.6831541863826037, 'support': 10182} weighted_avg {'precision': 0.7053744180334637, 'recall': 0.6992732272637988, 'f1-score': 0.6936062193165551, 'support': 10182}
 
time = 26.69 secondes

Val loss 0.5500326381183006 accuracy 0.8418728113174438 macro_avg {'precision': 0.8424775397022547, 'recall': 0.8369836203333355, 'f1-score': 0.8333897892274089, 'support': 1132} weighted_avg {'precision': 0.8479964965380131, 'recall': 0.8418727915194346, 'f1-score': 0.8390489980163394, 'support': 1132}
 
----------
Epoch 2/40
time = 769.67 secondes

Train loss 0.37453351959328823 accuracy 0.8922608494758606 macro_avg {'precision': 0.886759043738864, 'recall': 0.8850617276183366, 'f1-score': 0.8854100225631422, 'support': 10182} weighted_avg {'precision': 0.8921837691785371, 'recall': 0.892260852484777, 'f1-score': 0.89180913393649, 'support': 10182}
 
time = 26.23 secondes

Val loss 0.4509265445907351 accuracy 0.8860424160957336 macro_avg {'precision': 0.8918092892595719, 'recall': 0.8845411897716591, 'f1-score': 0.8839937562424149, 'support': 1132} weighted_avg {'precision': 0.8923305311551166, 'recall': 0.8860424028268551, 'f1-score': 0.8848832398561611, 'support': 1132}
 
----------
Epoch 3/40
time = 769.60 secondes

Train loss 0.22361444082736875 accuracy 0.9382243156433105 macro_avg {'precision': 0.9356214805531134, 'recall': 0.9344861433053803, 'f1-score': 0.9349307241711784, 'support': 10182} weighted_avg {'precision': 0.9382430551739714, 'recall': 0.9382243174229031, 'f1-score': 0.9381268520854906, 'support': 10182}
 
time = 26.02 secondes

Val loss 0.4757654075051697 accuracy 0.8886925578117371 macro_avg {'precision': 0.8957110641279961, 'recall': 0.8881913829696477, 'f1-score': 0.8885593057474676, 'support': 1132} weighted_avg {'precision': 0.8955510700508784, 'recall': 0.8886925795053003, 'f1-score': 0.8887438688914656, 'support': 1132}
 
----------
Epoch 4/40
time = 769.53 secondes

Train loss 0.1655457475872526 accuracy 0.9537419080734253 macro_avg {'precision': 0.952687816008598, 'recall': 0.9521562109341444, 'f1-score': 0.9523617157110411, 'support': 10182} weighted_avg {'precision': 0.9538569313744109, 'recall': 0.9537418974661167, 'f1-score': 0.9537418328404959, 'support': 10182}
 
time = 25.68 secondes

Val loss 0.5089793414579259 accuracy 0.898409903049469 macro_avg {'precision': 0.90742308416889, 'recall': 0.8984488890885951, 'f1-score': 0.8987972705662208, 'support': 1132} weighted_avg {'precision': 0.9075010968215311, 'recall': 0.8984098939929329, 'f1-score': 0.8989916447204946, 'support': 1132}
 
----------
Epoch 5/40
time = 767.06 secondes

Train loss 0.1452718278759757 accuracy 0.9648399353027344 macro_avg {'precision': 0.9635420826867864, 'recall': 0.9631810501919645, 'f1-score': 0.9632939564918364, 'support': 10182} weighted_avg {'precision': 0.9649908789734156, 'recall': 0.9648399135729719, 'f1-score': 0.9648494185464752, 'support': 10182}
 
time = 26.45 secondes

Val loss 0.5639575975701134 accuracy 0.9072438478469849 macro_avg {'precision': 0.9167123365571939, 'recall': 0.907872969835563, 'f1-score': 0.9094805087143362, 'support': 1132} weighted_avg {'precision': 0.9149722005111912, 'recall': 0.907243816254417, 'f1-score': 0.9084059339582409, 'support': 1132}
 
----------
Epoch 6/40
time = 773.38 secondes

Train loss 0.14025837469998062 accuracy 0.9682773947715759 macro_avg {'precision': 0.967377860631915, 'recall': 0.9671307599082631, 'f1-score': 0.9672192702011317, 'support': 10182} weighted_avg {'precision': 0.9683058457313443, 'recall': 0.9682773521901394, 'f1-score': 0.9682564374975383, 'support': 10182}
 
time = 26.17 secondes

Val loss 0.5483421055791886 accuracy 0.9054770469665527 macro_avg {'precision': 0.9123942505048708, 'recall': 0.9064368253923826, 'f1-score': 0.9069739346355771, 'support': 1132} weighted_avg {'precision': 0.9122214870611216, 'recall': 0.9054770318021201, 'f1-score': 0.9062645657169075, 'support': 1132}
 
----------
Epoch 7/40
time = 768.72 secondes

Train loss 0.12365442519536712 accuracy 0.9729915857315063 macro_avg {'precision': 0.9724105987510276, 'recall': 0.9720973341518583, 'f1-score': 0.9722320757078518, 'support': 10182} weighted_avg {'precision': 0.97303604558021, 'recall': 0.972991553722255, 'f1-score': 0.9729928956136804, 'support': 10182}
 
time = 26.16 secondes

Val loss 0.6629714612114492 accuracy 0.9001767039299011 macro_avg {'precision': 0.9086774418781369, 'recall': 0.9028596660832985, 'f1-score': 0.9027175020513333, 'support': 1132} weighted_avg {'precision': 0.9062292866517068, 'recall': 0.9001766784452296, 'f1-score': 0.8998846173854096, 'support': 1132}
 
----------
Epoch 8/40
time = 772.53 secondes

Train loss 0.1195222317696011 accuracy 0.9732862114906311 macro_avg {'precision': 0.9725997498036232, 'recall': 0.972396096419698, 'f1-score': 0.9724665418921832, 'support': 10182} weighted_avg {'precision': 0.973330678048713, 'recall': 0.9732861913180122, 'f1-score': 0.9732759359799331, 'support': 10182}
 
time = 26.28 secondes

Val loss 0.5459924184964825 accuracy 0.9054770469665527 macro_avg {'precision': 0.9136834916445619, 'recall': 0.9073799049119483, 'f1-score': 0.9080063419668081, 'support': 1132} weighted_avg {'precision': 0.9117453850209157, 'recall': 0.9054770318021201, 'f1-score': 0.906042489967929, 'support': 1132}
 
----------
Epoch 9/40
time = 770.51 secondes

Train loss 0.10039278836949185 accuracy 0.9781968593597412 macro_avg {'precision': 0.977556252154872, 'recall': 0.9773163814991479, 'f1-score': 0.9774117521712222, 'support': 10182} weighted_avg {'precision': 0.978262576927152, 'recall': 0.9781968179139658, 'f1-score': 0.9782048086633466, 'support': 10182}
 
time = 25.71 secondes

Val loss 0.6527323334561465 accuracy 0.8992933034896851 macro_avg {'precision': 0.9081495814582403, 'recall': 0.8976999437760472, 'f1-score': 0.8990672745425261, 'support': 1132} weighted_avg {'precision': 0.9071045974873065, 'recall': 0.8992932862190812, 'f1-score': 0.8993375609247867, 'support': 1132}
 
----------
Epoch 10/40
time = 766.45 secondes

Train loss 0.11001686446101505 accuracy 0.9770182967185974 macro_avg {'precision': 0.9761394417766539, 'recall': 0.9759155010390991, 'f1-score': 0.9759891068192846, 'support': 10182} weighted_avg {'precision': 0.9770745105583819, 'recall': 0.9770182675309369, 'f1-score': 0.9770077588773887, 'support': 10182}
 
time = 25.72 secondes

Val loss 0.597201738381942 accuracy 0.9134275913238525 macro_avg {'precision': 0.9146031129577535, 'recall': 0.9151176696520956, 'f1-score': 0.913698049846295, 'support': 1132} weighted_avg {'precision': 0.9146983156644966, 'recall': 0.9134275618374559, 'f1-score': 0.9129298750913949, 'support': 1132}
 
----------
Epoch 11/40
time = 766.19 secondes

Train loss 0.10055708454150064 accuracy 0.9796700477600098 macro_avg {'precision': 0.9795662533265226, 'recall': 0.9794269158535178, 'f1-score': 0.9794812792364652, 'support': 10182} weighted_avg {'precision': 0.9796533789008938, 'recall': 0.9796700058927519, 'f1-score': 0.979646053251302, 'support': 10182}
 
time = 26.23 secondes

Val loss 0.5374492783803234 accuracy 0.9116607904434204 macro_avg {'precision': 0.9178053027193945, 'recall': 0.911678694232182, 'f1-score': 0.9131133434581205, 'support': 1132} weighted_avg {'precision': 0.9157061073051106, 'recall': 0.911660777385159, 'f1-score': 0.912012074877652, 'support': 1132}
 
----------
Epoch 12/40
time = 767.67 secondes

Train loss 0.07523725316419798 accuracy 0.9839913845062256 macro_avg {'precision': 0.9837610306472742, 'recall': 0.9838167249383878, 'f1-score': 0.9837627372775726, 'support': 10182} weighted_avg {'precision': 0.9840442824785598, 'recall': 0.9839913572971911, 'f1-score': 0.9839910836336698, 'support': 10182}
 
time = 26.04 secondes

Val loss 0.7264124344291188 accuracy 0.8975265026092529 macro_avg {'precision': 0.9023836863422471, 'recall': 0.9021073580601249, 'f1-score': 0.8986215236238089, 'support': 1132} weighted_avg {'precision': 0.9022241254115754, 'recall': 0.8975265017667845, 'f1-score': 0.895733756517341, 'support': 1132}
 
----------
Epoch 13/40
time = 764.07 secondes

Train loss 0.08287307080581384 accuracy 0.9833039045333862 macro_avg {'precision': 0.9829122239329979, 'recall': 0.9832477626097711, 'f1-score': 0.9830561377139352, 'support': 10182} weighted_avg {'precision': 0.9833706985232601, 'recall': 0.9833038695737576, 'f1-score': 0.983313752197937, 'support': 10182}
 
time = 26.23 secondes

Val loss 0.7602170618026743 accuracy 0.9001767039299011 macro_avg {'precision': 0.9104447098775059, 'recall': 0.8928906700357135, 'f1-score': 0.8960297144770939, 'support': 1132} weighted_avg {'precision': 0.9073922142051706, 'recall': 0.9001766784452296, 'f1-score': 0.8992747814251681, 'support': 1132}
 
----------
Epoch 14/40
time = 770.13 secondes

Train loss 0.08726894972147603 accuracy 0.9829110503196716 macro_avg {'precision': 0.9822790103049346, 'recall': 0.9818931192207149, 'f1-score': 0.9820702001024836, 'support': 10182} weighted_avg {'precision': 0.9829374471327911, 'recall': 0.9829110194460813, 'f1-score': 0.9829099518240502, 'support': 10182}
 
time = 26.47 secondes

Val loss 0.724758009623054 accuracy 0.9028268456459045 macro_avg {'precision': 0.9057096424710565, 'recall': 0.9033938365627575, 'f1-score': 0.9031461539442898, 'support': 1132} weighted_avg {'precision': 0.9043086728179222, 'recall': 0.9028268551236749, 'f1-score': 0.9022094668451662, 'support': 1132}
 
----------
Epoch 15/40
time = 767.44 secondes

Train loss 0.0730835787392577 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860924036855689, 'recall': 0.9858303455249562, 'f1-score': 0.9859515435258187, 'support': 10182} weighted_avg {'precision': 0.986350715127951, 'recall': 0.9863484580632489, 'f1-score': 0.9863410500566635, 'support': 10182}
 
time = 26.19 secondes

Val loss 0.5962033248332274 accuracy 0.9196113348007202 macro_avg {'precision': 0.9263390583498907, 'recall': 0.9182727077631776, 'f1-score': 0.9200057343047563, 'support': 1132} weighted_avg {'precision': 0.926173746215277, 'recall': 0.9196113074204947, 'f1-score': 0.9206178214513991, 'support': 1132}
 
----------
Epoch 16/40
time = 763.62 secondes

Train loss 0.0781285993871279 accuracy 0.9861520528793335 macro_avg {'precision': 0.985879896774027, 'recall': 0.9858127385100615, 'f1-score': 0.9858273470741239, 'support': 10182} weighted_avg {'precision': 0.9861845802243018, 'recall': 0.9861520329994107, 'f1-score': 0.9861509212993507, 'support': 10182}
 
time = 26.04 secondes

Val loss 0.8194562458137253 accuracy 0.8904593586921692 macro_avg {'precision': 0.8941544637669037, 'recall': 0.892280187388954, 'f1-score': 0.8893652103722605, 'support': 1132} weighted_avg {'precision': 0.8975188975082281, 'recall': 0.8904593639575972, 'f1-score': 0.8907534659700781, 'support': 1132}
 
----------
Epoch 17/40
time = 766.27 secondes

Train loss 0.0782238551131615 accuracy 0.9846788644790649 macro_avg {'precision': 0.9842477816661196, 'recall': 0.9839688992595338, 'f1-score': 0.9840801992675388, 'support': 10182} weighted_avg {'precision': 0.98471608508109, 'recall': 0.9846788450206246, 'f1-score': 0.9846704744913527, 'support': 10182}
 
time = 26.01 secondes

Val loss 0.7417218617205 accuracy 0.8939929604530334 macro_avg {'precision': 0.9022441273457174, 'recall': 0.8981129056920709, 'f1-score': 0.8965861277042464, 'support': 1132} weighted_avg {'precision': 0.9027863662591445, 'recall': 0.8939929328621908, 'f1-score': 0.8946852978678895, 'support': 1132}
 
----------
Epoch 18/40
time = 764.64 secondes

Train loss 0.06573557020674686 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860211869529028, 'recall': 0.9860338263660899, 'f1-score': 0.9860031217905444, 'support': 10182} weighted_avg {'precision': 0.9863932696077052, 'recall': 0.9863484580632489, 'f1-score': 0.9863468249065231, 'support': 10182}
 
time = 26.96 secondes

Val loss 0.678361593169926 accuracy 0.9107773900032043 macro_avg {'precision': 0.914802961095736, 'recall': 0.912512607915939, 'f1-score': 0.9119201154115455, 'support': 1132} weighted_avg {'precision': 0.9160512931788432, 'recall': 0.9107773851590106, 'f1-score': 0.9115455287815484, 'support': 1132}
 
----------
Epoch 19/40
time = 768.10 secondes

Train loss 0.06147900433742174 accuracy 0.9881163239479065 macro_avg {'precision': 0.9880040209771431, 'recall': 0.9880052851216284, 'f1-score': 0.9879925349309092, 'support': 10182} weighted_avg {'precision': 0.9881433069006849, 'recall': 0.9881162836377921, 'f1-score': 0.9881175394019748, 'support': 10182}
 
time = 26.13 secondes

Val loss 0.693783710839622 accuracy 0.9045936465263367 macro_avg {'precision': 0.9083900688176657, 'recall': 0.9052563347367706, 'f1-score': 0.9048949001701759, 'support': 1132} weighted_avg {'precision': 0.9086181748492659, 'recall': 0.9045936395759717, 'f1-score': 0.9046284993116639, 'support': 1132}
 
----------
Epoch 20/40
time = 767.16 secondes

Train loss 0.05251523064801874 accuracy 0.98978590965271 macro_avg {'precision': 0.9898173246470954, 'recall': 0.9896813994231021, 'f1-score': 0.989739550363114, 'support': 10182} weighted_avg {'precision': 0.9898271385614065, 'recall': 0.9897858966804164, 'f1-score': 0.9897964802369357, 'support': 10182}
 
time = 26.43 secondes

Val loss 0.730046014588418 accuracy 0.9134275913238525 macro_avg {'precision': 0.9201719340967761, 'recall': 0.9148685251218118, 'f1-score': 0.9156323874803928, 'support': 1132} weighted_avg {'precision': 0.9178077280946397, 'recall': 0.9134275618374559, 'f1-score': 0.9136189356684414, 'support': 1132}
 
----------
Epoch 21/40
time = 768.48 secondes

Train loss 0.06471821027315136 accuracy 0.9886073470115662 macro_avg {'precision': 0.9879720797256816, 'recall': 0.9881803160973724, 'f1-score': 0.9880604535438728, 'support': 10182} weighted_avg {'precision': 0.988637563417663, 'recall': 0.9886073462973876, 'f1-score': 0.9886088009200503, 'support': 10182}
 
time = 25.76 secondes

Val loss 0.7411680286395622 accuracy 0.9072438478469849 macro_avg {'precision': 0.9155360947674346, 'recall': 0.9095517029381129, 'f1-score': 0.9091246073574574, 'support': 1132} weighted_avg {'precision': 0.9161960097226443, 'recall': 0.907243816254417, 'f1-score': 0.9082449515330879, 'support': 1132}
 
----------
Epoch 22/40
time = 768.10 secondes

Train loss 0.05728615259640562 accuracy 0.9893930554389954 macro_avg {'precision': 0.989070280364343, 'recall': 0.9891523750717811, 'f1-score': 0.9890984990823373, 'support': 10182} weighted_avg {'precision': 0.9894231322835164, 'recall': 0.9893930465527401, 'f1-score': 0.989395074485271, 'support': 10182}
 
time = 25.91 secondes

Val loss 0.7359306780772258 accuracy 0.9107773900032043 macro_avg {'precision': 0.9198844741899844, 'recall': 0.9151599435785973, 'f1-score': 0.9142414868064556, 'support': 1132} weighted_avg {'precision': 0.9208153231634278, 'recall': 0.9107773851590106, 'f1-score': 0.9123789440565764, 'support': 1132}
 
----------
Epoch 23/40
time = 767.39 secondes

Train loss 0.05991284031373156 accuracy 0.98978590965271 macro_avg {'precision': 0.9898044769904978, 'recall': 0.9898207076852632, 'f1-score': 0.9898014641879822, 'support': 10182} weighted_avg {'precision': 0.9897918442670648, 'recall': 0.9897858966804164, 'f1-score': 0.9897776888437246, 'support': 10182}
 
time = 25.89 secondes

Val loss 0.6149279242924588 accuracy 0.9213780760765076 macro_avg {'precision': 0.9235698767825884, 'recall': 0.923409972130786, 'f1-score': 0.9227728955549944, 'support': 1132} weighted_avg {'precision': 0.9227916990006332, 'recall': 0.9213780918727915, 'f1-score': 0.9213500175039802, 'support': 1132}
 
----------
Epoch 24/40
time = 764.56 secondes

Train loss 0.044030583770341664 accuracy 0.991750180721283 macro_avg {'precision': 0.9917868067069717, 'recall': 0.9917507512207677, 'f1-score': 0.9917535608734716, 'support': 10182} weighted_avg {'precision': 0.9917687553755192, 'recall': 0.9917501473187978, 'f1-score': 0.9917439201764492, 'support': 10182}
 
time = 26.14 secondes

Val loss 0.7622961111511858 accuracy 0.9143109321594238 macro_avg {'precision': 0.9239334765956217, 'recall': 0.9160861843120305, 'f1-score': 0.9172455530059397, 'support': 1132} weighted_avg {'precision': 0.9212382678495125, 'recall': 0.9143109540636042, 'f1-score': 0.9148503484965166, 'support': 1132}
 
----------
Epoch 25/40
time = 766.37 secondes

Train loss 0.04589476422073661 accuracy 0.9919465780258179 macro_avg {'precision': 0.9915640051668083, 'recall': 0.9914435690732969, 'f1-score': 0.9914939993259434, 'support': 10182} weighted_avg {'precision': 0.9919651581020994, 'recall': 0.9919465723826361, 'f1-score': 0.9919464667411052, 'support': 10182}
 
time = 26.09 secondes

Val loss 0.7067165101900276 accuracy 0.9125441908836365 macro_avg {'precision': 0.9208875174528675, 'recall': 0.9136128991112333, 'f1-score': 0.9154110960940864, 'support': 1132} weighted_avg {'precision': 0.9175648828641655, 'recall': 0.9125441696113075, 'f1-score': 0.9130246329155449, 'support': 1132}
 
----------
Epoch 26/40
time = 766.15 secondes

Train loss 0.04585659989872505 accuracy 0.9927322864532471 macro_avg {'precision': 0.9919036064763332, 'recall': 0.9921758993427876, 'f1-score': 0.9920298037483466, 'support': 10182} weighted_avg {'precision': 0.9927775720432874, 'recall': 0.9927322726379886, 'f1-score': 0.9927468229115042, 'support': 10182}
 
time = 26.66 secondes

Val loss 0.7478584032140415 accuracy 0.9098939895629883 macro_avg {'precision': 0.914888724246756, 'recall': 0.9130245479180864, 'f1-score': 0.9122264029141747, 'support': 1132} weighted_avg {'precision': 0.914986470291425, 'recall': 0.9098939929328622, 'f1-score': 0.9108167022064709, 'support': 1132}
 
----------
Epoch 27/40
time = 766.83 secondes

Train loss 0.03619205898121579 accuracy 0.993812620639801 macro_avg {'precision': 0.9933929781549118, 'recall': 0.9932086983405647, 'f1-score': 0.9932968992645886, 'support': 10182} weighted_avg {'precision': 0.9938136151600101, 'recall': 0.9938126104890984, 'f1-score': 0.9938097201415741, 'support': 10182}
 
time = 26.21 secondes

Val loss 0.8319672754992162 accuracy 0.9045936465263367 macro_avg {'precision': 0.9108000887164417, 'recall': 0.908551774154138, 'f1-score': 0.9054280195835348, 'support': 1132} weighted_avg {'precision': 0.9118574768329453, 'recall': 0.9045936395759717, 'f1-score': 0.9033562202746215, 'support': 1132}
 
----------
Epoch 28/40
time = 765.79 secondes

Train loss 0.035713566978984444 accuracy 0.9935179948806763 macro_avg {'precision': 0.9935265861862621, 'recall': 0.9934572796859141, 'f1-score': 0.993485905779945, 'support': 10182} weighted_avg {'precision': 0.9935300665631016, 'recall': 0.9935179728933412, 'f1-score': 0.993518316526113, 'support': 10182}
 
time = 26.04 secondes

Val loss 0.7352592958771529 accuracy 0.9151943325996399 macro_avg {'precision': 0.9187685552876019, 'recall': 0.9177831659564486, 'f1-score': 0.9162897647126078, 'support': 1132} weighted_avg {'precision': 0.9195142912748326, 'recall': 0.9151943462897526, 'f1-score': 0.9151571975217797, 'support': 1132}
 
----------
Epoch 29/40
time = 768.04 secondes

Train loss 0.0357989102956014 accuracy 0.9934197664260864 macro_avg {'precision': 0.9936144639138556, 'recall': 0.99349958221827, 'f1-score': 0.9935519813673233, 'support': 10182} weighted_avg {'precision': 0.9934366193730471, 'recall': 0.9934197603614221, 'f1-score': 0.9934231257104774, 'support': 10182}
 
time = 26.55 secondes

Val loss 0.704059490339589 accuracy 0.9178445339202881 macro_avg {'precision': 0.9234009613369645, 'recall': 0.9209184643125891, 'f1-score': 0.9205478429800935, 'support': 1132} weighted_avg {'precision': 0.9229176062497775, 'recall': 0.9178445229681979, 'f1-score': 0.9186367372970144, 'support': 1132}
 
----------
Epoch 30/40
time = 764.87 secondes

Train loss 0.03550821399584545 accuracy 0.9945001006126404 macro_avg {'precision': 0.9945323583748629, 'recall': 0.9944869281816867, 'f1-score': 0.9945059409096324, 'support': 10182} weighted_avg {'precision': 0.9945106723491639, 'recall': 0.9945000982125319, 'f1-score': 0.9945015838696165, 'support': 10182}
 
time = 26.18 secondes

Val loss 0.7272792888946588 accuracy 0.9204947352409363 macro_avg {'precision': 0.9234653827802898, 'recall': 0.922335010109767, 'f1-score': 0.921764454092622, 'support': 1132} weighted_avg {'precision': 0.9227367891103107, 'recall': 0.9204946996466431, 'f1-score': 0.9204204356759219, 'support': 1132}
 
----------
Epoch 31/40
time = 765.45 secondes

Train loss 0.030034986372027696 accuracy 0.9950894117355347 macro_avg {'precision': 0.9948342437541919, 'recall': 0.9948401911384381, 'f1-score': 0.9948256979868221, 'support': 10182} weighted_avg {'precision': 0.9951058935035427, 'recall': 0.9950893734040464, 'f1-score': 0.995087192111432, 'support': 10182}
 
time = 26.21 secondes

Val loss 0.7811331122306205 accuracy 0.916077733039856 macro_avg {'precision': 0.9217539146172404, 'recall': 0.9205488361756764, 'f1-score': 0.9181856172814378, 'support': 1132} weighted_avg {'precision': 0.9240830954087617, 'recall': 0.916077738515901, 'f1-score': 0.9172257337759557, 'support': 1132}
 
----------
Epoch 32/40
time = 767.32 secondes

Train loss 0.02256433667646787 accuracy 0.9954822659492493 macro_avg {'precision': 0.9953365042369878, 'recall': 0.9953548717024047, 'f1-score': 0.9953393380713658, 'support': 10182} weighted_avg {'precision': 0.9954936017572917, 'recall': 0.9954822235317227, 'f1-score': 0.9954820427312088, 'support': 10182}
 
time = 26.83 secondes

Val loss 0.670795983548295 accuracy 0.926678478717804 macro_avg {'precision': 0.9297975844556348, 'recall': 0.9301880026510476, 'f1-score': 0.9287634460310891, 'support': 1132} weighted_avg {'precision': 0.9293634168966268, 'recall': 0.926678445229682, 'f1-score': 0.9267753720912434, 'support': 1132}
 
----------
Epoch 33/40
time = 766.74 secondes

Train loss 0.03448951849446927 accuracy 0.9950894117355347 macro_avg {'precision': 0.9950015604058052, 'recall': 0.9950162564483781, 'f1-score': 0.9949942203653694, 'support': 10182} weighted_avg {'precision': 0.9951114086466056, 'recall': 0.9950893734040464, 'f1-score': 0.9950854984392615, 'support': 10182}
 
time = 26.07 secondes

Val loss 0.7527822067492361 accuracy 0.9143109321594238 macro_avg {'precision': 0.9198320622713603, 'recall': 0.9171941694981454, 'f1-score': 0.9165830123505968, 'support': 1132} weighted_avg {'precision': 0.9197953558271037, 'recall': 0.9143109540636042, 'f1-score': 0.9150836905649988, 'support': 1132}
 
----------
Epoch 34/40
time = 768.46 secondes

Train loss 0.01923151898878914 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970447757790118, 'recall': 0.9970056666795959, 'f1-score': 0.9970230102900868, 'support': 10182} weighted_avg {'precision': 0.9970548216174691, 'recall': 0.9970536240424278, 'f1-score': 0.9970521739727785, 'support': 10182}
 
time = 26.42 secondes

Val loss 0.7459155395803797 accuracy 0.9187279343605042 macro_avg {'precision': 0.9272917381263822, 'recall': 0.9227905032368262, 'f1-score': 0.9222009061812753, 'support': 1132} weighted_avg {'precision': 0.9266592830643263, 'recall': 0.9187279151943463, 'f1-score': 0.9196890299973277, 'support': 1132}
 
----------
Epoch 35/40
time = 765.99 secondes

Train loss 0.02146149805340604 accuracy 0.996857225894928 macro_avg {'precision': 0.9967997175556684, 'recall': 0.9967942831942727, 'f1-score': 0.9967849965408824, 'support': 10182} weighted_avg {'precision': 0.996876709721231, 'recall': 0.9968571989785897, 'f1-score': 0.9968544623775378, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.723062594147924 accuracy 0.9222614765167236 macro_avg {'precision': 0.928985873061823, 'recall': 0.9274248620696405, 'f1-score': 0.9254851782669109, 'support': 1132} weighted_avg {'precision': 0.9298465865874422, 'recall': 0.9222614840989399, 'f1-score': 0.923156446207166, 'support': 1132}
 
----------
Epoch 36/40
time = 767.64 secondes

Train loss 0.013712982331616242 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975911418387277, 'recall': 0.9974987893023709, 'f1-score': 0.9975433879011245, 'support': 10182} weighted_avg {'precision': 0.9975498472043298, 'recall': 0.9975446867020232, 'f1-score': 0.9975456736915271, 'support': 10182}
 
time = 26.44 secondes

Val loss 0.6634794584852116 accuracy 0.926678478717804 macro_avg {'precision': 0.9304922850725971, 'recall': 0.9302213361707871, 'f1-score': 0.9289799814254373, 'support': 1132} weighted_avg {'precision': 0.9300152012040337, 'recall': 0.926678445229682, 'f1-score': 0.926926652521254, 'support': 1132}
 
----------
Epoch 37/40
time = 768.80 secondes

Train loss 0.010947413324560205 accuracy 0.9976429343223572 macro_avg {'precision': 0.9974009786787252, 'recall': 0.9973340737599928, 'f1-score': 0.9973655814524441, 'support': 10182} weighted_avg {'precision': 0.9976465027650914, 'recall': 0.9976428992339422, 'f1-score': 0.9976427313772736, 'support': 10182}
 
time = 26.73 secondes

Val loss 0.7046788648285272 accuracy 0.9257950782775879 macro_avg {'precision': 0.9304612966447333, 'recall': 0.9288744126226058, 'f1-score': 0.9279841246306398, 'support': 1132} weighted_avg {'precision': 0.9308516333925064, 'recall': 0.9257950530035336, 'f1-score': 0.9266164615196354, 'support': 1132}
 
----------
Epoch 38/40
time = 766.92 secondes

Train loss 0.011959669182504561 accuracy 0.9983304142951965 macro_avg {'precision': 0.9982933281661065, 'recall': 0.9982659753676538, 'f1-score': 0.9982789133513649, 'support': 10182} weighted_avg {'precision': 0.998331616176419, 'recall': 0.9983303869573757, 'f1-score': 0.9983302488560071, 'support': 10182}
 
time = 26.43 secondes

Val loss 0.6857911084688068 accuracy 0.9213780760765076 macro_avg {'precision': 0.9240178229709904, 'recall': 0.9245433765207883, 'f1-score': 0.923135972341705, 'support': 1132} weighted_avg {'precision': 0.9239013737005791, 'recall': 0.9213780918727915, 'f1-score': 0.9213966051295687, 'support': 1132}
 
----------
Epoch 39/40
time = 771.06 secondes

Train loss 0.008626178407786103 accuracy 0.9986250400543213 macro_avg {'precision': 0.9985788392181766, 'recall': 0.9985914899257959, 'f1-score': 0.9985837644437829, 'support': 10182} weighted_avg {'precision': 0.9986275006966295, 'recall': 0.998625024553133, 'f1-score': 0.9986248417988374, 'support': 10182}
 
time = 25.75 secondes

Val loss 0.6742413681946141 accuracy 0.9257950782775879 macro_avg {'precision': 0.9282803360270699, 'recall': 0.929238166797292, 'f1-score': 0.9273356410162563, 'support': 1132} weighted_avg {'precision': 0.9290199113583544, 'recall': 0.9257950530035336, 'f1-score': 0.9258401297553229, 'support': 1132}
 
----------
Epoch 40/40
time = 765.30 secondes

Train loss 0.0029001068093978343 accuracy 0.9994107484817505 macro_avg {'precision': 0.999363168950117, 'recall': 0.9994208811215314, 'f1-score': 0.9993912898193488, 'support': 10182} weighted_avg {'precision': 0.9994117921294557, 'recall': 0.9994107248084856, 'f1-score': 0.9994105604889904, 'support': 10182}
 
time = 26.28 secondes

Val loss 0.6733708094703666 accuracy 0.9293286204338074 macro_avg {'precision': 0.9345003456361127, 'recall': 0.9326071475902824, 'f1-score': 0.932218373520324, 'support': 1132} weighted_avg {'precision': 0.9325265191392965, 'recall': 0.9293286219081273, 'f1-score': 0.9294797497889753, 'support': 1132}
 
----------
best_accuracy 0.9293286204338074 best_epoch 40 macro_avg {'precision': 0.9345003456361127, 'recall': 0.9326071475902824, 'f1-score': 0.932218373520324, 'support': 1132} weighted_avg {'precision': 0.9325265191392965, 'recall': 0.9293286219081273, 'f1-score': 0.9294797497889753, 'support': 1132}

average train time 767.8826164543628

average val time 26.221615010499953
 
time = 174.57 secondes

test_accuracy 0.8647105693817139 macro_avg {'precision': 0.8624275841639492, 'recall': 0.8569456416137674, 'f1-score': 0.8580021352432039, 'support': 7532} weighted_avg {'precision': 0.8676777601141179, 'recall': 0.8647105682421667, 'f1-score': 0.8646248478937791, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_3
----------
Epoch 1/40
time = 1173.61 secondes

Train loss 1.081395996901173 accuracy 0.696817934513092 macro_avg {'precision': 0.6943097352047595, 'recall': 0.6839493632880472, 'f1-score': 0.680312320408307, 'support': 10182} weighted_avg {'precision': 0.7049632669211721, 'recall': 0.696817913965822, 'f1-score': 0.6935456598216844, 'support': 10182}
 
time = 34.32 secondes

Val loss 0.5547278356594099 accuracy 0.8383392095565796 macro_avg {'precision': 0.8331145057059975, 'recall': 0.8318205695694584, 'f1-score': 0.8277415083670938, 'support': 1132} weighted_avg {'precision': 0.8361158136504567, 'recall': 0.838339222614841, 'f1-score': 0.8331274228120261, 'support': 1132}
 
----------
Epoch 2/40
time = 1186.69 secondes

Train loss 0.3992908700125137 accuracy 0.8846985101699829 macro_avg {'precision': 0.8774667703199601, 'recall': 0.8761048800674514, 'f1-score': 0.875913460188299, 'support': 10182} weighted_avg {'precision': 0.8833379230640036, 'recall': 0.8846984875270084, 'f1-score': 0.8833496680849042, 'support': 10182}
 
time = 32.79 secondes

Val loss 0.5006927799328532 accuracy 0.8648409843444824 macro_avg {'precision': 0.8667965628521033, 'recall': 0.8636928050846899, 'f1-score': 0.8604108659811465, 'support': 1132} weighted_avg {'precision': 0.8716358837816927, 'recall': 0.8648409893992933, 'f1-score': 0.8632153538938169, 'support': 1132}
 
----------
Epoch 3/40
time = 1656.11 secondes

Train loss 0.23909321215056362 accuracy 0.9310548305511475 macro_avg {'precision': 0.9272579656389699, 'recall': 0.9266378462989262, 'f1-score': 0.926877459999609, 'support': 10182} weighted_avg {'precision': 0.9311213608532841, 'recall': 0.9310548025928108, 'f1-score': 0.9310207714004581, 'support': 10182}
 
time = 44.55 secondes

Val loss 0.45566272743466035 accuracy 0.8939929604530334 macro_avg {'precision': 0.902361738451084, 'recall': 0.8940876132161255, 'f1-score': 0.8950041436149409, 'support': 1132} weighted_avg {'precision': 0.9020166504779575, 'recall': 0.8939929328621908, 'f1-score': 0.8946179938886708, 'support': 1132}
 
----------
Epoch 4/40
time = 1553.86 secondes

Train loss 0.18976014166824764 accuracy 0.94883131980896 macro_avg {'precision': 0.9460383832727459, 'recall': 0.946168983166015, 'f1-score': 0.9460282029987359, 'support': 10182} weighted_avg {'precision': 0.9488893422898845, 'recall': 0.9488312708701631, 'f1-score': 0.9487838638665756, 'support': 10182}
 
time = 44.16 secondes

Val loss 0.585024341878573 accuracy 0.8878092169761658 macro_avg {'precision': 0.8922228671322563, 'recall': 0.8930236724536925, 'f1-score': 0.8875105655348499, 'support': 1132} weighted_avg {'precision': 0.8971805933231499, 'recall': 0.8878091872791519, 'f1-score': 0.8867487085559751, 'support': 1132}
 
----------
Epoch 5/40
time = 1550.74 secondes

Train loss 0.16924462220090583 accuracy 0.9566882848739624 macro_avg {'precision': 0.9544730361688976, 'recall': 0.9543579016441809, 'f1-score': 0.9543898475518036, 'support': 10182} weighted_avg {'precision': 0.956691199804906, 'recall': 0.9566882734236889, 'f1-score': 0.9566637996834075, 'support': 10182}
 
time = 41.93 secondes

Val loss 0.4936837859150075 accuracy 0.9019434452056885 macro_avg {'precision': 0.9025260417854495, 'recall': 0.8990441025921116, 'f1-score': 0.8993033243929596, 'support': 1132} weighted_avg {'precision': 0.9029251410751621, 'recall': 0.9019434628975265, 'f1-score': 0.9009994325359537, 'support': 1132}
 
----------
Epoch 6/40
time = 1548.17 secondes

Train loss 0.14202701443306637 accuracy 0.9662148952484131 macro_avg {'precision': 0.9650257064629942, 'recall': 0.9651025715500804, 'f1-score': 0.965012662473905, 'support': 10182} weighted_avg {'precision': 0.9663420028526616, 'recall': 0.966214889019839, 'f1-score': 0.9662300783732154, 'support': 10182}
 
time = 45.33 secondes

Val loss 0.6243408449366361 accuracy 0.8966431021690369 macro_avg {'precision': 0.8990538587541199, 'recall': 0.8959388378186134, 'f1-score': 0.894539289133853, 'support': 1132} weighted_avg {'precision': 0.8993820850058719, 'recall': 0.8966431095406361, 'f1-score': 0.894961537220134, 'support': 1132}
 
----------
Epoch 7/40
time = 1546.14 secondes

Train loss 0.1365213273218292 accuracy 0.967197060585022 macro_avg {'precision': 0.9667653669553763, 'recall': 0.9662271472819386, 'f1-score': 0.9664572013208332, 'support': 10182} weighted_avg {'precision': 0.9672290158183522, 'recall': 0.9671970143390297, 'f1-score': 0.9671755421502458, 'support': 10182}
 
time = 43.14 secondes

Val loss 0.6819293846738603 accuracy 0.8913427591323853 macro_avg {'precision': 0.8998367587282233, 'recall': 0.8917274028830988, 'f1-score': 0.8923644609757606, 'support': 1132} weighted_avg {'precision': 0.8971323467602277, 'recall': 0.8913427561837456, 'f1-score': 0.8909811543525081, 'support': 1132}
 
----------
Epoch 8/40
time = 1557.00 secondes

Train loss 0.12435214839762572 accuracy 0.9726969599723816 macro_avg {'precision': 0.9722759269770445, 'recall': 0.972281866572135, 'f1-score': 0.9722252822408635, 'support': 10182} weighted_avg {'precision': 0.9728702956168603, 'recall': 0.9726969161264978, 'f1-score': 0.9727349816400147, 'support': 10182}
 
time = 42.56 secondes

Val loss 0.6511508396795531 accuracy 0.9037102460861206 macro_avg {'precision': 0.9088275241808438, 'recall': 0.9077165434532098, 'f1-score': 0.9039412336509705, 'support': 1132} weighted_avg {'precision': 0.9084030125563278, 'recall': 0.9037102473498233, 'f1-score': 0.9010254042771808, 'support': 1132}
 
----------
Epoch 9/40
time = 1545.47 secondes

Train loss 0.11994642934461675 accuracy 0.9745630025863647 macro_avg {'precision': 0.9745036068771293, 'recall': 0.9737595322289438, 'f1-score': 0.97408697235905, 'support': 10182} weighted_avg {'precision': 0.974556449376308, 'recall': 0.9745629542329601, 'f1-score': 0.9745185739363992, 'support': 10182}
 
time = 42.31 secondes

Val loss 0.7294233435150859 accuracy 0.8992933034896851 macro_avg {'precision': 0.90688264777563, 'recall': 0.9021598890458105, 'f1-score': 0.900692000830641, 'support': 1132} weighted_avg {'precision': 0.9063384896861693, 'recall': 0.8992932862190812, 'f1-score': 0.8985757537921514, 'support': 1132}
 
----------
Epoch 10/40
time = 1473.06 secondes

Train loss 0.10392636440711603 accuracy 0.9775093793869019 macro_avg {'precision': 0.9768985745634804, 'recall': 0.9770083934118615, 'f1-score': 0.976931577896259, 'support': 10182} weighted_avg {'precision': 0.9775448660710044, 'recall': 0.9775093301905323, 'f1-score': 0.9775052760508043, 'support': 10182}
 
time = 32.38 secondes

Val loss 0.7087583340410123 accuracy 0.9045936465263367 macro_avg {'precision': 0.9134354591136212, 'recall': 0.9042406815827231, 'f1-score': 0.9061797244599031, 'support': 1132} weighted_avg {'precision': 0.9106591830757785, 'recall': 0.9045936395759717, 'f1-score': 0.9050716683761956, 'support': 1132}
 
----------
Epoch 11/40
time = 1140.55 secondes

Train loss 0.11428199034102708 accuracy 0.9769200682640076 macro_avg {'precision': 0.9766518555657331, 'recall': 0.976003268683151, 'f1-score': 0.9762963400947535, 'support': 10182} weighted_avg {'precision': 0.9769270129525479, 'recall': 0.9769200549990179, 'f1-score': 0.9768961089638974, 'support': 10182}
 
time = 33.24 secondes

Val loss 0.6559131996055186 accuracy 0.9019434452056885 macro_avg {'precision': 0.9077428912916756, 'recall': 0.9059548352779627, 'f1-score': 0.9024126794804899, 'support': 1132} weighted_avg {'precision': 0.9087070898014589, 'recall': 0.9019434628975265, 'f1-score': 0.9003304208678007, 'support': 1132}
 
----------
Epoch 12/40
time = 1145.30 secondes

Train loss 0.10637474702636447 accuracy 0.9787861108779907 macro_avg {'precision': 0.9780268999648489, 'recall': 0.9784875937628541, 'f1-score': 0.978227444676228, 'support': 10182} weighted_avg {'precision': 0.978849560070865, 'recall': 0.9787860931054803, 'f1-score': 0.9787935615972277, 'support': 10182}
 
time = 32.31 secondes

Val loss 0.651494665836266 accuracy 0.9072438478469849 macro_avg {'precision': 0.9108792186680166, 'recall': 0.9096244970276753, 'f1-score': 0.9082558293182906, 'support': 1132} weighted_avg {'precision': 0.9117760757076575, 'recall': 0.907243816254417, 'f1-score': 0.9074720142696523, 'support': 1132}
 
----------
Epoch 13/40
time = 1136.67 secondes

Train loss 0.09863761000357969 accuracy 0.9806521534919739 macro_avg {'precision': 0.9793928946929962, 'recall': 0.9794292407305025, 'f1-score': 0.97939240560431, 'support': 10182} weighted_avg {'precision': 0.9806750281831358, 'recall': 0.9806521312119426, 'f1-score': 0.9806451824861662, 'support': 10182}
 
time = 33.20 secondes

Val loss 0.6247111160609818 accuracy 0.9125441908836365 macro_avg {'precision': 0.9174596272249159, 'recall': 0.9150437235212087, 'f1-score': 0.9145182524509362, 'support': 1132} weighted_avg {'precision': 0.9170015046381973, 'recall': 0.9125441696113075, 'f1-score': 0.9129464876585034, 'support': 1132}
 
----------
Epoch 14/40
time = 1142.62 secondes

Train loss 0.09157226328124249 accuracy 0.982518196105957 macro_avg {'precision': 0.9817640882246156, 'recall': 0.9816099269848098, 'f1-score': 0.9816685952257277, 'support': 10182} weighted_avg {'precision': 0.9825384909182318, 'recall': 0.9825181693184051, 'f1-score': 0.9825120074704914, 'support': 10182}
 
time = 33.95 secondes

Val loss 0.7001158989065951 accuracy 0.9063604474067688 macro_avg {'precision': 0.9150492806981134, 'recall': 0.9094603268994691, 'f1-score': 0.9092377966856109, 'support': 1132} weighted_avg {'precision': 0.9139856997005169, 'recall': 0.9063604240282686, 'f1-score': 0.9071493959903068, 'support': 1132}
 
----------
Epoch 15/40
time = 1132.87 secondes

Train loss 0.07552903109779556 accuracy 0.9846788644790649 macro_avg {'precision': 0.9841149405415486, 'recall': 0.9846799669904793, 'f1-score': 0.9843679504684122, 'support': 10182} weighted_avg {'precision': 0.9847559893728904, 'recall': 0.9846788450206246, 'f1-score': 0.9846922142860114, 'support': 10182}
 
time = 33.23 secondes

Val loss 0.9069673075477189 accuracy 0.8851590156555176 macro_avg {'precision': 0.8953894171090176, 'recall': 0.8888481041539344, 'f1-score': 0.8872462368047198, 'support': 1132} weighted_avg {'precision': 0.8969372429530377, 'recall': 0.8851590106007067, 'f1-score': 0.8860732599216901, 'support': 1132}
 
----------
Epoch 16/40
time = 1144.87 secondes

Train loss 0.0893056015896149 accuracy 0.9842860102653503 macro_avg {'precision': 0.9844319266901369, 'recall': 0.9842681143410056, 'f1-score': 0.9843382050881196, 'support': 10182} weighted_avg {'precision': 0.9843127331715241, 'recall': 0.9842859948929483, 'f1-score': 0.984287210439469, 'support': 10182}
 
time = 35.06 secondes

Val loss 0.6773878009350394 accuracy 0.9098939895629883 macro_avg {'precision': 0.9119379804331682, 'recall': 0.9104636828131385, 'f1-score': 0.9094968205914773, 'support': 1132} weighted_avg {'precision': 0.9131146632456875, 'recall': 0.9098939929328622, 'f1-score': 0.9096543302337006, 'support': 1132}
 
----------
Epoch 17/40
time = 1158.04 secondes

Train loss 0.0770844380902566 accuracy 0.9861520528793335 macro_avg {'precision': 0.9859054951422074, 'recall': 0.9859046438312019, 'f1-score': 0.9858830845174191, 'support': 10182} weighted_avg {'precision': 0.9861633791307028, 'recall': 0.9861520329994107, 'f1-score': 0.9861359216408155, 'support': 10182}
 
time = 32.81 secondes

Val loss 0.6379471121137202 accuracy 0.916961133480072 macro_avg {'precision': 0.9201785436603933, 'recall': 0.9191735963029863, 'f1-score': 0.9186856519502609, 'support': 1132} weighted_avg {'precision': 0.9195236991599733, 'recall': 0.9169611307420494, 'f1-score': 0.9172336708188392, 'support': 1132}
 
----------
Epoch 18/40
time = 1135.64 secondes

Train loss 0.08257209258175965 accuracy 0.9845806360244751 macro_avg {'precision': 0.9839392298030578, 'recall': 0.9843305866466279, 'f1-score': 0.9841082770234099, 'support': 10182} weighted_avg {'precision': 0.984651157241127, 'recall': 0.9845806324887055, 'f1-score': 0.9845906443280854, 'support': 10182}
 
time = 33.26 secondes

Val loss 0.751074045312404 accuracy 0.9081271886825562 macro_avg {'precision': 0.9154421853191884, 'recall': 0.9081391166156034, 'f1-score': 0.9098566754252607, 'support': 1132} weighted_avg {'precision': 0.9131026896158955, 'recall': 0.9081272084805654, 'f1-score': 0.9086910684863724, 'support': 1132}
 
----------
Epoch 19/40
time = 1144.66 secondes

Train loss 0.05819999324046581 accuracy 0.9881163239479065 macro_avg {'precision': 0.9877093466801707, 'recall': 0.9877431263841061, 'f1-score': 0.9877171126632325, 'support': 10182} weighted_avg {'precision': 0.988149431082576, 'recall': 0.9881162836377921, 'f1-score': 0.9881237139564841, 'support': 10182}
 
time = 30.11 secondes

Val loss 0.5966175246125408 accuracy 0.9151943325996399 macro_avg {'precision': 0.9206635900786997, 'recall': 0.9185208991550196, 'f1-score': 0.9186757643294603, 'support': 1132} weighted_avg {'precision': 0.9180967438314902, 'recall': 0.9151943462897526, 'f1-score': 0.9157175386364931, 'support': 1132}
 
----------
Epoch 20/40
time = 1149.84 secondes

Train loss 0.06208652966575881 accuracy 0.9893930554389954 macro_avg {'precision': 0.9888038869343794, 'recall': 0.9891352412602472, 'f1-score': 0.9889537924081717, 'support': 10182} weighted_avg {'precision': 0.9894286159251472, 'recall': 0.9893930465527401, 'f1-score': 0.9893964701825004, 'support': 10182}
 
time = 33.73 secondes

Val loss 0.6546849777691868 accuracy 0.9134275913238525 macro_avg {'precision': 0.9172758828136225, 'recall': 0.9141784729786091, 'f1-score': 0.9145867302329622, 'support': 1132} weighted_avg {'precision': 0.9156295542264818, 'recall': 0.9134275618374559, 'f1-score': 0.9133688242998868, 'support': 1132}
 
----------
Epoch 21/40
time = 1128.78 secondes

Train loss 0.06503734812469654 accuracy 0.9882145524024963 macro_avg {'precision': 0.9876846631516413, 'recall': 0.9877632758236062, 'f1-score': 0.9877146496258458, 'support': 10182} weighted_avg {'precision': 0.9882482434696489, 'recall': 0.9882144961697112, 'f1-score': 0.9882224612673788, 'support': 10182}
 
time = 33.31 secondes

Val loss 0.6293067669121485 accuracy 0.9151943325996399 macro_avg {'precision': 0.9157963133349639, 'recall': 0.9169593091616633, 'f1-score': 0.9154409412388146, 'support': 1132} weighted_avg {'precision': 0.917415125939456, 'recall': 0.9151943462897526, 'f1-score': 0.915436714467778, 'support': 1132}
 
----------
Epoch 22/40
time = 1141.31 secondes

Train loss 0.05829975231220486 accuracy 0.9886073470115662 macro_avg {'precision': 0.9887564865877791, 'recall': 0.9886247886456114, 'f1-score': 0.9886791518009549, 'support': 10182} weighted_avg {'precision': 0.9886376706586592, 'recall': 0.9886073462973876, 'f1-score': 0.9886110232854, 'support': 10182}
 
time = 33.27 secondes

Val loss 0.6397161412375206 accuracy 0.9143109321594238 macro_avg {'precision': 0.9180331889876225, 'recall': 0.9165908415190296, 'f1-score': 0.9162232364310112, 'support': 1132} weighted_avg {'precision': 0.9177094129002562, 'recall': 0.9143109540636042, 'f1-score': 0.9149909247347997, 'support': 1132}
 
----------
Epoch 23/40
time = 1132.11 secondes

Train loss 0.05209803959587589 accuracy 0.98978590965271 macro_avg {'precision': 0.9898531211115262, 'recall': 0.9895782445114157, 'f1-score': 0.9897005977408261, 'support': 10182} weighted_avg {'precision': 0.9898058744268339, 'recall': 0.9897858966804164, 'f1-score': 0.9897809825089032, 'support': 10182}
 
time = 33.51 secondes

Val loss 0.6421949171136718 accuracy 0.9178445339202881 macro_avg {'precision': 0.919627908451514, 'recall': 0.9186520605092545, 'f1-score': 0.9185310681644759, 'support': 1132} weighted_avg {'precision': 0.9193325165237043, 'recall': 0.9178445229681979, 'f1-score': 0.9180360890964352, 'support': 1132}
 
----------
Epoch 24/40
time = 1132.73 secondes

Train loss 0.06775351457178416 accuracy 0.9892948865890503 macro_avg {'precision': 0.9892295261564066, 'recall': 0.9892564015495122, 'f1-score': 0.9892099736175372, 'support': 10182} weighted_avg {'precision': 0.9893541334776268, 'recall': 0.9892948340208211, 'f1-score': 0.9892905436616569, 'support': 10182}
 
time = 35.62 secondes

Val loss 0.7593120131372109 accuracy 0.9098939895629883 macro_avg {'precision': 0.9172619347726709, 'recall': 0.9115833548171178, 'f1-score': 0.9120910727999663, 'support': 1132} weighted_avg {'precision': 0.9149297673285267, 'recall': 0.9098939929328622, 'f1-score': 0.9100372925455061, 'support': 1132}
 
----------
Epoch 25/40
time = 1153.41 secondes

Train loss 0.05602378918224795 accuracy 0.9901787638664246 macro_avg {'precision': 0.9903326050286594, 'recall': 0.9902268612913421, 'f1-score': 0.9902670950189882, 'support': 10182} weighted_avg {'precision': 0.9902010406760481, 'recall': 0.9901787468080927, 'f1-score': 0.9901770831794402, 'support': 10182}
 
time = 35.24 secondes

Val loss 0.6800213746174565 accuracy 0.9125441908836365 macro_avg {'precision': 0.9225834556990253, 'recall': 0.9148019269256473, 'f1-score': 0.9160955285437945, 'support': 1132} weighted_avg {'precision': 0.921689845226423, 'recall': 0.9125441696113075, 'f1-score': 0.9143767549668941, 'support': 1132}
 
----------
Epoch 26/40
time = 1150.32 secondes

Train loss 0.045556401049373446 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919550837452071, 'recall': 0.9919089018820229, 'f1-score': 0.9919222717429494, 'support': 10182} weighted_avg {'precision': 0.9920681407596549, 'recall': 0.9920447849145551, 'f1-score': 0.9920471577505633, 'support': 10182}
 
time = 36.53 secondes

Val loss 0.7402734299268021 accuracy 0.9072438478469849 macro_avg {'precision': 0.910498694163462, 'recall': 0.9096328944275109, 'f1-score': 0.9076225498605561, 'support': 1132} weighted_avg {'precision': 0.9112204943956298, 'recall': 0.907243816254417, 'f1-score': 0.9067543143800534, 'support': 1132}
 
----------
Epoch 27/40
time = 1161.17 secondes

Train loss 0.0497853410580352 accuracy 0.9914555549621582 macro_avg {'precision': 0.9914144692775444, 'recall': 0.9916434701530428, 'f1-score': 0.9915098381265679, 'support': 10182} weighted_avg {'precision': 0.9915015902647978, 'recall': 0.9914555097230406, 'f1-score': 0.9914592646053231, 'support': 10182}
 
time = 36.02 secondes

Val loss 0.6372558881097652 accuracy 0.9178445339202881 macro_avg {'precision': 0.9217358125144655, 'recall': 0.9194067717069029, 'f1-score': 0.9192043157092279, 'support': 1132} weighted_avg {'precision': 0.9228171326416446, 'recall': 0.9178445229681979, 'f1-score': 0.9189112221848376, 'support': 1132}
 
----------
Epoch 28/40
time = 1155.74 secondes

Train loss 0.03670861995168689 accuracy 0.9934197664260864 macro_avg {'precision': 0.9931967659966634, 'recall': 0.9933218053507584, 'f1-score': 0.9932533067440531, 'support': 10182} weighted_avg {'precision': 0.9934334058076358, 'recall': 0.9934197603614221, 'f1-score': 0.9934207958839086, 'support': 10182}
 
time = 35.15 secondes

Val loss 0.6196770639720162 accuracy 0.9178445339202881 macro_avg {'precision': 0.921040254305528, 'recall': 0.9198063107940062, 'f1-score': 0.9190279280985317, 'support': 1132} weighted_avg {'precision': 0.9210388439745777, 'recall': 0.9178445229681979, 'f1-score': 0.9180231332949492, 'support': 1132}
 
----------
Epoch 29/40
time = 1154.58 secondes

Train loss 0.05198002204571987 accuracy 0.9914555549621582 macro_avg {'precision': 0.9914417472300808, 'recall': 0.9911492359893621, 'f1-score': 0.9912753170785905, 'support': 10182} weighted_avg {'precision': 0.9914820639282269, 'recall': 0.9914555097230406, 'f1-score': 0.9914506107986187, 'support': 10182}
 
time = 35.58 secondes

Val loss 0.6398956603522274 accuracy 0.9240282773971558 macro_avg {'precision': 0.9260764943783013, 'recall': 0.9249104978866628, 'f1-score': 0.924311213006239, 'support': 1132} weighted_avg {'precision': 0.928192945071726, 'recall': 0.9240282685512368, 'f1-score': 0.9249031105156617, 'support': 1132}
 
----------
Epoch 30/40
time = 1159.44 secondes

Train loss 0.04113470484829449 accuracy 0.9930269122123718 macro_avg {'precision': 0.9930187921891813, 'recall': 0.9930941635728464, 'f1-score': 0.9930488308369748, 'support': 10182} weighted_avg {'precision': 0.993032436784564, 'recall': 0.9930269102337458, 'f1-score': 0.9930221871354857, 'support': 10182}
 
time = 35.57 secondes

Val loss 0.6563781621832315 accuracy 0.9187279343605042 macro_avg {'precision': 0.9241493481121361, 'recall': 0.9197437334519094, 'f1-score': 0.9206175644858158, 'support': 1132} weighted_avg {'precision': 0.9232186670307739, 'recall': 0.9187279151943463, 'f1-score': 0.919566386364348, 'support': 1132}
 
----------
Epoch 31/40
time = 1160.86 secondes

Train loss 0.03233429265917497 accuracy 0.9951876401901245 macro_avg {'precision': 0.9951763351731374, 'recall': 0.9945774487319152, 'f1-score': 0.9948565333842762, 'support': 10182} weighted_avg {'precision': 0.9952024252481985, 'recall': 0.9951875859359655, 'f1-score': 0.9951788221692534, 'support': 10182}
 
time = 35.79 secondes

Val loss 0.6953039596223725 accuracy 0.9187279343605042 macro_avg {'precision': 0.9224972296381739, 'recall': 0.9197981377957338, 'f1-score': 0.9192107922005016, 'support': 1132} weighted_avg {'precision': 0.925071607747163, 'recall': 0.9187279151943463, 'f1-score': 0.9199793334265883, 'support': 1132}
 
----------
Epoch 32/40
time = 1166.15 secondes

Train loss 0.024616793039879365 accuracy 0.9952858090400696 macro_avg {'precision': 0.995181975207273, 'recall': 0.9949681485216363, 'f1-score': 0.9950657112624942, 'support': 10182} weighted_avg {'precision': 0.995295238323748, 'recall': 0.9952857984678845, 'f1-score': 0.9952824263177874, 'support': 10182}
 
time = 36.08 secondes

Val loss 0.7084485312901654 accuracy 0.9187279343605042 macro_avg {'precision': 0.9246395497628599, 'recall': 0.9201824412961314, 'f1-score': 0.9200712289713099, 'support': 1132} weighted_avg {'precision': 0.9262589755553116, 'recall': 0.9187279151943463, 'f1-score': 0.9203959893468396, 'support': 1132}
 
----------
Epoch 33/40
time = 1148.18 secondes

Train loss 0.027942623719580333 accuracy 0.9954822659492493 macro_avg {'precision': 0.9953076987073673, 'recall': 0.9951169269198463, 'f1-score': 0.9952033751280573, 'support': 10182} weighted_avg {'precision': 0.9955069291472975, 'recall': 0.9954822235317227, 'f1-score': 0.9954860724608732, 'support': 10182}
 
time = 36.10 secondes

Val loss 0.6872997396620659 accuracy 0.9204947352409363 macro_avg {'precision': 0.9227358220997781, 'recall': 0.9218888122303012, 'f1-score': 0.9211877924746688, 'support': 1132} weighted_avg {'precision': 0.9232131534050162, 'recall': 0.9204946996466431, 'f1-score': 0.9207068277569089, 'support': 1132}
 
----------
Epoch 34/40
time = 1151.95 secondes

Train loss 0.02426675490192047 accuracy 0.9965626001358032 macro_avg {'precision': 0.996331304310403, 'recall': 0.9964176618166747, 'f1-score': 0.9963637332938605, 'support': 10182} weighted_avg {'precision': 0.9965858143048272, 'recall': 0.9965625613828325, 'f1-score': 0.9965636361235405, 'support': 10182}
 
time = 35.18 secondes

Val loss 0.7141995890337647 accuracy 0.9213780760765076 macro_avg {'precision': 0.9267241081956312, 'recall': 0.9241285666691883, 'f1-score': 0.9241065934600237, 'support': 1132} weighted_avg {'precision': 0.9259318671170385, 'recall': 0.9213780918727915, 'f1-score': 0.9223120403597578, 'support': 1132}
 
----------
Epoch 35/40
time = 1163.22 secondes

Train loss 0.01761965508818632 accuracy 0.9964643716812134 macro_avg {'precision': 0.9965602337425079, 'recall': 0.9965869813096384, 'f1-score': 0.9965682554435776, 'support': 10182} weighted_avg {'precision': 0.9964773182742358, 'recall': 0.9964643488509134, 'f1-score': 0.9964652382066659, 'support': 10182}
 
time = 36.31 secondes

Val loss 0.7725901875042247 accuracy 0.9134275913238525 macro_avg {'precision': 0.9192147432663047, 'recall': 0.9165232680501454, 'f1-score': 0.915037788274003, 'support': 1132} weighted_avg {'precision': 0.921301074837358, 'recall': 0.9134275618374559, 'f1-score': 0.9145603994109976, 'support': 1132}
 
----------
Epoch 36/40
time = 1148.32 secondes

Train loss 0.015804037522361987 accuracy 0.9971518516540527 macro_avg {'precision': 0.997179338751655, 'recall': 0.997155585841426, 'f1-score': 0.9971666210492659, 'support': 10182} weighted_avg {'precision': 0.9971524110431386, 'recall': 0.9971518365743469, 'f1-score': 0.9971512720601385, 'support': 10182}
 
time = 35.67 secondes

Val loss 0.708615073894692 accuracy 0.9143109321594238 macro_avg {'precision': 0.9179202778431661, 'recall': 0.9181204932947684, 'f1-score': 0.9164092873176269, 'support': 1132} weighted_avg {'precision': 0.9181117422513455, 'recall': 0.9143109540636042, 'f1-score': 0.9146000065751678, 'support': 1132}
 
----------
Epoch 37/40
time = 1143.86 secondes

Train loss 0.012302178435131176 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972658946616981, 'recall': 0.9971433350160701, 'f1-score': 0.9971969825374757, 'support': 10182} weighted_avg {'precision': 0.997259453974603, 'recall': 0.9972500491062659, 'f1-score': 0.9972471164292849, 'support': 10182}
 
time = 35.23 secondes

Val loss 0.7379781869100223 accuracy 0.9178445339202881 macro_avg {'precision': 0.9220678085778953, 'recall': 0.919291324253213, 'f1-score': 0.918853957307879, 'support': 1132} weighted_avg {'precision': 0.9223779093104226, 'recall': 0.9178445229681979, 'f1-score': 0.918176682899167, 'support': 1132}
 
----------
Epoch 38/40
time = 1166.13 secondes

Train loss 0.006055644766786782 accuracy 0.998919665813446 macro_avg {'precision': 0.9988536962895331, 'recall': 0.9988856951913435, 'f1-score': 0.9988683904502013, 'support': 10182} weighted_avg {'precision': 0.9989232869327604, 'recall': 0.9989196621488902, 'f1-score': 0.9989201523387943, 'support': 10182}
 
time = 35.20 secondes

Val loss 0.7152820901992014 accuracy 0.9213780760765076 macro_avg {'precision': 0.9266614623618693, 'recall': 0.9239592491135413, 'f1-score': 0.923542977963318, 'support': 1132} weighted_avg {'precision': 0.9260618137703013, 'recall': 0.9213780918727915, 'f1-score': 0.9219001971904388, 'support': 1132}
 
----------
Epoch 39/40
time = 1149.90 secondes

Train loss 0.005158637100864827 accuracy 0.9992143511772156 macro_avg {'precision': 0.9991834450420785, 'recall': 0.9991335200576824, 'f1-score': 0.9991576007080821, 'support': 10182} weighted_avg {'precision': 0.999215695247084, 'recall': 0.9992142997446474, 'f1-score': 0.999214129705282, 'support': 10182}
 
time = 36.09 secondes

Val loss 0.645582660174293 accuracy 0.9275618195533752 macro_avg {'precision': 0.9330787550769145, 'recall': 0.9292969517846006, 'f1-score': 0.9297455335669692, 'support': 1132} weighted_avg {'precision': 0.9314498727048649, 'recall': 0.9275618374558304, 'f1-score': 0.9280411558008027, 'support': 1132}
 
----------
Epoch 40/40
time = 1166.99 secondes

Train loss 0.001968301804931348 accuracy 0.9997053742408752 macro_avg {'precision': 0.9997175034371644, 'recall': 0.9996987510636123, 'f1-score': 0.9997079281641851, 'support': 10182} weighted_avg {'precision': 0.9997057337234707, 'recall': 0.9997053624042428, 'f1-score': 0.9997053531757775, 'support': 10182}
 
time = 35.36 secondes

Val loss 0.6927778340681804 accuracy 0.9231448769569397 macro_avg {'precision': 0.9274239216735953, 'recall': 0.9255555155976106, 'f1-score': 0.9250310341212955, 'support': 1132} weighted_avg {'precision': 0.926501305486485, 'recall': 0.9231448763250883, 'f1-score': 0.9233992200590494, 'support': 1132}
 
----------
best_accuracy 0.9275618195533752 best_epoch 39 macro_avg {'precision': 0.9330787550769145, 'recall': 0.9292969517846006, 'f1-score': 0.9297455335669692, 'support': 1132} weighted_avg {'precision': 0.9314498727048649, 'recall': 0.9275618374558304, 'f1-score': 0.9280411558008027, 'support': 1132}

average train time 1231.4260037600993

average val time 36.03038524389267
 
time = 232.39 secondes

test_accuracy 0.8647105693817139 macro_avg {'precision': 0.8616927025385751, 'recall': 0.8572996378719331, 'f1-score': 0.8577116250933174, 'support': 7532} weighted_avg {'precision': 0.8674691788387782, 'recall': 0.8647105682421667, 'f1-score': 0.8644762910787254, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_3
----------
Epoch 1/40
time = 1984.18 secondes

Train loss 1.0752775539502244 accuracy 0.6951483488082886 macro_avg {'precision': 0.699590091445297, 'recall': 0.6812344640469336, 'f1-score': 0.677675943681848, 'support': 10182} weighted_avg {'precision': 0.7050615991910059, 'recall': 0.6951483009231978, 'f1-score': 0.6899340746543617, 'support': 10182}
 
time = 42.07 secondes

Val loss 0.5287569040353869 accuracy 0.8401060104370117 macro_avg {'precision': 0.8427859881017996, 'recall': 0.8335958330641073, 'f1-score': 0.8270552651307146, 'support': 1132} weighted_avg {'precision': 0.8447278769529004, 'recall': 0.8401060070671378, 'f1-score': 0.8340419269615356, 'support': 1132}
 
----------
Epoch 2/40
time = 1983.20 secondes

Train loss 0.39580365893499725 accuracy 0.8864663243293762 macro_avg {'precision': 0.8793774305449782, 'recall': 0.8782682630160277, 'f1-score': 0.8781347214058709, 'support': 10182} weighted_avg {'precision': 0.8855141837295148, 'recall': 0.8864663131015518, 'f1-score': 0.8854509800515442, 'support': 10182}
 
time = 39.29 secondes

Val loss 0.4954897319556962 accuracy 0.8657243847846985 macro_avg {'precision': 0.8678149535485773, 'recall': 0.8651711560346744, 'f1-score': 0.8599626205667409, 'support': 1132} weighted_avg {'precision': 0.8745713479762353, 'recall': 0.8657243816254417, 'f1-score': 0.8632270919425737, 'support': 1132}
 
----------
Epoch 3/40
time = 1979.44 secondes

Train loss 0.24515964400339024 accuracy 0.9318405389785767 macro_avg {'precision': 0.9288730722864804, 'recall': 0.9277371906142564, 'f1-score': 0.9281493771321552, 'support': 10182} weighted_avg {'precision': 0.9318765395843267, 'recall': 0.9318405028481634, 'f1-score': 0.9317204349358176, 'support': 10182}
 
time = 39.04 secondes

Val loss 0.4583042230076668 accuracy 0.8939929604530334 macro_avg {'precision': 0.8978936825565637, 'recall': 0.8965775062683514, 'f1-score': 0.8939195592466056, 'support': 1132} weighted_avg {'precision': 0.901021650481991, 'recall': 0.8939929328621908, 'f1-score': 0.8938121082595003, 'support': 1132}
 
----------
Epoch 4/40
time = 1974.06 secondes

Train loss 0.18184648309044799 accuracy 0.9521705508232117 macro_avg {'precision': 0.9497626502180714, 'recall': 0.9498796438008312, 'f1-score': 0.9497655042552292, 'support': 10182} weighted_avg {'precision': 0.9522771081584702, 'recall': 0.9521704969554116, 'f1-score': 0.9521705501495341, 'support': 10182}
 
time = 37.24 secondes

Val loss 0.5007298894154406 accuracy 0.8975265026092529 macro_avg {'precision': 0.9028349301142266, 'recall': 0.8969552545851454, 'f1-score': 0.8960700976945585, 'support': 1132} weighted_avg {'precision': 0.9051411931150569, 'recall': 0.8975265017667845, 'f1-score': 0.8974030631114228, 'support': 1132}
 
----------
Epoch 5/40
time = 1954.68 secondes

Train loss 0.15597617650240825 accuracy 0.9588489532470703 macro_avg {'precision': 0.9573563883138381, 'recall': 0.9573197765741854, 'f1-score': 0.9573227307664173, 'support': 10182} weighted_avg {'precision': 0.958986487312516, 'recall': 0.9588489491259085, 'f1-score': 0.958902077355187, 'support': 10182}
 
time = 38.63 secondes

Val loss 0.5006567004422041 accuracy 0.9037102460861206 macro_avg {'precision': 0.906784160886972, 'recall': 0.9047237845868867, 'f1-score': 0.9042931784771756, 'support': 1132} weighted_avg {'precision': 0.906431073178634, 'recall': 0.9037102473498233, 'f1-score': 0.9036633731313519, 'support': 1132}
 
----------
Epoch 6/40
time = 1943.49 secondes

Train loss 0.15150024500650644 accuracy 0.9665095806121826 macro_avg {'precision': 0.9660968453493728, 'recall': 0.9656975938975177, 'f1-score': 0.9658385975872987, 'support': 10182} weighted_avg {'precision': 0.9665418349002964, 'recall': 0.9665095266155962, 'f1-score': 0.9664683483822825, 'support': 10182}
 
time = 38.62 secondes

Val loss 0.6646389711679379 accuracy 0.8939929604530334 macro_avg {'precision': 0.9029945944935021, 'recall': 0.895692084608038, 'f1-score': 0.895442053903305, 'support': 1132} weighted_avg {'precision': 0.9028293454268137, 'recall': 0.8939929328621908, 'f1-score': 0.894276234844556, 'support': 1132}
 
----------
Epoch 7/40
time = 1928.40 secondes

Train loss 0.13318906959723403 accuracy 0.9721076488494873 macro_avg {'precision': 0.9716943710039512, 'recall': 0.971442509536715, 'f1-score': 0.9715344474486383, 'support': 10182} weighted_avg {'precision': 0.9721722696473658, 'recall': 0.9721076409349833, 'f1-score': 0.9721052259825406, 'support': 10182}
 
time = 37.42 secondes

Val loss 0.7693227940053732 accuracy 0.8922261595726013 macro_avg {'precision': 0.8975699269715539, 'recall': 0.895325362187228, 'f1-score': 0.8933268176757385, 'support': 1132} weighted_avg {'precision': 0.8989209354989897, 'recall': 0.892226148409894, 'f1-score': 0.8921813769811068, 'support': 1132}
 
----------
Epoch 8/40
time = 1925.67 secondes

Train loss 0.12709598354580395 accuracy 0.9719112515449524 macro_avg {'precision': 0.9711119997493803, 'recall': 0.9708604073213886, 'f1-score': 0.9709607235841977, 'support': 10182} weighted_avg {'precision': 0.9719433477058134, 'recall': 0.9719112158711452, 'f1-score': 0.9719027223934034, 'support': 10182}
 
time = 37.31 secondes

Val loss 0.7759333660630968 accuracy 0.8825088143348694 macro_avg {'precision': 0.8992826307719273, 'recall': 0.882533223262943, 'f1-score': 0.8853495330684987, 'support': 1132} weighted_avg {'precision': 0.8979015280464236, 'recall': 0.8825088339222615, 'f1-score': 0.8845950800954185, 'support': 1132}
 
----------
Epoch 9/40
time = 1925.27 secondes

Train loss 0.11545659872975378 accuracy 0.976527214050293 macro_avg {'precision': 0.9754398911585904, 'recall': 0.9757095231449799, 'f1-score': 0.9755487092368383, 'support': 10182} weighted_avg {'precision': 0.9766573744703744, 'recall': 0.9765272048713416, 'f1-score': 0.9765702175871029, 'support': 10182}
 
time = 39.23 secondes

Val loss 0.9748238395812633 accuracy 0.8719081282615662 macro_avg {'precision': 0.9002673472575691, 'recall': 0.8691186384569309, 'f1-score': 0.8603047095956008, 'support': 1132} weighted_avg {'precision': 0.8956911549676901, 'recall': 0.8719081272084805, 'f1-score': 0.8605754027508226, 'support': 1132}
 
----------
Epoch 10/40
time = 1934.91 secondes

Train loss 0.10877496295956181 accuracy 0.9778040051460266 macro_avg {'precision': 0.9774809449586084, 'recall': 0.9775557388085797, 'f1-score': 0.977484884698244, 'support': 10182} weighted_avg {'precision': 0.9778709357008146, 'recall': 0.9778039677862895, 'f1-score': 0.97780262876635, 'support': 10182}
 
time = 39.46 secondes

Val loss 0.8700600139555705 accuracy 0.8710247278213501 macro_avg {'precision': 0.8891196281759189, 'recall': 0.8748511791128786, 'f1-score': 0.8720499556303919, 'support': 1132} weighted_avg {'precision': 0.8902294678099035, 'recall': 0.8710247349823321, 'f1-score': 0.8704120850884276, 'support': 1132}
 
----------
Epoch 11/40
time = 1928.82 secondes

Train loss 0.10715490677731157 accuracy 0.9783932566642761 macro_avg {'precision': 0.9781706939709197, 'recall': 0.977781372137222, 'f1-score': 0.9779496345318682, 'support': 10182} weighted_avg {'precision': 0.9783675276832448, 'recall': 0.978393242977804, 'f1-score': 0.9783555408781008, 'support': 10182}
 
time = 37.84 secondes

Val loss 0.8146578149647046 accuracy 0.8842756152153015 macro_avg {'precision': 0.8930726136693441, 'recall': 0.8854066590693439, 'f1-score': 0.8833509958535055, 'support': 1132} weighted_avg {'precision': 0.8937183069974367, 'recall': 0.8842756183745583, 'f1-score': 0.8832109496023709, 'support': 1132}
 
----------
Epoch 12/40
time = 1927.19 secondes

Train loss 0.09454548403153232 accuracy 0.9810450077056885 macro_avg {'precision': 0.9806353054892487, 'recall': 0.9804881721526749, 'f1-score': 0.9805493002566138, 'support': 10182} weighted_avg {'precision': 0.9810896708011148, 'recall': 0.9810449813396189, 'f1-score': 0.9810558234548872, 'support': 10182}
 
time = 37.51 secondes

Val loss 0.6082535432180239 accuracy 0.9107773900032043 macro_avg {'precision': 0.9106512702286629, 'recall': 0.9146442201037571, 'f1-score': 0.9110624048886905, 'support': 1132} weighted_avg {'precision': 0.9146388610190213, 'recall': 0.9107773851590106, 'f1-score': 0.9111353369924904, 'support': 1132}
 
----------
Epoch 13/40
time = 1923.39 secondes

Train loss 0.0810487469635137 accuracy 0.9836967587471008 macro_avg {'precision': 0.9834208294009577, 'recall': 0.9831023162696668, 'f1-score': 0.9832211327570469, 'support': 10182} weighted_avg {'precision': 0.9837552522579128, 'recall': 0.9836967197014339, 'f1-score': 0.983686173432983, 'support': 10182}
 
time = 37.27 secondes

Val loss 0.6966914111017872 accuracy 0.9019434452056885 macro_avg {'precision': 0.9065766072725893, 'recall': 0.902930490778779, 'f1-score': 0.9025758289048864, 'support': 1132} weighted_avg {'precision': 0.9074928515230426, 'recall': 0.9019434628975265, 'f1-score': 0.9023743964866422, 'support': 1132}
 
----------
Epoch 14/40
time = 1921.70 secondes

Train loss 0.10669871428458742 accuracy 0.9801610708236694 macro_avg {'precision': 0.980028478547122, 'recall': 0.9801545503925821, 'f1-score': 0.9800608745782557, 'support': 10182} weighted_avg {'precision': 0.9802842699911355, 'recall': 0.9801610685523473, 'f1-score': 0.980193197324741, 'support': 10182}
 
time = 37.21 secondes

Val loss 0.6384843044408473 accuracy 0.9125441908836365 macro_avg {'precision': 0.9176527303419508, 'recall': 0.9130631132092331, 'f1-score': 0.9134786398049425, 'support': 1132} weighted_avg {'precision': 0.917147347979774, 'recall': 0.9125441696113075, 'f1-score': 0.9129069085523793, 'support': 1132}
 
----------
Epoch 15/40
time = 1921.40 secondes

Train loss 0.10867906829768614 accuracy 0.9802592992782593 macro_avg {'precision': 0.9790828385426307, 'recall': 0.9796806310677573, 'f1-score': 0.9793435403781616, 'support': 10182} weighted_avg {'precision': 0.9803341654850354, 'recall': 0.9802592810842663, 'f1-score': 0.9802680291512685, 'support': 10182}
 
time = 37.16 secondes

Val loss 0.7744576967174588 accuracy 0.9010601043701172 macro_avg {'precision': 0.9097685915305241, 'recall': 0.9024959510358054, 'f1-score': 0.9010741120958656, 'support': 1132} weighted_avg {'precision': 0.9121005214666773, 'recall': 0.901060070671378, 'f1-score': 0.901759770665767, 'support': 1132}
 
----------
Epoch 16/40
time = 1928.21 secondes

Train loss 0.08321373923690357 accuracy 0.9828128218650818 macro_avg {'precision': 0.9824712642613648, 'recall': 0.9827287441333603, 'f1-score': 0.9825737608948895, 'support': 10182} weighted_avg {'precision': 0.9828652262747499, 'recall': 0.9828128069141623, 'f1-score': 0.9828157410351536, 'support': 10182}
 
time = 39.05 secondes

Val loss 0.8627733450629306 accuracy 0.8895759582519531 macro_avg {'precision': 0.9062209716730154, 'recall': 0.8968379504703462, 'f1-score': 0.8939476397225385, 'support': 1132} weighted_avg {'precision': 0.9068312134697026, 'recall': 0.8895759717314488, 'f1-score': 0.8896840014898495, 'support': 1132}
 
----------
Epoch 17/40
time = 1929.92 secondes

Train loss 0.07659149181398928 accuracy 0.9857591986656189 macro_avg {'precision': 0.985555806154195, 'recall': 0.9854007495151077, 'f1-score': 0.9854604668125608, 'support': 10182} weighted_avg {'precision': 0.9857989071256318, 'recall': 0.9857591828717345, 'f1-score': 0.9857626288360191, 'support': 10182}
 
time = 39.12 secondes

Val loss 0.7231309669896547 accuracy 0.9054770469665527 macro_avg {'precision': 0.9033514286573538, 'recall': 0.9082947793848197, 'f1-score': 0.9039030895220563, 'support': 1132} weighted_avg {'precision': 0.9102503965529343, 'recall': 0.9054770318021201, 'f1-score': 0.906015220131708, 'support': 1132}
 
----------
Epoch 18/40
time = 1922.62 secondes

Train loss 0.07306650489366948 accuracy 0.9863485097885132 macro_avg {'precision': 0.9857778734369577, 'recall': 0.98569825484131, 'f1-score': 0.9857204837871724, 'support': 10182} weighted_avg {'precision': 0.9863585432700058, 'recall': 0.9863484580632489, 'f1-score': 0.9863355847247497, 'support': 10182}
 
time = 37.10 secondes

Val loss 0.6549350259699334 accuracy 0.9143109321594238 macro_avg {'precision': 0.9169229745002397, 'recall': 0.9145079120224795, 'f1-score': 0.9134243166560274, 'support': 1132} weighted_avg {'precision': 0.9166280537736267, 'recall': 0.9143109540636042, 'f1-score': 0.9131414594700007, 'support': 1132}
 
----------
Epoch 19/40
time = 1923.11 secondes

Train loss 0.0680572883440898 accuracy 0.9881163239479065 macro_avg {'precision': 0.9875042563132006, 'recall': 0.9875160098329676, 'f1-score': 0.9875000631822501, 'support': 10182} weighted_avg {'precision': 0.9881215129959255, 'recall': 0.9881162836377921, 'f1-score': 0.9881088585363474, 'support': 10182}
 
time = 37.18 secondes

Val loss 0.731785641234855 accuracy 0.9116607904434204 macro_avg {'precision': 0.9171398087886444, 'recall': 0.9158556204292616, 'f1-score': 0.9135324330083308, 'support': 1132} weighted_avg {'precision': 0.9188684218078971, 'recall': 0.911660777385159, 'f1-score': 0.9120852518351689, 'support': 1132}
 
----------
Epoch 20/40
time = 1921.29 secondes

Train loss 0.06349861894930117 accuracy 0.9882145524024963 macro_avg {'precision': 0.9879882894326295, 'recall': 0.9881285668848957, 'f1-score': 0.9880464505097825, 'support': 10182} weighted_avg {'precision': 0.9882327913750413, 'recall': 0.9882144961697112, 'f1-score': 0.9882118534463895, 'support': 10182}
 
time = 37.60 secondes

Val loss 0.8044984862829385 accuracy 0.898409903049469 macro_avg {'precision': 0.9090523872715309, 'recall': 0.9025349204296578, 'f1-score': 0.9009810409439651, 'support': 1132} weighted_avg {'precision': 0.911114867629559, 'recall': 0.8984098939929329, 'f1-score': 0.8998842421796556, 'support': 1132}
 
----------
Epoch 21/40
time = 1922.52 secondes

Train loss 0.0581312946024171 accuracy 0.9900805354118347 macro_avg {'precision': 0.9897717231529338, 'recall': 0.9900752024031882, 'f1-score': 0.9898985932195711, 'support': 10182} weighted_avg {'precision': 0.9901378189596516, 'recall': 0.9900805342761736, 'f1-score': 0.9900867086825212, 'support': 10182}
 
time = 36.96 secondes

Val loss 0.7817282419773491 accuracy 0.9037102460861206 macro_avg {'precision': 0.9080011995131194, 'recall': 0.907713041359522, 'f1-score': 0.9052573722508015, 'support': 1132} weighted_avg {'precision': 0.9103862353694372, 'recall': 0.9037102473498233, 'f1-score': 0.9043585909088931, 'support': 1132}
 
----------
Epoch 22/40
time = 1922.49 secondes

Train loss 0.05950817546630962 accuracy 0.9892948865890503 macro_avg {'precision': 0.9892611757441324, 'recall': 0.9893504356450012, 'f1-score': 0.989293948151387, 'support': 10182} weighted_avg {'precision': 0.9893308957009166, 'recall': 0.9892948340208211, 'f1-score': 0.9893013644672997, 'support': 10182}
 
time = 37.75 secondes

Val loss 0.6916191144309394 accuracy 0.9063604474067688 macro_avg {'precision': 0.9117157706692776, 'recall': 0.9107630876219343, 'f1-score': 0.9083702279442327, 'support': 1132} weighted_avg {'precision': 0.9132667759406147, 'recall': 0.9063604240282686, 'f1-score': 0.9067854294410365, 'support': 1132}
 
----------
Epoch 23/40
time = 1928.02 secondes

Train loss 0.04832894893366453 accuracy 0.9900805354118347 macro_avg {'precision': 0.9896012384861926, 'recall': 0.9898046065593256, 'f1-score': 0.9896876218552114, 'support': 10182} weighted_avg {'precision': 0.9901366969675859, 'recall': 0.9900805342761736, 'f1-score': 0.9900948999339803, 'support': 10182}
 
time = 37.04 secondes

Val loss 0.7966383406822733 accuracy 0.9019434452056885 macro_avg {'precision': 0.9046145302141502, 'recall': 0.9056902628730319, 'f1-score': 0.9003580134753605, 'support': 1132} weighted_avg {'precision': 0.9084581968042128, 'recall': 0.9019434628975265, 'f1-score': 0.9003252770748633, 'support': 1132}
 
----------
Epoch 24/40
time = 1930.16 secondes

Train loss 0.048621146681598275 accuracy 0.9910627007484436 macro_avg {'precision': 0.9909282705928616, 'recall': 0.9910799905391988, 'f1-score': 0.9909951797715715, 'support': 10182} weighted_avg {'precision': 0.9910789043379347, 'recall': 0.9910626595953643, 'f1-score': 0.9910623855411643, 'support': 10182}
 
time = 37.26 secondes

Val loss 0.7358131516374554 accuracy 0.9116607904434204 macro_avg {'precision': 0.9133230111264912, 'recall': 0.9150092275528781, 'f1-score': 0.9127683071985739, 'support': 1132} weighted_avg {'precision': 0.9141957532527965, 'recall': 0.911660777385159, 'f1-score': 0.9114298998630794, 'support': 1132}
 
----------
Epoch 25/40
time = 1929.96 secondes

Train loss 0.052621135083988475 accuracy 0.9903752207756042 macro_avg {'precision': 0.9904790910385101, 'recall': 0.9903915991053115, 'f1-score': 0.9904131898910231, 'support': 10182} weighted_avg {'precision': 0.9903805468358597, 'recall': 0.9903751718719308, 'f1-score': 0.9903550310498941, 'support': 10182}
 
time = 37.11 secondes

Val loss 0.7897854151229233 accuracy 0.9072438478469849 macro_avg {'precision': 0.9092895504547445, 'recall': 0.9116808345121026, 'f1-score': 0.9087927817873165, 'support': 1132} weighted_avg {'precision': 0.9102119351227688, 'recall': 0.907243816254417, 'f1-score': 0.9068540903909255, 'support': 1132}
 
----------
Epoch 26/40
time = 1934.61 secondes

Train loss 0.041646211664461946 accuracy 0.9927322864532471 macro_avg {'precision': 0.9925206690554077, 'recall': 0.9927589272268449, 'f1-score': 0.992634699084894, 'support': 10182} weighted_avg {'precision': 0.9927516005472357, 'recall': 0.9927322726379886, 'f1-score': 0.9927373380034116, 'support': 10182}
 
time = 37.14 secondes

Val loss 0.7601030975543118 accuracy 0.9134275913238525 macro_avg {'precision': 0.9164695864404726, 'recall': 0.9167172514192657, 'f1-score': 0.9137066544606794, 'support': 1132} weighted_avg {'precision': 0.9204566812577583, 'recall': 0.9134275618374559, 'f1-score': 0.914215833128188, 'support': 1132}
 
----------
Epoch 27/40
time = 1931.40 secondes

Train loss 0.045824050868345456 accuracy 0.9924376606941223 macro_avg {'precision': 0.9923485499405643, 'recall': 0.992501229242712, 'f1-score': 0.9924173733211686, 'support': 10182} weighted_avg {'precision': 0.9924460307519568, 'recall': 0.9924376350422314, 'f1-score': 0.9924344070698178, 'support': 10182}
 
time = 37.37 secondes

Val loss 0.7070700989621708 accuracy 0.916077733039856 macro_avg {'precision': 0.9188610174537226, 'recall': 0.918020240232406, 'f1-score': 0.9170143301666245, 'support': 1132} weighted_avg {'precision': 0.9190770142709417, 'recall': 0.916077738515901, 'f1-score': 0.9162579565175448, 'support': 1132}
 
----------
Epoch 28/40
time = 1932.21 secondes

Train loss 0.03673395695776643 accuracy 0.9936162233352661 macro_avg {'precision': 0.993507506685663, 'recall': 0.9936514575212347, 'f1-score': 0.9935723455396023, 'support': 10182} weighted_avg {'precision': 0.9936289151436163, 'recall': 0.9936161854252603, 'f1-score': 0.9936152915367172, 'support': 10182}
 
time = 37.46 secondes

Val loss 0.7318540201443502 accuracy 0.9098939895629883 macro_avg {'precision': 0.9120858482575942, 'recall': 0.9144752640345205, 'f1-score': 0.9122843205832671, 'support': 1132} weighted_avg {'precision': 0.9117288396054494, 'recall': 0.9098939929328622, 'f1-score': 0.9097595947981086, 'support': 1132}
 
----------
Epoch 29/40
time = 1933.52 secondes

Train loss 0.027629042176220087 accuracy 0.9947947859764099 macro_avg {'precision': 0.9944884279112894, 'recall': 0.9945206770862001, 'f1-score': 0.9945006069478429, 'support': 10182} weighted_avg {'precision': 0.9948006793204527, 'recall': 0.9947947358082891, 'f1-score': 0.9947937799280783, 'support': 10182}
 
time = 38.29 secondes

Val loss 0.7782946855500918 accuracy 0.9143109321594238 macro_avg {'precision': 0.9168775441973324, 'recall': 0.9191040550342497, 'f1-score': 0.9164033316192108, 'support': 1132} weighted_avg {'precision': 0.9174021834813799, 'recall': 0.9143109540636042, 'f1-score': 0.9141770771106817, 'support': 1132}
 
----------
Epoch 30/40
time = 1927.03 secondes

Train loss 0.031108650183482873 accuracy 0.9943037033081055 macro_avg {'precision': 0.9938559377149542, 'recall': 0.9940615120422536, 'f1-score': 0.993950997803769, 'support': 10182} weighted_avg {'precision': 0.9943243680077576, 'recall': 0.9943036731486937, 'f1-score': 0.9943066502450477, 'support': 10182}
 
time = 37.41 secondes

Val loss 0.6615355432002386 accuracy 0.9196113348007202 macro_avg {'precision': 0.9214318318752415, 'recall': 0.9212584526797082, 'f1-score': 0.919780745173761, 'support': 1132} weighted_avg {'precision': 0.9235685233671284, 'recall': 0.9196113074204947, 'f1-score': 0.9200943435673848, 'support': 1132}
 
----------
Epoch 31/40
time = 1924.11 secondes

Train loss 0.030908190959885565 accuracy 0.9946965575218201 macro_avg {'precision': 0.9941070148452281, 'recall': 0.9945460610797685, 'f1-score': 0.994310898301158, 'support': 10182} weighted_avg {'precision': 0.9947236717245124, 'recall': 0.99469652327637, 'f1-score': 0.9946978315838753, 'support': 10182}
 
time = 37.59 secondes

Val loss 0.668798551188854 accuracy 0.9257950782775879 macro_avg {'precision': 0.9262764398050262, 'recall': 0.9275162996121933, 'f1-score': 0.9255551700652142, 'support': 1132} weighted_avg {'precision': 0.9285246117911036, 'recall': 0.9257950530035336, 'f1-score': 0.9258541015034446, 'support': 1132}
 
----------
Epoch 32/40
time = 1926.67 secondes

Train loss 0.023378237553819764 accuracy 0.9958751201629639 macro_avg {'precision': 0.995860732686717, 'recall': 0.9958412880364914, 'f1-score': 0.9958471321199445, 'support': 10182} weighted_avg {'precision': 0.9958793984422494, 'recall': 0.995875073659399, 'f1-score': 0.9958733968489468, 'support': 10182}
 
time = 37.26 secondes

Val loss 0.7977429336325501 accuracy 0.9098939895629883 macro_avg {'precision': 0.9126561614884017, 'recall': 0.911474622830774, 'f1-score': 0.9097218441461494, 'support': 1132} weighted_avg {'precision': 0.9139994591974598, 'recall': 0.9098939929328622, 'f1-score': 0.9096383621671936, 'support': 1132}
 
----------
Epoch 33/40
time = 1927.20 secondes

Train loss 0.027970955779035727 accuracy 0.9953840374946594 macro_avg {'precision': 0.9948981526997132, 'recall': 0.9951383107985619, 'f1-score': 0.9950117602878338, 'support': 10182} weighted_avg {'precision': 0.9954003928539457, 'recall': 0.9953840109998036, 'f1-score': 0.9953863627429507, 'support': 10182}
 
time = 37.45 secondes

Val loss 0.7724204736886362 accuracy 0.9151943325996399 macro_avg {'precision': 0.9169347110986047, 'recall': 0.9181384445208222, 'f1-score': 0.9154109233759551, 'support': 1132} weighted_avg {'precision': 0.9209654494356386, 'recall': 0.9151943462897526, 'f1-score': 0.9161414090778628, 'support': 1132}
 
----------
Epoch 34/40
time = 1926.60 secondes

Train loss 0.020953697911996638 accuracy 0.9963661432266235 macro_avg {'precision': 0.9960337126230385, 'recall': 0.9960646190310612, 'f1-score': 0.996047598914392, 'support': 10182} weighted_avg {'precision': 0.9963671323675576, 'recall': 0.9963661363189943, 'f1-score': 0.9963650360345021, 'support': 10182}
 
time = 37.19 secondes

Val loss 0.7182275112881285 accuracy 0.9213780760765076 macro_avg {'precision': 0.923417696895083, 'recall': 0.9247665364539939, 'f1-score': 0.9227835994285443, 'support': 1132} weighted_avg {'precision': 0.9254548647025199, 'recall': 0.9213780918727915, 'f1-score': 0.922073647994211, 'support': 1132}
 
----------
Epoch 35/40
time = 1928.84 secondes

Train loss 0.020094018810448967 accuracy 0.9964643716812134 macro_avg {'precision': 0.9964767454422001, 'recall': 0.996469551468777, 'f1-score': 0.9964661540957719, 'support': 10182} weighted_avg {'precision': 0.9964762294838763, 'recall': 0.9964643488509134, 'f1-score': 0.996463103719443, 'support': 10182}
 
time = 37.45 secondes

Val loss 0.6865110783626118 accuracy 0.9231448769569397 macro_avg {'precision': 0.9258365197288387, 'recall': 0.9266617693531893, 'f1-score': 0.9233427765217114, 'support': 1132} weighted_avg {'precision': 0.9308970688384687, 'recall': 0.9231448763250883, 'f1-score': 0.9244928985821989, 'support': 1132}
 
----------
Epoch 36/40
time = 1926.11 secondes

Train loss 0.014530989391609942 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972022016482047, 'recall': 0.9971763679643908, 'f1-score': 0.9971866328873705, 'support': 10182} weighted_avg {'precision': 0.9973516583274846, 'recall': 0.997348261638185, 'f1-score': 0.9973472915795266, 'support': 10182}
 
time = 37.30 secondes

Val loss 0.6850943047566418 accuracy 0.9222614765167236 macro_avg {'precision': 0.9285634673086068, 'recall': 0.925960764080717, 'f1-score': 0.9249055949489696, 'support': 1132} weighted_avg {'precision': 0.9307973195727285, 'recall': 0.9222614840989399, 'f1-score': 0.9240342210998868, 'support': 1132}
 
----------
Epoch 37/40
time = 1926.15 secondes

Train loss 0.009144955364119805 accuracy 0.9978393316268921 macro_avg {'precision': 0.9978371889353397, 'recall': 0.997825443101525, 'f1-score': 0.9978291373783701, 'support': 10182} weighted_avg {'precision': 0.9978456768541429, 'recall': 0.9978393242977804, 'f1-score': 0.9978402677873028, 'support': 10182}
 
time = 37.30 secondes

Val loss 0.683851780532972 accuracy 0.9178445339202881 macro_avg {'precision': 0.920131096260248, 'recall': 0.9215138995578673, 'f1-score': 0.9192975889678874, 'support': 1132} weighted_avg {'precision': 0.9207118841976293, 'recall': 0.9178445229681979, 'f1-score': 0.9176036476073053, 'support': 1132}
 
----------
Epoch 38/40
time = 1924.77 secondes

Train loss 0.00620976758778178 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985287250272735, 'recall': 0.9985677668837931, 'f1-score': 0.9985476129850956, 'support': 10182} weighted_avg {'precision': 0.9985273025225019, 'recall': 0.998526812021214, 'f1-score': 0.9985264596224476, 'support': 10182}
 
time = 37.39 secondes

Val loss 0.6670197633906816 accuracy 0.926678478717804 macro_avg {'precision': 0.9294278785005579, 'recall': 0.9311155474878667, 'f1-score': 0.9285262852853391, 'support': 1132} weighted_avg {'precision': 0.9312360026450394, 'recall': 0.926678445229682, 'f1-score': 0.9270503068997789, 'support': 1132}
 
----------
Epoch 39/40
time = 1927.26 secondes

Train loss 0.003853089623369889 accuracy 0.9993125200271606 macro_avg {'precision': 0.999343798930868, 'recall': 0.9993445031389101, 'f1-score': 0.9993434561077649, 'support': 10182} weighted_avg {'precision': 0.9993130531345167, 'recall': 0.9993125122765665, 'f1-score': 0.9993120508541753, 'support': 10182}
 
time = 37.34 secondes

Val loss 0.6853171320178685 accuracy 0.9249116778373718 macro_avg {'precision': 0.928475762730592, 'recall': 0.9288025811584841, 'f1-score': 0.9263310686532036, 'support': 1132} weighted_avg {'precision': 0.9312570510556073, 'recall': 0.9249116607773852, 'f1-score': 0.925793037615155, 'support': 1132}
 
----------
Epoch 40/40
time = 1925.55 secondes

Train loss 0.006253270398520388 accuracy 0.998821496963501 macro_avg {'precision': 0.9988179451436336, 'recall': 0.9988566557191231, 'f1-score': 0.998835992268765, 'support': 10182} weighted_avg {'precision': 0.9988246920163502, 'recall': 0.9988214496169712, 'f1-score': 0.9988217520295929, 'support': 10182}
 
time = 37.47 secondes

Val loss 0.7189179855841745 accuracy 0.9240282773971558 macro_avg {'precision': 0.9293536374232787, 'recall': 0.9280491177269387, 'f1-score': 0.9266170398356406, 'support': 1132} weighted_avg {'precision': 0.9306049181797015, 'recall': 0.9240282685512368, 'f1-score': 0.9252208058775891, 'support': 1132}
 
----------
best_accuracy 0.926678478717804 best_epoch 38 macro_avg {'precision': 0.9294278785005579, 'recall': 0.9311155474878667, 'f1-score': 0.9285262852853391, 'support': 1132} weighted_avg {'precision': 0.9312360026450394, 'recall': 0.926678445229682, 'f1-score': 0.9270503068997789, 'support': 1132}

average train time 1933.403184068203

average val time 37.82248169779778
 
time = 245.25 secondes

test_accuracy 0.8595326542854309 macro_avg {'precision': 0.8561444093750099, 'recall': 0.8519330753982184, 'f1-score': 0.8526205858665179, 'support': 7532} weighted_avg {'precision': 0.8642304445856612, 'recall': 0.8595326606479022, 'f1-score': 0.8605213099208747, 'support': 7532}

----------



[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/lib64/python3.6/site-packages/h5py/__init__.py:39: UserWarning: h5py is running against HDF5 1.10.8 when it was built against 1.10.7, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_4
----------
Epoch 1/40
time = 68.12 secondes

Train loss 0.6153191075180516 accuracy 0.6647287011146545 macro_avg {'precision': 0.6513594164456233, 'recall': 0.5593599141784373, 'f1-score': 0.5289958686625125, 'support': 516} weighted_avg {'precision': 0.655967270166348, 'recall': 0.6647286821705426, 'f1-score': 0.5985773109662681, 'support': 516}
 
time = 1.37 secondes

Val loss 0.5174446180462837 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 2/40
time = 55.32 secondes

Train loss 0.41157210821455176 accuracy 0.819767415523529 macro_avg {'precision': 0.8057675857077055, 'recall': 0.8021146563073972, 'f1-score': 0.8038479932310635, 'support': 516} weighted_avg {'precision': 0.8188463986925204, 'recall': 0.8197674418604651, 'f1-score': 0.8192259640159276, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4606687054038048 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 3/40
time = 57.27 secondes

Train loss 0.2572311648365223 accuracy 0.9011628031730652 macro_avg {'precision': 0.8927413077322263, 'recall': 0.8936414024023536, 'f1-score': 0.8931872146118721, 'support': 516} weighted_avg {'precision': 0.9012830975971807, 'recall': 0.9011627906976745, 'f1-score': 0.9012193550670773, 'support': 516}
 
time = 1.44 secondes

Val loss 0.49736127257347107 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 4/40
time = 56.23 secondes

Train loss 0.19871302677149122 accuracy 0.9282945990562439 macro_avg {'precision': 0.9289675337769712, 'recall': 0.9149179981470345, 'f1-score': 0.9211826727380064, 'support': 516} weighted_avg {'precision': 0.9283987222355093, 'recall': 0.9282945736434108, 'f1-score': 0.9276980916319898, 'support': 516}
 
time = 1.53 secondes

Val loss 0.48872246593236923 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 58.11 secondes

Train loss 0.1334665554265181 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.50 secondes

Val loss 0.7548781484365463 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 6/40
time = 57.61 secondes

Train loss 0.23320880540731279 accuracy 0.9205426573753357 macro_avg {'precision': 0.9241584564860428, 'recall': 0.903068771028721, 'f1-score': 0.9119728712006159, 'support': 516} weighted_avg {'precision': 0.9213059756113086, 'recall': 0.9205426356589147, 'f1-score': 0.9195312969961341, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5518350973725319 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 57.96 secondes

Train loss 0.2628673800394278 accuracy 0.9282945990562439 macro_avg {'precision': 0.9189536878216124, 'recall': 0.9287664775774913, 'f1-score': 0.9233545434472792, 'support': 516} weighted_avg {'precision': 0.9300070693774072, 'recall': 0.9282945736434108, 'f1-score': 0.9287093853392693, 'support': 516}
 
time = 1.53 secondes

Val loss 1.1816385835409164 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 8/40
time = 58.93 secondes

Train loss 0.2524587168485265 accuracy 0.9341084957122803 macro_avg {'precision': 0.9348470883954755, 'recall': 0.9217853485688279, 'f1-score': 0.9276655397047908, 'support': 516} weighted_avg {'precision': 0.9342153070735217, 'recall': 0.9341085271317829, 'f1-score': 0.9336064761634458, 'support': 516}
 
time = 1.59 secondes

Val loss 1.4966325610876083 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 57.95 secondes

Train loss 0.11853025468404997 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.48 secondes

Val loss 0.8987989872694016 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.07 secondes

Train loss 0.1455599951141542 accuracy 0.961240291595459 macro_avg {'precision': 0.9529495380241649, 'recall': 0.9661427433642703, 'f1-score': 0.9586988538131523, 'support': 516} weighted_avg {'precision': 0.9632766400555363, 'recall': 0.9612403100775194, 'f1-score': 0.9615182818564345, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8139927685260773 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 57.52 secondes

Train loss 0.16063062787394633 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.56 secondes

Val loss 0.94292351603508 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 12/40
time = 57.96 secondes

Train loss 0.07956342408821608 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9539240002632141 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 13/40
time = 58.60 secondes

Train loss 0.14827841556997914 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.42 secondes

Val loss 1.1003360152244568 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 59.25 secondes

Train loss 0.5446962917816233 accuracy 0.9069767594337463 macro_avg {'precision': 0.920650353805434, 'recall': 0.8797360336784616, 'f1-score': 0.8947296837810269, 'support': 516} weighted_avg {'precision': 0.9114043892056577, 'recall': 0.9069767441860465, 'f1-score': 0.9046108347896223, 'support': 516}
 
time = 1.57 secondes

Val loss 1.6026472672820091 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 15/40
time = 57.45 secondes

Train loss 0.434218908577212 accuracy 0.9108527302742004 macro_avg {'precision': 0.9028687927770497, 'recall': 0.9047023064544967, 'f1-score': 0.9037688116242866, 'support': 516} weighted_avg {'precision': 0.9110841311609394, 'recall': 0.9108527131782945, 'f1-score': 0.9109539117719233, 'support': 516}
 
time = 1.51 secondes

Val loss 0.885037012398243 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 16/40
time = 58.15 secondes

Train loss 0.17614273403799444 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1502974927425385 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 58.25 secondes

Train loss 0.11607593716877146 accuracy 0.9767441749572754 macro_avg {'precision': 0.9770590262393541, 'recall': 0.9725305983128261, 'f1-score': 0.9747203396750224, 'support': 516} weighted_avg {'precision': 0.9767609775234631, 'recall': 0.9767441860465116, 'f1-score': 0.9766887382007174, 'support': 516}
 
time = 1.43 secondes

Val loss 1.78080315887928 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 58.10 secondes

Train loss 0.1036966544819403 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 1.48 secondes

Val loss 1.043642833828926 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 19/40
time = 59.61 secondes

Train loss 0.04387720590845371 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.46 secondes

Val loss 1.057699915021658 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 20/40
time = 58.65 secondes

Train loss 0.037541744390954125 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0658883154392242 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 21/40
time = 57.82 secondes

Train loss 0.022469222611768848 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.49 secondes

Val loss 1.4138997495174408 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 22/40
time = 58.14 secondes

Train loss 0.1305960425368429 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.45 secondes

Val loss 1.0970347225666046 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 23/40
time = 58.16 secondes

Train loss 0.13053028398964228 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.43 secondes

Val loss 1.3298837095499039 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 24/40
time = 58.85 secondes

Train loss 0.054781283178299695 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4081860333681107 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 25/40
time = 58.53 secondes

Train loss 0.05968497074685398 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.52 secondes

Val loss 1.5865978300571442 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 57.49 secondes

Train loss 0.025103735711044548 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.45 secondes

Val loss 1.4306539446115494 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 27/40
time = 57.73 secondes

Train loss 0.16369178507364157 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 1.50 secondes

Val loss 1.851192146539688 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 59.18 secondes

Train loss 0.005236345648881979 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5091046690940857 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 29/40
time = 58.40 secondes

Train loss 0.1426365165534662 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 1.49 secondes

Val loss 2.00705686211586 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 58.43 secondes

Train loss 0.0003581510629208589 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.907425582408905 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 31/40
time = 58.29 secondes

Train loss 0.13050016070580264 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 1.52 secondes

Val loss 1.369198501110077 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 32/40
time = 57.92 secondes

Train loss 0.02882400349754431 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.55 secondes

Val loss 1.362718105316162 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 33/40
time = 57.82 secondes

Train loss 0.05366902462485472 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.43 secondes

Val loss 1.574650526046753 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 58.83 secondes

Train loss 0.11593728005810232 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2834101170301437 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 35/40
time = 58.55 secondes

Train loss 0.0005483728027408661 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.46 secondes

Val loss 1.4318679571151733 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 57.69 secondes

Train loss 0.014917325891226275 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.55 secondes

Val loss 1.4637317061424255 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 58.11 secondes

Train loss 0.00034030022321861577 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.44 secondes

Val loss 1.5544102787971497 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 38/40
time = 59.14 secondes

Train loss 0.012974465915414674 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.56 secondes

Val loss 1.5192304253578186 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 39/40
time = 56.62 secondes

Train loss 0.0002518649698961808 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.72 secondes

Val loss 1.492131769657135 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 54.25 secondes

Train loss 0.0002192168105852254 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4562963843345642 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 4 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}

average train time 58.2268084526062

average val time 1.498611730337143
 
time = 1.60 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9187370600414079, 'recall': 0.8942495126705653, 'f1-score': 0.9025000000000001, 'support': 65} weighted_avg {'precision': 0.9123427297340341, 'recall': 0.9076923076923077, 'f1-score': 0.9063076923076923, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 58.20 secondes

Train loss 0.6374155364253304 accuracy 0.6531007885932922 macro_avg {'precision': 0.6155701754385965, 'recall': 0.5513954130975408, 'f1-score': 0.523639083008845, 'support': 516} weighted_avg {'precision': 0.6290281177750577, 'recall': 0.6531007751937985, 'f1-score': 0.591979455835103, 'support': 516}
 
time = 1.46 secondes

Val loss 0.561345599591732 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 2/40
time = 41.70 secondes

Train loss 0.45311670502026874 accuracy 0.8023256063461304 macro_avg {'precision': 0.791846732569329, 'recall': 0.7711262454691741, 'f1-score': 0.778886872353297, 'support': 516} weighted_avg {'precision': 0.7995168177924982, 'recall': 0.8023255813953488, 'f1-score': 0.7986981621388408, 'support': 516}
 
time = 1.43 secondes

Val loss 0.4244902431964874 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 3/40
time = 42.44 secondes

Train loss 0.37801144791371893 accuracy 0.8391472697257996 macro_avg {'precision': 0.8257978723404256, 'recall': 0.8265445443167596, 'f1-score': 0.8261674277016743, 'support': 516} weighted_avg {'precision': 0.8393379927428665, 'recall': 0.8391472868217055, 'f1-score': 0.8392393425601453, 'support': 516}
 
time = 1.17 secondes

Val loss 0.6173442825675011 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 4/40
time = 42.40 secondes

Train loss 0.27668220640131924 accuracy 0.8992248177528381 macro_avg {'precision': 0.8931805063082379, 'recall': 0.8875054857532956, 'f1-score': 0.8901911995809324, 'support': 516} weighted_avg {'precision': 0.8987538217942793, 'recall': 0.8992248062015504, 'f1-score': 0.89885857890612, 'support': 516}
 
time = 1.44 secondes

Val loss 0.45129262655973434 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 42.02 secondes

Train loss 0.226768580858003 accuracy 0.9263566136360168 macro_avg {'precision': 0.933022533022533, 'recall': 0.9076280415454383, 'f1-score': 0.9180815508021389, 'support': 516} weighted_avg {'precision': 0.9279334790962698, 'recall': 0.9263565891472868, 'f1-score': 0.9252465230278157, 'support': 516}
 
time = 1.43 secondes

Val loss 0.5047126337885857 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 6/40
time = 42.15 secondes

Train loss 0.20628938553008166 accuracy 0.9379844665527344 macro_avg {'precision': 0.9368068564229233, 'recall': 0.9282869821042536, 'f1-score': 0.9322601289814404, 'support': 516} weighted_avg {'precision': 0.9378652414707542, 'recall': 0.937984496124031, 'f1-score': 0.9376791965430928, 'support': 516}
 
time = 1.47 secondes

Val loss 0.6155314296483994 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 7/40
time = 45.11 secondes

Train loss 0.14635137129913678 accuracy 0.963178277015686 macro_avg {'precision': 0.9606549364613881, 'recall': 0.9595842205354095, 'f1-score': 0.960115049612094, 'support': 516} weighted_avg {'precision': 0.9631432479331955, 'recall': 0.9631782945736435, 'f1-score': 0.9631568732802058, 'support': 516}
 
time = 1.49 secondes

Val loss 0.5944652408361435 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 8/40
time = 45.62 secondes

Train loss 0.10439335131509737 accuracy 0.9748061895370483 macro_avg {'precision': 0.9732649071358749, 'recall': 0.9721648814264584, 'f1-score': 0.9727102971030117, 'support': 516} weighted_avg {'precision': 0.9747847946835194, 'recall': 0.9748062015503876, 'f1-score': 0.9747915448759306, 'support': 516}
 
time = 1.33 secondes

Val loss 1.0335868299007416 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 9/40
time = 42.00 secondes

Train loss 0.3664853804829446 accuracy 0.9069767594337463 macro_avg {'precision': 0.9008516713434747, 'recall': 0.8970466329665329, 'f1-score': 0.8988813587000898, 'support': 516} weighted_avg {'precision': 0.9066500736344427, 'recall': 0.9069767441860465, 'f1-score': 0.9067549528028697, 'support': 516}
 
time = 1.25 secondes

Val loss 0.8458001017570496 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 10/40
time = 42.26 secondes

Train loss 0.06868391689336435 accuracy 0.9825581312179565 macro_avg {'precision': 0.9816715542521994, 'recall': 0.9805519886871576, 'f1-score': 0.9811071287636235, 'support': 516} weighted_avg {'precision': 0.982545825850402, 'recall': 0.9825581395348837, 'f1-score': 0.9825479926064133, 'support': 516}
 
time = 1.19 secondes

Val loss 1.2060777097940445 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 11/40
time = 41.71 secondes

Train loss 0.13057113065962878 accuracy 0.963178277015686 macro_avg {'precision': 0.959684743124027, 'recall': 0.9607382604879476, 'f1-score': 0.96020700152207, 'support': 516} weighted_avg {'precision': 0.9632282024514951, 'recall': 0.9631782945736435, 'f1-score': 0.9631993675740091, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4606791138648987 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 12/40
time = 41.65 secondes

Train loss 0.14628580346294312 accuracy 0.9689922332763672 macro_avg {'precision': 0.9752439373767674, 'recall': 0.9583732912894365, 'f1-score': 0.9658730158730159, 'support': 516} weighted_avg {'precision': 0.9700219380667982, 'recall': 0.9689922480620154, 'f1-score': 0.968712316968131, 'support': 516}
 
time = 1.21 secondes

Val loss 0.5726804840378463 accuracy 0.921875 macro_avg {'precision': 0.9193548387096775, 'recall': 0.9342105263157895, 'f1-score': 0.9209290832715591, 'support': 64} weighted_avg {'precision': 0.934475806451613, 'recall': 0.921875, 'f1-score': 0.9225506548060292, 'support': 64}
 
----------
Epoch 13/40
time = 41.91 secondes

Train loss 0.21209905690259553 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.40 secondes

Val loss 0.9804760664701462 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 48.72 secondes

Train loss 0.09598232348534194 accuracy 0.9709302186965942 macro_avg {'precision': 0.9725198412698413, 'recall': 0.9645092079384945, 'f1-score': 0.9682858372088259, 'support': 516} weighted_avg {'precision': 0.9710728897502153, 'recall': 0.9709302325581395, 'f1-score': 0.9708059992195812, 'support': 516}
 
time = 1.32 secondes

Val loss 1.113977000117302 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 15/40
time = 41.98 secondes

Train loss 0.10521147426246016 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 1.32 secondes

Val loss 1.0409061312675476 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 16/40
time = 41.91 secondes

Train loss 0.10001609932320814 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.47 secondes

Val loss 0.8525237143039703 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 17/40
time = 42.09 secondes

Train loss 0.15838851241013882 accuracy 0.9554263353347778 macro_avg {'precision': 0.9579545454545455, 'recall': 0.9454269135120199, 'f1-score': 0.9511297236531644, 'support': 516} weighted_avg {'precision': 0.955765503875969, 'recall': 0.9554263565891473, 'f1-score': 0.9551174483388478, 'support': 516}
 
time = 1.12 secondes

Val loss 0.8903215527534485 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 18/40
time = 42.53 secondes

Train loss 0.14687808098229158 accuracy 0.9670542478561401 macro_avg {'precision': 0.9682539682539683, 'recall': 0.9603156543081449, 'f1-score': 0.9640572821700026, 'support': 516} weighted_avg {'precision': 0.9671619293712317, 'recall': 0.9670542635658915, 'f1-score': 0.9669134657821921, 'support': 516}
 
time = 1.32 secondes

Val loss 1.0236577168107033 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 19/40
time = 41.75 secondes

Train loss 0.1107209228035627 accuracy 0.9670542478561401 macro_avg {'precision': 0.9659180199057098, 'recall': 0.9626237342132211, 'f1-score': 0.9642296447023418, 'support': 516} weighted_avg {'precision': 0.967008199633722, 'recall': 0.9670542635658915, 'f1-score': 0.9669958231756111, 'support': 516}
 
time = 1.23 secondes

Val loss 0.5944316647946835 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 20/40
time = 41.89 secondes

Train loss 0.1313451775049819 accuracy 0.9670542478561401 macro_avg {'precision': 0.9708890374331551, 'recall': 0.9580075744030687, 'f1-score': 0.9638784913958172, 'support': 516} weighted_avg {'precision': 0.9675686844505244, 'recall': 0.9670542635658915, 'f1-score': 0.9668259400765398, 'support': 516}
 
time = 1.38 secondes

Val loss 1.186326190829277 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 21/40
time = 42.63 secondes

Train loss 0.11823306926243911 accuracy 0.9728682041168213 macro_avg {'precision': 0.9706451245875526, 'recall': 0.9706451245875526, 'f1-score': 0.9706451245875526, 'support': 516} weighted_avg {'precision': 0.9728682170542635, 'recall': 0.9728682170542635, 'f1-score': 0.9728682170542635, 'support': 516}
 
time = 1.05 secondes

Val loss 1.6532002538442612 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 22/40
time = 42.35 secondes

Train loss 0.22252190469016292 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 1.46 secondes

Val loss 1.1024556532502174 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 23/40
time = 48.15 secondes

Train loss 0.059392741511780485 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.27 secondes

Val loss 1.9410807937383652 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 24/40
time = 42.37 secondes

Train loss 1.261617637073593 accuracy 0.8352712988853455 macro_avg {'precision': 0.84375, 'recall': 0.8708206686930091, 'f1-score': 0.8332363777389955, 'support': 516} weighted_avg {'precision': 0.8867490310077519, 'recall': 0.8352713178294574, 'f1-score': 0.8383058776134794, 'support': 516}
 
time = 1.48 secondes

Val loss 1.9783078134059906 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 25/40
time = 41.69 secondes

Train loss 0.13178771482798216 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 1.61 secondes

Val loss 1.1167332902550697 accuracy 0.84375 macro_avg {'precision': 0.8392156862745098, 'recall': 0.8502024291497976, 'f1-score': 0.8412698412698413, 'support': 64} weighted_avg {'precision': 0.8528186274509804, 'recall': 0.84375, 'f1-score': 0.8449900793650793, 'support': 64}
 
----------
Epoch 26/40
time = 42.21 secondes

Train loss 0.02259709742572864 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.52 secondes

Val loss 1.3107868134975433 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 27/40
time = 42.41 secondes

Train loss 0.04662652994827085 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.37 secondes

Val loss 1.6763089895248413 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 49.69 secondes

Train loss 0.10702105236564283 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.24 secondes

Val loss 1.4293473958969116 accuracy 0.78125 macro_avg {'precision': 0.78125, 'recall': 0.791497975708502, 'f1-score': 0.7793103448275862, 'support': 64} weighted_avg {'precision': 0.798828125, 'recall': 0.78125, 'f1-score': 0.7831896551724138, 'support': 64}
 
----------
Epoch 29/40
time = 41.83 secondes

Train loss 0.01551296721762893 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.28 secondes

Val loss 2.058484822511673 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 41.75 secondes

Train loss 0.24252158252629946 accuracy 0.9593023061752319 macro_avg {'precision': 0.97, 'recall': 0.9438502673796791, 'f1-score': 0.9547910399813089, 'support': 516} weighted_avg {'precision': 0.9617441860465116, 'recall': 0.9593023255813954, 'f1-score': 0.9587211170071511, 'support': 516}
 
time = 1.25 secondes

Val loss 1.1964348554611206 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 31/40
time = 41.75 secondes

Train loss 0.023894131638702343 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.38 secondes

Val loss 1.3375350311398506 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 32/40
time = 42.13 secondes

Train loss 0.11144921667282963 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 1.43 secondes

Val loss 1.541494458913803 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 33/40
time = 42.51 secondes

Train loss 0.00033461486578523886 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.29 secondes

Val loss 1.375336142955348 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 34/40
time = 42.10 secondes

Train loss 0.0182146547903716 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.44 secondes

Val loss 1.4331416711211205 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 35/40
time = 42.15 secondes

Train loss 0.007207537785165407 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.33 secondes

Val loss 1.6340249180793762 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 36/40
time = 41.92 secondes

Train loss 0.00018465895096376312 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.40 secondes

Val loss 1.369975435849483 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 47.14 secondes

Train loss 0.02102430409506655 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.36 secondes

Val loss 1.3082566987723112 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 38/40
time = 43.19 secondes

Train loss 0.00015546607601484567 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.42 secondes

Val loss 1.5648955404758453 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 39/40
time = 42.72 secondes

Train loss 0.00022033859061070183 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.49 secondes

Val loss 1.5159098207950592 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 40/40
time = 41.82 secondes

Train loss 0.01635921289959118 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.33 secondes

Val loss 1.4965901970863342 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 12 macro_avg {'precision': 0.9193548387096775, 'recall': 0.9342105263157895, 'f1-score': 0.9209290832715591, 'support': 64} weighted_avg {'precision': 0.934475806451613, 'recall': 0.921875, 'f1-score': 0.9225506548060292, 'support': 64}

average train time 43.313937336206436

average val time 1.354438805580139
 
time = 1.52 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9366471734892787, 'recall': 0.9366471734892787, 'f1-score': 0.9366471734892787, 'support': 65} weighted_avg {'precision': 0.9384615384615385, 'recall': 0.9384615384615385, 'f1-score': 0.9384615384615385, 'support': 65}

normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 38.57 GiB already allocated; 76.62 MiB free; 39.42 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.24 GiB already allocated; 504.62 MiB free; 39.00 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 36.10 GiB already allocated; 626.62 MiB free; 38.88 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.48 GiB already allocated; 590.62 MiB free; 38.91 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_4
----------
Epoch 1/40
time = 42.50 secondes

Train loss 0.6502475828835459 accuracy 0.6182170510292053 macro_avg {'precision': 0.5408768497003791, 'recall': 0.5217317100921607, 'f1-score': 0.49484920315458353, 'support': 516} weighted_avg {'precision': 0.5707200808090002, 'recall': 0.6182170542635659, 'f1-score': 0.5635481633799777, 'support': 516}
 
time = 2.37 secondes

Val loss 0.6215917989611626 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 37.77 secondes

Train loss 0.509406199057897 accuracy 0.7655038833618164 macro_avg {'precision': 0.7535542391706775, 'recall': 0.7226321863368171, 'f1-score': 0.7317661008648133, 'support': 516} weighted_avg {'precision': 0.7611294553553235, 'recall': 0.7655038759689923, 'f1-score': 0.7579451394702418, 'support': 516}
 
time = 1.99 secondes

Val loss 0.44741108268499374 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 3/40
time = 39.79 secondes

Train loss 0.42789786783131684 accuracy 0.8081395030021667 macro_avg {'precision': 0.7919287211740043, 'recall': 0.7987663150366529, 'f1-score': 0.7949216162508279, 'support': 516} weighted_avg {'precision': 0.811111517397169, 'recall': 0.8081395348837209, 'f1-score': 0.809249436448315, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7124811410903931 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 4/40
time = 40.92 secondes

Train loss 0.3097408725456758 accuracy 0.8759689927101135 macro_avg {'precision': 0.8676506967922817, 'recall': 0.8623441639711977, 'f1-score': 0.8648507071765322, 'support': 516} weighted_avg {'precision': 0.8753208133813778, 'recall': 0.875968992248062, 'f1-score': 0.8755182509613785, 'support': 516}
 
time = 2.12 secondes

Val loss 0.6435048878192902 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 38.93 secondes

Train loss 0.2929804043167017 accuracy 0.8992248177528381 macro_avg {'precision': 0.8992718653547738, 'recall': 0.8805812460380671, 'f1-score': 0.888504753673293, 'support': 516} weighted_avg {'precision': 0.8992343237831012, 'recall': 0.8992248062015504, 'f1-score': 0.8980188002921213, 'support': 516}
 
time = 2.05 secondes

Val loss 0.47357431799173355 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 6/40
time = 39.33 secondes

Train loss 0.25419013525331113 accuracy 0.9205426573753357 macro_avg {'precision': 0.9117468143689569, 'recall': 0.9180712904117159, 'f1-score': 0.9147042103608016, 'support': 516} weighted_avg {'precision': 0.9215046786125038, 'recall': 0.9205426356589147, 'f1-score': 0.9208453688225204, 'support': 516}
 
time = 1.87 secondes

Val loss 0.6549891345202923 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 7/40
time = 40.48 secondes

Train loss 0.1737329674052131 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 1.93 secondes

Val loss 0.41872819140553474 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 39.11 secondes

Train loss 0.16758951770536828 accuracy 0.9496123790740967 macro_avg {'precision': 0.9430693466369368, 'recall': 0.9489459226630691, 'f1-score': 0.9458508233774621, 'support': 516} weighted_avg {'precision': 0.950216377543591, 'recall': 0.9496124031007752, 'f1-score': 0.9497783551473921, 'support': 516}
 
time = 1.53 secondes

Val loss 1.8777442574501038 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 9/40
time = 38.00 secondes

Train loss 0.2548922983661407 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.88 secondes

Val loss 0.842892125248909 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 10/40
time = 43.55 secondes

Train loss 0.1294738863608941 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 1.67 secondes

Val loss 1.2877298295497894 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 11/40
time = 38.03 secondes

Train loss 0.37414150096998183 accuracy 0.9341084957122803 macro_avg {'precision': 0.9510678223572513, 'recall': 0.9102449490434472, 'f1-score': 0.9256547165013984, 'support': 516} weighted_avg {'precision': 0.9393774343862973, 'recall': 0.9341085271317829, 'f1-score': 0.9325538033376891, 'support': 516}
 
time = 1.91 secondes

Val loss 1.1649150848388672 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 12/40
time = 40.47 secondes

Train loss 0.14792993520280684 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.65 secondes

Val loss 1.3746942579746246 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 13/40
time = 39.73 secondes

Train loss 0.19222142119454502 accuracy 0.9496123790740967 macro_avg {'precision': 0.9580666746735755, 'recall': 0.9339434032800741, 'f1-score': 0.9441027948602569, 'support': 516} weighted_avg {'precision': 0.9514704847651269, 'recall': 0.9496124031007752, 'f1-score': 0.948932204552563, 'support': 516}
 
time = 2.05 secondes

Val loss 2.012902110815048 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 14/40
time = 39.40 secondes

Train loss 0.12621477409310033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9797821938540501, 'recall': 0.9740503551517319, 'f1-score': 0.9767992250058248, 'support': 516} weighted_avg {'precision': 0.9787545404973339, 'recall': 0.9786821705426356, 'f1-score': 0.9786181247760776, 'support': 516}
 
time = 1.95 secondes

Val loss 1.8121185898780823 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 15/40
time = 39.27 secondes

Train loss 0.22127158074352227 accuracy 0.9573643207550049 macro_avg {'precision': 0.9622002393029879, 'recall': 0.9457926303983876, 'f1-score': 0.9530753968253968, 'support': 516} weighted_avg {'precision': 0.9581608419681893, 'recall': 0.9573643410852714, 'f1-score': 0.9569794358311798, 'support': 516}
 
time = 1.82 secondes

Val loss 2.10396209359169 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 16/40
time = 40.10 secondes

Train loss 0.18444505678516263 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.62 secondes

Val loss 1.3474785685539246 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 17/40
time = 41.29 secondes

Train loss 0.06399768915037964 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.97 secondes

Val loss 0.9417189881205559 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 18/40
time = 39.05 secondes

Train loss 0.4419193771336171 accuracy 0.9186046719551086 macro_avg {'precision': 0.9105598066854612, 'recall': 0.914243453667734, 'f1-score': 0.9123343527013252, 'support': 516} weighted_avg {'precision': 0.9190849403853179, 'recall': 0.9186046511627907, 'f1-score': 0.9187863989442825, 'support': 516}
 
time = 1.47 secondes

Val loss 0.8806437849998474 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 19/40
time = 39.49 secondes

Train loss 0.16448156353947002 accuracy 0.961240291595459 macro_avg {'precision': 0.9612599983507875, 'recall': 0.9546023438388895, 'f1-score': 0.9577658459926663, 'support': 516} weighted_avg {'precision': 0.9612418442286832, 'recall': 0.9612403100775194, 'f1-score': 0.9610994534254307, 'support': 516}
 
time = 2.17 secondes

Val loss 0.8274401426315308 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 20/40
time = 39.11 secondes

Train loss 0.12876486600990492 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.93 secondes

Val loss 0.8372616544365883 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 21/40
time = 38.67 secondes

Train loss 0.08721147193996744 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 1.82 secondes

Val loss 1.062270313501358 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 22/40
time = 38.95 secondes

Train loss 0.058648511774442864 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.66 secondes

Val loss 1.291184887290001 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 23/40
time = 39.03 secondes

Train loss 0.0452318968741703 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 2.23 secondes

Val loss 1.9735469222068787 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 24/40
time = 40.91 secondes

Train loss 0.34293285790111194 accuracy 0.9418604373931885 macro_avg {'precision': 0.9311009245590863, 'recall': 0.9509451749752125, 'f1-score': 0.9386522517952539, 'support': 516} weighted_avg {'precision': 0.9473546985922924, 'recall': 0.9418604651162791, 'f1-score': 0.9425129830798774, 'support': 516}
 
time = 1.43 secondes

Val loss 1.6655630320310593 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 25/40
time = 41.02 secondes

Train loss 0.09535022647469305 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.75 secondes

Val loss 1.0390583989210427 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 26/40
time = 40.02 secondes

Train loss 0.13972099651062198 accuracy 0.9786821603775024 macro_avg {'precision': 0.9774682306940372, 'recall': 0.976358435056808, 'f1-score': 0.9769087129333176, 'support': 516} weighted_avg {'precision': 0.9786653102669607, 'recall': 0.9786821705426356, 'f1-score': 0.978669768741172, 'support': 516}
 
time = 1.30 secondes

Val loss 1.4147384315729141 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 27/40
time = 38.41 secondes

Train loss 0.058669980899360256 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.09 secondes

Val loss 0.903839536011219 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 28/40
time = 38.97 secondes

Train loss 0.06214826349451235 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.80 secondes

Val loss 0.728185917250812 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 29/40
time = 38.54 secondes

Train loss 0.010623939959755675 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6172033548355103 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 38.79 secondes

Train loss 0.07192157786586463 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.82 secondes

Val loss 1.2587793618440628 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 31/40
time = 36.69 secondes

Train loss 0.012085543607650889 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.34 secondes

Val loss 1.4146884232759476 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 32/40
time = 36.32 secondes

Train loss 0.017149427898843758 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5102647494059056 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 34.84 secondes

Train loss 0.09528234315075679 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.33 secondes

Val loss 1.3578190803527832 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 34/40
time = 36.44 secondes

Train loss 0.002466697441625663 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.66 secondes

Val loss 1.0218378957360983 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 36.86 secondes

Train loss 0.0346477697074244 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.75 secondes

Val loss 1.3860953450202942 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 36/40
time = 35.81 secondes

Train loss 0.07223866712637105 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.64 secondes

Val loss 1.2280682548880577 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 36.47 secondes

Train loss 0.021948573842096128 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.90 secondes

Val loss 1.1350205773487687 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 38/40
time = 36.94 secondes

Train loss 0.012120993220543658 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3076321929693222 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 39/40
time = 36.49 secondes

Train loss 0.009670125583149704 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.66 secondes

Val loss 1.4507780820131302 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 36.42 secondes

Train loss 0.00014191514073348972 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4333347380161285 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 17 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 38.82262225151062

average val time 1.7757685899734497
 
time = 1.87 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9032567049808429, 'recall': 0.9103313840155945, 'f1-score': 0.9058880308880309, 'support': 65} weighted_avg {'precision': 0.9102269378131447, 'recall': 0.9076923076923077, 'f1-score': 0.9080932580932581, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_4
----------
Epoch 1/40
time = 54.61 secondes

Train loss 0.6052206285072096 accuracy 0.6220930218696594 macro_avg {'precision': 0.5354737854737854, 'recall': 0.5143848641971295, 'f1-score': 0.47217399058914866, 'support': 516} weighted_avg {'precision': 0.5656206770547857, 'recall': 0.622093023255814, 'f1-score': 0.5495867274570267, 'support': 516}
 
time = 2.24 secondes

Val loss 0.665861502289772 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 53.84 secondes

Train loss 0.3566817093753453 accuracy 0.8507751822471619 macro_avg {'precision': 0.8415441176470588, 'recall': 0.8322009654925799, 'f1-score': 0.8363908139692894, 'support': 516} weighted_avg {'precision': 0.8495368787049704, 'recall': 0.8507751937984496, 'f1-score': 0.8497410226996212, 'support': 516}
 
time = 2.00 secondes

Val loss 0.44534941762685776 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 3/40
time = 52.19 secondes

Train loss 0.24334063615198387 accuracy 0.9147287011146545 macro_avg {'precision': 0.912154392280386, 'recall': 0.9019716203696179, 'f1-score': 0.9066263078239126, 'support': 516} weighted_avg {'precision': 0.9144108686038567, 'recall': 0.9147286821705426, 'f1-score': 0.9141956312266853, 'support': 516}
 
time = 2.06 secondes

Val loss 0.5378583557903767 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 4/40
time = 51.95 secondes

Train loss 0.1814212049922031 accuracy 0.9515503644943237 macro_avg {'precision': 0.9500723827071132, 'recall': 0.9446954797392846, 'f1-score': 0.947270965922329, 'support': 516} weighted_avg {'precision': 0.9514531504330975, 'recall': 0.9515503875968992, 'f1-score': 0.9514048290365398, 'support': 516}
 
time = 1.95 secondes

Val loss 0.8098108023405075 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 5/40
time = 51.21 secondes

Train loss 0.10685272798450156 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0759399235248566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 6/40
time = 63.39 secondes

Train loss 0.19757196083876558 accuracy 0.9437984228134155 macro_avg {'precision': 0.9348417721518987, 'recall': 0.946694732051428, 'f1-score': 0.9400516795865634, 'support': 516} weighted_avg {'precision': 0.9458059807673437, 'recall': 0.9437984496124031, 'f1-score': 0.9441760310878754, 'support': 516}
 
time = 2.20 secondes

Val loss 1.289656475186348 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 7/40
time = 61.12 secondes

Train loss 0.2610441936306994 accuracy 0.9341084957122803 macro_avg {'precision': 0.931475220582172, 'recall': 0.9252474684264422, 'f1-score': 0.9282019381875328, 'support': 516} weighted_avg {'precision': 0.9339033344136316, 'recall': 0.9341085271317829, 'f1-score': 0.9338690708232323, 'support': 516}
 
time = 2.50 secondes

Val loss 1.5010225176811218 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 8/40
time = 61.58 secondes

Train loss 0.24086559725180973 accuracy 0.9437984228134155 macro_avg {'precision': 0.9379560865353568, 'recall': 0.9409245322887376, 'f1-score': 0.9394010569583089, 'support': 516} weighted_avg {'precision': 0.9440562009246258, 'recall': 0.9437984496124031, 'f1-score': 0.9438933573675274, 'support': 516}
 
time = 2.37 secondes

Val loss 1.2972755208611488 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 9/40
time = 62.57 secondes

Train loss 0.17100825949896578 accuracy 0.9554263353347778 macro_avg {'precision': 0.9513168137000518, 'recall': 0.9523511532272484, 'f1-score': 0.9518295281582952, 'support': 516} weighted_avg {'precision': 0.9554850643447058, 'recall': 0.9554263565891473, 'f1-score': 0.9554518660106426, 'support': 516}
 
time = 2.40 secondes

Val loss 1.391263633966446 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 10/40
time = 61.73 secondes

Train loss 0.10851525875940835 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 2.51 secondes

Val loss 1.0451386719942093 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 11/40
time = 62.26 secondes

Train loss 0.08287082006272888 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.48 secondes

Val loss 1.8729027807712555 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 12/40
time = 60.71 secondes

Train loss 0.09569069002949011 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5543503165245056 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 13/40
time = 61.53 secondes

Train loss 0.1608647581667879 accuracy 0.9573643207550049 macro_avg {'precision': 0.9652643964326518, 'recall': 0.9434845504933115, 'f1-score': 0.9528289342463933, 'support': 516} weighted_avg {'precision': 0.9589621050881123, 'recall': 0.9573643410852714, 'f1-score': 0.9568541078158976, 'support': 516}
 
time = 2.26 secondes

Val loss 2.117667078971863 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 14/40
time = 62.03 secondes

Train loss 0.9873484827412264 accuracy 0.8449612259864807 macro_avg {'precision': 0.8341594416723306, 'recall': 0.8276416949758627, 'f1-score': 0.830650322453601, 'support': 516} weighted_avg {'precision': 0.8438673872834702, 'recall': 0.8449612403100775, 'f1-score': 0.8441979913577321, 'support': 516}
 
time = 2.38 secondes

Val loss 1.617888018488884 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 62.55 secondes

Train loss 0.2168506928402084 accuracy 0.9573643207550049 macro_avg {'precision': 0.9499864742294288, 'recall': 0.9596411098288444, 'f1-score': 0.9543788580246912, 'support': 516} weighted_avg {'precision': 0.9585738274550816, 'recall': 0.9573643410852714, 'f1-score': 0.957590514044406, 'support': 516}
 
time = 2.47 secondes

Val loss 1.4157423079013824 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 62.15 secondes

Train loss 0.3946956769972475 accuracy 0.9244186282157898 macro_avg {'precision': 0.9194604504976427, 'recall': 0.9164946442793752, 'f1-score': 0.9179385966700785, 'support': 516} weighted_avg {'precision': 0.9242175984016957, 'recall': 0.9244186046511628, 'f1-score': 0.9242845355205198, 'support': 516}
 
time = 2.35 secondes

Val loss 1.1583004891872406 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 17/40
time = 61.35 secondes

Train loss 0.0524032155808527 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.59 secondes

Val loss 1.6846273094415665 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 61.86 secondes

Train loss 0.34373950946434034 accuracy 0.9263566136360168 macro_avg {'precision': 0.9220203810367744, 'recall': 0.9180144011182809, 'f1-score': 0.9199477423042377, 'support': 516} weighted_avg {'precision': 0.926125324714726, 'recall': 0.9263565891472868, 'f1-score': 0.9261810043022717, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6776372492313385 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 19/40
time = 61.59 secondes

Train loss 0.08670012707421626 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 2.45 secondes

Val loss 1.7826304137706757 accuracy 0.75 macro_avg {'precision': 0.7584541062801933, 'recall': 0.7165991902834008, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7548309178743962, 'recall': 0.75, 'f1-score': 0.7391774891774892, 'support': 64}
 
----------
Epoch 20/40
time = 59.85 secondes

Train loss 0.15885241739857575 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.78 secondes

Val loss 2.010408192873001 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 21/40
time = 50.90 secondes

Train loss 0.032350728449245886 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9708139672875404 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 51.22 secondes

Train loss 0.14020680028911695 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.92 secondes

Val loss 1.6221761107444763 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 23/40
time = 53.36 secondes

Train loss 0.04975731879720556 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.94 secondes

Val loss 1.6517925560474396 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 24/40
time = 53.40 secondes

Train loss 0.14401069832224908 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6974860578775406 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 25/40
time = 54.26 secondes

Train loss 0.0782484006027296 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 2.16 secondes

Val loss 1.621832400560379 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 26/40
time = 54.42 secondes

Train loss 0.06845679857647294 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8443526327610016 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 27/40
time = 53.62 secondes

Train loss 0.07718372638346134 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.13 secondes

Val loss 0.8541925735771656 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 28/40
time = 53.58 secondes

Train loss 0.01471875214536505 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.07 secondes

Val loss 1.1719386577606201 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 53.66 secondes

Train loss 0.0024413235792466862 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.2058558948338032 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 30/40
time = 52.92 secondes

Train loss 0.06301927973022843 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9099354445934296 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 31/40
time = 54.50 secondes

Train loss 0.0012452832337602917 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.79 secondes

Val loss 1.8820369988679886 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 32/40
time = 51.50 secondes

Train loss 0.029958484159909527 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.15250226855278 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 33/40
time = 51.21 secondes

Train loss 0.05022731599660112 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.72 secondes

Val loss 1.7247264087200165 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 34/40
time = 50.71 secondes

Train loss 0.040888782590848154 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8039852678775787 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 35/40
time = 51.41 secondes

Train loss 7.64346513085801e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6951496303081512 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 36/40
time = 55.03 secondes

Train loss 0.0001358925539093572 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.64 secondes

Val loss 1.6230476200580597 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 51.52 secondes

Train loss 4.082438560241523e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4412242770195007 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 50.16 secondes

Train loss 0.04809678205635988 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.34 secondes

Val loss 1.2933878004550934 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 39/40
time = 51.09 secondes

Train loss 0.00479410793476828 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.90 secondes

Val loss 1.3506575971841812 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 40/40
time = 53.81 secondes

Train loss 2.7775521768048886e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.85 secondes

Val loss 1.3970402926206589 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 39 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 56.059385776519775

average val time 2.077598822116852
 
time = 2.04 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_4
----------
Epoch 1/40
time = 146.99 secondes

Train loss 0.6226144866509871 accuracy 0.6627907156944275 macro_avg {'precision': 0.6470588235294117, 'recall': 0.5566861173869935, 'f1-score': 0.5248819930995068, 'support': 516} weighted_avg {'precision': 0.6524547803617571, 'recall': 0.6627906976744186, 'f1-score': 0.5953245688176271, 'support': 516}
 
time = 5.62 secondes

Val loss 0.590197965502739 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 2/40
time = 127.88 secondes

Train loss 0.3791160960540627 accuracy 0.8391472697257996 macro_avg {'precision': 0.8342226407198159, 'recall': 0.8115420249337646, 'f1-score': 0.8203274782163639, 'support': 516} weighted_avg {'precision': 0.8378648268993383, 'recall': 0.8391472868217055, 'f1-score': 0.8363299502041392, 'support': 516}
 
time = 5.58 secondes

Val loss 0.44320477172732353 accuracy 0.78125 macro_avg {'precision': 0.7738095238095238, 'recall': 0.7793522267206479, 'f1-score': 0.7757757757757758, 'support': 64} weighted_avg {'precision': 0.7849702380952381, 'recall': 0.78125, 'f1-score': 0.7823448448448449, 'support': 64}
 
----------
Epoch 3/40
time = 128.06 secondes

Train loss 0.2569656067838271 accuracy 0.8972868323326111 macro_avg {'precision': 0.8898965426925092, 'recall': 0.8871397688669278, 'f1-score': 0.8884806570131835, 'support': 516} weighted_avg {'precision': 0.8969872157994973, 'recall': 0.8972868217054264, 'f1-score': 0.8971046251945523, 'support': 516}
 
time = 5.45 secondes

Val loss 0.5784313306212425 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 4/40
time = 125.27 secondes

Train loss 0.2570064131622062 accuracy 0.8992248177528381 macro_avg {'precision': 0.8892667511509649, 'recall': 0.894429725468524, 'f1-score': 0.8917016467549241, 'support': 516} weighted_avg {'precision': 0.9001440112831428, 'recall': 0.8992248062015504, 'f1-score': 0.899556710294784, 'support': 516}
 
time = 5.65 secondes

Val loss 1.5297240316867828 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 5/40
time = 127.23 secondes

Train loss 0.20653889537788928 accuracy 0.9282945990562439 macro_avg {'precision': 0.9329844006568144, 'recall': 0.9114558782894202, 'f1-score': 0.9205608837664094, 'support': 516} weighted_avg {'precision': 0.9292846482351294, 'recall': 0.9282945736434108, 'f1-score': 0.9273819021672429, 'support': 516}
 
time = 5.35 secondes

Val loss 0.9345216155052185 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 6/40
time = 128.26 secondes

Train loss 0.10963218675742885 accuracy 0.9689922332763672 macro_avg {'precision': 0.9685915423620342, 'recall': 0.9641434910521269, 'f1-score': 0.9662937862333634, 'support': 516} weighted_avg {'precision': 0.9689708770913499, 'recall': 0.9689922480620154, 'f1-score': 0.9689183176009566, 'support': 516}
 
time = 5.43 secondes

Val loss 1.0677233040332794 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 7/40
time = 128.31 secondes

Train loss 0.039509868803151854 accuracy 0.9883720874786377 macro_avg {'precision': 0.988552298522087, 'recall': 0.9862652991564131, 'f1-score': 0.9873900293255132, 'support': 516} weighted_avg {'precision': 0.9883770301602101, 'recall': 0.9883720930232558, 'f1-score': 0.9883584532496761, 'support': 516}
 
time = 5.58 secondes

Val loss 1.4108815491199493 accuracy 0.734375 macro_avg {'precision': 0.7571428571428571, 'recall': 0.6912955465587045, 'f1-score': 0.694981777403981, 'support': 64} weighted_avg {'precision': 0.7491071428571429, 'recall': 0.734375, 'f1-score': 0.7155347631062519, 'support': 64}
 
----------
Epoch 8/40
time = 127.78 secondes

Train loss 0.1702873665931155 accuracy 0.961240291595459 macro_avg {'precision': 0.9580644636965038, 'recall': 0.9580644636965038, 'f1-score': 0.9580644636965038, 'support': 516} weighted_avg {'precision': 0.9612403100775194, 'recall': 0.9612403100775194, 'f1-score': 0.9612403100775194, 'support': 516}
 
time = 5.38 secondes

Val loss 1.8825113773345947 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 9/40
time = 128.80 secondes

Train loss 0.309170419209157 accuracy 0.9379844665527344 macro_avg {'precision': 0.9498381593911294, 'recall': 0.917900622531411, 'f1-score': 0.93063117564025, 'support': 516} weighted_avg {'precision': 0.9411617666904697, 'recall': 0.937984496124031, 'f1-score': 0.9368464822396364, 'support': 516}
 
time = 5.34 secondes

Val loss 2.8618274331092834 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 10/40
time = 126.00 secondes

Train loss 0.127136225330601 accuracy 0.9709302186965942 macro_avg {'precision': 0.9725198412698413, 'recall': 0.9645092079384945, 'f1-score': 0.9682858372088259, 'support': 516} weighted_avg {'precision': 0.9710728897502153, 'recall': 0.9709302325581395, 'f1-score': 0.9708059992195812, 'support': 516}
 
time = 5.50 secondes

Val loss 2.4762226939201355 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 11/40
time = 127.80 secondes

Train loss 0.1028368935693641 accuracy 0.9748061895370483 macro_avg {'precision': 0.9755379351187734, 'recall': 0.9698568015213822, 'f1-score': 0.972580902279611, 'support': 516} weighted_avg {'precision': 0.9748543419167288, 'recall': 0.9748062015503876, 'f1-score': 0.9747305110990007, 'support': 516}
 
time = 5.64 secondes

Val loss 1.4339593648910522 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 12/40
time = 129.44 secondes

Train loss 0.35239843155035155 accuracy 0.9341084957122803 macro_avg {'precision': 0.9234557478542282, 'recall': 0.940249987809437, 'f1-score': 0.9302070238530942, 'support': 516} weighted_avg {'precision': 0.9382860876327849, 'recall': 0.9341085271317829, 'f1-score': 0.9347481178332073, 'support': 516}
 
time = 5.39 secondes

Val loss 1.0263081938028336 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 13/40
time = 127.11 secondes

Train loss 0.40703716848722915 accuracy 0.9069767594337463 macro_avg {'precision': 0.9246383702430372, 'recall': 0.8774279537733856, 'f1-score': 0.8940886699507389, 'support': 516} weighted_avg {'precision': 0.9131340083160066, 'recall': 0.9069767441860465, 'f1-score': 0.9042559285141483, 'support': 516}
 
time = 5.25 secondes

Val loss 1.401521921157837 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 14/40
time = 129.63 secondes

Train loss 0.14335149148202175 accuracy 0.9573643207550049 macro_avg {'precision': 0.9538709100661541, 'recall': 0.9538709100661541, 'f1-score': 0.9538709100661541, 'support': 516} weighted_avg {'precision': 0.9573643410852714, 'recall': 0.9573643410852714, 'f1-score': 0.9573643410852714, 'support': 516}
 
time = 5.29 secondes

Val loss 1.3256975710391998 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 15/40
time = 129.00 secondes

Train loss 0.1679057201236543 accuracy 0.9554263353347778 macro_avg {'precision': 0.9476367448065561, 'recall': 0.9581213529899387, 'f1-score': 0.9523555270077682, 'support': 516} weighted_avg {'precision': 0.9568544520826223, 'recall': 0.9554263565891473, 'f1-score': 0.9556842125081945, 'support': 516}
 
time = 5.64 secondes

Val loss 1.3805959522724152 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 16/40
time = 127.74 secondes

Train loss 0.03892988086723066 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 5.66 secondes

Val loss 1.9749776721000671 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 17/40
time = 126.30 secondes

Train loss 0.08267923452976075 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 5.27 secondes

Val loss 1.987569808959961 accuracy 0.6875 macro_avg {'precision': 0.7333333333333334, 'recall': 0.6275303643724697, 'f1-score': 0.6135265700483092, 'support': 64} weighted_avg {'precision': 0.7208333333333333, 'recall': 0.6875, 'f1-score': 0.6452294685990339, 'support': 64}
 
----------
Epoch 18/40
time = 128.56 secondes

Train loss 0.05737642337882073 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 5.60 secondes

Val loss 1.7153352499008179 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 19/40
time = 128.76 secondes

Train loss 0.06155502911993112 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 5.27 secondes

Val loss 1.9239692091941833 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 20/40
time = 128.74 secondes

Train loss 0.07560826328875864 accuracy 0.9844961166381836 macro_avg {'precision': 0.9812162706403544, 'recall': 0.9855338653836776, 'f1-score': 0.983301781466919, 'support': 516} weighted_avg {'precision': 0.9846919361737333, 'recall': 0.9844961240310077, 'f1-score': 0.9845307426560538, 'support': 516}
 
time = 5.24 secondes

Val loss 1.5968544483184814 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 21/40
time = 127.32 secondes

Train loss 0.015910511703457978 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 5.63 secondes

Val loss 1.8169176280498505 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 22/40
time = 128.03 secondes

Train loss 0.06386333148938403 accuracy 0.9844961166381836 macro_avg {'precision': 0.9867898078667436, 'recall': 0.9797636656209873, 'f1-score': 0.9831063383970666, 'support': 516} weighted_avg {'precision': 0.9846748526415846, 'recall': 0.9844961240310077, 'f1-score': 0.9844397813701723, 'support': 516}
 
time = 5.67 secondes

Val loss 1.368076130747795 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 23/40
time = 126.40 secondes

Train loss 0.07740578859771961 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 5.51 secondes

Val loss 1.570286363363266 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 24/40
time = 128.14 secondes

Train loss 0.016081998069377292 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 5.65 secondes

Val loss 2.1131279468536377 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 25/40
time = 127.94 secondes

Train loss 0.14825899847148155 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 5.56 secondes

Val loss 1.63151016831398 accuracy 0.75 macro_avg {'precision': 0.7445887445887446, 'recall': 0.728744939271255, 'f1-score': 0.7333333333333334, 'support': 64} weighted_avg {'precision': 0.7478354978354977, 'recall': 0.75, 'f1-score': 0.7458333333333333, 'support': 64}
 
----------
Epoch 26/40
time = 128.30 secondes

Train loss 0.04690977355262889 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 5.51 secondes

Val loss 1.581773191690445 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 27/40
time = 128.16 secondes

Train loss 0.0947956953461857 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 5.38 secondes

Val loss 1.8625943064689636 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 28/40
time = 126.99 secondes

Train loss 0.06735615151917569 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 5.33 secondes

Val loss 1.9080259501934052 accuracy 0.71875 macro_avg {'precision': 0.71875, 'recall': 0.7267206477732794, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.736328125, 'recall': 0.71875, 'f1-score': 0.7212438423645322, 'support': 64}
 
----------
Epoch 29/40
time = 127.37 secondes

Train loss 0.03262368301930661 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 5.30 secondes

Val loss 1.9862456023693085 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 30/40
time = 126.51 secondes

Train loss 0.029364165662682906 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 5.75 secondes

Val loss 2.224456936120987 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 31/40
time = 128.27 secondes

Train loss 0.014102763104870754 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 5.48 secondes

Val loss 2.6864945888519287 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 32/40
time = 127.92 secondes

Train loss 0.034437943286045054 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 5.50 secondes

Val loss 1.5310964733362198 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 33/40
time = 129.81 secondes

Train loss 0.016010257460341865 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 5.41 secondes

Val loss 1.3927721977233887 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 34/40
time = 127.79 secondes

Train loss 7.088732435835426e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.45 secondes

Val loss 1.8502059280872345 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 35/40
time = 128.62 secondes

Train loss 3.5147451027031906e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.43 secondes

Val loss 1.8132334053516388 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 36/40
time = 125.87 secondes

Train loss 0.018532499757467038 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 5.57 secondes

Val loss 1.831334501504898 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 127.93 secondes

Train loss 7.412664644741172e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.52 secondes

Val loss 1.8803961873054504 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 38/40
time = 128.02 secondes

Train loss 0.0008282636349163527 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.58 secondes

Val loss 1.8789447247982025 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 39/40
time = 128.17 secondes

Train loss 5.177492899251361e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.72 secondes

Val loss 1.784306287765503 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 40/40
time = 128.28 secondes

Train loss 1.7252428843869094e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 5.48 secondes

Val loss 1.8102921545505524 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 33 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 128.33797478079796

average val time 5.488497787714005
 
time = 6.63 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9343869731800767, 'recall': 0.9420077972709551, 'f1-score': 0.9372586872586872, 'support': 65} weighted_avg {'precision': 0.9407898614795167, 'recall': 0.9384615384615385, 'f1-score': 0.9387288387288387, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_4
----------
Epoch 1/40
time = 95.91 secondes

Train loss 0.6500309759920294 accuracy 0.6259689927101135 macro_avg {'precision': 0.5233729338842975, 'recall': 0.5058839783495603, 'f1-score': 0.4406645436317377, 'support': 516} weighted_avg {'precision': 0.5556044389454802, 'recall': 0.625968992248062, 'f1-score': 0.5292612833742226, 'support': 516}
 
time = 2.48 secondes

Val loss 0.586968868970871 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 2/40
time = 95.70 secondes

Train loss 0.40865411135283386 accuracy 0.819767415523529 macro_avg {'precision': 0.8135386464889329, 'recall': 0.7882661768769403, 'f1-score': 0.7975318017846972, 'support': 516} weighted_avg {'precision': 0.8179610912027208, 'recall': 0.8197674418604651, 'f1-score': 0.8159964853563874, 'support': 516}
 
time = 2.29 secondes

Val loss 0.4012707322835922 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 3/40
time = 95.70 secondes

Train loss 0.3743392319390268 accuracy 0.8488371968269348 macro_avg {'precision': 0.8352264557872034, 'recall': 0.841067568226517, 'f1-score': 0.8379057591623036, 'support': 516} weighted_avg {'precision': 0.8505655589550395, 'recall': 0.8488372093023255, 'f1-score': 0.849489833191282, 'support': 516}
 
time = 2.32 secondes

Val loss 0.4602035582065582 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 4/40
time = 95.78 secondes

Train loss 0.33859480166751327 accuracy 0.8604651093482971 macro_avg {'precision': 0.8527021365731043, 'recall': 0.8421078295921851, 'f1-score': 0.8468211429042631, 'support': 516} weighted_avg {'precision': 0.859342757767364, 'recall': 0.8604651162790697, 'f1-score': 0.8594019495225913, 'support': 516}
 
time = 2.28 secondes

Val loss 0.6095099896192551 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 95.50 secondes

Train loss 0.17225323292906536 accuracy 0.9399224519729614 macro_avg {'precision': 0.9373396065012831, 'recall': 0.9321148188482355, 'f1-score': 0.9346159977436879, 'support': 516} weighted_avg {'precision': 0.9397525546912818, 'recall': 0.939922480620155, 'f1-score': 0.9397419880053092, 'support': 516}
 
time = 2.29 secondes

Val loss 0.6047244109213352 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 95.54 secondes

Train loss 0.1416061415591023 accuracy 0.9476743936538696 macro_avg {'precision': 0.943841642228739, 'recall': 0.942810006014011, 'f1-score': 0.9433213862908705, 'support': 516} weighted_avg {'precision': 0.94762118559943, 'recall': 0.9476744186046512, 'f1-score': 0.9476439778192401, 'support': 516}
 
time = 2.28 secondes

Val loss 1.0758813619613647 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 7/40
time = 95.69 secondes

Train loss 0.24907160627260577 accuracy 0.9496123790740967 macro_avg {'precision': 0.9423915648214714, 'recall': 0.9500999626156073, 'f1-score': 0.9459685863874345, 'support': 516} weighted_avg {'precision': 0.9505293349457662, 'recall': 0.9496124031007752, 'f1-score': 0.9498299443970939, 'support': 516}
 
time = 2.33 secondes

Val loss 1.2039525508880615 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 8/40
time = 95.69 secondes

Train loss 0.124722281012289 accuracy 0.9554263353347778 macro_avg {'precision': 0.956668439598431, 'recall': 0.946580953464558, 'f1-score': 0.9512517713745866, 'support': 516} weighted_avg {'precision': 0.9555660909276917, 'recall': 0.9554263565891473, 'f1-score': 0.9551775402518555, 'support': 516}
 
time = 2.31 secondes

Val loss 0.9990151524543762 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 9/40
time = 95.54 secondes

Train loss 0.2372714005336589 accuracy 0.9399224519729614 macro_avg {'precision': 0.9330632716049383, 'recall': 0.937885018610926, 'f1-score': 0.9353663020683916, 'support': 516} weighted_avg {'precision': 0.9404421176667624, 'recall': 0.939922480620155, 'f1-score': 0.9400887645089057, 'support': 516}
 
time = 2.26 secondes

Val loss 0.96970534324646 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 10/40
time = 95.58 secondes

Train loss 0.12673311930495512 accuracy 0.9593023061752319 macro_avg {'precision': 0.954617371649984, 'recall': 0.9576987468101361, 'f1-score': 0.9561180067629134, 'support': 516} weighted_avg {'precision': 0.9595090147254282, 'recall': 0.9593023255813954, 'f1-score': 0.9593710518868303, 'support': 516}
 
time = 2.33 secondes

Val loss 1.210192322731018 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 11/40
time = 96.02 secondes

Train loss 0.03446841064512476 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.39 secondes

Val loss 1.4306222349405289 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 12/40
time = 96.16 secondes

Train loss 0.10062360530983741 accuracy 0.9767441749572754 macro_avg {'precision': 0.9748386782179023, 'recall': 0.9748386782179023, 'f1-score': 0.9748386782179023, 'support': 516} weighted_avg {'precision': 0.9767441860465116, 'recall': 0.9767441860465116, 'f1-score': 0.9767441860465116, 'support': 516}
 
time = 2.29 secondes

Val loss 2.4953129291534424 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 13/40
time = 95.44 secondes

Train loss 0.19307244459085984 accuracy 0.961240291595459 macro_avg {'precision': 0.9612599983507875, 'recall': 0.9546023438388895, 'f1-score': 0.9577658459926663, 'support': 516} weighted_avg {'precision': 0.9612418442286832, 'recall': 0.9612403100775194, 'f1-score': 0.9610994534254307, 'support': 516}
 
time = 2.33 secondes

Val loss 1.283530741930008 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 14/40
time = 95.92 secondes

Train loss 0.08746723584067007 accuracy 0.9767441749572754 macro_avg {'precision': 0.9729037454691905, 'recall': 0.9771467581229785, 'f1-score': 0.9749526722003787, 'support': 516} weighted_avg {'precision': 0.9769734660809786, 'recall': 0.9767441860465116, 'f1-score': 0.9767961139840808, 'support': 516}
 
time = 2.30 secondes

Val loss 1.4817948043346405 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 15/40
time = 95.79 secondes

Train loss 0.059289228971024524 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 2.26 secondes

Val loss 1.381548434495926 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 16/40
time = 95.76 secondes

Train loss 0.15866045987477814 accuracy 0.9748061895370483 macro_avg {'precision': 0.9743648507071765, 'recall': 0.9710108414739204, 'f1-score': 0.9726461988900261, 'support': 516} weighted_avg {'precision': 0.9747883089486359, 'recall': 0.9748062015503876, 'f1-score': 0.9747615118401732, 'support': 516}
 
time = 2.34 secondes

Val loss 1.5982169806957245 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 95.47 secondes

Train loss 0.21647141193777011 accuracy 0.9573643207550049 macro_avg {'precision': 0.9499864742294288, 'recall': 0.9596411098288444, 'f1-score': 0.9543788580246912, 'support': 516} weighted_avg {'precision': 0.9585738274550816, 'recall': 0.9573643410852714, 'f1-score': 0.957590514044406, 'support': 516}
 
time = 2.30 secondes

Val loss 2.443080246448517 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 18/40
time = 95.51 secondes

Train loss 0.5588889509562057 accuracy 0.9108527302742004 macro_avg {'precision': 0.899443180926986, 'recall': 0.9139346260748014, 'f1-score': 0.905389030612245, 'support': 516} weighted_avg {'precision': 0.914727648659871, 'recall': 0.9108527131782945, 'f1-score': 0.9116458283894954, 'support': 516}
 
time = 2.30 secondes

Val loss 1.4202370792627335 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 19/40
time = 95.59 secondes

Train loss 0.3689985271211657 accuracy 0.9360464811325073 macro_avg {'precision': 0.9466938690102532, 'recall': 0.9163808656925052, 'f1-score': 0.9285639371221688, 'support': 516} weighted_avg {'precision': 0.9388192609462264, 'recall': 0.936046511627907, 'f1-score': 0.9349263657438144, 'support': 516}
 
time = 2.31 secondes

Val loss 1.5082087218761444 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 20/40
time = 95.75 secondes

Train loss 0.10505592618441865 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 2.32 secondes

Val loss 1.8348849713802338 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 21/40
time = 96.10 secondes

Train loss 0.09415379674222397 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 2.31 secondes

Val loss 1.25135837495327 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 22/40
time = 95.56 secondes

Train loss 0.18749890221608273 accuracy 0.961240291595459 macro_avg {'precision': 0.9534898467098901, 'recall': 0.9649887034117322, 'f1-score': 0.9586133880877139, 'support': 516} weighted_avg {'precision': 0.9628166755082236, 'recall': 0.9612403100775194, 'f1-score': 0.9614827951842706, 'support': 516}
 
time = 2.30 secondes

Val loss 1.3243838995695114 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 23/40
time = 95.44 secondes

Train loss 0.1785870201446497 accuracy 0.9593023061752319 macro_avg {'precision': 0.9498434074538052, 'recall': 0.9669310664304407, 'f1-score': 0.9568505178654625, 'support': 516} weighted_avg {'precision': 0.9627584687433994, 'recall': 0.9593023255813954, 'f1-score': 0.9596810601066208, 'support': 516}
 
time = 2.35 secondes

Val loss 1.4906807839870453 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 24/40
time = 96.29 secondes

Train loss 0.1213383174723607 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 2.30 secondes

Val loss 1.1453349515795708 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.888663967611336, 'f1-score': 0.8738916256157635, 'support': 64} weighted_avg {'precision': 0.892578125, 'recall': 0.875, 'f1-score': 0.8761083743842364, 'support': 64}
 
----------
Epoch 25/40
time = 95.70 secondes

Train loss 0.04359891957287663 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.28 secondes

Val loss 1.584856778383255 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 95.59 secondes

Train loss 0.0502232605905385 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.30 secondes

Val loss 1.4108153879642487 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 27/40
time = 95.71 secondes

Train loss 0.11314819947504227 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 2.33 secondes

Val loss 1.5030540823936462 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 28/40
time = 95.55 secondes

Train loss 0.007855981981044875 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.30 secondes

Val loss 1.7671788483858109 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 29/40
time = 95.48 secondes

Train loss 0.013232484645083208 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.36 secondes

Val loss 1.6029400825500488 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 30/40
time = 96.38 secondes

Train loss 0.029153939134795855 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.25 secondes

Val loss 1.5550691932439804 accuracy 0.828125 macro_avg {'precision': 0.8399014778325123, 'recall': 0.8491902834008097, 'f1-score': 0.8277465133349645, 'support': 64} weighted_avg {'precision': 0.8634544334975369, 'recall': 0.828125, 'f1-score': 0.8292604599951064, 'support': 64}
 
----------
Epoch 31/40
time = 95.69 secondes

Train loss 0.18521113308760864 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 2.30 secondes

Val loss 1.2273879200220108 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 32/40
time = 95.97 secondes

Train loss 0.03388288719879435 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 2.33 secondes

Val loss 1.6904181838035583 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 33/40
time = 95.84 secondes

Train loss 0.07650311529681803 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.33 secondes

Val loss 1.442181646823883 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 34/40
time = 95.82 secondes

Train loss 0.008669921423213302 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.29 secondes

Val loss 1.9768588840961456 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 35/40
time = 95.92 secondes

Train loss 0.041166322403803475 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 2.39 secondes

Val loss 1.9623083174228668 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 36/40
time = 95.79 secondes

Train loss 0.0002607633119403159 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.26 secondes

Val loss 1.5779370814561844 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 37/40
time = 95.69 secondes

Train loss 0.006322559271211503 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.29 secondes

Val loss 1.6484745740890503 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 38/40
time = 95.48 secondes

Train loss 5.127401902537906e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.26 secondes

Val loss 1.6884622871875763 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 39/40
time = 95.54 secondes

Train loss 6.34294950886573e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.84 secondes

Val loss 2.0221321880817413 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 40/40
time = 95.81 secondes

Train loss 7.463705007852916e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.24 secondes

Val loss 1.9694238603115082 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 24 macro_avg {'precision': 0.875, 'recall': 0.888663967611336, 'f1-score': 0.8738916256157635, 'support': 64} weighted_avg {'precision': 0.892578125, 'recall': 0.875, 'f1-score': 0.8761083743842364, 'support': 64}

average train time 95.7343442440033

average val time 2.3231769323349
 
time = 2.49 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------

Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 36.54 GiB already allocated; 740.62 MiB free; 38.77 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 38.18 GiB already allocated; 604.62 MiB free; 38.90 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_4
----------
Epoch 1/40
time = 745.27 secondes

Train loss 1.3620169442527148 accuracy 0.6241406798362732 macro_avg {'precision': 0.6219353346972651, 'recall': 0.6093775343137428, 'f1-score': 0.6038378794281871, 'support': 10182} weighted_avg {'precision': 0.6313274750649881, 'recall': 0.6241406403457082, 'f1-score': 0.6175725358091669, 'support': 10182}
 
time = 22.36 secondes

Val loss 0.7721365014432182 accuracy 0.7597173452377319 macro_avg {'precision': 0.7510064078283013, 'recall': 0.7575722002372418, 'f1-score': 0.7333221118737335, 'support': 1132} weighted_avg {'precision': 0.7658912605288779, 'recall': 0.7597173144876325, 'f1-score': 0.7376422287608863, 'support': 1132}
 
----------
Epoch 2/40
time = 766.24 secondes

Train loss 0.546149585969173 accuracy 0.8348065614700317 macro_avg {'precision': 0.8236073259763789, 'recall': 0.8245366376709649, 'f1-score': 0.8223070801175615, 'support': 10182} weighted_avg {'precision': 0.8310555458212395, 'recall': 0.8348065213121194, 'f1-score': 0.8316300753948395, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.6738081362465738 accuracy 0.814487636089325 macro_avg {'precision': 0.8165992188440303, 'recall': 0.8043235652313483, 'f1-score': 0.8017284224585145, 'support': 1132} weighted_avg {'precision': 0.8195720156833913, 'recall': 0.8144876325088339, 'f1-score': 0.809553568452201, 'support': 1132}
 
----------
Epoch 3/40
time = 768.31 secondes

Train loss 0.3193511044404804 accuracy 0.9082695245742798 macro_avg {'precision': 0.9038035449565139, 'recall': 0.9032763062642241, 'f1-score': 0.9033817246880691, 'support': 10182} weighted_avg {'precision': 0.9082510812578475, 'recall': 0.9082694951875859, 'f1-score': 0.908112436578834, 'support': 10182}
 
time = 22.62 secondes

Val loss 0.5849336762846985 accuracy 0.8454063534736633 macro_avg {'precision': 0.849900965163863, 'recall': 0.8460074205288585, 'f1-score': 0.8439324710790324, 'support': 1132} weighted_avg {'precision': 0.8542639253863423, 'recall': 0.8454063604240283, 'f1-score': 0.8457747090933558, 'support': 1132}
 
----------
Epoch 4/40
time = 773.58 secondes

Train loss 0.20227789867660573 accuracy 0.9434295892715454 macro_avg {'precision': 0.9405317590672155, 'recall': 0.9401481633333828, 'f1-score': 0.9402355111462699, 'support': 10182} weighted_avg {'precision': 0.943535975587809, 'recall': 0.943429581614614, 'f1-score': 0.9433797877924599, 'support': 10182}
 
time = 22.87 secondes

Val loss 0.7339574697781617 accuracy 0.8418728113174438 macro_avg {'precision': 0.84419152931348, 'recall': 0.8410633327348359, 'f1-score': 0.8388628420054788, 'support': 1132} weighted_avg {'precision': 0.8501978305965588, 'recall': 0.8418727915194346, 'f1-score': 0.8421960297837339, 'support': 1132}
 
----------
Epoch 5/40
time = 771.98 secondes

Train loss 0.1737769185960164 accuracy 0.9549204707145691 macro_avg {'precision': 0.9531487007597782, 'recall': 0.9528330497148285, 'f1-score': 0.952963187484175, 'support': 10182} weighted_avg {'precision': 0.9549531711986364, 'recall': 0.9549204478491455, 'f1-score': 0.9549092989161182, 'support': 10182}
 
time = 23.21 secondes

Val loss 0.9111240202393777 accuracy 0.8312720656394958 macro_avg {'precision': 0.8455761824246381, 'recall': 0.8375173263457919, 'f1-score': 0.8294228629011243, 'support': 1132} weighted_avg {'precision': 0.8537160674498004, 'recall': 0.8312720848056537, 'f1-score': 0.8300448546692971, 'support': 1132}
 
----------
Epoch 6/40
time = 773.24 secondes

Train loss 0.15160615080503345 accuracy 0.9617953300476074 macro_avg {'precision': 0.9610260638246407, 'recall': 0.9604506611626145, 'f1-score': 0.9607005253697132, 'support': 10182} weighted_avg {'precision': 0.9618160264973088, 'recall': 0.9617953250834806, 'f1-score': 0.961770041507121, 'support': 10182}
 
time = 22.85 secondes

Val loss 0.998122779804964 accuracy 0.8445229530334473 macro_avg {'precision': 0.86176540409393, 'recall': 0.8371493208463822, 'f1-score': 0.8373026897444229, 'support': 1132} weighted_avg {'precision': 0.8565802864566736, 'recall': 0.8445229681978799, 'f1-score': 0.8406369555904527, 'support': 1132}
 
----------
Epoch 7/40
time = 773.70 secondes

Train loss 0.13249409085351993 accuracy 0.9710273146629333 macro_avg {'precision': 0.9704108841346606, 'recall': 0.9700146838761171, 'f1-score': 0.9701941170730904, 'support': 10182} weighted_avg {'precision': 0.9710566094241091, 'recall': 0.9710273030838735, 'f1-score': 0.9710243416756901, 'support': 10182}
 
time = 23.08 secondes

Val loss 0.8362880445931526 accuracy 0.8639575839042664 macro_avg {'precision': 0.8681998035408321, 'recall': 0.8681591102441922, 'f1-score': 0.8645186873143812, 'support': 1132} weighted_avg {'precision': 0.8718214855734102, 'recall': 0.8639575971731449, 'f1-score': 0.8641791456507038, 'support': 1132}
 
----------
Epoch 8/40
time = 758.75 secondes

Train loss 0.13370663273675307 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684523782408114, 'recall': 0.9677270730485317, 'f1-score': 0.9680024685834953, 'support': 10182} weighted_avg {'precision': 0.9696792400102836, 'recall': 0.9696523276370065, 'f1-score': 0.9695957000383791, 'support': 10182}
 
time = 20.58 secondes

Val loss 0.8870222394192316 accuracy 0.8657243847846985 macro_avg {'precision': 0.8743692474806753, 'recall': 0.8684181330159395, 'f1-score': 0.8667837124379828, 'support': 1132} weighted_avg {'precision': 0.8780266374755173, 'recall': 0.8657243816254417, 'f1-score': 0.8671335891632083, 'support': 1132}
 
----------
Epoch 9/40
time = 698.45 secondes

Train loss 0.12476795982899147 accuracy 0.9742683172225952 macro_avg {'precision': 0.9734524805354475, 'recall': 0.9730562821113491, 'f1-score': 0.9732113025726197, 'support': 10182} weighted_avg {'precision': 0.9743408213655522, 'recall': 0.9742683166372029, 'f1-score': 0.974264383294331, 'support': 10182}
 
time = 20.01 secondes

Val loss 1.0709312920914438 accuracy 0.851590096950531 macro_avg {'precision': 0.8618469341045939, 'recall': 0.8506343820580625, 'f1-score': 0.8488575863227006, 'support': 1132} weighted_avg {'precision': 0.8606690731130928, 'recall': 0.8515901060070671, 'f1-score': 0.8488655818227334, 'support': 1132}
 
----------
Epoch 10/40
time = 699.35 secondes

Train loss 0.10657032142415952 accuracy 0.9776075482368469 macro_avg {'precision': 0.9769480650107714, 'recall': 0.9770833438378135, 'f1-score': 0.9769876055665282, 'support': 10182} weighted_avg {'precision': 0.9777417859206715, 'recall': 0.9776075427224514, 'f1-score': 0.977648333241033, 'support': 10182}
 
time = 20.72 secondes

Val loss 0.8671397315576004 accuracy 0.8772084712982178 macro_avg {'precision': 0.8790587520681088, 'recall': 0.87829477409379, 'f1-score': 0.8767878389616722, 'support': 1132} weighted_avg {'precision': 0.8815916966721384, 'recall': 0.877208480565371, 'f1-score': 0.8776737900561747, 'support': 1132}
 
----------
Epoch 11/40
time = 703.64 secondes

Train loss 0.10393895805039219 accuracy 0.9787861108779907 macro_avg {'precision': 0.9778726796861175, 'recall': 0.9780146405470868, 'f1-score': 0.9779145709832899, 'support': 10182} weighted_avg {'precision': 0.9788332416846702, 'recall': 0.9787860931054803, 'f1-score': 0.9787801712601663, 'support': 10182}
 
time = 20.65 secondes

Val loss 0.9710595562056357 accuracy 0.8692579865455627 macro_avg {'precision': 0.8718157550565303, 'recall': 0.8710751745676049, 'f1-score': 0.8684620167480812, 'support': 1132} weighted_avg {'precision': 0.8777388931596417, 'recall': 0.8692579505300353, 'f1-score': 0.8704451067827041, 'support': 1132}
 
----------
Epoch 12/40
time = 689.91 secondes

Train loss 0.10528037115589575 accuracy 0.9807503819465637 macro_avg {'precision': 0.9804643394641822, 'recall': 0.9802863378013882, 'f1-score': 0.9803451952507197, 'support': 10182} weighted_avg {'precision': 0.9808097000871195, 'recall': 0.9807503437438617, 'f1-score': 0.980748975135919, 'support': 10182}
 
time = 20.74 secondes

Val loss 1.2224667010100028 accuracy 0.8312720656394958 macro_avg {'precision': 0.864524379948219, 'recall': 0.8297763668257702, 'f1-score': 0.8267850206468976, 'support': 1132} weighted_avg {'precision': 0.8595217923061619, 'recall': 0.8312720848056537, 'f1-score': 0.8265133905669328, 'support': 1132}
 
----------
Epoch 13/40
time = 700.54 secondes

Train loss 0.09644961703639607 accuracy 0.9803575277328491 macro_avg {'precision': 0.9800837171113825, 'recall': 0.9802778822976173, 'f1-score': 0.980135990312105, 'support': 10182} weighted_avg {'precision': 0.9804062785539409, 'recall': 0.9803574936161854, 'f1-score': 0.9803358166878084, 'support': 10182}
 
time = 21.35 secondes

Val loss 0.9216421468471977 accuracy 0.8780918717384338 macro_avg {'precision': 0.8812960716770168, 'recall': 0.8822794153471014, 'f1-score': 0.8793194896482628, 'support': 1132} weighted_avg {'precision': 0.8859058558683396, 'recall': 0.8780918727915195, 'f1-score': 0.8794953527575989, 'support': 1132}
 
----------
Epoch 14/40
time = 699.16 secondes

Train loss 0.09607161275642775 accuracy 0.9819289445877075 macro_avg {'precision': 0.9822522626749933, 'recall': 0.9820770697621208, 'f1-score': 0.982131037783696, 'support': 10182} weighted_avg {'precision': 0.9820279917307982, 'recall': 0.9819288941268906, 'f1-score': 0.9819440098992143, 'support': 10182}
 
time = 20.95 secondes

Val loss 0.9335599796425118 accuracy 0.8745583295822144 macro_avg {'precision': 0.8852245172900725, 'recall': 0.877608305894492, 'f1-score': 0.8777894613070318, 'support': 1132} weighted_avg {'precision': 0.8844214411749265, 'recall': 0.8745583038869258, 'f1-score': 0.8757253421009883, 'support': 1132}
 
----------
Epoch 15/40
time = 682.30 secondes

Train loss 0.08353636490348401 accuracy 0.9842860102653503 macro_avg {'precision': 0.9835806520904248, 'recall': 0.9834871336192673, 'f1-score': 0.983525805895978, 'support': 10182} weighted_avg {'precision': 0.9843032987367522, 'recall': 0.9842859948929483, 'f1-score': 0.984286306191619, 'support': 10182}
 
time = 20.20 secondes

Val loss 1.0414238832224878 accuracy 0.8657243847846985 macro_avg {'precision': 0.8778192106122139, 'recall': 0.8683858423141085, 'f1-score': 0.8692654664556635, 'support': 1132} weighted_avg {'precision': 0.876649614312357, 'recall': 0.8657243816254417, 'f1-score': 0.8673841186677678, 'support': 1132}
 
----------
Epoch 16/40
time = 705.24 secondes

Train loss 0.07256669544100303 accuracy 0.9866431355476379 macro_avg {'precision': 0.9864878620742441, 'recall': 0.9865670335622065, 'f1-score': 0.9865045910052166, 'support': 10182} weighted_avg {'precision': 0.9866826645012108, 'recall': 0.9866430956590061, 'f1-score': 0.9866393863813295, 'support': 10182}
 
time = 21.48 secondes

Val loss 1.0761123847791885 accuracy 0.8666077852249146 macro_avg {'precision': 0.8857127917157939, 'recall': 0.87050924793125, 'f1-score': 0.8694601701336022, 'support': 1132} weighted_avg {'precision': 0.8877783722129482, 'recall': 0.8666077738515902, 'f1-score': 0.8681293463513361, 'support': 1132}
 
----------
Epoch 17/40
time = 703.86 secondes

Train loss 0.08226310823394078 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860862812453279, 'recall': 0.9859821072805651, 'f1-score': 0.9860092044452424, 'support': 10182} weighted_avg {'precision': 0.9863694605782292, 'recall': 0.9863484580632489, 'f1-score': 0.9863330161665136, 'support': 10182}
 
time = 21.00 secondes

Val loss 0.9512951463068635 accuracy 0.880742073059082 macro_avg {'precision': 0.8892570711515984, 'recall': 0.8838023447508127, 'f1-score': 0.8837065412596324, 'support': 1132} weighted_avg {'precision': 0.8885338818820876, 'recall': 0.8807420494699647, 'f1-score': 0.8815531069712201, 'support': 1132}
 
----------
Epoch 18/40
time = 706.69 secondes

Train loss 0.06583956096286986 accuracy 0.9883127212524414 macro_avg {'precision': 0.9879759745271921, 'recall': 0.9880367845986097, 'f1-score': 0.9879990604833886, 'support': 10182} weighted_avg {'precision': 0.9883356887909751, 'recall': 0.9883127087016303, 'f1-score': 0.9883171167043273, 'support': 10182}
 
time = 21.26 secondes

Val loss 0.9716631421289722 accuracy 0.8851590156555176 macro_avg {'precision': 0.8907503671755105, 'recall': 0.8885455190564968, 'f1-score': 0.8876144829445867, 'support': 1132} weighted_avg {'precision': 0.8920035777982743, 'recall': 0.8851590106007067, 'f1-score': 0.8865040684979207, 'support': 1132}
 
----------
Epoch 19/40
time = 704.69 secondes

Train loss 0.07458173049252617 accuracy 0.9871341586112976 macro_avg {'precision': 0.9866151935998693, 'recall': 0.9870062654443321, 'f1-score': 0.9867909347428755, 'support': 10182} weighted_avg {'precision': 0.9871751911790048, 'recall': 0.9871341583186014, 'f1-score': 0.9871380597195486, 'support': 10182}
 
time = 21.43 secondes

Val loss 1.0510698059446901 accuracy 0.8736749291419983 macro_avg {'precision': 0.8770775055974511, 'recall': 0.8788532085496559, 'f1-score': 0.8745193566255486, 'support': 1132} weighted_avg {'precision': 0.8812584546811169, 'recall': 0.8736749116607774, 'f1-score': 0.8739535981005717, 'support': 1132}
 
----------
Epoch 20/40
time = 712.92 secondes

Train loss 0.05827744971126093 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885058858070346, 'recall': 0.9885540060536595, 'f1-score': 0.9885183032362466, 'support': 10182} weighted_avg {'precision': 0.9888337480645996, 'recall': 0.9888037713612257, 'f1-score': 0.9888071670813554, 'support': 10182}
 
time = 22.73 secondes

Val loss 0.9113514228915782 accuracy 0.8754417300224304 macro_avg {'precision': 0.8783642542057297, 'recall': 0.8811695663990241, 'f1-score': 0.8768913572358479, 'support': 1132} weighted_avg {'precision': 0.88027049403999, 'recall': 0.8754416961130742, 'f1-score': 0.874989055526413, 'support': 1132}
 
----------
Epoch 21/40
time = 713.83 secondes

Train loss 0.05414249188574364 accuracy 0.9899823665618896 macro_avg {'precision': 0.9896811373235022, 'recall': 0.9896857934266231, 'f1-score': 0.9896766156350276, 'support': 10182} weighted_avg {'precision': 0.9899830158296052, 'recall': 0.9899823217442546, 'f1-score': 0.989975721491508, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.9406612613523284 accuracy 0.8833922147750854 macro_avg {'precision': 0.8864774228495398, 'recall': 0.8868482932133638, 'f1-score': 0.8845347749620582, 'support': 1132} weighted_avg {'precision': 0.8880506029243672, 'recall': 0.8833922261484098, 'f1-score': 0.8834232818629714, 'support': 1132}
 
----------
Epoch 22/40
time = 709.07 secondes

Train loss 0.06321538336166756 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885349925498985, 'recall': 0.988619905777308, 'f1-score': 0.9885633007210728, 'support': 10182} weighted_avg {'precision': 0.9888276773514048, 'recall': 0.9888037713612257, 'f1-score': 0.9888017059262472, 'support': 10182}
 
time = 22.23 secondes

Val loss 0.9494373546134431 accuracy 0.8904593586921692 macro_avg {'precision': 0.8964239749844956, 'recall': 0.8922292994369618, 'f1-score': 0.891969584475252, 'support': 1132} weighted_avg {'precision': 0.8951258398891432, 'recall': 0.8904593639575972, 'f1-score': 0.8904251473573744, 'support': 1132}
 
----------
Epoch 23/40
time = 691.88 secondes

Train loss 0.04857952967429116 accuracy 0.9911609292030334 macro_avg {'precision': 0.9907975937648537, 'recall': 0.990839082682229, 'f1-score': 0.990810605221346, 'support': 10182} weighted_avg {'precision': 0.9911795119385237, 'recall': 0.9911608721272834, 'f1-score': 0.9911627469753196, 'support': 10182}
 
time = 20.71 secondes

Val loss 0.9655102952009413 accuracy 0.8833922147750854 macro_avg {'precision': 0.8886718481419615, 'recall': 0.8870599470472408, 'f1-score': 0.8857946870419733, 'support': 1132} weighted_avg {'precision': 0.8903540304441377, 'recall': 0.8833922261484098, 'f1-score': 0.8847178543076476, 'support': 1132}
 
----------
Epoch 24/40
time = 699.92 secondes

Train loss 0.0450729193765154 accuracy 0.9923394322395325 macro_avg {'precision': 0.9924901388510726, 'recall': 0.9924470850931696, 'f1-score': 0.9924512443871001, 'support': 10182} weighted_avg {'precision': 0.9923676629113869, 'recall': 0.9923394225103123, 'f1-score': 0.9923355509710997, 'support': 10182}
 
time = 19.41 secondes

Val loss 0.836745535082128 accuracy 0.880742073059082 macro_avg {'precision': 0.8880632550218042, 'recall': 0.8885674242227573, 'f1-score': 0.8836372572968904, 'support': 1132} weighted_avg {'precision': 0.8890579400123074, 'recall': 0.8807420494699647, 'f1-score': 0.8798031601983608, 'support': 1132}
 
----------
Epoch 25/40
time = 696.96 secondes

Train loss 0.041573701396991736 accuracy 0.9928305149078369 macro_avg {'precision': 0.9926707685663384, 'recall': 0.9927095162963937, 'f1-score': 0.9926770180932033, 'support': 10182} weighted_avg {'precision': 0.9928525212902264, 'recall': 0.9928304851699077, 'f1-score': 0.9928280889061362, 'support': 10182}
 
time = 20.79 secondes

Val loss 0.9172713470946126 accuracy 0.8904593586921692 macro_avg {'precision': 0.8977775497432579, 'recall': 0.8930249060989794, 'f1-score': 0.8929279155286448, 'support': 1132} weighted_avg {'precision': 0.8981227098162188, 'recall': 0.8904593639575972, 'f1-score': 0.8919707046493922, 'support': 1132}
 
----------
Epoch 26/40
time = 695.29 secondes

Train loss 0.051566629921358166 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918855819986678, 'recall': 0.9919605736432617, 'f1-score': 0.9919130991547908, 'support': 10182} weighted_avg {'precision': 0.9921668416481433, 'recall': 0.9921429974464742, 'f1-score': 0.9921450926916305, 'support': 10182}
 
time = 20.91 secondes

Val loss 0.8739972566411228 accuracy 0.898409903049469 macro_avg {'precision': 0.9012356060438425, 'recall': 0.9031105712105127, 'f1-score': 0.8998764371975436, 'support': 1132} weighted_avg {'precision': 0.9034981314415198, 'recall': 0.8984098939929329, 'f1-score': 0.898513288727122, 'support': 1132}
 
----------
Epoch 27/40
time = 701.29 secondes

Train loss 0.03362585368210504 accuracy 0.993812620639801 macro_avg {'precision': 0.9936813701782633, 'recall': 0.993651087279944, 'f1-score': 0.9936605836350786, 'support': 10182} weighted_avg {'precision': 0.9938260102210492, 'recall': 0.9938126104890984, 'f1-score': 0.993813584954164, 'support': 10182}
 
time = 21.78 secondes

Val loss 0.9841584200487336 accuracy 0.8869258165359497 macro_avg {'precision': 0.8928491765519961, 'recall': 0.8895534368326056, 'f1-score': 0.8884768804384828, 'support': 1132} weighted_avg {'precision': 0.8940190248694975, 'recall': 0.8869257950530035, 'f1-score': 0.8876188808040355, 'support': 1132}
 
----------
Epoch 28/40
time = 712.54 secondes

Train loss 0.03560435815925131 accuracy 0.9941073060035706 macro_avg {'precision': 0.993901640495395, 'recall': 0.9940760487261853, 'f1-score': 0.9939835844048668, 'support': 10182} weighted_avg {'precision': 0.9941153024384927, 'recall': 0.9941072480848556, 'f1-score': 0.9941063078036233, 'support': 10182}
 
time = 22.65 secondes

Val loss 0.907973636499943 accuracy 0.8922261595726013 macro_avg {'precision': 0.8986013058814274, 'recall': 0.8947767306738778, 'f1-score': 0.8944735758358444, 'support': 1132} weighted_avg {'precision': 0.8970462600507981, 'recall': 0.892226148409894, 'f1-score': 0.8923185442350859, 'support': 1132}
 
----------
Epoch 29/40
time = 711.03 secondes

Train loss 0.0322029616904022 accuracy 0.9944019317626953 macro_avg {'precision': 0.9942696711601255, 'recall': 0.9943981985336577, 'f1-score': 0.9943275607647631, 'support': 10182} weighted_avg {'precision': 0.9944133378799135, 'recall': 0.9944018856806128, 'f1-score': 0.9944018538096763, 'support': 10182}
 
time = 22.86 secondes

Val loss 1.0846933569888457 accuracy 0.8736749291419983 macro_avg {'precision': 0.9032072288139238, 'recall': 0.8766037779772992, 'f1-score': 0.8835065943098448, 'support': 1132} weighted_avg {'precision': 0.8997056982124427, 'recall': 0.8736749116607774, 'f1-score': 0.8796482107509905, 'support': 1132}
 
----------
Epoch 30/40
time = 714.34 secondes

Train loss 0.04390207801046144 accuracy 0.9927322864532471 macro_avg {'precision': 0.9928927709334676, 'recall': 0.9927686700216203, 'f1-score': 0.9928191125276473, 'support': 10182} weighted_avg {'precision': 0.992759222675427, 'recall': 0.9927322726379886, 'f1-score': 0.9927339674971646, 'support': 10182}
 
time = 23.52 secondes

Val loss 0.97769883338338 accuracy 0.8895759582519531 macro_avg {'precision': 0.8999506151752122, 'recall': 0.8932693509929666, 'f1-score': 0.8933086365215439, 'support': 1132} weighted_avg {'precision': 0.899727154883964, 'recall': 0.8895759717314488, 'f1-score': 0.8911901160520143, 'support': 1132}
 
----------
Epoch 31/40
time = 713.65 secondes

Train loss 0.03768539344519998 accuracy 0.9939108490943909 macro_avg {'precision': 0.9940811145014619, 'recall': 0.9940208663248304, 'f1-score': 0.9940416375339247, 'support': 10182} weighted_avg {'precision': 0.9939334031716122, 'recall': 0.9939108230210175, 'f1-score': 0.9939124582771408, 'support': 10182}
 
time = 23.38 secondes

Val loss 1.0496889290219078 accuracy 0.8860424160957336 macro_avg {'precision': 0.8906881951325689, 'recall': 0.8883084314455004, 'f1-score': 0.8868118834854863, 'support': 1132} weighted_avg {'precision': 0.8919113180176217, 'recall': 0.8860424028268551, 'f1-score': 0.8862005230438254, 'support': 1132}
 
----------
Epoch 32/40
time = 653.77 secondes

Train loss 0.02706357283376471 accuracy 0.9950894117355347 macro_avg {'precision': 0.9952409133951537, 'recall': 0.9951504626502177, 'f1-score': 0.9951884939765808, 'support': 10182} weighted_avg {'precision': 0.9951138158768448, 'recall': 0.9950893734040464, 'f1-score': 0.995094267219817, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9302681963955353 accuracy 0.8931095600128174 macro_avg {'precision': 0.8928497230841828, 'recall': 0.8957077229084442, 'f1-score': 0.8927317692573087, 'support': 1132} weighted_avg {'precision': 0.8962022591747876, 'recall': 0.8931095406360424, 'f1-score': 0.893076508444322, 'support': 1132}
 
----------
Epoch 33/40
time = 683.45 secondes

Train loss 0.025361298259636407 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959508938265327, 'recall': 0.9959884946603067, 'f1-score': 0.9959655254919765, 'support': 10182} weighted_avg {'precision': 0.9960741844524214, 'recall': 0.9960714987232371, 'f1-score': 0.9960685545101935, 'support': 10182}
 
time = 18.55 secondes

Val loss 1.0081298280417965 accuracy 0.8913427591323853 macro_avg {'precision': 0.9023920959352804, 'recall': 0.8917292988200985, 'f1-score': 0.894601658931505, 'support': 1132} weighted_avg {'precision': 0.9008028136990566, 'recall': 0.8913427561837456, 'f1-score': 0.8934007229770258, 'support': 1132}
 
----------
Epoch 34/40
time = 678.98 secondes

Train loss 0.025458554901564314 accuracy 0.9963661432266235 macro_avg {'precision': 0.9964063705808023, 'recall': 0.9962222254469509, 'f1-score': 0.9963042095751732, 'support': 10182} weighted_avg {'precision': 0.9963930880506273, 'recall': 0.9963661363189943, 'f1-score': 0.9963695133467236, 'support': 10182}
 
time = 22.45 secondes

Val loss 0.9037004050345863 accuracy 0.9010601043701172 macro_avg {'precision': 0.9040137393888521, 'recall': 0.904111122935673, 'f1-score': 0.9021453306483747, 'support': 1132} weighted_avg {'precision': 0.9062686449108778, 'recall': 0.901060070671378, 'f1-score': 0.9015265011929081, 'support': 1132}
 
----------
Epoch 35/40
time = 682.30 secondes

Train loss 0.019751426164674023 accuracy 0.9969554543495178 macro_avg {'precision': 0.9970698626179555, 'recall': 0.997047539246241, 'f1-score': 0.9970550599423305, 'support': 10182} weighted_avg {'precision': 0.9969624559255742, 'recall': 0.9969554115105087, 'f1-score': 0.996955171732931, 'support': 10182}
 
time = 19.71 secondes

Val loss 0.9164097473412894 accuracy 0.898409903049469 macro_avg {'precision': 0.9033335063455921, 'recall': 0.9002338099032864, 'f1-score': 0.8995990886469393, 'support': 1132} weighted_avg {'precision': 0.9055019949002336, 'recall': 0.8984098939929329, 'f1-score': 0.8996726968246683, 'support': 1132}
 
----------
Epoch 36/40
time = 651.33 secondes

Train loss 0.015566366553085263 accuracy 0.9974464774131775 macro_avg {'precision': 0.9974816972709475, 'recall': 0.9975090592363942, 'f1-score': 0.9974938102139564, 'support': 10182} weighted_avg {'precision': 0.9974522002547943, 'recall': 0.9974464741701041, 'f1-score': 0.9974477393460691, 'support': 10182}
 
time = 16.49 secondes

Val loss 0.8430173347981214 accuracy 0.9045936465263367 macro_avg {'precision': 0.9088606239398981, 'recall': 0.9067041708807878, 'f1-score': 0.9060410874843683, 'support': 1132} weighted_avg {'precision': 0.9103726613330795, 'recall': 0.9045936395759717, 'f1-score': 0.9056116676543543, 'support': 1132}
 
----------
Epoch 37/40
time = 630.80 secondes

Train loss 0.008411392220468727 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981792721550404, 'recall': 0.9981675830676011, 'f1-score': 0.9981718137996921, 'support': 10182} weighted_avg {'precision': 0.9981370987829821, 'recall': 0.9981339618935376, 'f1-score': 0.9981338602150323, 'support': 10182}
 
time = 17.78 secondes

Val loss 0.8666398737408548 accuracy 0.9072438478469849 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}
 
----------
Epoch 38/40
time = 657.08 secondes

Train loss 0.00363665757710664 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991479970546828, 'recall': 0.9991442419023459, 'f1-score': 0.999145760441634, 'support': 10182} weighted_avg {'precision': 0.999116631275601, 'recall': 0.9991160872127284, 'f1-score': 0.9991159874346697, 'support': 10182}
 
time = 20.75 secondes

Val loss 0.9295898494970637 accuracy 0.9028268456459045 macro_avg {'precision': 0.9060399377803906, 'recall': 0.9056944083481362, 'f1-score': 0.9044988995544063, 'support': 1132} weighted_avg {'precision': 0.9065984939144717, 'recall': 0.9028268551236749, 'f1-score': 0.9032727859370949, 'support': 1132}
 
----------
Epoch 39/40
time = 735.68 secondes

Train loss 0.0073776574524289365 accuracy 0.998821496963501 macro_avg {'precision': 0.9988446447385501, 'recall': 0.9988559297558119, 'f1-score': 0.9988491227300283, 'support': 10182} weighted_avg {'precision': 0.9988234807892794, 'recall': 0.9988214496169712, 'f1-score': 0.9988212604229645, 'support': 10182}
 
time = 20.87 secondes

Val loss 0.9766664895803739 accuracy 0.8992933034896851 macro_avg {'precision': 0.9031340386036965, 'recall': 0.9028152435072675, 'f1-score': 0.901175336518987, 'support': 1132} weighted_avg {'precision': 0.9035455724944119, 'recall': 0.8992932862190812, 'f1-score': 0.8994590099560085, 'support': 1132}
 
----------
Epoch 40/40
time = 733.80 secondes

Train loss 0.0013381021140298549 accuracy 0.9996072053909302 macro_avg {'precision': 0.999619535206102, 'recall': 0.9996171073534079, 'f1-score': 0.9996180539138934, 'support': 10182} weighted_avg {'precision': 0.9996077034874572, 'recall': 0.9996071498723237, 'f1-score': 0.9996071486778729, 'support': 10182}
 
time = 20.86 secondes

Val loss 0.9683842703135512 accuracy 0.9001767039299011 macro_avg {'precision': 0.9049967233911268, 'recall': 0.9031661481628822, 'f1-score': 0.9025115850836439, 'support': 1132} weighted_avg {'precision': 0.9047317864972204, 'recall': 0.9001766784452296, 'f1-score': 0.9007451703857408, 'support': 1132}
 
----------
best_accuracy 0.9072438478469849 best_epoch 37 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}

average train time 710.1203987717629

average val time 21.27267496585846
 
time = 136.86 secondes

test_accuracy 0.8296601176261902 macro_avg {'precision': 0.8261694392580499, 'recall': 0.8224345462904866, 'f1-score': 0.8221196564902696, 'support': 7532} weighted_avg {'precision': 0.8336363981546475, 'recall': 0.829660116834838, 'f1-score': 0.8295233448050705, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 488.17 secondes

Train loss 1.372230394902746 accuracy 0.6279709339141846 macro_avg {'precision': 0.6134986424362526, 'recall': 0.6129635552418231, 'f1-score': 0.6060368639532894, 'support': 10182} weighted_avg {'precision': 0.6262844028878005, 'recall': 0.627970929090552, 'f1-score': 0.6205845935912996, 'support': 10182}
 
time = 13.61 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.7827829303036273 accuracy 0.7588339447975159 macro_avg {'precision': 0.7414010329079515, 'recall': 0.7519130459253796, 'f1-score': 0.739521506874756, 'support': 1132} weighted_avg {'precision': 0.7486685046889161, 'recall': 0.758833922261484, 'f1-score': 0.7457319008112446, 'support': 1132}
 
----------
Epoch 2/40
time = 489.15 secondes

Train loss 0.5661003756420204 accuracy 0.827440619468689 macro_avg {'precision': 0.8147678466302217, 'recall': 0.8158370966826813, 'f1-score': 0.8124413299970389, 'support': 10182} weighted_avg {'precision': 0.8230306057456931, 'recall': 0.827440581418189, 'f1-score': 0.8231434523553137, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.6228134159890699 accuracy 0.8127208352088928 macro_avg {'precision': 0.8184673457899517, 'recall': 0.809688721738919, 'f1-score': 0.8083539561335371, 'support': 1132} weighted_avg {'precision': 0.8247300743455266, 'recall': 0.8127208480565371, 'f1-score': 0.8126672420729907, 'support': 1132}
 
----------
Epoch 3/40
time = 491.28 secondes

Train loss 0.33805252711348577 accuracy 0.9015910625457764 macro_avg {'precision': 0.8957571854167836, 'recall': 0.8953094824603985, 'f1-score': 0.895339588984726, 'support': 10182} weighted_avg {'precision': 0.9010649766918674, 'recall': 0.901591043017089, 'f1-score': 0.9011625070151672, 'support': 10182}
 
time = 17.79 secondes

Val loss 0.5765100382006084 accuracy 0.843639612197876 macro_avg {'precision': 0.8421845395505955, 'recall': 0.8433724466720106, 'f1-score': 0.8400549172690479, 'support': 1132} weighted_avg {'precision': 0.8484319877702833, 'recall': 0.8436395759717314, 'f1-score': 0.8432237679969962, 'support': 1132}
 
----------
Epoch 4/40
time = 491.14 secondes

Train loss 0.2288811775070602 accuracy 0.9349833130836487 macro_avg {'precision': 0.9312153196858393, 'recall': 0.9310185014458814, 'f1-score': 0.9310589110266136, 'support': 10182} weighted_avg {'precision': 0.9350689782123511, 'recall': 0.9349833038695737, 'f1-score': 0.9349687755698205, 'support': 10182}
 
time = 17.83 secondes

Val loss 0.5590408811227642 accuracy 0.880742073059082 macro_avg {'precision': 0.8845080012108, 'recall': 0.882472471066747, 'f1-score': 0.881267876937239, 'support': 1132} weighted_avg {'precision': 0.886225079068045, 'recall': 0.8807420494699647, 'f1-score': 0.8810748498825536, 'support': 1132}
 
----------
Epoch 5/40
time = 490.57 secondes

Train loss 0.1857722676421254 accuracy 0.9504026770591736 macro_avg {'precision': 0.9480834602951884, 'recall': 0.9485453763437274, 'f1-score': 0.9482459793105406, 'support': 10182} weighted_avg {'precision': 0.950653561700645, 'recall': 0.9504026713808682, 'f1-score': 0.9504711492450918, 'support': 10182}
 
time = 15.60 secondes

Val loss 0.7408904056163164 accuracy 0.8551236987113953 macro_avg {'precision': 0.8611180769010952, 'recall': 0.854606225684463, 'f1-score': 0.8522397877748296, 'support': 1132} weighted_avg {'precision': 0.8628258380080642, 'recall': 0.8551236749116607, 'f1-score': 0.8533244085846735, 'support': 1132}
 
----------
Epoch 6/40
time = 490.37 secondes

Train loss 0.15462405650527034 accuracy 0.9615989327430725 macro_avg {'precision': 0.9598932908325567, 'recall': 0.9599465519921091, 'f1-score': 0.9598828051434406, 'support': 10182} weighted_avg {'precision': 0.9616245166317874, 'recall': 0.9615989000196425, 'f1-score': 0.9615741195984013, 'support': 10182}
 
time = 13.76 secondes

Val loss 0.7150365061341444 accuracy 0.8754417300224304 macro_avg {'precision': 0.878739346260199, 'recall': 0.8760024770493183, 'f1-score': 0.8734891524807982, 'support': 1132} weighted_avg {'precision': 0.8820861260425824, 'recall': 0.8754416961130742, 'f1-score': 0.8752574340459215, 'support': 1132}
 
----------
Epoch 7/40
time = 494.37 secondes

Train loss 0.14585145360540183 accuracy 0.9639560580253601 macro_avg {'precision': 0.9623347317696279, 'recall': 0.9622403292495353, 'f1-score': 0.9622596178820302, 'support': 10182} weighted_avg {'precision': 0.9640556077331855, 'recall': 0.9639560007857002, 'f1-score': 0.9639770889392808, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.8331980400269484 accuracy 0.8613074421882629 macro_avg {'precision': 0.868494389634822, 'recall': 0.8573161469789887, 'f1-score': 0.8581150544115875, 'support': 1132} weighted_avg {'precision': 0.8682268049920878, 'recall': 0.8613074204946997, 'f1-score': 0.859760914451488, 'support': 1132}
 
----------
Epoch 8/40
time = 487.60 secondes

Train loss 0.1186752834756094 accuracy 0.9718130230903625 macro_avg {'precision': 0.9713017162299213, 'recall': 0.9707824655697375, 'f1-score': 0.9710097538676095, 'support': 10182} weighted_avg {'precision': 0.9718727633802077, 'recall': 0.971813003339226, 'f1-score': 0.9718136489595701, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.8462979193300527 accuracy 0.8630741834640503 macro_avg {'precision': 0.8725732539327089, 'recall': 0.8673504791744057, 'f1-score': 0.8663530343110819, 'support': 1132} weighted_avg {'precision': 0.872618110774337, 'recall': 0.8630742049469965, 'f1-score': 0.8640104617219612, 'support': 1132}
 
----------
Epoch 9/40
time = 488.58 secondes

Train loss 0.11825049903272655 accuracy 0.9743665456771851 macro_avg {'precision': 0.9740086854920506, 'recall': 0.974112404271855, 'f1-score': 0.9740159629028021, 'support': 10182} weighted_avg {'precision': 0.974465338982123, 'recall': 0.974366529169122, 'f1-score': 0.9743709731066372, 'support': 10182}
 
time = 16.43 secondes

Val loss 0.9256451609122246 accuracy 0.8639575839042664 macro_avg {'precision': 0.8824459459285106, 'recall': 0.8625915616704909, 'f1-score': 0.8619694083914471, 'support': 1132} weighted_avg {'precision': 0.8806347128863042, 'recall': 0.8639575971731449, 'f1-score': 0.8620541476430885, 'support': 1132}
 
----------
Epoch 10/40
time = 486.19 secondes

Train loss 0.11346419836974556 accuracy 0.9750540256500244 macro_avg {'precision': 0.97450725055481, 'recall': 0.9743253265364838, 'f1-score': 0.9743980761514989, 'support': 10182} weighted_avg {'precision': 0.9750587087134146, 'recall': 0.9750540168925554, 'f1-score': 0.9750386996645554, 'support': 10182}
 
time = 16.46 secondes

Val loss 0.8181793919307816 accuracy 0.8816254734992981 macro_avg {'precision': 0.8870936772739799, 'recall': 0.8787759075554369, 'f1-score': 0.8796876771208831, 'support': 1132} weighted_avg {'precision': 0.8868924462024713, 'recall': 0.8816254416961131, 'f1-score': 0.8812846585930596, 'support': 1132}
 
----------
Epoch 11/40
time = 486.58 secondes

Train loss 0.10685138974943782 accuracy 0.9750540256500244 macro_avg {'precision': 0.9741895940350366, 'recall': 0.9740720774068772, 'f1-score': 0.9740559897593369, 'support': 10182} weighted_avg {'precision': 0.9751324577830939, 'recall': 0.9750540168925554, 'f1-score': 0.9750184803027615, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.7958596906719835 accuracy 0.8833922147750854 macro_avg {'precision': 0.8881437786434876, 'recall': 0.8858844799921325, 'f1-score': 0.8836898021982268, 'support': 1132} weighted_avg {'precision': 0.8926884265146741, 'recall': 0.8833922261484098, 'f1-score': 0.8848140538233903, 'support': 1132}
 
----------
Epoch 12/40
time = 506.69 secondes

Train loss 0.10075849265040077 accuracy 0.9801610708236694 macro_avg {'precision': 0.9797901599964524, 'recall': 0.9797899321281885, 'f1-score': 0.9797558861134699, 'support': 10182} weighted_avg {'precision': 0.9802004472266795, 'recall': 0.9801610685523473, 'f1-score': 0.9801461661898113, 'support': 10182}
 
time = 14.34 secondes

Val loss 0.9541186206231327 accuracy 0.879858672618866 macro_avg {'precision': 0.8828713936030749, 'recall': 0.8784922752829685, 'f1-score': 0.8778538292449707, 'support': 1132} weighted_avg {'precision': 0.8856776000815779, 'recall': 0.8798586572438163, 'f1-score': 0.8797755253078842, 'support': 1132}
 
----------
Epoch 13/40
time = 488.93 secondes

Train loss 0.10441090892515148 accuracy 0.9802592992782593 macro_avg {'precision': 0.9794845718966325, 'recall': 0.9797048143007034, 'f1-score': 0.9795638484449899, 'support': 10182} weighted_avg {'precision': 0.9803275513052511, 'recall': 0.9802592810842663, 'f1-score': 0.9802628398848975, 'support': 10182}
 
time = 14.75 secondes

Val loss 0.8988799220143693 accuracy 0.8745583295822144 macro_avg {'precision': 0.8814277598646584, 'recall': 0.8738627496219035, 'f1-score': 0.8739511900593356, 'support': 1132} weighted_avg {'precision': 0.8858681322468805, 'recall': 0.8745583038869258, 'f1-score': 0.876847167364503, 'support': 1132}
 
----------
Epoch 14/40
time = 489.73 secondes

Train loss 0.08451853798011269 accuracy 0.9827145934104919 macro_avg {'precision': 0.9823634188430204, 'recall': 0.9824499123150842, 'f1-score': 0.9823833808999947, 'support': 10182} weighted_avg {'precision': 0.9827651600725505, 'recall': 0.9827145943822432, 'f1-score': 0.9827185574201125, 'support': 10182}
 
time = 18.26 secondes

Val loss 1.005025987142392 accuracy 0.8666077852249146 macro_avg {'precision': 0.8707890007422545, 'recall': 0.8623199144754998, 'f1-score': 0.8620408912045308, 'support': 1132} weighted_avg {'precision': 0.8717789109663399, 'recall': 0.8666077738515902, 'f1-score': 0.8647975551135907, 'support': 1132}
 
----------
Epoch 15/40
time = 491.91 secondes

Train loss 0.09230599000317968 accuracy 0.9824199676513672 macro_avg {'precision': 0.9823548887811533, 'recall': 0.9823786354922104, 'f1-score': 0.9823358200226784, 'support': 10182} weighted_avg {'precision': 0.9825093061296726, 'recall': 0.982419956786486, 'f1-score': 0.9824330277513538, 'support': 10182}
 
time = 18.04 secondes

Val loss 0.7845906613662701 accuracy 0.8851590156555176 macro_avg {'precision': 0.8951839296464218, 'recall': 0.8860687816631868, 'f1-score': 0.8875806482059341, 'support': 1132} weighted_avg {'precision': 0.8934525128527322, 'recall': 0.8851590106007067, 'f1-score': 0.8864657235022194, 'support': 1132}
 
----------
Epoch 16/40
time = 487.17 secondes

Train loss 0.08120033956571945 accuracy 0.9857591986656189 macro_avg {'precision': 0.9856007649918759, 'recall': 0.985589411973374, 'f1-score': 0.9855879929316487, 'support': 10182} weighted_avg {'precision': 0.9857882740708496, 'recall': 0.9857591828717345, 'f1-score': 0.9857664248721059, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.8467162548196272 accuracy 0.8886925578117371 macro_avg {'precision': 0.8894714861259192, 'recall': 0.8910452145586675, 'f1-score': 0.8883126872628445, 'support': 1132} weighted_avg {'precision': 0.8950558166496053, 'recall': 0.8886925795053003, 'f1-score': 0.8899516681041303, 'support': 1132}
 
----------
Epoch 17/40
time = 487.28 secondes

Train loss 0.08028282645871948 accuracy 0.9842860102653503 macro_avg {'precision': 0.9845290160187709, 'recall': 0.9841880577887079, 'f1-score': 0.9843210876134163, 'support': 10182} weighted_avg {'precision': 0.9843540375810377, 'recall': 0.9842859948929483, 'f1-score': 0.9842830317126103, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.9497336844923807 accuracy 0.8816254734992981 macro_avg {'precision': 0.8873666179939917, 'recall': 0.8833658572109119, 'f1-score': 0.8828998120156791, 'support': 1132} weighted_avg {'precision': 0.8886393377323234, 'recall': 0.8816254416961131, 'f1-score': 0.8825970831400709, 'support': 1132}
 
----------
Epoch 18/40
time = 490.02 secondes

Train loss 0.07437754537806691 accuracy 0.9868395328521729 macro_avg {'precision': 0.9867719032975376, 'recall': 0.9869686569225546, 'f1-score': 0.9868560537388754, 'support': 10182} weighted_avg {'precision': 0.9868616052400053, 'recall': 0.9868395207228442, 'f1-score': 0.9868369893768763, 'support': 10182}
 
time = 17.09 secondes

Val loss 0.9334095772064757 accuracy 0.8772084712982178 macro_avg {'precision': 0.8905713211610389, 'recall': 0.8806413338281516, 'f1-score': 0.8798014196876822, 'support': 1132} weighted_avg {'precision': 0.8915907330242588, 'recall': 0.877208480565371, 'f1-score': 0.8784170098739621, 'support': 1132}
 
----------
Epoch 19/40
time = 488.29 secondes

Train loss 0.09132055171308819 accuracy 0.9840896129608154 macro_avg {'precision': 0.9842839487160475, 'recall': 0.9840497680018687, 'f1-score': 0.9841323301804465, 'support': 10182} weighted_avg {'precision': 0.9841800430700687, 'recall': 0.9840895698291102, 'f1-score': 0.9840991999695425, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.8979851967291529 accuracy 0.8833922147750854 macro_avg {'precision': 0.8852721517452874, 'recall': 0.8822380930033369, 'f1-score': 0.8821195781358651, 'support': 1132} weighted_avg {'precision': 0.8869370745239983, 'recall': 0.8833922261484098, 'f1-score': 0.883579286845738, 'support': 1132}
 
----------
Epoch 20/40
time = 485.94 secondes

Train loss 0.07078124692998816 accuracy 0.9886073470115662 macro_avg {'precision': 0.9882883552952432, 'recall': 0.9885152509074665, 'f1-score': 0.9883874603655458, 'support': 10182} weighted_avg {'precision': 0.9886287808102308, 'recall': 0.9886073462973876, 'f1-score': 0.9886044643734994, 'support': 10182}
 
time = 17.05 secondes

Val loss 0.9121021994102244 accuracy 0.879858672618866 macro_avg {'precision': 0.8863520453601899, 'recall': 0.8858818411917095, 'f1-score': 0.8824003912134566, 'support': 1132} weighted_avg {'precision': 0.8907662149939454, 'recall': 0.8798586572438163, 'f1-score': 0.8814693791356971, 'support': 1132}
 
----------
Epoch 21/40
time = 487.08 secondes

Train loss 0.07294998872044513 accuracy 0.9873306155204773 macro_avg {'precision': 0.986532473077764, 'recall': 0.9865166261139251, 'f1-score': 0.9865043176403641, 'support': 10182} weighted_avg {'precision': 0.9873672841744154, 'recall': 0.9873305833824396, 'f1-score': 0.987330229957416, 'support': 10182}
 
time = 16.95 secondes

Val loss 0.8688818541219955 accuracy 0.8860424160957336 macro_avg {'precision': 0.8862351848124492, 'recall': 0.8869942262601409, 'f1-score': 0.8838019377910195, 'support': 1132} weighted_avg {'precision': 0.8907075506545076, 'recall': 0.8860424028268551, 'f1-score': 0.88573891202981, 'support': 1132}
 
----------
Epoch 22/40
time = 490.66 secondes

Train loss 0.043440933120939086 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913243832135695, 'recall': 0.9911799788027315, 'f1-score': 0.9912445970561737, 'support': 10182} weighted_avg {'precision': 0.9914609482103978, 'recall': 0.9914555097230406, 'f1-score': 0.9914505544804166, 'support': 10182}
 
time = 15.58 secondes

Val loss 0.9318128447770838 accuracy 0.8878092169761658 macro_avg {'precision': 0.8963237600320598, 'recall': 0.889199630755362, 'f1-score': 0.8883786247394371, 'support': 1132} weighted_avg {'precision': 0.8956585814142959, 'recall': 0.8878091872791519, 'f1-score': 0.8875604069497222, 'support': 1132}
 
----------
Epoch 23/40
time = 491.01 secondes

Train loss 0.06255713016332239 accuracy 0.9885091781616211 macro_avg {'precision': 0.988523195874824, 'recall': 0.9882103683856995, 'f1-score': 0.988338273754849, 'support': 10182} weighted_avg {'precision': 0.9885446289318368, 'recall': 0.9885091337654685, 'f1-score': 0.9885004727756067, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.9402312323518472 accuracy 0.8878092169761658 macro_avg {'precision': 0.8987763811563193, 'recall': 0.8896794112269883, 'f1-score': 0.8910679558539568, 'support': 1132} weighted_avg {'precision': 0.8975640029252027, 'recall': 0.8878091872791519, 'f1-score': 0.8892913361189201, 'support': 1132}
 
----------
Epoch 24/40
time = 490.83 secondes

Train loss 0.055328569931412254 accuracy 0.989589512348175 macro_avg {'precision': 0.9893423849098216, 'recall': 0.9891398619656012, 'f1-score': 0.9892320066001252, 'support': 10182} weighted_avg {'precision': 0.9896097211723638, 'recall': 0.9895894716165783, 'f1-score': 0.9895909720870555, 'support': 10182}
 
time = 18.10 secondes

Val loss 0.8536099085987432 accuracy 0.8931095600128174 macro_avg {'precision': 0.8978794390144269, 'recall': 0.8952682902981536, 'f1-score': 0.8952666377968598, 'support': 1132} weighted_avg {'precision': 0.8965989555736836, 'recall': 0.8931095406360424, 'f1-score': 0.8934271640108543, 'support': 1132}
 
----------
Epoch 25/40
time = 492.02 secondes

Train loss 0.048025573856519906 accuracy 0.9914555549621582 macro_avg {'precision': 0.9910891263122237, 'recall': 0.9912474357616755, 'f1-score': 0.9911592092081717, 'support': 10182} weighted_avg {'precision': 0.9914795215813981, 'recall': 0.9914555097230406, 'f1-score': 0.9914586028952662, 'support': 10182}
 
time = 18.23 secondes

Val loss 0.9816776340711852 accuracy 0.8851590156555176 macro_avg {'precision': 0.89216978991629, 'recall': 0.8912719765222672, 'f1-score': 0.8882022192522887, 'support': 1132} weighted_avg {'precision': 0.8922891582191874, 'recall': 0.8851590106007067, 'f1-score': 0.8848010215787145, 'support': 1132}
 
----------
Epoch 26/40
time = 490.14 secondes

Train loss 0.053180109787220944 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901019634156555, 'recall': 0.9899631812789288, 'f1-score': 0.9900226691265948, 'support': 10182} weighted_avg {'precision': 0.9902853722822829, 'recall': 0.9902769593400118, 'f1-score': 0.9902710489264681, 'support': 10182}
 
time = 16.04 secondes

Val loss 0.8954135703127795 accuracy 0.8948763608932495 macro_avg {'precision': 0.9032181452001661, 'recall': 0.8966401913830161, 'f1-score': 0.8983986906619524, 'support': 1132} weighted_avg {'precision': 0.8994401272587367, 'recall': 0.8948763250883393, 'f1-score': 0.8956565251777344, 'support': 1132}
 
----------
Epoch 27/40
time = 484.89 secondes

Train loss 0.042838661891403104 accuracy 0.9928305149078369 macro_avg {'precision': 0.992779989232632, 'recall': 0.9925686410324687, 'f1-score': 0.9926652998691445, 'support': 10182} weighted_avg {'precision': 0.9928536683523782, 'recall': 0.9928304851699077, 'f1-score': 0.9928332035536895, 'support': 10182}
 
time = 13.95 secondes

Val loss 0.783622395410059 accuracy 0.8957597017288208 macro_avg {'precision': 0.9053960765158007, 'recall': 0.8976766010382423, 'f1-score': 0.8994368968521333, 'support': 1132} weighted_avg {'precision': 0.9031240259548763, 'recall': 0.8957597173144877, 'f1-score': 0.8972480218915037, 'support': 1132}
 
----------
Epoch 28/40
time = 488.09 secondes

Train loss 0.04538817257733406 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925276289487466, 'recall': 0.9924504435329224, 'f1-score': 0.9924583061202862, 'support': 10182} weighted_avg {'precision': 0.9924788647576538, 'recall': 0.9924376350422314, 'f1-score': 0.9924264228565537, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.8187132704896241 accuracy 0.898409903049469 macro_avg {'precision': 0.9047068451525082, 'recall': 0.9011550982814628, 'f1-score': 0.9017240528964837, 'support': 1132} weighted_avg {'precision': 0.9033973202378874, 'recall': 0.8984098939929329, 'f1-score': 0.8996291268308446, 'support': 1132}
 
----------
Epoch 29/40
time = 487.02 secondes

Train loss 0.03546970920377554 accuracy 0.9936162233352661 macro_avg {'precision': 0.993438009869314, 'recall': 0.9936223354618058, 'f1-score': 0.9935193618824207, 'support': 10182} weighted_avg {'precision': 0.9936573239949072, 'recall': 0.9936161854252603, 'f1-score': 0.9936261725135686, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.9601371724073571 accuracy 0.8913427591323853 macro_avg {'precision': 0.8963699808616876, 'recall': 0.8920662500095216, 'f1-score': 0.8910116232891095, 'support': 1132} weighted_avg {'precision': 0.897333147374894, 'recall': 0.8913427561837456, 'f1-score': 0.8911798464247624, 'support': 1132}
 
----------
Epoch 30/40
time = 485.73 secondes

Train loss 0.047092177982953363 accuracy 0.9927322864532471 macro_avg {'precision': 0.9926148432180856, 'recall': 0.9928958896739545, 'f1-score': 0.9927369345088103, 'support': 10182} weighted_avg {'precision': 0.9927693663149169, 'recall': 0.9927322726379886, 'f1-score': 0.9927331042465847, 'support': 10182}
 
time = 16.88 secondes

Val loss 0.8546571832748284 accuracy 0.9019434452056885 macro_avg {'precision': 0.9094320126124791, 'recall': 0.9035783027462891, 'f1-score': 0.9040339276222668, 'support': 1132} weighted_avg {'precision': 0.9082984916503419, 'recall': 0.9019434628975265, 'f1-score': 0.9025831044499247, 'support': 1132}
 
----------
Epoch 31/40
time = 486.96 secondes

Train loss 0.034184968343536494 accuracy 0.9947947859764099 macro_avg {'precision': 0.9948178065580633, 'recall': 0.9947239046346447, 'f1-score': 0.994765473560555, 'support': 10182} weighted_avg {'precision': 0.9948098324599354, 'recall': 0.9947947358082891, 'f1-score': 0.9947970880322522, 'support': 10182}
 
time = 17.00 secondes

Val loss 0.8772415368557759 accuracy 0.8975265026092529 macro_avg {'precision': 0.9010416020691002, 'recall': 0.9000388807733468, 'f1-score': 0.8983944025432467, 'support': 1132} weighted_avg {'precision': 0.9043372530067465, 'recall': 0.8975265017667845, 'f1-score': 0.8988259660448761, 'support': 1132}
 
----------
Epoch 32/40
time = 487.65 secondes

Train loss 0.02907559409452214 accuracy 0.994892954826355 macro_avg {'precision': 0.9946961216282444, 'recall': 0.9947656267053133, 'f1-score': 0.9947177909580999, 'support': 10182} weighted_avg {'precision': 0.9949175162410399, 'recall': 0.9948929483402082, 'f1-score': 0.9948926388513117, 'support': 10182}
 
time = 14.17 secondes

Val loss 0.8864078008758645 accuracy 0.9063604474067688 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}
 
----------
Epoch 33/40
time = 491.51 secondes

Train loss 0.018558030947326123 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961598519809417, 'recall': 0.9962079437863531, 'f1-score': 0.9961809548320988, 'support': 10182} weighted_avg {'precision': 0.9961749802862734, 'recall': 0.9961697112551562, 'f1-score': 0.9961695639904631, 'support': 10182}
 
time = 17.70 secondes

Val loss 0.9240517644173732 accuracy 0.8948763608932495 macro_avg {'precision': 0.8992828271654106, 'recall': 0.8981555553207621, 'f1-score': 0.8970924601966054, 'support': 1132} weighted_avg {'precision': 0.8993005922681244, 'recall': 0.8948763250883393, 'f1-score': 0.8954393011399944, 'support': 1132}
 
----------
Epoch 34/40
time = 495.19 secondes

Train loss 0.015434786263873118 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973201221154783, 'recall': 0.9973587430373227, 'f1-score': 0.9973356899470944, 'support': 10182} weighted_avg {'precision': 0.9972579411593034, 'recall': 0.9972500491062659, 'f1-score': 0.9972501322836794, 'support': 10182}
 
time = 14.32 secondes

Val loss 0.970689211645357 accuracy 0.9010601043701172 macro_avg {'precision': 0.9081098265003671, 'recall': 0.9048019091298014, 'f1-score': 0.9048334082347476, 'support': 1132} weighted_avg {'precision': 0.9062698197846981, 'recall': 0.901060070671378, 'f1-score': 0.9019115077892547, 'support': 1132}
 
----------
Epoch 35/40
time = 490.50 secondes

Train loss 0.015224112326950704 accuracy 0.9970536828041077 macro_avg {'precision': 0.9971078988560829, 'recall': 0.9971290395992076, 'f1-score': 0.9971160947116736, 'support': 10182} weighted_avg {'precision': 0.9970564643820542, 'recall': 0.9970536240424278, 'f1-score': 0.9970526125758338, 'support': 10182}
 
time = 13.96 secondes

Val loss 1.0586093372875836 accuracy 0.8860424160957336 macro_avg {'precision': 0.8901913220712654, 'recall': 0.8899745896660238, 'f1-score': 0.887978243966247, 'support': 1132} weighted_avg {'precision': 0.8917902826546585, 'recall': 0.8860424028268551, 'f1-score': 0.8867095002665827, 'support': 1132}
 
----------
Epoch 36/40
time = 490.58 secondes

Train loss 0.011458166437499629 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977290675211758, 'recall': 0.9977344511960915, 'f1-score': 0.9977275275558508, 'support': 10182} weighted_avg {'precision': 0.9976505839908223, 'recall': 0.9976428992339422, 'f1-score': 0.9976422779565713, 'support': 10182}
 
time = 18.39 secondes

Val loss 1.0479406079636173 accuracy 0.8895759582519531 macro_avg {'precision': 0.8946014408162679, 'recall': 0.8946823636762374, 'f1-score': 0.8924248315725173, 'support': 1132} weighted_avg {'precision': 0.8951866512472697, 'recall': 0.8895759717314488, 'f1-score': 0.8900919336625984, 'support': 1132}
 
----------
Epoch 37/40
time = 491.32 secondes

Train loss 0.012433224166921986 accuracy 0.9976429343223572 macro_avg {'precision': 0.997666933043128, 'recall': 0.997660764647519, 'f1-score': 0.9976617643128012, 'support': 10182} weighted_avg {'precision': 0.997650076857833, 'recall': 0.9976428992339422, 'f1-score': 0.9976444077011188, 'support': 10182}
 
time = 13.64 secondes

Val loss 1.0875365298662716 accuracy 0.880742073059082 macro_avg {'precision': 0.8920760627723396, 'recall': 0.8828426313127318, 'f1-score': 0.883561513370473, 'support': 1132} weighted_avg {'precision': 0.8909768298742995, 'recall': 0.8807420494699647, 'f1-score': 0.8820504779987526, 'support': 1132}
 
----------
Epoch 38/40
time = 486.75 secondes

Train loss 0.00736699988197553 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986724793607479, 'recall': 0.9986177782746211, 'f1-score': 0.9986445191101117, 'support': 10182} weighted_avg {'precision': 0.9986261459605219, 'recall': 0.998625024553133, 'f1-score': 0.9986249982978715, 'support': 10182}
 
time = 14.33 secondes

Val loss 0.9899729756264823 accuracy 0.8966431021690369 macro_avg {'precision': 0.9033257307121026, 'recall': 0.8995797686037006, 'f1-score': 0.899380161965453, 'support': 1132} weighted_avg {'precision': 0.9008787333203346, 'recall': 0.8966431095406361, 'f1-score': 0.8966693539605891, 'support': 1132}
 
----------
Epoch 39/40
time = 487.93 secondes

Train loss 0.005694779054336971 accuracy 0.998919665813446 macro_avg {'precision': 0.9989580038204101, 'recall': 0.9989386812541543, 'f1-score': 0.9989469044544748, 'support': 10182} weighted_avg {'precision': 0.9989227880789354, 'recall': 0.9989196621488902, 'f1-score': 0.9989197384473645, 'support': 10182}
 
time = 14.26 secondes

Val loss 0.9627102215352121 accuracy 0.9037102460861206 macro_avg {'precision': 0.9093682933925138, 'recall': 0.9059448150132239, 'f1-score': 0.9058614675898525, 'support': 1132} weighted_avg {'precision': 0.9079005331950925, 'recall': 0.9037102473498233, 'f1-score': 0.9041046676552479, 'support': 1132}
 
----------
Epoch 40/40
time = 487.81 secondes

Train loss 0.00132249186964221 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994329792780207, 'recall': 0.9994311540244109, 'f1-score': 0.9994316208258944, 'support': 10182} weighted_avg {'precision': 0.9994118385793007, 'recall': 0.9994107248084856, 'f1-score': 0.9994108183455855, 'support': 10182}
 
time = 17.08 secondes

Val loss 0.9609772389760853 accuracy 0.9037102460861206 macro_avg {'precision': 0.9086078944814305, 'recall': 0.9057185509194206, 'f1-score': 0.9053069769314114, 'support': 1132} weighted_avg {'precision': 0.9082412875438725, 'recall': 0.9037102473498233, 'f1-score': 0.9040503657343512, 'support': 1132}
 
----------
best_accuracy 0.9063604474067688 best_epoch 32 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}

average train time 489.5902926445007

average val time 15.876436096429824
 
time = 108.31 secondes

test_accuracy 0.828066885471344 macro_avg {'precision': 0.8274202315415042, 'recall': 0.821766739596894, 'f1-score': 0.8224073284679108, 'support': 7532} weighted_avg {'precision': 0.8336561868218115, 'recall': 0.8280669144981413, 'f1-score': 0.8287879284705231, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 69.49 GiB already allocated; 161.62 MiB free; 70.56 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 68.59 GiB already allocated; 33.62 MiB free; 70.69 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 79.21 GiB total capacity; 66.38 GiB already allocated; 495.62 MiB free; 70.23 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 69.37 GiB already allocated; 405.62 MiB free; 70.32 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_4
----------
Epoch 1/40
time = 705.30 secondes

Train loss 1.1060675276060306 accuracy 0.6868984699249268 macro_avg {'precision': 0.6912446852383314, 'recall': 0.6731791282505873, 'f1-score': 0.6712349620356672, 'support': 10182} weighted_avg {'precision': 0.6988909620616774, 'recall': 0.6868984482419956, 'f1-score': 0.6836668714808398, 'support': 10182}
 
time = 26.07 secondes

Val loss 0.5286669056390373 accuracy 0.8471731543540955 macro_avg {'precision': 0.8472686007983714, 'recall': 0.8357032277465798, 'f1-score': 0.8279019482566463, 'support': 1132} weighted_avg {'precision': 0.8485481188132882, 'recall': 0.8471731448763251, 'f1-score': 0.8378357951330426, 'support': 1132}
 
----------
Epoch 2/40
time = 682.32 secondes

Train loss 0.3978598882419348 accuracy 0.8833235502243042 macro_avg {'precision': 0.8759068462412211, 'recall': 0.8751244981793697, 'f1-score': 0.875047420180022, 'support': 10182} weighted_avg {'precision': 0.8824652770853887, 'recall': 0.8833235120801414, 'f1-score': 0.8825159713444198, 'support': 10182}
 
time = 19.46 secondes

Val loss 0.4057910417954267 accuracy 0.8869258165359497 macro_avg {'precision': 0.8889799665980631, 'recall': 0.8861582263071087, 'f1-score': 0.8839589378606589, 'support': 1132} weighted_avg {'precision': 0.8915387292246331, 'recall': 0.8869257950530035, 'f1-score': 0.8854585051980637, 'support': 1132}
 
----------
Epoch 3/40
time = 596.00 secondes

Train loss 0.23685451580015607 accuracy 0.9334119558334351 macro_avg {'precision': 0.9301979073177152, 'recall': 0.9293517586328252, 'f1-score': 0.9296644330094257, 'support': 10182} weighted_avg {'precision': 0.9334374723906101, 'recall': 0.9334119033588686, 'f1-score': 0.9333293359157556, 'support': 10182}
 
time = 20.68 secondes

Val loss 0.5218494231156795 accuracy 0.8825088143348694 macro_avg {'precision': 0.885712851373954, 'recall': 0.8848041534201124, 'f1-score': 0.8813553475093755, 'support': 1132} weighted_avg {'precision': 0.8909162139592807, 'recall': 0.8825088339222615, 'f1-score': 0.8827363830550884, 'support': 1132}
 
----------
Epoch 4/40
time = 600.61 secondes

Train loss 0.1841260397070624 accuracy 0.9513848423957825 macro_avg {'precision': 0.9493771868075461, 'recall': 0.9485518198694969, 'f1-score': 0.9488723013099912, 'support': 10182} weighted_avg {'precision': 0.9515848942706286, 'recall': 0.9513847967000589, 'f1-score': 0.951394518218109, 'support': 10182}
 
time = 27.47 secondes

Val loss 0.5575415709377332 accuracy 0.8939929604530334 macro_avg {'precision': 0.8969716363061095, 'recall': 0.8983188436739713, 'f1-score': 0.8934728443982068, 'support': 1132} weighted_avg {'precision': 0.9009013961173981, 'recall': 0.8939929328621908, 'f1-score': 0.8928251713474634, 'support': 1132}
 
----------
Epoch 5/40
time = 737.69 secondes

Train loss 0.1618475667215603 accuracy 0.9597328901290894 macro_avg {'precision': 0.9585814501329857, 'recall': 0.9582446219287704, 'f1-score': 0.9583543266615256, 'support': 10182} weighted_avg {'precision': 0.9599442689185511, 'recall': 0.9597328619131801, 'f1-score': 0.9597799729996482, 'support': 10182}
 
time = 27.59 secondes

Val loss 0.6505570747482945 accuracy 0.8851590156555176 macro_avg {'precision': 0.89922688978667, 'recall': 0.8837955803108095, 'f1-score': 0.8845939451625988, 'support': 1132} weighted_avg {'precision': 0.8955478358911739, 'recall': 0.8851590106007067, 'f1-score': 0.8832450065119175, 'support': 1132}
 
----------
Epoch 6/40
time = 663.77 secondes

Train loss 0.13605199301077325 accuracy 0.9662148952484131 macro_avg {'precision': 0.9650446810491384, 'recall': 0.9650979604878012, 'f1-score': 0.9650446251308138, 'support': 10182} weighted_avg {'precision': 0.966290868694431, 'recall': 0.966214889019839, 'f1-score': 0.9662259015033429, 'support': 10182}
 
time = 20.24 secondes

Val loss 0.690308154780339 accuracy 0.8816254734992981 macro_avg {'precision': 0.8948453305151413, 'recall': 0.876315155342611, 'f1-score': 0.8793078137885797, 'support': 1132} weighted_avg {'precision': 0.8912771610085204, 'recall': 0.8816254416961131, 'f1-score': 0.8805164929925261, 'support': 1132}
 
----------
Epoch 7/40
time = 591.54 secondes

Train loss 0.13388681847423395 accuracy 0.9697505831718445 macro_avg {'precision': 0.96871088051502, 'recall': 0.9684726531550311, 'f1-score': 0.9685216841963967, 'support': 10182} weighted_avg {'precision': 0.9698889276833448, 'recall': 0.9697505401689256, 'f1-score': 0.9697530159155721, 'support': 10182}
 
time = 24.14 secondes

Val loss 0.5743945597787388 accuracy 0.9028268456459045 macro_avg {'precision': 0.907319086340857, 'recall': 0.9073387317926096, 'f1-score': 0.9045282429061057, 'support': 1132} weighted_avg {'precision': 0.9101459427296902, 'recall': 0.9028268551236749, 'f1-score': 0.903542176057734, 'support': 1132}
 
----------
Epoch 8/40
time = 696.13 secondes

Train loss 0.13252034265242058 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684956057779385, 'recall': 0.9685064743185684, 'f1-score': 0.9684294011763324, 'support': 10182} weighted_avg {'precision': 0.9698175682747254, 'recall': 0.9696523276370065, 'f1-score': 0.9696663239708587, 'support': 10182}
 
time = 26.88 secondes

Val loss 0.5323867150660256 accuracy 0.9178445339202881 macro_avg {'precision': 0.9216557235264993, 'recall': 0.9184208288807696, 'f1-score': 0.9186140388009134, 'support': 1132} weighted_avg {'precision': 0.9200747697275344, 'recall': 0.9178445229681979, 'f1-score': 0.9176474145586859, 'support': 1132}
 
----------
Epoch 9/40
time = 696.58 secondes

Train loss 0.10771712561635435 accuracy 0.9758397340774536 macro_avg {'precision': 0.9752500526860203, 'recall': 0.9750574344323087, 'f1-score': 0.9751295162105595, 'support': 10182} weighted_avg {'precision': 0.9758576934947365, 'recall': 0.9758397171479081, 'f1-score': 0.9758240595121059, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.5117967357382697 accuracy 0.9178445339202881 macro_avg {'precision': 0.9220901510027393, 'recall': 0.9167387930776668, 'f1-score': 0.9181575848274892, 'support': 1132} weighted_avg {'precision': 0.9198526828202191, 'recall': 0.9178445229681979, 'f1-score': 0.9177038508320591, 'support': 1132}
 
----------
Epoch 10/40
time = 640.72 secondes

Train loss 0.10899010083495217 accuracy 0.9778040051460266 macro_avg {'precision': 0.9777540238752934, 'recall': 0.9771476432101253, 'f1-score': 0.9774216100481932, 'support': 10182} weighted_avg {'precision': 0.9778292142296359, 'recall': 0.9778039677862895, 'f1-score': 0.9777891903176193, 'support': 10182}
 
time = 19.31 secondes

Val loss 0.6681109112974348 accuracy 0.9054770469665527 macro_avg {'precision': 0.9097256877636044, 'recall': 0.907997507579536, 'f1-score': 0.9050312726449965, 'support': 1132} weighted_avg {'precision': 0.9132857715872643, 'recall': 0.9054770318021201, 'f1-score': 0.9054054583341857, 'support': 1132}
 
----------
Epoch 11/40
time = 609.36 secondes

Train loss 0.10413005455183977 accuracy 0.9786878824234009 macro_avg {'precision': 0.978044083335637, 'recall': 0.9781025492966398, 'f1-score': 0.9780429513234588, 'support': 10182} weighted_avg {'precision': 0.9787549561320905, 'recall': 0.9786878805735612, 'f1-score': 0.9786917395363781, 'support': 10182}
 
time = 27.80 secondes

Val loss 0.6473687676285331 accuracy 0.9063604474067688 macro_avg {'precision': 0.9180492484949221, 'recall': 0.9076285562335175, 'f1-score': 0.9086999320878901, 'support': 1132} weighted_avg {'precision': 0.9160186837305626, 'recall': 0.9063604240282686, 'f1-score': 0.9070516650932384, 'support': 1132}
 
----------
Epoch 12/40
time = 741.65 secondes

Train loss 0.10119091835575839 accuracy 0.9797682762145996 macro_avg {'precision': 0.9795000177219366, 'recall': 0.9791976476251193, 'f1-score': 0.9793133155370329, 'support': 10182} weighted_avg {'precision': 0.97980539941072, 'recall': 0.979768218424671, 'f1-score': 0.9797509468823947, 'support': 10182}
 
time = 27.93 secondes

Val loss 0.6771856486325113 accuracy 0.9045936465263367 macro_avg {'precision': 0.9102385137720266, 'recall': 0.9049482055476844, 'f1-score': 0.9048612354083737, 'support': 1132} weighted_avg {'precision': 0.9095680500156623, 'recall': 0.9045936395759717, 'f1-score': 0.9046403421033066, 'support': 1132}
 
----------
Epoch 13/40
time = 639.81 secondes

Train loss 0.08585803825886126 accuracy 0.9830092787742615 macro_avg {'precision': 0.9827604179509757, 'recall': 0.9824351702377474, 'f1-score': 0.9825860071422369, 'support': 10182} weighted_avg {'precision': 0.9830270698992964, 'recall': 0.9830092319780004, 'f1-score': 0.9830069203379079, 'support': 10182}
 
time = 19.00 secondes

Val loss 0.5900274603154172 accuracy 0.916961133480072 macro_avg {'precision': 0.9209412309698781, 'recall': 0.9168673652720715, 'f1-score': 0.9174175716627484, 'support': 1132} weighted_avg {'precision': 0.9201833934027098, 'recall': 0.9169611307420494, 'f1-score': 0.9170738912461951, 'support': 1132}
 
----------
Epoch 14/40
time = 587.76 secondes

Train loss 0.09248712605375868 accuracy 0.9827145934104919 macro_avg {'precision': 0.9813820088136511, 'recall': 0.9818019907841379, 'f1-score': 0.9815589595694174, 'support': 10182} weighted_avg {'precision': 0.9828194248902724, 'recall': 0.9827145943822432, 'f1-score': 0.9827364401365913, 'support': 10182}
 
time = 23.53 secondes

Val loss 0.5817499518452678 accuracy 0.9231448769569397 macro_avg {'precision': 0.9295499052856476, 'recall': 0.9234835227956328, 'f1-score': 0.9253898049959355, 'support': 1132} weighted_avg {'precision': 0.9261676282878981, 'recall': 0.9231448763250883, 'f1-score': 0.9235688303951032, 'support': 1132}
 
----------
Epoch 15/40
time = 695.72 secondes

Train loss 0.08148616211262409 accuracy 0.9845806360244751 macro_avg {'precision': 0.9838972371720296, 'recall': 0.9838564616591607, 'f1-score': 0.983863810837829, 'support': 10182} weighted_avg {'precision': 0.9845882445974019, 'recall': 0.9845806324887055, 'f1-score': 0.9845712056234294, 'support': 10182}
 
time = 27.81 secondes

Val loss 0.6428248902748365 accuracy 0.9116607904434204 macro_avg {'precision': 0.9168341631872643, 'recall': 0.9130958831324026, 'f1-score': 0.9129289267015068, 'support': 1132} weighted_avg {'precision': 0.9162579266627331, 'recall': 0.911660777385159, 'f1-score': 0.911837507014717, 'support': 1132}
 
----------
Epoch 16/40
time = 703.04 secondes

Train loss 0.08350212321748933 accuracy 0.9848753213882446 macro_avg {'precision': 0.984127391242002, 'recall': 0.9839850491505638, 'f1-score': 0.9840462283090234, 'support': 10182} weighted_avg {'precision': 0.984880727412725, 'recall': 0.9848752700844627, 'f1-score': 0.9848683678863138, 'support': 10182}
 
time = 27.39 secondes

Val loss 0.691425802100972 accuracy 0.9063604474067688 macro_avg {'precision': 0.9152816118054625, 'recall': 0.9037073938222822, 'f1-score': 0.9041287672800747, 'support': 1132} weighted_avg {'precision': 0.9135942440439255, 'recall': 0.9063604240282686, 'f1-score': 0.9053957171937761, 'support': 1132}
 
----------
Epoch 17/40
time = 653.95 secondes

Train loss 0.08545175178308281 accuracy 0.9836967587471008 macro_avg {'precision': 0.9831744370368641, 'recall': 0.9834052312170941, 'f1-score': 0.9832617373784835, 'support': 10182} weighted_avg {'precision': 0.9837752317975386, 'recall': 0.9836967197014339, 'f1-score': 0.9837082719040301, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.7905226800173462 accuracy 0.9010601043701172 macro_avg {'precision': 0.908133028988131, 'recall': 0.9023480054597346, 'f1-score': 0.9015914277488009, 'support': 1132} weighted_avg {'precision': 0.9095412038744146, 'recall': 0.901060070671378, 'f1-score': 0.9015176035500834, 'support': 1132}
 
----------
Epoch 18/40
time = 607.97 secondes

Train loss 0.07429239696775224 accuracy 0.9863485097885132 macro_avg {'precision': 0.9862253378626212, 'recall': 0.9863236402798213, 'f1-score': 0.9862670808272161, 'support': 10182} weighted_avg {'precision': 0.9863641512937589, 'recall': 0.9863484580632489, 'f1-score': 0.9863487745563073, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.7154949730941387 accuracy 0.9045936465263367 macro_avg {'precision': 0.9122740610805613, 'recall': 0.9079966677160826, 'f1-score': 0.9062272244050437, 'support': 1132} weighted_avg {'precision': 0.9128248465382911, 'recall': 0.9045936395759717, 'f1-score': 0.9043473336959126, 'support': 1132}
 
----------
Epoch 19/40
time = 711.02 secondes

Train loss 0.06322611827293471 accuracy 0.9884109497070312 macro_avg {'precision': 0.9883716232952142, 'recall': 0.988385654130053, 'f1-score': 0.9883696257652099, 'support': 10182} weighted_avg {'precision': 0.9884523009944993, 'recall': 0.9884109212335495, 'f1-score': 0.9884231872355632, 'support': 10182}
 
time = 28.27 secondes

Val loss 0.6903213634339946 accuracy 0.9143109321594238 macro_avg {'precision': 0.9165861629374893, 'recall': 0.9131187961458499, 'f1-score': 0.9136065339862915, 'support': 1132} weighted_avg {'precision': 0.916367592050385, 'recall': 0.9143109540636042, 'f1-score': 0.9139502695336543, 'support': 1132}
 
----------
Epoch 20/40
time = 703.91 secondes

Train loss 0.06370170586600139 accuracy 0.987625241279602 macro_avg {'precision': 0.9876622272064459, 'recall': 0.9875979682749616, 'f1-score': 0.9876090207893835, 'support': 10182} weighted_avg {'precision': 0.9876805295241795, 'recall': 0.9876252209781968, 'f1-score': 0.9876313555066041, 'support': 10182}
 
time = 26.43 secondes

Val loss 0.8140881195395708 accuracy 0.8992933034896851 macro_avg {'precision': 0.9101433630108735, 'recall': 0.903807546291335, 'f1-score': 0.9028787486834874, 'support': 1132} weighted_avg {'precision': 0.9099515369987482, 'recall': 0.8992932862190812, 'f1-score': 0.9000997394107609, 'support': 1132}
 
----------
Epoch 21/40
time = 611.63 secondes

Train loss 0.06980787126894868 accuracy 0.9870359897613525 macro_avg {'precision': 0.9869789224145114, 'recall': 0.9869577896506447, 'f1-score': 0.9869430527920601, 'support': 10182} weighted_avg {'precision': 0.9870891977591097, 'recall': 0.9870359457866824, 'f1-score': 0.9870365318199881, 'support': 10182}
 
time = 18.35 secondes

Val loss 0.583161075158835 accuracy 0.9257950782775879 macro_avg {'precision': 0.9306286574728816, 'recall': 0.9269232561441803, 'f1-score': 0.9273308939536824, 'support': 1132} weighted_avg {'precision': 0.9291192950243722, 'recall': 0.9257950530035336, 'f1-score': 0.9259807252188786, 'support': 1132}
 
----------
Epoch 22/40
time = 625.28 secondes

Train loss 0.04929591415242001 accuracy 0.9905716180801392 macro_avg {'precision': 0.9901913120462951, 'recall': 0.9903451313292176, 'f1-score': 0.9902603738465654, 'support': 10182} weighted_avg {'precision': 0.9905932003493267, 'recall': 0.990571596935769, 'f1-score': 0.9905756010607671, 'support': 10182}
 
time = 25.32 secondes

Val loss 0.597238124483597 accuracy 0.9204947352409363 macro_avg {'precision': 0.9214044830058903, 'recall': 0.9201898065722419, 'f1-score': 0.9194187957298624, 'support': 1132} weighted_avg {'precision': 0.9216081116755768, 'recall': 0.9204946996466431, 'f1-score': 0.9197343243039526, 'support': 1132}
 
----------
Epoch 23/40
time = 696.97 secondes

Train loss 0.054166213144039535 accuracy 0.9901787638664246 macro_avg {'precision': 0.9899661030482336, 'recall': 0.989863192536187, 'f1-score': 0.9898999768862209, 'support': 10182} weighted_avg {'precision': 0.9902179472577962, 'recall': 0.9901787468080927, 'f1-score': 0.9901844723661855, 'support': 10182}
 
time = 26.60 secondes

Val loss 0.8195115862923353 accuracy 0.898409903049469 macro_avg {'precision': 0.9169869687624589, 'recall': 0.9045926618688374, 'f1-score': 0.9032761519159453, 'support': 1132} weighted_avg {'precision': 0.9193404920757998, 'recall': 0.8984098939929329, 'f1-score': 0.9005864377142849, 'support': 1132}
 
----------
Epoch 24/40
time = 696.79 secondes

Train loss 0.04356538374605625 accuracy 0.9922412633895874 macro_avg {'precision': 0.9923073718705743, 'recall': 0.9923324505639659, 'f1-score': 0.9923132205787455, 'support': 10182} weighted_avg {'precision': 0.992259492365566, 'recall': 0.9922412099783933, 'f1-score': 0.9922434598375655, 'support': 10182}
 
time = 26.36 secondes

Val loss 0.6636610788796453 accuracy 0.9204947352409363 macro_avg {'precision': 0.9245280401830843, 'recall': 0.9239281468705249, 'f1-score': 0.9232237470485624, 'support': 1132} weighted_avg {'precision': 0.9232758144280496, 'recall': 0.9204946996466431, 'f1-score': 0.9208297858338002, 'support': 1132}
 
----------
Epoch 25/40
time = 623.56 secondes

Train loss 0.04442561767454675 accuracy 0.9919465780258179 macro_avg {'precision': 0.9917652364253609, 'recall': 0.9917758383552087, 'f1-score': 0.9917495403902894, 'support': 10182} weighted_avg {'precision': 0.9919777758763085, 'recall': 0.9919465723826361, 'f1-score': 0.9919419169078556, 'support': 10182}
 
time = 19.38 secondes

Val loss 0.7743988546843494 accuracy 0.9098939895629883 macro_avg {'precision': 0.9149703794158031, 'recall': 0.9129398289623982, 'f1-score': 0.912640761480574, 'support': 1132} weighted_avg {'precision': 0.9133097658672248, 'recall': 0.9098939929328622, 'f1-score': 0.9102983167401695, 'support': 1132}
 
----------
Epoch 26/40
time = 593.51 secondes

Train loss 0.04405577227414343 accuracy 0.9921430349349976 macro_avg {'precision': 0.9923405245527064, 'recall': 0.9921843435335809, 'f1-score': 0.992251753610546, 'support': 10182} weighted_avg {'precision': 0.9921698885790088, 'recall': 0.9921429974464742, 'f1-score': 0.992145658635006, 'support': 10182}
 
time = 21.29 secondes

Val loss 0.7370792464841454 accuracy 0.9187279343605042 macro_avg {'precision': 0.9251129823915983, 'recall': 0.9203312833194099, 'f1-score': 0.9204582891422112, 'support': 1132} weighted_avg {'precision': 0.9231320332087978, 'recall': 0.9187279151943463, 'f1-score': 0.918658660048929, 'support': 1132}
 
----------
Epoch 27/40
time = 700.73 secondes

Train loss 0.047902431881980984 accuracy 0.9918484091758728 macro_avg {'precision': 0.9918177646233962, 'recall': 0.9918984406004878, 'f1-score': 0.991850270401045, 'support': 10182} weighted_avg {'precision': 0.9918524349644825, 'recall': 0.991848359850717, 'f1-score': 0.9918424089212325, 'support': 10182}
 
time = 27.95 secondes

Val loss 0.7159251871939567 accuracy 0.9151943325996399 macro_avg {'precision': 0.9172010831330697, 'recall': 0.9177046019317782, 'f1-score': 0.9164633249642697, 'support': 1132} weighted_avg {'precision': 0.917211976398288, 'recall': 0.9151943462897526, 'f1-score': 0.9153023465156732, 'support': 1132}
 
----------
Epoch 28/40
time = 713.01 secondes

Train loss 0.05265458361329188 accuracy 0.9922412633895874 macro_avg {'precision': 0.9919754250427623, 'recall': 0.9917530973833502, 'f1-score': 0.9918515435781348, 'support': 10182} weighted_avg {'precision': 0.9922523550140555, 'recall': 0.9922412099783933, 'f1-score': 0.9922346623108822, 'support': 10182}
 
time = 26.72 secondes

Val loss 0.6761692108318552 accuracy 0.9125441908836365 macro_avg {'precision': 0.9144155609191962, 'recall': 0.9132053676806366, 'f1-score': 0.9117773590662427, 'support': 1132} weighted_avg {'precision': 0.9163984599451592, 'recall': 0.9125441696113075, 'f1-score': 0.9123992584244972, 'support': 1132}
 
----------
Epoch 29/40
time = 623.68 secondes

Train loss 0.03723010137813049 accuracy 0.9930269122123718 macro_avg {'precision': 0.9923969087037925, 'recall': 0.9926255276146634, 'f1-score': 0.9924925233064312, 'support': 10182} weighted_avg {'precision': 0.9930762628268881, 'recall': 0.9930269102337458, 'f1-score': 0.99303594577261, 'support': 10182}
 
time = 23.72 secondes

Val loss 0.7755163902462735 accuracy 0.9054770469665527 macro_avg {'precision': 0.9082705504754018, 'recall': 0.8984981993344098, 'f1-score': 0.895968898392149, 'support': 1132} weighted_avg {'precision': 0.9101828245999619, 'recall': 0.9054770318021201, 'f1-score': 0.9021662389586872, 'support': 1132}
 
----------
Epoch 30/40
time = 676.55 secondes

Train loss 0.0331371460849127 accuracy 0.9944019317626953 macro_avg {'precision': 0.993815474965601, 'recall': 0.9935848967060853, 'f1-score': 0.9936953334805307, 'support': 10182} weighted_avg {'precision': 0.9943958958782103, 'recall': 0.9944018856806128, 'f1-score': 0.9943948538416383, 'support': 10182}
 
time = 28.45 secondes

Val loss 0.7394706521957066 accuracy 0.9107773900032043 macro_avg {'precision': 0.9125390272635909, 'recall': 0.9135206647238296, 'f1-score': 0.9113728786671272, 'support': 1132} weighted_avg {'precision': 0.9135388641660348, 'recall': 0.9107773851590106, 'f1-score': 0.9104671511381013, 'support': 1132}
 
----------
Epoch 31/40
time = 708.89 secondes

Train loss 0.03652404040292528 accuracy 0.9934197664260864 macro_avg {'precision': 0.9933030976243387, 'recall': 0.9933397725708912, 'f1-score': 0.9933056316481498, 'support': 10182} weighted_avg {'precision': 0.9934494477268754, 'recall': 0.9934197603614221, 'f1-score': 0.9934184128852765, 'support': 10182}
 
time = 28.74 secondes

Val loss 0.6802429843874436 accuracy 0.9240282773971558 macro_avg {'precision': 0.9269612525650874, 'recall': 0.9259771744489447, 'f1-score': 0.9250672014461012, 'support': 1132} weighted_avg {'precision': 0.926416227058555, 'recall': 0.9240282685512368, 'f1-score': 0.9238386514698844, 'support': 1132}
 
----------
Epoch 32/40
time = 682.71 secondes

Train loss 0.036610273318086514 accuracy 0.9947947859764099 macro_avg {'precision': 0.9947167792275721, 'recall': 0.9945818100179318, 'f1-score': 0.9946402361688941, 'support': 10182} weighted_avg {'precision': 0.9948061784591095, 'recall': 0.9947947358082891, 'f1-score': 0.9947927171417783, 'support': 10182}
 
time = 22.80 secondes

Val loss 0.6812933082429469 accuracy 0.9204947352409363 macro_avg {'precision': 0.9228387142474617, 'recall': 0.9199797358237835, 'f1-score': 0.920161694281958, 'support': 1132} weighted_avg {'precision': 0.921647023239589, 'recall': 0.9204946996466431, 'f1-score': 0.9198579182834276, 'support': 1132}
 
----------
Epoch 33/40
time = 611.77 secondes

Train loss 0.025893018248746298 accuracy 0.9949911832809448 macro_avg {'precision': 0.9950161227926675, 'recall': 0.9948893439284221, 'f1-score': 0.9949479431660991, 'support': 10182} weighted_avg {'precision': 0.99500781277529, 'recall': 0.9949911608721272, 'f1-score': 0.9949946954804524, 'support': 10182}
 
time = 21.34 secondes

Val loss 0.6255771583172146 accuracy 0.926678478717804 macro_avg {'precision': 0.932046484079858, 'recall': 0.9269041044438355, 'f1-score': 0.9284069573755875, 'support': 1132} weighted_avg {'precision': 0.9287665040191243, 'recall': 0.926678445229682, 'f1-score': 0.9266992759868344, 'support': 1132}
 
----------
Epoch 34/40
time = 735.10 secondes

Train loss 0.020180653476325024 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960735996777347, 'recall': 0.9961860290492238, 'f1-score': 0.9961281745161272, 'support': 10182} weighted_avg {'precision': 0.9961715956414416, 'recall': 0.9961697112551562, 'f1-score': 0.9961690286032697, 'support': 10182}
 
time = 28.21 secondes

Val loss 0.6108652519036132 accuracy 0.9302120208740234 macro_avg {'precision': 0.9333181761873073, 'recall': 0.931443065277411, 'f1-score': 0.9311875672952515, 'support': 1132} weighted_avg {'precision': 0.9319582665519985, 'recall': 0.9302120141342756, 'f1-score': 0.929828629530147, 'support': 1132}
 
----------
Epoch 35/40
time = 703.67 secondes

Train loss 0.013384737196130364 accuracy 0.996857225894928 macro_avg {'precision': 0.9969160809565508, 'recall': 0.9969438673604017, 'f1-score': 0.996927717825192, 'support': 10182} weighted_avg {'precision': 0.9968630197924128, 'recall': 0.9968571989785897, 'f1-score': 0.9968578391907479, 'support': 10182}
 
time = 28.31 secondes

Val loss 0.7458468108792992 accuracy 0.9125441908836365 macro_avg {'precision': 0.920039994825761, 'recall': 0.9149433765425361, 'f1-score': 0.9151550703675154, 'support': 1132} weighted_avg {'precision': 0.9183281306535528, 'recall': 0.9125441696113075, 'f1-score': 0.9129450085247252, 'support': 1132}
 
----------
Epoch 36/40
time = 621.24 secondes

Train loss 0.016556875870637425 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972805063742948, 'recall': 0.9973106430723139, 'f1-score': 0.9972933752756482, 'support': 10182} weighted_avg {'precision': 0.9972519416804106, 'recall': 0.9972500491062659, 'f1-score': 0.9972487535905936, 'support': 10182}
 
time = 27.41 secondes

Val loss 0.7119446248405848 accuracy 0.9249116778373718 macro_avg {'precision': 0.9270133652175563, 'recall': 0.9268664269169851, 'f1-score': 0.926162295295553, 'support': 1132} weighted_avg {'precision': 0.9259750687785058, 'recall': 0.9249116607773852, 'f1-score': 0.9246726850771582, 'support': 1132}
 
----------
Epoch 37/40
time = 679.61 secondes

Train loss 0.013919861226729969 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975079807853859, 'recall': 0.9975264367936066, 'f1-score': 0.997512869988349, 'support': 10182} weighted_avg {'precision': 0.9975520450098153, 'recall': 0.9975446867020232, 'f1-score': 0.9975438954164462, 'support': 10182}
 
time = 27.84 secondes

Val loss 0.6116368122778331 accuracy 0.9284452199935913 macro_avg {'precision': 0.9309369172096511, 'recall': 0.9288526501090054, 'f1-score': 0.928895025512035, 'support': 1132} weighted_avg {'precision': 0.9303366081094099, 'recall': 0.9284452296819788, 'f1-score': 0.9283748229922568, 'support': 1132}
 
----------
Epoch 38/40
time = 674.97 secondes

Train loss 0.010290060932206949 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983960247705579, 'recall': 0.9984201029246327, 'f1-score': 0.9984070644465841, 'support': 10182} weighted_avg {'precision': 0.9984299798628996, 'recall': 0.9984285994892949, 'f1-score': 0.9984283171994623, 'support': 10182}
 
time = 28.24 secondes

Val loss 0.669733625727736 accuracy 0.9249116778373718 macro_avg {'precision': 0.9291732958446545, 'recall': 0.925920596149344, 'f1-score': 0.9258018262841998, 'support': 1132} weighted_avg {'precision': 0.9288699070651483, 'recall': 0.9249116607773852, 'f1-score': 0.9250877226703653, 'support': 1132}
 
----------
Epoch 39/40
time = 675.67 secondes

Train loss 0.008411739502049868 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983625627714435, 'recall': 0.9984539581446207, 'f1-score': 0.9984063915504502, 'support': 10182} weighted_avg {'precision': 0.9984308764873713, 'recall': 0.9984285994892949, 'f1-score': 0.9984279634692939, 'support': 10182}
 
time = 27.05 secondes

Val loss 0.6490206598372052 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321141625342501, 'recall': 0.9294347603772039, 'f1-score': 0.9295096020090323, 'support': 1132} weighted_avg {'precision': 0.9305246573801035, 'recall': 0.9284452296819788, 'f1-score': 0.9282465783053647, 'support': 1132}
 
----------
Epoch 40/40
time = 678.91 secondes

Train loss 0.004953109803582936 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991551314033231, 'recall': 0.9991605277080037, 'f1-score': 0.9991572201615794, 'support': 10182} weighted_avg {'precision': 0.9991170055431035, 'recall': 0.9991160872127284, 'f1-score': 0.9991159056042657, 'support': 10182}
 
time = 27.57 secondes

Val loss 0.635465871139184 accuracy 0.9310954213142395 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}
 
----------
best_accuracy 0.9310954213142395 best_epoch 40 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}

average train time 664.97757076025

average val time 25.108302837610246
 
time = 177.83 secondes

test_accuracy 0.8637811541557312 macro_avg {'precision': 0.8619622881992794, 'recall': 0.8568902043892187, 'f1-score': 0.8573933439667325, 'support': 7532} weighted_avg {'precision': 0.8669934848523781, 'recall': 0.863781200212427, 'f1-score': 0.8635495729265222, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_4
----------
Epoch 1/40
time = 904.45 secondes

Train loss 1.085930619523327 accuracy 0.6867020726203918 macro_avg {'precision': 0.6865075689896771, 'recall': 0.6737792097754312, 'f1-score': 0.6700662454551063, 'support': 10182} weighted_avg {'precision': 0.6905970792110961, 'recall': 0.6867020231781575, 'f1-score': 0.6805359750626276, 'support': 10182}
 
time = 32.97 secondes

Val loss 0.5193957160686103 accuracy 0.8462897539138794 macro_avg {'precision': 0.8412125670626283, 'recall': 0.8402299982502687, 'f1-score': 0.8376936715326793, 'support': 1132} weighted_avg {'precision': 0.843922428205379, 'recall': 0.8462897526501767, 'f1-score': 0.842413568276659, 'support': 1132}
 
----------
Epoch 2/40
time = 895.94 secondes

Train loss 0.3838968490202161 accuracy 0.8871538043022156 macro_avg {'precision': 0.8815384222332305, 'recall': 0.8801776800723407, 'f1-score': 0.8803636926429504, 'support': 10182} weighted_avg {'precision': 0.8864567932606825, 'recall': 0.8871538008249853, 'f1-score': 0.8864063484907485, 'support': 10182}
 
time = 31.86 secondes

Val loss 0.41492575365053097 accuracy 0.8966431021690369 macro_avg {'precision': 0.8999323251246455, 'recall': 0.8975723282585276, 'f1-score': 0.8956750378397782, 'support': 1132} weighted_avg {'precision': 0.9005802693326558, 'recall': 0.8966431095406361, 'f1-score': 0.895143936676859, 'support': 1132}
 
----------
Epoch 3/40
time = 871.07 secondes

Train loss 0.23415676027746926 accuracy 0.9339029788970947 macro_avg {'precision': 0.9313366144984473, 'recall': 0.931048279689529, 'f1-score': 0.9311270378667762, 'support': 10182} weighted_avg {'precision': 0.9341356114413687, 'recall': 0.933902966018464, 'f1-score': 0.9339549314983527, 'support': 10182}
 
time = 31.74 secondes

Val loss 0.4685395577804408 accuracy 0.9028268456459045 macro_avg {'precision': 0.9048725084604504, 'recall': 0.9024120467548313, 'f1-score': 0.9002344086445928, 'support': 1132} weighted_avg {'precision': 0.9050233225133233, 'recall': 0.9028268551236749, 'f1-score': 0.9006327586233528, 'support': 1132}
 
----------
Epoch 4/40
time = 886.40 secondes

Train loss 0.1755128247609283 accuracy 0.9548222422599792 macro_avg {'precision': 0.9531579260691849, 'recall': 0.9528312455868295, 'f1-score': 0.9529470096924959, 'support': 10182} weighted_avg {'precision': 0.9548200036377498, 'recall': 0.9548222353172264, 'f1-score': 0.9547756605009832, 'support': 10182}
 
time = 30.38 secondes

Val loss 0.48899852524472165 accuracy 0.9063604474067688 macro_avg {'precision': 0.9113016963466535, 'recall': 0.9073621871432493, 'f1-score': 0.9063413900703441, 'support': 1132} weighted_avg {'precision': 0.9125648337918182, 'recall': 0.9063604240282686, 'f1-score': 0.9061862724231018, 'support': 1132}
 
----------
Epoch 5/40
time = 889.66 secondes

Train loss 0.15959863709026342 accuracy 0.9608132243156433 macro_avg {'precision': 0.9589868555310874, 'recall': 0.9586793542749328, 'f1-score': 0.9587745556055326, 'support': 10182} weighted_avg {'precision': 0.9607763663144321, 'recall': 0.9608131997642899, 'f1-score': 0.9607364885199169, 'support': 10182}
 
time = 31.15 secondes

Val loss 0.5388715893135104 accuracy 0.9010601043701172 macro_avg {'precision': 0.907591546568366, 'recall': 0.9013343999069345, 'f1-score': 0.9010584883871751, 'support': 1132} weighted_avg {'precision': 0.908005280658987, 'recall': 0.901060070671378, 'f1-score': 0.9011480861926803, 'support': 1132}
 
----------
Epoch 6/40
time = 888.10 secondes

Train loss 0.1381628696523092 accuracy 0.9673934578895569 macro_avg {'precision': 0.9665400416858814, 'recall': 0.9665452750523024, 'f1-score': 0.9664698139836971, 'support': 10182} weighted_avg {'precision': 0.9676099019947199, 'recall': 0.9673934394028678, 'f1-score': 0.967433825158669, 'support': 10182}
 
time = 30.86 secondes

Val loss 0.5589238259396975 accuracy 0.898409903049469 macro_avg {'precision': 0.9107780061389394, 'recall': 0.8990560839242434, 'f1-score': 0.9005934197614881, 'support': 1132} weighted_avg {'precision': 0.9088274890381041, 'recall': 0.8984098939929329, 'f1-score': 0.899540464371059, 'support': 1132}
 
----------
Epoch 7/40
time = 886.07 secondes

Train loss 0.12212684896103511 accuracy 0.9725987315177917 macro_avg {'precision': 0.972092109588592, 'recall': 0.9722323636192046, 'f1-score': 0.9721184211638796, 'support': 10182} weighted_avg {'precision': 0.9727148341507819, 'recall': 0.9725987035945787, 'f1-score': 0.9726144256906292, 'support': 10182}
 
time = 32.09 secondes

Val loss 0.5849548677535085 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126284591765751, 'recall': 0.9094974132947063, 'f1-score': 0.9083472707306803, 'support': 1132} weighted_avg {'precision': 0.9124542703248095, 'recall': 0.9081272084805654, 'f1-score': 0.9073014295784437, 'support': 1132}
 
----------
Epoch 8/40
time = 886.88 secondes

Train loss 0.11177829492930762 accuracy 0.9741701483726501 macro_avg {'precision': 0.973594696465962, 'recall': 0.9734491551783859, 'f1-score': 0.9734950780435249, 'support': 10182} weighted_avg {'precision': 0.974196918075608, 'recall': 0.9741701041052838, 'f1-score': 0.9741565543818885, 'support': 10182}
 
time = 31.16 secondes

Val loss 0.5017699991921816 accuracy 0.9204947352409363 macro_avg {'precision': 0.9244479644558574, 'recall': 0.9198750978312731, 'f1-score': 0.918678550890413, 'support': 1132} weighted_avg {'precision': 0.9249164074099199, 'recall': 0.9204946996466431, 'f1-score': 0.9196652619276384, 'support': 1132}
 
----------
Epoch 9/40
time = 881.07 secondes

Train loss 0.11146013088578437 accuracy 0.9759379625320435 macro_avg {'precision': 0.9750177619936367, 'recall': 0.97545290705052, 'f1-score': 0.9751860900778242, 'support': 10182} weighted_avg {'precision': 0.9759976803279738, 'recall': 0.9759379296798272, 'f1-score': 0.9759226007932119, 'support': 10182}
 
time = 31.52 secondes

Val loss 0.7485236363833062 accuracy 0.879858672618866 macro_avg {'precision': 0.896906504806414, 'recall': 0.8720591196309572, 'f1-score': 0.8712675490746763, 'support': 1132} weighted_avg {'precision': 0.896645497634433, 'recall': 0.8798586572438163, 'f1-score': 0.8778132357248053, 'support': 1132}
 
----------
Epoch 10/40
time = 888.16 secondes

Train loss 0.11016958717904105 accuracy 0.9777057766914368 macro_avg {'precision': 0.9767650159952659, 'recall': 0.9770413140656095, 'f1-score': 0.9768544129001375, 'support': 10182} weighted_avg {'precision': 0.9778079420816265, 'recall': 0.9777057552543704, 'f1-score': 0.9777171184522614, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.6425116605991924 accuracy 0.9107773900032043 macro_avg {'precision': 0.9217270403779807, 'recall': 0.9112960560306606, 'f1-score': 0.9132886534816338, 'support': 1132} weighted_avg {'precision': 0.9197899578043967, 'recall': 0.9107773851590106, 'f1-score': 0.9120199309815973, 'support': 1132}
 
----------
Epoch 11/40
time = 887.69 secondes

Train loss 0.10249908830617076 accuracy 0.9800629019737244 macro_avg {'precision': 0.9795009061695769, 'recall': 0.9797302742176737, 'f1-score': 0.9795970230580796, 'support': 10182} weighted_avg {'precision': 0.9800965897243733, 'recall': 0.9800628560204282, 'f1-score': 0.9800632197023552, 'support': 10182}
 
time = 31.40 secondes

Val loss 0.5195122392418545 accuracy 0.9196113348007202 macro_avg {'precision': 0.9222364650195294, 'recall': 0.9228078046566048, 'f1-score': 0.9214777802676926, 'support': 1132} weighted_avg {'precision': 0.9229993100415419, 'recall': 0.9196113074204947, 'f1-score': 0.9202951152689185, 'support': 1132}
 
----------
Epoch 12/40
time = 884.34 secondes

Train loss 0.09942209077085674 accuracy 0.9806521534919739 macro_avg {'precision': 0.9799102835107767, 'recall': 0.9796952108777759, 'f1-score': 0.9797671273381034, 'support': 10182} weighted_avg {'precision': 0.9806918441615122, 'recall': 0.9806521312119426, 'f1-score': 0.9806387957507825, 'support': 10182}
 
time = 31.12 secondes

Val loss 0.7199064678589168 accuracy 0.9045936465263367 macro_avg {'precision': 0.9142361637909909, 'recall': 0.9044086756644818, 'f1-score': 0.9064587066213372, 'support': 1132} weighted_avg {'precision': 0.9139669927240228, 'recall': 0.9045936395759717, 'f1-score': 0.9062910000462504, 'support': 1132}
 
----------
Epoch 13/40
time = 892.53 secondes

Train loss 0.10019335445704515 accuracy 0.9812414646148682 macro_avg {'precision': 0.9800448220615527, 'recall': 0.9804267281056586, 'f1-score': 0.9802047141721688, 'support': 10182} weighted_avg {'precision': 0.9813307964791219, 'recall': 0.981241406403457, 'f1-score': 0.9812596499994694, 'support': 10182}
 
time = 31.14 secondes

Val loss 0.8165900552287472 accuracy 0.8878092169761658 macro_avg {'precision': 0.9011281371267614, 'recall': 0.8852364533612294, 'f1-score': 0.8864581928861661, 'support': 1132} weighted_avg {'precision': 0.8986244409402355, 'recall': 0.8878091872791519, 'f1-score': 0.8867222613745912, 'support': 1132}
 
----------
Epoch 14/40
time = 849.97 secondes

Train loss 0.09773514877786488 accuracy 0.9814378619194031 macro_avg {'precision': 0.9813610444115877, 'recall': 0.9810298890042756, 'f1-score': 0.9811697066823106, 'support': 10182} weighted_avg {'precision': 0.9814497264505064, 'recall': 0.9814378314672952, 'f1-score': 0.9814182077101277, 'support': 10182}
 
time = 23.76 secondes

Val loss 0.8164968457526747 accuracy 0.8913427591323853 macro_avg {'precision': 0.9014434343927695, 'recall': 0.8960916809256038, 'f1-score': 0.8927996249156402, 'support': 1132} weighted_avg {'precision': 0.9050721572627863, 'recall': 0.8913427561837456, 'f1-score': 0.8917019108997021, 'support': 1132}
 
----------
Epoch 15/40
time = 809.63 secondes

Train loss 0.0852009838246766 accuracy 0.9847770929336548 macro_avg {'precision': 0.984738529277273, 'recall': 0.9845590137659823, 'f1-score': 0.9846202021731381, 'support': 10182} weighted_avg {'precision': 0.9848526790621743, 'recall': 0.9847770575525437, 'f1-score': 0.9847866931252149, 'support': 10182}
 
time = 31.26 secondes

Val loss 0.6942899270814477 accuracy 0.9090105891227722 macro_avg {'precision': 0.9135506304505899, 'recall': 0.9066611815332631, 'f1-score': 0.9088391604208, 'support': 1132} weighted_avg {'precision': 0.9109398970241406, 'recall': 0.9090106007067138, 'f1-score': 0.9087468740851598, 'support': 1132}
 
----------
Epoch 16/40
time = 832.00 secondes

Train loss 0.0820784205051791 accuracy 0.9854645729064941 macro_avg {'precision': 0.9855058740680616, 'recall': 0.985370173621485, 'f1-score': 0.9853833692723507, 'support': 10182} weighted_avg {'precision': 0.9855786158729254, 'recall': 0.9854645452759773, 'f1-score': 0.9854654057996362, 'support': 10182}
 
time = 31.48 secondes

Val loss 0.6275781476102616 accuracy 0.9125441908836365 macro_avg {'precision': 0.9187629424288086, 'recall': 0.9121109985551719, 'f1-score': 0.9145346774284221, 'support': 1132} weighted_avg {'precision': 0.914260494802553, 'recall': 0.9125441696113075, 'f1-score': 0.9124711805937453, 'support': 1132}
 
----------
Epoch 17/40
time = 847.80 secondes

Train loss 0.08730184219728378 accuracy 0.9851699471473694 macro_avg {'precision': 0.9849575776816355, 'recall': 0.9851428217879704, 'f1-score': 0.9850097983707263, 'support': 10182} weighted_avg {'precision': 0.9852473653884686, 'recall': 0.98516990768022, 'f1-score': 0.9851692857918276, 'support': 10182}
 
time = 25.74 secondes

Val loss 0.7229484111049318 accuracy 0.8992933034896851 macro_avg {'precision': 0.9022305834531945, 'recall': 0.9043702783368799, 'f1-score': 0.8999537426896568, 'support': 1132} weighted_avg {'precision': 0.9069119119456899, 'recall': 0.8992932862190812, 'f1-score': 0.8997867434282643, 'support': 1132}
 
----------
Epoch 18/40
time = 922.10 secondes

Train loss 0.07129670814004269 accuracy 0.9870359897613525 macro_avg {'precision': 0.9866693485698406, 'recall': 0.9871836831129777, 'f1-score': 0.9869032952034905, 'support': 10182} weighted_avg {'precision': 0.9870945904981376, 'recall': 0.9870359457866824, 'f1-score': 0.9870434803235079, 'support': 10182}
 
time = 32.26 secondes

Val loss 0.5969959354033435 accuracy 0.916961133480072 macro_avg {'precision': 0.9259543968350992, 'recall': 0.9205818030305034, 'f1-score': 0.9211064907549019, 'support': 1132} weighted_avg {'precision': 0.9230064219570709, 'recall': 0.9169611307420494, 'f1-score': 0.9177016493579521, 'support': 1132}
 
----------
Epoch 19/40
time = 931.96 secondes

Train loss 0.06571471136292421 accuracy 0.9877234697341919 macro_avg {'precision': 0.9874937388551459, 'recall': 0.987279933565938, 'f1-score': 0.9873746777387578, 'support': 10182} weighted_avg {'precision': 0.9877469769518392, 'recall': 0.9877234335101159, 'f1-score': 0.9877231923755789, 'support': 10182}
 
time = 33.13 secondes

Val loss 0.6810309944031219 accuracy 0.9090105891227722 macro_avg {'precision': 0.9139858929954672, 'recall': 0.9109036378960074, 'f1-score': 0.9107076115090409, 'support': 1132} weighted_avg {'precision': 0.9140579818744584, 'recall': 0.9090106007067138, 'f1-score': 0.9096541664120402, 'support': 1132}
 
----------
Epoch 20/40
time = 824.59 secondes

Train loss 0.06306088293250459 accuracy 0.9881163239479065 macro_avg {'precision': 0.9871770559180423, 'recall': 0.9870661817022851, 'f1-score': 0.9871115766407377, 'support': 10182} weighted_avg {'precision': 0.988111724482609, 'recall': 0.9881162836377921, 'f1-score': 0.9881043287784385, 'support': 10182}
 
time = 25.54 secondes

Val loss 0.6654901082767256 accuracy 0.9187279343605042 macro_avg {'precision': 0.9225022253885852, 'recall': 0.920677766004936, 'f1-score': 0.9199235289990169, 'support': 1132} weighted_avg {'precision': 0.9242391407004176, 'recall': 0.9187279151943463, 'f1-score': 0.9199027903917225, 'support': 1132}
 
----------
Epoch 21/40
time = 749.71 secondes

Train loss 0.05299371498184764 accuracy 0.989589512348175 macro_avg {'precision': 0.9887296085423477, 'recall': 0.988832172725511, 'f1-score': 0.9887677615139981, 'support': 10182} weighted_avg {'precision': 0.9896181715370865, 'recall': 0.9895894716165783, 'f1-score': 0.9895906788751021, 'support': 10182}
 
time = 24.74 secondes

Val loss 0.6802497056125734 accuracy 0.916077733039856 macro_avg {'precision': 0.9187116393897616, 'recall': 0.9179064496880024, 'f1-score': 0.9169774747079489, 'support': 1132} weighted_avg {'precision': 0.9193771327550203, 'recall': 0.916077738515901, 'f1-score': 0.9162875602048626, 'support': 1132}
 
----------
Epoch 22/40
time = 725.42 secondes

Train loss 0.06242271111844973 accuracy 0.9889020323753357 macro_avg {'precision': 0.9881938934300022, 'recall': 0.9881719683330811, 'f1-score': 0.9881682046838465, 'support': 10182} weighted_avg {'precision': 0.9889477766358592, 'recall': 0.9889019838931448, 'f1-score': 0.9889106281827171, 'support': 10182}
 
time = 24.69 secondes

Val loss 0.6513749236457417 accuracy 0.9257950782775879 macro_avg {'precision': 0.93231797412231, 'recall': 0.9238606887022037, 'f1-score': 0.9262688151741167, 'support': 1132} weighted_avg {'precision': 0.9294437721233918, 'recall': 0.9257950530035336, 'f1-score': 0.9258321831296487, 'support': 1132}
 
----------
Epoch 23/40
time = 721.05 secondes

Train loss 0.05685086062583413 accuracy 0.989589512348175 macro_avg {'precision': 0.989066353413764, 'recall': 0.9890039166038262, 'f1-score': 0.9890162405558197, 'support': 10182} weighted_avg {'precision': 0.9896006173984353, 'recall': 0.9895894716165783, 'f1-score': 0.9895767360402349, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7105753186485126 accuracy 0.9178445339202881 macro_avg {'precision': 0.9168506664443754, 'recall': 0.9210171993563337, 'f1-score': 0.9179118569345952, 'support': 1132} weighted_avg {'precision': 0.9189260577429352, 'recall': 0.9178445229681979, 'f1-score': 0.9173579302317096, 'support': 1132}
 
----------
Epoch 24/40
time = 723.17 secondes

Train loss 0.05538533817794597 accuracy 0.9908662438392639 macro_avg {'precision': 0.9909166988481599, 'recall': 0.9908721002456348, 'f1-score': 0.9908853517095133, 'support': 10182} weighted_avg {'precision': 0.990889139086868, 'recall': 0.9908662345315262, 'f1-score': 0.9908684828046269, 'support': 10182}
 
time = 24.35 secondes

Val loss 0.7588620925948112 accuracy 0.9054770469665527 macro_avg {'precision': 0.9111761909126249, 'recall': 0.9089792477308543, 'f1-score': 0.9061665829913517, 'support': 1132} weighted_avg {'precision': 0.9150934313022671, 'recall': 0.9054770318021201, 'f1-score': 0.9061167602309964, 'support': 1132}
 
----------
Epoch 25/40
time = 721.45 secondes

Train loss 0.04196974732863048 accuracy 0.9925358891487122 macro_avg {'precision': 0.9923421609613369, 'recall': 0.9925736264987691, 'f1-score': 0.9924446181074436, 'support': 10182} weighted_avg {'precision': 0.9925696076571987, 'recall': 0.9925358475741505, 'f1-score': 0.9925393657607952, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.6123379302967601 accuracy 0.9302120208740234 macro_avg {'precision': 0.9344926025439475, 'recall': 0.9304099728605759, 'f1-score': 0.9305748284696176, 'support': 1132} weighted_avg {'precision': 0.9345175032134959, 'recall': 0.9302120141342756, 'f1-score': 0.930474416830259, 'support': 1132}
 
----------
Epoch 26/40
time = 720.91 secondes

Train loss 0.04845086469917081 accuracy 0.9909644722938538 macro_avg {'precision': 0.99088961412954, 'recall': 0.9908579582373319, 'f1-score': 0.9908559577983175, 'support': 10182} weighted_avg {'precision': 0.990990255554527, 'recall': 0.9909644470634453, 'f1-score': 0.9909593388301886, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.6515468313973799 accuracy 0.9187279343605042 macro_avg {'precision': 0.9235763965287459, 'recall': 0.9210695551871797, 'f1-score': 0.9206373320575294, 'support': 1132} weighted_avg {'precision': 0.9231579262767182, 'recall': 0.9187279151943463, 'f1-score': 0.9191803382565835, 'support': 1132}
 
----------
Epoch 27/40
time = 746.80 secondes

Train loss 0.04168468048204432 accuracy 0.9928305149078369 macro_avg {'precision': 0.9925499255606015, 'recall': 0.9925200415637796, 'f1-score': 0.992529032890555, 'support': 10182} weighted_avg {'precision': 0.9928395079606481, 'recall': 0.9928304851699077, 'f1-score': 0.9928292377396122, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.6601591920423769 accuracy 0.9204947352409363 macro_avg {'precision': 0.9224227821208183, 'recall': 0.9214949051296937, 'f1-score': 0.9204901465424513, 'support': 1132} weighted_avg {'precision': 0.9239788503292518, 'recall': 0.9204946996466431, 'f1-score': 0.9206783818597479, 'support': 1132}
 
----------
Epoch 28/40
time = 985.60 secondes

Train loss 0.03838881240947985 accuracy 0.993812620639801 macro_avg {'precision': 0.9935769595247766, 'recall': 0.9935652362701312, 'f1-score': 0.9935642935237002, 'support': 10182} weighted_avg {'precision': 0.9938296889935495, 'recall': 0.9938126104890984, 'f1-score': 0.9938145105010365, 'support': 10182}
 
time = 34.95 secondes

Val loss 0.860883043595966 accuracy 0.8992933034896851 macro_avg {'precision': 0.9024835600071854, 'recall': 0.9033449379728232, 'f1-score': 0.8984828133129075, 'support': 1132} weighted_avg {'precision': 0.9079316562062043, 'recall': 0.8992932862190812, 'f1-score': 0.8990663151226878, 'support': 1132}
 
----------
Epoch 29/40
time = 1038.42 secondes

Train loss 0.04060292713660561 accuracy 0.993714451789856 macro_avg {'precision': 0.9937117463797953, 'recall': 0.9938319781744969, 'f1-score': 0.9937672216812059, 'support': 10182} weighted_avg {'precision': 0.9937201588059923, 'recall': 0.9937143979571793, 'f1-score': 0.9937126857096119, 'support': 10182}
 
time = 27.09 secondes

Val loss 0.6890976755303584 accuracy 0.9213780760765076 macro_avg {'precision': 0.922281037142921, 'recall': 0.9222590680862274, 'f1-score': 0.9203910822765398, 'support': 1132} weighted_avg {'precision': 0.9267961509911602, 'recall': 0.9213780918727915, 'f1-score': 0.922214289591987, 'support': 1132}
 
----------
Epoch 30/40
time = 858.29 secondes

Train loss 0.031173711125298934 accuracy 0.994892954826355 macro_avg {'precision': 0.994535827873061, 'recall': 0.9947610278644549, 'f1-score': 0.994641772197798, 'support': 10182} weighted_avg {'precision': 0.9949075764601065, 'recall': 0.9948929483402082, 'f1-score': 0.9948949755322696, 'support': 10182}
 
time = 34.05 secondes

Val loss 0.5181108321646117 accuracy 0.9381625652313232 macro_avg {'precision': 0.9397061516426184, 'recall': 0.9385536350939858, 'f1-score': 0.9385425372008287, 'support': 1132} weighted_avg {'precision': 0.9395799989536734, 'recall': 0.9381625441696113, 'f1-score': 0.9383633479438508, 'support': 1132}
 
----------
Epoch 31/40
time = 941.53 secondes

Train loss 0.030867749507702037 accuracy 0.993714451789856 macro_avg {'precision': 0.9937514821204327, 'recall': 0.9938023578428083, 'f1-score': 0.9937638990889566, 'support': 10182} weighted_avg {'precision': 0.9937537063880632, 'recall': 0.9937143979571793, 'f1-score': 0.993721086007801, 'support': 10182}
 
time = 33.27 secondes

Val loss 0.5612273408090991 accuracy 0.9337455630302429 macro_avg {'precision': 0.9359974509163143, 'recall': 0.93484449411371, 'f1-score': 0.9345026692250284, 'support': 1132} weighted_avg {'precision': 0.935810554555756, 'recall': 0.9337455830388692, 'f1-score': 0.9338709052223133, 'support': 1132}
 
----------
Epoch 32/40
time = 899.15 secondes

Train loss 0.02310575361171605 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963257524786006, 'recall': 0.9964232535783323, 'f1-score': 0.9963725519896849, 'support': 10182} weighted_avg {'precision': 0.9963712110158622, 'recall': 0.9963661363189943, 'f1-score': 0.9963668141470821, 'support': 10182}
 
time = 27.42 secondes

Val loss 0.5719641888216769 accuracy 0.9231448769569397 macro_avg {'precision': 0.9232094713707418, 'recall': 0.9252079619270377, 'f1-score': 0.9229192758373415, 'support': 1132} weighted_avg {'precision': 0.9260076461693314, 'recall': 0.9231448763250883, 'f1-score': 0.9232811127704171, 'support': 1132}
 
----------
Epoch 33/40
time = 802.84 secondes

Train loss 0.02288988167023907 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961711895226604, 'recall': 0.9960872234544421, 'f1-score': 0.9961276667985807, 'support': 10182} weighted_avg {'precision': 0.9960728919332007, 'recall': 0.9960714987232371, 'f1-score': 0.9960707790937092, 'support': 10182}
 
time = 25.43 secondes

Val loss 0.570196613516549 accuracy 0.9284452199935913 macro_avg {'precision': 0.930398041129781, 'recall': 0.9314545608623694, 'f1-score': 0.9302127048762674, 'support': 1132} weighted_avg {'precision': 0.9303285099956946, 'recall': 0.9284452296819788, 'f1-score': 0.9286587977714396, 'support': 1132}
 
----------
Epoch 34/40
time = 729.81 secondes

Train loss 0.022912930652256226 accuracy 0.9958751201629639 macro_avg {'precision': 0.99586094864021, 'recall': 0.996017571352667, 'f1-score': 0.9959375842810543, 'support': 10182} weighted_avg {'precision': 0.995876237591081, 'recall': 0.995875073659399, 'f1-score': 0.9958741272109735, 'support': 10182}
 
time = 25.02 secondes

Val loss 0.6081943999041113 accuracy 0.9293286204338074 macro_avg {'precision': 0.9308768834788852, 'recall': 0.9316163994078817, 'f1-score': 0.9303342030632656, 'support': 1132} weighted_avg {'precision': 0.931874792968735, 'recall': 0.9293286219081273, 'f1-score': 0.929633049931186, 'support': 1132}
 
----------
Epoch 35/40
time = 731.54 secondes

Train loss 0.012990592034385177 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976388217559149, 'recall': 0.9977231060685143, 'f1-score': 0.9976776629397343, 'support': 10182} weighted_avg {'precision': 0.9976510756655848, 'recall': 0.9976428992339422, 'f1-score': 0.9976436215766573, 'support': 10182}
 
time = 25.28 secondes

Val loss 0.5714157906219094 accuracy 0.9390459656715393 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}
 
----------
Epoch 36/40
time = 729.01 secondes

Train loss 0.01833871189036482 accuracy 0.9969554543495178 macro_avg {'precision': 0.996884086841674, 'recall': 0.9969676468006174, 'f1-score': 0.996919469712536, 'support': 10182} weighted_avg {'precision': 0.9969736934344191, 'recall': 0.9969554115105087, 'f1-score': 0.9969581469381175, 'support': 10182}
 
time = 25.98 secondes

Val loss 0.5994078302624267 accuracy 0.9293286204338074 macro_avg {'precision': 0.9299352449609296, 'recall': 0.9315913919887848, 'f1-score': 0.929768704288418, 'support': 1132} weighted_avg {'precision': 0.932670118027193, 'recall': 0.9293286219081273, 'f1-score': 0.9299518385785527, 'support': 1132}
 
----------
Epoch 37/40
time = 729.77 secondes

Train loss 0.011112356264953743 accuracy 0.9982321858406067 macro_avg {'precision': 0.9983171733400937, 'recall': 0.9982307827420612, 'f1-score': 0.9982710723288559, 'support': 10182} weighted_avg {'precision': 0.9982399977390333, 'recall': 0.9982321744254566, 'f1-score': 0.9982331126085662, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.5924408991639109 accuracy 0.9310954213142395 macro_avg {'precision': 0.9338731707688073, 'recall': 0.9336734436606633, 'f1-score': 0.9325406862964474, 'support': 1132} weighted_avg {'precision': 0.935230106640389, 'recall': 0.931095406360424, 'f1-score': 0.9318909013144914, 'support': 1132}
 
----------
Epoch 38/40
time = 728.57 secondes

Train loss 0.007094374627405235 accuracy 0.9985268115997314 macro_avg {'precision': 0.9983785635338565, 'recall': 0.9985166071708447, 'f1-score': 0.9984445929154344, 'support': 10182} weighted_avg {'precision': 0.9985332444686208, 'recall': 0.998526812021214, 'f1-score': 0.9985276773775542, 'support': 10182}
 
time = 25.39 secondes

Val loss 0.6083182109004168 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321705996842805, 'recall': 0.9312106288458313, 'f1-score': 0.9301701070542325, 'support': 1132} weighted_avg {'precision': 0.9331578994457744, 'recall': 0.9284452296819788, 'f1-score': 0.9291780103692845, 'support': 1132}
 
----------
Epoch 39/40
time = 834.23 secondes

Train loss 0.004099554753626863 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990445153619305, 'recall': 0.9990465124100428, 'f1-score': 0.9990450770469763, 'support': 10182} weighted_avg {'precision': 0.9990189772040283, 'recall': 0.9990178746808093, 'f1-score': 0.9990179675363912, 'support': 10182}
 
time = 34.52 secondes

Val loss 0.6324473496378501 accuracy 0.9337455630302429 macro_avg {'precision': 0.9389891292501433, 'recall': 0.9361597063520225, 'f1-score': 0.9362935689683122, 'support': 1132} weighted_avg {'precision': 0.938128479283786, 'recall': 0.9337455830388692, 'f1-score': 0.9345301109424841, 'support': 1132}
 
----------
Epoch 40/40
time = 973.10 secondes

Train loss 0.0029508336193605914 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993654156660551, 'recall': 0.9993890841637985, 'f1-score': 0.9993765447608427, 'support': 10182} weighted_avg {'precision': 0.9994121086721734, 'recall': 0.9994107248084856, 'f1-score': 0.9994107345412815, 'support': 10182}
 
time = 31.97 secondes

Val loss 0.604129914752852 accuracy 0.9337455630302429 macro_avg {'precision': 0.9364403679707334, 'recall': 0.935185174255696, 'f1-score': 0.9349140513727106, 'support': 1132} weighted_avg {'precision': 0.9359944263180545, 'recall': 0.9337455830388692, 'f1-score': 0.9339703121737567, 'support': 1132}
 
----------
best_accuracy 0.9390459656715393 best_epoch 35 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}

average train time 841.2686648905277

average val time 29.002124965190887
 
time = 199.06 secondes

test_accuracy 0.8559479117393494 macro_avg {'precision': 0.853801041312529, 'recall': 0.8495474935062125, 'f1-score': 0.8497281728064007, 'support': 7532} weighted_avg {'precision': 0.8607974784860157, 'recall': 0.8559479553903345, 'f1-score': 0.8564545903716746, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_4
----------
Epoch 1/40
time = 1224.70 secondes

Train loss 1.173128953370232 accuracy 0.6593989729881287 macro_avg {'precision': 0.662829769087903, 'recall': 0.6455535306271434, 'f1-score': 0.6410237550364425, 'support': 10182} weighted_avg {'precision': 0.6703989207273187, 'recall': 0.6593989393046553, 'f1-score': 0.6534405257138537, 'support': 10182}
 
time = 40.74 secondes

Val loss 0.589547368212485 accuracy 0.8242049813270569 macro_avg {'precision': 0.8513547433588059, 'recall': 0.8217635358966021, 'f1-score': 0.8070310135342676, 'support': 1132} weighted_avg {'precision': 0.8448801925737545, 'recall': 0.8242049469964664, 'f1-score': 0.8120437700387597, 'support': 1132}
 
----------
Epoch 2/40
time = 1292.61 secondes

Train loss 0.433301338121833 accuracy 0.8733058571815491 macro_avg {'precision': 0.8652638294358969, 'recall': 0.8641945615311402, 'f1-score': 0.8636283597576035, 'support': 10182} weighted_avg {'precision': 0.8718183863417169, 'recall': 0.873305833824396, 'f1-score': 0.8717080931309271, 'support': 10182}
 
time = 37.63 secondes

Val loss 0.5033257722224987 accuracy 0.8648409843444824 macro_avg {'precision': 0.8691521618456436, 'recall': 0.8624626086280799, 'f1-score': 0.8593810526738238, 'support': 1132} weighted_avg {'precision': 0.8751966966445278, 'recall': 0.8648409893992933, 'f1-score': 0.8635484994452928, 'support': 1132}
 
----------
Epoch 3/40
time = 1168.28 secondes

Train loss 0.26697434020467 accuracy 0.9230996370315552 macro_avg {'precision': 0.9188650171477862, 'recall': 0.9178367231555937, 'f1-score': 0.9181392721051699, 'support': 10182} weighted_avg {'precision': 0.9230208678322049, 'recall': 0.923099587507366, 'f1-score': 0.9228604440474881, 'support': 10182}
 
time = 31.54 secondes

Val loss 0.4773428943139357 accuracy 0.8878092169761658 macro_avg {'precision': 0.8893159478547924, 'recall': 0.8901384851693358, 'f1-score': 0.8843182079086016, 'support': 1132} weighted_avg {'precision': 0.8957682804469341, 'recall': 0.8878091872791519, 'f1-score': 0.8856897656047938, 'support': 1132}
 
----------
Epoch 4/40
time = 1113.69 secondes

Train loss 0.1947178938616143 accuracy 0.9453938603401184 macro_avg {'precision': 0.9427466024270726, 'recall': 0.9425265062203646, 'f1-score': 0.9425725025417689, 'support': 10182} weighted_avg {'precision': 0.945480084806776, 'recall': 0.9453938322529954, 'f1-score': 0.9453761839551973, 'support': 10182}
 
time = 30.97 secondes

Val loss 0.4491022658881954 accuracy 0.8948763608932495 macro_avg {'precision': 0.8996512456924854, 'recall': 0.8927313125982309, 'f1-score': 0.8921173758259456, 'support': 1132} weighted_avg {'precision': 0.9011924365315521, 'recall': 0.8948763250883393, 'f1-score': 0.893673234573963, 'support': 1132}
 
----------
Epoch 5/40
time = 1115.33 secondes

Train loss 0.1558833939708284 accuracy 0.9604203701019287 macro_avg {'precision': 0.9585975356538083, 'recall': 0.9587788823766434, 'f1-score': 0.9586219752270683, 'support': 10182} weighted_avg {'precision': 0.960574103478398, 'recall': 0.9604203496366136, 'f1-score': 0.9604363157078126, 'support': 10182}
 
time = 30.81 secondes

Val loss 0.4840479651088892 accuracy 0.9045936465263367 macro_avg {'precision': 0.9110295516794489, 'recall': 0.9027701981303082, 'f1-score': 0.9039572929440777, 'support': 1132} weighted_avg {'precision': 0.9100952857362941, 'recall': 0.9045936395759717, 'f1-score': 0.9046826167520323, 'support': 1132}
 
----------
Epoch 6/40
time = 1112.66 secondes

Train loss 0.13205229320740283 accuracy 0.9665095806121826 macro_avg {'precision': 0.9654723418428794, 'recall': 0.964841858873853, 'f1-score': 0.9651167315236387, 'support': 10182} weighted_avg {'precision': 0.966505152875396, 'recall': 0.9665095266155962, 'f1-score': 0.9664729666915374, 'support': 10182}
 
time = 29.48 secondes

Val loss 0.5088391571230269 accuracy 0.9045936465263367 macro_avg {'precision': 0.9130306601038022, 'recall': 0.901036550177752, 'f1-score': 0.9037126908571272, 'support': 1132} weighted_avg {'precision': 0.9090787836056673, 'recall': 0.9045936395759717, 'f1-score': 0.9036050004244318, 'support': 1132}
 
----------
Epoch 7/40
time = 1180.33 secondes

Train loss 0.1275869197653697 accuracy 0.968375563621521 macro_avg {'precision': 0.9671232772670066, 'recall': 0.9670273626391609, 'f1-score': 0.9670436412078562, 'support': 10182} weighted_avg {'precision': 0.968415866768847, 'recall': 0.9683755647220585, 'f1-score': 0.9683656847802719, 'support': 10182}
 
time = 41.00 secondes

Val loss 0.5309758744764955 accuracy 0.9116607904434204 macro_avg {'precision': 0.9187587319013115, 'recall': 0.9118835917962625, 'f1-score': 0.9130421130537897, 'support': 1132} weighted_avg {'precision': 0.917786147161771, 'recall': 0.911660777385159, 'f1-score': 0.9122863957441552, 'support': 1132}
 
----------
Epoch 8/40
time = 1282.49 secondes

Train loss 0.12002114570318403 accuracy 0.9730898141860962 macro_avg {'precision': 0.9723695992863715, 'recall': 0.9725255250033399, 'f1-score': 0.9724196049338719, 'support': 10182} weighted_avg {'precision': 0.9731267731823616, 'recall': 0.973089766254174, 'f1-score': 0.973079996811068, 'support': 10182}
 
time = 33.48 secondes

Val loss 0.610222482664796 accuracy 0.9010601043701172 macro_avg {'precision': 0.9083310837239571, 'recall': 0.9017994046940101, 'f1-score': 0.902471061050858, 'support': 1132} weighted_avg {'precision': 0.9061301049524046, 'recall': 0.901060070671378, 'f1-score': 0.9010895163950153, 'support': 1132}
 
----------
Epoch 9/40
time = 1246.58 secondes

Train loss 0.11085762805689209 accuracy 0.9742683172225952 macro_avg {'precision': 0.973686279384073, 'recall': 0.9738118937993816, 'f1-score': 0.9736728343620366, 'support': 10182} weighted_avg {'precision': 0.9744314222238106, 'recall': 0.9742683166372029, 'f1-score': 0.974272621149981, 'support': 10182}
 
time = 39.99 secondes

Val loss 0.7214796951718622 accuracy 0.8895759582519531 macro_avg {'precision': 0.8994128375388721, 'recall': 0.8895234200606467, 'f1-score': 0.8872931770524671, 'support': 1132} weighted_avg {'precision': 0.8976454810010577, 'recall': 0.8895759717314488, 'f1-score': 0.8870161223513768, 'support': 1132}
 
----------
Epoch 10/40
time = 1275.10 secondes

Train loss 0.10936332721249646 accuracy 0.9776075482368469 macro_avg {'precision': 0.9767742980562198, 'recall': 0.9769731977042383, 'f1-score': 0.9768160730254177, 'support': 10182} weighted_avg {'precision': 0.9777560649362148, 'recall': 0.9776075427224514, 'f1-score': 0.9776304879429484, 'support': 10182}
 
time = 32.49 secondes

Val loss 0.7261400397065174 accuracy 0.8922261595726013 macro_avg {'precision': 0.9029049154363806, 'recall': 0.8845884143093088, 'f1-score': 0.8869576307269895, 'support': 1132} weighted_avg {'precision': 0.8992483930448251, 'recall': 0.892226148409894, 'f1-score': 0.8902926862224189, 'support': 1132}
 
----------
Epoch 11/40
time = 1173.23 secondes

Train loss 0.1113884581535153 accuracy 0.9768218994140625 macro_avg {'precision': 0.9764015273357499, 'recall': 0.9762835552114361, 'f1-score': 0.9763053778161573, 'support': 10182} weighted_avg {'precision': 0.976946745757334, 'recall': 0.9768218424670988, 'f1-score': 0.9768490430920068, 'support': 10182}
 
time = 29.82 secondes

Val loss 0.7375211480754497 accuracy 0.8913427591323853 macro_avg {'precision': 0.9034405375273469, 'recall': 0.8937246809433292, 'f1-score': 0.894844329996282, 'support': 1132} weighted_avg {'precision': 0.900602132890465, 'recall': 0.8913427561837456, 'f1-score': 0.8919937340788233, 'support': 1132}
 
----------
Epoch 12/40
time = 1108.55 secondes

Train loss 0.08710213793374764 accuracy 0.9813396334648132 macro_avg {'precision': 0.9806174222910761, 'recall': 0.9803114936494837, 'f1-score': 0.9804177817813814, 'support': 10182} weighted_avg {'precision': 0.9813525144951474, 'recall': 0.9813396189353761, 'f1-score': 0.9812990831162066, 'support': 10182}
 
time = 29.72 secondes

Val loss 0.6837542199695312 accuracy 0.9054770469665527 macro_avg {'precision': 0.909983083412181, 'recall': 0.9059370038583193, 'f1-score': 0.9062647942244851, 'support': 1132} weighted_avg {'precision': 0.9097723472290224, 'recall': 0.9054770318021201, 'f1-score': 0.9061650393385801, 'support': 1132}
 
----------
Epoch 13/40
time = 1090.41 secondes

Train loss 0.09975643206413436 accuracy 0.9794735908508301 macro_avg {'precision': 0.9785171435016073, 'recall': 0.9787878927846843, 'f1-score': 0.9786211459867573, 'support': 10182} weighted_avg {'precision': 0.9795479839719737, 'recall': 0.9794735808289138, 'f1-score': 0.9794798817304826, 'support': 10182}
 
time = 29.36 secondes

Val loss 0.7395239552113221 accuracy 0.9028268456459045 macro_avg {'precision': 0.9065318876715376, 'recall': 0.9018933300113309, 'f1-score': 0.9010727985620935, 'support': 1132} weighted_avg {'precision': 0.9090351744299293, 'recall': 0.9028268551236749, 'f1-score': 0.9032605624516509, 'support': 1132}
 
----------
Epoch 14/40
time = 1072.60 secondes

Train loss 0.1041517634550082 accuracy 0.9807503819465637 macro_avg {'precision': 0.9803118434347358, 'recall': 0.9801581158287969, 'f1-score': 0.9802194703977467, 'support': 10182} weighted_avg {'precision': 0.9807725229012776, 'recall': 0.9807503437438617, 'f1-score': 0.9807480826984695, 'support': 10182}
 
time = 29.57 secondes

Val loss 0.6951771441406019 accuracy 0.9010601043701172 macro_avg {'precision': 0.9098368210121406, 'recall': 0.9074688763014256, 'f1-score': 0.9055443756944952, 'support': 1132} weighted_avg {'precision': 0.912072516182919, 'recall': 0.901060070671378, 'f1-score': 0.9034544070036912, 'support': 1132}
 
----------
Epoch 15/40
time = 1134.67 secondes

Train loss 0.09907813972971798 accuracy 0.9801610708236694 macro_avg {'precision': 0.9803470345623824, 'recall': 0.9801084447512854, 'f1-score': 0.9801644759369725, 'support': 10182} weighted_avg {'precision': 0.9802926297436175, 'recall': 0.9801610685523473, 'f1-score': 0.9801619759530473, 'support': 10182}
 
time = 39.75 secondes

Val loss 0.5585858548846273 accuracy 0.9116607904434204 macro_avg {'precision': 0.9143666532188124, 'recall': 0.9137448242853597, 'f1-score': 0.9113943401124687, 'support': 1132} weighted_avg {'precision': 0.9161052805227066, 'recall': 0.911660777385159, 'f1-score': 0.9111157622126106, 'support': 1132}
 
----------
Epoch 16/40
time = 1285.49 secondes

Train loss 0.07078671759552596 accuracy 0.9845806360244751 macro_avg {'precision': 0.9846564197876992, 'recall': 0.9847336787844652, 'f1-score': 0.9846853312421416, 'support': 10182} weighted_avg {'precision': 0.9845912730323304, 'recall': 0.9845806324887055, 'f1-score': 0.9845762128402021, 'support': 10182}
 
time = 35.27 secondes

Val loss 0.6790391367095241 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116774105898218, 'recall': 0.9044757834425546, 'f1-score': 0.9051812447696526, 'support': 1132} weighted_avg {'precision': 0.9105562910558808, 'recall': 0.9054770318021201, 'f1-score': 0.9052724476469872, 'support': 1132}
 
----------
Epoch 17/40
time = 1149.65 secondes

Train loss 0.08262343541803543 accuracy 0.98448246717453 macro_avg {'precision': 0.9838758636884674, 'recall': 0.983824785192455, 'f1-score': 0.9838377657089625, 'support': 10182} weighted_avg {'precision': 0.9845032314147716, 'recall': 0.9844824199567865, 'f1-score': 0.9844806506245479, 'support': 10182}
 
time = 28.90 secondes

Val loss 0.6675969711099062 accuracy 0.9098939895629883 macro_avg {'precision': 0.9175170331290108, 'recall': 0.9137003281628557, 'f1-score': 0.9130973781929667, 'support': 1132} weighted_avg {'precision': 0.9153607333580289, 'recall': 0.9098939929328622, 'f1-score': 0.9101382769290672, 'support': 1132}
 
----------
Epoch 18/40
time = 1237.76 secondes

Train loss 0.07865465861195815 accuracy 0.9847770929336548 macro_avg {'precision': 0.9842677434524223, 'recall': 0.9842331433022877, 'f1-score': 0.9842315516973337, 'support': 10182} weighted_avg {'precision': 0.9847936010201597, 'recall': 0.9847770575525437, 'f1-score': 0.9847667130802006, 'support': 10182}
 
time = 37.34 secondes

Val loss 0.6060551764832114 accuracy 0.916961133480072 macro_avg {'precision': 0.9263419664845014, 'recall': 0.9184225660001063, 'f1-score': 0.9209961047367257, 'support': 1132} weighted_avg {'precision': 0.9223100819699891, 'recall': 0.9169611307420494, 'f1-score': 0.9181423242742753, 'support': 1132}
 
----------
Epoch 19/40
time = 1209.37 secondes

Train loss 0.0673055721901956 accuracy 0.9873306155204773 macro_avg {'precision': 0.9871487143408387, 'recall': 0.9872925660679774, 'f1-score': 0.9872059543505107, 'support': 10182} weighted_avg {'precision': 0.9873643240524663, 'recall': 0.9873305833824396, 'f1-score': 0.9873326691980662, 'support': 10182}
 
time = 27.38 secondes

Val loss 0.6902313331825803 accuracy 0.9098939895629883 macro_avg {'precision': 0.916784055501925, 'recall': 0.9131119592189154, 'f1-score': 0.9135067568208598, 'support': 1132} weighted_avg {'precision': 0.9142045095375844, 'recall': 0.9098939929328622, 'f1-score': 0.9105594024373984, 'support': 1132}
 
----------
Epoch 20/40
time = 1108.04 secondes

Train loss 0.05156581461380206 accuracy 0.9898841381072998 macro_avg {'precision': 0.9898651280787847, 'recall': 0.9898505334572463, 'f1-score': 0.9898508146356513, 'support': 10182} weighted_avg {'precision': 0.989893612300699, 'recall': 0.9898841092123355, 'f1-score': 0.9898816337155468, 'support': 10182}
 
time = 28.30 secondes

Val loss 0.7284231496959249 accuracy 0.9072438478469849 macro_avg {'precision': 0.916677708864943, 'recall': 0.9065174217566927, 'f1-score': 0.9086229362405996, 'support': 1132} weighted_avg {'precision': 0.9147920204142058, 'recall': 0.907243816254417, 'f1-score': 0.9077452447160728, 'support': 1132}
 
----------
Epoch 21/40
time = 1089.44 secondes

Train loss 0.05262981496453508 accuracy 0.9903752207756042 macro_avg {'precision': 0.9897860448009699, 'recall': 0.9898247601087489, 'f1-score': 0.9897978347815505, 'support': 10182} weighted_avg {'precision': 0.9903830221973918, 'recall': 0.9903751718719308, 'f1-score': 0.9903715833742723, 'support': 10182}
 
time = 27.86 secondes

Val loss 0.5405368513932278 accuracy 0.9213780760765076 macro_avg {'precision': 0.922967290604376, 'recall': 0.9231754422651266, 'f1-score': 0.9223770243755471, 'support': 1132} weighted_avg {'precision': 0.9234580836900056, 'recall': 0.9213780918727915, 'f1-score': 0.9217048420196515, 'support': 1132}
 
----------
Epoch 22/40
time = 1085.43 secondes

Train loss 0.07800975690941762 accuracy 0.9861520528793335 macro_avg {'precision': 0.985552763132928, 'recall': 0.9847686519366258, 'f1-score': 0.9851033962781639, 'support': 10182} weighted_avg {'precision': 0.9862185499783711, 'recall': 0.9861520329994107, 'f1-score': 0.98613745173871, 'support': 10182}
 
time = 28.15 secondes

Val loss 0.7695977911254732 accuracy 0.9010601043701172 macro_avg {'precision': 0.9059755189411064, 'recall': 0.9005632335090912, 'f1-score': 0.9007980153053141, 'support': 1132} weighted_avg {'precision': 0.9056162411016176, 'recall': 0.901060070671378, 'f1-score': 0.9009348145572135, 'support': 1132}
 
----------
Epoch 23/40
time = 1079.60 secondes

Train loss 0.05152084587404902 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896574398550466, 'recall': 0.9895832316152815, 'f1-score': 0.9896138818934137, 'support': 10182} weighted_avg {'precision': 0.989898269358908, 'recall': 0.9898841092123355, 'f1-score': 0.9898848755434715, 'support': 10182}
 
time = 30.82 secondes

Val loss 0.7936162035389636 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131990828246564, 'recall': 0.9056719375921614, 'f1-score': 0.9071294265184106, 'support': 1132} weighted_avg {'precision': 0.9096255221803872, 'recall': 0.9028268551236749, 'f1-score': 0.9037552313881405, 'support': 1132}
 
----------
Epoch 24/40
time = 1114.59 secondes

Train loss 0.04399941098220479 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919961057368154, 'recall': 0.9920428267227223, 'f1-score': 0.9920009652372783, 'support': 10182} weighted_avg {'precision': 0.9920978220091236, 'recall': 0.9920447849145551, 'f1-score': 0.9920531696989157, 'support': 10182}
 
time = 40.98 secondes

Val loss 0.8122427599947502 accuracy 0.9028268456459045 macro_avg {'precision': 0.9121225761037076, 'recall': 0.9058953550979032, 'f1-score': 0.905512504831522, 'support': 1132} weighted_avg {'precision': 0.9099222693408211, 'recall': 0.9028268551236749, 'f1-score': 0.9026512794229142, 'support': 1132}
 
----------
Epoch 25/40
time = 1348.57 secondes

Train loss 0.05157633342244607 accuracy 0.9911609292030334 macro_avg {'precision': 0.991235079616599, 'recall': 0.9910128289878702, 'f1-score': 0.9911122496694889, 'support': 10182} weighted_avg {'precision': 0.9911831736760645, 'recall': 0.9911608721272834, 'f1-score': 0.9911614428459055, 'support': 10182}
 
time = 30.44 secondes

Val loss 0.7859033855928713 accuracy 0.9090105891227722 macro_avg {'precision': 0.9183370192209784, 'recall': 0.9097627734904264, 'f1-score': 0.9118822614216973, 'support': 1132} weighted_avg {'precision': 0.913194382116697, 'recall': 0.9090106007067138, 'f1-score': 0.9089501762847121, 'support': 1132}
 
----------
Epoch 26/40
time = 1185.48 secondes

Train loss 0.03815147458516545 accuracy 0.9931251406669617 macro_avg {'precision': 0.9931207056707281, 'recall': 0.9929949659658257, 'f1-score': 0.9930501461758221, 'support': 10182} weighted_avg {'precision': 0.9931428057080325, 'recall': 0.9931251227656649, 'f1-score': 0.9931262692119824, 'support': 10182}
 
time = 40.54 secondes

Val loss 0.7952744145332475 accuracy 0.9037102460861206 macro_avg {'precision': 0.9088168321864577, 'recall': 0.9068121564382429, 'f1-score': 0.9052162969949664, 'support': 1132} weighted_avg {'precision': 0.9104586189376747, 'recall': 0.9037102473498233, 'f1-score': 0.9044359095808839, 'support': 1132}
 
----------
Epoch 27/40
time = 1254.75 secondes

Train loss 0.04687636622501382 accuracy 0.9919465780258179 macro_avg {'precision': 0.9913783057134566, 'recall': 0.9913846991272063, 'f1-score': 0.9913749594686664, 'support': 10182} weighted_avg {'precision': 0.9919659922809686, 'recall': 0.9919465723826361, 'f1-score': 0.9919497431243338, 'support': 10182}
 
time = 40.42 secondes

Val loss 0.7230789358727634 accuracy 0.916961133480072 macro_avg {'precision': 0.9204045652749689, 'recall': 0.9212877533354302, 'f1-score': 0.9197161326455235, 'support': 1132} weighted_avg {'precision': 0.9189325883975328, 'recall': 0.9169611307420494, 'f1-score': 0.9167505934278293, 'support': 1132}
 
----------
Epoch 28/40
time = 1124.97 secondes

Train loss 0.0346876363987369 accuracy 0.993812620639801 macro_avg {'precision': 0.993785827075021, 'recall': 0.9936224631453333, 'f1-score': 0.9936974384926796, 'support': 10182} weighted_avg {'precision': 0.9938255842704584, 'recall': 0.9938126104890984, 'f1-score': 0.9938126507339887, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.7594218039683281 accuracy 0.916077733039856 macro_avg {'precision': 0.9247947601594305, 'recall': 0.9130417711642312, 'f1-score': 0.9149844122186469, 'support': 1132} weighted_avg {'precision': 0.9211981005629416, 'recall': 0.916077738515901, 'f1-score': 0.9152967708359533, 'support': 1132}
 
----------
Epoch 29/40
time = 1081.95 secondes

Train loss 0.029682740100603552 accuracy 0.9943037033081055 macro_avg {'precision': 0.994152605246059, 'recall': 0.9941700468110615, 'f1-score': 0.9941577637436951, 'support': 10182} weighted_avg {'precision': 0.9943066431011253, 'recall': 0.9943036731486937, 'f1-score': 0.9943015746604917, 'support': 10182}
 
time = 30.19 secondes

Val loss 0.6428052852110417 accuracy 0.9187279343605042 macro_avg {'precision': 0.923623845854396, 'recall': 0.9232728062023368, 'f1-score': 0.9216879608226309, 'support': 1132} weighted_avg {'precision': 0.924515784885518, 'recall': 0.9187279151943463, 'f1-score': 0.9198638392432227, 'support': 1132}
 
----------
Epoch 30/40
time = 1074.27 secondes

Train loss 0.04244267715503399 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934845743208314, 'recall': 0.9934108940008418, 'f1-score': 0.993441166493812, 'support': 10182} weighted_avg {'precision': 0.9935294528454889, 'recall': 0.9935179728933412, 'f1-score': 0.99351754358324, 'support': 10182}
 
time = 30.73 secondes

Val loss 0.780875301633092 accuracy 0.9134275913238525 macro_avg {'precision': 0.9190056543572901, 'recall': 0.915465232910684, 'f1-score': 0.9143606560772973, 'support': 1132} weighted_avg {'precision': 0.9205614363350298, 'recall': 0.9134275618374559, 'f1-score': 0.9145049263741012, 'support': 1132}
 
----------
Epoch 31/40
time = 1076.25 secondes

Train loss 0.037834766441223085 accuracy 0.9935179948806763 macro_avg {'precision': 0.9931024802076875, 'recall': 0.9934809968282673, 'f1-score': 0.9932820732796935, 'support': 10182} weighted_avg {'precision': 0.9935412159073012, 'recall': 0.9935179728933412, 'f1-score': 0.993521526366487, 'support': 10182}
 
time = 29.94 secondes

Val loss 0.7062834084915177 accuracy 0.9196113348007202 macro_avg {'precision': 0.9219231256832684, 'recall': 0.9212209318968796, 'f1-score': 0.920578487641141, 'support': 1132} weighted_avg {'precision': 0.9224772180909359, 'recall': 0.9196113074204947, 'f1-score': 0.9201709547124864, 'support': 1132}
 
----------
Epoch 32/40
time = 1083.77 secondes

Train loss 0.02412203981095539 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960304982541324, 'recall': 0.9960496465411574, 'f1-score': 0.9960362633148098, 'support': 10182} weighted_avg {'precision': 0.9961755640010032, 'recall': 0.9961697112551562, 'f1-score': 0.9961691980492696, 'support': 10182}
 
time = 30.89 secondes

Val loss 0.6580886034170247 accuracy 0.9187279343605042 macro_avg {'precision': 0.9228078252720765, 'recall': 0.9221267933109788, 'f1-score': 0.921600794979606, 'support': 1132} weighted_avg {'precision': 0.9211518836347686, 'recall': 0.9187279151943463, 'f1-score': 0.9190321449724921, 'support': 1132}
 
----------
Epoch 33/40
time = 1483.08 secondes

Train loss 0.02530337013519771 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959803073846893, 'recall': 0.9960673795778192, 'f1-score': 0.9960212070872515, 'support': 10182} weighted_avg {'precision': 0.9960757622558254, 'recall': 0.9960714987232371, 'f1-score': 0.9960711430269469, 'support': 10182}
 
time = 53.96 secondes

Val loss 0.6948370012062914 accuracy 0.9222614765167236 macro_avg {'precision': 0.9275029628835825, 'recall': 0.9267365730890184, 'f1-score': 0.9247489970310475, 'support': 1132} weighted_avg {'precision': 0.9268186803404175, 'recall': 0.9222614840989399, 'f1-score': 0.9218882711831319, 'support': 1132}
 
----------
Epoch 34/40
time = 1595.51 secondes

Train loss 0.023037698807479606 accuracy 0.9959732890129089 macro_avg {'precision': 0.9959533744853157, 'recall': 0.9960475313452296, 'f1-score': 0.9959961119491328, 'support': 10182} weighted_avg {'precision': 0.9959823435775503, 'recall': 0.995973286191318, 'f1-score': 0.9959735622130645, 'support': 10182}
 
time = 65.61 secondes

Val loss 0.6623712189526921 accuracy 0.9231448769569397 macro_avg {'precision': 0.9294943267729266, 'recall': 0.9269410391314814, 'f1-score': 0.9272632533574103, 'support': 1132} weighted_avg {'precision': 0.9271176145909381, 'recall': 0.9231448763250883, 'f1-score': 0.9241115349345486, 'support': 1132}
 
----------
Epoch 35/40
time = 1726.40 secondes

Train loss 0.016237483508767716 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973019046787233, 'recall': 0.9973426933472478, 'f1-score': 0.9973190077220812, 'support': 10182} weighted_avg {'precision': 0.9972512226311497, 'recall': 0.9972500491062659, 'f1-score': 0.9972472179248817, 'support': 10182}
 
time = 37.47 secondes

Val loss 0.8065760831423817 accuracy 0.9143109321594238 macro_avg {'precision': 0.9206712506578478, 'recall': 0.917771633361687, 'f1-score': 0.9172342597162807, 'support': 1132} weighted_avg {'precision': 0.9186255959463229, 'recall': 0.9143109540636042, 'f1-score': 0.9144636679258188, 'support': 1132}
 
----------
Epoch 36/40
time = 1370.85 secondes

Train loss 0.025357766442642087 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961844434895871, 'recall': 0.995781970627846, 'f1-score': 0.9959683345671918, 'support': 10182} weighted_avg {'precision': 0.9961005527206787, 'recall': 0.9960714987232371, 'f1-score': 0.9960720771807897, 'support': 10182}
 
time = 32.65 secondes

Val loss 0.6931538505031966 accuracy 0.9204947352409363 macro_avg {'precision': 0.9241523840368053, 'recall': 0.9233341733643927, 'f1-score': 0.9222089538293217, 'support': 1132} weighted_avg {'precision': 0.9233787330782004, 'recall': 0.9204946996466431, 'f1-score': 0.9203009665384038, 'support': 1132}
 
----------
Epoch 37/40
time = 1533.49 secondes

Train loss 0.009452947335321683 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985752726146846, 'recall': 0.9984050155717765, 'f1-score': 0.9984880995518857, 'support': 10182} weighted_avg {'precision': 0.9985299897051066, 'recall': 0.998526812021214, 'f1-score': 0.998526665216976, 'support': 10182}
 
time = 50.69 secondes

Val loss 0.6974155892021885 accuracy 0.9284452199935913 macro_avg {'precision': 0.9307141080246586, 'recall': 0.9309652097008814, 'f1-score': 0.9298610666221713, 'support': 1132} weighted_avg {'precision': 0.9300566201728419, 'recall': 0.9284452296819788, 'f1-score': 0.9281881674613488, 'support': 1132}
 
----------
Epoch 38/40
time = 1139.06 secondes

Train loss 0.0073112805066428985 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985532627046865, 'recall': 0.9985109141219939, 'f1-score': 0.9985313372215815, 'support': 10182} weighted_avg {'precision': 0.9985285375777367, 'recall': 0.998526812021214, 'f1-score': 0.998526968399147, 'support': 10182}
 
time = 29.80 secondes

Val loss 0.69951459828607 accuracy 0.9257950782775879 macro_avg {'precision': 0.9268087234630148, 'recall': 0.9281142214004829, 'f1-score': 0.9264451133408542, 'support': 1132} weighted_avg {'precision': 0.9268198393796826, 'recall': 0.9257950530035336, 'f1-score': 0.9252727130551571, 'support': 1132}
 
----------
Epoch 39/40
time = 1078.94 secondes

Train loss 0.007423831143256576 accuracy 0.9987232685089111 macro_avg {'precision': 0.9985803342149723, 'recall': 0.9986694626825277, 'f1-score': 0.9986238832749494, 'support': 10182} weighted_avg {'precision': 0.9987249263288509, 'recall': 0.9987232370850521, 'f1-score': 0.9987232157191313, 'support': 10182}
 
time = 30.88 secondes

Val loss 0.6638481289054153 accuracy 0.9319788217544556 macro_avg {'precision': 0.9348373272106537, 'recall': 0.9332568964087973, 'f1-score': 0.9331794425757571, 'support': 1132} weighted_avg {'precision': 0.9327407372835154, 'recall': 0.9319787985865724, 'f1-score': 0.931473466176567, 'support': 1132}
 
----------
Epoch 40/40
time = 1263.51 secondes

Train loss 0.0035627700361880585 accuracy 0.9993125200271606 macro_avg {'precision': 0.9993165108132139, 'recall': 0.9993443809685154, 'f1-score': 0.9993299794245303, 'support': 10182} weighted_avg {'precision': 0.9993134876840168, 'recall': 0.9993125122765665, 'f1-score': 0.9993125274778357, 'support': 10182}
 
time = 42.41 secondes

Val loss 0.6577107990499019 accuracy 0.9328622221946716 macro_avg {'precision': 0.9352309384925, 'recall': 0.9348459847930638, 'f1-score': 0.9344182622918487, 'support': 1132} weighted_avg {'precision': 0.93365478118775, 'recall': 0.9328621908127208, 'f1-score': 0.9325864091480177, 'support': 1132}
 
----------
best_accuracy 0.9328622221946716 best_epoch 40 macro_avg {'precision': 0.9352309384925, 'recall': 0.9348459847930638, 'f1-score': 0.9344182622918487, 'support': 1132} weighted_avg {'precision': 0.93365478118775, 'recall': 0.9328621908127208, 'f1-score': 0.9325864091480177, 'support': 1132}

average train time 1209.2859081029892

average val time 34.97829531431198
 
time = 245.03 secondes

test_accuracy 0.8592671155929565 macro_avg {'precision': 0.8576221432779153, 'recall': 0.8515066389187063, 'f1-score': 0.8524181344711739, 'support': 7532} weighted_avg {'precision': 0.8637431675034107, 'recall': 0.8592671269251195, 'f1-score': 0.8593961799461779, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_4
----------
Epoch 1/40
time = 1780.72 secondes

Train loss 1.0643720469398064 accuracy 0.7039874792098999 macro_avg {'precision': 0.7098520090129563, 'recall': 0.6900162844388875, 'f1-score': 0.6874012451445285, 'support': 10182} weighted_avg {'precision': 0.7150777703108269, 'recall': 0.7039874287959144, 'f1-score': 0.6993187386025836, 'support': 10182}
 
time = 40.72 secondes

Val loss 0.5467216497365858 accuracy 0.8445229530334473 macro_avg {'precision': 0.8443550522576124, 'recall': 0.8363342784112959, 'f1-score': 0.8305644143625545, 'support': 1132} weighted_avg {'precision': 0.8461792791696383, 'recall': 0.8445229681978799, 'f1-score': 0.8376852111883878, 'support': 1132}
 
----------
Epoch 2/40
time = 1776.38 secondes

Train loss 0.38912855520891243 accuracy 0.8873502612113953 macro_avg {'precision': 0.8794969423174654, 'recall': 0.8779016208000174, 'f1-score': 0.8776321460039254, 'support': 10182} weighted_avg {'precision': 0.8859913586785148, 'recall': 0.8873502258888234, 'f1-score': 0.8858422880634641, 'support': 10182}
 
time = 38.03 secondes

Val loss 0.39505568416920345 accuracy 0.8931095600128174 macro_avg {'precision': 0.8973329012584484, 'recall': 0.8895347379874783, 'f1-score': 0.8894674889719777, 'support': 1132} weighted_avg {'precision': 0.8974873458484065, 'recall': 0.8931095406360424, 'f1-score': 0.8915729451007552, 'support': 1132}
 
----------
Epoch 3/40
time = 1774.74 secondes

Train loss 0.2307349254371338 accuracy 0.9337065815925598 macro_avg {'precision': 0.9305841345243963, 'recall': 0.9294946966850567, 'f1-score': 0.9298942650734109, 'support': 10182} weighted_avg {'precision': 0.9336974232419126, 'recall': 0.9337065409546258, 'f1-score': 0.9335727029194496, 'support': 10182}
 
time = 40.10 secondes

Val loss 0.426759997769718 accuracy 0.9028268456459045 macro_avg {'precision': 0.9027611558585165, 'recall': 0.9026044566612239, 'f1-score': 0.9010999801627564, 'support': 1132} weighted_avg {'precision': 0.9051464539754898, 'recall': 0.9028268551236749, 'f1-score': 0.9022066568804831, 'support': 1132}
 
----------
Epoch 4/40
time = 1775.98 secondes

Train loss 0.1685318492526215 accuracy 0.9553133249282837 macro_avg {'precision': 0.9533900458105155, 'recall': 0.9532771369260249, 'f1-score': 0.9532895260300911, 'support': 10182} weighted_avg {'precision': 0.9555431537591756, 'recall': 0.9553132979768219, 'f1-score': 0.9553833700299249, 'support': 10182}
 
time = 40.39 secondes

Val loss 0.46442157865016603 accuracy 0.9010601043701172 macro_avg {'precision': 0.9038767638282552, 'recall': 0.8978037807626871, 'f1-score': 0.897961043041651, 'support': 1132} weighted_avg {'precision': 0.9036995648287836, 'recall': 0.901060070671378, 'f1-score': 0.8996564249435034, 'support': 1132}
 
----------
Epoch 5/40
time = 1782.77 secondes

Train loss 0.14712801650023963 accuracy 0.9616971611976624 macro_avg {'precision': 0.960783334934065, 'recall': 0.9602048870520143, 'f1-score': 0.9604520050951088, 'support': 10182} weighted_avg {'precision': 0.9617505897644628, 'recall': 0.9616971125515615, 'f1-score': 0.9616837077684436, 'support': 10182}
 
time = 39.32 secondes

Val loss 0.5588094333373667 accuracy 0.9010601043701172 macro_avg {'precision': 0.9136162106861562, 'recall': 0.9036587939044163, 'f1-score': 0.9021673594944136, 'support': 1132} weighted_avg {'precision': 0.9129368086208927, 'recall': 0.901060070671378, 'f1-score': 0.9000170271498694, 'support': 1132}
 
----------
Epoch 6/40
time = 1770.78 secondes

Train loss 0.13456887333618048 accuracy 0.9677863121032715 macro_avg {'precision': 0.9664619792596383, 'recall': 0.9665718187127578, 'f1-score': 0.9664380013753837, 'support': 10182} weighted_avg {'precision': 0.9678714160774984, 'recall': 0.9677862895305441, 'f1-score': 0.9677544412675972, 'support': 10182}
 
time = 39.73 secondes

Val loss 0.548120071872918 accuracy 0.9037102460861206 macro_avg {'precision': 0.9082116507057922, 'recall': 0.9001590722065288, 'f1-score': 0.9018885276861044, 'support': 1132} weighted_avg {'precision': 0.9057705005257537, 'recall': 0.9037102473498233, 'f1-score': 0.9026026316964354, 'support': 1132}
 
----------
Epoch 7/40
time = 1772.74 secondes

Train loss 0.13785983417351297 accuracy 0.9670006036758423 macro_avg {'precision': 0.9661266080420912, 'recall': 0.9661328972704508, 'f1-score': 0.9661020641320649, 'support': 10182} weighted_avg {'precision': 0.9670366567197477, 'recall': 0.9670005892751915, 'f1-score': 0.966990908899257, 'support': 10182}
 
time = 39.21 secondes

Val loss 0.5659879978055882 accuracy 0.9063604474067688 macro_avg {'precision': 0.9118621001730585, 'recall': 0.9056045632642569, 'f1-score': 0.9067003749155736, 'support': 1132} weighted_avg {'precision': 0.911244844913783, 'recall': 0.9063604240282686, 'f1-score': 0.9067890587665526, 'support': 1132}
 
----------
Epoch 8/40
time = 1773.06 secondes

Train loss 0.11468688705569649 accuracy 0.9740719199180603 macro_avg {'precision': 0.9734831441709183, 'recall': 0.9737468251828165, 'f1-score': 0.9735820076483982, 'support': 10182} weighted_avg {'precision': 0.9741792292535091, 'recall': 0.9740718915733647, 'f1-score': 0.9740941670299851, 'support': 10182}
 
time = 39.96 secondes

Val loss 0.5501768905571072 accuracy 0.9125441908836365 macro_avg {'precision': 0.9145581890910096, 'recall': 0.9117049386903269, 'f1-score': 0.9113897116518246, 'support': 1132} weighted_avg {'precision': 0.9157344965396166, 'recall': 0.9125441696113075, 'f1-score': 0.9123848964520049, 'support': 1132}
 
----------
Epoch 9/40
time = 1769.79 secondes

Train loss 0.10950061088138051 accuracy 0.977411150932312 macro_avg {'precision': 0.9767868736866274, 'recall': 0.9767516909924765, 'f1-score': 0.9766992812630344, 'support': 10182} weighted_avg {'precision': 0.977529005494187, 'recall': 0.9774111176586132, 'f1-score': 0.9774067054051321, 'support': 10182}
 
time = 39.72 secondes

Val loss 0.840447043417953 accuracy 0.8860424160957336 macro_avg {'precision': 0.9024769238725782, 'recall': 0.8876485758755688, 'f1-score': 0.8887104718728193, 'support': 1132} weighted_avg {'precision': 0.9023537947389936, 'recall': 0.8860424028268551, 'f1-score': 0.8878424295408067, 'support': 1132}
 
----------
Epoch 10/40
time = 1769.47 secondes

Train loss 0.11759779568918026 accuracy 0.9764290452003479 macro_avg {'precision': 0.9758893725768216, 'recall': 0.9756711998895711, 'f1-score': 0.9757399864704492, 'support': 10182} weighted_avg {'precision': 0.9764877862687028, 'recall': 0.9764289923394225, 'f1-score': 0.9764185979893668, 'support': 10182}
 
time = 39.46 secondes

Val loss 0.70774396617928 accuracy 0.9010601043701172 macro_avg {'precision': 0.9036299453966334, 'recall': 0.8979904500522344, 'f1-score': 0.89634361949253, 'support': 1132} weighted_avg {'precision': 0.9048492059787397, 'recall': 0.901060070671378, 'f1-score': 0.898812569662735, 'support': 1132}
 
----------
Epoch 11/40
time = 1770.27 secondes

Train loss 0.11773652320973878 accuracy 0.9780004024505615 macro_avg {'precision': 0.9773414349445032, 'recall': 0.9774182702865375, 'f1-score': 0.9773550377849162, 'support': 10182} weighted_avg {'precision': 0.9780723620254086, 'recall': 0.9780003928501276, 'f1-score': 0.9780123679428812, 'support': 10182}
 
time = 39.13 secondes

Val loss 0.6567598895867057 accuracy 0.9072438478469849 macro_avg {'precision': 0.9149985681286992, 'recall': 0.9076223292984247, 'f1-score': 0.9076679696791633, 'support': 1132} weighted_avg {'precision': 0.9134142550001108, 'recall': 0.907243816254417, 'f1-score': 0.9066630379409457, 'support': 1132}
 
----------
Epoch 12/40
time = 1772.79 secondes

Train loss 0.09454892972800215 accuracy 0.981634259223938 macro_avg {'precision': 0.9810302775938874, 'recall': 0.9808074146407053, 'f1-score': 0.9808844015084649, 'support': 10182} weighted_avg {'precision': 0.9816991096162047, 'recall': 0.9816342565311333, 'f1-score': 0.9816316964795545, 'support': 10182}
 
time = 37.76 secondes

Val loss 0.7297114950422735 accuracy 0.8948763608932495 macro_avg {'precision': 0.9039017893232482, 'recall': 0.8910078478741827, 'f1-score': 0.8943979786146571, 'support': 1132} weighted_avg {'precision': 0.902672121659412, 'recall': 0.8948763250883393, 'f1-score': 0.8957230179581128, 'support': 1132}
 
----------
Epoch 13/40
time = 1773.55 secondes

Train loss 0.09344938312807677 accuracy 0.9809467792510986 macro_avg {'precision': 0.9800546316237029, 'recall': 0.9802120715339235, 'f1-score': 0.9801210616708405, 'support': 10182} weighted_avg {'precision': 0.9809809081340701, 'recall': 0.9809467688076998, 'f1-score': 0.9809516769482264, 'support': 10182}
 
time = 39.46 secondes

Val loss 0.596296400500955 accuracy 0.9125441908836365 macro_avg {'precision': 0.918583644497579, 'recall': 0.9122782608091778, 'f1-score': 0.9138872906482473, 'support': 1132} weighted_avg {'precision': 0.9146927748385135, 'recall': 0.9125441696113075, 'f1-score': 0.9120934123304899, 'support': 1132}
 
----------
Epoch 14/40
time = 1773.19 secondes

Train loss 0.07567093908183954 accuracy 0.985562801361084 macro_avg {'precision': 0.9856053171941834, 'recall': 0.9856001010463281, 'f1-score': 0.9855930284550132, 'support': 10182} weighted_avg {'precision': 0.9856027027845865, 'recall': 0.9855627578078963, 'f1-score': 0.9855728943347403, 'support': 10182}
 
time = 38.55 secondes

Val loss 0.7622560998194311 accuracy 0.9028268456459045 macro_avg {'precision': 0.9042290091190012, 'recall': 0.9054991528655595, 'f1-score': 0.901508705574585, 'support': 1132} weighted_avg {'precision': 0.907568289437859, 'recall': 0.9028268551236749, 'f1-score': 0.901876994429407, 'support': 1132}
 
----------
Epoch 15/40
time = 1772.66 secondes

Train loss 0.07988626511222986 accuracy 0.98448246717453 macro_avg {'precision': 0.9842236927326111, 'recall': 0.98442847978358, 'f1-score': 0.9843093626501076, 'support': 10182} weighted_avg {'precision': 0.9845220030547663, 'recall': 0.9844824199567865, 'f1-score': 0.9844858041180833, 'support': 10182}
 
time = 39.93 secondes

Val loss 0.7227320783336246 accuracy 0.9072438478469849 macro_avg {'precision': 0.9138192099651187, 'recall': 0.9101922534229532, 'f1-score': 0.909791293584834, 'support': 1132} weighted_avg {'precision': 0.9118295315406199, 'recall': 0.907243816254417, 'f1-score': 0.9072051213354186, 'support': 1132}
 
----------
Epoch 16/40
time = 1769.14 secondes

Train loss 0.07366866520843335 accuracy 0.9854645729064941 macro_avg {'precision': 0.9851367323334413, 'recall': 0.9852718263489197, 'f1-score': 0.9851876395001982, 'support': 10182} weighted_avg {'precision': 0.9854840875426419, 'recall': 0.9854645452759773, 'f1-score': 0.9854596425417133, 'support': 10182}
 
time = 37.92 secondes

Val loss 0.7966084748979586 accuracy 0.8948763608932495 macro_avg {'precision': 0.9067005419040244, 'recall': 0.9005152202693212, 'f1-score': 0.898933955298715, 'support': 1132} weighted_avg {'precision': 0.9087207049560709, 'recall': 0.8948763250883393, 'f1-score': 0.8967060231924924, 'support': 1132}
 
----------
Epoch 17/40
time = 1767.67 secondes

Train loss 0.08393145722816892 accuracy 0.9851699471473694 macro_avg {'precision': 0.9850038675185914, 'recall': 0.9849688083185898, 'f1-score': 0.9849631028769379, 'support': 10182} weighted_avg {'precision': 0.9851787290894111, 'recall': 0.98516990768022, 'f1-score': 0.9851503294629562, 'support': 10182}
 
time = 38.51 secondes

Val loss 0.7260937918525625 accuracy 0.898409903049469 macro_avg {'precision': 0.9048391253100819, 'recall': 0.9030672998778184, 'f1-score': 0.9009569665182822, 'support': 1132} weighted_avg {'precision': 0.9059958507986366, 'recall': 0.8984098939929329, 'f1-score': 0.899009463442307, 'support': 1132}
 
----------
Epoch 18/40
time = 1768.69 secondes

Train loss 0.08038657188084831 accuracy 0.9850717186927795 macro_avg {'precision': 0.9844606631554557, 'recall': 0.9847586855720601, 'f1-score': 0.9845952861346525, 'support': 10182} weighted_avg {'precision': 0.9851285592895836, 'recall': 0.985071695148301, 'f1-score': 0.9850862815836011, 'support': 10182}
 
time = 38.60 secondes

Val loss 0.6407051066892397 accuracy 0.9204947352409363 macro_avg {'precision': 0.9214278669821583, 'recall': 0.9202026670428157, 'f1-score': 0.91972479615847, 'support': 1132} weighted_avg {'precision': 0.9225138337172138, 'recall': 0.9204946996466431, 'f1-score': 0.9204195875446792, 'support': 1132}
 
----------
Epoch 19/40
time = 1766.03 secondes

Train loss 0.07192397075532983 accuracy 0.9870359897613525 macro_avg {'precision': 0.9870421450917914, 'recall': 0.9868847774274825, 'f1-score': 0.986940695929903, 'support': 10182} weighted_avg {'precision': 0.9870787474592505, 'recall': 0.9870359457866824, 'f1-score': 0.9870339929547343, 'support': 10182}
 
time = 38.38 secondes

Val loss 0.6841933627011956 accuracy 0.916077733039856 macro_avg {'precision': 0.9179981479902016, 'recall': 0.9189086514683129, 'f1-score': 0.916507218250963, 'support': 1132} weighted_avg {'precision': 0.9195226903985181, 'recall': 0.916077738515901, 'f1-score': 0.9157535387893504, 'support': 1132}
 
----------
Epoch 20/40
time = 1768.52 secondes

Train loss 0.06347555918007719 accuracy 0.9881163239479065 macro_avg {'precision': 0.9878633014430738, 'recall': 0.9874602652684041, 'f1-score': 0.9876421809439044, 'support': 10182} weighted_avg {'precision': 0.9881508213800578, 'recall': 0.9881162836377921, 'f1-score': 0.9881152858011728, 'support': 10182}
 
time = 37.29 secondes

Val loss 0.7649937114462299 accuracy 0.9072438478469849 macro_avg {'precision': 0.9165228289639362, 'recall': 0.9109428819315408, 'f1-score': 0.909710063007785, 'support': 1132} weighted_avg {'precision': 0.9174021845251845, 'recall': 0.907243816254417, 'f1-score': 0.9079651338873628, 'support': 1132}
 
----------
Epoch 21/40
time = 1771.51 secondes

Train loss 0.054452599806834805 accuracy 0.9892948865890503 macro_avg {'precision': 0.9893976361934375, 'recall': 0.9892727274915429, 'f1-score': 0.9893228163680032, 'support': 10182} weighted_avg {'precision': 0.9893348759694855, 'recall': 0.9892948340208211, 'f1-score': 0.9893022645215958, 'support': 10182}
 
time = 36.99 secondes

Val loss 0.7552845823937415 accuracy 0.9081271886825562 macro_avg {'precision': 0.9151248476399759, 'recall': 0.9087905935065275, 'f1-score': 0.9087658925255979, 'support': 1132} weighted_avg {'precision': 0.9143314730431013, 'recall': 0.9081272084805654, 'f1-score': 0.907924067943396, 'support': 1132}
 
----------
Epoch 22/40
time = 1772.93 secondes

Train loss 0.0769467752278054 accuracy 0.9870359897613525 macro_avg {'precision': 0.9868751181173785, 'recall': 0.9866538500753521, 'f1-score': 0.9867503065699521, 'support': 10182} weighted_avg {'precision': 0.9870655152005507, 'recall': 0.9870359457866824, 'f1-score': 0.987036635049514, 'support': 10182}
 
time = 36.71 secondes

Val loss 0.7348045992025938 accuracy 0.9107773900032043 macro_avg {'precision': 0.9146946745295, 'recall': 0.9142623037376323, 'f1-score': 0.9126200183391481, 'support': 1132} weighted_avg {'precision': 0.9164748451748169, 'recall': 0.9107773851590106, 'f1-score': 0.9118343872109138, 'support': 1132}
 
----------
Epoch 23/40
time = 1769.44 secondes

Train loss 0.048985206023878576 accuracy 0.9915537238121033 macro_avg {'precision': 0.9916293346714525, 'recall': 0.9912476766301728, 'f1-score': 0.9914163347259777, 'support': 10182} weighted_avg {'precision': 0.9915957861369107, 'recall': 0.9915537222549597, 'f1-score': 0.9915529745588492, 'support': 10182}
 
time = 37.39 secondes

Val loss 0.631747732816992 accuracy 0.9134275913238525 macro_avg {'precision': 0.915313266373251, 'recall': 0.9148784883999539, 'f1-score': 0.9129796881183383, 'support': 1132} weighted_avg {'precision': 0.9182134312920653, 'recall': 0.9134275618374559, 'f1-score': 0.9138618210696592, 'support': 1132}
 
----------
Epoch 24/40
time = 1767.15 secondes

Train loss 0.04862967007133967 accuracy 0.9911609292030334 macro_avg {'precision': 0.9911237450546118, 'recall': 0.9910582556612602, 'f1-score': 0.9910663297670432, 'support': 10182} weighted_avg {'precision': 0.99122738020538, 'recall': 0.9911608721272834, 'f1-score': 0.9911706409463739, 'support': 10182}
 
time = 37.67 secondes

Val loss 0.6201973041705213 accuracy 0.9178445339202881 macro_avg {'precision': 0.9189195193824704, 'recall': 0.9193586975630451, 'f1-score': 0.9182439934911321, 'support': 1132} weighted_avg {'precision': 0.9205235885992176, 'recall': 0.9178445229681979, 'f1-score': 0.9182665317398444, 'support': 1132}
 
----------
Epoch 25/40
time = 1767.29 secondes

Train loss 0.04542757934964635 accuracy 0.9911609292030334 macro_avg {'precision': 0.9908887975639183, 'recall': 0.9910771938018611, 'f1-score': 0.9909680061923766, 'support': 10182} weighted_avg {'precision': 0.9911868790793967, 'recall': 0.9911608721272834, 'f1-score': 0.9911598582358402, 'support': 10182}
 
time = 38.10 secondes

Val loss 0.7766106700038223 accuracy 0.9081271886825562 macro_avg {'precision': 0.9179782951860865, 'recall': 0.910288879678242, 'f1-score': 0.9108918769314339, 'support': 1132} weighted_avg {'precision': 0.9172997333159387, 'recall': 0.9081272084805654, 'f1-score': 0.9094239667658985, 'support': 1132}
 
----------
Epoch 26/40
time = 1769.66 secondes

Train loss 0.052645294729307616 accuracy 0.9916519522666931 macro_avg {'precision': 0.9915491998163347, 'recall': 0.9915770694500964, 'f1-score': 0.9915522653440642, 'support': 10182} weighted_avg {'precision': 0.9916652063497732, 'recall': 0.9916519347868789, 'f1-score': 0.9916478637356203, 'support': 10182}
 
time = 37.88 secondes

Val loss 0.7220031250104051 accuracy 0.9125441908836365 macro_avg {'precision': 0.9165267963258449, 'recall': 0.9102549576704547, 'f1-score': 0.9118840248921438, 'support': 1132} weighted_avg {'precision': 0.9150205574028017, 'recall': 0.9125441696113075, 'f1-score': 0.9123010417526177, 'support': 1132}
 
----------
Epoch 27/40
time = 1767.80 secondes

Train loss 0.04380714208576364 accuracy 0.9927322864532471 macro_avg {'precision': 0.9925021772209177, 'recall': 0.9923140654346343, 'f1-score': 0.9924028488871028, 'support': 10182} weighted_avg {'precision': 0.9927372197709751, 'recall': 0.9927322726379886, 'f1-score': 0.9927297290123073, 'support': 10182}
 
time = 37.72 secondes

Val loss 0.815474622854926 accuracy 0.9063604474067688 macro_avg {'precision': 0.9116337312632135, 'recall': 0.9086499366456939, 'f1-score': 0.9079189513072059, 'support': 1132} weighted_avg {'precision': 0.9126502181374283, 'recall': 0.9063604240282686, 'f1-score': 0.9071556192712529, 'support': 1132}
 
----------
Epoch 28/40
time = 1771.84 secondes

Train loss 0.04848109285994781 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913096915451574, 'recall': 0.9914668793237565, 'f1-score': 0.9913769372986014, 'support': 10182} weighted_avg {'precision': 0.991478550631802, 'recall': 0.9914555097230406, 'f1-score': 0.9914558627361024, 'support': 10182}
 
time = 37.64 secondes

Val loss 0.7435223418461121 accuracy 0.9090105891227722 macro_avg {'precision': 0.9149658874182938, 'recall': 0.9107200817531268, 'f1-score': 0.9109283204803196, 'support': 1132} weighted_avg {'precision': 0.9139893795933881, 'recall': 0.9090106007067138, 'f1-score': 0.9095906301606709, 'support': 1132}
 
----------
Epoch 29/40
time = 1768.32 secondes

Train loss 0.036892871898446596 accuracy 0.9932233691215515 macro_avg {'precision': 0.9930737847647826, 'recall': 0.9931487184328516, 'f1-score': 0.9931038032117584, 'support': 10182} weighted_avg {'precision': 0.9932402170037661, 'recall': 0.993223335297584, 'f1-score': 0.9932242333254705, 'support': 10182}
 
time = 39.19 secondes

Val loss 0.7439896168475635 accuracy 0.9125441908836365 macro_avg {'precision': 0.9177571032274733, 'recall': 0.9143811835455296, 'f1-score': 0.912759296603823, 'support': 1132} weighted_avg {'precision': 0.9197674653221034, 'recall': 0.9125441696113075, 'f1-score': 0.9131685093573519, 'support': 1132}
 
----------
Epoch 30/40
time = 1770.34 secondes

Train loss 0.03640957631020913 accuracy 0.9940090775489807 macro_avg {'precision': 0.9934493633373824, 'recall': 0.9937576353966711, 'f1-score': 0.9935923066329879, 'support': 10182} weighted_avg {'precision': 0.9940352009921775, 'recall': 0.9940090355529365, 'f1-score': 0.9940125467380145, 'support': 10182}
 
time = 38.33 secondes

Val loss 0.7348350549107405 accuracy 0.9213780760765076 macro_avg {'precision': 0.9236069771396187, 'recall': 0.9222447808822676, 'f1-score': 0.9215261073641378, 'support': 1132} weighted_avg {'precision': 0.9246144652013585, 'recall': 0.9213780918727915, 'f1-score': 0.921532596918768, 'support': 1132}
 
----------
Epoch 31/40
time = 1773.87 secondes

Train loss 0.03341889115883641 accuracy 0.9935179948806763 macro_avg {'precision': 0.9935007032507054, 'recall': 0.9930328314549575, 'f1-score': 0.9932522090720827, 'support': 10182} weighted_avg {'precision': 0.9935408166918978, 'recall': 0.9935179728933412, 'f1-score': 0.9935170914407112, 'support': 10182}
 
time = 39.62 secondes

Val loss 0.6731896907637658 accuracy 0.9187279343605042 macro_avg {'precision': 0.9211513388533549, 'recall': 0.921266630104336, 'f1-score': 0.9200206516847329, 'support': 1132} weighted_avg {'precision': 0.9228030049191679, 'recall': 0.9187279151943463, 'f1-score': 0.919571439231325, 'support': 1132}
 
----------
Epoch 32/40
time = 1773.69 secondes

Train loss 0.035043264502558284 accuracy 0.9943037033081055 macro_avg {'precision': 0.993947249978625, 'recall': 0.9937891666240384, 'f1-score': 0.9938512046241824, 'support': 10182} weighted_avg {'precision': 0.9943394294003685, 'recall': 0.9943036731486937, 'f1-score': 0.9943057155301473, 'support': 10182}
 
time = 39.29 secondes

Val loss 0.7167344220062762 accuracy 0.9196113348007202 macro_avg {'precision': 0.9213036024833257, 'recall': 0.9207088520945128, 'f1-score': 0.9200277649312195, 'support': 1132} weighted_avg {'precision': 0.922060731696338, 'recall': 0.9196113074204947, 'f1-score': 0.9198963828520226, 'support': 1132}
 
----------
Epoch 33/40
time = 1766.98 secondes

Train loss 0.019810584816748893 accuracy 0.9960715174674988 macro_avg {'precision': 0.9958668748275201, 'recall': 0.9957804894677696, 'f1-score': 0.9958216124339596, 'support': 10182} weighted_avg {'precision': 0.9960746997489706, 'recall': 0.9960714987232371, 'f1-score': 0.9960711314717758, 'support': 10182}
 
time = 36.98 secondes

Val loss 0.7113326620991001 accuracy 0.9196113348007202 macro_avg {'precision': 0.9260034861698297, 'recall': 0.9178139143212862, 'f1-score': 0.9199781403558308, 'support': 1132} weighted_avg {'precision': 0.9241092078490188, 'recall': 0.9196113074204947, 'f1-score': 0.9200921245674215, 'support': 1132}
 
----------
Epoch 34/40
time = 1767.43 secondes

Train loss 0.027513636992853422 accuracy 0.9958751201629639 macro_avg {'precision': 0.9957921178255956, 'recall': 0.9958421635019317, 'f1-score': 0.9958047320830685, 'support': 10182} weighted_avg {'precision': 0.9958969275141675, 'recall': 0.995875073659399, 'f1-score': 0.9958734159585547, 'support': 10182}
 
time = 38.40 secondes

Val loss 0.7841334501481726 accuracy 0.9090105891227722 macro_avg {'precision': 0.9185974992515785, 'recall': 0.9136344580266916, 'f1-score': 0.913355814790642, 'support': 1132} weighted_avg {'precision': 0.9158576258667701, 'recall': 0.9090106007067138, 'f1-score': 0.90941074843424, 'support': 1132}
 
----------
Epoch 35/40
time = 1772.63 secondes

Train loss 0.011383429830636189 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981760305915545, 'recall': 0.9981309788001074, 'f1-score': 0.9981518266948578, 'support': 10182} weighted_avg {'precision': 0.9981365127226056, 'recall': 0.9981339618935376, 'f1-score': 0.9981335350156508, 'support': 10182}
 
time = 38.01 secondes

Val loss 0.7993642379098136 accuracy 0.9072438478469849 macro_avg {'precision': 0.9165510080571962, 'recall': 0.9102352459873408, 'f1-score': 0.9108609508415068, 'support': 1132} weighted_avg {'precision': 0.9146227506968184, 'recall': 0.907243816254417, 'f1-score': 0.9083560431917478, 'support': 1132}
 
----------
Epoch 36/40
time = 1765.02 secondes

Train loss 0.012999473351420295 accuracy 0.9969554543495178 macro_avg {'precision': 0.9968402848683503, 'recall': 0.9968215400492515, 'f1-score': 0.9968298544583154, 'support': 10182} weighted_avg {'precision': 0.9969577874992662, 'recall': 0.9969554115105087, 'f1-score': 0.9969556007727108, 'support': 10182}
 
time = 37.52 secondes

Val loss 0.6992632972948779 accuracy 0.9240282773971558 macro_avg {'precision': 0.9285336862494041, 'recall': 0.9247641226600182, 'f1-score': 0.9254795098391815, 'support': 1132} weighted_avg {'precision': 0.926371248299799, 'recall': 0.9240282685512368, 'f1-score': 0.9239905028912908, 'support': 1132}
 
----------
Epoch 37/40
time = 1760.67 secondes

Train loss 0.00818222663329096 accuracy 0.9987232685089111 macro_avg {'precision': 0.998770630916796, 'recall': 0.9987709031653713, 'f1-score': 0.9987697864947365, 'support': 10182} weighted_avg {'precision': 0.9987249076577447, 'recall': 0.9987232370850521, 'f1-score': 0.9987230550449794, 'support': 10182}
 
time = 37.26 secondes

Val loss 0.68369624451481 accuracy 0.9240282773971558 macro_avg {'precision': 0.9297900196697299, 'recall': 0.9259888085657204, 'f1-score': 0.926611346687638, 'support': 1132} weighted_avg {'precision': 0.9270512991739984, 'recall': 0.9240282685512368, 'f1-score': 0.9242061095389178, 'support': 1132}
 
----------
Epoch 38/40
time = 1764.66 secondes

Train loss 0.007885077850436663 accuracy 0.9980357885360718 macro_avg {'precision': 0.9981177268562693, 'recall': 0.9981148134712041, 'f1-score': 0.9981132649279267, 'support': 10182} weighted_avg {'precision': 0.9980428951300779, 'recall': 0.9980357493616185, 'f1-score': 0.9980361939271861, 'support': 10182}
 
time = 39.26 secondes

Val loss 0.8938041660002596 accuracy 0.9037102460861206 macro_avg {'precision': 0.9154821637929013, 'recall': 0.9075421429240572, 'f1-score': 0.908881064377417, 'support': 1132} weighted_avg {'precision': 0.9118009645520382, 'recall': 0.9037102473498233, 'f1-score': 0.9048803915449543, 'support': 1132}
 
----------
Epoch 39/40
time = 1768.00 secondes

Train loss 0.002384573850639821 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994348103551065, 'recall': 0.9994348103551065, 'f1-score': 0.9994348103551065, 'support': 10182} weighted_avg {'precision': 0.9994107248084856, 'recall': 0.9994107248084856, 'f1-score': 0.9994107248084856, 'support': 10182}
 
time = 39.35 secondes

Val loss 0.7908856512102842 accuracy 0.916077733039856 macro_avg {'precision': 0.9231623189191719, 'recall': 0.9184855528307537, 'f1-score': 0.9193355904448051, 'support': 1132} weighted_avg {'precision': 0.9205988255332913, 'recall': 0.916077738515901, 'f1-score': 0.9167168140462278, 'support': 1132}
 
----------
Epoch 40/40
time = 1761.04 secondes

Train loss 0.004505431844257744 accuracy 0.9991161227226257 macro_avg {'precision': 0.9990940383025219, 'recall': 0.999104280108367, 'f1-score': 0.9990981934340442, 'support': 10182} weighted_avg {'precision': 0.9991176895878338, 'recall': 0.9991160872127284, 'f1-score': 0.9991159819447047, 'support': 10182}
 
time = 36.92 secondes

Val loss 0.8216125675217356 accuracy 0.9125441908836365 macro_avg {'precision': 0.9185160523263619, 'recall': 0.9141953033976471, 'f1-score': 0.9144449301445585, 'support': 1132} weighted_avg {'precision': 0.9181684120207989, 'recall': 0.9125441696113075, 'f1-score': 0.9133786294436227, 'support': 1132}
 
----------
best_accuracy 0.9240282773971558 best_epoch 36 macro_avg {'precision': 0.9285336862494041, 'recall': 0.9247641226600182, 'f1-score': 0.9254795098391815, 'support': 1132} weighted_avg {'precision': 0.926371248299799, 'recall': 0.9240282685512368, 'f1-score': 0.9239905028912908, 'support': 1132}

average train time 1770.4799679219723

average val time 38.55873111486435
 
time = 245.35 secondes

test_accuracy 0.8643122315406799 macro_avg {'precision': 0.8631947401649536, 'recall': 0.8559448706145772, 'f1-score': 0.8569010690738319, 'support': 7532} weighted_avg {'precision': 0.867419176605361, 'recall': 0.8643122676579925, 'f1-score': 0.8634249984047243, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 372.00 MiB (GPU 0; 79.21 GiB total capacity; 66.18 GiB already allocated; 143.62 MiB free; 67.96 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 79.21 GiB total capacity; 63.69 GiB already allocated; 1.44 GiB free; 66.66 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_5
----------
Epoch 1/40
time = 50.37 secondes

Train loss 0.5785357464443553 accuracy 0.7209302186965942 macro_avg {'precision': 0.777877859845073, 'recall': 0.6253596216049282, 'f1-score': 0.6178406846609612, 'support': 516} weighted_avg {'precision': 0.757353588081762, 'recall': 0.7209302325581395, 'f1-score': 0.6724627585467795, 'support': 516}
 
time = 1.74 secondes

Val loss 0.4417421296238899 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 2/40
time = 49.92 secondes

Train loss 0.43623110245574603 accuracy 0.8003876209259033 macro_avg {'precision': 0.7851372914034971, 'recall': 0.778838808250573, 'f1-score': 0.7816927152861926, 'support': 516} weighted_avg {'precision': 0.7986719375309554, 'recall': 0.8003875968992248, 'f1-score': 0.7992733324322229, 'support': 516}
 
time = 1.78 secondes

Val loss 0.43553073704242706 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 46.49 secondes

Train loss 0.27082930889093515 accuracy 0.9031007885932922 macro_avg {'precision': 0.895860210663836, 'recall': 0.8940071192887213, 'f1-score': 0.8949169110459433, 'support': 516} weighted_avg {'precision': 0.9029024035628407, 'recall': 0.9031007751937985, 'f1-score': 0.9029871104139672, 'support': 516}
 
time = 1.27 secondes

Val loss 0.5664536282420158 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 4/40
time = 56.81 secondes

Train loss 0.2047454687682065 accuracy 0.9224806427955627 macro_avg {'precision': 0.9187103158241939, 'recall': 0.9126668075353932, 'f1-score': 0.9155316919853327, 'support': 516} weighted_avg {'precision': 0.9221868302071807, 'recall': 0.9224806201550387, 'f1-score': 0.9221989068508614, 'support': 516}
 
time = 1.74 secondes

Val loss 0.46314261853694916 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 5/40
time = 50.49 secondes

Train loss 0.16994805580400157 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 1.79 secondes

Val loss 0.7137393206357956 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 6/40
time = 51.09 secondes

Train loss 0.17125710816771694 accuracy 0.9476743936538696 macro_avg {'precision': 0.941358024691358, 'recall': 0.9462721258716252, 'f1-score': 0.9437061340595667, 'support': 516} weighted_avg {'precision': 0.9481529332950521, 'recall': 0.9476744186046512, 'f1-score': 0.9478192465077563, 'support': 516}
 
time = 1.77 secondes

Val loss 0.5731381922960281 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 7/40
time = 45.77 secondes

Train loss 0.34058457927665475 accuracy 0.9108527302742004 macro_avg {'precision': 0.8990288244891617, 'recall': 0.9173967459324155, 'f1-score': 0.9059334527527225, 'support': 516} weighted_avg {'precision': 0.9168904435727455, 'recall': 0.9108527131782945, 'f1-score': 0.9118532407224786, 'support': 516}
 
time = 1.53 secondes

Val loss 1.2049719989299774 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 8/40
time = 36.26 secondes

Train loss 0.17929535172879696 accuracy 0.9457364082336426 macro_avg {'precision': 0.9491565412292085, 'recall': 0.9332119695073386, 'f1-score': 0.9402777777777778, 'support': 516} weighted_avg {'precision': 0.9462997458695805, 'recall': 0.9457364341085271, 'f1-score': 0.9452465546942291, 'support': 516}
 
time = 1.50 secondes

Val loss 0.624084485694766 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 9/40
time = 37.78 secondes

Train loss 0.08933507653912812 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.51 secondes

Val loss 0.9640759527683258 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 10/40
time = 37.23 secondes

Train loss 0.16304157955120457 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.51 secondes

Val loss 1.364451378583908 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 11/40
time = 37.49 secondes

Train loss 0.1857795735969293 accuracy 0.9496123790740967 macro_avg {'precision': 0.9615217504649021, 'recall': 0.931635323374998, 'f1-score': 0.9437955592794303, 'support': 516} weighted_avg {'precision': 0.9526210803296072, 'recall': 0.9496124031007752, 'f1-score': 0.9487714136326291, 'support': 516}
 
time = 1.50 secondes

Val loss 1.090748518705368 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 12/40
time = 36.40 secondes

Train loss 0.36802843679448194 accuracy 0.9147287011146545 macro_avg {'precision': 0.9048263131931957, 'recall': 0.9135120198949986, 'f1-score': 0.9087577160493827, 'support': 516} weighted_avg {'precision': 0.916352021347157, 'recall': 0.9147286821705426, 'f1-score': 0.9151810280888124, 'support': 516}
 
time = 1.53 secondes

Val loss 0.5019816942512989 accuracy 0.90625 macro_avg {'precision': 0.9019607843137255, 'recall': 0.9149797570850202, 'f1-score': 0.9047619047619049, 'support': 64} weighted_avg {'precision': 0.914828431372549, 'recall': 0.90625, 'f1-score': 0.9069940476190477, 'support': 64}
 
----------
Epoch 13/40
time = 38.02 secondes

Train loss 0.0328395896887576 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.56 secondes

Val loss 1.525788590312004 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 14/40
time = 36.96 secondes

Train loss 0.19201526149514725 accuracy 0.9651162624359131 macro_avg {'precision': 0.9622580173268533, 'recall': 0.9622580173268533, 'f1-score': 0.9622580173268533, 'support': 516} weighted_avg {'precision': 0.9651162790697675, 'recall': 0.9651162790697675, 'f1-score': 0.9651162790697675, 'support': 516}
 
time = 1.53 secondes

Val loss 1.5498851090669632 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 15/40
time = 40.01 secondes

Train loss 0.30489716843426734 accuracy 0.9379844665527344 macro_avg {'precision': 0.930653363063251, 'recall': 0.9363652617720202, 'f1-score': 0.9333548595414918, 'support': 516} weighted_avg {'precision': 0.9386612160988722, 'recall': 0.937984496124031, 'f1-score': 0.9381887447967902, 'support': 516}
 
time = 1.49 secondes

Val loss 1.1167567521333694 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 16/40
time = 36.55 secondes

Train loss 0.6880099339504148 accuracy 0.8875969052314758 macro_avg {'precision': 0.876850767577279, 'recall': 0.881849064577475, 'f1-score': 0.8792056829189538, 'support': 516} weighted_avg {'precision': 0.888588849838424, 'recall': 0.8875968992248062, 'f1-score': 0.887967099944182, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9743818044662476 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 17/40
time = 37.10 secondes

Train loss 0.04038924096631959 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.51 secondes

Val loss 0.8908985704183578 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 18/40
time = 36.67 secondes

Train loss 0.05158346899781574 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.54 secondes

Val loss 1.136631190776825 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 19/40
time = 37.49 secondes

Train loss 0.3833118747555118 accuracy 0.9418604373931885 macro_avg {'precision': 0.9562390994133503, 'recall': 0.9209401362092227, 'f1-score': 0.9347815096311026, 'support': 516} weighted_avg {'precision': 0.9459271495639355, 'recall': 0.9418604651162791, 'f1-score': 0.9406945195069558, 'support': 516}
 
time = 1.59 secondes

Val loss 0.6167784109711647 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 20/40
time = 44.70 secondes

Train loss 0.1696175141352631 accuracy 0.963178277015686 macro_avg {'precision': 0.9579475308641976, 'recall': 0.9630463403930237, 'f1-score': 0.9603857980419174, 'support': 516} weighted_avg {'precision': 0.9635745645516317, 'recall': 0.9631782945736435, 'f1-score': 0.9632802105054582, 'support': 516}
 
time = 1.72 secondes

Val loss 1.8512237966060638 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 21/40
time = 48.18 secondes

Train loss 0.02433981015058111 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.69 secondes

Val loss 1.2347436770796776 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 22/40
time = 48.25 secondes

Train loss 0.3162043102497454 accuracy 0.9534883499145508 macro_avg {'precision': 0.9660056657223797, 'recall': 0.9358288770053476, 'f1-score': 0.9481189777963972, 'support': 516} weighted_avg {'precision': 0.9566506357467554, 'recall': 0.9534883720930233, 'f1-score': 0.9527120741224266, 'support': 516}
 
time = 1.92 secondes

Val loss 0.861766133835772 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 23/40
time = 43.40 secondes

Train loss 0.10592500182180876 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.24 secondes

Val loss 1.4977411963045597 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 47.08 secondes

Train loss 0.09178342920825923 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.49 secondes

Val loss 0.8594629913568497 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 25/40
time = 36.17 secondes

Train loss 0.14807472024580365 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9010960161685944 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 26/40
time = 36.11 secondes

Train loss 0.038501093977670695 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.57 secondes

Val loss 0.7616828689642716 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 27/40
time = 36.70 secondes

Train loss 0.03727828310608553 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.89 secondes

Val loss 0.8963013953762129 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 28/40
time = 36.40 secondes

Train loss 0.02583663882427517 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.51 secondes

Val loss 0.7788073015399277 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 29/40
time = 36.78 secondes

Train loss 0.07138461387181781 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4827834218740463 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 30/40
time = 36.59 secondes

Train loss 0.017415500096059546 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.45 secondes

Val loss 1.6044223308563232 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 31/40
time = 38.34 secondes

Train loss 0.08602908646891151 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.51 secondes

Val loss 1.71498404443264 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 32/40
time = 38.33 secondes

Train loss 0.03763934879040762 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.31 secondes

Val loss 0.5475304075080203 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 33/40
time = 47.89 secondes

Train loss 0.0011520596064766517 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.76 secondes

Val loss 0.6424322120892612 accuracy 0.921875 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}
 
----------
Epoch 34/40
time = 47.51 secondes

Train loss 0.05396978022690746 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.72 secondes

Val loss 1.2283049449324608 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 35/40
time = 47.89 secondes

Train loss 5.9699193529509515e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.140531338751316 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 36/40
time = 42.32 secondes

Train loss 0.07929666361572647 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.17 secondes

Val loss 1.1519591361284256 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 37/40
time = 52.18 secondes

Train loss 0.0003500996348465736 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.75 secondes

Val loss 1.126236841082573 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 38/40
time = 47.40 secondes

Train loss 4.362430329572155e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.75 secondes

Val loss 1.299934297800064 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 39/40
time = 47.35 secondes

Train loss 0.01226048874399787 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.88 secondes

Val loss 1.7424597144126892 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 40/40
time = 45.58 secondes

Train loss 0.00027114622626510084 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.45 secondes

Val loss 1.4189036190509796 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 33 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}

average train time 42.60167174935341

average val time 1.5871415555477142
 
time = 1.71 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9634146341463414, 'recall': 0.9444444444444444, 'f1-score': 0.9516008935219658, 'support': 65} weighted_avg {'precision': 0.9572232645403377, 'recall': 0.9538461538461539, 'f1-score': 0.9533650266338279, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_5
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 31.91 secondes

Train loss 0.6055088810848467 accuracy 0.6976743936538696 macro_avg {'precision': 0.7507756850063365, 'recall': 0.5932740601076021, 'f1-score': 0.5715015756749852, 'support': 516} weighted_avg {'precision': 0.7327364988124626, 'recall': 0.6976744186046512, 'f1-score': 0.6354892317321729, 'support': 516}
 
time = 1.71 secondes

Val loss 0.5178461596369743 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 30.05 secondes

Train loss 0.41637915056763275 accuracy 0.815891444683075 macro_avg {'precision': 0.8009286412512219, 'recall': 0.8002291825821237, 'f1-score': 0.8005752480604701, 'support': 516} weighted_avg {'precision': 0.8156836557624254, 'recall': 0.8158914728682171, 'f1-score': 0.8157843664010298, 'support': 516}
 
time = 1.23 secondes

Val loss 0.4601578861474991 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 28.72 secondes

Train loss 0.29384797359957837 accuracy 0.8837209343910217 macro_avg {'precision': 0.8747938270596881, 'recall': 0.8730393511369732, 'f1-score': 0.8739002932551321, 'support': 516} weighted_avg {'precision': 0.8834763520634384, 'recall': 0.8837209302325582, 'f1-score': 0.8835845324967607, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4497328996658325 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 4/40
time = 28.76 secondes

Train loss 0.2003762016467976 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 1.27 secondes

Val loss 0.8374121934175491 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 28.39 secondes

Train loss 0.19977518267026453 accuracy 0.9379844665527344 macro_avg {'precision': 0.9337797011513024, 'recall': 0.9317491019618679, 'f1-score': 0.9327468230694037, 'support': 516} weighted_avg {'precision': 0.9378692962617645, 'recall': 0.937984496124031, 'f1-score': 0.937911750664939, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7177746891975403 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 6/40
time = 28.10 secondes

Train loss 0.2395004698668014 accuracy 0.9166666865348816 macro_avg {'precision': 0.9241996233521657, 'recall': 0.8954130975407572, 'f1-score': 0.9069166453410078, 'support': 516} weighted_avg {'precision': 0.9186283741368487, 'recall': 0.9166666666666666, 'f1-score': 0.9152070826358794, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5157174468040466 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 7/40
time = 29.83 secondes

Train loss 0.3180221591681016 accuracy 0.9031007885932922 macro_avg {'precision': 0.8939347563431332, 'recall': 0.8974692391463355, 'f1-score': 0.8956361341682443, 'support': 516} weighted_avg {'precision': 0.9036480001998084, 'recall': 0.9031007751937985, 'f1-score': 0.9033171416003363, 'support': 516}
 
time = 1.40 secondes

Val loss 1.368193730711937 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 8/40
time = 28.59 secondes

Train loss 0.3218901076170644 accuracy 0.9186046719551086 macro_avg {'precision': 0.9135528971594545, 'recall': 0.9096272938575817, 'f1-score': 0.9115211888625786, 'support': 516} weighted_avg {'precision': 0.9183352242826127, 'recall': 0.9186046511627907, 'f1-score': 0.9184105837025108, 'support': 516}
 
time = 0.83 secondes

Val loss 1.0186066329479218 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 9/40
time = 28.10 secondes

Train loss 0.17021271953302802 accuracy 0.9496123790740967 macro_avg {'precision': 0.9430693466369368, 'recall': 0.9489459226630691, 'f1-score': 0.9458508233774621, 'support': 516} weighted_avg {'precision': 0.950216377543591, 'recall': 0.9496124031007752, 'f1-score': 0.9497783551473921, 'support': 516}
 
time = 1.61 secondes

Val loss 0.778531439602375 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 10/40
time = 30.01 secondes

Train loss 0.25808775011506496 accuracy 0.9244186282157898 macro_avg {'precision': 0.9132742257742257, 'recall': 0.9303431237098321, 'f1-score': 0.9200206664944459, 'support': 516} weighted_avg {'precision': 0.9290992437794763, 'recall': 0.9244186046511628, 'f1-score': 0.9251818831742294, 'support': 516}
 
time = 1.10 secondes

Val loss 1.4070512652397156 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 28.49 secondes

Train loss 0.1316862459873047 accuracy 0.9651162624359131 macro_avg {'precision': 0.9622580173268533, 'recall': 0.9622580173268533, 'f1-score': 0.9622580173268533, 'support': 516} weighted_avg {'precision': 0.9651162790697675, 'recall': 0.9651162790697675, 'f1-score': 0.9651162790697675, 'support': 516}
 
time = 1.39 secondes

Val loss 1.4596914499998093 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 12/40
time = 27.91 secondes

Train loss 0.15253865611598347 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 1.28 secondes

Val loss 1.3049113750457764 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 13/40
time = 28.36 secondes

Train loss 0.08008079433630248 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.44 secondes

Val loss 1.2245709523558617 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 14/40
time = 28.79 secondes

Train loss 0.16608708114081033 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.22 secondes

Val loss 0.6278153154999018 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 15/40
time = 29.47 secondes

Train loss 0.1657902698462942 accuracy 0.963178277015686 macro_avg {'precision': 0.9679874974793305, 'recall': 0.952659980820181, 'f1-score': 0.9595262373519492, 'support': 516} weighted_avg {'precision': 0.9639225759757141, 'recall': 0.9631782945736435, 'f1-score': 0.9628719930002111, 'support': 516}
 
time = 1.19 secondes

Val loss 0.7917515523731709 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 16/40
time = 28.55 secondes

Train loss 0.082673484156134 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 0.90 secondes

Val loss 1.2155693173408508 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 17/40
time = 28.30 secondes

Train loss 0.2356311271891393 accuracy 0.9554263353347778 macro_avg {'precision': 0.9466008702781106, 'recall': 0.9604294328950149, 'f1-score': 0.9525521035314061, 'support': 516} weighted_avg {'precision': 0.9577903261367464, 'recall': 0.9554263565891473, 'f1-score': 0.9557658352967545, 'support': 516}
 
time = 1.71 secondes

Val loss 1.3267927467823029 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 18/40
time = 29.47 secondes

Train loss 0.0846989969087934 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.37 secondes

Val loss 1.355791375041008 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 19/40
time = 28.66 secondes

Train loss 0.2298231251135638 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.24 secondes

Val loss 0.8663311451673508 accuracy 0.859375 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}
 
----------
Epoch 20/40
time = 29.09 secondes

Train loss 0.3805894045825963 accuracy 0.9341084957122803 macro_avg {'precision': 0.9510678223572513, 'recall': 0.9102449490434472, 'f1-score': 0.9256547165013984, 'support': 516} weighted_avg {'precision': 0.9393774343862973, 'recall': 0.9341085271317829, 'f1-score': 0.9325538033376891, 'support': 516}
 
time = 1.25 secondes

Val loss 1.0674018114805222 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 21/40
time = 28.59 secondes

Train loss 0.013893383962567896 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.23 secondes

Val loss 1.5000531673431396 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 22/40
time = 28.48 secondes

Train loss 0.13386091332402872 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0316883400082588 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 23/40
time = 28.56 secondes

Train loss 0.03982241804866741 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.23 secondes

Val loss 0.7050020471215248 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 24/40
time = 28.85 secondes

Train loss 0.04280002636986672 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 0.96 secondes

Val loss 0.9664607867598534 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 25/40
time = 29.70 secondes

Train loss 0.06715802989977722 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.73 secondes

Val loss 1.373269572854042 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 26/40
time = 26.92 secondes

Train loss 0.04048553929015091 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.19 secondes

Val loss 1.654378354549408 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 27/40
time = 26.50 secondes

Train loss 0.015653184451035817 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.17 secondes

Val loss 1.4575733840465546 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 28/40
time = 26.41 secondes

Train loss 0.014280279892387405 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.17 secondes

Val loss 1.485522210597992 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 29/40
time = 26.42 secondes

Train loss 0.13605778625677692 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.18 secondes

Val loss 0.9787640869617462 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 30/40
time = 27.02 secondes

Train loss 0.05264737793759471 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4045115411281586 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 26.99 secondes

Train loss 0.01947837616678567 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.19 secondes

Val loss 1.0818202793598175 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 32/40
time = 26.46 secondes

Train loss 0.07363944264282261 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.23 secondes

Val loss 2.130279690027237 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 33/40
time = 26.37 secondes

Train loss 0.05635173305354053 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.18 secondes

Val loss 1.3625943809747696 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 34/40
time = 24.93 secondes

Train loss 0.008828196026584148 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.26 secondes

Val loss 1.3460484594106674 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 35/40
time = 24.88 secondes

Train loss 0.022749034476432964 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.25 secondes

Val loss 1.5586301684379578 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 36/40
time = 24.80 secondes

Train loss 0.002344031000878507 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.23 secondes

Val loss 1.2875741720199585 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 24.85 secondes

Train loss 0.04667099496939706 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.23 secondes

Val loss 1.2418979294598103 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 38/40
time = 27.62 secondes

Train loss 0.02889695379748115 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.23 secondes

Val loss 1.493181973695755 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 39/40
time = 24.98 secondes

Train loss 0.00011823756711127123 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.25 secondes

Val loss 1.465138703584671 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 25.04 secondes

Train loss 0.00010699871486532643 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.3879858255386353 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 19 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}

average train time 27.84760047197342

average val time 1.258577471971512
 
time = 1.37 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 68.92 GiB already allocated; 55.62 MiB free; 70.41 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 79.21 GiB total capacity; 67.85 GiB already allocated; 29.62 MiB free; 70.44 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 79.21 GiB total capacity; 66.38 GiB already allocated; 143.62 MiB free; 70.32 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 69.37 GiB already allocated; 403.62 MiB free; 70.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_5
----------
Epoch 1/40
time = 39.47 secondes

Train loss 0.6596325906840238 accuracy 0.6356589198112488 macro_avg {'precision': 0.5417488494411571, 'recall': 0.5030964029712466, 'f1-score': 0.4079679718777463, 'support': 516} weighted_avg {'precision': 0.5685264182580819, 'recall': 0.6356589147286822, 'f1-score': 0.5090058277678491, 'support': 516}
 
time = 1.96 secondes

Val loss 0.6540125757455826 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 36.25 secondes

Train loss 0.41757593981244345 accuracy 0.817829430103302 macro_avg {'precision': 0.8215602836879432, 'recall': 0.7763600604651919, 'f1-score': 0.7899459534368071, 'support': 516} weighted_avg {'precision': 0.8192962779702018, 'recall': 0.8178294573643411, 'f1-score': 0.8110068978927104, 'support': 516}
 
time = 1.66 secondes

Val loss 0.46204736083745956 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 3/40
time = 37.09 secondes

Train loss 0.29561012918411783 accuracy 0.8875969052314758 macro_avg {'precision': 0.8804156015502598, 'recall': 0.8749248248622467, 'f1-score': 0.8775209533787325, 'support': 516} weighted_avg {'precision': 0.8870373175878287, 'recall': 0.8875968992248062, 'f1-score': 0.8871884149337493, 'support': 516}
 
time = 1.78 secondes

Val loss 0.6985491141676903 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 4/40
time = 36.21 secondes

Train loss 0.2553276833937024 accuracy 0.8972868323326111 macro_avg {'precision': 0.8879722311914756, 'recall': 0.890601888724542, 'f1-score': 0.8892502075444955, 'support': 516} weighted_avg {'precision': 0.8976977595222183, 'recall': 0.8972868217054264, 'f1-score': 0.897460273809619, 'support': 516}
 
time = 1.78 secondes

Val loss 0.6597933620214462 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 5/40
time = 36.19 secondes

Train loss 0.14953927009253565 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.68 secondes

Val loss 1.2888303995132446 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 6/40
time = 34.85 secondes

Train loss 0.24625496865976884 accuracy 0.9496123790740967 macro_avg {'precision': 0.9597513597513598, 'recall': 0.9327893633275361, 'f1-score': 0.9439505347593583, 'support': 516} weighted_avg {'precision': 0.9520108659643544, 'recall': 0.9496124031007752, 'f1-score': 0.9488528841769266, 'support': 516}
 
time = 1.80 secondes

Val loss 1.6546040177345276 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 7/40
time = 35.99 secondes

Train loss 0.30818482825469057 accuracy 0.9244186282157898 macro_avg {'precision': 0.9131185807656396, 'recall': 0.9314971636623701, 'f1-score': 0.9201729506733572, 'support': 516} weighted_avg {'precision': 0.9298331994296427, 'recall': 0.9244186046511628, 'f1-score': 0.9252391932351083, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6984992921352386 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 8/40
time = 36.62 secondes

Train loss 0.348958120164532 accuracy 0.9244186282157898 macro_avg {'precision': 0.9331973216154007, 'recall': 0.9038002048014564, 'f1-score': 0.9155755620534722, 'support': 516} weighted_avg {'precision': 0.9267047288605997, 'recall': 0.9244186046511628, 'f1-score': 0.9230947958790534, 'support': 516}
 
time = 1.76 secondes

Val loss 2.3076946139335632 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 9/40
time = 35.78 secondes

Train loss 0.31855761974249175 accuracy 0.9282945990562439 macro_avg {'precision': 0.9200070436063263, 'recall': 0.9264583976724152, 'f1-score': 0.9230257508134063, 'support': 516} weighted_avg {'precision': 0.9292010222412169, 'recall': 0.9282945736434108, 'f1-score': 0.9285677718642259, 'support': 516}
 
time = 1.66 secondes

Val loss 2.0324240922927856 accuracy 0.6875 macro_avg {'precision': 0.7333333333333334, 'recall': 0.6275303643724697, 'f1-score': 0.6135265700483092, 'support': 64} weighted_avg {'precision': 0.7208333333333333, 'recall': 0.6875, 'f1-score': 0.6452294685990339, 'support': 64}
 
----------
Epoch 10/40
time = 35.82 secondes

Train loss 0.4835658711187231 accuracy 0.8798449635505676 macro_avg {'precision': 0.8743192291579388, 'recall': 0.8630755977439332, 'f1-score': 0.86809598416756, 'support': 516} weighted_avg {'precision': 0.8790460602163528, 'recall': 0.8798449612403101, 'f1-score': 0.8789294565333425, 'support': 516}
 
time = 1.77 secondes

Val loss 1.5945920944213867 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 11/40
time = 37.52 secondes

Train loss 0.11010846042666923 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6021197587251663 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 12/40
time = 36.16 secondes

Train loss 0.28141708153381123 accuracy 0.9282945990562439 macro_avg {'precision': 0.9431623931623931, 'recall': 0.9045316385741917, 'f1-score': 0.9192136319591074, 'support': 516} weighted_avg {'precision': 0.9328132246736898, 'recall': 0.9282945736434108, 'f1-score': 0.9266673528791713, 'support': 516}
 
time = 1.65 secondes

Val loss 1.6205876916646957 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 13/40
time = 35.24 secondes

Train loss 0.10712611229709265 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.77 secondes

Val loss 1.507264366489835 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 14/40
time = 36.48 secondes

Train loss 0.24680152282896664 accuracy 0.9341084957122803 macro_avg {'precision': 0.9253536591187563, 'recall': 0.9344797880467468, 'f1-score': 0.9294945987654321, 'support': 516} weighted_avg {'precision': 0.9355437513962136, 'recall': 0.9341085271317829, 'f1-score': 0.9344580671595367, 'support': 516}
 
time = 1.78 secondes

Val loss 2.0836925208568573 accuracy 0.6875 macro_avg {'precision': 0.6971428571428572, 'recall': 0.6396761133603239, 'f1-score': 0.6363636363636364, 'support': 64} weighted_avg {'precision': 0.6939285714285715, 'recall': 0.6875, 'f1-score': 0.6619318181818181, 'support': 64}
 
----------
Epoch 15/40
time = 35.99 secondes

Train loss 0.0598244810868037 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.78 secondes

Val loss 2.3507427275180817 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 16/40
time = 35.46 secondes

Train loss 0.14621195546351373 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.67 secondes

Val loss 1.8404104933142662 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 17/40
time = 35.98 secondes

Train loss 0.025181636091226457 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.77 secondes

Val loss 2.279051572084427 accuracy 0.65625 macro_avg {'precision': 0.6406926406926408, 'recall': 0.631578947368421, 'f1-score': 0.6333333333333333, 'support': 64} weighted_avg {'precision': 0.6500270562770563, 'recall': 0.65625, 'f1-score': 0.6505208333333334, 'support': 64}
 
----------
Epoch 18/40
time = 35.67 secondes

Train loss 0.014446764088819637 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.80 secondes

Val loss 2.2448810636997223 accuracy 0.6875 macro_avg {'precision': 0.6772727272727272, 'recall': 0.6578947368421053, 'f1-score': 0.6606574761399788, 'support': 64} weighted_avg {'precision': 0.6823863636363636, 'recall': 0.6875, 'f1-score': 0.6785524920466596, 'support': 64}
 
----------
Epoch 19/40
time = 35.71 secondes

Train loss 0.1239258512130508 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.63 secondes

Val loss 1.9149967730045319 accuracy 0.703125 macro_avg {'precision': 0.6960591133004926, 'recall': 0.701417004048583, 'f1-score': 0.6971357409713573, 'support': 64} weighted_avg {'precision': 0.7101908866995075, 'recall': 0.703125, 'f1-score': 0.7051214196762141, 'support': 64}
 
----------
Epoch 20/40
time = 37.76 secondes

Train loss 0.08994716231906998 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9973073229193687 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 21/40
time = 36.19 secondes

Train loss 0.1763206832712802 accuracy 0.9651162624359131 macro_avg {'precision': 0.9565306347282772, 'recall': 0.9714903369471579, 'f1-score': 0.9629043853342919, 'support': 516} weighted_avg {'precision': 0.9676139210600191, 'recall': 0.9651162790697675, 'f1-score': 0.9653971544647485, 'support': 516}
 
time = 1.78 secondes

Val loss 1.8345214128494263 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 22/40
time = 35.88 secondes

Train loss 0.029560259027978947 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.71 secondes

Val loss 1.4371252357959747 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 23/40
time = 35.38 secondes

Train loss 0.09456860534643938 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.78 secondes

Val loss 2.2086907029151917 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 24/40
time = 36.43 secondes

Train loss 0.26123174625646434 accuracy 0.9515503644943237 macro_avg {'precision': 0.9412231559290383, 'recall': 0.9608520390748175, 'f1-score': 0.9488288145342033, 'support': 516} weighted_avg {'precision': 0.9564988527710827, 'recall': 0.9515503875968992, 'f1-score': 0.9520764059199412, 'support': 516}
 
time = 1.74 secondes

Val loss 2.216898187994957 accuracy 0.71875 macro_avg {'precision': 0.71875, 'recall': 0.7267206477732794, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.736328125, 'recall': 0.71875, 'f1-score': 0.7212438423645322, 'support': 64}
 
----------
Epoch 25/40
time = 36.08 secondes

Train loss 0.05011993380961058 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9723159074783325 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 26/40
time = 35.32 secondes

Train loss 0.040407819859396885 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.62 secondes

Val loss 1.5966625809669495 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 27/40
time = 36.63 secondes

Train loss 0.02180237731000957 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.80 secondes

Val loss 1.8547040633293363 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 28/40
time = 37.11 secondes

Train loss 0.025038175020337363 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.77 secondes

Val loss 2.257102608680725 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 29/40
time = 35.34 secondes

Train loss 0.03586251149659581 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.73 secondes

Val loss 2.0248604118824005 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 30/40
time = 35.67 secondes

Train loss 0.010146453589958113 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.81 secondes

Val loss 2.6559970378875732 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 31/40
time = 35.76 secondes

Train loss 0.0011678848073973893 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9615291208028793 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 32/40
time = 35.98 secondes

Train loss 0.09148746317000725 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.77 secondes

Val loss 2.027755957096815 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 34.71 secondes

Train loss 0.10219918492718232 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.78 secondes

Val loss 2.0863365456461906 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 34/40
time = 35.62 secondes

Train loss 0.014533261137716401 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.78 secondes

Val loss 1.8787337839603424 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 35/40
time = 36.39 secondes

Train loss 0.01623848834325062 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9302708059549332 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 37.74 secondes

Train loss 0.01358794819217027 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.66 secondes

Val loss 2.2175754010677338 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 37/40
time = 35.39 secondes

Train loss 1.8417606869744223e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.74 secondes

Val loss 2.108957454562187 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 38/40
time = 35.54 secondes

Train loss 0.00013098448636645281 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 2.141955181956291 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 39/40
time = 35.75 secondes

Train loss 0.012624403157932455 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.70 secondes

Val loss 2.4175869673490524 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 40/40
time = 35.73 secondes

Train loss 1.640458757526975e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.77 secondes

Val loss 2.419247344136238 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 26 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}

average train time 36.12207238078118

average val time 1.752069318294525
 
time = 2.06 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_5
----------
Epoch 1/40
time = 50.51 secondes

Train loss 0.5910323840199094 accuracy 0.6666666865348816 macro_avg {'precision': 0.6399703144809672, 'recall': 0.573574110495262, 'f1-score': 0.5578318055001993, 'support': 516} weighted_avg {'precision': 0.6502159415360195, 'recall': 0.6666666666666666, 'f1-score': 0.6182011425534742, 'support': 516}
 
time = 2.26 secondes

Val loss 0.5481565296649933 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 2/40
time = 46.74 secondes

Train loss 0.36564857444979926 accuracy 0.8449612259864807 macro_avg {'precision': 0.8368675311467073, 'recall': 0.8230255351657103, 'f1-score': 0.828920975415679, 'support': 516} weighted_avg {'precision': 0.8434727420731359, 'recall': 0.8449612403100775, 'f1-score': 0.8433369096878599, 'support': 516}
 
time = 1.99 secondes

Val loss 0.44013357907533646 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 3/40
time = 47.68 secondes

Train loss 0.22042961548449416 accuracy 0.9321705102920532 macro_avg {'precision': 0.9288510890307298, 'recall': 0.9237277115875364, 'f1-score': 0.9261793522912605, 'support': 516} weighted_avg {'precision': 0.9319521575300713, 'recall': 0.9321705426356589, 'f1-score': 0.9319667606511556, 'support': 516}
 
time = 2.03 secondes

Val loss 0.487371064722538 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 4/40
time = 47.89 secondes

Train loss 0.13868150792338632 accuracy 0.9534883499145508 macro_avg {'precision': 0.9506328080346207, 'recall': 0.9485233164832665, 'f1-score': 0.9495601173020528, 'support': 516} weighted_avg {'precision': 0.9534101374612861, 'recall': 0.9534883720930233, 'f1-score': 0.9534338129987042, 'support': 516}
 
time = 2.03 secondes

Val loss 0.999733179807663 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 5/40
time = 47.51 secondes

Train loss 0.13043163808161448 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.97 secondes

Val loss 1.1745552122592926 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 6/40
time = 47.34 secondes

Train loss 0.23934848059434444 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 2.03 secondes

Val loss 1.209568351507187 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 7/40
time = 47.67 secondes

Train loss 0.1828564876676396 accuracy 0.9593023061752319 macro_avg {'precision': 0.9666609996599796, 'recall': 0.9461583472847553, 'f1-score': 0.9550326797385621, 'support': 516} weighted_avg {'precision': 0.9607238876193037, 'recall': 0.9593023255813954, 'f1-score': 0.9588458225667528, 'support': 516}
 
time = 2.05 secondes

Val loss 0.9432844966650009 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 8/40
time = 47.61 secondes

Train loss 0.23287382603898135 accuracy 0.9476743936538696 macro_avg {'precision': 0.9377231443783276, 'recall': 0.9543504055393918, 'f1-score': 0.9445220943984518, 'support': 516} weighted_avg {'precision': 0.9513104611104232, 'recall': 0.9476744186046512, 'f1-score': 0.9481613629942266, 'support': 516}
 
time = 1.98 secondes

Val loss 1.283152848482132 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 9/40
time = 47.59 secondes

Train loss 0.20853390188792467 accuracy 0.9399224519729614 macro_avg {'precision': 0.9447296837810268, 'recall': 0.9251905791330072, 'f1-score': 0.9336196700902584, 'support': 516} weighted_avg {'precision': 0.9408511448671417, 'recall': 0.939922480620155, 'f1-score': 0.9392485952175874, 'support': 516}
 
time = 2.03 secondes

Val loss 1.7600042819976807 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 10/40
time = 47.53 secondes

Train loss 0.08870545986097898 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 2.08 secondes

Val loss 1.3058391511440277 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 11/40
time = 47.56 secondes

Train loss 0.14479094041885357 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.94 secondes

Val loss 1.5295238941907883 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 12/40
time = 46.89 secondes

Train loss 0.1398550421281746 accuracy 0.963178277015686 macro_avg {'precision': 0.9564732142857143, 'recall': 0.9653544202980999, 'f1-score': 0.9605579179858952, 'support': 516} weighted_avg {'precision': 0.9641516126799556, 'recall': 0.9631782945736435, 'f1-score': 0.9633556132901075, 'support': 516}
 
time = 2.04 secondes

Val loss 2.2241888642311096 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 47.18 secondes

Train loss 0.4474029034648662 accuracy 0.9108527302742004 macro_avg {'precision': 0.9059454110662158, 'recall': 0.9000861466443444, 'f1-score': 0.9028614457831324, 'support': 516} weighted_avg {'precision': 0.91047032600073, 'recall': 0.9108527131782945, 'f1-score': 0.9105287428784906, 'support': 516}
 
time = 2.04 secondes

Val loss 1.702726811170578 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 14/40
time = 47.71 secondes

Train loss 0.18895393477798667 accuracy 0.9515503644943237 macro_avg {'precision': 0.9549808429118773, 'recall': 0.9400793199291322, 'f1-score': 0.9467450491473015, 'support': 516} weighted_avg {'precision': 0.9520812913956459, 'recall': 0.9515503875968992, 'f1-score': 0.9511473592108038, 'support': 516}
 
time = 1.64 secondes

Val loss 1.5786226093769073 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 46.60 secondes

Train loss 0.26798076624717476 accuracy 0.9302325248718262 macro_avg {'precision': 0.9245160346537067, 'recall': 0.9245160346537067, 'f1-score': 0.9245160346537067, 'support': 516} weighted_avg {'precision': 0.9302325581395349, 'recall': 0.9302325581395349, 'f1-score': 0.9302325581395349, 'support': 516}
 
time = 2.01 secondes

Val loss 1.1818162202835083 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 16/40
time = 47.25 secondes

Train loss 0.1367008129313807 accuracy 0.9728682041168213 macro_avg {'precision': 0.9687474828836086, 'recall': 0.9729532044926288, 'f1-score': 0.9707781175671084, 'support': 516} weighted_avg {'precision': 0.9731142310346013, 'recall': 0.9728682170542635, 'f1-score': 0.9729287996480942, 'support': 516}
 
time = 2.04 secondes

Val loss 1.9243815541267395 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 17/40
time = 47.26 secondes

Train loss 0.11368218480140169 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 2.02 secondes

Val loss 2.1379575729370117 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 18/40
time = 46.37 secondes

Train loss 0.3002762895842104 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 2.06 secondes

Val loss 1.6149703040719032 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 19/40
time = 47.62 secondes

Train loss 0.27802333997026313 accuracy 0.9554263353347778 macro_avg {'precision': 0.9655593803786575, 'recall': 0.9396567137493295, 'f1-score': 0.9504854247414336, 'support': 516} weighted_avg {'precision': 0.9577393294106659, 'recall': 0.9554263565891473, 'f1-score': 0.9547897948173559, 'support': 516}
 
time = 2.03 secondes

Val loss 2.1017946600914 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 20/40
time = 48.27 secondes

Train loss 0.036708026026176274 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 2.04 secondes

Val loss 1.4314833283424377 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 21/40
time = 46.61 secondes

Train loss 0.02071020985000139 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.93 secondes

Val loss 1.6393872499465942 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 22/40
time = 47.48 secondes

Train loss 0.15497525026766004 accuracy 0.9709302186965942 macro_avg {'precision': 0.9701414353064431, 'recall': 0.9668172878435708, 'f1-score': 0.968437921796184, 'support': 516} weighted_avg {'precision': 0.9708982542911787, 'recall': 0.9709302325581395, 'f1-score': 0.9708786675078922, 'support': 516}
 
time = 2.04 secondes

Val loss 2.449527829885483 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 23/40
time = 47.59 secondes

Train loss 0.019958430711884637 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.07 secondes

Val loss 1.7753691375255585 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 24/40
time = 46.98 secondes

Train loss 0.026676164117375403 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.93 secondes

Val loss 1.7789091765880585 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 25/40
time = 47.67 secondes

Train loss 0.024895357951181446 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.03 secondes

Val loss 1.5825062096118927 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 48.07 secondes

Train loss 0.04376842919637883 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4540241807699203 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 27/40
time = 46.61 secondes

Train loss 0.13242332182876868 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.95 secondes

Val loss 1.6940194442868233 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 28/40
time = 46.97 secondes

Train loss 0.02142573737623796 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.03 secondes

Val loss 2.5181883573532104 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 29/40
time = 47.51 secondes

Train loss 0.04753035110766315 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.04 secondes

Val loss 2.033795490860939 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 30/40
time = 47.40 secondes

Train loss 0.030743188688079084 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.94 secondes

Val loss 2.5642741322517395 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 31/40
time = 47.45 secondes

Train loss 0.022605743973282657 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.04 secondes

Val loss 1.8749131858348846 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 32/40
time = 47.22 secondes

Train loss 0.047096558171798475 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 2.04 secondes

Val loss 1.6534931063652039 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 47.06 secondes

Train loss 0.017086773851505397 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.98 secondes

Val loss 1.576234057545662 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 34/40
time = 46.20 secondes

Train loss 0.006529018187751662 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.98 secondes

Val loss 2.0151139348745346 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 35/40
time = 47.21 secondes

Train loss 0.0023693594315166897 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.04 secondes

Val loss 2.5039400458335876 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 36/40
time = 48.61 secondes

Train loss 0.00038946697173797116 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.9285318553447723 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 47.49 secondes

Train loss 0.0002714873602544134 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.5742321610450745 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 47.16 secondes

Train loss 0.0058480329138491825 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.47617569565773 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 47.57 secondes

Train loss 1.8546307397958696e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.05 secondes

Val loss 1.8630253672599792 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 40/40
time = 46.17 secondes

Train loss 1.9603210162269093e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.03 secondes

Val loss 2.07417294383049 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 2 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}

average train time 47.39488708376884

average val time 2.013846296072006
 
time = 2.34 secondes

test_accuracy 0.8615384697914124 macro_avg {'precision': 0.8731501057082452, 'recall': 0.8440545808966862, 'f1-score': 0.8526077097505669, 'support': 65} weighted_avg {'precision': 0.8670678159050252, 'recall': 0.8615384615384616, 'f1-score': 0.8587476016047444, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_5
----------
Epoch 1/40
time = 64.89 secondes

Train loss 0.6344757694186587 accuracy 0.6124030947685242 macro_avg {'precision': 0.492600422832981, 'recall': 0.49755376038229604, 'f1-score': 0.4405291120026022, 'support': 516} weighted_avg {'precision': 0.5321631676418048, 'recall': 0.6124031007751938, 'f1-score': 0.5258651483861966, 'support': 516}
 
time = 2.53 secondes

Val loss 0.7047123461961746 accuracy 0.625 macro_avg {'precision': 0.6436781609195402, 'recall': 0.5506072874493927, 'f1-score': 0.5, 'support': 64} weighted_avg {'precision': 0.639367816091954, 'recall': 0.625, 'f1-score': 0.546875, 'support': 64}
 
----------
Epoch 2/40
time = 63.24 secondes

Train loss 0.4081495079127225 accuracy 0.8275193572044373 macro_avg {'precision': 0.8182471264367817, 'recall': 0.8024234839003299, 'f1-score': 0.8089167204110927, 'support': 516} weighted_avg {'precision': 0.8255619041254566, 'recall': 0.8275193798449613, 'f1-score': 0.8253240349428277, 'support': 516}
 
time = 2.41 secondes

Val loss 0.47046664729714394 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 3/40
time = 64.15 secondes

Train loss 0.27177304368127475 accuracy 0.895348846912384 macro_avg {'precision': 0.8926338495761641, 'recall': 0.8786957723127936, 'f1-score': 0.8848214285714286, 'support': 516} weighted_avg {'precision': 0.8949016627756089, 'recall': 0.8953488372093024, 'f1-score': 0.8944040697674418, 'support': 516}
 
time = 2.40 secondes

Val loss 0.7492381855845451 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 4/40
time = 63.58 secondes

Train loss 0.2250140564459743 accuracy 0.9069767594337463 macro_avg {'precision': 0.8986942381437795, 'recall': 0.9005087528241471, 'f1-score': 0.8995848469122989, 'support': 516} weighted_avg {'precision': 0.9072168168249528, 'recall': 0.9069767441860465, 'f1-score': 0.9070823427185286, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0591700375080109 accuracy 0.703125 macro_avg {'precision': 0.7277526395173455, 'recall': 0.652834008097166, 'f1-score': 0.6496686833765485, 'support': 64} weighted_avg {'precision': 0.7199754901960784, 'recall': 0.703125, 'f1-score': 0.6753277153558052, 'support': 64}
 
----------
Epoch 5/40
time = 63.71 secondes

Train loss 0.11614983166201097 accuracy 0.9554263353347778 macro_avg {'precision': 0.9496527777777778, 'recall': 0.9546592331323245, 'f1-score': 0.9520459660507421, 'support': 516} weighted_avg {'precision': 0.9558637489233419, 'recall': 0.9554263565891473, 'f1-score': 0.9555497285066072, 'support': 516}
 
time = 2.41 secondes

Val loss 1.1028559058904648 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 64.11 secondes

Train loss 0.17169949148647543 accuracy 0.9476743936538696 macro_avg {'precision': 0.9458281239718365, 'recall': 0.9405019261089349, 'f1-score': 0.9430526431961153, 'support': 516} weighted_avg {'precision': 0.9475529518524923, 'recall': 0.9476744186046512, 'f1-score': 0.9475172153594628, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2844282239675522 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 7/40
time = 63.99 secondes

Train loss 0.08162372033852576 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 2.40 secondes

Val loss 2.0404615998268127 accuracy 0.671875 macro_avg {'precision': 0.6794871794871795, 'recall': 0.6204453441295547, 'f1-score': 0.6127917026793431, 'support': 64} weighted_avg {'precision': 0.6770833333333333, 'recall': 0.671875, 'f1-score': 0.6411516853932584, 'support': 64}
 
----------
Epoch 8/40
time = 63.13 secondes

Train loss 0.04511403784801422 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 2.29 secondes

Val loss 1.523890107870102 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 9/40
time = 64.03 secondes

Train loss 0.25329303799949365 accuracy 0.9496123790740967 macro_avg {'precision': 0.9474228326687344, 'recall': 0.9431757229003788, 'f1-score': 0.9452274026292153, 'support': 516} weighted_avg {'precision': 0.9494956260110663, 'recall': 0.9496124031007752, 'f1-score': 0.9494922661015543, 'support': 516}
 
time = 2.39 secondes

Val loss 3.3487228751182556 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 10/40
time = 63.56 secondes

Train loss 0.15164010854950352 accuracy 0.963178277015686 macro_avg {'precision': 0.9710472628357701, 'recall': 0.9503519009151049, 'f1-score': 0.9593152816682228, 'support': 516} weighted_avg {'precision': 0.964698436169736, 'recall': 0.9631782945736435, 'f1-score': 0.9627652680365858, 'support': 516}
 
time = 2.31 secondes

Val loss 1.323911041021347 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 11/40
time = 63.48 secondes

Train loss 0.3907353119745191 accuracy 0.9108527302742004 macro_avg {'precision': 0.9112128146453089, 'recall': 0.894315946881654, 'f1-score': 0.9016295608640154, 'support': 516} weighted_avg {'precision': 0.9109189387354466, 'recall': 0.9108527131782945, 'f1-score': 0.9099187230705195, 'support': 516}
 
time = 2.40 secondes

Val loss 1.1457586586475372 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 12/40
time = 63.95 secondes

Train loss 0.08500378701424008 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 2.33 secondes

Val loss 1.5894540846347809 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 13/40
time = 63.24 secondes

Train loss 0.36790513601127633 accuracy 0.9205426573753357 macro_avg {'precision': 0.9161183128248996, 'recall': 0.9111470506964875, 'f1-score': 0.9135243841126194, 'support': 516} weighted_avg {'precision': 0.9202515617882558, 'recall': 0.9205426356589147, 'f1-score': 0.920303919619925, 'support': 516}
 
time = 2.41 secondes

Val loss 1.8764704167842865 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 14/40
time = 64.01 secondes

Train loss 0.30232763955515995 accuracy 0.9457364082336426 macro_avg {'precision': 0.9588662409238037, 'recall': 0.9262877297921103, 'f1-score': 0.9393022786852188, 'support': 516} weighted_avg {'precision': 0.9492557637703538, 'recall': 0.9457364341085271, 'f1-score': 0.9447406719596818, 'support': 516}
 
time = 2.43 secondes

Val loss 1.405108779668808 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 15/40
time = 64.06 secondes

Train loss 0.105212262044502 accuracy 0.9806201457977295 macro_avg {'precision': 0.975365444524323, 'recall': 0.9836483916584042, 'f1-score': 0.9792186870720903, 'support': 516} weighted_avg {'precision': 0.9812874198659898, 'recall': 0.9806201550387597, 'f1-score': 0.9807038247681131, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0011996626853943 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 16/40
time = 63.50 secondes

Train loss 0.10744832911873484 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.40 secondes

Val loss 1.3794954717159271 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 17/40
time = 63.66 secondes

Train loss 0.15484984128852375 accuracy 0.9767441749572754 macro_avg {'precision': 0.9782798713614249, 'recall': 0.971376558360288, 'f1-score': 0.9746595075955997, 'support': 516} weighted_avg {'precision': 0.976863849837284, 'recall': 0.9767441860465116, 'f1-score': 0.9766596720552585, 'support': 516}
 
time = 2.42 secondes

Val loss 3.537547469139099 accuracy 0.625 macro_avg {'precision': 0.8064516129032258, 'recall': 0.5384615384615384, 'f1-score': 0.45142857142857146, 'support': 64} weighted_avg {'precision': 0.7701612903225806, 'recall': 0.625, 'f1-score': 0.5092857142857142, 'support': 64}
 
----------
Epoch 18/40
time = 63.80 secondes

Train loss 0.31025361128757306 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 2.34 secondes

Val loss 1.9575761426240206 accuracy 0.6875 macro_avg {'precision': 0.6941176470588235, 'recall': 0.7004048582995952, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7139705882352941, 'recall': 0.6875, 'f1-score': 0.6899509803921569, 'support': 64}
 
----------
Epoch 19/40
time = 64.03 secondes

Train loss 0.07327435472104822 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 2.39 secondes

Val loss 1.4731745550743653 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 20/40
time = 63.88 secondes

Train loss 0.02493490790452184 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 2.39 secondes

Val loss 2.337515354156494 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 21/40
time = 63.57 secondes

Train loss 0.30126284278837073 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5259078741073608 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 22/40
time = 63.71 secondes

Train loss 0.14629958515235392 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 2.40 secondes

Val loss 1.9173211306333542 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 23/40
time = 63.39 secondes

Train loss 0.11955594053385236 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 2.33 secondes

Val loss 2.036495476961136 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 24/40
time = 64.45 secondes

Train loss 0.04826089989783765 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 2.39 secondes

Val loss 2.3925761580467224 accuracy 0.71875 macro_avg {'precision': 0.7083333333333333, 'recall': 0.7024291497975709, 'f1-score': 0.7046153846153846, 'support': 64} weighted_avg {'precision': 0.7161458333333333, 'recall': 0.71875, 'f1-score': 0.7167307692307692, 'support': 64}
 
----------
Epoch 25/40
time = 63.42 secondes

Train loss 0.007716502251710292 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.10 secondes

Val loss 2.354571968317032 accuracy 0.71875 macro_avg {'precision': 0.7136363636363636, 'recall': 0.6902834008097165, 'f1-score': 0.6945917285259808, 'support': 64} weighted_avg {'precision': 0.7161931818181818, 'recall': 0.71875, 'f1-score': 0.7106972428419936, 'support': 64}
 
----------
Epoch 26/40
time = 63.93 secondes

Train loss 0.04601316248370109 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.40 secondes

Val loss 1.5618539154529572 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 63.69 secondes

Train loss 0.029210912724066118 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.40 secondes

Val loss 1.4712326377630234 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 28/40
time = 62.79 secondes

Train loss 0.013589704758267158 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.41 secondes

Val loss 1.9226640537381172 accuracy 0.734375 macro_avg {'precision': 0.7246153846153847, 'recall': 0.7216599190283401, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7329807692307693, 'recall': 0.734375, 'f1-score': 0.733495670995671, 'support': 64}
 
----------
Epoch 29/40
time = 63.54 secondes

Train loss 0.010797472032925614 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.35 secondes

Val loss 2.7729963660240173 accuracy 0.71875 macro_avg {'precision': 0.7291666666666667, 'recall': 0.6781376518218624, 'f1-score': 0.681063122923588, 'support': 64} weighted_avg {'precision': 0.7252604166666667, 'recall': 0.71875, 'f1-score': 0.7016196013289037, 'support': 64}
 
----------
Epoch 30/40
time = 63.12 secondes

Train loss 0.004680027035481709 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.24 secondes

Val loss 1.8207261264324188 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 31/40
time = 63.53 secondes

Train loss 0.00021894843016387753 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.37 secondes

Val loss 2.4117945432662964 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 32/40
time = 63.21 secondes

Train loss 0.06950217944843946 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 2.34 secondes

Val loss 1.668237030506134 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 33/40
time = 64.19 secondes

Train loss 8.767282611877431e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.21 secondes

Val loss 2.0411403477191925 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 34/40
time = 63.39 secondes

Train loss 0.0038068929507889234 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.28 secondes

Val loss 1.8155798316001892 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 35/40
time = 64.15 secondes

Train loss 0.036502424025512126 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.41 secondes

Val loss 1.784977287054062 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 36/40
time = 63.51 secondes

Train loss 0.0033578467760945027 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.34 secondes

Val loss 2.149091988801956 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 63.80 secondes

Train loss 0.00033578165378209883 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.33 secondes

Val loss 2.1878055930137634 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 38/40
time = 63.28 secondes

Train loss 1.858470466576171e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.35 secondes

Val loss 2.3817780762910843 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 39/40
time = 170.05 secondes

Train loss 0.03543913245856388 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.15 secondes

Val loss 2.4503409564495087 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 40/40
time = 120.57 secondes

Train loss 1.6785312116994508e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.17 secondes

Val loss 2.401164799928665 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 15 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}

average train time 67.78205339312554

average val time 2.357852375507355
 
time = 2.38 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9343869731800767, 'recall': 0.9420077972709551, 'f1-score': 0.9372586872586872, 'support': 65} weighted_avg {'precision': 0.9407898614795167, 'recall': 0.9384615384615385, 'f1-score': 0.9387288387288387, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_5
----------
Epoch 1/40
time = 97.08 secondes

Train loss 0.6105801715995326 accuracy 0.6647287011146545 macro_avg {'precision': 0.6454976660141545, 'recall': 0.5628220340360516, 'f1-score': 0.5370277208723387, 'support': 516} weighted_avg {'precision': 0.6523246767496723, 'recall': 0.6647286821705426, 'f1-score': 0.6039411397075599, 'support': 516}
 
time = 2.60 secondes

Val loss 0.6312644630670547 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 2/40
time = 97.72 secondes

Train loss 0.38495282049883495 accuracy 0.8275193572044373 macro_avg {'precision': 0.8175280516831009, 'recall': 0.803577523852868, 'f1-score': 0.8094242141300965, 'support': 516} weighted_avg {'precision': 0.825589236904602, 'recall': 0.8275193798449613, 'f1-score': 0.8255846765924285, 'support': 516}
 
time = 2.28 secondes

Val loss 0.4585530683398247 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 3/40
time = 95.65 secondes

Train loss 0.26308536411009054 accuracy 0.8992248177528381 macro_avg {'precision': 0.8884044364527472, 'recall': 0.8967378053736001, 'f1-score': 0.8921682098765432, 'support': 516} weighted_avg {'precision': 0.9009986373079115, 'recall': 0.8992248062015504, 'f1-score': 0.8997593968322327, 'support': 516}
 
time = 2.62 secondes

Val loss 0.5538471266627312 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 4/40
time = 96.28 secondes

Train loss 0.2177308683537624 accuracy 0.9108527302742004 macro_avg {'precision': 0.8996836588551913, 'recall': 0.9127805861222632, 'f1-score': 0.9052000958543014, 'support': 516} weighted_avg {'precision': 0.9141018926177429, 'recall': 0.9108527131782945, 'f1-score': 0.9115705058543572, 'support': 516}
 
time = 2.69 secondes

Val loss 1.2044606059789658 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 5/40
time = 96.84 secondes

Train loss 0.1489811398963811 accuracy 0.9437984228134155 macro_avg {'precision': 0.9387649195640893, 'recall': 0.9397704923361995, 'f1-score': 0.9392633181126333, 'support': 516} weighted_avg {'precision': 0.9438703571845218, 'recall': 0.9437984496124031, 'f1-score': 0.943830613665593, 'support': 516}
 
time = 2.36 secondes

Val loss 0.9686707258224487 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 6/40
time = 97.86 secondes

Train loss 0.14251784359415373 accuracy 0.9515503644943237 macro_avg {'precision': 0.9549808429118773, 'recall': 0.9400793199291322, 'f1-score': 0.9467450491473015, 'support': 516} weighted_avg {'precision': 0.9520812913956459, 'recall': 0.9515503875968992, 'f1-score': 0.9511473592108038, 'support': 516}
 
time = 2.62 secondes

Val loss 1.2175011187791824 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 7/40
time = 95.92 secondes

Train loss 0.11555256271403226 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 2.34 secondes

Val loss 2.6762818694114685 accuracy 0.65625 macro_avg {'precision': 0.8166666666666667, 'recall': 0.5769230769230769, 'f1-score': 0.5210884353741496, 'support': 64} weighted_avg {'precision': 0.7822916666666666, 'recall': 0.65625, 'f1-score': 0.5687925170068028, 'support': 64}
 
----------
Epoch 8/40
time = 96.76 secondes

Train loss 0.3483512049843381 accuracy 0.9379844665527344 macro_avg {'precision': 0.9516938851012102, 'recall': 0.916746582578873, 'f1-score': 0.9304336102731762, 'support': 516} weighted_avg {'precision': 0.9418618990670715, 'recall': 0.937984496124031, 'f1-score': 0.9367408208074196, 'support': 516}
 
time = 2.43 secondes

Val loss 1.5232515335083008 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 9/40
time = 99.65 secondes

Train loss 0.14492588584438304 accuracy 0.9689922332763672 macro_avg {'precision': 0.9637626525930798, 'recall': 0.9699136908148172, 'f1-score': 0.9666774297707459, 'support': 516} weighted_avg {'precision': 0.9694749799514557, 'recall': 0.9689922480620154, 'f1-score': 0.969094372398395, 'support': 516}
 
time = 2.33 secondes

Val loss 2.0451291501522064 accuracy 0.71875 macro_avg {'precision': 0.7925925925925926, 'recall': 0.659919028340081, 'f1-score': 0.6521739130434783, 'support': 64} weighted_avg {'precision': 0.7724537037037038, 'recall': 0.71875, 'f1-score': 0.6807065217391304, 'support': 64}
 
----------
Epoch 10/40
time = 96.78 secondes

Train loss 0.17136061929914198 accuracy 0.9554263353347778 macro_avg {'precision': 0.9655593803786575, 'recall': 0.9396567137493295, 'f1-score': 0.9504854247414336, 'support': 516} weighted_avg {'precision': 0.9577393294106659, 'recall': 0.9554263565891473, 'f1-score': 0.9547897948173559, 'support': 516}
 
time = 2.50 secondes

Val loss 1.5014728158712387 accuracy 0.71875 macro_avg {'precision': 0.7103174603174603, 'recall': 0.714574898785425, 'f1-score': 0.7117117117117117, 'support': 64} weighted_avg {'precision': 0.7229662698412699, 'recall': 0.71875, 'f1-score': 0.7201576576576576, 'support': 64}
 
----------
Epoch 11/40
time = 98.18 secondes

Train loss 0.27812971157078265 accuracy 0.9399224519729614 macro_avg {'precision': 0.9433139534883721, 'recall': 0.9263446190855452, 'f1-score': 0.9337933089686972, 'support': 516} weighted_avg {'precision': 0.9405140165855418, 'recall': 0.939922480620155, 'f1-score': 0.9393368909719265, 'support': 516}
 
time = 2.33 secondes

Val loss 2.1477906703948975 accuracy 0.6875 macro_avg {'precision': 0.7023809523809523, 'recall': 0.7064777327935223, 'f1-score': 0.6871945259042034, 'support': 64} weighted_avg {'precision': 0.7247023809523809, 'recall': 0.6875, 'f1-score': 0.6890273704789833, 'support': 64}
 
----------
Epoch 12/40
time = 99.08 secondes

Train loss 0.14177454037549483 accuracy 0.9670542478561401 macro_avg {'precision': 0.9638687078360145, 'recall': 0.9649318141182972, 'f1-score': 0.9643957382039574, 'support': 516} weighted_avg {'precision': 0.9670997715048896, 'recall': 0.9670542635658915, 'f1-score': 0.9670731183556924, 'support': 516}
 
time = 2.28 secondes

Val loss 1.7538037598133087 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 13/40
time = 96.79 secondes

Train loss 0.028067519679704372 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.51 secondes

Val loss 1.689132198691368 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 14/40
time = 95.64 secondes

Train loss 0.07486269770654899 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 2.77 secondes

Val loss 1.6677513718605042 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 15/40
time = 95.72 secondes

Train loss 0.18354126298094564 accuracy 0.9573643207550049 macro_avg {'precision': 0.9529634483762924, 'recall': 0.9550249500186923, 'f1-score': 0.953976388168137, 'support': 516} weighted_avg {'precision': 0.9574919031927781, 'recall': 0.9573643410852714, 'f1-score': 0.957412740412659, 'support': 516}
 
time = 2.38 secondes

Val loss 2.447042465209961 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 16/40
time = 96.40 secondes

Train loss 0.32178121477817045 accuracy 0.9418604373931885 macro_avg {'precision': 0.952553919949947, 'recall': 0.9232482161142987, 'f1-score': 0.9351487222454964, 'support': 516} weighted_avg {'precision': 0.9445619694953109, 'recall': 0.9418604651162791, 'f1-score': 0.9408900926530335, 'support': 516}
 
time = 2.35 secondes

Val loss 1.8442941308021545 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 17/40
time = 97.88 secondes

Train loss 0.06044246012342311 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.30 secondes

Val loss 1.4839599430561066 accuracy 0.75 macro_avg {'precision': 0.7584541062801933, 'recall': 0.7165991902834008, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7548309178743962, 'recall': 0.75, 'f1-score': 0.7391774891774892, 'support': 64}
 
----------
Epoch 18/40
time = 93.92 secondes

Train loss 0.08736352982558662 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 2.25 secondes

Val loss 2.2618618607521057 accuracy 0.703125 macro_avg {'precision': 0.7136054421768707, 'recall': 0.6589068825910931, 'f1-score': 0.6590972806279787, 'support': 64} weighted_avg {'precision': 0.709906462585034, 'recall': 0.703125, 'f1-score': 0.6820682646481637, 'support': 64}
 
----------
Epoch 19/40
time = 95.30 secondes

Train loss 0.06074255636155034 accuracy 0.9864341020584106 macro_avg {'precision': 0.981958762886598, 'recall': 0.9893617021276595, 'f1-score': 0.9854373042079417, 'support': 516} weighted_avg {'precision': 0.9869235994565653, 'recall': 0.9864341085271318, 'f1-score': 0.9864857946770157, 'support': 516}
 
time = 2.25 secondes

Val loss 1.304172158241272 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 20/40
time = 95.82 secondes

Train loss 0.10594780509740248 accuracy 0.9825581312179565 macro_avg {'precision': 0.9796092993219245, 'recall': 0.9828600685922338, 'f1-score': 0.98119343146982, 'support': 516} weighted_avg {'precision': 0.9826882354266319, 'recall': 0.9825581395348837, 'f1-score': 0.9825875936657844, 'support': 516}
 
time = 2.24 secondes

Val loss 1.7981841564178467 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 21/40
time = 96.18 secondes

Train loss 0.020950009518745708 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.46 secondes

Val loss 2.2905587404966354 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 22/40
time = 98.12 secondes

Train loss 0.0374300014800886 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.30 secondes

Val loss 1.5093772858381271 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 23/40
time = 97.07 secondes

Train loss 0.13740495004254405 accuracy 0.9864341020584106 macro_avg {'precision': 0.9828317901234568, 'recall': 0.9882076621751215, 'f1-score': 0.9854052940154432, 'support': 516} weighted_avg {'precision': 0.9867070114365011, 'recall': 0.9864341085271318, 'f1-score': 0.986471656502011, 'support': 516}
 
time = 2.43 secondes

Val loss 1.3919234722852707 accuracy 0.875 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}
 
----------
Epoch 24/40
time = 96.00 secondes

Train loss 0.03336966437178269 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 2.59 secondes

Val loss 1.9513734579086304 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 25/40
time = 97.97 secondes

Train loss 0.20603643774737782 accuracy 0.9515503644943237 macro_avg {'precision': 0.9410377358490566, 'recall': 0.9620060790273557, 'f1-score': 0.9489244438109492, 'support': 516} weighted_avg {'precision': 0.9572637852859441, 'recall': 0.9515503875968992, 'f1-score': 0.9521114866964612, 'support': 516}
 
time = 2.35 secondes

Val loss 2.0431941896677017 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 26/40
time = 95.70 secondes

Train loss 0.06190236652549753 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 2.46 secondes

Val loss 1.5396923571825027 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 27/40
time = 95.92 secondes

Train loss 0.025572522605326605 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 2.40 secondes

Val loss 2.6437965631484985 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 28/40
time = 97.44 secondes

Train loss 0.17858382947778492 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 2.33 secondes

Val loss 1.5160861313343048 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 29/40
time = 95.92 secondes

Train loss 0.002054555234777085 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.35 secondes

Val loss 2.598694920539856 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 30/40
time = 98.17 secondes

Train loss 0.09427262667073096 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 2.27 secondes

Val loss 1.5170997977256775 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 31/40
time = 96.47 secondes

Train loss 0.05216553043773632 accuracy 0.9903100728988647 macro_avg {'precision': 0.9869791666666667, 'recall': 0.9924012158054711, 'f1-score': 0.9895752100110309, 'support': 516} weighted_avg {'precision': 0.990562419250646, 'recall': 0.9903100775193798, 'f1-score': 0.9903368975014364, 'support': 516}
 
time = 2.32 secondes

Val loss 1.4797152131795883 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 32/40
time = 98.18 secondes

Train loss 0.011231567642563747 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.90 secondes

Val loss 1.5877420231699944 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 33/40
time = 95.15 secondes

Train loss 0.0003088504964773275 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.32 secondes

Val loss 2.2744517624378204 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 34/40
time = 97.47 secondes

Train loss 0.06467259159117847 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 2.29 secondes

Val loss 1.827213704586029 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 35/40
time = 95.18 secondes

Train loss 0.022950739244372402 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.24 secondes

Val loss 2.356035351753235 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 36/40
time = 95.39 secondes

Train loss 0.02523489761347953 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.40 secondes

Val loss 1.5961343199014664 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 37/40
time = 95.47 secondes

Train loss 0.013120350754599547 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.30 secondes

Val loss 2.1533150672912598 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 38/40
time = 94.22 secondes

Train loss 2.0240700795318734e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.25 secondes

Val loss 1.7154121696949005 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 39/40
time = 94.48 secondes

Train loss 2.7752488952528715e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.68 secondes

Val loss 1.7746042907238007 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 40/40
time = 96.16 secondes

Train loss 3.1042768872187786e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.89 secondes

Val loss 1.7621958255767822 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
best_accuracy 0.875 best_epoch 23 macro_avg {'precision': 0.9130434782608696, 'recall': 0.8461538461538461, 'f1-score': 0.8614718614718614, 'support': 64} weighted_avg {'precision': 0.8967391304347826, 'recall': 0.875, 'f1-score': 0.8695887445887445, 'support': 64}

average train time 96.54877365231513

average val time 2.4244620978832243
 
time = 2.57 secondes

test_accuracy 0.9692307710647583 macro_avg {'precision': 0.9683235867446394, 'recall': 0.9683235867446394, 'f1-score': 0.9683235867446394, 'support': 65} weighted_avg {'precision': 0.9692307692307692, 'recall': 0.9692307692307692, 'f1-score': 0.9692307692307692, 'support': 65}

----------

Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 65.99 GiB already allocated; 65.62 MiB free; 68.03 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 79.21 GiB total capacity; 65.40 GiB already allocated; 47.62 MiB free; 68.05 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_5
----------
Epoch 1/40
time = 849.58 secondes

Train loss 1.4312548981263087 accuracy 0.6022392511367798 macro_avg {'precision': 0.5861513429096493, 'recall': 0.5863111111128874, 'f1-score': 0.5772182334626426, 'support': 10182} weighted_avg {'precision': 0.5989619255114187, 'recall': 0.6022392457277549, 'f1-score': 0.5916127116307923, 'support': 10182}
 
time = 24.11 secondes

Val loss 0.7933436409688331 accuracy 0.7553003430366516 macro_avg {'precision': 0.7478226247407316, 'recall': 0.7530032148815808, 'f1-score': 0.7422860984920215, 'support': 1132} weighted_avg {'precision': 0.7551601254187336, 'recall': 0.7553003533568905, 'f1-score': 0.7465671889006782, 'support': 1132}
 
----------
Epoch 2/40
time = 863.67 secondes

Train loss 0.5829177796372813 accuracy 0.8215478658676147 macro_avg {'precision': 0.8065223921253244, 'recall': 0.8087393349745577, 'f1-score': 0.8041436160435025, 'support': 10182} weighted_avg {'precision': 0.8160433532303408, 'recall': 0.8215478295030446, 'f1-score': 0.8162739839941251, 'support': 10182}
 
time = 24.04 secondes

Val loss 0.6160416040622013 accuracy 0.8162544369697571 macro_avg {'precision': 0.8071452889121339, 'recall': 0.8120789542900282, 'f1-score': 0.80750880777158, 'support': 1132} weighted_avg {'precision': 0.813129355514115, 'recall': 0.8162544169611308, 'f1-score': 0.8129537526984704, 'support': 1132}
 
----------
Epoch 3/40
time = 861.28 secondes

Train loss 0.35109051198258506 accuracy 0.9001178741455078 macro_avg {'precision': 0.8943526974592231, 'recall': 0.893299312697789, 'f1-score': 0.893417888894789, 'support': 10182} weighted_avg {'precision': 0.8997624308621794, 'recall': 0.9001178550383029, 'f1-score': 0.8995902930411375, 'support': 10182}
 
time = 23.92 secondes

Val loss 0.6401716846395547 accuracy 0.8392226099967957 macro_avg {'precision': 0.8413760764545763, 'recall': 0.8369603496549309, 'f1-score': 0.8355856610743307, 'support': 1132} weighted_avg {'precision': 0.8451420973684478, 'recall': 0.8392226148409894, 'f1-score': 0.8387181851065832, 'support': 1132}
 
----------
Epoch 4/40
time = 860.91 secondes

Train loss 0.22683721302615206 accuracy 0.9384207725524902 macro_avg {'precision': 0.9355301325182337, 'recall': 0.9347839810971097, 'f1-score': 0.9350276291792028, 'support': 10182} weighted_avg {'precision': 0.9383402153664772, 'recall': 0.9384207424867413, 'f1-score': 0.9382756739125039, 'support': 10182}
 
time = 23.44 secondes

Val loss 0.589920004869116 accuracy 0.8674911856651306 macro_avg {'precision': 0.8731317608585375, 'recall': 0.8656319070912882, 'f1-score': 0.8667292724481367, 'support': 1132} weighted_avg {'precision': 0.8729445335137809, 'recall': 0.8674911660777385, 'f1-score': 0.8678630531706275, 'support': 1132}
 
----------
Epoch 5/40
time = 859.31 secondes

Train loss 0.1717259293541625 accuracy 0.9543312191963196 macro_avg {'precision': 0.9527937353119766, 'recall': 0.9520894667925445, 'f1-score': 0.9523769831393608, 'support': 10182} weighted_avg {'precision': 0.9544517009719067, 'recall': 0.9543311726576311, 'f1-score': 0.9543280535964221, 'support': 10182}
 
time = 23.86 secondes

Val loss 0.672271591486593 accuracy 0.8595406413078308 macro_avg {'precision': 0.8687769404205865, 'recall': 0.8568765612745128, 'f1-score': 0.8591776340961907, 'support': 1132} weighted_avg {'precision': 0.8654796657508681, 'recall': 0.8595406360424028, 'f1-score': 0.8590947645989528, 'support': 1132}
 
----------
Epoch 6/40
time = 860.56 secondes

Train loss 0.15396920466039687 accuracy 0.9628756642341614 macro_avg {'precision': 0.9614276616223091, 'recall': 0.9609437935106195, 'f1-score': 0.961104941351002, 'support': 10182} weighted_avg {'precision': 0.9630514661294381, 'recall': 0.9628756629345905, 'f1-score': 0.9628823896508789, 'support': 10182}
 
time = 22.36 secondes

Val loss 0.858624896423196 accuracy 0.8560070991516113 macro_avg {'precision': 0.8711987930147801, 'recall': 0.8562054903789866, 'f1-score': 0.8558219664762532, 'support': 1132} weighted_avg {'precision': 0.8694960499640965, 'recall': 0.8560070671378092, 'f1-score': 0.8553676415566184, 'support': 1132}
 
----------
Epoch 7/40
time = 860.25 secondes

Train loss 0.13468267497265918 accuracy 0.9665095806121826 macro_avg {'precision': 0.9655453166960342, 'recall': 0.9650139294220601, 'f1-score': 0.9652529883198875, 'support': 10182} weighted_avg {'precision': 0.9665053275073165, 'recall': 0.9665095266155962, 'f1-score': 0.966482061710614, 'support': 10182}
 
time = 21.86 secondes

Val loss 0.8158548109423579 accuracy 0.8613074421882629 macro_avg {'precision': 0.8661895909607408, 'recall': 0.8652670082901581, 'f1-score': 0.8629745161907637, 'support': 1132} weighted_avg {'precision': 0.8684960785588797, 'recall': 0.8613074204946997, 'f1-score': 0.8618842727224654, 'support': 1132}
 
----------
Epoch 8/40
time = 851.31 secondes

Train loss 0.13122339901856836 accuracy 0.9715183973312378 macro_avg {'precision': 0.9712775118482668, 'recall': 0.970778274938783, 'f1-score': 0.9709690134891391, 'support': 10182} weighted_avg {'precision': 0.9716447987447734, 'recall': 0.9715183657434688, 'f1-score': 0.9715241258303963, 'support': 10182}
 
time = 21.32 secondes

Val loss 0.8002755246481786 accuracy 0.8692579865455627 macro_avg {'precision': 0.8724363908351276, 'recall': 0.8685854398782634, 'f1-score': 0.8677077708730231, 'support': 1132} weighted_avg {'precision': 0.8732315575801163, 'recall': 0.8692579505300353, 'f1-score': 0.8683770943584687, 'support': 1132}
 
----------
Epoch 9/40
time = 854.19 secondes

Train loss 0.10568257173730917 accuracy 0.975446879863739 macro_avg {'precision': 0.9744679041366666, 'recall': 0.9743700954167418, 'f1-score': 0.9744051201396882, 'support': 10182} weighted_avg {'precision': 0.9754650710190862, 'recall': 0.9754468670202318, 'f1-score': 0.9754421448299795, 'support': 10182}
 
time = 22.38 secondes

Val loss 0.7780912819988272 accuracy 0.8833922147750854 macro_avg {'precision': 0.8880378483091773, 'recall': 0.8847673855292637, 'f1-score': 0.8839910890539805, 'support': 1132} weighted_avg {'precision': 0.8893365384725258, 'recall': 0.8833922261484098, 'f1-score': 0.8840144510285867, 'support': 1132}
 
----------
Epoch 10/40
time = 854.83 secondes

Train loss 0.11547593472774391 accuracy 0.9752504825592041 macro_avg {'precision': 0.9749240458874999, 'recall': 0.9746499466777367, 'f1-score': 0.9747691701853176, 'support': 10182} weighted_avg {'precision': 0.9752024121710273, 'recall': 0.9752504419563937, 'f1-score': 0.9752099068506445, 'support': 10182}
 
time = 21.98 secondes

Val loss 0.9787806746366263 accuracy 0.8604240417480469 macro_avg {'precision': 0.8707799482569142, 'recall': 0.8601728915048596, 'f1-score': 0.8607962801050763, 'support': 1132} weighted_avg {'precision': 0.8701122613492387, 'recall': 0.8604240282685512, 'f1-score': 0.8603794629849567, 'support': 1132}
 
----------
Epoch 11/40
time = 856.56 secondes

Train loss 0.1002664164796905 accuracy 0.9798664450645447 macro_avg {'precision': 0.9791756573176903, 'recall': 0.9789242427687694, 'f1-score': 0.9790121720485242, 'support': 10182} weighted_avg {'precision': 0.979929925719414, 'recall': 0.9798664309565901, 'f1-score': 0.9798613964172957, 'support': 10182}
 
time = 21.30 secondes

Val loss 0.8351574636697375 accuracy 0.879858672618866 macro_avg {'precision': 0.8902788341130702, 'recall': 0.8827134645725861, 'f1-score': 0.8830838750169882, 'support': 1132} weighted_avg {'precision': 0.8906157564209971, 'recall': 0.8798586572438163, 'f1-score': 0.8819968493492182, 'support': 1132}
 
----------
Epoch 12/40
time = 937.63 secondes

Train loss 0.08698806129133707 accuracy 0.9822235703468323 macro_avg {'precision': 0.9818655120656901, 'recall': 0.9820484353561506, 'f1-score': 0.9819451303243687, 'support': 10182} weighted_avg {'precision': 0.9822679007842865, 'recall': 0.9822235317226478, 'f1-score': 0.9822337873606093, 'support': 10182}
 
time = 21.82 secondes

Val loss 1.0066690578196742 accuracy 0.8736749291419983 macro_avg {'precision': 0.8799553911658908, 'recall': 0.8771299497844742, 'f1-score': 0.8751353353929195, 'support': 1132} weighted_avg {'precision': 0.8820477756365517, 'recall': 0.8736749116607774, 'f1-score': 0.8741216574092657, 'support': 1132}
 
----------
Epoch 13/40
time = 953.09 secondes

Train loss 0.09897647940826625 accuracy 0.980455756187439 macro_avg {'precision': 0.9799204711273972, 'recall': 0.9796644812072438, 'f1-score': 0.9797747588908006, 'support': 10182} weighted_avg {'precision': 0.9804524679648826, 'recall': 0.9804557061481045, 'f1-score': 0.9804367289626226, 'support': 10182}
 
time = 22.07 secondes

Val loss 0.9548734918019068 accuracy 0.8736749291419983 macro_avg {'precision': 0.8821733334823042, 'recall': 0.8760684807349486, 'f1-score': 0.8757894408799732, 'support': 1132} weighted_avg {'precision': 0.882583251375298, 'recall': 0.8736749116607774, 'f1-score': 0.8747577395481589, 'support': 1132}
 
----------
Epoch 14/40
time = 903.12 secondes

Train loss 0.08482772979361608 accuracy 0.983598530292511 macro_avg {'precision': 0.9832645197779021, 'recall': 0.9831745857671859, 'f1-score': 0.9832075857590951, 'support': 10182} weighted_avg {'precision': 0.983630622842753, 'recall': 0.9835985071695148, 'f1-score': 0.9836022163943122, 'support': 10182}
 
time = 20.98 secondes

Val loss 1.031510774091683 accuracy 0.8674911856651306 macro_avg {'precision': 0.8766976349757962, 'recall': 0.8692188574596166, 'f1-score': 0.8682692175574038, 'support': 1132} weighted_avg {'precision': 0.8816688695968382, 'recall': 0.8674911660777385, 'f1-score': 0.8698975958547371, 'support': 1132}
 
----------
Epoch 15/40
time = 854.60 secondes

Train loss 0.0918117870750389 accuracy 0.9829110503196716 macro_avg {'precision': 0.9818964457444375, 'recall': 0.981896429393613, 'f1-score': 0.9818853273384924, 'support': 10182} weighted_avg {'precision': 0.9829071265976774, 'recall': 0.9829110194460813, 'f1-score': 0.9828980720545216, 'support': 10182}
 
time = 21.21 secondes

Val loss 0.8866187608202355 accuracy 0.8860424160957336 macro_avg {'precision': 0.891081172363118, 'recall': 0.8903106438152717, 'f1-score': 0.8879542565873704, 'support': 1132} weighted_avg {'precision': 0.8948188024100511, 'recall': 0.8860424028268551, 'f1-score': 0.8873418682426274, 'support': 1132}
 
----------
Epoch 16/40
time = 880.84 secondes

Train loss 0.07459202086449675 accuracy 0.9852681756019592 macro_avg {'precision': 0.9850442380701914, 'recall': 0.9849555734215079, 'f1-score': 0.9849766326342794, 'support': 10182} weighted_avg {'precision': 0.9853438398266204, 'recall': 0.985268120212139, 'f1-score': 0.98528242732882, 'support': 10182}
 
time = 20.28 secondes

Val loss 0.9828186720073908 accuracy 0.8710247278213501 macro_avg {'precision': 0.8764398230809473, 'recall': 0.8735766004922034, 'f1-score': 0.8720239482235863, 'support': 1132} weighted_avg {'precision': 0.8791673853350164, 'recall': 0.8710247349823321, 'f1-score': 0.8720232881950208, 'support': 1132}
 
----------
Epoch 17/40
time = 936.67 secondes

Train loss 0.0826620026096145 accuracy 0.9846788644790649 macro_avg {'precision': 0.9841159180476889, 'recall': 0.9843863071532208, 'f1-score': 0.9842057983581359, 'support': 10182} weighted_avg {'precision': 0.9847775352355143, 'recall': 0.9846788450206246, 'f1-score': 0.9846823168247154, 'support': 10182}
 
time = 22.71 secondes

Val loss 0.9380689814988471 accuracy 0.8745583295822144 macro_avg {'precision': 0.8824460333133042, 'recall': 0.8786792862550195, 'f1-score': 0.8757327110830649, 'support': 1132} weighted_avg {'precision': 0.8832048826771657, 'recall': 0.8745583038869258, 'f1-score': 0.8736966168634014, 'support': 1132}
 
----------
Epoch 18/40
time = 1096.61 secondes

Train loss 0.07722196563587587 accuracy 0.9846788644790649 macro_avg {'precision': 0.9841131931541419, 'recall': 0.9842574298305411, 'f1-score': 0.9841582425445627, 'support': 10182} weighted_avg {'precision': 0.984766081199487, 'recall': 0.9846788450206246, 'f1-score': 0.9846954427022915, 'support': 10182}
 
time = 24.36 secondes

Val loss 1.0655838723858477 accuracy 0.8568904399871826 macro_avg {'precision': 0.870778027655207, 'recall': 0.8562761435870234, 'f1-score': 0.8572889588669762, 'support': 1132} weighted_avg {'precision': 0.8708501997939126, 'recall': 0.8568904593639576, 'f1-score': 0.8578388055586543, 'support': 1132}
 
----------
Epoch 19/40
time = 1126.44 secondes

Train loss 0.07523725620609653 accuracy 0.9868395328521729 macro_avg {'precision': 0.9866684969758184, 'recall': 0.9865023574270355, 'f1-score': 0.9865685984851377, 'support': 10182} weighted_avg {'precision': 0.9868575757317218, 'recall': 0.9868395207228442, 'f1-score': 0.9868311221011512, 'support': 10182}
 
time = 24.96 secondes

Val loss 1.0309053696382506 accuracy 0.8789752721786499 macro_avg {'precision': 0.8843281834946841, 'recall': 0.8806551868307457, 'f1-score': 0.8790259122189857, 'support': 1132} weighted_avg {'precision': 0.8875809727525954, 'recall': 0.8789752650176679, 'f1-score': 0.8797451296609061, 'support': 1132}
 
----------
Epoch 20/40
time = 1161.02 secondes

Train loss 0.05956662572358395 accuracy 0.9884109497070312 macro_avg {'precision': 0.9882560537502147, 'recall': 0.9883785812421071, 'f1-score': 0.988304817333802, 'support': 10182} weighted_avg {'precision': 0.9884555175785132, 'recall': 0.9884109212335495, 'f1-score': 0.9884206970205229, 'support': 10182}
 
time = 25.06 secondes

Val loss 0.8748426504074891 accuracy 0.8886925578117371 macro_avg {'precision': 0.8925118334200057, 'recall': 0.8919400517478902, 'f1-score': 0.8904687443120831, 'support': 1132} weighted_avg {'precision': 0.8942517570418645, 'recall': 0.8886925795053003, 'f1-score': 0.8898226195767842, 'support': 1132}
 
----------
Epoch 21/40
time = 1186.24 secondes

Train loss 0.06798052210352998 accuracy 0.9889020323753357 macro_avg {'precision': 0.9890155243448474, 'recall': 0.9890104036925571, 'f1-score': 0.9889987025718734, 'support': 10182} weighted_avg {'precision': 0.9889198739293578, 'recall': 0.9889019838931448, 'f1-score': 0.9888963264748601, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.9237130698755106 accuracy 0.8816254734992981 macro_avg {'precision': 0.8942799000319578, 'recall': 0.8841700525341734, 'f1-score': 0.8840708172954901, 'support': 1132} weighted_avg {'precision': 0.8948835779397892, 'recall': 0.8816254416961131, 'f1-score': 0.883124557116959, 'support': 1132}
 
----------
Epoch 22/40
time = 1434.60 secondes

Train loss 0.06869830963003713 accuracy 0.9880180954933167 macro_avg {'precision': 0.9875880780135917, 'recall': 0.9880545492101925, 'f1-score': 0.9877885511851865, 'support': 10182} weighted_avg {'precision': 0.988067416781787, 'recall': 0.9880180711058731, 'f1-score': 0.9880113360685921, 'support': 10182}
 
time = 31.36 secondes

Val loss 0.8765658177292953 accuracy 0.8851590156555176 macro_avg {'precision': 0.8962181571210431, 'recall': 0.8886440851503922, 'f1-score': 0.888139050278016, 'support': 1132} weighted_avg {'precision': 0.8970230388490854, 'recall': 0.8851590106007067, 'f1-score': 0.8867605419323478, 'support': 1132}
 
----------
Epoch 23/40
time = 1341.64 secondes

Train loss 0.0486002111777151 accuracy 0.991750180721283 macro_avg {'precision': 0.9912978070511246, 'recall': 0.991507773538306, 'f1-score': 0.9913937540472091, 'support': 10182} weighted_avg {'precision': 0.9917675584205592, 'recall': 0.9917501473187978, 'f1-score': 0.9917506475144265, 'support': 10182}
 
time = 29.49 secondes

Val loss 0.9066176368249498 accuracy 0.8825088143348694 macro_avg {'precision': 0.8884269364470054, 'recall': 0.8849013650946395, 'f1-score': 0.8836294414327626, 'support': 1132} weighted_avg {'precision': 0.8883479860014257, 'recall': 0.8825088339222615, 'f1-score': 0.8823542635086714, 'support': 1132}
 
----------
Epoch 24/40
time = 1296.30 secondes

Train loss 0.05312774732644372 accuracy 0.9915537238121033 macro_avg {'precision': 0.9915573390814056, 'recall': 0.9915973278725584, 'f1-score': 0.9915628929017013, 'support': 10182} weighted_avg {'precision': 0.9915936074823354, 'recall': 0.9915537222549597, 'f1-score': 0.9915589211309911, 'support': 10182}
 
time = 29.31 secondes

Val loss 0.8944892345486589 accuracy 0.8931095600128174 macro_avg {'precision': 0.897167038094501, 'recall': 0.8951184458582875, 'f1-score': 0.8945623395520252, 'support': 1132} weighted_avg {'precision': 0.8984312918314162, 'recall': 0.8931095406360424, 'f1-score': 0.8941539316475323, 'support': 1132}
 
----------
Epoch 25/40
time = 1329.53 secondes

Train loss 0.04496533385430284 accuracy 0.9912590980529785 macro_avg {'precision': 0.9912434454065313, 'recall': 0.9913965955810407, 'f1-score': 0.9913115669265234, 'support': 10182} weighted_avg {'precision': 0.9912744086011449, 'recall': 0.9912590846592025, 'f1-score': 0.9912584020902269, 'support': 10182}
 
time = 29.98 secondes

Val loss 0.8794359564663339 accuracy 0.8878092169761658 macro_avg {'precision': 0.8950607453220629, 'recall': 0.8906941778266756, 'f1-score': 0.8901770608888668, 'support': 1132} weighted_avg {'precision': 0.8936857677163356, 'recall': 0.8878091872791519, 'f1-score': 0.8878542854076767, 'support': 1132}
 
----------
Epoch 26/40
time = 1342.76 secondes

Train loss 0.049011306044607184 accuracy 0.9918484091758728 macro_avg {'precision': 0.991921961257065, 'recall': 0.9919419572948023, 'f1-score': 0.9919128244728445, 'support': 10182} weighted_avg {'precision': 0.9918500756443376, 'recall': 0.991848359850717, 'f1-score': 0.9918298306232236, 'support': 10182}
 
time = 31.47 secondes

Val loss 0.9377694841178952 accuracy 0.8904593586921692 macro_avg {'precision': 0.8951412983914, 'recall': 0.8931751285404677, 'f1-score': 0.8921064987717102, 'support': 1132} weighted_avg {'precision': 0.895019900335295, 'recall': 0.8904593639575972, 'f1-score': 0.8905885499462283, 'support': 1132}
 
----------
Epoch 27/40
time = 1374.58 secondes

Train loss 0.0459009681416743 accuracy 0.9919465780258179 macro_avg {'precision': 0.991763323532221, 'recall': 0.9914593170309374, 'f1-score': 0.9915972976437841, 'support': 10182} weighted_avg {'precision': 0.9919651724183749, 'recall': 0.9919465723826361, 'f1-score': 0.9919421442725579, 'support': 10182}
 
time = 32.00 secondes

Val loss 1.0882969913456666 accuracy 0.8816254734992981 macro_avg {'precision': 0.8835399946544846, 'recall': 0.8824477529974312, 'f1-score': 0.8816272293447772, 'support': 1132} weighted_avg {'precision': 0.8836165657488688, 'recall': 0.8816254416961131, 'f1-score': 0.8813481513193335, 'support': 1132}
 
----------
Epoch 28/40
time = 1183.43 secondes

Train loss 0.029473741943100897 accuracy 0.9944019317626953 macro_avg {'precision': 0.9945032649057302, 'recall': 0.994447055192234, 'f1-score': 0.9944734731680944, 'support': 10182} weighted_avg {'precision': 0.9944039315752246, 'recall': 0.9944018856806128, 'f1-score': 0.9944011616096184, 'support': 10182}
 
time = 24.97 secondes

Val loss 1.0212657319007377 accuracy 0.8869258165359497 macro_avg {'precision': 0.8915544667711517, 'recall': 0.8874791139978873, 'f1-score': 0.8869129384164554, 'support': 1132} weighted_avg {'precision': 0.8933257714149114, 'recall': 0.8869257950530035, 'f1-score': 0.8876299977680818, 'support': 1132}
 
----------
Epoch 29/40
time = 1184.56 secondes

Train loss 0.03569565054703572 accuracy 0.9942054748535156 macro_avg {'precision': 0.9936179739237506, 'recall': 0.9939453968491894, 'f1-score': 0.9937696855858557, 'support': 10182} weighted_avg {'precision': 0.9942303527852617, 'recall': 0.9942054606167747, 'f1-score': 0.9942078529762364, 'support': 10182}
 
time = 27.13 secondes

Val loss 1.0344161822184004 accuracy 0.8833922147750854 macro_avg {'precision': 0.8917407303703138, 'recall': 0.8847318408413093, 'f1-score': 0.8846554098789208, 'support': 1132} weighted_avg {'precision': 0.8919374618135942, 'recall': 0.8833922261484098, 'f1-score': 0.8842967857058172, 'support': 1132}
 
----------
Epoch 30/40
time = 1216.95 secondes

Train loss 0.022770490139840747 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959021286026435, 'recall': 0.9960756059472263, 'f1-score': 0.9959851676223506, 'support': 10182} weighted_avg {'precision': 0.9960800174614386, 'recall': 0.9960714987232371, 'f1-score': 0.9960721151947546, 'support': 10182}
 
time = 28.08 secondes

Val loss 1.045017809698243 accuracy 0.8851590156555176 macro_avg {'precision': 0.8894988628335682, 'recall': 0.8868737526970942, 'f1-score': 0.8869093155104244, 'support': 1132} weighted_avg {'precision': 0.8873105198465048, 'recall': 0.8851590106007067, 'f1-score': 0.8850035136412726, 'support': 1132}
 
----------
Epoch 31/40
time = 1244.98 secondes

Train loss 0.019269846633707267 accuracy 0.9964643716812134 macro_avg {'precision': 0.9965086190484822, 'recall': 0.996528478574404, 'f1-score': 0.9965164272105149, 'support': 10182} weighted_avg {'precision': 0.9964707084233485, 'recall': 0.9964643488509134, 'f1-score': 0.9964653212931619, 'support': 10182}
 
time = 22.92 secondes

Val loss 1.0626089175888742 accuracy 0.8851590156555176 macro_avg {'precision': 0.8886867309776239, 'recall': 0.888119372788222, 'f1-score': 0.8869526378187494, 'support': 1132} weighted_avg {'precision': 0.8902285262272368, 'recall': 0.8851590106007067, 'f1-score': 0.8861654169361, 'support': 1132}
 
----------
Epoch 32/40
time = 1081.97 secondes

Train loss 0.025597536132820203 accuracy 0.9953840374946594 macro_avg {'precision': 0.9953983378912685, 'recall': 0.9955014905759458, 'f1-score': 0.9954465078490544, 'support': 10182} weighted_avg {'precision': 0.9953869521759636, 'recall': 0.9953840109998036, 'f1-score': 0.9953821309251999, 'support': 10182}
 
time = 23.83 secondes

Val loss 1.095460822059669 accuracy 0.8816254734992981 macro_avg {'precision': 0.8917167063296946, 'recall': 0.883989297354631, 'f1-score': 0.8859204862370322, 'support': 1132} weighted_avg {'precision': 0.8873206902810274, 'recall': 0.8816254416961131, 'f1-score': 0.8825601769228062, 'support': 1132}
 
----------
Epoch 33/40
time = 1126.25 secondes

Train loss 0.022465366227547613 accuracy 0.9965626001358032 macro_avg {'precision': 0.9966653641693146, 'recall': 0.9966530290871767, 'f1-score': 0.9966569244980084, 'support': 10182} weighted_avg {'precision': 0.9965623313511267, 'recall': 0.9965625613828325, 'f1-score': 0.9965601173886991, 'support': 10182}
 
time = 24.63 secondes

Val loss 0.9557764117839789 accuracy 0.8878092169761658 macro_avg {'precision': 0.894831828024631, 'recall': 0.8891746571295455, 'f1-score': 0.8908763781506653, 'support': 1132} weighted_avg {'precision': 0.8922129775864506, 'recall': 0.8878091872791519, 'f1-score': 0.8888600651535743, 'support': 1132}
 
----------
Epoch 34/40
time = 1153.45 secondes

Train loss 0.015950075875767234 accuracy 0.9973483085632324 macro_avg {'precision': 0.9973742507126133, 'recall': 0.9974361392635351, 'f1-score': 0.9973991320056038, 'support': 10182} weighted_avg {'precision': 0.9973638040738988, 'recall': 0.997348261638185, 'f1-score': 0.9973498427812444, 'support': 10182}
 
time = 24.94 secondes

Val loss 0.9064437302032518 accuracy 0.9019434452056885 macro_avg {'precision': 0.9067339523448599, 'recall': 0.9051767337547328, 'f1-score': 0.9048602753463504, 'support': 1132} weighted_avg {'precision': 0.9042875630894683, 'recall': 0.9019434628975265, 'f1-score': 0.9020518290019937, 'support': 1132}
 
----------
Epoch 35/40
time = 1193.01 secondes

Train loss 0.01455530049232758 accuracy 0.9970536828041077 macro_avg {'precision': 0.9971543262307003, 'recall': 0.997018611938809, 'f1-score': 0.9970822767886789, 'support': 10182} weighted_avg {'precision': 0.9970619155313678, 'recall': 0.9970536240424278, 'f1-score': 0.9970536822570581, 'support': 10182}
 
time = 24.47 secondes

Val loss 0.9059621625418541 accuracy 0.8939929604530334 macro_avg {'precision': 0.8963631287002232, 'recall': 0.8957724269784112, 'f1-score': 0.8951897111619778, 'support': 1132} weighted_avg {'precision': 0.8958548795847242, 'recall': 0.8939929328621908, 'f1-score': 0.8940104371509244, 'support': 1132}
 
----------
Epoch 36/40
time = 1394.89 secondes

Train loss 0.010811260358752985 accuracy 0.9974464774131775 macro_avg {'precision': 0.9972048431402799, 'recall': 0.997145188467402, 'f1-score': 0.9971730159821467, 'support': 10182} weighted_avg {'precision': 0.9974474165315602, 'recall': 0.9974464741701041, 'f1-score': 0.9974450588588412, 'support': 10182}
 
time = 32.26 secondes

Val loss 0.9508356560163392 accuracy 0.8975265026092529 macro_avg {'precision': 0.9003011736092728, 'recall': 0.9017584196718174, 'f1-score': 0.9000250111304823, 'support': 1132} weighted_avg {'precision': 0.9000551448434188, 'recall': 0.8975265017667845, 'f1-score': 0.8978360119902286, 'support': 1132}
 
----------
Epoch 37/40
time = 1398.72 secondes

Train loss 0.007389041417653866 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986176299168947, 'recall': 0.998654637879333, 'f1-score': 0.9986347063586098, 'support': 10182} weighted_avg {'precision': 0.9986280464622246, 'recall': 0.998625024553133, 'f1-score': 0.9986251081228757, 'support': 10182}
 
time = 32.59 secondes

Val loss 1.0624865795993634 accuracy 0.8869258165359497 macro_avg {'precision': 0.8901787263213435, 'recall': 0.8915742031457692, 'f1-score': 0.8900483601863364, 'support': 1132} weighted_avg {'precision': 0.8900049984152029, 'recall': 0.8869257950530035, 'f1-score': 0.8876511333546707, 'support': 1132}
 
----------
Epoch 38/40
time = 1253.29 secondes

Train loss 0.015716702129780852 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976884421082216, 'recall': 0.9977138545763458, 'f1-score': 0.9976989138004179, 'support': 10182} weighted_avg {'precision': 0.9976479711046489, 'recall': 0.9976428992339422, 'f1-score': 0.9976431175634519, 'support': 10182}
 
time = 26.56 secondes

Val loss 0.9402411588595807 accuracy 0.8931095600128174 macro_avg {'precision': 0.8966264705200435, 'recall': 0.8962712308683505, 'f1-score': 0.8953582932048393, 'support': 1132} weighted_avg {'precision': 0.8966932950645161, 'recall': 0.8931095406360424, 'f1-score': 0.8937697237430003, 'support': 1132}
 
----------
Epoch 39/40
time = 1174.70 secondes

Train loss 0.002657911222589605 accuracy 0.9995089769363403 macro_avg {'precision': 0.9995252622584371, 'recall': 0.9995275336091336, 'f1-score': 0.9995263031761634, 'support': 10182} weighted_avg {'precision': 0.9995091306721604, 'recall': 0.9995089373404047, 'f1-score': 0.9995089384579537, 'support': 10182}
 
time = 27.58 secondes

Val loss 1.10635522957985 accuracy 0.8931095600128174 macro_avg {'precision': 0.8959953073625903, 'recall': 0.8969748158089919, 'f1-score': 0.8944020073268675, 'support': 1132} weighted_avg {'precision': 0.8974899420034819, 'recall': 0.8931095406360424, 'f1-score': 0.8931984016997568, 'support': 1132}
 
----------
Epoch 40/40
time = 2324.00 secondes

Train loss 0.005112186250336213 accuracy 0.9993125200271606 macro_avg {'precision': 0.9992857614185683, 'recall': 0.9992914532927715, 'f1-score': 0.9992876470487395, 'support': 10182} weighted_avg {'precision': 0.9993140942865576, 'recall': 0.9993125122765665, 'f1-score': 0.9993123992711441, 'support': 10182}
 
time = 61.07 secondes

Val loss 1.0489486779109438 accuracy 0.8957597017288208 macro_avg {'precision': 0.8987508485581344, 'recall': 0.9001263698524072, 'f1-score': 0.8976044452027022, 'support': 1132} weighted_avg {'precision': 0.9000369380784401, 'recall': 0.8957597173144877, 'f1-score': 0.8959454225838379, 'support': 1132}
 
----------
best_accuracy 0.9019434452056885 best_epoch 34 macro_avg {'precision': 0.9067339523448599, 'recall': 0.9051767337547328, 'f1-score': 0.9048602753463504, 'support': 1132} weighted_avg {'precision': 0.9042875630894683, 'recall': 0.9019434628975265, 'f1-score': 0.9020518290019937, 'support': 1132}

average train time 1112.9581684589386

average val time 26.12616394162178
 
time = 428.29 secondes

test_accuracy 0.8279341459274292 macro_avg {'precision': 0.8275417584675105, 'recall': 0.8203266791981296, 'f1-score': 0.8203523576848644, 'support': 7532} weighted_avg {'precision': 0.8330005334813047, 'recall': 0.8279341476367499, 'f1-score': 0.8270706861260362, 'support': 7532}

----------


normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_5
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 841.04 secondes

Train loss 1.4359859216437796 accuracy 0.6041052937507629 macro_avg {'precision': 0.6115785964449099, 'recall': 0.588374086515131, 'f1-score': 0.579138179797241, 'support': 10182} weighted_avg {'precision': 0.6170356398110198, 'recall': 0.6041052838342172, 'f1-score': 0.593570297256576, 'support': 10182}
 
time = 16.99 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.8336770920686318 accuracy 0.7402827143669128 macro_avg {'precision': 0.7235120196067658, 'recall': 0.7381245717223879, 'f1-score': 0.7208831684483508, 'support': 1132} weighted_avg {'precision': 0.7337041997588066, 'recall': 0.7402826855123675, 'f1-score': 0.7273678813504183, 'support': 1132}
 
----------
Epoch 2/40
time = 833.47 secondes

Train loss 0.6253614772924074 accuracy 0.8085837960243225 macro_avg {'precision': 0.7937509314889337, 'recall': 0.7957543820029691, 'f1-score': 0.7910500398717386, 'support': 10182} weighted_avg {'precision': 0.8032259872745175, 'recall': 0.8085837752897269, 'f1-score': 0.8032392548364184, 'support': 10182}
 
time = 16.55 secondes

Val loss 0.6084149794679292 accuracy 0.8215547800064087 macro_avg {'precision': 0.8160129200438698, 'recall': 0.8189178213636487, 'f1-score': 0.8127847393062533, 'support': 1132} weighted_avg {'precision': 0.8215148970343925, 'recall': 0.8215547703180212, 'f1-score': 0.8167221989738878, 'support': 1132}
 
----------
Epoch 3/40
time = 833.67 secondes

Train loss 0.37901885416563397 accuracy 0.8916715979576111 macro_avg {'precision': 0.8862011639644525, 'recall': 0.8861885543547358, 'f1-score': 0.8860655753222973, 'support': 10182} weighted_avg {'precision': 0.8920613615883124, 'recall': 0.8916715772932626, 'f1-score': 0.8917430052023493, 'support': 10182}
 
time = 17.15 secondes

Val loss 0.5586988792662889 accuracy 0.8427562117576599 macro_avg {'precision': 0.8457708742696213, 'recall': 0.8457306821653555, 'f1-score': 0.8426933770878666, 'support': 1132} weighted_avg {'precision': 0.8495781184525897, 'recall': 0.842756183745583, 'f1-score': 0.8427032742511928, 'support': 1132}
 
----------
Epoch 4/40
time = 833.52 secondes

Train loss 0.2650797669424893 accuracy 0.9242781400680542 macro_avg {'precision': 0.9205413955708899, 'recall': 0.9205248479817545, 'f1-score': 0.9204021554877364, 'support': 10182} weighted_avg {'precision': 0.9243102159404728, 'recall': 0.9242781378903948, 'f1-score': 0.9241680509656972, 'support': 10182}
 
time = 16.05 secondes

Val loss 0.5314093072518287 accuracy 0.8745583295822144 macro_avg {'precision': 0.8794963732458978, 'recall': 0.8751185168266531, 'f1-score': 0.8750855386583345, 'support': 1132} weighted_avg {'precision': 0.8803936622456631, 'recall': 0.8745583038869258, 'f1-score': 0.8751819413390292, 'support': 1132}
 
----------
Epoch 5/40
time = 833.72 secondes

Train loss 0.20787576911642014 accuracy 0.9458849430084229 macro_avg {'precision': 0.9440781562452365, 'recall': 0.9430191831784127, 'f1-score': 0.9434002833391355, 'support': 10182} weighted_avg {'precision': 0.9459446597960931, 'recall': 0.9458848949125909, 'f1-score': 0.9457752854264664, 'support': 10182}
 
time = 15.87 secondes

Val loss 0.6224908117421338 accuracy 0.8666077852249146 macro_avg {'precision': 0.8724147131132431, 'recall': 0.8670296151414068, 'f1-score': 0.8671030965713709, 'support': 1132} weighted_avg {'precision': 0.8718402769055285, 'recall': 0.8666077738515902, 'f1-score': 0.8665012398598103, 'support': 1132}
 
----------
Epoch 6/40
time = 833.65 secondes

Train loss 0.17425055750550664 accuracy 0.9559025764465332 macro_avg {'precision': 0.9546908965044161, 'recall': 0.9543906061901322, 'f1-score': 0.9544999673945954, 'support': 10182} weighted_avg {'precision': 0.9559909567960366, 'recall': 0.9559025731683363, 'f1-score': 0.9559062959810732, 'support': 10182}
 
time = 16.22 secondes

Val loss 0.7199654635730606 accuracy 0.8648409843444824 macro_avg {'precision': 0.8693571361122616, 'recall': 0.867512928961378, 'f1-score': 0.8652112351673764, 'support': 1132} weighted_avg {'precision': 0.8726198238182822, 'recall': 0.8648409893992933, 'f1-score': 0.8654902250225508, 'support': 1132}
 
----------
Epoch 7/40
time = 833.88 secondes

Train loss 0.13485908563584353 accuracy 0.9677863121032715 macro_avg {'precision': 0.9665540434655038, 'recall': 0.966356691638427, 'f1-score': 0.9664370716834183, 'support': 10182} weighted_avg {'precision': 0.9677621500393132, 'recall': 0.9677862895305441, 'f1-score': 0.9677561593085557, 'support': 10182}
 
time = 15.83 secondes

Val loss 0.7490412853297476 accuracy 0.8780918717384338 macro_avg {'precision': 0.8884635019228346, 'recall': 0.8788895018781391, 'f1-score': 0.8812947706915084, 'support': 1132} weighted_avg {'precision': 0.8869342054529559, 'recall': 0.8780918727915195, 'f1-score': 0.8798968861581833, 'support': 1132}
 
----------
Epoch 8/40
time = 833.15 secondes

Train loss 0.13546646493137082 accuracy 0.9680809378623962 macro_avg {'precision': 0.9672930309616469, 'recall': 0.9671944885721864, 'f1-score': 0.9672087203417801, 'support': 10182} weighted_avg {'precision': 0.9681437134065279, 'recall': 0.9680809271263013, 'f1-score': 0.9680768770201392, 'support': 10182}
 
time = 15.85 secondes

Val loss 0.7735924931783328 accuracy 0.8727915287017822 macro_avg {'precision': 0.879497681951471, 'recall': 0.8731191357743834, 'f1-score': 0.874019598168184, 'support': 1132} weighted_avg {'precision': 0.8787885549234148, 'recall': 0.872791519434629, 'f1-score': 0.8731901270338276, 'support': 1132}
 
----------
Epoch 9/40
time = 833.91 secondes

Train loss 0.1286747109176817 accuracy 0.9716166257858276 macro_avg {'precision': 0.9709292440417034, 'recall': 0.9708354640024034, 'f1-score': 0.9708329635130308, 'support': 10182} weighted_avg {'precision': 0.9716316388184356, 'recall': 0.9716165782753879, 'f1-score': 0.9715733271458431, 'support': 10182}
 
time = 15.84 secondes

Val loss 0.9651985226148202 accuracy 0.862190842628479 macro_avg {'precision': 0.8725171758028019, 'recall': 0.8705733064873569, 'f1-score': 0.8627889345405964, 'support': 1132} weighted_avg {'precision': 0.875751924373794, 'recall': 0.8621908127208481, 'f1-score': 0.8589941540053767, 'support': 1132}
 
----------
Epoch 10/40
time = 833.83 secondes

Train loss 0.12563205300674962 accuracy 0.9713219404220581 macro_avg {'precision': 0.9710020619073692, 'recall': 0.9710754823950923, 'f1-score': 0.9709832113552915, 'support': 10182} weighted_avg {'precision': 0.9714243758787722, 'recall': 0.9713219406796307, 'f1-score': 0.9713190977332897, 'support': 10182}
 
time = 16.04 secondes

Val loss 0.7446257168727166 accuracy 0.8922261595726013 macro_avg {'precision': 0.8964199608075699, 'recall': 0.8964323059703059, 'f1-score': 0.8946902580181939, 'support': 1132} weighted_avg {'precision': 0.8982498287379278, 'recall': 0.892226148409894, 'f1-score': 0.8934564535754443, 'support': 1132}
 
----------
Epoch 11/40
time = 833.77 secondes

Train loss 0.10322341940073688 accuracy 0.9791789650917053 macro_avg {'precision': 0.9789526372721513, 'recall': 0.9784799895791151, 'f1-score': 0.9786686260706116, 'support': 10182} weighted_avg {'precision': 0.9792621463672087, 'recall': 0.9791789432331566, 'f1-score': 0.9791730964693484, 'support': 10182}
 
time = 15.94 secondes

Val loss 0.8699215380843847 accuracy 0.8692579865455627 macro_avg {'precision': 0.8806922009479303, 'recall': 0.8717286817410752, 'f1-score': 0.8717994325701838, 'support': 1132} weighted_avg {'precision': 0.8791210215543146, 'recall': 0.8692579505300353, 'f1-score': 0.8699257396288513, 'support': 1132}
 
----------
Epoch 12/40
time = 833.83 secondes

Train loss 0.10182776560031354 accuracy 0.9786878824234009 macro_avg {'precision': 0.9781327890178501, 'recall': 0.9782154652779289, 'f1-score': 0.9781510049347588, 'support': 10182} weighted_avg {'precision': 0.9787257915502913, 'recall': 0.9786878805735612, 'f1-score': 0.9786830950179912, 'support': 10182}
 
time = 16.14 secondes

Val loss 0.8699083523107463 accuracy 0.8745583295822144 macro_avg {'precision': 0.8814391879044956, 'recall': 0.8723212862462997, 'f1-score': 0.8715492532006849, 'support': 1132} weighted_avg {'precision': 0.8804871868121411, 'recall': 0.8745583038869258, 'f1-score': 0.8731364902068064, 'support': 1132}
 
----------
Epoch 13/40
time = 834.10 secondes

Train loss 0.10792054092120255 accuracy 0.9778040051460266 macro_avg {'precision': 0.9771788358527207, 'recall': 0.9767407800933892, 'f1-score': 0.9769141503943326, 'support': 10182} weighted_avg {'precision': 0.977874603321086, 'recall': 0.9778039677862895, 'f1-score': 0.9777950794098952, 'support': 10182}
 
time = 15.80 secondes

Val loss 0.8781702863060685 accuracy 0.8763250708580017 macro_avg {'precision': 0.8812735772901815, 'recall': 0.879079421361981, 'f1-score': 0.8766790330409826, 'support': 1132} weighted_avg {'precision': 0.8837562529836646, 'recall': 0.8763250883392226, 'f1-score': 0.8765778445187545, 'support': 1132}
 
----------
Epoch 14/40
time = 833.92 secondes

Train loss 0.09465792713889866 accuracy 0.9829110503196716 macro_avg {'precision': 0.9815893490177137, 'recall': 0.9820967056721764, 'f1-score': 0.9817959417566193, 'support': 10182} weighted_avg {'precision': 0.9830594414989671, 'recall': 0.9829110194460813, 'f1-score': 0.9829505335676929, 'support': 10182}
 
time = 16.35 secondes

Val loss 0.787243391163557 accuracy 0.8878092169761658 macro_avg {'precision': 0.889523792046125, 'recall': 0.8873380358705141, 'f1-score': 0.8870959004175394, 'support': 1132} weighted_avg {'precision': 0.8915642722320427, 'recall': 0.8878091872791519, 'f1-score': 0.8883777713039791, 'support': 1132}
 
----------
Epoch 15/40
time = 834.10 secondes

Train loss 0.09304337042239107 accuracy 0.9826164245605469 macro_avg {'precision': 0.9821630599330236, 'recall': 0.9823438162888831, 'f1-score': 0.9822057909870858, 'support': 10182} weighted_avg {'precision': 0.982701716121811, 'recall': 0.9826163818503241, 'f1-score': 0.9826122588549823, 'support': 10182}
 
time = 15.96 secondes

Val loss 0.9249479246713569 accuracy 0.879858672618866 macro_avg {'precision': 0.8816361934749821, 'recall': 0.881054474342462, 'f1-score': 0.8795519835184245, 'support': 1132} weighted_avg {'precision': 0.883336200065236, 'recall': 0.8798586572438163, 'f1-score': 0.8797273692529395, 'support': 1132}
 
----------
Epoch 16/40
time = 833.92 secondes

Train loss 0.07693101135124576 accuracy 0.9849734902381897 macro_avg {'precision': 0.9842398362807833, 'recall': 0.9843771997253038, 'f1-score': 0.9842922738232888, 'support': 10182} weighted_avg {'precision': 0.9849879689138972, 'recall': 0.9849734826163818, 'f1-score': 0.9849644074669784, 'support': 10182}
 
time = 15.80 secondes

Val loss 0.8792896916809849 accuracy 0.8860424160957336 macro_avg {'precision': 0.8895874715337684, 'recall': 0.8876429694550444, 'f1-score': 0.8868151878652716, 'support': 1132} weighted_avg {'precision': 0.8913261476745891, 'recall': 0.8860424028268551, 'f1-score': 0.886968932346656, 'support': 1132}
 
----------
Epoch 17/40
time = 834.03 secondes

Train loss 0.079076971054935 accuracy 0.9850717186927795 macro_avg {'precision': 0.9848592727207134, 'recall': 0.9842388388066816, 'f1-score': 0.9845208490247959, 'support': 10182} weighted_avg {'precision': 0.9850836044413764, 'recall': 0.985071695148301, 'f1-score': 0.9850526559785158, 'support': 10182}
 
time = 15.81 secondes

Val loss 1.0055479906646134 accuracy 0.8780918717384338 macro_avg {'precision': 0.8853881091835802, 'recall': 0.8812045289814664, 'f1-score': 0.879227394044309, 'support': 1132} weighted_avg {'precision': 0.888674044002992, 'recall': 0.8780918727915195, 'f1-score': 0.879394248373433, 'support': 1132}
 
----------
Epoch 18/40
time = 834.38 secondes

Train loss 0.09529640037279315 accuracy 0.9828128218650818 macro_avg {'precision': 0.9818277769249525, 'recall': 0.9817831530303176, 'f1-score': 0.9817869391122196, 'support': 10182} weighted_avg {'precision': 0.9828118440812919, 'recall': 0.9828128069141623, 'f1-score': 0.9827960019837, 'support': 10182}
 
time = 15.74 secondes

Val loss 0.9675544286077075 accuracy 0.8710247278213501 macro_avg {'precision': 0.8756574139937949, 'recall': 0.867411300159224, 'f1-score': 0.8681236784034294, 'support': 1132} weighted_avg {'precision': 0.8776324273305197, 'recall': 0.8710247349823321, 'f1-score': 0.8713701119254484, 'support': 1132}
 
----------
Epoch 19/40
time = 833.83 secondes

Train loss 0.0879586329741001 accuracy 0.9840896129608154 macro_avg {'precision': 0.9833054502010248, 'recall': 0.9826619792726452, 'f1-score': 0.9829363386566807, 'support': 10182} weighted_avg {'precision': 0.9841063023954151, 'recall': 0.9840895698291102, 'f1-score': 0.9840580516192299, 'support': 10182}
 
time = 16.37 secondes

Val loss 0.9405480187331346 accuracy 0.8772084712982178 macro_avg {'precision': 0.8844989010056616, 'recall': 0.8768907750757711, 'f1-score': 0.8772666226297527, 'support': 1132} weighted_avg {'precision': 0.8828473732644577, 'recall': 0.877208480565371, 'f1-score': 0.8766854769979026, 'support': 1132}
 
----------
Epoch 20/40
time = 834.18 secondes

Train loss 0.07670682597396378 accuracy 0.9872323870658875 macro_avg {'precision': 0.9864486459281719, 'recall': 0.9865001221758828, 'f1-score': 0.9864593980650438, 'support': 10182} weighted_avg {'precision': 0.9872613255308802, 'recall': 0.9872323708505205, 'f1-score': 0.9872329839096389, 'support': 10182}
 
time = 16.46 secondes

Val loss 0.9428760547938586 accuracy 0.8833922147750854 macro_avg {'precision': 0.8898438203572299, 'recall': 0.8794818807482576, 'f1-score': 0.8792361791886281, 'support': 1132} weighted_avg {'precision': 0.8917646603182864, 'recall': 0.8833922261484098, 'f1-score': 0.8828274855764494, 'support': 1132}
 
----------
Epoch 21/40
time = 833.86 secondes

Train loss 0.0641264440243248 accuracy 0.988705575466156 macro_avg {'precision': 0.9882754419162303, 'recall': 0.9885474574758983, 'f1-score': 0.9883995406948092, 'support': 10182} weighted_avg {'precision': 0.9887147075268026, 'recall': 0.9887055588293067, 'f1-score': 0.988699011259809, 'support': 10182}
 
time = 16.16 secondes

Val loss 0.98804946892266 accuracy 0.8860424160957336 macro_avg {'precision': 0.8911445123234021, 'recall': 0.8872221550503092, 'f1-score': 0.8858031471364602, 'support': 1132} weighted_avg {'precision': 0.8946881923169903, 'recall': 0.8860424028268551, 'f1-score': 0.8870786420001951, 'support': 1132}
 
----------
Epoch 22/40
time = 833.72 secondes

Train loss 0.0725790101898563 accuracy 0.9879198670387268 macro_avg {'precision': 0.9876454986170637, 'recall': 0.9876366738029894, 'f1-score': 0.9876222069511131, 'support': 10182} weighted_avg {'precision': 0.9879490035731506, 'recall': 0.987919858573954, 'f1-score': 0.987915316711477, 'support': 10182}
 
time = 15.67 secondes

Val loss 1.1213829368717714 accuracy 0.8692579865455627 macro_avg {'precision': 0.872496693251111, 'recall': 0.8719853400455152, 'f1-score': 0.8689748736610527, 'support': 1132} weighted_avg {'precision': 0.8760940062168342, 'recall': 0.8692579505300353, 'f1-score': 0.8692562087425862, 'support': 1132}
 
----------
Epoch 23/40
time = 833.69 secondes

Train loss 0.06138286530324618 accuracy 0.98978590965271 macro_avg {'precision': 0.9895755671461851, 'recall': 0.9893900732171448, 'f1-score': 0.9894756773363973, 'support': 10182} weighted_avg {'precision': 0.9897858038268808, 'recall': 0.9897858966804164, 'f1-score': 0.9897789628993469, 'support': 10182}
 
time = 16.10 secondes

Val loss 0.8898202362380148 accuracy 0.8913427591323853 macro_avg {'precision': 0.8969138479567169, 'recall': 0.8919759774482217, 'f1-score': 0.8928565821989551, 'support': 1132} weighted_avg {'precision': 0.8961077561621872, 'recall': 0.8913427561837456, 'f1-score': 0.8921654407659206, 'support': 1132}
 
----------
Epoch 24/40
time = 834.44 secondes

Train loss 0.059825254081151 accuracy 0.9899823665618896 macro_avg {'precision': 0.989918377921964, 'recall': 0.9900423076945556, 'f1-score': 0.9899681973250949, 'support': 10182} weighted_avg {'precision': 0.9900102051693161, 'recall': 0.9899823217442546, 'f1-score': 0.9899838386658277, 'support': 10182}
 
time = 16.36 secondes

Val loss 0.8402501346301993 accuracy 0.8878092169761658 macro_avg {'precision': 0.8932536167228082, 'recall': 0.891451143937594, 'f1-score': 0.8900011327926005, 'support': 1132} weighted_avg {'precision': 0.895324367375492, 'recall': 0.8878091872791519, 'f1-score': 0.8890566463647741, 'support': 1132}
 
----------
Epoch 25/40
time = 833.62 secondes

Train loss 0.05685468986368985 accuracy 0.9907680749893188 macro_avg {'precision': 0.9908389167307192, 'recall': 0.9907598197674217, 'f1-score': 0.99077797198814, 'support': 10182} weighted_avg {'precision': 0.9907912435421542, 'recall': 0.9907680219996071, 'f1-score': 0.990758047747322, 'support': 10182}
 
time = 16.37 secondes

Val loss 0.9185877745557276 accuracy 0.8922261595726013 macro_avg {'precision': 0.896161700867947, 'recall': 0.8958467642425145, 'f1-score': 0.894350906161284, 'support': 1132} weighted_avg {'precision': 0.8964070598325868, 'recall': 0.892226148409894, 'f1-score': 0.8926788545325366, 'support': 1132}
 
----------
Epoch 26/40
time = 834.02 secondes

Train loss 0.04798192115196807 accuracy 0.9920448064804077 macro_avg {'precision': 0.991654563837624, 'recall': 0.9914356987424847, 'f1-score': 0.9915351429637947, 'support': 10182} weighted_avg {'precision': 0.9920593428842002, 'recall': 0.9920447849145551, 'f1-score': 0.9920432470631094, 'support': 10182}
 
time = 16.83 secondes

Val loss 0.8565206280943809 accuracy 0.8886925578117371 macro_avg {'precision': 0.8963321658986866, 'recall': 0.8936545217237555, 'f1-score': 0.8912870271873443, 'support': 1132} weighted_avg {'precision': 0.8981586869613538, 'recall': 0.8886925795053003, 'f1-score': 0.8893766514383155, 'support': 1132}
 
----------
Epoch 27/40
time = 833.02 secondes

Train loss 0.03829216314701757 accuracy 0.9931251406669617 macro_avg {'precision': 0.9931571115997316, 'recall': 0.9931124252690836, 'f1-score': 0.9931215929705635, 'support': 10182} weighted_avg {'precision': 0.9931313200194287, 'recall': 0.9931251227656649, 'f1-score': 0.9931148217241247, 'support': 10182}
 
time = 16.17 secondes

Val loss 0.9219513097849185 accuracy 0.8992933034896851 macro_avg {'precision': 0.9034608770639633, 'recall': 0.9021348285108456, 'f1-score': 0.9015351287137181, 'support': 1132} weighted_avg {'precision': 0.9035474975155886, 'recall': 0.8992932862190812, 'f1-score': 0.9000243959020334, 'support': 1132}
 
----------
Epoch 28/40
time = 833.38 secondes

Train loss 0.03444620174795401 accuracy 0.9936162233352661 macro_avg {'precision': 0.9934927030303402, 'recall': 0.9936454973363438, 'f1-score': 0.9935625692586317, 'support': 10182} weighted_avg {'precision': 0.9936236570246617, 'recall': 0.9936161854252603, 'f1-score': 0.9936134840202441, 'support': 10182}
 
time = 16.18 secondes

Val loss 1.0694728272194969 accuracy 0.8816254734992981 macro_avg {'precision': 0.8938924873473804, 'recall': 0.8882375284032941, 'f1-score': 0.886257919331444, 'support': 1132} weighted_avg {'precision': 0.8968197607919431, 'recall': 0.8816254416961131, 'f1-score': 0.8843328644147308, 'support': 1132}
 
----------
Epoch 29/40
time = 833.31 secondes

Train loss 0.03819090863137059 accuracy 0.9933215975761414 macro_avg {'precision': 0.9933980295350804, 'recall': 0.9933419762005501, 'f1-score': 0.9933592660187163, 'support': 10182} weighted_avg {'precision': 0.9933333847844544, 'recall': 0.993321547829503, 'f1-score': 0.99331662407219, 'support': 10182}
 
time = 16.42 secondes

Val loss 1.0215226716687718 accuracy 0.8825088143348694 macro_avg {'precision': 0.8835372029402973, 'recall': 0.8857784088126393, 'f1-score': 0.8830669837726278, 'support': 1132} weighted_avg {'precision': 0.8863574734381188, 'recall': 0.8825088339222615, 'f1-score': 0.8828247889496493, 'support': 1132}
 
----------
Epoch 30/40
time = 833.18 secondes

Train loss 0.034174852623241284 accuracy 0.9945983290672302 macro_avg {'precision': 0.9947114904219709, 'recall': 0.994469915565858, 'f1-score': 0.9945862792733253, 'support': 10182} weighted_avg {'precision': 0.9946051841165896, 'recall': 0.994598310744451, 'f1-score': 0.9945979118133834, 'support': 10182}
 
time = 15.98 secondes

Val loss 1.0090871385651092 accuracy 0.8878092169761658 macro_avg {'precision': 0.8906897219489016, 'recall': 0.8907659515776825, 'f1-score': 0.8887745568587798, 'support': 1132} weighted_avg {'precision': 0.891053372288629, 'recall': 0.8878091872791519, 'f1-score': 0.8875434160342233, 'support': 1132}
 
----------
Epoch 31/40
time = 833.69 secondes

Train loss 0.026936119972308128 accuracy 0.9949911832809448 macro_avg {'precision': 0.9949578415566827, 'recall': 0.9949416306327474, 'f1-score': 0.9949430821817684, 'support': 10182} weighted_avg {'precision': 0.9950030007614024, 'recall': 0.9949911608721272, 'f1-score': 0.9949906828380162, 'support': 10182}
 
time = 16.16 secondes

Val loss 0.9546087066126757 accuracy 0.8922261595726013 macro_avg {'precision': 0.8989254140650988, 'recall': 0.8948527461484594, 'f1-score': 0.895390775445341, 'support': 1132} weighted_avg {'precision': 0.8978337359199208, 'recall': 0.892226148409894, 'f1-score': 0.893450488925284, 'support': 1132}
 
----------
Epoch 32/40
time = 833.27 secondes

Train loss 0.04062619605007869 accuracy 0.9941073060035706 macro_avg {'precision': 0.9942134996767237, 'recall': 0.9941822186897367, 'f1-score': 0.9941804303902556, 'support': 10182} weighted_avg {'precision': 0.9941566534788129, 'recall': 0.9941072480848556, 'f1-score': 0.9941142034197359, 'support': 10182}
 
time = 15.88 secondes

Val loss 1.0331154415880903 accuracy 0.8860424160957336 macro_avg {'precision': 0.8982704313266796, 'recall': 0.8888138330421025, 'f1-score': 0.889623953233355, 'support': 1132} weighted_avg {'precision': 0.8979028374869088, 'recall': 0.8860424028268551, 'f1-score': 0.8881168129675303, 'support': 1132}
 
----------
Epoch 33/40
time = 833.67 secondes

Train loss 0.024131016338136392 accuracy 0.9961697459220886 macro_avg {'precision': 0.9962728648033095, 'recall': 0.9962398049014569, 'f1-score': 0.9962496126801472, 'support': 10182} weighted_avg {'precision': 0.9961896231282673, 'recall': 0.9961697112551562, 'f1-score': 0.9961728226475083, 'support': 10182}
 
time = 15.87 secondes

Val loss 0.9097823962115975 accuracy 0.8966431021690369 macro_avg {'precision': 0.9006799839962187, 'recall': 0.8976583320851539, 'f1-score': 0.8976705330915749, 'support': 1132} weighted_avg {'precision': 0.8994408225462905, 'recall': 0.8966431095406361, 'f1-score': 0.896647441222982, 'support': 1132}
 
----------
Epoch 34/40
time = 833.69 secondes

Train loss 0.016502152755501282 accuracy 0.9967589974403381 macro_avg {'precision': 0.996850184508711, 'recall': 0.9968590528998069, 'f1-score': 0.9968504553661865, 'support': 10182} weighted_avg {'precision': 0.9967678187176385, 'recall': 0.9967589864466706, 'f1-score': 0.996759127660606, 'support': 10182}
 
time = 16.09 secondes

Val loss 0.896802779041818 accuracy 0.8975265026092529 macro_avg {'precision': 0.9034159171593951, 'recall': 0.8994677804774325, 'f1-score': 0.899340278221931, 'support': 1132} weighted_avg {'precision': 0.9040346584706984, 'recall': 0.8975265017667845, 'f1-score': 0.8983642002369739, 'support': 1132}
 
----------
Epoch 35/40
time = 834.01 secondes

Train loss 0.018884313126796465 accuracy 0.9966608285903931 macro_avg {'precision': 0.9967139709197192, 'recall': 0.9967750223747325, 'f1-score': 0.9967426169230846, 'support': 10182} weighted_avg {'precision': 0.9966604686631153, 'recall': 0.9966607739147515, 'f1-score': 0.9966587297566541, 'support': 10182}
 
time = 16.31 secondes

Val loss 0.9907729545374564 accuracy 0.9010601043701172 macro_avg {'precision': 0.9036820464436623, 'recall': 0.9045823242395359, 'f1-score': 0.902221696260953, 'support': 1132} weighted_avg {'precision': 0.9060674562365408, 'recall': 0.901060070671378, 'f1-score': 0.9015826916841456, 'support': 1132}
 
----------
Epoch 36/40
time = 833.69 secondes

Train loss 0.022438662033352187 accuracy 0.9965626001358032 macro_avg {'precision': 0.9966215685704535, 'recall': 0.9963838192029, 'f1-score': 0.9964967453865862, 'support': 10182} weighted_avg {'precision': 0.9965731964454367, 'recall': 0.9965625613828325, 'f1-score': 0.9965624152183324, 'support': 10182}
 
time = 16.15 secondes

Val loss 0.879332910000556 accuracy 0.9001767039299011 macro_avg {'precision': 0.9046400123709525, 'recall': 0.9030782360012107, 'f1-score': 0.9026633368706907, 'support': 1132} weighted_avg {'precision': 0.9032481888516498, 'recall': 0.9001766784452296, 'f1-score': 0.9005352166063105, 'support': 1132}
 
----------
Epoch 37/40
time = 833.63 secondes

Train loss 0.013934320149860147 accuracy 0.9974464774131775 macro_avg {'precision': 0.99751094307358, 'recall': 0.9974760011490217, 'f1-score': 0.9974887742395706, 'support': 10182} weighted_avg {'precision': 0.9974607568362671, 'recall': 0.9974464741701041, 'f1-score': 0.9974487866851796, 'support': 10182}
 
time = 16.65 secondes

Val loss 0.9314448827433705 accuracy 0.8948763608932495 macro_avg {'precision': 0.8994619992410551, 'recall': 0.8955821201148684, 'f1-score': 0.8958661751083218, 'support': 1132} weighted_avg {'precision': 0.8990663452406881, 'recall': 0.8948763250883393, 'f1-score': 0.8954451973019815, 'support': 1132}
 
----------
Epoch 38/40
time = 833.67 secondes

Train loss 0.006083248421324596 accuracy 0.998821496963501 macro_avg {'precision': 0.9987837766121535, 'recall': 0.9987655149946638, 'f1-score': 0.9987738098332264, 'support': 10182} weighted_avg {'precision': 0.9988238788727669, 'recall': 0.9988214496169712, 'f1-score': 0.9988218152389604, 'support': 10182}
 
time = 16.04 secondes

Val loss 1.043477416063313 accuracy 0.8869258165359497 macro_avg {'precision': 0.8924507386811191, 'recall': 0.8908768789143107, 'f1-score': 0.8898739052880844, 'support': 1132} weighted_avg {'precision': 0.8921861635675286, 'recall': 0.8869257950530035, 'f1-score': 0.8877380387595052, 'support': 1132}
 
----------
Epoch 39/40
time = 833.52 secondes

Train loss 0.009100148502450335 accuracy 0.9984286427497864 macro_avg {'precision': 0.9982829773975934, 'recall': 0.9982554815806417, 'f1-score': 0.9982683266052188, 'support': 10182} weighted_avg {'precision': 0.9984299874129814, 'recall': 0.9984285994892949, 'f1-score': 0.9984284168747954, 'support': 10182}
 
time = 16.13 secondes

Val loss 1.0222451766672032 accuracy 0.8913427591323853 macro_avg {'precision': 0.8936360798876677, 'recall': 0.8933574376615055, 'f1-score': 0.8923546716117461, 'support': 1132} weighted_avg {'precision': 0.8944782223549133, 'recall': 0.8913427561837456, 'f1-score': 0.8916930425476138, 'support': 1132}
 
----------
Epoch 40/40
time = 833.42 secondes

Train loss 0.004497619240945291 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993378634153126, 'recall': 0.9993042813012739, 'f1-score': 0.9993205417428894, 'support': 10182} weighted_avg {'precision': 0.9994118100536943, 'recall': 0.9994107248084856, 'f1-score': 0.9994107688921863, 'support': 10182}
 
time = 16.19 secondes

Val loss 0.9787560359696393 accuracy 0.8975265026092529 macro_avg {'precision': 0.9002106064676937, 'recall': 0.900438335032462, 'f1-score': 0.8992976676941871, 'support': 1132} weighted_avg {'precision': 0.9006025243998075, 'recall': 0.8975265017667845, 'f1-score': 0.8980387920694547, 'support': 1132}
 
----------
best_accuracy 0.9010601043701172 best_epoch 35 macro_avg {'precision': 0.9036820464436623, 'recall': 0.9045823242395359, 'f1-score': 0.902221696260953, 'support': 1132} weighted_avg {'precision': 0.9060674562365408, 'recall': 0.901060070671378, 'f1-score': 0.9015826916841456, 'support': 1132}

average train time 833.9100533902645

average val time 16.161902397871017
 
time = 101.75 secondes

test_accuracy 0.8321826457977295 macro_avg {'precision': 0.831338169461198, 'recall': 0.8262973982178996, 'f1-score': 0.8256512120144196, 'support': 7532} weighted_avg {'precision': 0.8376453522888846, 'recall': 0.8321826872012745, 'f1-score': 0.8321670161573641, 'support': 7532}

----------


normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 672.00 MiB (GPU 0; 79.21 GiB total capacity; 64.53 GiB already allocated; 437.62 MiB free; 66.51 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 64.19 GiB already allocated; 237.62 MiB free; 66.71 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 62.10 GiB already allocated; 103.62 MiB free; 66.84 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.11 GiB (GPU 0; 79.21 GiB total capacity; 63.52 GiB already allocated; 357.62 MiB free; 66.59 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_5
----------
Epoch 1/40
time = 913.73 secondes

Train loss 1.0529196231481233 accuracy 0.7031035423278809 macro_avg {'precision': 0.705632349970513, 'recall': 0.6894674370328993, 'f1-score': 0.6872567824021324, 'support': 10182} weighted_avg {'precision': 0.7117221891628065, 'recall': 0.7031035160086427, 'f1-score': 0.6991502861151947, 'support': 10182}
 
time = 24.36 secondes

Val loss 0.5561937723361271 accuracy 0.833038866519928 macro_avg {'precision': 0.8335973126924199, 'recall': 0.8292495977215729, 'f1-score': 0.8210901650350839, 'support': 1132} weighted_avg {'precision': 0.8363312901780213, 'recall': 0.8330388692579506, 'f1-score': 0.8250418492823371, 'support': 1132}
 
----------
Epoch 2/40
time = 866.28 secondes

Train loss 0.3909332869425299 accuracy 0.8863681554794312 macro_avg {'precision': 0.8800609916784646, 'recall': 0.8788523924222924, 'f1-score': 0.8789085468732087, 'support': 10182} weighted_avg {'precision': 0.8854453065044171, 'recall': 0.8863681005696327, 'f1-score': 0.8854761743033714, 'support': 10182}
 
time = 24.22 secondes

Val loss 0.45651176317371955 accuracy 0.8736749291419983 macro_avg {'precision': 0.8719963700325787, 'recall': 0.8740285127206002, 'f1-score': 0.8691615756678365, 'support': 1132} weighted_avg {'precision': 0.8759089227758822, 'recall': 0.8736749116607774, 'f1-score': 0.8708138111037941, 'support': 1132}
 
----------
Epoch 3/40
time = 887.84 secondes

Train loss 0.24249503950279913 accuracy 0.9311530590057373 macro_avg {'precision': 0.9281606308739436, 'recall': 0.9274062429114476, 'f1-score': 0.9276701255097723, 'support': 10182} weighted_avg {'precision': 0.9314791484269698, 'recall': 0.9311530151247299, 'f1-score': 0.9312035708198313, 'support': 10182}
 
time = 23.09 secondes

Val loss 0.45375601596421966 accuracy 0.8966431021690369 macro_avg {'precision': 0.9003006162076082, 'recall': 0.9016771240497405, 'f1-score': 0.8966504703891458, 'support': 1132} weighted_avg {'precision': 0.9031743019205942, 'recall': 0.8966431095406361, 'f1-score': 0.8949363538081423, 'support': 1132}
 
----------
Epoch 4/40
time = 863.75 secondes

Train loss 0.17310096956190055 accuracy 0.9514830112457275 macro_avg {'precision': 0.9503744197390054, 'recall': 0.9498505914035192, 'f1-score': 0.9500553416311066, 'support': 10182} weighted_avg {'precision': 0.9516930759823145, 'recall': 0.951483009231978, 'f1-score': 0.9515311902624624, 'support': 10182}
 
time = 23.90 secondes

Val loss 0.5568043170332856 accuracy 0.8860424160957336 macro_avg {'precision': 0.8901660277678041, 'recall': 0.8862077196715357, 'f1-score': 0.8858856605057663, 'support': 1132} weighted_avg {'precision': 0.8870058052115339, 'recall': 0.8860424028268551, 'f1-score': 0.8842804490464707, 'support': 1132}
 
----------
Epoch 5/40
time = 882.54 secondes

Train loss 0.16923388506627965 accuracy 0.9589471817016602 macro_avg {'precision': 0.9576996755632792, 'recall': 0.9573349100637023, 'f1-score': 0.9574772451699436, 'support': 10182} weighted_avg {'precision': 0.9590018406411505, 'recall': 0.9589471616578276, 'f1-score': 0.9589377324298092, 'support': 10182}
 
time = 23.58 secondes

Val loss 0.5112238477433467 accuracy 0.898409903049469 macro_avg {'precision': 0.904122706656494, 'recall': 0.8980105881031974, 'f1-score': 0.8991921348828409, 'support': 1132} weighted_avg {'precision': 0.9019077973164924, 'recall': 0.8984098939929329, 'f1-score': 0.8982062135833655, 'support': 1132}
 
----------
Epoch 6/40
time = 879.51 secondes

Train loss 0.14556103036117563 accuracy 0.9656256437301636 macro_avg {'precision': 0.964588421881903, 'recall': 0.9650015926200997, 'f1-score': 0.9647390415928185, 'support': 10182} weighted_avg {'precision': 0.9657100022923802, 'recall': 0.9656256138283245, 'f1-score': 0.965616483309107, 'support': 10182}
 
time = 21.98 secondes

Val loss 0.5124580213032716 accuracy 0.9054770469665527 macro_avg {'precision': 0.9108529808090158, 'recall': 0.9072251468293573, 'f1-score': 0.9064274823200205, 'support': 1132} weighted_avg {'precision': 0.9090813941548666, 'recall': 0.9054770318021201, 'f1-score': 0.9044792875027687, 'support': 1132}
 
----------
Epoch 7/40
time = 875.65 secondes

Train loss 0.14093843093536665 accuracy 0.9678845405578613 macro_avg {'precision': 0.966855142045512, 'recall': 0.9664459383136862, 'f1-score': 0.9666079532716501, 'support': 10182} weighted_avg {'precision': 0.9679094389704582, 'recall': 0.9678845020624631, 'f1-score': 0.9678541772955149, 'support': 10182}
 
time = 24.95 secondes

Val loss 0.5002321378322987 accuracy 0.9134275913238525 macro_avg {'precision': 0.9167528611417037, 'recall': 0.9148925325234802, 'f1-score': 0.9143189068223478, 'support': 1132} weighted_avg {'precision': 0.9173719278822906, 'recall': 0.9134275618374559, 'f1-score': 0.9140421945734903, 'support': 1132}
 
----------
Epoch 8/40
time = 884.34 secondes

Train loss 0.1212577764925805 accuracy 0.9722058773040771 macro_avg {'precision': 0.9714418098226101, 'recall': 0.9713780092762075, 'f1-score': 0.9713707123375682, 'support': 10182} weighted_avg {'precision': 0.9722140951208773, 'recall': 0.9722058534669024, 'f1-score': 0.97216972644836, 'support': 10182}
 
time = 23.79 secondes

Val loss 0.7032024757317628 accuracy 0.8860424160957336 macro_avg {'precision': 0.8995955896643164, 'recall': 0.8818007604044074, 'f1-score': 0.8823326825107463, 'support': 1132} weighted_avg {'precision': 0.8981304489316306, 'recall': 0.8860424028268551, 'f1-score': 0.8849140355069587, 'support': 1132}
 
----------
Epoch 9/40
time = 852.18 secondes

Train loss 0.11898924746581506 accuracy 0.9728933572769165 macro_avg {'precision': 0.9724798116364999, 'recall': 0.9718243762485917, 'f1-score': 0.9720947648095816, 'support': 10182} weighted_avg {'precision': 0.9729356385781954, 'recall': 0.9728933411903359, 'f1-score': 0.9728700348604118, 'support': 10182}
 
time = 23.90 secondes

Val loss 0.5929113426639265 accuracy 0.9143109321594238 macro_avg {'precision': 0.9147842494689058, 'recall': 0.9168050978698249, 'f1-score': 0.914596910034805, 'support': 1132} weighted_avg {'precision': 0.9159212366637904, 'recall': 0.9143109540636042, 'f1-score': 0.913908491412981, 'support': 1132}
 
----------
Epoch 10/40
time = 908.30 secondes

Train loss 0.10289081000801346 accuracy 0.9787861108779907 macro_avg {'precision': 0.9777927915134965, 'recall': 0.9781758336304701, 'f1-score': 0.9779381506509971, 'support': 10182} weighted_avg {'precision': 0.9789173432188664, 'recall': 0.9787860931054803, 'f1-score': 0.9788067837751961, 'support': 10182}
 
time = 24.66 secondes

Val loss 0.7064821836138948 accuracy 0.8992933034896851 macro_avg {'precision': 0.9091912505498062, 'recall': 0.9018787391481855, 'f1-score': 0.9030206073764633, 'support': 1132} weighted_avg {'precision': 0.9070240306005503, 'recall': 0.8992932862190812, 'f1-score': 0.9005430813266829, 'support': 1132}
 
----------
Epoch 11/40
time = 872.82 secondes

Train loss 0.09792808793869683 accuracy 0.9806521534919739 macro_avg {'precision': 0.9801290921957554, 'recall': 0.9803552738014574, 'f1-score': 0.9802181501785279, 'support': 10182} weighted_avg {'precision': 0.9806983177946599, 'recall': 0.9806521312119426, 'f1-score': 0.9806544245322255, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.9069245120760095 accuracy 0.8692579865455627 macro_avg {'precision': 0.8871116479625375, 'recall': 0.8784779115050423, 'f1-score': 0.8713810293614598, 'support': 1132} weighted_avg {'precision': 0.8887972123367265, 'recall': 0.8692579505300353, 'f1-score': 0.8664175515389018, 'support': 1132}
 
----------
Epoch 12/40
time = 896.83 secondes

Train loss 0.11036955080173923 accuracy 0.9772146940231323 macro_avg {'precision': 0.9766993402279484, 'recall': 0.9766336090567191, 'f1-score': 0.9766513232556997, 'support': 10182} weighted_avg {'precision': 0.9772398695073967, 'recall': 0.9772146925947751, 'f1-score': 0.977211864696432, 'support': 10182}
 
time = 25.58 secondes

Val loss 0.673391999042893 accuracy 0.9028268456459045 macro_avg {'precision': 0.9067313260401584, 'recall': 0.9043345267926199, 'f1-score': 0.9038397394827193, 'support': 1132} weighted_avg {'precision': 0.9084507032801885, 'recall': 0.9028268551236749, 'f1-score': 0.9039625689784528, 'support': 1132}
 
----------
Epoch 13/40
time = 866.89 secondes

Train loss 0.09200066759820251 accuracy 0.980455756187439 macro_avg {'precision': 0.9800342542948002, 'recall': 0.9802794473300548, 'f1-score': 0.9801276306572888, 'support': 10182} weighted_avg {'precision': 0.9805330938225301, 'recall': 0.9804557061481045, 'f1-score': 0.9804661809002712, 'support': 10182}
 
time = 24.24 secondes

Val loss 0.6992438145610668 accuracy 0.9054770469665527 macro_avg {'precision': 0.9089080068731633, 'recall': 0.9083737860765725, 'f1-score': 0.9064650606991712, 'support': 1132} weighted_avg {'precision': 0.910949769267542, 'recall': 0.9054770318021201, 'f1-score': 0.9061061106541616, 'support': 1132}
 
----------
Epoch 14/40
time = 893.64 secondes

Train loss 0.09314343607321765 accuracy 0.9819289445877075 macro_avg {'precision': 0.9817311803849851, 'recall': 0.9814756184947988, 'f1-score': 0.9815535810364752, 'support': 10182} weighted_avg {'precision': 0.9819258003832675, 'recall': 0.9819288941268906, 'f1-score': 0.9818780145995161, 'support': 10182}
 
time = 24.69 secondes

Val loss 0.8327094943965228 accuracy 0.8825088143348694 macro_avg {'precision': 0.896494543098845, 'recall': 0.8787395929251497, 'f1-score': 0.8826866337461349, 'support': 1132} weighted_avg {'precision': 0.8916048368710869, 'recall': 0.8825088339222615, 'f1-score': 0.8823946950546402, 'support': 1132}
 
----------
Epoch 15/40
time = 1501.65 secondes

Train loss 0.08474814498257839 accuracy 0.9828128218650818 macro_avg {'precision': 0.9827589086002583, 'recall': 0.982823837542108, 'f1-score': 0.9827627062308398, 'support': 10182} weighted_avg {'precision': 0.9828887392516562, 'recall': 0.9828128069141623, 'f1-score': 0.9828213400532886, 'support': 10182}
 
time = 72.31 secondes

Val loss 0.6890195512120992 accuracy 0.9072438478469849 macro_avg {'precision': 0.9138710962403855, 'recall': 0.9094014436845012, 'f1-score': 0.9097224378729036, 'support': 1132} weighted_avg {'precision': 0.9143750385841574, 'recall': 0.907243816254417, 'f1-score': 0.9088608989623012, 'support': 1132}
 
----------
Epoch 16/40
time = 1908.43 secondes

Train loss 0.0892974606826875 accuracy 0.9827145934104919 macro_avg {'precision': 0.9828523813303137, 'recall': 0.9825071415085933, 'f1-score': 0.9826318680384665, 'support': 10182} weighted_avg {'precision': 0.9828214325435196, 'recall': 0.9827145943822432, 'f1-score': 0.9827202654562575, 'support': 10182}
 
time = 73.57 secondes

Val loss 0.7085326880529772 accuracy 0.8966431021690369 macro_avg {'precision': 0.9051257332897393, 'recall': 0.8980710851703503, 'f1-score': 0.8990535391415504, 'support': 1132} weighted_avg {'precision': 0.9041482952040241, 'recall': 0.8966431095406361, 'f1-score': 0.8977659268307148, 'support': 1132}
 
----------
Epoch 17/40
time = 1905.50 secondes

Train loss 0.08861904432291443 accuracy 0.9839913845062256 macro_avg {'precision': 0.98349507009133, 'recall': 0.9838563672567743, 'f1-score': 0.9836482262016967, 'support': 10182} weighted_avg {'precision': 0.9841072346350854, 'recall': 0.9839913572971911, 'f1-score': 0.9840238537790288, 'support': 10182}
 
time = 75.49 secondes

Val loss 0.6441033299863551 accuracy 0.9107773900032043 macro_avg {'precision': 0.9181188405283974, 'recall': 0.9119785650419232, 'f1-score': 0.911714605557675, 'support': 1132} weighted_avg {'precision': 0.9151340128512342, 'recall': 0.9107773851590106, 'f1-score': 0.9090477395067282, 'support': 1132}
 
----------
Epoch 18/40
time = 1912.68 secondes

Train loss 0.08951262709338988 accuracy 0.9840896129608154 macro_avg {'precision': 0.983771579260097, 'recall': 0.983733812546372, 'f1-score': 0.9837198456473715, 'support': 10182} weighted_avg {'precision': 0.9841558682904539, 'recall': 0.9840895698291102, 'f1-score': 0.9840932580870176, 'support': 10182}
 
time = 74.30 secondes

Val loss 0.6768208123251843 accuracy 0.9098939895629883 macro_avg {'precision': 0.9162074643321491, 'recall': 0.9125172219085913, 'f1-score': 0.9122404179532033, 'support': 1132} weighted_avg {'precision': 0.9157514515679726, 'recall': 0.9098939929328622, 'f1-score': 0.9106059969220235, 'support': 1132}
 
----------
Epoch 19/40
time = 1911.36 secondes

Train loss 0.06785300565083778 accuracy 0.9869377613067627 macro_avg {'precision': 0.9869666375629847, 'recall': 0.9868481486613774, 'f1-score': 0.986881220153389, 'support': 10182} weighted_avg {'precision': 0.9869965248358992, 'recall': 0.9869377332547633, 'f1-score': 0.9869403486764318, 'support': 10182}
 
time = 73.61 secondes

Val loss 0.7266728139173364 accuracy 0.9045936465263367 macro_avg {'precision': 0.9122176811690903, 'recall': 0.901183716676859, 'f1-score': 0.9033911522948289, 'support': 1132} weighted_avg {'precision': 0.9081728404915075, 'recall': 0.9045936395759717, 'f1-score': 0.903382826318427, 'support': 1132}
 
----------
Epoch 20/40
time = 1912.64 secondes

Train loss 0.07532707088819225 accuracy 0.9864466786384583 macro_avg {'precision': 0.9857022600046956, 'recall': 0.9851226940763098, 'f1-score': 0.9853831878750784, 'support': 10182} weighted_avg {'precision': 0.9864501821015792, 'recall': 0.986446670595168, 'f1-score': 0.9864233792321643, 'support': 10182}
 
time = 74.94 secondes

Val loss 0.7848289859375398 accuracy 0.9028268456459045 macro_avg {'precision': 0.9072643991862398, 'recall': 0.9030932702470003, 'f1-score': 0.9025757805578852, 'support': 1132} weighted_avg {'precision': 0.906926980352612, 'recall': 0.9028268551236749, 'f1-score': 0.9021194240132558, 'support': 1132}
 
----------
Epoch 21/40
time = 1911.13 secondes

Train loss 0.07872671919982764 accuracy 0.9871341586112976 macro_avg {'precision': 0.9871576555468756, 'recall': 0.9870202447952124, 'f1-score': 0.9870794368830156, 'support': 10182} weighted_avg {'precision': 0.9871576187325434, 'recall': 0.9871341583186014, 'f1-score': 0.987136124987022, 'support': 10182}
 
time = 74.29 secondes

Val loss 0.7043196061815866 accuracy 0.9125441908836365 macro_avg {'precision': 0.9165780081851075, 'recall': 0.9145176445569083, 'f1-score': 0.9137468218025285, 'support': 1132} weighted_avg {'precision': 0.9158146790390099, 'recall': 0.9125441696113075, 'f1-score': 0.9123635299112962, 'support': 1132}
 
----------
Epoch 22/40
time = 1907.24 secondes

Train loss 0.06493377672543814 accuracy 0.9890002012252808 macro_avg {'precision': 0.9890696805249259, 'recall': 0.9890370172290697, 'f1-score': 0.9890397262693364, 'support': 10182} weighted_avg {'precision': 0.9890219768895816, 'recall': 0.9890001964250639, 'f1-score': 0.9889971035411057, 'support': 10182}
 
time = 74.30 secondes

Val loss 0.8577622954107937 accuracy 0.8948763608932495 macro_avg {'precision': 0.9058280652859956, 'recall': 0.8982081086014769, 'f1-score': 0.8985474967904643, 'support': 1132} weighted_avg {'precision': 0.9061121991872237, 'recall': 0.8948763250883393, 'f1-score': 0.8966494999079139, 'support': 1132}
 
----------
Epoch 23/40
time = 1912.94 secondes

Train loss 0.08452486360515385 accuracy 0.9862502813339233 macro_avg {'precision': 0.986218160958131, 'recall': 0.9862916363004268, 'f1-score': 0.9862318306045003, 'support': 10182} weighted_avg {'precision': 0.9863155205264791, 'recall': 0.9862502455313298, 'f1-score': 0.9862596389998026, 'support': 10182}
 
time = 74.75 secondes

Val loss 0.7104836040210064 accuracy 0.9125441908836365 macro_avg {'precision': 0.9164018417076261, 'recall': 0.9147487388757968, 'f1-score': 0.9136604292822593, 'support': 1132} weighted_avg {'precision': 0.9163953112761292, 'recall': 0.9125441696113075, 'f1-score': 0.9124966269781285, 'support': 1132}
 
----------
Epoch 24/40
time = 1903.97 secondes

Train loss 0.05018784531110576 accuracy 0.9914555549621582 macro_avg {'precision': 0.9914148184307046, 'recall': 0.9912578951198421, 'f1-score': 0.9913100014253354, 'support': 10182} weighted_avg {'precision': 0.9915045764815479, 'recall': 0.9914555097230406, 'f1-score': 0.9914538135677317, 'support': 10182}
 
time = 74.74 secondes

Val loss 0.8573575183802693 accuracy 0.8957597017288208 macro_avg {'precision': 0.9109237750773959, 'recall': 0.9001829154968155, 'f1-score': 0.9001226140223799, 'support': 1132} weighted_avg {'precision': 0.9125930704997337, 'recall': 0.8957597173144877, 'f1-score': 0.8990515603934986, 'support': 1132}
 
----------
Epoch 25/40
time = 1907.26 secondes

Train loss 0.05535722426499532 accuracy 0.9915537238121033 macro_avg {'precision': 0.991576214968702, 'recall': 0.9915094685004945, 'f1-score': 0.9915277916080003, 'support': 10182} weighted_avg {'precision': 0.9915864055112609, 'recall': 0.9915537222549597, 'f1-score': 0.9915546389793708, 'support': 10182}
 
time = 74.26 secondes

Val loss 0.7411516099798486 accuracy 0.9063604474067688 macro_avg {'precision': 0.9097105195159141, 'recall': 0.9105204735975431, 'f1-score': 0.9085934536436472, 'support': 1132} weighted_avg {'precision': 0.9100124008822131, 'recall': 0.9063604240282686, 'f1-score': 0.9064358380603716, 'support': 1132}
 
----------
Epoch 26/40
time = 1628.61 secondes

Train loss 0.041554601828086034 accuracy 0.9921430349349976 macro_avg {'precision': 0.9922892446550687, 'recall': 0.9920764616823391, 'f1-score': 0.9921664670044017, 'support': 10182} weighted_avg {'precision': 0.9921777802493127, 'recall': 0.9921429974464742, 'f1-score': 0.992144859148888, 'support': 10182}
 
time = 71.18 secondes

Val loss 0.7057788807370586 accuracy 0.9134275913238525 macro_avg {'precision': 0.9164797915550235, 'recall': 0.9146891797079263, 'f1-score': 0.913747932842641, 'support': 1132} weighted_avg {'precision': 0.9175759975564975, 'recall': 0.9134275618374559, 'f1-score': 0.9137237268117254, 'support': 1132}
 
----------
Epoch 27/40
time = 1427.54 secondes

Train loss 0.043858772030710085 accuracy 0.992634117603302 macro_avg {'precision': 0.9926042700581776, 'recall': 0.9925148775590733, 'f1-score': 0.9925574291884655, 'support': 10182} weighted_avg {'precision': 0.9926356466467566, 'recall': 0.9926340601060696, 'f1-score': 0.9926326939664362, 'support': 10182}
 
time = 70.62 secondes

Val loss 0.695935310742512 accuracy 0.9134275913238525 macro_avg {'precision': 0.9165698909740865, 'recall': 0.9189080101221763, 'f1-score': 0.9156219363779629, 'support': 1132} weighted_avg {'precision': 0.9195339338288367, 'recall': 0.9134275618374559, 'f1-score': 0.9141993469152092, 'support': 1132}
 
----------
Epoch 28/40
time = 1432.24 secondes

Train loss 0.04685956270394122 accuracy 0.9922412633895874 macro_avg {'precision': 0.9920309332821091, 'recall': 0.9917281058501043, 'f1-score': 0.9918708736295934, 'support': 10182} weighted_avg {'precision': 0.9922532985147421, 'recall': 0.9922412099783933, 'f1-score': 0.9922391414368757, 'support': 10182}
 
time = 73.20 secondes

Val loss 0.7071312021872076 accuracy 0.9222614765167236 macro_avg {'precision': 0.9243560807062277, 'recall': 0.9247292752686196, 'f1-score': 0.9235131040751071, 'support': 1132} weighted_avg {'precision': 0.9252882132734019, 'recall': 0.9222614840989399, 'f1-score': 0.9227173652062558, 'support': 1132}
 
----------
Epoch 29/40
time = 1431.82 secondes

Train loss 0.027368703356747928 accuracy 0.9950894117355347 macro_avg {'precision': 0.9950688153280826, 'recall': 0.9950881712769546, 'f1-score': 0.9950751601858515, 'support': 10182} weighted_avg {'precision': 0.9950961293834043, 'recall': 0.9950893734040464, 'f1-score': 0.9950893635801195, 'support': 10182}
 
time = 71.92 secondes

Val loss 0.7973717996715544 accuracy 0.9107773900032043 macro_avg {'precision': 0.914431586560464, 'recall': 0.9157440153098702, 'f1-score': 0.9134758872499363, 'support': 1132} weighted_avg {'precision': 0.915251313092525, 'recall': 0.9107773851590106, 'f1-score': 0.9113229492938475, 'support': 1132}
 
----------
Epoch 30/40
time = 1434.68 secondes

Train loss 0.0372283371904744 accuracy 0.9941073060035706 macro_avg {'precision': 0.9942089445107335, 'recall': 0.9938043251725978, 'f1-score': 0.9939912876815274, 'support': 10182} weighted_avg {'precision': 0.9941274649252683, 'recall': 0.9941072480848556, 'f1-score': 0.9941029611356638, 'support': 10182}
 
time = 72.76 secondes

Val loss 0.6923599597303878 accuracy 0.9213780760765076 macro_avg {'precision': 0.9268561430643558, 'recall': 0.9234856199226223, 'f1-score': 0.923260439338495, 'support': 1132} weighted_avg {'precision': 0.9265023930805982, 'recall': 0.9213780918727915, 'f1-score': 0.9220217033821745, 'support': 1132}
 
----------
Epoch 31/40
time = 1434.10 secondes

Train loss 0.03570166841075474 accuracy 0.9944019317626953 macro_avg {'precision': 0.9944773760975985, 'recall': 0.9943983460354058, 'f1-score': 0.994430583857602, 'support': 10182} weighted_avg {'precision': 0.9944167586398923, 'recall': 0.9944018856806128, 'f1-score': 0.9944023643799718, 'support': 10182}
 
time = 72.19 secondes

Val loss 0.6698896742711159 accuracy 0.9178445339202881 macro_avg {'precision': 0.9303260849921393, 'recall': 0.9213501771641548, 'f1-score': 0.9231255767259603, 'support': 1132} weighted_avg {'precision': 0.9278151663598178, 'recall': 0.9178445229681979, 'f1-score': 0.9196545156453705, 'support': 1132}
 
----------
Epoch 32/40
time = 1430.89 secondes

Train loss 0.02427467726701419 accuracy 0.995776891708374 macro_avg {'precision': 0.9957687210127372, 'recall': 0.9958141643272638, 'f1-score': 0.9957864030000335, 'support': 10182} weighted_avg {'precision': 0.9957921532500464, 'recall': 0.9957768611274799, 'f1-score': 0.9957798298344621, 'support': 10182}
 
time = 71.77 secondes

Val loss 0.7321931140355497 accuracy 0.916961133480072 macro_avg {'precision': 0.9223180561697367, 'recall': 0.9207572040492435, 'f1-score': 0.919752470010884, 'support': 1132} weighted_avg {'precision': 0.923375275769754, 'recall': 0.9169611307420494, 'f1-score': 0.9181739818715644, 'support': 1132}
 
----------
Epoch 33/40
time = 1433.43 secondes

Train loss 0.01910145691451092 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963555183178885, 'recall': 0.9963977491024734, 'f1-score': 0.9963747060381196, 'support': 10182} weighted_avg {'precision': 0.9963701010371042, 'recall': 0.9963661363189943, 'f1-score': 0.9963662082994769, 'support': 10182}
 
time = 71.79 secondes

Val loss 0.7489455820813047 accuracy 0.9125441908836365 macro_avg {'precision': 0.9188496184131978, 'recall': 0.9172508816998132, 'f1-score': 0.9160354905923583, 'support': 1132} weighted_avg {'precision': 0.9187452638381444, 'recall': 0.9125441696113075, 'f1-score': 0.9134145895720392, 'support': 1132}
 
----------
Epoch 34/40
time = 1434.33 secondes

Train loss 0.02159184623806098 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959927703526219, 'recall': 0.9959159817377718, 'f1-score': 0.9959518568596835, 'support': 10182} weighted_avg {'precision': 0.9960737273666963, 'recall': 0.9960714987232371, 'f1-score': 0.9960700679252968, 'support': 10182}
 
time = 73.07 secondes

Val loss 0.7538630442352474 accuracy 0.9187279343605042 macro_avg {'precision': 0.9265605253305808, 'recall': 0.9228568460155548, 'f1-score': 0.9229134181236283, 'support': 1132} weighted_avg {'precision': 0.9245991972036816, 'recall': 0.9187279151943463, 'f1-score': 0.9197401288745232, 'support': 1132}
 
----------
Epoch 35/40
time = 1573.26 secondes

Train loss 0.01821002433347619 accuracy 0.9974464774131775 macro_avg {'precision': 0.997432653621287, 'recall': 0.9973989993184726, 'f1-score': 0.9974130004319328, 'support': 10182} weighted_avg {'precision': 0.9974508713421637, 'recall': 0.9974464741701041, 'f1-score': 0.997445874468691, 'support': 10182}
 
time = 75.25 secondes

Val loss 0.6483897857187015 accuracy 0.9196113348007202 macro_avg {'precision': 0.923224025119023, 'recall': 0.9223545704147208, 'f1-score': 0.9218816184712848, 'support': 1132} weighted_avg {'precision': 0.9224368659700027, 'recall': 0.9196113074204947, 'f1-score': 0.9200043629498748, 'support': 1132}
 
----------
Epoch 36/40
time = 1783.34 secondes

Train loss 0.016244017781745137 accuracy 0.9970536828041077 macro_avg {'precision': 0.9970685807694328, 'recall': 0.9971215489610079, 'f1-score': 0.9970901500318974, 'support': 10182} weighted_avg {'precision': 0.9970615730744894, 'recall': 0.9970536240424278, 'f1-score': 0.9970526141928542, 'support': 10182}
 
time = 75.61 secondes

Val loss 0.7969484987220761 accuracy 0.9143109321594238 macro_avg {'precision': 0.918706322794363, 'recall': 0.9170662403820412, 'f1-score': 0.9164330589563552, 'support': 1132} weighted_avg {'precision': 0.9173089311900466, 'recall': 0.9143109540636042, 'f1-score': 0.9142678920529809, 'support': 1132}
 
----------
Epoch 37/40
time = 1825.07 secondes

Train loss 0.008236348588229024 accuracy 0.9980357885360718 macro_avg {'precision': 0.998049800276155, 'recall': 0.9979907138435076, 'f1-score': 0.998017897810341, 'support': 10182} weighted_avg {'precision': 0.9980392720757688, 'recall': 0.9980357493616185, 'f1-score': 0.9980353556993165, 'support': 10182}
 
time = 74.14 secondes

Val loss 0.7645782452023078 accuracy 0.9187279343605042 macro_avg {'precision': 0.9233763784839976, 'recall': 0.9214445194318381, 'f1-score': 0.9207003542493759, 'support': 1132} weighted_avg {'precision': 0.9236631079057227, 'recall': 0.9187279151943463, 'f1-score': 0.9193603751190974, 'support': 1132}
 
----------
Epoch 38/40
time = 1734.89 secondes

Train loss 0.0038821093486595933 accuracy 0.9990178942680359 macro_avg {'precision': 0.9989837279373195, 'recall': 0.9989866897735574, 'f1-score': 0.9989843726562553, 'support': 10182} weighted_avg {'precision': 0.9990199509620405, 'recall': 0.9990178746808093, 'f1-score': 0.9990180644208886, 'support': 10182}
 
time = 73.37 secondes

Val loss 0.7850234049237002 accuracy 0.9143109321594238 macro_avg {'precision': 0.9192117621044256, 'recall': 0.9187371260930517, 'f1-score': 0.9170214256887945, 'support': 1132} weighted_avg {'precision': 0.9204178723425744, 'recall': 0.9143109540636042, 'f1-score': 0.9154525261650535, 'support': 1132}
 
----------
Epoch 39/40
time = 1833.53 secondes

Train loss 0.005984680129781801 accuracy 0.998821496963501 macro_avg {'precision': 0.9988167590069343, 'recall': 0.9988617541828857, 'f1-score': 0.9988379651468847, 'support': 10182} weighted_avg {'precision': 0.998825007859331, 'recall': 0.9988214496169712, 'f1-score': 0.9988219202720118, 'support': 10182}
 
time = 73.81 secondes

Val loss 0.7516699168978628 accuracy 0.9222614765167236 macro_avg {'precision': 0.9262987664184568, 'recall': 0.9244092947430742, 'f1-score': 0.9242004189360475, 'support': 1132} weighted_avg {'precision': 0.9259295971743708, 'recall': 0.9222614840989399, 'f1-score': 0.922851180342459, 'support': 1132}
 
----------
Epoch 40/40
time = 1820.60 secondes

Train loss 0.002567954103796178 accuracy 0.9995089769363403 macro_avg {'precision': 0.9994855226203704, 'recall': 0.9994672690008007, 'f1-score': 0.999475746205472, 'support': 10182} weighted_avg {'precision': 0.9995103136851677, 'recall': 0.9995089373404047, 'f1-score': 0.9995090200519398, 'support': 10182}
 
time = 74.83 secondes

Val loss 0.7571087862392694 accuracy 0.9204947352409363 macro_avg {'precision': 0.9234512767085077, 'recall': 0.9237505500690769, 'f1-score': 0.9225557756282642, 'support': 1132} weighted_avg {'precision': 0.922771644712822, 'recall': 0.9204946996466431, 'f1-score': 0.9204807029717612, 'support': 1132}
 
----------
best_accuracy 0.9222614765167236 best_epoch 28 macro_avg {'precision': 0.9243560807062277, 'recall': 0.9247292752686196, 'f1-score': 0.9235131040751071, 'support': 1132} weighted_avg {'precision': 0.9252882132734019, 'recall': 0.9222614840989399, 'f1-score': 0.9227173652062558, 'support': 1132}

average train time 1414.9352379202842

average val time 56.236400336027145
 
time = 491.92 secondes

test_accuracy 0.8436006307601929 macro_avg {'precision': 0.8436262969624359, 'recall': 0.8363538497982882, 'f1-score': 0.8370206285399995, 'support': 7532} weighted_avg {'precision': 0.8496057911097519, 'recall': 0.8436006372809347, 'f1-score': 0.8438043826385, 'support': 7532}

----------

Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_5
----------
Epoch 1/40
time = 1278.03 secondes

Train loss 1.0410066138795069 accuracy 0.7082105875015259 macro_avg {'precision': 0.7029482640919367, 'recall': 0.6941421907349189, 'f1-score': 0.6877377367338036, 'support': 10182} weighted_avg {'precision': 0.7089482693394742, 'recall': 0.7082105676684345, 'f1-score': 0.7001035724858343, 'support': 10182}
 
time = 47.50 secondes

Val loss 0.5471607497040655 accuracy 0.8365724682807922 macro_avg {'precision': 0.8263871441339103, 'recall': 0.8256853607315865, 'f1-score': 0.814109882696699, 'support': 1132} weighted_avg {'precision': 0.8317530798349507, 'recall': 0.8365724381625441, 'f1-score': 0.824460556183695, 'support': 1132}
 
----------
Epoch 2/40
time = 1265.66 secondes

Train loss 0.3660952147283537 accuracy 0.8939304947853088 macro_avg {'precision': 0.8883287092298089, 'recall': 0.8861978900741889, 'f1-score': 0.8863358634688308, 'support': 10182} weighted_avg {'precision': 0.8932312824502139, 'recall': 0.8939304655274013, 'f1-score': 0.8928774726725832, 'support': 10182}
 
time = 44.52 secondes

Val loss 0.5028679795878034 accuracy 0.8736749291419983 macro_avg {'precision': 0.8812620943950005, 'recall': 0.8729330435929917, 'f1-score': 0.8696474172392238, 'support': 1132} weighted_avg {'precision': 0.8833324823305789, 'recall': 0.8736749116607774, 'f1-score': 0.8713639244217642, 'support': 1132}
 
----------
Epoch 3/40
time = 1251.49 secondes

Train loss 0.21385439735467385 accuracy 0.9386171698570251 macro_avg {'precision': 0.9356398794585594, 'recall': 0.9348388079416822, 'f1-score': 0.9351067919764574, 'support': 10182} weighted_avg {'precision': 0.9385468581343115, 'recall': 0.9386171675505794, 'f1-score': 0.9384681785503812, 'support': 10182}
 
time = 43.65 secondes

Val loss 0.4897728716547955 accuracy 0.8966431021690369 macro_avg {'precision': 0.8990645550321492, 'recall': 0.8963040792909165, 'f1-score': 0.8946906810219776, 'support': 1132} weighted_avg {'precision': 0.8987085965495601, 'recall': 0.8966431095406361, 'f1-score': 0.8947535496146685, 'support': 1132}
 
----------
Epoch 4/40
time = 1264.50 secondes

Train loss 0.16279420425078803 accuracy 0.9566882848739624 macro_avg {'precision': 0.954835838338911, 'recall': 0.9550507478249475, 'f1-score': 0.9548759820308265, 'support': 10182} weighted_avg {'precision': 0.9568703019172888, 'recall': 0.9566882734236889, 'f1-score': 0.9567182180570666, 'support': 10182}
 
time = 40.84 secondes

Val loss 0.48358213460125343 accuracy 0.9045936465263367 macro_avg {'precision': 0.9097813899265503, 'recall': 0.9044359012333674, 'f1-score': 0.9049299760106525, 'support': 1132} weighted_avg {'precision': 0.9074283934692466, 'recall': 0.9045936395759717, 'f1-score': 0.903919524942915, 'support': 1132}
 
----------
Epoch 5/40
time = 1261.97 secondes

Train loss 0.148579688592349 accuracy 0.9631703495979309 macro_avg {'precision': 0.9612722178045463, 'recall': 0.9614293869052121, 'f1-score': 0.9612849494144078, 'support': 10182} weighted_avg {'precision': 0.9634177326798685, 'recall': 0.9631703005303477, 'f1-score': 0.9632361931799226, 'support': 10182}
 
time = 42.53 secondes

Val loss 0.4881502291946803 accuracy 0.916961133480072 macro_avg {'precision': 0.9209246489996256, 'recall': 0.9179116804626458, 'f1-score': 0.9180379292469534, 'support': 1132} weighted_avg {'precision': 0.9167533845316717, 'recall': 0.9169611307420494, 'f1-score': 0.9155353962148769, 'support': 1132}
 
----------
Epoch 6/40
time = 1261.35 secondes

Train loss 0.1456805533983341 accuracy 0.9649381637573242 macro_avg {'precision': 0.9639392069483957, 'recall': 0.9641015694680641, 'f1-score': 0.9639809013132832, 'support': 10182} weighted_avg {'precision': 0.9650115334128779, 'recall': 0.9649381261048909, 'f1-score': 0.9649345475358673, 'support': 10182}
 
time = 44.03 secondes

Val loss 0.5439284573781343 accuracy 0.9045936465263367 macro_avg {'precision': 0.9082047218855449, 'recall': 0.9024674494091064, 'f1-score': 0.9011391677375624, 'support': 1132} weighted_avg {'precision': 0.9073333158046251, 'recall': 0.9045936395759717, 'f1-score': 0.9024077629770623, 'support': 1132}
 
----------
Epoch 7/40
time = 1271.72 secondes

Train loss 0.13599951193357995 accuracy 0.9682773947715759 macro_avg {'precision': 0.9679788080401917, 'recall': 0.9674384622529472, 'f1-score': 0.9676416151966338, 'support': 10182} weighted_avg {'precision': 0.9683091365941926, 'recall': 0.9682773521901394, 'f1-score': 0.9682335059606366, 'support': 10182}
 
time = 43.78 secondes

Val loss 0.6720750675771162 accuracy 0.898409903049469 macro_avg {'precision': 0.9095902352686913, 'recall': 0.8998642833950731, 'f1-score': 0.900030191103607, 'support': 1132} weighted_avg {'precision': 0.9057373344097834, 'recall': 0.8984098939929329, 'f1-score': 0.8974433304929748, 'support': 1132}
 
----------
Epoch 8/40
time = 1251.92 secondes

Train loss 0.10997186288777798 accuracy 0.9756433367729187 macro_avg {'precision': 0.9752824210963403, 'recall': 0.9751900133915201, 'f1-score': 0.9752022389619844, 'support': 10182} weighted_avg {'precision': 0.9756970610416366, 'recall': 0.97564329208407, 'f1-score': 0.975635140923291, 'support': 10182}
 
time = 39.84 secondes

Val loss 0.667114541862606 accuracy 0.9010601043701172 macro_avg {'precision': 0.9092774999845075, 'recall': 0.8993305173818216, 'f1-score': 0.9003149196646651, 'support': 1132} weighted_avg {'precision': 0.9078171346435945, 'recall': 0.901060070671378, 'f1-score': 0.9001778767462966, 'support': 1132}
 
----------
Epoch 9/40
time = 1261.48 secondes

Train loss 0.10784836513070892 accuracy 0.976527214050293 macro_avg {'precision': 0.9755654362070432, 'recall': 0.9754687656772812, 'f1-score': 0.9755013910773341, 'support': 10182} weighted_avg {'precision': 0.9765405057773149, 'recall': 0.9765272048713416, 'f1-score': 0.976520159387736, 'support': 10182}
 
time = 39.26 secondes

Val loss 0.6398391171943062 accuracy 0.9028268456459045 macro_avg {'precision': 0.9099987293326283, 'recall': 0.902750467759601, 'f1-score': 0.904226974438685, 'support': 1132} weighted_avg {'precision': 0.9073220780704142, 'recall': 0.9028268551236749, 'f1-score': 0.9030028805382366, 'support': 1132}
 
----------
Epoch 10/40
time = 1252.79 secondes

Train loss 0.10562860691659313 accuracy 0.9787861108779907 macro_avg {'precision': 0.977319361694531, 'recall': 0.9773039613607934, 'f1-score': 0.9772893793574677, 'support': 10182} weighted_avg {'precision': 0.9788136652921988, 'recall': 0.9787860931054803, 'f1-score': 0.9787796712338008, 'support': 10182}
 
time = 44.62 secondes

Val loss 0.6436800062992531 accuracy 0.8948763608932495 macro_avg {'precision': 0.9019601933526686, 'recall': 0.8984695874210955, 'f1-score': 0.8967710953444085, 'support': 1132} weighted_avg {'precision': 0.9035825026823225, 'recall': 0.8948763250883393, 'f1-score': 0.8954450061065078, 'support': 1132}
 
----------
Epoch 11/40
time = 1250.77 secondes

Train loss 0.08888991892924353 accuracy 0.9815360903739929 macro_avg {'precision': 0.9813157300467431, 'recall': 0.9815251649772726, 'f1-score': 0.9813917785109817, 'support': 10182} weighted_avg {'precision': 0.9816361567385283, 'recall': 0.9815360439992143, 'f1-score': 0.9815587703612366, 'support': 10182}
 
time = 41.34 secondes

Val loss 0.7337902416788701 accuracy 0.8957597017288208 macro_avg {'precision': 0.9083691631940717, 'recall': 0.8952080749251319, 'f1-score': 0.8959246268080847, 'support': 1132} weighted_avg {'precision': 0.9041590406499347, 'recall': 0.8957597173144877, 'f1-score': 0.8939263301581506, 'support': 1132}
 
----------
Epoch 12/40
time = 1178.18 secondes

Train loss 0.09620683605307889 accuracy 0.981634259223938 macro_avg {'precision': 0.981449140730367, 'recall': 0.9812136333406404, 'f1-score': 0.9812854418810467, 'support': 10182} weighted_avg {'precision': 0.9816962584035613, 'recall': 0.9816342565311333, 'f1-score': 0.9816193756271911, 'support': 10182}
 
time = 41.54 secondes

Val loss 0.8171910391866335 accuracy 0.8992933034896851 macro_avg {'precision': 0.9065257436553, 'recall': 0.9034553664770488, 'f1-score': 0.9012317414222096, 'support': 1132} weighted_avg {'precision': 0.9068160208741999, 'recall': 0.8992932862190812, 'f1-score': 0.8992679586460046, 'support': 1132}
 
----------
Epoch 13/40
time = 1138.26 secondes

Train loss 0.09559244924944331 accuracy 0.9811432361602783 macro_avg {'precision': 0.9809180783248859, 'recall': 0.980868606309361, 'f1-score': 0.9808647843217138, 'support': 10182} weighted_avg {'precision': 0.9811761573990974, 'recall': 0.981143193871538, 'f1-score': 0.9811310562035233, 'support': 10182}
 
time = 42.00 secondes

Val loss 0.7723643653675616 accuracy 0.9090105891227722 macro_avg {'precision': 0.9117568991379595, 'recall': 0.9090898467579873, 'f1-score': 0.9084833620991404, 'support': 1132} weighted_avg {'precision': 0.9111319112543579, 'recall': 0.9090106007067138, 'f1-score': 0.9080215974897606, 'support': 1132}
 
----------
Epoch 14/40
time = 1124.54 secondes

Train loss 0.0814916079215489 accuracy 0.9836967587471008 macro_avg {'precision': 0.9833862172813678, 'recall': 0.983364398083514, 'f1-score': 0.9833576834945704, 'support': 10182} weighted_avg {'precision': 0.9837028809857377, 'recall': 0.9836967197014339, 'f1-score': 0.9836820213380901, 'support': 10182}
 
time = 41.51 secondes

Val loss 0.7219847984142432 accuracy 0.9028268456459045 macro_avg {'precision': 0.9095676003164993, 'recall': 0.9047117284470512, 'f1-score': 0.9049702373425712, 'support': 1132} weighted_avg {'precision': 0.9088716865741259, 'recall': 0.9028268551236749, 'f1-score': 0.9034853617746318, 'support': 1132}
 
----------
Epoch 15/40
time = 1118.64 secondes

Train loss 0.09349864044196689 accuracy 0.9822235703468323 macro_avg {'precision': 0.9821886703007952, 'recall': 0.9820099965000001, 'f1-score': 0.9820563733173392, 'support': 10182} weighted_avg {'precision': 0.9823922145984311, 'recall': 0.9822235317226478, 'f1-score': 0.9822641067008587, 'support': 10182}
 
time = 37.90 secondes

Val loss 1.0347046369854171 accuracy 0.8736749291419983 macro_avg {'precision': 0.8934776485855831, 'recall': 0.8763760190422183, 'f1-score': 0.878622370953436, 'support': 1132} weighted_avg {'precision': 0.8934756840359399, 'recall': 0.8736749116607774, 'f1-score': 0.8772723131312008, 'support': 1132}
 
----------
Epoch 16/40
time = 1142.08 secondes

Train loss 0.08546897212090555 accuracy 0.9845806360244751 macro_avg {'precision': 0.9847963363585246, 'recall': 0.9845491342770865, 'f1-score': 0.9846484924934689, 'support': 10182} weighted_avg {'precision': 0.9846011804265655, 'recall': 0.9845806324887055, 'f1-score': 0.9845675598028777, 'support': 10182}
 
time = 41.71 secondes

Val loss 0.7052467561753846 accuracy 0.9072438478469849 macro_avg {'precision': 0.9087586009550657, 'recall': 0.9068622685605174, 'f1-score': 0.9056630139230932, 'support': 1132} weighted_avg {'precision': 0.910730122067205, 'recall': 0.907243816254417, 'f1-score': 0.9069886565087558, 'support': 1132}
 
----------
Epoch 17/40
time = 984.14 secondes

Train loss 0.06754512823318354 accuracy 0.9861520528793335 macro_avg {'precision': 0.9858022133208688, 'recall': 0.9857200785342544, 'f1-score': 0.9857532187663711, 'support': 10182} weighted_avg {'precision': 0.9861691677893012, 'recall': 0.9861520329994107, 'f1-score': 0.9861526481306957, 'support': 10182}
 
time = 31.89 secondes

Val loss 0.7591919435507292 accuracy 0.9045936465263367 macro_avg {'precision': 0.9133183203203117, 'recall': 0.9043738468470325, 'f1-score': 0.906112029477135, 'support': 1132} weighted_avg {'precision': 0.9116921194438198, 'recall': 0.9045936395759717, 'f1-score': 0.9052468314525771, 'support': 1132}
 
----------
Epoch 18/40
time = 853.95 secondes

Train loss 0.06260714792223206 accuracy 0.9877234697341919 macro_avg {'precision': 0.9874038058629427, 'recall': 0.9872925463560904, 'f1-score': 0.987333396447408, 'support': 10182} weighted_avg {'precision': 0.9877619463508348, 'recall': 0.9877234335101159, 'f1-score': 0.9877283581110511, 'support': 10182}
 
time = 29.64 secondes

Val loss 0.663980843581183 accuracy 0.9143109321594238 macro_avg {'precision': 0.9205762522508225, 'recall': 0.9143730493592445, 'f1-score': 0.9150562278391352, 'support': 1132} weighted_avg {'precision': 0.9197992172205032, 'recall': 0.9143109540636042, 'f1-score': 0.9146463488380763, 'support': 1132}
 
----------
Epoch 19/40
time = 859.11 secondes

Train loss 0.07463403753531259 accuracy 0.9871341586112976 macro_avg {'precision': 0.9867026146315314, 'recall': 0.9866129342249221, 'f1-score': 0.9866418053720288, 'support': 10182} weighted_avg {'precision': 0.9871930720557713, 'recall': 0.9871341583186014, 'f1-score': 0.9871473375624276, 'support': 10182}
 
time = 30.09 secondes

Val loss 0.7655369853778147 accuracy 0.9054770469665527 macro_avg {'precision': 0.9113870447953584, 'recall': 0.9057525319579064, 'f1-score': 0.9057885143623225, 'support': 1132} weighted_avg {'precision': 0.9104160623027439, 'recall': 0.9054770318021201, 'f1-score': 0.9051768435385642, 'support': 1132}
 
----------
Epoch 20/40
time = 852.52 secondes

Train loss 0.05961765103982221 accuracy 0.9889020323753357 macro_avg {'precision': 0.9889816519565635, 'recall': 0.9890676841825424, 'f1-score': 0.9890074868668931, 'support': 10182} weighted_avg {'precision': 0.9889460262899427, 'recall': 0.9889019838931448, 'f1-score': 0.9889071727799348, 'support': 10182}
 
time = 29.90 secondes

Val loss 0.8321129928302416 accuracy 0.9019434452056885 macro_avg {'precision': 0.9133012794345685, 'recall': 0.9077429201627671, 'f1-score': 0.9067454043382677, 'support': 1132} weighted_avg {'precision': 0.9150498047052216, 'recall': 0.9019434628975265, 'f1-score': 0.9047363482263753, 'support': 1132}
 
----------
Epoch 21/40
time = 852.96 secondes

Train loss 0.059427638276235886 accuracy 0.9889020323753357 macro_avg {'precision': 0.988643711000288, 'recall': 0.9886518583276726, 'f1-score': 0.9886382106454461, 'support': 10182} weighted_avg {'precision': 0.9889249725570338, 'recall': 0.9889019838931448, 'f1-score': 0.9889039231530038, 'support': 10182}
 
time = 26.93 secondes

Val loss 0.7601776000866125 accuracy 0.9037102460861206 macro_avg {'precision': 0.9153043370359122, 'recall': 0.9066816307303484, 'f1-score': 0.9066290037656367, 'support': 1132} weighted_avg {'precision': 0.915299886443193, 'recall': 0.9037102473498233, 'f1-score': 0.9045804488162794, 'support': 1132}
 
----------
Epoch 22/40
time = 857.53 secondes

Train loss 0.0579601059042582 accuracy 0.9894912838935852 macro_avg {'precision': 0.9893842314930748, 'recall': 0.9893540388965182, 'f1-score': 0.9893217614085845, 'support': 10182} weighted_avg {'precision': 0.98960971726177, 'recall': 0.9894912590846592, 'f1-score': 0.9895019277451077, 'support': 10182}
 
time = 27.40 secondes

Val loss 0.7379221126518555 accuracy 0.9037102460861206 macro_avg {'precision': 0.9146840114140881, 'recall': 0.9049455595546375, 'f1-score': 0.9051983691388816, 'support': 1132} weighted_avg {'precision': 0.9155642649351061, 'recall': 0.9037102473498233, 'f1-score': 0.9046688557644291, 'support': 1132}
 
----------
Epoch 23/40
time = 848.30 secondes

Train loss 0.055728540437653684 accuracy 0.9898841381072998 macro_avg {'precision': 0.9900389974152362, 'recall': 0.9897590293501086, 'f1-score': 0.989875817258534, 'support': 10182} weighted_avg {'precision': 0.9899444035768236, 'recall': 0.9898841092123355, 'f1-score': 0.9898915115822058, 'support': 10182}
 
time = 28.80 secondes

Val loss 0.8499182992213911 accuracy 0.8992933034896851 macro_avg {'precision': 0.9111239602374608, 'recall': 0.902143169065053, 'f1-score': 0.9028438175558829, 'support': 1132} weighted_avg {'precision': 0.9117001100521408, 'recall': 0.8992932862190812, 'f1-score': 0.9013759803529592, 'support': 1132}
 
----------
Epoch 24/40
time = 856.96 secondes

Train loss 0.05498439313461339 accuracy 0.9891966581344604 macro_avg {'precision': 0.9884833386792848, 'recall': 0.9880332781593564, 'f1-score': 0.9882354048556033, 'support': 10182} weighted_avg {'precision': 0.9891872662096036, 'recall': 0.989196621488902, 'f1-score': 0.9891733863433227, 'support': 10182}
 
time = 28.30 secondes

Val loss 0.7449860824281259 accuracy 0.898409903049469 macro_avg {'precision': 0.9066364414110367, 'recall': 0.8995952106346146, 'f1-score': 0.9007261618222456, 'support': 1132} weighted_avg {'precision': 0.9070715840180344, 'recall': 0.8984098939929329, 'f1-score': 0.9001576406749707, 'support': 1132}
 
----------
Epoch 25/40
time = 853.96 secondes

Train loss 0.03776003312569961 accuracy 0.992634117603302 macro_avg {'precision': 0.9921292258007293, 'recall': 0.9921787539689534, 'f1-score': 0.9921491719151947, 'support': 10182} weighted_avg {'precision': 0.9926388344811653, 'recall': 0.9926340601060696, 'f1-score': 0.992631619424834, 'support': 10182}
 
time = 30.05 secondes

Val loss 0.7397243759463583 accuracy 0.916961133480072 macro_avg {'precision': 0.9183683184787176, 'recall': 0.9164070500035573, 'f1-score': 0.9162106206803671, 'support': 1132} weighted_avg {'precision': 0.9196135404051596, 'recall': 0.9169611307420494, 'f1-score': 0.9171894396924912, 'support': 1132}
 
----------
Epoch 26/40
time = 856.42 secondes

Train loss 0.05122490665910145 accuracy 0.9905716180801392 macro_avg {'precision': 0.9902228453297152, 'recall': 0.9901246572449598, 'f1-score': 0.9901647447004958, 'support': 10182} weighted_avg {'precision': 0.9905833083983221, 'recall': 0.990571596935769, 'f1-score': 0.9905688448136409, 'support': 10182}
 
time = 27.98 secondes

Val loss 0.7992157501555507 accuracy 0.9054770469665527 macro_avg {'precision': 0.9169034694061342, 'recall': 0.9027407541247653, 'f1-score': 0.9067534207539918, 'support': 1132} weighted_avg {'precision': 0.9120488352812897, 'recall': 0.9054770318021201, 'f1-score': 0.9056541043102705, 'support': 1132}
 
----------
Epoch 27/40
time = 852.77 secondes

Train loss 0.05716856041816665 accuracy 0.9916519522666931 macro_avg {'precision': 0.9916735066891578, 'recall': 0.9912515963354505, 'f1-score': 0.991441415045476, 'support': 10182} weighted_avg {'precision': 0.9916905004100165, 'recall': 0.9916519347868789, 'f1-score': 0.9916506863119843, 'support': 10182}
 
time = 29.47 secondes

Val loss 0.7453327474269801 accuracy 0.916077733039856 macro_avg {'precision': 0.9222156228206687, 'recall': 0.9150621308160408, 'f1-score': 0.9170430422455136, 'support': 1132} weighted_avg {'precision': 0.9186798090119166, 'recall': 0.916077738515901, 'f1-score': 0.9158023389751843, 'support': 1132}
 
----------
Epoch 28/40
time = 851.04 secondes

Train loss 0.039331617534531016 accuracy 0.993714451789856 macro_avg {'precision': 0.9933584777499871, 'recall': 0.9932209279230243, 'f1-score': 0.9932776055228816, 'support': 10182} weighted_avg {'precision': 0.9937353594668228, 'recall': 0.9937143979571793, 'f1-score': 0.9937133335461933, 'support': 10182}
 
time = 29.61 secondes

Val loss 0.798071673598725 accuracy 0.9116607904434204 macro_avg {'precision': 0.9174200254823038, 'recall': 0.9115161598808207, 'f1-score': 0.9124434321739233, 'support': 1132} weighted_avg {'precision': 0.9146394200693866, 'recall': 0.911660777385159, 'f1-score': 0.9111412411847691, 'support': 1132}
 
----------
Epoch 29/40
time = 857.07 secondes

Train loss 0.04142470813061509 accuracy 0.991750180721283 macro_avg {'precision': 0.9915775482831725, 'recall': 0.9914590483524552, 'f1-score': 0.9914936029461042, 'support': 10182} weighted_avg {'precision': 0.9918272159842144, 'recall': 0.9917501473187978, 'f1-score': 0.9917642027058032, 'support': 10182}
 
time = 30.80 secondes

Val loss 0.7242563167046555 accuracy 0.9178445339202881 macro_avg {'precision': 0.9258350868688229, 'recall': 0.9195154293685274, 'f1-score': 0.9207606291082483, 'support': 1132} weighted_avg {'precision': 0.9228854815126709, 'recall': 0.9178445229681979, 'f1-score': 0.918384472930696, 'support': 1132}
 
----------
Epoch 30/40
time = 862.97 secondes

Train loss 0.036637708850698295 accuracy 0.9936162233352661 macro_avg {'precision': 0.9936632713167732, 'recall': 0.9936432908454348, 'f1-score': 0.9936388392361973, 'support': 10182} weighted_avg {'precision': 0.9936549319646949, 'recall': 0.9936161854252603, 'f1-score': 0.9936210511222473, 'support': 10182}
 
time = 29.86 secondes

Val loss 0.6464378509682691 accuracy 0.9178445339202881 macro_avg {'precision': 0.9227777470740983, 'recall': 0.9187379759181449, 'f1-score': 0.919674479223912, 'support': 1132} weighted_avg {'precision': 0.9210131228394323, 'recall': 0.9178445229681979, 'f1-score': 0.9183631539990135, 'support': 1132}
 
----------
Epoch 31/40
time = 858.09 secondes

Train loss 0.027774398153863386 accuracy 0.9954822659492493 macro_avg {'precision': 0.9954917514453653, 'recall': 0.9954236725697099, 'f1-score': 0.9954491725422148, 'support': 10182} weighted_avg {'precision': 0.9954978695812576, 'recall': 0.9954822235317227, 'f1-score': 0.9954812213033093, 'support': 10182}
 
time = 30.03 secondes

Val loss 0.7845124446369957 accuracy 0.9151943325996399 macro_avg {'precision': 0.9222503650549218, 'recall': 0.9179047157754827, 'f1-score': 0.9177818093138977, 'support': 1132} weighted_avg {'precision': 0.9205456974120391, 'recall': 0.9151943462897526, 'f1-score': 0.9153983124199291, 'support': 1132}
 
----------
Epoch 32/40
time = 858.71 secondes

Train loss 0.03306070997749138 accuracy 0.9945001006126404 macro_avg {'precision': 0.994658492469973, 'recall': 0.9946267712472032, 'f1-score': 0.9946368924028188, 'support': 10182} weighted_avg {'precision': 0.9945077954580422, 'recall': 0.9945000982125319, 'f1-score': 0.9944980752591107, 'support': 10182}
 
time = 29.36 secondes

Val loss 0.745267776314097 accuracy 0.9116607904434204 macro_avg {'precision': 0.9210581645619366, 'recall': 0.91382607407627, 'f1-score': 0.9155132255305007, 'support': 1132} weighted_avg {'precision': 0.9181362020809369, 'recall': 0.911660777385159, 'f1-score': 0.9128666813325857, 'support': 1132}
 
----------
Epoch 33/40
time = 854.63 secondes

Train loss 0.02222806531685898 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961572924543611, 'recall': 0.9962608388942196, 'f1-score': 0.9962073457849367, 'support': 10182} weighted_avg {'precision': 0.9961754087338917, 'recall': 0.9961697112551562, 'f1-score': 0.9961708982385292, 'support': 10182}
 
time = 30.54 secondes

Val loss 0.7453445871989304 accuracy 0.9125441908836365 macro_avg {'precision': 0.926168800604368, 'recall': 0.9150188800206163, 'f1-score': 0.9173571722361411, 'support': 1132} weighted_avg {'precision': 0.9230178254435311, 'recall': 0.9125441696113075, 'f1-score': 0.9142233388617108, 'support': 1132}
 
----------
Epoch 34/40
time = 856.26 secondes

Train loss 0.015327444549988075 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972138008113328, 'recall': 0.99737369788386, 'f1-score': 0.9972904431223254, 'support': 10182} weighted_avg {'precision': 0.9973543886688778, 'recall': 0.997348261638185, 'f1-score': 0.9973482921549701, 'support': 10182}
 
time = 31.16 secondes

Val loss 0.681848058899767 accuracy 0.916961133480072 macro_avg {'precision': 0.9208856730842963, 'recall': 0.9182178768872417, 'f1-score': 0.9177825582001111, 'support': 1132} weighted_avg {'precision': 0.9209941102698507, 'recall': 0.9169611307420494, 'f1-score': 0.9170861855295437, 'support': 1132}
 
----------
Epoch 35/40
time = 868.31 secondes

Train loss 0.017208318330627016 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972950489215162, 'recall': 0.9971656265073264, 'f1-score': 0.9972264382890306, 'support': 10182} weighted_avg {'precision': 0.9973538696145816, 'recall': 0.997348261638185, 'f1-score': 0.9973477758744823, 'support': 10182}
 
time = 31.88 secondes

Val loss 0.6644987162614764 accuracy 0.9196113348007202 macro_avg {'precision': 0.9247230557964142, 'recall': 0.9221587930206395, 'f1-score': 0.9214808346420575, 'support': 1132} weighted_avg {'precision': 0.9251294852786494, 'recall': 0.9196113074204947, 'f1-score': 0.9202345761129728, 'support': 1132}
 
----------
Epoch 36/40
time = 862.11 secondes

Train loss 0.015581840921161813 accuracy 0.9975447058677673 macro_avg {'precision': 0.997558486928632, 'recall': 0.9976096414123095, 'f1-score': 0.9975815026237221, 'support': 10182} weighted_avg {'precision': 0.9975460966873929, 'recall': 0.9975446867020232, 'f1-score': 0.9975428168082098, 'support': 10182}
 
time = 29.90 secondes

Val loss 0.6797184858581422 accuracy 0.9213780760765076 macro_avg {'precision': 0.9238006456718517, 'recall': 0.9228786730525403, 'f1-score': 0.9223153293503467, 'support': 1132} weighted_avg {'precision': 0.9245841342114436, 'recall': 0.9213780918727915, 'f1-score': 0.9219040087638087, 'support': 1132}
 
----------
Epoch 37/40
time = 858.48 secondes

Train loss 0.013806983781119537 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974027768397387, 'recall': 0.9973938316281077, 'f1-score': 0.9973961410408687, 'support': 10182} weighted_avg {'precision': 0.9973531859596724, 'recall': 0.997348261638185, 'f1-score': 0.9973484907657797, 'support': 10182}
 
time = 30.80 secondes

Val loss 0.804871028646105 accuracy 0.9231448769569397 macro_avg {'precision': 0.9319711188385534, 'recall': 0.9245454650851738, 'f1-score': 0.9257997264661567, 'support': 1132} weighted_avg {'precision': 0.9308496110726515, 'recall': 0.9231448763250883, 'f1-score': 0.9243600459129587, 'support': 1132}
 
----------
Epoch 38/40
time = 855.21 secondes

Train loss 0.010794003921709159 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985671706362995, 'recall': 0.9985447032983696, 'f1-score': 0.9985554705882068, 'support': 10182} weighted_avg {'precision': 0.9985271318619927, 'recall': 0.998526812021214, 'f1-score': 0.9985264992324384, 'support': 10182}
 
time = 30.05 secondes

Val loss 0.7302941198095781 accuracy 0.9240282773971558 macro_avg {'precision': 0.9300096413852609, 'recall': 0.9257847685812169, 'f1-score': 0.9267074978647594, 'support': 1132} weighted_avg {'precision': 0.9279225203369199, 'recall': 0.9240282685512368, 'f1-score': 0.9247391708879779, 'support': 1132}
 
----------
Epoch 39/40
time = 861.47 secondes

Train loss 0.011380939080050577 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984966056501363, 'recall': 0.9984597823151914, 'f1-score': 0.9984753377070316, 'support': 10182} weighted_avg {'precision': 0.9984360639972933, 'recall': 0.9984285994892949, 'f1-score': 0.9984293812841731, 'support': 10182}
 
time = 30.23 secondes

Val loss 0.7874818144574535 accuracy 0.9187279343605042 macro_avg {'precision': 0.9269948500608315, 'recall': 0.920546303150098, 'f1-score': 0.921685395642722, 'support': 1132} weighted_avg {'precision': 0.9256446738587789, 'recall': 0.9187279151943463, 'f1-score': 0.9199305708118599, 'support': 1132}
 
----------
Epoch 40/40
time = 864.22 secondes

Train loss 0.001622616501164993 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996283860557307, 'recall': 0.9996226139678146, 'f1-score': 0.9996252364308884, 'support': 10182} weighted_avg {'precision': 0.9996076962404251, 'recall': 0.9996071498723237, 'f1-score': 0.9996071470325572, 'support': 10182}
 
time = 29.69 secondes

Val loss 0.7293297224956328 accuracy 0.9257950782775879 macro_avg {'precision': 0.9322699492679736, 'recall': 0.9277151417669126, 'f1-score': 0.9288242092413274, 'support': 1132} weighted_avg {'precision': 0.9300862753065733, 'recall': 0.9257950530035336, 'f1-score': 0.9267039859714794, 'support': 1132}
 
----------
best_accuracy 0.9257950782775879 best_epoch 40 macro_avg {'precision': 0.9322699492679736, 'recall': 0.9277151417669126, 'f1-score': 0.9288242092413274, 'support': 1132} weighted_avg {'precision': 0.9300862753065733, 'recall': 0.9257950530035336, 'f1-score': 0.9267039859714794, 'support': 1132}

average train time 1006.7639273285865

average val time 34.7730585873127
 
time = 196.33 secondes

test_accuracy 0.8579394221305847 macro_avg {'precision': 0.8555628803386437, 'recall': 0.8499440395946329, 'f1-score': 0.850911266602864, 'support': 7532} weighted_avg {'precision': 0.8621982331852962, 'recall': 0.8579394583112055, 'f1-score': 0.8582808092412973, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_5
----------
Epoch 1/40
time = 1158.74 secondes

Train loss 1.1305344080906274 accuracy 0.6820860505104065 macro_avg {'precision': 0.6850373820133395, 'recall': 0.6689953496798119, 'f1-score': 0.6692851198214754, 'support': 10182} weighted_avg {'precision': 0.6923192210501069, 'recall': 0.6820860341779611, 'f1-score': 0.6804454498629472, 'support': 10182}
 
time = 38.78 secondes

Val loss 0.5575317289208023 accuracy 0.8374558091163635 macro_avg {'precision': 0.8338128485838858, 'recall': 0.8328304723036398, 'f1-score': 0.8241014059895895, 'support': 1132} weighted_avg {'precision': 0.8381286797824806, 'recall': 0.8374558303886925, 'f1-score': 0.8297660328817458, 'support': 1132}
 
----------
Epoch 2/40
time = 1143.28 secondes

Train loss 0.40187442868515216 accuracy 0.8809664249420166 macro_avg {'precision': 0.873702072866626, 'recall': 0.8729348031403328, 'f1-score': 0.8728477251250023, 'support': 10182} weighted_avg {'precision': 0.8800857449690599, 'recall': 0.8809664113140837, 'f1-score': 0.880145235801781, 'support': 10182}
 
time = 37.15 secondes

Val loss 0.5407826971315163 accuracy 0.8604240417480469 macro_avg {'precision': 0.8688497409436083, 'recall': 0.8644242039134422, 'f1-score': 0.8573736606194329, 'support': 1132} weighted_avg {'precision': 0.8733549456742314, 'recall': 0.8604240282685512, 'f1-score': 0.8566728758685138, 'support': 1132}
 
----------
Epoch 3/40
time = 1210.65 secondes

Train loss 0.23758739418915972 accuracy 0.9309566020965576 macro_avg {'precision': 0.9267232847283801, 'recall': 0.9262454705748265, 'f1-score': 0.9263835007615621, 'support': 10182} weighted_avg {'precision': 0.9308821603155657, 'recall': 0.9309565900608918, 'f1-score': 0.9308273045060012, 'support': 10182}
 
time = 35.94 secondes

Val loss 0.4170163656965318 accuracy 0.9019434452056885 macro_avg {'precision': 0.9070273541952982, 'recall': 0.9023568576375398, 'f1-score': 0.9021384201050923, 'support': 1132} weighted_avg {'precision': 0.9062141780615479, 'recall': 0.9019434628975265, 'f1-score': 0.9015070385768217, 'support': 1132}
 
----------
Epoch 4/40
time = 1217.25 secondes

Train loss 0.1749730537465687 accuracy 0.9523669481277466 macro_avg {'precision': 0.9503629538872694, 'recall': 0.9498952097401201, 'f1-score': 0.9500721321537823, 'support': 10182} weighted_avg {'precision': 0.9526071445926362, 'recall': 0.9523669220192497, 'f1-score': 0.9524299112961209, 'support': 10182}
 
time = 34.91 secondes

Val loss 0.49717233845190156 accuracy 0.8931095600128174 macro_avg {'precision': 0.8985333019345791, 'recall': 0.8918850364094402, 'f1-score': 0.8918611436879258, 'support': 1132} weighted_avg {'precision': 0.8972706381155869, 'recall': 0.8931095406360424, 'f1-score': 0.8919446526507887, 'support': 1132}
 
----------
Epoch 5/40
time = 1213.42 secondes

Train loss 0.14887764721577387 accuracy 0.9619917869567871 macro_avg {'precision': 0.9601035820962245, 'recall': 0.9600273611521054, 'f1-score': 0.9600352145892239, 'support': 10182} weighted_avg {'precision': 0.9620721512509437, 'recall': 0.9619917501473187, 'f1-score': 0.9620015940194782, 'support': 10182}
 
time = 41.74 secondes

Val loss 0.6723526065962546 accuracy 0.8754417300224304 macro_avg {'precision': 0.894968572273221, 'recall': 0.8663475489247446, 'f1-score': 0.8725534685724774, 'support': 1132} weighted_avg {'precision': 0.8903134473684027, 'recall': 0.8754416961130742, 'f1-score': 0.8749145918607554, 'support': 1132}
 
----------
Epoch 6/40
time = 1264.76 secondes

Train loss 0.13837236522739313 accuracy 0.9677863121032715 macro_avg {'precision': 0.9671931469728845, 'recall': 0.9668529736760965, 'f1-score': 0.9670018331685629, 'support': 10182} weighted_avg {'precision': 0.9677989261792014, 'recall': 0.9677862895305441, 'f1-score': 0.9677730851409737, 'support': 10182}
 
time = 39.76 secondes

Val loss 0.588329784348312 accuracy 0.9037102460861206 macro_avg {'precision': 0.9101592314420044, 'recall': 0.9055444707166853, 'f1-score': 0.9047220567275487, 'support': 1132} weighted_avg {'precision': 0.9096550829516835, 'recall': 0.9037102473498233, 'f1-score': 0.9032266521192527, 'support': 1132}
 
----------
Epoch 7/40
time = 1400.06 secondes

Train loss 0.12472769236166521 accuracy 0.9709291458129883 macro_avg {'precision': 0.9703085250074601, 'recall': 0.9702231310268642, 'f1-score': 0.9702421181501609, 'support': 10182} weighted_avg {'precision': 0.9709528427227425, 'recall': 0.9709290905519544, 'f1-score': 0.9709171076850264, 'support': 10182}
 
time = 50.70 secondes

Val loss 0.6630023712436603 accuracy 0.8992933034896851 macro_avg {'precision': 0.9066026529488891, 'recall': 0.9041010219387106, 'f1-score': 0.9006252916508787, 'support': 1132} weighted_avg {'precision': 0.9111850187671798, 'recall': 0.8992932862190812, 'f1-score': 0.9008921695832972, 'support': 1132}
 
----------
Epoch 8/40
time = 1788.24 secondes

Train loss 0.12507492639405837 accuracy 0.9715183973312378 macro_avg {'precision': 0.9703972672470021, 'recall': 0.9704413692920237, 'f1-score': 0.9703960971650213, 'support': 10182} weighted_avg {'precision': 0.9715600754175054, 'recall': 0.9715183657434688, 'f1-score': 0.9715159245448858, 'support': 10182}
 
time = 48.02 secondes

Val loss 0.6080183136050629 accuracy 0.9028268456459045 macro_avg {'precision': 0.9098572144783714, 'recall': 0.9044471910835371, 'f1-score': 0.9044492662271939, 'support': 1132} weighted_avg {'precision': 0.9078726508675276, 'recall': 0.9028268551236749, 'f1-score': 0.9022932430045096, 'support': 1132}
 
----------
Epoch 9/40
time = 1741.43 secondes

Train loss 0.12859460070856818 accuracy 0.9724023342132568 macro_avg {'precision': 0.9720826333431507, 'recall': 0.9716910095960747, 'f1-score': 0.9717940758645497, 'support': 10182} weighted_avg {'precision': 0.9723373940772726, 'recall': 0.9724022785307406, 'f1-score': 0.9722811491036726, 'support': 10182}
 
time = 96.78 secondes

Val loss 0.576187524891665 accuracy 0.9098939895629883 macro_avg {'precision': 0.9174313671232737, 'recall': 0.9072453524240732, 'f1-score': 0.9083803206091522, 'support': 1132} weighted_avg {'precision': 0.9149583742430102, 'recall': 0.9098939929328622, 'f1-score': 0.9089740087513175, 'support': 1132}
 
----------
Epoch 10/40
time = 2515.26 secondes

Train loss 0.0976811626864293 accuracy 0.9780004024505615 macro_avg {'precision': 0.9777889526124184, 'recall': 0.9774974470046628, 'f1-score': 0.9776313828307606, 'support': 10182} weighted_avg {'precision': 0.9780080718117166, 'recall': 0.9780003928501276, 'f1-score': 0.9779935440988431, 'support': 10182}
 
time = 78.06 secondes

Val loss 0.6970274205738515 accuracy 0.898409903049469 macro_avg {'precision': 0.9085908771574642, 'recall': 0.9021606091579054, 'f1-score': 0.9015754466210018, 'support': 1132} weighted_avg {'precision': 0.9096717529437047, 'recall': 0.8984098939929329, 'f1-score': 0.900087389775917, 'support': 1132}
 
----------
Epoch 11/40
time = 2389.86 secondes

Train loss 0.11280565700000587 accuracy 0.9777057766914368 macro_avg {'precision': 0.9768054538003996, 'recall': 0.9770668479341017, 'f1-score': 0.9768924977576766, 'support': 10182} weighted_avg {'precision': 0.9778241340749976, 'recall': 0.9777057552543704, 'f1-score': 0.9777218359602396, 'support': 10182}
 
time = 89.00 secondes

Val loss 0.7559369873041517 accuracy 0.8922261595726013 macro_avg {'precision': 0.9023529133889445, 'recall': 0.8950017181655363, 'f1-score': 0.8948262238442727, 'support': 1132} weighted_avg {'precision': 0.9011404042164843, 'recall': 0.892226148409894, 'f1-score': 0.8928866316850319, 'support': 1132}
 
----------
Epoch 12/40
time = 1321.09 secondes

Train loss 0.10476085289876347 accuracy 0.978295087814331 macro_avg {'precision': 0.977997700376285, 'recall': 0.9778072470193095, 'f1-score': 0.9778502725071674, 'support': 10182} weighted_avg {'precision': 0.9783768731464567, 'recall': 0.978295030445885, 'f1-score': 0.9782824732410752, 'support': 10182}
 
time = 46.60 secondes

Val loss 0.6623062740219839 accuracy 0.9107773900032043 macro_avg {'precision': 0.9136203500900008, 'recall': 0.9147066850522746, 'f1-score': 0.9119264574857479, 'support': 1132} weighted_avg {'precision': 0.9157980835645412, 'recall': 0.9107773851590106, 'f1-score': 0.9110578297072937, 'support': 1132}
 
----------
Epoch 13/40
time = 1800.13 secondes

Train loss 0.09222395056458424 accuracy 0.9820271134376526 macro_avg {'precision': 0.9815789808108392, 'recall': 0.9815360658481357, 'f1-score': 0.9815379351414194, 'support': 10182} weighted_avg {'precision': 0.9820651062015643, 'recall': 0.9820271066588097, 'f1-score': 0.9820265445303971, 'support': 10182}
 
time = 54.60 secondes

Val loss 0.8333549677217248 accuracy 0.8851590156555176 macro_avg {'precision': 0.8982208141559909, 'recall': 0.8899732060240876, 'f1-score': 0.8875379928141951, 'support': 1132} weighted_avg {'precision': 0.8992828896383976, 'recall': 0.8851590106007067, 'f1-score': 0.8846679551407592, 'support': 1132}
 
----------
Epoch 14/40
time = 1707.20 secondes

Train loss 0.09113939176834432 accuracy 0.9815360903739929 macro_avg {'precision': 0.9808630603119763, 'recall': 0.9810160086599456, 'f1-score': 0.9809290779943561, 'support': 10182} weighted_avg {'precision': 0.9815626689259355, 'recall': 0.9815360439992143, 'f1-score': 0.9815392516905038, 'support': 10182}
 
time = 54.28 secondes

Val loss 0.7265318556203799 accuracy 0.9063604474067688 macro_avg {'precision': 0.9096436783979571, 'recall': 0.9058792020308131, 'f1-score': 0.9058652045161892, 'support': 1132} weighted_avg {'precision': 0.9115270106808036, 'recall': 0.9063604240282686, 'f1-score': 0.9070310320098495, 'support': 1132}
 
----------
Epoch 15/40
time = 1701.98 secondes

Train loss 0.08464127557230744 accuracy 0.9841877818107605 macro_avg {'precision': 0.9836256785516546, 'recall': 0.9833482108893618, 'f1-score': 0.9834672172217722, 'support': 10182} weighted_avg {'precision': 0.9842138525786391, 'recall': 0.9841877823610292, 'f1-score': 0.9841817913910089, 'support': 10182}
 
time = 54.56 secondes

Val loss 0.7460037481230782 accuracy 0.9107773900032043 macro_avg {'precision': 0.9154972320665069, 'recall': 0.9146530025292623, 'f1-score': 0.9125179582019601, 'support': 1132} weighted_avg {'precision': 0.917195712252655, 'recall': 0.9107773851590106, 'f1-score': 0.911498241541149, 'support': 1132}
 
----------
Epoch 16/40
time = 1720.72 secondes

Train loss 0.10207240852046491 accuracy 0.9813396334648132 macro_avg {'precision': 0.9808294680562399, 'recall': 0.9810017543479654, 'f1-score': 0.9808770797177828, 'support': 10182} weighted_avg {'precision': 0.9814284369105609, 'recall': 0.9813396189353761, 'f1-score': 0.9813474441408492, 'support': 10182}
 
time = 55.77 secondes

Val loss 0.8083855497349925 accuracy 0.9028268456459045 macro_avg {'precision': 0.9075573983389502, 'recall': 0.9056358141832114, 'f1-score': 0.9037263107376532, 'support': 1132} weighted_avg {'precision': 0.9107805054415361, 'recall': 0.9028268551236749, 'f1-score': 0.9039978751083967, 'support': 1132}
 
----------
Epoch 17/40
time = 1708.23 secondes

Train loss 0.08065592809208359 accuracy 0.9851699471473694 macro_avg {'precision': 0.9845104390610253, 'recall': 0.9844617082552501, 'f1-score': 0.9844684966347057, 'support': 10182} weighted_avg {'precision': 0.9852012731898345, 'recall': 0.98516990768022, 'f1-score': 0.9851687063516796, 'support': 10182}
 
time = 55.79 secondes

Val loss 0.7177609835419735 accuracy 0.9045936465263367 macro_avg {'precision': 0.9090280336256974, 'recall': 0.9033866039569347, 'f1-score': 0.9041678741810157, 'support': 1132} weighted_avg {'precision': 0.9087963713871106, 'recall': 0.9045936395759717, 'f1-score': 0.9046482714108125, 'support': 1132}
 
----------
Epoch 18/40
time = 1573.09 secondes

Train loss 0.07094720301905812 accuracy 0.9866431355476379 macro_avg {'precision': 0.985706924244399, 'recall': 0.9857851007317244, 'f1-score': 0.9857291331903509, 'support': 10182} weighted_avg {'precision': 0.9866748690929084, 'recall': 0.9866430956590061, 'f1-score': 0.9866415412385727, 'support': 10182}
 
time = 40.42 secondes

Val loss 0.7480571825773796 accuracy 0.9001767039299011 macro_avg {'precision': 0.9095796892427991, 'recall': 0.9035556516185765, 'f1-score': 0.9031503597205409, 'support': 1132} weighted_avg {'precision': 0.9108631352001592, 'recall': 0.9001766784452296, 'f1-score': 0.901935404930142, 'support': 1132}
 
----------
Epoch 19/40
time = 1392.44 secondes

Train loss 0.07527019657045257 accuracy 0.9858574271202087 macro_avg {'precision': 0.9855096795105907, 'recall': 0.9853831067865402, 'f1-score': 0.9854259110239392, 'support': 10182} weighted_avg {'precision': 0.9859184008741201, 'recall': 0.9858573954036535, 'f1-score': 0.9858685975766042, 'support': 10182}
 
time = 39.29 secondes

Val loss 0.5616493090357169 accuracy 0.9204947352409363 macro_avg {'precision': 0.9227233908239612, 'recall': 0.9228383580064865, 'f1-score': 0.9218528184361345, 'support': 1132} weighted_avg {'precision': 0.922087071595895, 'recall': 0.9204946996466431, 'f1-score': 0.9203484676913775, 'support': 1132}
 
----------
Epoch 20/40
time = 1398.24 secondes

Train loss 0.050737213073691716 accuracy 0.98978590965271 macro_avg {'precision': 0.9893947826730047, 'recall': 0.9894096697769657, 'f1-score': 0.9893951672839097, 'support': 10182} weighted_avg {'precision': 0.9897874098692602, 'recall': 0.9897858966804164, 'f1-score': 0.989779532781744, 'support': 10182}
 
time = 36.89 secondes

Val loss 0.707198783521652 accuracy 0.9134275913238525 macro_avg {'precision': 0.9176158733113107, 'recall': 0.9173602071911974, 'f1-score': 0.9156736356111528, 'support': 1132} weighted_avg {'precision': 0.9190842371107043, 'recall': 0.9134275618374559, 'f1-score': 0.9143623562395508, 'support': 1132}
 
----------
Epoch 21/40
time = 1400.30 secondes

Train loss 0.07619439555388764 accuracy 0.9879198670387268 macro_avg {'precision': 0.9874735505786983, 'recall': 0.9877774318404597, 'f1-score': 0.987594966061676, 'support': 10182} weighted_avg {'precision': 0.9880058282936296, 'recall': 0.987919858573954, 'f1-score': 0.9879336805724702, 'support': 10182}
 
time = 41.61 secondes

Val loss 0.8041701002954833 accuracy 0.8966431021690369 macro_avg {'precision': 0.9108554328547658, 'recall': 0.9021392233687143, 'f1-score': 0.8996014647149628, 'support': 1132} weighted_avg {'precision': 0.9122529929620926, 'recall': 0.8966431095406361, 'f1-score': 0.8971749955494288, 'support': 1132}
 
----------
Epoch 22/40
time = 1406.93 secondes

Train loss 0.05821075624832874 accuracy 0.9901787638664246 macro_avg {'precision': 0.9901536150193371, 'recall': 0.9901358009665664, 'f1-score': 0.9901362095457719, 'support': 10182} weighted_avg {'precision': 0.9901959820932905, 'recall': 0.9901787468080927, 'f1-score': 0.9901791278646703, 'support': 10182}
 
time = 40.27 secondes

Val loss 0.6160226992520416 accuracy 0.9231448769569397 macro_avg {'precision': 0.9264078171661833, 'recall': 0.9233659403922202, 'f1-score': 0.924062190174249, 'support': 1132} weighted_avg {'precision': 0.9245511426007168, 'recall': 0.9231448763250883, 'f1-score': 0.9230048845392417, 'support': 1132}
 
----------
Epoch 23/40
time = 1403.22 secondes

Train loss 0.05566785504335678 accuracy 0.9899823665618896 macro_avg {'precision': 0.9897064181526825, 'recall': 0.9898317236820711, 'f1-score': 0.9897550764017335, 'support': 10182} weighted_avg {'precision': 0.9900045855355776, 'recall': 0.9899823217442546, 'f1-score': 0.9899798220775783, 'support': 10182}
 
time = 40.65 secondes

Val loss 0.6073500090537955 accuracy 0.9240282773971558 macro_avg {'precision': 0.9293066007668184, 'recall': 0.9261411934642609, 'f1-score': 0.9261450938144101, 'support': 1132} weighted_avg {'precision': 0.9275836709543789, 'recall': 0.9240282685512368, 'f1-score': 0.924196284945097, 'support': 1132}
 
----------
Epoch 24/40
time = 1493.57 secondes

Train loss 0.06600047455838054 accuracy 0.9888038039207458 macro_avg {'precision': 0.9886405739345301, 'recall': 0.9885526311657505, 'f1-score': 0.9885486023878391, 'support': 10182} weighted_avg {'precision': 0.9888919127385037, 'recall': 0.9888037713612257, 'f1-score': 0.9888017526858824, 'support': 10182}
 
time = 39.31 secondes

Val loss 0.6416098288124924 accuracy 0.9222614765167236 macro_avg {'precision': 0.9253814621743901, 'recall': 0.9248932778550193, 'f1-score': 0.9238604895854957, 'support': 1132} weighted_avg {'precision': 0.9254277545786035, 'recall': 0.9222614840989399, 'f1-score': 0.922494327098302, 'support': 1132}
 
----------
Epoch 25/40
time = 1594.67 secondes

Train loss 0.054765893018443916 accuracy 0.9901787638664246 macro_avg {'precision': 0.9902242333967044, 'recall': 0.9900586167070035, 'f1-score': 0.9901269686162502, 'support': 10182} weighted_avg {'precision': 0.9901963392526407, 'recall': 0.9901787468080927, 'f1-score': 0.9901729625989875, 'support': 10182}
 
time = 44.68 secondes

Val loss 0.7675280765288848 accuracy 0.9001767039299011 macro_avg {'precision': 0.9139748291135751, 'recall': 0.903779273710267, 'f1-score': 0.9045480238339193, 'support': 1132} weighted_avg {'precision': 0.9124109988086011, 'recall': 0.9001766784452296, 'f1-score': 0.9014116914249154, 'support': 1132}
 
----------
Epoch 26/40
time = 1716.63 secondes

Train loss 0.0612130660056195 accuracy 0.9893930554389954 macro_avg {'precision': 0.9894041079420791, 'recall': 0.9891852877188493, 'f1-score': 0.9892695708554321, 'support': 10182} weighted_avg {'precision': 0.9894879545639466, 'recall': 0.9893930465527401, 'f1-score': 0.9894151636256698, 'support': 10182}
 
time = 55.07 secondes

Val loss 0.6358479074949339 accuracy 0.916077733039856 macro_avg {'precision': 0.9197435840605216, 'recall': 0.9207693510634435, 'f1-score': 0.9184080808675654, 'support': 1132} weighted_avg {'precision': 0.920837390847071, 'recall': 0.916077738515901, 'f1-score': 0.9165556712776163, 'support': 1132}
 
----------
Epoch 27/40
time = 1768.63 secondes

Train loss 0.047665141433916654 accuracy 0.9911609292030334 macro_avg {'precision': 0.9909279733338783, 'recall': 0.9908696431287929, 'f1-score': 0.9908812573614535, 'support': 10182} weighted_avg {'precision': 0.9912106426848722, 'recall': 0.9911608721272834, 'f1-score': 0.9911675366199921, 'support': 10182}
 
time = 54.06 secondes

Val loss 0.5772119487015183 accuracy 0.9213780760765076 macro_avg {'precision': 0.9248846062607912, 'recall': 0.9238012391271818, 'f1-score': 0.9229678784351367, 'support': 1132} weighted_avg {'precision': 0.9245769269633028, 'recall': 0.9213780918727915, 'f1-score': 0.9215337459960716, 'support': 1132}
 
----------
Epoch 28/40
time = 1774.87 secondes

Train loss 0.04000872611076984 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934710162025127, 'recall': 0.9935303399184875, 'f1-score': 0.993495722976985, 'support': 10182} weighted_avg {'precision': 0.993528389825299, 'recall': 0.9935179728933412, 'f1-score': 0.9935180872340954, 'support': 10182}
 
time = 58.93 secondes

Val loss 0.6434107668229303 accuracy 0.9213780760765076 macro_avg {'precision': 0.9285221864362538, 'recall': 0.9221251731401482, 'f1-score': 0.9229292862745764, 'support': 1132} weighted_avg {'precision': 0.9270456641936767, 'recall': 0.9213780918727915, 'f1-score': 0.9219181373356892, 'support': 1132}
 
----------
Epoch 29/40
time = 1784.27 secondes

Train loss 0.027891033626350165 accuracy 0.9947947859764099 macro_avg {'precision': 0.9948107115201579, 'recall': 0.99452790784131, 'f1-score': 0.9946616834767976, 'support': 10182} weighted_avg {'precision': 0.9948008416888167, 'recall': 0.9947947358082891, 'f1-score': 0.994791222324211, 'support': 10182}
 
time = 51.84 secondes

Val loss 0.6736052075085726 accuracy 0.9249116778373718 macro_avg {'precision': 0.9276408805753338, 'recall': 0.9272865738120266, 'f1-score': 0.9256489019163959, 'support': 1132} weighted_avg {'precision': 0.9289071113734977, 'recall': 0.9249116607773852, 'f1-score': 0.9251318023205112, 'support': 1132}
 
----------
Epoch 30/40
time = 1797.70 secondes

Train loss 0.03540460405201884 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934825190867222, 'recall': 0.9934803634109043, 'f1-score': 0.9934754353669997, 'support': 10182} weighted_avg {'precision': 0.9935292579790387, 'recall': 0.9935179728933412, 'f1-score': 0.9935174840555993, 'support': 10182}
 
time = 56.42 secondes

Val loss 0.6631120628119622 accuracy 0.9151943325996399 macro_avg {'precision': 0.9217475868454053, 'recall': 0.9181371932996631, 'f1-score': 0.9177973288272581, 'support': 1132} weighted_avg {'precision': 0.9218695804542374, 'recall': 0.9151943462897526, 'f1-score': 0.9161886134957098, 'support': 1132}
 
----------
Epoch 31/40
time = 1787.69 secondes

Train loss 0.027699407553542527 accuracy 0.9951876401901245 macro_avg {'precision': 0.9953175193278231, 'recall': 0.9953233222637898, 'f1-score': 0.9953148243020011, 'support': 10182} weighted_avg {'precision': 0.9951913026635637, 'recall': 0.9951875859359655, 'f1-score': 0.9951836964188637, 'support': 10182}
 
time = 57.50 secondes

Val loss 0.6066643394000827 accuracy 0.926678478717804 macro_avg {'precision': 0.9283366114445327, 'recall': 0.9278526047985169, 'f1-score': 0.9270327013161248, 'support': 1132} weighted_avg {'precision': 0.9290727547846553, 'recall': 0.926678445229682, 'f1-score': 0.9267484484099504, 'support': 1132}
 
----------
Epoch 32/40
time = 1686.51 secondes

Train loss 0.02783537795889406 accuracy 0.9944019317626953 macro_avg {'precision': 0.9940104163164104, 'recall': 0.9942120610085512, 'f1-score': 0.9940949395208314, 'support': 10182} weighted_avg {'precision': 0.9944371608898261, 'recall': 0.9944018856806128, 'f1-score': 0.9944056988087661, 'support': 10182}
 
time = 44.12 secondes

Val loss 0.6685229087647393 accuracy 0.9213780760765076 macro_avg {'precision': 0.927276927279531, 'recall': 0.9215974721167557, 'f1-score': 0.9221967094152272, 'support': 1132} weighted_avg {'precision': 0.9269729451792571, 'recall': 0.9213780918727915, 'f1-score': 0.9219293548202676, 'support': 1132}
 
----------
Epoch 33/40
time = 1568.07 secondes

Train loss 0.0193779758511101 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960206854994235, 'recall': 0.9960134621554729, 'f1-score': 0.9960096727623288, 'support': 10182} weighted_avg {'precision': 0.9961867513951065, 'recall': 0.9961697112551562, 'f1-score': 0.9961710662755333, 'support': 10182}
 
time = 43.02 secondes

Val loss 0.7528022624264593 accuracy 0.9081271886825562 macro_avg {'precision': 0.9172289023894207, 'recall': 0.9119414776649599, 'f1-score': 0.9114802563933615, 'support': 1132} weighted_avg {'precision': 0.9183835003999731, 'recall': 0.9081272084805654, 'f1-score': 0.9101379177502416, 'support': 1132}
 
----------
Epoch 34/40
time = 1388.12 secondes

Train loss 0.020970788584096366 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959735911746399, 'recall': 0.99590866703295, 'f1-score': 0.9959329915809205, 'support': 10182} weighted_avg {'precision': 0.9958971193199402, 'recall': 0.995875073659399, 'f1-score': 0.9958777281648554, 'support': 10182}
 
time = 39.89 secondes

Val loss 0.7249698054715544 accuracy 0.9151943325996399 macro_avg {'precision': 0.9251122578834184, 'recall': 0.9192693789728986, 'f1-score': 0.9194348300569588, 'support': 1132} weighted_avg {'precision': 0.924341374560887, 'recall': 0.9151943462897526, 'f1-score': 0.9166072600600726, 'support': 1132}
 
----------
Epoch 35/40
time = 1292.15 secondes

Train loss 0.021882109113253785 accuracy 0.9967589974403381 macro_avg {'precision': 0.9968172693741945, 'recall': 0.9967784472335248, 'f1-score': 0.9967952457385026, 'support': 10182} weighted_avg {'precision': 0.9967644162565928, 'recall': 0.9967589864466706, 'f1-score': 0.9967591094403794, 'support': 10182}
 
time = 40.31 secondes

Val loss 0.6772329003110634 accuracy 0.9231448769569397 macro_avg {'precision': 0.9277668569916722, 'recall': 0.9264500882794389, 'f1-score': 0.9255432065941538, 'support': 1132} weighted_avg {'precision': 0.9267689959349648, 'recall': 0.9231448763250883, 'f1-score': 0.9233166084881061, 'support': 1132}
 
----------
Epoch 36/40
time = 1286.28 secondes

Train loss 0.016210656367525084 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973607996716127, 'recall': 0.997369023157287, 'f1-score': 0.9973607777849685, 'support': 10182} weighted_avg {'precision': 0.997256409136161, 'recall': 0.9972500491062659, 'f1-score': 0.9972489095572997, 'support': 10182}
 
time = 34.82 secondes

Val loss 0.69942385952245 accuracy 0.9178445339202881 macro_avg {'precision': 0.9235077275866784, 'recall': 0.9219908764226206, 'f1-score': 0.9204444120581009, 'support': 1132} weighted_avg {'precision': 0.9243818115347605, 'recall': 0.9178445229681979, 'f1-score': 0.9186517573640954, 'support': 1132}
 
----------
Epoch 37/40
time = 1285.74 secondes

Train loss 0.010134344625619853 accuracy 0.9976429343223572 macro_avg {'precision': 0.997608285484645, 'recall': 0.9976545816155087, 'f1-score': 0.997629594236406, 'support': 10182} weighted_avg {'precision': 0.9976462083290575, 'recall': 0.9976428992339422, 'f1-score': 0.9976426815293276, 'support': 10182}
 
time = 37.09 secondes

Val loss 0.6969437940724034 accuracy 0.9204947352409363 macro_avg {'precision': 0.9232007558825577, 'recall': 0.9227496431656865, 'f1-score': 0.9210965724409835, 'support': 1132} weighted_avg {'precision': 0.9256498810130085, 'recall': 0.9204946996466431, 'f1-score': 0.9210594439290632, 'support': 1132}
 
----------
Epoch 38/40
time = 1281.11 secondes

Train loss 0.00419865687570341 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986552743652094, 'recall': 0.9987466391568234, 'f1-score': 0.9986998147815562, 'support': 10182} weighted_avg {'precision': 0.9987260428821306, 'recall': 0.9987232370850521, 'f1-score': 0.9987236130339551, 'support': 10182}
 
time = 38.55 secondes

Val loss 0.6921614385338332 accuracy 0.9257950782775879 macro_avg {'precision': 0.9331501157774132, 'recall': 0.9275327259908825, 'f1-score': 0.9277965072836782, 'support': 1132} weighted_avg {'precision': 0.9334226397011728, 'recall': 0.9257950530035336, 'f1-score': 0.9270477298179949, 'support': 1132}
 
----------
Epoch 39/40
time = 1283.79 secondes

Train loss 0.004758495891687037 accuracy 0.9986250400543213 macro_avg {'precision': 0.9985557083965922, 'recall': 0.9986313093803746, 'f1-score': 0.9985926201502886, 'support': 10182} weighted_avg {'precision': 0.9986271315824751, 'recall': 0.998625024553133, 'f1-score': 0.9986252079663189, 'support': 10182}
 
time = 36.16 secondes

Val loss 0.6723217470260121 accuracy 0.9240282773971558 macro_avg {'precision': 0.9317871502784835, 'recall': 0.9262912287730616, 'f1-score': 0.9263957258777212, 'support': 1132} weighted_avg {'precision': 0.931364771695833, 'recall': 0.9240282685512368, 'f1-score': 0.925004358555096, 'support': 1132}
 
----------
Epoch 40/40
time = 1291.84 secondes

Train loss 0.0020646654560068224 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993601772037453, 'recall': 0.999394593675839, 'f1-score': 0.9993764985275027, 'support': 10182} weighted_avg {'precision': 0.9994123508008663, 'recall': 0.9994107248084856, 'f1-score': 0.9994107197181057, 'support': 10182}
 
time = 35.49 secondes

Val loss 0.6236739793879883 accuracy 0.9319788217544556 macro_avg {'precision': 0.9398570938832664, 'recall': 0.9341695919040406, 'f1-score': 0.9351399730668428, 'support': 1132} weighted_avg {'precision': 0.9378455916100297, 'recall': 0.9319787985865724, 'f1-score': 0.9329664528297767, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 40 macro_avg {'precision': 0.9398570938832664, 'recall': 0.9341695919040406, 'f1-score': 0.9351399730668428, 'support': 1132} weighted_avg {'precision': 0.9378455916100297, 'recall': 0.9319787985865724, 'f1-score': 0.9329664528297767, 'support': 1132}

average train time 1541.4539187908172

average val time 47.97027012705803
 
time = 227.59 secondes

test_accuracy 0.8673658967018127 macro_avg {'precision': 0.8650566408359784, 'recall': 0.861064970065892, 'f1-score': 0.8614629511008991, 'support': 7532} weighted_avg {'precision': 0.8711740006301247, 'recall': 0.8673659054699947, 'f1-score': 0.867828831005756, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_5
----------
Epoch 1/40
time = 1890.11 secondes

Train loss 1.0452365369961438 accuracy 0.7054606080055237 macro_avg {'precision': 0.7086144907209706, 'recall': 0.6920083932386022, 'f1-score': 0.6889285193972012, 'support': 10182} weighted_avg {'precision': 0.7141732920382139, 'recall': 0.7054606167747004, 'f1-score': 0.7006769274699, 'support': 10182}
 
time = 37.60 secondes

Val loss 0.556780601786056 accuracy 0.8303887248039246 macro_avg {'precision': 0.8280621776650575, 'recall': 0.8220706054162159, 'f1-score': 0.8132484539639613, 'support': 1132} weighted_avg {'precision': 0.828263637162333, 'recall': 0.8303886925795053, 'f1-score': 0.8201552287170046, 'support': 1132}
 
----------
Epoch 2/40
time = 1894.19 secondes

Train loss 0.394104111071214 accuracy 0.886760950088501 macro_avg {'precision': 0.8809394423911007, 'recall': 0.8789542016641425, 'f1-score': 0.8791729160002703, 'support': 10182} weighted_avg {'precision': 0.8862821643718155, 'recall': 0.886760950697309, 'f1-score': 0.8859003404384684, 'support': 10182}
 
time = 36.98 secondes

Val loss 0.46331991352350776 accuracy 0.8710247278213501 macro_avg {'precision': 0.8722347418886292, 'recall': 0.8729429240401003, 'f1-score': 0.8672242650538514, 'support': 1132} weighted_avg {'precision': 0.8766455655313478, 'recall': 0.8710247349823321, 'f1-score': 0.867742160559105, 'support': 1132}
 
----------
Epoch 3/40
time = 1891.11 secondes

Train loss 0.2458764588229323 accuracy 0.9291887879371643 macro_avg {'precision': 0.9255668901929062, 'recall': 0.9252938317653182, 'f1-score': 0.9253330019243713, 'support': 10182} weighted_avg {'precision': 0.9295662123261859, 'recall': 0.9291887644863485, 'f1-score': 0.9292823959361608, 'support': 10182}
 
time = 36.85 secondes

Val loss 0.48844882544182555 accuracy 0.8886925578117371 macro_avg {'precision': 0.8939203558195608, 'recall': 0.8929072508622535, 'f1-score': 0.8904957839777715, 'support': 1132} weighted_avg {'precision': 0.8954002335147456, 'recall': 0.8886925795053003, 'f1-score': 0.8888757406136457, 'support': 1132}
 
----------
Epoch 4/40
time = 1888.82 secondes

Train loss 0.17689922526610352 accuracy 0.9523669481277466 macro_avg {'precision': 0.950303572602045, 'recall': 0.9500460671286909, 'f1-score': 0.950120141302256, 'support': 10182} weighted_avg {'precision': 0.9525295658200635, 'recall': 0.9523669220192497, 'f1-score': 0.9523931671273091, 'support': 10182}
 
time = 36.88 secondes

Val loss 0.5090959492782262 accuracy 0.9019434452056885 macro_avg {'precision': 0.907316405401717, 'recall': 0.9032602019275515, 'f1-score': 0.9035013992133514, 'support': 1132} weighted_avg {'precision': 0.9071077883457421, 'recall': 0.9019434628975265, 'f1-score': 0.9026757968475515, 'support': 1132}
 
----------
Epoch 5/40
time = 1888.63 secondes

Train loss 0.15402838432272456 accuracy 0.9612060785293579 macro_avg {'precision': 0.9596687858177718, 'recall': 0.9595744036932278, 'f1-score': 0.9595842417845326, 'support': 10182} weighted_avg {'precision': 0.9612865611368864, 'recall': 0.9612060498919662, 'f1-score': 0.9612099086084411, 'support': 10182}
 
time = 35.34 secondes

Val loss 0.5208902965516219 accuracy 0.9063604474067688 macro_avg {'precision': 0.910320553772813, 'recall': 0.9062378766476655, 'f1-score': 0.9062207411234239, 'support': 1132} weighted_avg {'precision': 0.9100036933570564, 'recall': 0.9063604240282686, 'f1-score': 0.9062683738573419, 'support': 1132}
 
----------
Epoch 6/40
time = 1885.86 secondes

Train loss 0.14351002225026216 accuracy 0.9670006036758423 macro_avg {'precision': 0.9664004485911141, 'recall': 0.9662739228244954, 'f1-score': 0.9662738096575975, 'support': 10182} weighted_avg {'precision': 0.9671330091724826, 'recall': 0.9670005892751915, 'f1-score': 0.9670027768087194, 'support': 10182}
 
time = 36.76 secondes

Val loss 0.7662919432090425 accuracy 0.8816254734992981 macro_avg {'precision': 0.8947655502308056, 'recall': 0.8813719815236987, 'f1-score': 0.8818040916696137, 'support': 1132} weighted_avg {'precision': 0.8937673224683919, 'recall': 0.8816254416961131, 'f1-score': 0.8811927031462151, 'support': 1132}
 
----------
Epoch 7/40
time = 1887.30 secondes

Train loss 0.13450459102837564 accuracy 0.9707326889038086 macro_avg {'precision': 0.9695498701242814, 'recall': 0.9698355352204195, 'f1-score': 0.9696701535854164, 'support': 10182} weighted_avg {'precision': 0.9708716595039129, 'recall': 0.9707326654881163, 'f1-score': 0.970782615587034, 'support': 10182}
 
time = 37.21 secondes

Val loss 0.5943814275842029 accuracy 0.9072438478469849 macro_avg {'precision': 0.9156338998417424, 'recall': 0.9099618544758666, 'f1-score': 0.9106800665294971, 'support': 1132} weighted_avg {'precision': 0.9116538893321767, 'recall': 0.907243816254417, 'f1-score': 0.9072278879081793, 'support': 1132}
 
----------
Epoch 8/40
time = 1885.55 secondes

Train loss 0.12795835734724967 accuracy 0.9715183973312378 macro_avg {'precision': 0.9705279586826288, 'recall': 0.9703809635350724, 'f1-score': 0.9704179390994353, 'support': 10182} weighted_avg {'precision': 0.9715878736748783, 'recall': 0.9715183657434688, 'f1-score': 0.9715161662887781, 'support': 10182}
 
time = 36.51 secondes

Val loss 0.7312220756676127 accuracy 0.8948763608932495 macro_avg {'precision': 0.9032150100357625, 'recall': 0.8974396877664169, 'f1-score': 0.8955235493958409, 'support': 1132} weighted_avg {'precision': 0.9039749679190412, 'recall': 0.8948763250883393, 'f1-score': 0.8941501624572562, 'support': 1132}
 
----------
Epoch 9/40
time = 1886.56 secondes

Train loss 0.10779177164147188 accuracy 0.9768218994140625 macro_avg {'precision': 0.9758878576995098, 'recall': 0.9760389389437563, 'f1-score': 0.9759371524026899, 'support': 10182} weighted_avg {'precision': 0.9768596282300948, 'recall': 0.9768218424670988, 'f1-score': 0.9768141067300712, 'support': 10182}
 
time = 36.74 secondes

Val loss 0.8913121079160294 accuracy 0.8745583295822144 macro_avg {'precision': 0.8929027233292475, 'recall': 0.87155970876564, 'f1-score': 0.8732349062876225, 'support': 1132} weighted_avg {'precision': 0.8909265629294388, 'recall': 0.8745583038869258, 'f1-score': 0.8736949741223762, 'support': 1132}
 
----------
Epoch 10/40
time = 1887.85 secondes

Train loss 0.11267751887775307 accuracy 0.9757415056228638 macro_avg {'precision': 0.9755416554369394, 'recall': 0.9754694379356442, 'f1-score': 0.9754682012829932, 'support': 10182} weighted_avg {'precision': 0.9757887308901575, 'recall': 0.975741504615989, 'f1-score': 0.9757279152755064, 'support': 10182}
 
time = 37.53 secondes

Val loss 0.6703473197949663 accuracy 0.8975265026092529 macro_avg {'precision': 0.9093272227871365, 'recall': 0.898436044387036, 'f1-score': 0.8992821574562448, 'support': 1132} weighted_avg {'precision': 0.9061302357382847, 'recall': 0.8975265017667845, 'f1-score': 0.8971307888102009, 'support': 1132}
 
----------
Epoch 11/40
time = 1892.12 secondes

Train loss 0.11094402070424053 accuracy 0.9762325882911682 macro_avg {'precision': 0.975279755900692, 'recall': 0.9753941301828698, 'f1-score': 0.9753069264624058, 'support': 10182} weighted_avg {'precision': 0.9763256480688984, 'recall': 0.9762325672755844, 'f1-score': 0.9762508251740559, 'support': 10182}
 
time = 37.45 secondes

Val loss 0.7521684316057027 accuracy 0.8931095600128174 macro_avg {'precision': 0.9042208770987843, 'recall': 0.8923512053181917, 'f1-score': 0.8959417655794437, 'support': 1132} weighted_avg {'precision': 0.898979581760947, 'recall': 0.8931095406360424, 'f1-score': 0.8935860723992654, 'support': 1132}
 
----------
Epoch 12/40
time = 1895.09 secondes

Train loss 0.12270867285503073 accuracy 0.9760361909866333 macro_avg {'precision': 0.9758577750954522, 'recall': 0.9759697739325336, 'f1-score': 0.9758731611253321, 'support': 10182} weighted_avg {'precision': 0.9760672304366685, 'recall': 0.9760361422117462, 'f1-score': 0.9760106013599882, 'support': 10182}
 
time = 37.87 secondes

Val loss 0.7042935578813317 accuracy 0.9019434452056885 macro_avg {'precision': 0.9080013937141184, 'recall': 0.9036557776801478, 'f1-score': 0.9034941361114752, 'support': 1132} weighted_avg {'precision': 0.9077963597435514, 'recall': 0.9019434628975265, 'f1-score': 0.9023087404744866, 'support': 1132}
 
----------
Epoch 13/40
time = 1892.39 secondes

Train loss 0.09128395513155507 accuracy 0.9819289445877075 macro_avg {'precision': 0.9818978207385983, 'recall': 0.9813190035380732, 'f1-score': 0.9815558548689515, 'support': 10182} weighted_avg {'precision': 0.9820092401973927, 'recall': 0.9819288941268906, 'f1-score': 0.9819283883237839, 'support': 10182}
 
time = 37.52 secondes

Val loss 0.764622885143773 accuracy 0.8975265026092529 macro_avg {'precision': 0.9011251803672, 'recall': 0.8969325066802106, 'f1-score': 0.8966096004337316, 'support': 1132} weighted_avg {'precision': 0.9029706059059902, 'recall': 0.8975265017667845, 'f1-score': 0.8978608994071532, 'support': 1132}
 
----------
Epoch 14/40
time = 1893.01 secondes

Train loss 0.08499375025398541 accuracy 0.9836967587471008 macro_avg {'precision': 0.9835203153426715, 'recall': 0.9835414275793155, 'f1-score': 0.9835235518396731, 'support': 10182} weighted_avg {'precision': 0.9837171590412037, 'recall': 0.9836967197014339, 'f1-score': 0.9836996224777483, 'support': 10182}
 
time = 37.85 secondes

Val loss 0.7005178337817533 accuracy 0.9063604474067688 macro_avg {'precision': 0.9147954134953096, 'recall': 0.9068157334502203, 'f1-score': 0.9080979030637918, 'support': 1132} weighted_avg {'precision': 0.9127451873582045, 'recall': 0.9063604240282686, 'f1-score': 0.9068995750649721, 'support': 1132}
 
----------
Epoch 15/40
time = 1891.17 secondes

Train loss 0.10003281086330555 accuracy 0.9815360903739929 macro_avg {'precision': 0.981394888041031, 'recall': 0.9815040712824603, 'f1-score': 0.9814295536996596, 'support': 10182} weighted_avg {'precision': 0.9815607196481961, 'recall': 0.9815360439992143, 'f1-score': 0.9815285026458207, 'support': 10182}
 
time = 37.50 secondes

Val loss 0.7022789130524345 accuracy 0.9090105891227722 macro_avg {'precision': 0.9117965898010528, 'recall': 0.9094116768031189, 'f1-score': 0.9097796077053021, 'support': 1132} weighted_avg {'precision': 0.9103785934431726, 'recall': 0.9090106007067138, 'f1-score': 0.9088446553423056, 'support': 1132}
 
----------
Epoch 16/40
time = 1892.52 secondes

Train loss 0.0890808218406918 accuracy 0.9832056760787964 macro_avg {'precision': 0.982966115242926, 'recall': 0.9831169259960968, 'f1-score': 0.9830298898332723, 'support': 10182} weighted_avg {'precision': 0.9832398604746353, 'recall': 0.9832056570418385, 'f1-score': 0.9832111498760551, 'support': 10182}
 
time = 37.46 secondes

Val loss 0.7146269426453394 accuracy 0.9001767039299011 macro_avg {'precision': 0.9105940809410118, 'recall': 0.9005552462464396, 'f1-score': 0.9013850354370547, 'support': 1132} weighted_avg {'precision': 0.9075274038444444, 'recall': 0.9001766784452296, 'f1-score': 0.8998851064931669, 'support': 1132}
 
----------
Epoch 17/40
time = 1893.46 secondes

Train loss 0.08522490012792346 accuracy 0.9834021329879761 macro_avg {'precision': 0.9833261722207093, 'recall': 0.9830038266398002, 'f1-score': 0.9831337014376832, 'support': 10182} weighted_avg {'precision': 0.9834349080033784, 'recall': 0.9834020821056767, 'f1-score': 0.9833879229764487, 'support': 10182}
 
time = 35.20 secondes

Val loss 0.7706211844100912 accuracy 0.9072438478469849 macro_avg {'precision': 0.9125892118630352, 'recall': 0.905548471557978, 'f1-score': 0.905849540177042, 'support': 1132} weighted_avg {'precision': 0.9119123638642411, 'recall': 0.907243816254417, 'f1-score': 0.9067830748972489, 'support': 1132}
 
----------
Epoch 18/40
time = 1891.89 secondes

Train loss 0.08210866508213273 accuracy 0.9850717186927795 macro_avg {'precision': 0.9841358208472183, 'recall': 0.9849111949648843, 'f1-score': 0.9844724541684841, 'support': 10182} weighted_avg {'precision': 0.9852169211523611, 'recall': 0.985071695148301, 'f1-score': 0.9851048003549255, 'support': 10182}
 
time = 36.99 secondes

Val loss 0.6999712215970568 accuracy 0.9054770469665527 macro_avg {'precision': 0.9126540868491977, 'recall': 0.9033225220689024, 'f1-score': 0.9056685244815063, 'support': 1132} weighted_avg {'precision': 0.9092845568058122, 'recall': 0.9054770318021201, 'f1-score': 0.9051800827972554, 'support': 1132}
 
----------
Epoch 19/40
time = 1885.26 secondes

Train loss 0.05981488490537377 accuracy 0.9881163239479065 macro_avg {'precision': 0.9873503246775712, 'recall': 0.9878124379529588, 'f1-score': 0.9875540562484438, 'support': 10182} weighted_avg {'precision': 0.9881851719180106, 'recall': 0.9881162836377921, 'f1-score': 0.9881282051742933, 'support': 10182}
 
time = 36.86 secondes

Val loss 0.6605240042533719 accuracy 0.9054770469665527 macro_avg {'precision': 0.9084776693496013, 'recall': 0.907667287811287, 'f1-score': 0.9058090238087129, 'support': 1132} weighted_avg {'precision': 0.9117645398886178, 'recall': 0.9054770318021201, 'f1-score': 0.9064787897923077, 'support': 1132}
 
----------
Epoch 20/40
time = 1887.48 secondes

Train loss 0.07516459425222044 accuracy 0.9870359897613525 macro_avg {'precision': 0.9870035726260111, 'recall': 0.987001912953672, 'f1-score': 0.9869653930288502, 'support': 10182} weighted_avg {'precision': 0.9871268485866309, 'recall': 0.9870359457866824, 'f1-score': 0.987044910788908, 'support': 10182}
 
time = 37.87 secondes

Val loss 0.6897117940421645 accuracy 0.9081271886825562 macro_avg {'precision': 0.9147576368411364, 'recall': 0.9097719114474115, 'f1-score': 0.9096453937232127, 'support': 1132} weighted_avg {'precision': 0.9150823141618292, 'recall': 0.9081272084805654, 'f1-score': 0.9091908721100865, 'support': 1132}
 
----------
Epoch 21/40
time = 1891.71 secondes

Train loss 0.05860135490147628 accuracy 0.9890002012252808 macro_avg {'precision': 0.9888613037461118, 'recall': 0.988868088224042, 'f1-score': 0.9888549249762143, 'support': 10182} weighted_avg {'precision': 0.989015413474736, 'recall': 0.9890001964250639, 'f1-score': 0.9889977169777643, 'support': 10182}
 
time = 36.90 secondes

Val loss 0.7045101515540294 accuracy 0.9054770469665527 macro_avg {'precision': 0.9110940192509324, 'recall': 0.906499560075947, 'f1-score': 0.906936935142107, 'support': 1132} weighted_avg {'precision': 0.909644873092169, 'recall': 0.9054770318021201, 'f1-score': 0.9056301190511857, 'support': 1132}
 
----------
Epoch 22/40
time = 1888.03 secondes

Train loss 0.05899249599700155 accuracy 0.9890002012252808 macro_avg {'precision': 0.9891735936618626, 'recall': 0.9890934228957814, 'f1-score': 0.9891244025695218, 'support': 10182} weighted_avg {'precision': 0.9890329524022025, 'recall': 0.9890001964250639, 'f1-score': 0.9890074179724078, 'support': 10182}
 
time = 37.03 secondes

Val loss 0.6619136734774606 accuracy 0.9063604474067688 macro_avg {'precision': 0.9121458848548629, 'recall': 0.9081271801834496, 'f1-score': 0.9078764955361583, 'support': 1132} weighted_avg {'precision': 0.9129166406957194, 'recall': 0.9063604240282686, 'f1-score': 0.9075342950004159, 'support': 1132}
 
----------
Epoch 23/40
time = 1889.09 secondes

Train loss 0.052181956860557745 accuracy 0.9905716180801392 macro_avg {'precision': 0.9901038039193631, 'recall': 0.9900185317473863, 'f1-score': 0.9900410597205955, 'support': 10182} weighted_avg {'precision': 0.9906012638011754, 'recall': 0.990571596935769, 'f1-score': 0.9905661241988541, 'support': 10182}
 
time = 37.07 secondes

Val loss 0.8443118010179884 accuracy 0.8992933034896851 macro_avg {'precision': 0.907893471376901, 'recall': 0.8988789208913479, 'f1-score': 0.8990219882880247, 'support': 1132} weighted_avg {'precision': 0.9050161854206037, 'recall': 0.8992932862190812, 'f1-score': 0.8984638358969425, 'support': 1132}
 
----------
Epoch 24/40
time = 1888.56 secondes

Train loss 0.04842913802482427 accuracy 0.990669846534729 macro_avg {'precision': 0.9905837988940684, 'recall': 0.9902526760644855, 'f1-score': 0.9904015053203075, 'support': 10182} weighted_avg {'precision': 0.9906978333519252, 'recall': 0.9906698094676881, 'f1-score': 0.9906692032106204, 'support': 10182}
 
time = 36.85 secondes

Val loss 0.7467098076766132 accuracy 0.9107773900032043 macro_avg {'precision': 0.9143479235553917, 'recall': 0.9141885796436581, 'f1-score': 0.9124362234743243, 'support': 1132} weighted_avg {'precision': 0.9148286446348076, 'recall': 0.9107773851590106, 'f1-score': 0.9109405214173414, 'support': 1132}
 
----------
Epoch 25/40
time = 1892.92 secondes

Train loss 0.0314380417658015 accuracy 0.993714451789856 macro_avg {'precision': 0.9936992130859295, 'recall': 0.9937041994693813, 'f1-score': 0.9936964092993789, 'support': 10182} weighted_avg {'precision': 0.9937148727043507, 'recall': 0.9937143979571793, 'f1-score': 0.9937094747036366, 'support': 10182}
 
time = 38.19 secondes

Val loss 0.7393070331702507 accuracy 0.9098939895629883 macro_avg {'precision': 0.9160370091587609, 'recall': 0.9123043519969667, 'f1-score': 0.9117856071837286, 'support': 1132} weighted_avg {'precision': 0.9159951254357536, 'recall': 0.9098939929328622, 'f1-score': 0.9104943743547941, 'support': 1132}
 
----------
Epoch 26/40
time = 1894.36 secondes

Train loss 0.04602852650222042 accuracy 0.9923394322395325 macro_avg {'precision': 0.992338972495, 'recall': 0.9921716748949019, 'f1-score': 0.9922513201307908, 'support': 10182} weighted_avg {'precision': 0.9923432800941283, 'recall': 0.9923394225103123, 'f1-score': 0.9923373829116008, 'support': 10182}
 
time = 38.17 secondes

Val loss 0.7412347551640188 accuracy 0.9107773900032043 macro_avg {'precision': 0.9143493043812182, 'recall': 0.9148926768750603, 'f1-score': 0.9125713697578837, 'support': 1132} weighted_avg {'precision': 0.9147060087652226, 'recall': 0.9107773851590106, 'f1-score': 0.9104919866118303, 'support': 1132}
 
----------
Epoch 27/40
time = 1896.14 secondes

Train loss 0.03880460114936113 accuracy 0.9931251406669617 macro_avg {'precision': 0.9928516802487085, 'recall': 0.9924626998640391, 'f1-score': 0.9926401043199258, 'support': 10182} weighted_avg {'precision': 0.9931316755933106, 'recall': 0.9931251227656649, 'f1-score': 0.9931141033740796, 'support': 10182}
 
time = 39.26 secondes

Val loss 0.8498436335772874 accuracy 0.8992933034896851 macro_avg {'precision': 0.9153404812572117, 'recall': 0.906602878783961, 'f1-score': 0.9049882555599431, 'support': 1132} weighted_avg {'precision': 0.9197376624687745, 'recall': 0.8992932862190812, 'f1-score': 0.903603901556028, 'support': 1132}
 
----------
Epoch 28/40
time = 1896.77 secondes

Train loss 0.037983562995066666 accuracy 0.9930269122123718 macro_avg {'precision': 0.9929066377654607, 'recall': 0.9928331759347756, 'f1-score': 0.9928580838184603, 'support': 10182} weighted_avg {'precision': 0.9930343335623991, 'recall': 0.9930269102337458, 'f1-score': 0.9930186191683215, 'support': 10182}
 
time = 39.28 secondes

Val loss 0.7993092061733478 accuracy 0.9054770469665527 macro_avg {'precision': 0.9088007506595789, 'recall': 0.9086163109443659, 'f1-score': 0.9057560055470686, 'support': 1132} weighted_avg {'precision': 0.9124742707276141, 'recall': 0.9054770318021201, 'f1-score': 0.9061647958312401, 'support': 1132}
 
----------
Epoch 29/40
time = 1899.23 secondes

Train loss 0.036427918797066874 accuracy 0.9940090775489807 macro_avg {'precision': 0.994117519513788, 'recall': 0.9940884736457974, 'f1-score': 0.9940864739827783, 'support': 10182} weighted_avg {'precision': 0.9940346586939687, 'recall': 0.9940090355529365, 'f1-score': 0.9940051859678917, 'support': 10182}
 
time = 39.38 secondes

Val loss 0.8075757512149363 accuracy 0.9054770469665527 macro_avg {'precision': 0.9096784972631802, 'recall': 0.9082589104390355, 'f1-score': 0.907432420842075, 'support': 1132} weighted_avg {'precision': 0.9093573085333362, 'recall': 0.9054770318021201, 'f1-score': 0.905828893200855, 'support': 1132}
 
----------
Epoch 30/40
time = 1896.04 secondes

Train loss 0.03302365173556815 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934586764729321, 'recall': 0.993520627649613, 'f1-score': 0.9934809085241556, 'support': 10182} weighted_avg {'precision': 0.9935311265729171, 'recall': 0.9935179728933412, 'f1-score': 0.9935156238069055, 'support': 10182}
 
time = 39.35 secondes

Val loss 0.7279069835604902 accuracy 0.9178445339202881 macro_avg {'precision': 0.9228601195499581, 'recall': 0.9192478654923338, 'f1-score': 0.9197096212652376, 'support': 1132} weighted_avg {'precision': 0.9212031310720975, 'recall': 0.9178445229681979, 'f1-score': 0.9180920326761925, 'support': 1132}
 
----------
Epoch 31/40
time = 1898.84 secondes

Train loss 0.0379670704186676 accuracy 0.9942054748535156 macro_avg {'precision': 0.994204573186936, 'recall': 0.994224352000716, 'f1-score': 0.9942079346429169, 'support': 10182} weighted_avg {'precision': 0.9942237415987186, 'recall': 0.9942054606167747, 'f1-score': 0.9942078568424719, 'support': 10182}
 
time = 37.78 secondes

Val loss 0.8047025903882533 accuracy 0.9143109321594238 macro_avg {'precision': 0.916022742746272, 'recall': 0.9172768899412034, 'f1-score': 0.915228183794583, 'support': 1132} weighted_avg {'precision': 0.9177920215153739, 'recall': 0.9143109540636042, 'f1-score': 0.9145252354822957, 'support': 1132}
 
----------
Epoch 32/40
time = 1896.03 secondes

Train loss 0.026658928540785966 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960497525877052, 'recall': 0.9960296876629539, 'f1-score': 0.9960342568042473, 'support': 10182} weighted_avg {'precision': 0.9961790377496872, 'recall': 0.9961697112551562, 'f1-score': 0.9961688705738228, 'support': 10182}
 
time = 39.16 secondes

Val loss 0.8382545992615018 accuracy 0.9098939895629883 macro_avg {'precision': 0.9148331152420189, 'recall': 0.9137872884030322, 'f1-score': 0.9130306274684683, 'support': 1132} weighted_avg {'precision': 0.9147457051718482, 'recall': 0.9098939929328622, 'f1-score': 0.910997022180132, 'support': 1132}
 
----------
Epoch 33/40
time = 1897.99 secondes

Train loss 0.027941205632465837 accuracy 0.9954822659492493 macro_avg {'precision': 0.9953841213176092, 'recall': 0.9953983972289491, 'f1-score': 0.9953887369524252, 'support': 10182} weighted_avg {'precision': 0.9954879665940226, 'recall': 0.9954822235317227, 'f1-score': 0.9954826471563749, 'support': 10182}
 
time = 39.39 secondes

Val loss 0.837613183257648 accuracy 0.9063604474067688 macro_avg {'precision': 0.9109861024857361, 'recall': 0.906224823299218, 'f1-score': 0.9064702800971298, 'support': 1132} weighted_avg {'precision': 0.9121562471363233, 'recall': 0.9063604240282686, 'f1-score': 0.907026679037465, 'support': 1132}
 
----------
Epoch 34/40
time = 1895.63 secondes

Train loss 0.02036935283885238 accuracy 0.9965626001358032 macro_avg {'precision': 0.996341191572137, 'recall': 0.9963838256482902, 'f1-score': 0.996357402806711, 'support': 10182} weighted_avg {'precision': 0.9965718061793744, 'recall': 0.9965625613828325, 'f1-score': 0.9965624380090038, 'support': 10182}
 
time = 39.79 secondes

Val loss 0.7792046884025925 accuracy 0.9125441908836365 macro_avg {'precision': 0.913923172840766, 'recall': 0.9137809931133161, 'f1-score': 0.912565803428933, 'support': 1132} weighted_avg {'precision': 0.9159709339062734, 'recall': 0.9125441696113075, 'f1-score': 0.912893945096584, 'support': 1132}
 
----------
Epoch 35/40
time = 1897.53 secondes

Train loss 0.016678169094501892 accuracy 0.9969554543495178 macro_avg {'precision': 0.9970263466251778, 'recall': 0.9970010314557701, 'f1-score': 0.9970085171409755, 'support': 10182} weighted_avg {'precision': 0.9969657866330691, 'recall': 0.9969554115105087, 'f1-score': 0.9969554389854544, 'support': 10182}
 
time = 39.50 secondes

Val loss 0.7884505740749377 accuracy 0.9187279343605042 macro_avg {'precision': 0.9198496844480684, 'recall': 0.9198881021491573, 'f1-score': 0.9187306445075307, 'support': 1132} weighted_avg {'precision': 0.9215264300754216, 'recall': 0.9187279151943463, 'f1-score': 0.9189705599184625, 'support': 1132}
 
----------
Epoch 36/40
time = 1896.70 secondes

Train loss 0.012155064381373475 accuracy 0.9978393316268921 macro_avg {'precision': 0.99778627753058, 'recall': 0.9977761196257703, 'f1-score': 0.997779779769932, 'support': 10182} weighted_avg {'precision': 0.997839894092531, 'recall': 0.9978393242977804, 'f1-score': 0.9978382889128018, 'support': 10182}
 
time = 39.51 secondes

Val loss 0.7878309154125098 accuracy 0.9143109321594238 macro_avg {'precision': 0.9174572892507202, 'recall': 0.9169320416618648, 'f1-score': 0.9159423653485547, 'support': 1132} weighted_avg {'precision': 0.9176687002041316, 'recall': 0.9143109540636042, 'f1-score': 0.9146362747169797, 'support': 1132}
 
----------
Epoch 37/40
time = 1958.52 secondes

Train loss 0.011358045936432524 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975929897932818, 'recall': 0.9975899591742499, 'f1-score': 0.9975848097466458, 'support': 10182} weighted_avg {'precision': 0.9975551253299948, 'recall': 0.9975446867020232, 'f1-score': 0.9975431210399631, 'support': 10182}
 
time = 42.75 secondes

Val loss 0.7754268053324498 accuracy 0.9151943325996399 macro_avg {'precision': 0.9177039792758845, 'recall': 0.9171882592859488, 'f1-score': 0.9159358150580699, 'support': 1132} weighted_avg {'precision': 0.9182160299537959, 'recall': 0.9151943462897526, 'f1-score': 0.9150808358313979, 'support': 1132}
 
----------
Epoch 38/40
time = 1977.35 secondes

Train loss 0.01081580017885394 accuracy 0.997741162776947 macro_avg {'precision': 0.9977659557412561, 'recall': 0.997716063684156, 'f1-score': 0.9977366831491631, 'support': 10182} weighted_avg {'precision': 0.9977498138058949, 'recall': 0.9977411117658613, 'f1-score': 0.9977410619745964, 'support': 10182}
 
time = 39.13 secondes

Val loss 0.7973231797665942 accuracy 0.9125441908836365 macro_avg {'precision': 0.9146403165461763, 'recall': 0.914766691929454, 'f1-score': 0.9132729976174956, 'support': 1132} weighted_avg {'precision': 0.9152044468294539, 'recall': 0.9125441696113075, 'f1-score': 0.9123966814769371, 'support': 1132}
 
----------
Epoch 39/40
time = 1967.02 secondes

Train loss 0.005048066405527134 accuracy 0.9987232685089111 macro_avg {'precision': 0.9987229276762534, 'recall': 0.998668768510069, 'f1-score': 0.9986953247644241, 'support': 10182} weighted_avg {'precision': 0.9987237004613971, 'recall': 0.9987232370850521, 'f1-score': 0.9987229726640062, 'support': 10182}
 
time = 40.13 secondes

Val loss 0.7686420200792731 accuracy 0.9143109321594238 macro_avg {'precision': 0.9168860426044084, 'recall': 0.9168717037766301, 'f1-score': 0.9154590408107062, 'support': 1132} weighted_avg {'precision': 0.9175232364197115, 'recall': 0.9143109540636042, 'f1-score': 0.9144523646336441, 'support': 1132}
 
----------
Epoch 40/40
time = 1968.11 secondes

Train loss 0.0064128111811030866 accuracy 0.998821496963501 macro_avg {'precision': 0.9988211058128117, 'recall': 0.9988309666095649, 'f1-score': 0.9988246660010006, 'support': 10182} weighted_avg {'precision': 0.9988235552241777, 'recall': 0.9988214496169712, 'f1-score': 0.9988211516789484, 'support': 10182}
 
time = 40.11 secondes

Val loss 0.7454317777780783 accuracy 0.9151943325996399 macro_avg {'precision': 0.9174995213739274, 'recall': 0.9172220983344316, 'f1-score': 0.9161787740699386, 'support': 1132} weighted_avg {'precision': 0.9179384605408324, 'recall': 0.9151943462897526, 'f1-score': 0.91533564643242, 'support': 1132}
 
----------
best_accuracy 0.9187279343605042 best_epoch 35 macro_avg {'precision': 0.9198496844480684, 'recall': 0.9198881021491573, 'f1-score': 0.9187306445075307, 'support': 1132} weighted_avg {'precision': 0.9215264300754216, 'recall': 0.9187279151943463, 'f1-score': 0.9189705599184625, 'support': 1132}

average train time 1899.6733523130417

average val time 37.992555898427966
 
time = 260.16 secondes

test_accuracy 0.8514338731765747 macro_avg {'precision': 0.8494272407700763, 'recall': 0.8445929349157565, 'f1-score': 0.8452832953325469, 'support': 7532} weighted_avg {'precision': 0.8562430025155733, 'recall': 0.8514338821030271, 'f1-score': 0.8521905456042668, 'support': 7532}

----------

Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.46 GiB (GPU 0; 79.21 GiB total capacity; 60.37 GiB already allocated; 1.12 GiB free; 62.35 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 60.11 GiB already allocated; 194.62 MiB free; 63.28 GiB reserved in total by PyTorch)

