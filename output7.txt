[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/lib64/python3.6/site-packages/h5py/__init__.py:39: UserWarning: h5py is running against HDF5 1.10.8 when it was built against 1.10.7, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_4
----------
Epoch 1/40
time = 68.12 secondes

Train loss 0.6153191075180516 accuracy 0.6647287011146545 macro_avg {'precision': 0.6513594164456233, 'recall': 0.5593599141784373, 'f1-score': 0.5289958686625125, 'support': 516} weighted_avg {'precision': 0.655967270166348, 'recall': 0.6647286821705426, 'f1-score': 0.5985773109662681, 'support': 516}
 
time = 1.37 secondes

Val loss 0.5174446180462837 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 2/40
time = 55.32 secondes

Train loss 0.41157210821455176 accuracy 0.819767415523529 macro_avg {'precision': 0.8057675857077055, 'recall': 0.8021146563073972, 'f1-score': 0.8038479932310635, 'support': 516} weighted_avg {'precision': 0.8188463986925204, 'recall': 0.8197674418604651, 'f1-score': 0.8192259640159276, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4606687054038048 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 3/40
time = 57.27 secondes

Train loss 0.2572311648365223 accuracy 0.9011628031730652 macro_avg {'precision': 0.8927413077322263, 'recall': 0.8936414024023536, 'f1-score': 0.8931872146118721, 'support': 516} weighted_avg {'precision': 0.9012830975971807, 'recall': 0.9011627906976745, 'f1-score': 0.9012193550670773, 'support': 516}
 
time = 1.44 secondes

Val loss 0.49736127257347107 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 4/40
time = 56.23 secondes

Train loss 0.19871302677149122 accuracy 0.9282945990562439 macro_avg {'precision': 0.9289675337769712, 'recall': 0.9149179981470345, 'f1-score': 0.9211826727380064, 'support': 516} weighted_avg {'precision': 0.9283987222355093, 'recall': 0.9282945736434108, 'f1-score': 0.9276980916319898, 'support': 516}
 
time = 1.53 secondes

Val loss 0.48872246593236923 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 58.11 secondes

Train loss 0.1334665554265181 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.50 secondes

Val loss 0.7548781484365463 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 6/40
time = 57.61 secondes

Train loss 0.23320880540731279 accuracy 0.9205426573753357 macro_avg {'precision': 0.9241584564860428, 'recall': 0.903068771028721, 'f1-score': 0.9119728712006159, 'support': 516} weighted_avg {'precision': 0.9213059756113086, 'recall': 0.9205426356589147, 'f1-score': 0.9195312969961341, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5518350973725319 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 57.96 secondes

Train loss 0.2628673800394278 accuracy 0.9282945990562439 macro_avg {'precision': 0.9189536878216124, 'recall': 0.9287664775774913, 'f1-score': 0.9233545434472792, 'support': 516} weighted_avg {'precision': 0.9300070693774072, 'recall': 0.9282945736434108, 'f1-score': 0.9287093853392693, 'support': 516}
 
time = 1.53 secondes

Val loss 1.1816385835409164 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 8/40
time = 58.93 secondes

Train loss 0.2524587168485265 accuracy 0.9341084957122803 macro_avg {'precision': 0.9348470883954755, 'recall': 0.9217853485688279, 'f1-score': 0.9276655397047908, 'support': 516} weighted_avg {'precision': 0.9342153070735217, 'recall': 0.9341085271317829, 'f1-score': 0.9336064761634458, 'support': 516}
 
time = 1.59 secondes

Val loss 1.4966325610876083 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 57.95 secondes

Train loss 0.11853025468404997 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.48 secondes

Val loss 0.8987989872694016 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.07 secondes

Train loss 0.1455599951141542 accuracy 0.961240291595459 macro_avg {'precision': 0.9529495380241649, 'recall': 0.9661427433642703, 'f1-score': 0.9586988538131523, 'support': 516} weighted_avg {'precision': 0.9632766400555363, 'recall': 0.9612403100775194, 'f1-score': 0.9615182818564345, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8139927685260773 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 57.52 secondes

Train loss 0.16063062787394633 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.56 secondes

Val loss 0.94292351603508 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 12/40
time = 57.96 secondes

Train loss 0.07956342408821608 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9539240002632141 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 13/40
time = 58.60 secondes

Train loss 0.14827841556997914 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.42 secondes

Val loss 1.1003360152244568 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 59.25 secondes

Train loss 0.5446962917816233 accuracy 0.9069767594337463 macro_avg {'precision': 0.920650353805434, 'recall': 0.8797360336784616, 'f1-score': 0.8947296837810269, 'support': 516} weighted_avg {'precision': 0.9114043892056577, 'recall': 0.9069767441860465, 'f1-score': 0.9046108347896223, 'support': 516}
 
time = 1.57 secondes

Val loss 1.6026472672820091 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 15/40
time = 57.45 secondes

Train loss 0.434218908577212 accuracy 0.9108527302742004 macro_avg {'precision': 0.9028687927770497, 'recall': 0.9047023064544967, 'f1-score': 0.9037688116242866, 'support': 516} weighted_avg {'precision': 0.9110841311609394, 'recall': 0.9108527131782945, 'f1-score': 0.9109539117719233, 'support': 516}
 
time = 1.51 secondes

Val loss 0.885037012398243 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 16/40
time = 58.15 secondes

Train loss 0.17614273403799444 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1502974927425385 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 58.25 secondes

Train loss 0.11607593716877146 accuracy 0.9767441749572754 macro_avg {'precision': 0.9770590262393541, 'recall': 0.9725305983128261, 'f1-score': 0.9747203396750224, 'support': 516} weighted_avg {'precision': 0.9767609775234631, 'recall': 0.9767441860465116, 'f1-score': 0.9766887382007174, 'support': 516}
 
time = 1.43 secondes

Val loss 1.78080315887928 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 58.10 secondes

Train loss 0.1036966544819403 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 1.48 secondes

Val loss 1.043642833828926 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 19/40
time = 59.61 secondes

Train loss 0.04387720590845371 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.46 secondes

Val loss 1.057699915021658 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 20/40
time = 58.65 secondes

Train loss 0.037541744390954125 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0658883154392242 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 21/40
time = 57.82 secondes

Train loss 0.022469222611768848 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.49 secondes

Val loss 1.4138997495174408 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 22/40
time = 58.14 secondes

Train loss 0.1305960425368429 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.45 secondes

Val loss 1.0970347225666046 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 23/40
time = 58.16 secondes

Train loss 0.13053028398964228 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.43 secondes

Val loss 1.3298837095499039 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 24/40
time = 58.85 secondes

Train loss 0.054781283178299695 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4081860333681107 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 25/40
time = 58.53 secondes

Train loss 0.05968497074685398 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.52 secondes

Val loss 1.5865978300571442 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 57.49 secondes

Train loss 0.025103735711044548 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.45 secondes

Val loss 1.4306539446115494 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 27/40
time = 57.73 secondes

Train loss 0.16369178507364157 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 1.50 secondes

Val loss 1.851192146539688 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 59.18 secondes

Train loss 0.005236345648881979 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5091046690940857 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 29/40
time = 58.40 secondes

Train loss 0.1426365165534662 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 1.49 secondes

Val loss 2.00705686211586 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 58.43 secondes

Train loss 0.0003581510629208589 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.907425582408905 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 31/40
time = 58.29 secondes

Train loss 0.13050016070580264 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 1.52 secondes

Val loss 1.369198501110077 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 32/40
time = 57.92 secondes

Train loss 0.02882400349754431 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.55 secondes

Val loss 1.362718105316162 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 33/40
time = 57.82 secondes

Train loss 0.05366902462485472 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.43 secondes

Val loss 1.574650526046753 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 58.83 secondes

Train loss 0.11593728005810232 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2834101170301437 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 35/40
time = 58.55 secondes

Train loss 0.0005483728027408661 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.46 secondes

Val loss 1.4318679571151733 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 57.69 secondes

Train loss 0.014917325891226275 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.55 secondes

Val loss 1.4637317061424255 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 58.11 secondes

Train loss 0.00034030022321861577 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.44 secondes

Val loss 1.5544102787971497 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 38/40
time = 59.14 secondes

Train loss 0.012974465915414674 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.56 secondes

Val loss 1.5192304253578186 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 39/40
time = 56.62 secondes

Train loss 0.0002518649698961808 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.72 secondes

Val loss 1.492131769657135 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 54.25 secondes

Train loss 0.0002192168105852254 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4562963843345642 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 4 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}

average train time 58.2268084526062

average val time 1.498611730337143
 
time = 1.60 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9187370600414079, 'recall': 0.8942495126705653, 'f1-score': 0.9025000000000001, 'support': 65} weighted_avg {'precision': 0.9123427297340341, 'recall': 0.9076923076923077, 'f1-score': 0.9063076923076923, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 39.31 GiB already allocated; 38.62 MiB free; 39.45 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 38.57 GiB already allocated; 76.62 MiB free; 39.42 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.24 GiB already allocated; 504.62 MiB free; 39.00 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 36.10 GiB already allocated; 626.62 MiB free; 38.88 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.48 GiB already allocated; 590.62 MiB free; 38.91 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_4
----------
Epoch 1/40
time = 42.50 secondes

Train loss 0.6502475828835459 accuracy 0.6182170510292053 macro_avg {'precision': 0.5408768497003791, 'recall': 0.5217317100921607, 'f1-score': 0.49484920315458353, 'support': 516} weighted_avg {'precision': 0.5707200808090002, 'recall': 0.6182170542635659, 'f1-score': 0.5635481633799777, 'support': 516}
 
time = 2.37 secondes

Val loss 0.6215917989611626 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 37.77 secondes

Train loss 0.509406199057897 accuracy 0.7655038833618164 macro_avg {'precision': 0.7535542391706775, 'recall': 0.7226321863368171, 'f1-score': 0.7317661008648133, 'support': 516} weighted_avg {'precision': 0.7611294553553235, 'recall': 0.7655038759689923, 'f1-score': 0.7579451394702418, 'support': 516}
 
time = 1.99 secondes

Val loss 0.44741108268499374 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 3/40
time = 39.79 secondes

Train loss 0.42789786783131684 accuracy 0.8081395030021667 macro_avg {'precision': 0.7919287211740043, 'recall': 0.7987663150366529, 'f1-score': 0.7949216162508279, 'support': 516} weighted_avg {'precision': 0.811111517397169, 'recall': 0.8081395348837209, 'f1-score': 0.809249436448315, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7124811410903931 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 4/40
time = 40.92 secondes

Train loss 0.3097408725456758 accuracy 0.8759689927101135 macro_avg {'precision': 0.8676506967922817, 'recall': 0.8623441639711977, 'f1-score': 0.8648507071765322, 'support': 516} weighted_avg {'precision': 0.8753208133813778, 'recall': 0.875968992248062, 'f1-score': 0.8755182509613785, 'support': 516}
 
time = 2.12 secondes

Val loss 0.6435048878192902 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 38.93 secondes

Train loss 0.2929804043167017 accuracy 0.8992248177528381 macro_avg {'precision': 0.8992718653547738, 'recall': 0.8805812460380671, 'f1-score': 0.888504753673293, 'support': 516} weighted_avg {'precision': 0.8992343237831012, 'recall': 0.8992248062015504, 'f1-score': 0.8980188002921213, 'support': 516}
 
time = 2.05 secondes

Val loss 0.47357431799173355 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 6/40
time = 39.33 secondes

Train loss 0.25419013525331113 accuracy 0.9205426573753357 macro_avg {'precision': 0.9117468143689569, 'recall': 0.9180712904117159, 'f1-score': 0.9147042103608016, 'support': 516} weighted_avg {'precision': 0.9215046786125038, 'recall': 0.9205426356589147, 'f1-score': 0.9208453688225204, 'support': 516}
 
time = 1.87 secondes

Val loss 0.6549891345202923 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 7/40
time = 40.48 secondes

Train loss 0.1737329674052131 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 1.93 secondes

Val loss 0.41872819140553474 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 39.11 secondes

Train loss 0.16758951770536828 accuracy 0.9496123790740967 macro_avg {'precision': 0.9430693466369368, 'recall': 0.9489459226630691, 'f1-score': 0.9458508233774621, 'support': 516} weighted_avg {'precision': 0.950216377543591, 'recall': 0.9496124031007752, 'f1-score': 0.9497783551473921, 'support': 516}
 
time = 1.53 secondes

Val loss 1.8777442574501038 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 9/40
time = 38.00 secondes

Train loss 0.2548922983661407 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.88 secondes

Val loss 0.842892125248909 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 10/40
time = 43.55 secondes

Train loss 0.1294738863608941 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 1.67 secondes

Val loss 1.2877298295497894 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 11/40
time = 38.03 secondes

Train loss 0.37414150096998183 accuracy 0.9341084957122803 macro_avg {'precision': 0.9510678223572513, 'recall': 0.9102449490434472, 'f1-score': 0.9256547165013984, 'support': 516} weighted_avg {'precision': 0.9393774343862973, 'recall': 0.9341085271317829, 'f1-score': 0.9325538033376891, 'support': 516}
 
time = 1.91 secondes

Val loss 1.1649150848388672 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 12/40
time = 40.47 secondes

Train loss 0.14792993520280684 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.65 secondes

Val loss 1.3746942579746246 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 13/40
time = 39.73 secondes

Train loss 0.19222142119454502 accuracy 0.9496123790740967 macro_avg {'precision': 0.9580666746735755, 'recall': 0.9339434032800741, 'f1-score': 0.9441027948602569, 'support': 516} weighted_avg {'precision': 0.9514704847651269, 'recall': 0.9496124031007752, 'f1-score': 0.948932204552563, 'support': 516}
 
time = 2.05 secondes

Val loss 2.012902110815048 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 14/40
time = 39.40 secondes

Train loss 0.12621477409310033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9797821938540501, 'recall': 0.9740503551517319, 'f1-score': 0.9767992250058248, 'support': 516} weighted_avg {'precision': 0.9787545404973339, 'recall': 0.9786821705426356, 'f1-score': 0.9786181247760776, 'support': 516}
 
time = 1.95 secondes

Val loss 1.8121185898780823 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 15/40
time = 39.27 secondes

Train loss 0.22127158074352227 accuracy 0.9573643207550049 macro_avg {'precision': 0.9622002393029879, 'recall': 0.9457926303983876, 'f1-score': 0.9530753968253968, 'support': 516} weighted_avg {'precision': 0.9581608419681893, 'recall': 0.9573643410852714, 'f1-score': 0.9569794358311798, 'support': 516}
 
time = 1.82 secondes

Val loss 2.10396209359169 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 16/40
time = 40.10 secondes

Train loss 0.18444505678516263 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.62 secondes

Val loss 1.3474785685539246 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 17/40
time = 41.29 secondes

Train loss 0.06399768915037964 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.97 secondes

Val loss 0.9417189881205559 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 18/40
time = 39.05 secondes

Train loss 0.4419193771336171 accuracy 0.9186046719551086 macro_avg {'precision': 0.9105598066854612, 'recall': 0.914243453667734, 'f1-score': 0.9123343527013252, 'support': 516} weighted_avg {'precision': 0.9190849403853179, 'recall': 0.9186046511627907, 'f1-score': 0.9187863989442825, 'support': 516}
 
time = 1.47 secondes

Val loss 0.8806437849998474 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 19/40
time = 39.49 secondes

Train loss 0.16448156353947002 accuracy 0.961240291595459 macro_avg {'precision': 0.9612599983507875, 'recall': 0.9546023438388895, 'f1-score': 0.9577658459926663, 'support': 516} weighted_avg {'precision': 0.9612418442286832, 'recall': 0.9612403100775194, 'f1-score': 0.9610994534254307, 'support': 516}
 
time = 2.17 secondes

Val loss 0.8274401426315308 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 20/40
time = 39.11 secondes

Train loss 0.12876486600990492 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.93 secondes

Val loss 0.8372616544365883 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 21/40
time = 38.67 secondes

Train loss 0.08721147193996744 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 1.82 secondes

Val loss 1.062270313501358 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 22/40
time = 38.95 secondes

Train loss 0.058648511774442864 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.66 secondes

Val loss 1.291184887290001 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 23/40
time = 39.03 secondes

Train loss 0.0452318968741703 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 2.23 secondes

Val loss 1.9735469222068787 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 24/40
time = 40.91 secondes

Train loss 0.34293285790111194 accuracy 0.9418604373931885 macro_avg {'precision': 0.9311009245590863, 'recall': 0.9509451749752125, 'f1-score': 0.9386522517952539, 'support': 516} weighted_avg {'precision': 0.9473546985922924, 'recall': 0.9418604651162791, 'f1-score': 0.9425129830798774, 'support': 516}
 
time = 1.43 secondes

Val loss 1.6655630320310593 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 25/40
time = 41.02 secondes

Train loss 0.09535022647469305 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.75 secondes

Val loss 1.0390583989210427 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 26/40
time = 40.02 secondes

Train loss 0.13972099651062198 accuracy 0.9786821603775024 macro_avg {'precision': 0.9774682306940372, 'recall': 0.976358435056808, 'f1-score': 0.9769087129333176, 'support': 516} weighted_avg {'precision': 0.9786653102669607, 'recall': 0.9786821705426356, 'f1-score': 0.978669768741172, 'support': 516}
 
time = 1.30 secondes

Val loss 1.4147384315729141 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 27/40
time = 38.41 secondes

Train loss 0.058669980899360256 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.09 secondes

Val loss 0.903839536011219 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 28/40
time = 38.97 secondes

Train loss 0.06214826349451235 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.80 secondes

Val loss 0.728185917250812 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 29/40
time = 38.54 secondes

Train loss 0.010623939959755675 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6172033548355103 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 38.79 secondes

Train loss 0.07192157786586463 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.82 secondes

Val loss 1.2587793618440628 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 31/40
time = 36.69 secondes

Train loss 0.012085543607650889 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.34 secondes

Val loss 1.4146884232759476 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 32/40
time = 36.32 secondes

Train loss 0.017149427898843758 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5102647494059056 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 34.84 secondes

Train loss 0.09528234315075679 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.33 secondes

Val loss 1.3578190803527832 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 34/40
time = 36.44 secondes

Train loss 0.002466697441625663 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.66 secondes

Val loss 1.0218378957360983 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 36.86 secondes

Train loss 0.0346477697074244 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.75 secondes

Val loss 1.3860953450202942 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 36/40
time = 35.81 secondes

Train loss 0.07223866712637105 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.64 secondes

Val loss 1.2280682548880577 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 36.47 secondes

Train loss 0.021948573842096128 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.90 secondes

Val loss 1.1350205773487687 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 38/40
time = 36.94 secondes

Train loss 0.012120993220543658 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3076321929693222 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 39/40
time = 36.49 secondes

Train loss 0.009670125583149704 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.66 secondes

Val loss 1.4507780820131302 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 36.42 secondes

Train loss 0.00014191514073348972 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4333347380161285 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 17 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 38.82262225151062

average val time 1.7757685899734497
 
time = 1.87 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9032567049808429, 'recall': 0.9103313840155945, 'f1-score': 0.9058880308880309, 'support': 65} weighted_avg {'precision': 0.9102269378131447, 'recall': 0.9076923076923077, 'f1-score': 0.9080932580932581, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_4
----------
Epoch 1/40
time = 54.61 secondes

Train loss 0.6052206285072096 accuracy 0.6220930218696594 macro_avg {'precision': 0.5354737854737854, 'recall': 0.5143848641971295, 'f1-score': 0.47217399058914866, 'support': 516} weighted_avg {'precision': 0.5656206770547857, 'recall': 0.622093023255814, 'f1-score': 0.5495867274570267, 'support': 516}
 
time = 2.24 secondes

Val loss 0.665861502289772 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 53.84 secondes

Train loss 0.3566817093753453 accuracy 0.8507751822471619 macro_avg {'precision': 0.8415441176470588, 'recall': 0.8322009654925799, 'f1-score': 0.8363908139692894, 'support': 516} weighted_avg {'precision': 0.8495368787049704, 'recall': 0.8507751937984496, 'f1-score': 0.8497410226996212, 'support': 516}
 
time = 2.00 secondes

Val loss 0.44534941762685776 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 3/40
time = 52.19 secondes

Train loss 0.24334063615198387 accuracy 0.9147287011146545 macro_avg {'precision': 0.912154392280386, 'recall': 0.9019716203696179, 'f1-score': 0.9066263078239126, 'support': 516} weighted_avg {'precision': 0.9144108686038567, 'recall': 0.9147286821705426, 'f1-score': 0.9141956312266853, 'support': 516}
 
time = 2.06 secondes

Val loss 0.5378583557903767 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 4/40
time = 51.95 secondes

Train loss 0.1814212049922031 accuracy 0.9515503644943237 macro_avg {'precision': 0.9500723827071132, 'recall': 0.9446954797392846, 'f1-score': 0.947270965922329, 'support': 516} weighted_avg {'precision': 0.9514531504330975, 'recall': 0.9515503875968992, 'f1-score': 0.9514048290365398, 'support': 516}
 
time = 1.95 secondes

Val loss 0.8098108023405075 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 5/40
time = 51.21 secondes

Train loss 0.10685272798450156 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0759399235248566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 6/40
time = 63.39 secondes

Train loss 0.19757196083876558 accuracy 0.9437984228134155 macro_avg {'precision': 0.9348417721518987, 'recall': 0.946694732051428, 'f1-score': 0.9400516795865634, 'support': 516} weighted_avg {'precision': 0.9458059807673437, 'recall': 0.9437984496124031, 'f1-score': 0.9441760310878754, 'support': 516}
 
time = 2.20 secondes

Val loss 1.289656475186348 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 7/40
time = 61.12 secondes

Train loss 0.2610441936306994 accuracy 0.9341084957122803 macro_avg {'precision': 0.931475220582172, 'recall': 0.9252474684264422, 'f1-score': 0.9282019381875328, 'support': 516} weighted_avg {'precision': 0.9339033344136316, 'recall': 0.9341085271317829, 'f1-score': 0.9338690708232323, 'support': 516}
 
time = 2.50 secondes

Val loss 1.5010225176811218 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 8/40
time = 61.58 secondes

Train loss 0.24086559725180973 accuracy 0.9437984228134155 macro_avg {'precision': 0.9379560865353568, 'recall': 0.9409245322887376, 'f1-score': 0.9394010569583089, 'support': 516} weighted_avg {'precision': 0.9440562009246258, 'recall': 0.9437984496124031, 'f1-score': 0.9438933573675274, 'support': 516}
 
time = 2.37 secondes

Val loss 1.2972755208611488 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 9/40
time = 62.57 secondes

Train loss 0.17100825949896578 accuracy 0.9554263353347778 macro_avg {'precision': 0.9513168137000518, 'recall': 0.9523511532272484, 'f1-score': 0.9518295281582952, 'support': 516} weighted_avg {'precision': 0.9554850643447058, 'recall': 0.9554263565891473, 'f1-score': 0.9554518660106426, 'support': 516}
 
time = 2.40 secondes

Val loss 1.391263633966446 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 10/40
time = 61.73 secondes

Train loss 0.10851525875940835 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 2.51 secondes

Val loss 1.0451386719942093 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 11/40
time = 62.26 secondes

Train loss 0.08287082006272888 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.48 secondes

Val loss 1.8729027807712555 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 12/40
time = 60.71 secondes

Train loss 0.09569069002949011 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5543503165245056 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 13/40
time = 61.53 secondes

Train loss 0.1608647581667879 accuracy 0.9573643207550049 macro_avg {'precision': 0.9652643964326518, 'recall': 0.9434845504933115, 'f1-score': 0.9528289342463933, 'support': 516} weighted_avg {'precision': 0.9589621050881123, 'recall': 0.9573643410852714, 'f1-score': 0.9568541078158976, 'support': 516}
 
time = 2.26 secondes

Val loss 2.117667078971863 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 14/40
time = 62.03 secondes

Train loss 0.9873484827412264 accuracy 0.8449612259864807 macro_avg {'precision': 0.8341594416723306, 'recall': 0.8276416949758627, 'f1-score': 0.830650322453601, 'support': 516} weighted_avg {'precision': 0.8438673872834702, 'recall': 0.8449612403100775, 'f1-score': 0.8441979913577321, 'support': 516}
 
time = 2.38 secondes

Val loss 1.617888018488884 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 62.55 secondes

Train loss 0.2168506928402084 accuracy 0.9573643207550049 macro_avg {'precision': 0.9499864742294288, 'recall': 0.9596411098288444, 'f1-score': 0.9543788580246912, 'support': 516} weighted_avg {'precision': 0.9585738274550816, 'recall': 0.9573643410852714, 'f1-score': 0.957590514044406, 'support': 516}
 
time = 2.47 secondes

Val loss 1.4157423079013824 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 62.15 secondes

Train loss 0.3946956769972475 accuracy 0.9244186282157898 macro_avg {'precision': 0.9194604504976427, 'recall': 0.9164946442793752, 'f1-score': 0.9179385966700785, 'support': 516} weighted_avg {'precision': 0.9242175984016957, 'recall': 0.9244186046511628, 'f1-score': 0.9242845355205198, 'support': 516}
 
time = 2.35 secondes

Val loss 1.1583004891872406 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 17/40
time = 61.35 secondes

Train loss 0.0524032155808527 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.59 secondes

Val loss 1.6846273094415665 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 61.86 secondes

Train loss 0.34373950946434034 accuracy 0.9263566136360168 macro_avg {'precision': 0.9220203810367744, 'recall': 0.9180144011182809, 'f1-score': 0.9199477423042377, 'support': 516} weighted_avg {'precision': 0.926125324714726, 'recall': 0.9263565891472868, 'f1-score': 0.9261810043022717, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6776372492313385 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 19/40
time = 61.59 secondes

Train loss 0.08670012707421626 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 2.45 secondes

Val loss 1.7826304137706757 accuracy 0.75 macro_avg {'precision': 0.7584541062801933, 'recall': 0.7165991902834008, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7548309178743962, 'recall': 0.75, 'f1-score': 0.7391774891774892, 'support': 64}
 
----------
Epoch 20/40
time = 59.85 secondes

Train loss 0.15885241739857575 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.78 secondes

Val loss 2.010408192873001 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 21/40
time = 50.90 secondes

Train loss 0.032350728449245886 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9708139672875404 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 51.22 secondes

Train loss 0.14020680028911695 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.92 secondes

Val loss 1.6221761107444763 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 23/40
time = 53.36 secondes

Train loss 0.04975731879720556 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.94 secondes

Val loss 1.6517925560474396 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 24/40
time = 53.40 secondes

Train loss 0.14401069832224908 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6974860578775406 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 25/40
time = 54.26 secondes

Train loss 0.0782484006027296 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 2.16 secondes

Val loss 1.621832400560379 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 26/40
time = 54.42 secondes

Train loss 0.06845679857647294 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8443526327610016 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 27/40
time = 53.62 secondes

Train loss 0.07718372638346134 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.13 secondes

Val loss 0.8541925735771656 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 28/40
time = 53.58 secondes

Train loss 0.01471875214536505 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.07 secondes

Val loss 1.1719386577606201 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 53.66 secondes

Train loss 0.0024413235792466862 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.2058558948338032 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 30/40
time = 52.92 secondes

Train loss 0.06301927973022843 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9099354445934296 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 31/40
time = 54.50 secondes

Train loss 0.0012452832337602917 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.79 secondes

Val loss 1.8820369988679886 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 32/40
time = 51.50 secondes

Train loss 0.029958484159909527 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.15250226855278 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 33/40
time = 51.21 secondes

Train loss 0.05022731599660112 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.72 secondes

Val loss 1.7247264087200165 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 34/40
time = 50.71 secondes

Train loss 0.040888782590848154 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8039852678775787 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 35/40
time = 51.41 secondes

Train loss 7.64346513085801e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6951496303081512 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 36/40
time = 55.03 secondes

Train loss 0.0001358925539093572 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.64 secondes

Val loss 1.6230476200580597 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 51.52 secondes

Train loss 4.082438560241523e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4412242770195007 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 50.16 secondes

Train loss 0.04809678205635988 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.34 secondes

Val loss 1.2933878004550934 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 39/40
time = 51.09 secondes

Train loss 0.00479410793476828 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.90 secondes

Val loss 1.3506575971841812 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 40/40
time = 53.81 secondes

Train loss 2.7775521768048886e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.85 secondes

Val loss 1.3970402926206589 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 39 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 56.059385776519775

average val time 2.077598822116852
 
time = 2.04 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 720.00 MiB (GPU 0; 79.21 GiB total capacity; 37.65 GiB already allocated; 592.62 MiB free; 38.91 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 770.00 MiB (GPU 0; 79.21 GiB total capacity; 37.45 GiB already allocated; 162.62 MiB free; 39.33 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 36.54 GiB already allocated; 740.62 MiB free; 38.77 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 38.18 GiB already allocated; 604.62 MiB free; 38.90 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_4
----------
Epoch 1/40
time = 745.27 secondes

Train loss 1.3620169442527148 accuracy 0.6241406798362732 macro_avg {'precision': 0.6219353346972651, 'recall': 0.6093775343137428, 'f1-score': 0.6038378794281871, 'support': 10182} weighted_avg {'precision': 0.6313274750649881, 'recall': 0.6241406403457082, 'f1-score': 0.6175725358091669, 'support': 10182}
 
time = 22.36 secondes

Val loss 0.7721365014432182 accuracy 0.7597173452377319 macro_avg {'precision': 0.7510064078283013, 'recall': 0.7575722002372418, 'f1-score': 0.7333221118737335, 'support': 1132} weighted_avg {'precision': 0.7658912605288779, 'recall': 0.7597173144876325, 'f1-score': 0.7376422287608863, 'support': 1132}
 
----------
Epoch 2/40
time = 766.24 secondes

Train loss 0.546149585969173 accuracy 0.8348065614700317 macro_avg {'precision': 0.8236073259763789, 'recall': 0.8245366376709649, 'f1-score': 0.8223070801175615, 'support': 10182} weighted_avg {'precision': 0.8310555458212395, 'recall': 0.8348065213121194, 'f1-score': 0.8316300753948395, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.6738081362465738 accuracy 0.814487636089325 macro_avg {'precision': 0.8165992188440303, 'recall': 0.8043235652313483, 'f1-score': 0.8017284224585145, 'support': 1132} weighted_avg {'precision': 0.8195720156833913, 'recall': 0.8144876325088339, 'f1-score': 0.809553568452201, 'support': 1132}
 
----------
Epoch 3/40
time = 768.31 secondes

Train loss 0.3193511044404804 accuracy 0.9082695245742798 macro_avg {'precision': 0.9038035449565139, 'recall': 0.9032763062642241, 'f1-score': 0.9033817246880691, 'support': 10182} weighted_avg {'precision': 0.9082510812578475, 'recall': 0.9082694951875859, 'f1-score': 0.908112436578834, 'support': 10182}
 
time = 22.62 secondes

Val loss 0.5849336762846985 accuracy 0.8454063534736633 macro_avg {'precision': 0.849900965163863, 'recall': 0.8460074205288585, 'f1-score': 0.8439324710790324, 'support': 1132} weighted_avg {'precision': 0.8542639253863423, 'recall': 0.8454063604240283, 'f1-score': 0.8457747090933558, 'support': 1132}
 
----------
Epoch 4/40
time = 773.58 secondes

Train loss 0.20227789867660573 accuracy 0.9434295892715454 macro_avg {'precision': 0.9405317590672155, 'recall': 0.9401481633333828, 'f1-score': 0.9402355111462699, 'support': 10182} weighted_avg {'precision': 0.943535975587809, 'recall': 0.943429581614614, 'f1-score': 0.9433797877924599, 'support': 10182}
 
time = 22.87 secondes

Val loss 0.7339574697781617 accuracy 0.8418728113174438 macro_avg {'precision': 0.84419152931348, 'recall': 0.8410633327348359, 'f1-score': 0.8388628420054788, 'support': 1132} weighted_avg {'precision': 0.8501978305965588, 'recall': 0.8418727915194346, 'f1-score': 0.8421960297837339, 'support': 1132}
 
----------
Epoch 5/40
time = 771.98 secondes

Train loss 0.1737769185960164 accuracy 0.9549204707145691 macro_avg {'precision': 0.9531487007597782, 'recall': 0.9528330497148285, 'f1-score': 0.952963187484175, 'support': 10182} weighted_avg {'precision': 0.9549531711986364, 'recall': 0.9549204478491455, 'f1-score': 0.9549092989161182, 'support': 10182}
 
time = 23.21 secondes

Val loss 0.9111240202393777 accuracy 0.8312720656394958 macro_avg {'precision': 0.8455761824246381, 'recall': 0.8375173263457919, 'f1-score': 0.8294228629011243, 'support': 1132} weighted_avg {'precision': 0.8537160674498004, 'recall': 0.8312720848056537, 'f1-score': 0.8300448546692971, 'support': 1132}
 
----------
Epoch 6/40
time = 773.24 secondes

Train loss 0.15160615080503345 accuracy 0.9617953300476074 macro_avg {'precision': 0.9610260638246407, 'recall': 0.9604506611626145, 'f1-score': 0.9607005253697132, 'support': 10182} weighted_avg {'precision': 0.9618160264973088, 'recall': 0.9617953250834806, 'f1-score': 0.961770041507121, 'support': 10182}
 
time = 22.85 secondes

Val loss 0.998122779804964 accuracy 0.8445229530334473 macro_avg {'precision': 0.86176540409393, 'recall': 0.8371493208463822, 'f1-score': 0.8373026897444229, 'support': 1132} weighted_avg {'precision': 0.8565802864566736, 'recall': 0.8445229681978799, 'f1-score': 0.8406369555904527, 'support': 1132}
 
----------
Epoch 7/40
time = 773.70 secondes

Train loss 0.13249409085351993 accuracy 0.9710273146629333 macro_avg {'precision': 0.9704108841346606, 'recall': 0.9700146838761171, 'f1-score': 0.9701941170730904, 'support': 10182} weighted_avg {'precision': 0.9710566094241091, 'recall': 0.9710273030838735, 'f1-score': 0.9710243416756901, 'support': 10182}
 
time = 23.08 secondes

Val loss 0.8362880445931526 accuracy 0.8639575839042664 macro_avg {'precision': 0.8681998035408321, 'recall': 0.8681591102441922, 'f1-score': 0.8645186873143812, 'support': 1132} weighted_avg {'precision': 0.8718214855734102, 'recall': 0.8639575971731449, 'f1-score': 0.8641791456507038, 'support': 1132}
 
----------
Epoch 8/40
time = 758.75 secondes

Train loss 0.13370663273675307 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684523782408114, 'recall': 0.9677270730485317, 'f1-score': 0.9680024685834953, 'support': 10182} weighted_avg {'precision': 0.9696792400102836, 'recall': 0.9696523276370065, 'f1-score': 0.9695957000383791, 'support': 10182}
 
time = 20.58 secondes

Val loss 0.8870222394192316 accuracy 0.8657243847846985 macro_avg {'precision': 0.8743692474806753, 'recall': 0.8684181330159395, 'f1-score': 0.8667837124379828, 'support': 1132} weighted_avg {'precision': 0.8780266374755173, 'recall': 0.8657243816254417, 'f1-score': 0.8671335891632083, 'support': 1132}
 
----------
Epoch 9/40
time = 698.45 secondes

Train loss 0.12476795982899147 accuracy 0.9742683172225952 macro_avg {'precision': 0.9734524805354475, 'recall': 0.9730562821113491, 'f1-score': 0.9732113025726197, 'support': 10182} weighted_avg {'precision': 0.9743408213655522, 'recall': 0.9742683166372029, 'f1-score': 0.974264383294331, 'support': 10182}
 
time = 20.01 secondes

Val loss 1.0709312920914438 accuracy 0.851590096950531 macro_avg {'precision': 0.8618469341045939, 'recall': 0.8506343820580625, 'f1-score': 0.8488575863227006, 'support': 1132} weighted_avg {'precision': 0.8606690731130928, 'recall': 0.8515901060070671, 'f1-score': 0.8488655818227334, 'support': 1132}
 
----------
Epoch 10/40
time = 699.35 secondes

Train loss 0.10657032142415952 accuracy 0.9776075482368469 macro_avg {'precision': 0.9769480650107714, 'recall': 0.9770833438378135, 'f1-score': 0.9769876055665282, 'support': 10182} weighted_avg {'precision': 0.9777417859206715, 'recall': 0.9776075427224514, 'f1-score': 0.977648333241033, 'support': 10182}
 
time = 20.72 secondes

Val loss 0.8671397315576004 accuracy 0.8772084712982178 macro_avg {'precision': 0.8790587520681088, 'recall': 0.87829477409379, 'f1-score': 0.8767878389616722, 'support': 1132} weighted_avg {'precision': 0.8815916966721384, 'recall': 0.877208480565371, 'f1-score': 0.8776737900561747, 'support': 1132}
 
----------
Epoch 11/40
time = 703.64 secondes

Train loss 0.10393895805039219 accuracy 0.9787861108779907 macro_avg {'precision': 0.9778726796861175, 'recall': 0.9780146405470868, 'f1-score': 0.9779145709832899, 'support': 10182} weighted_avg {'precision': 0.9788332416846702, 'recall': 0.9787860931054803, 'f1-score': 0.9787801712601663, 'support': 10182}
 
time = 20.65 secondes

Val loss 0.9710595562056357 accuracy 0.8692579865455627 macro_avg {'precision': 0.8718157550565303, 'recall': 0.8710751745676049, 'f1-score': 0.8684620167480812, 'support': 1132} weighted_avg {'precision': 0.8777388931596417, 'recall': 0.8692579505300353, 'f1-score': 0.8704451067827041, 'support': 1132}
 
----------
Epoch 12/40
time = 689.91 secondes

Train loss 0.10528037115589575 accuracy 0.9807503819465637 macro_avg {'precision': 0.9804643394641822, 'recall': 0.9802863378013882, 'f1-score': 0.9803451952507197, 'support': 10182} weighted_avg {'precision': 0.9808097000871195, 'recall': 0.9807503437438617, 'f1-score': 0.980748975135919, 'support': 10182}
 
time = 20.74 secondes

Val loss 1.2224667010100028 accuracy 0.8312720656394958 macro_avg {'precision': 0.864524379948219, 'recall': 0.8297763668257702, 'f1-score': 0.8267850206468976, 'support': 1132} weighted_avg {'precision': 0.8595217923061619, 'recall': 0.8312720848056537, 'f1-score': 0.8265133905669328, 'support': 1132}
 
----------
Epoch 13/40
time = 700.54 secondes

Train loss 0.09644961703639607 accuracy 0.9803575277328491 macro_avg {'precision': 0.9800837171113825, 'recall': 0.9802778822976173, 'f1-score': 0.980135990312105, 'support': 10182} weighted_avg {'precision': 0.9804062785539409, 'recall': 0.9803574936161854, 'f1-score': 0.9803358166878084, 'support': 10182}
 
time = 21.35 secondes

Val loss 0.9216421468471977 accuracy 0.8780918717384338 macro_avg {'precision': 0.8812960716770168, 'recall': 0.8822794153471014, 'f1-score': 0.8793194896482628, 'support': 1132} weighted_avg {'precision': 0.8859058558683396, 'recall': 0.8780918727915195, 'f1-score': 0.8794953527575989, 'support': 1132}
 
----------
Epoch 14/40
time = 699.16 secondes

Train loss 0.09607161275642775 accuracy 0.9819289445877075 macro_avg {'precision': 0.9822522626749933, 'recall': 0.9820770697621208, 'f1-score': 0.982131037783696, 'support': 10182} weighted_avg {'precision': 0.9820279917307982, 'recall': 0.9819288941268906, 'f1-score': 0.9819440098992143, 'support': 10182}
 
time = 20.95 secondes

Val loss 0.9335599796425118 accuracy 0.8745583295822144 macro_avg {'precision': 0.8852245172900725, 'recall': 0.877608305894492, 'f1-score': 0.8777894613070318, 'support': 1132} weighted_avg {'precision': 0.8844214411749265, 'recall': 0.8745583038869258, 'f1-score': 0.8757253421009883, 'support': 1132}
 
----------
Epoch 15/40
time = 682.30 secondes

Train loss 0.08353636490348401 accuracy 0.9842860102653503 macro_avg {'precision': 0.9835806520904248, 'recall': 0.9834871336192673, 'f1-score': 0.983525805895978, 'support': 10182} weighted_avg {'precision': 0.9843032987367522, 'recall': 0.9842859948929483, 'f1-score': 0.984286306191619, 'support': 10182}
 
time = 20.20 secondes

Val loss 1.0414238832224878 accuracy 0.8657243847846985 macro_avg {'precision': 0.8778192106122139, 'recall': 0.8683858423141085, 'f1-score': 0.8692654664556635, 'support': 1132} weighted_avg {'precision': 0.876649614312357, 'recall': 0.8657243816254417, 'f1-score': 0.8673841186677678, 'support': 1132}
 
----------
Epoch 16/40
time = 705.24 secondes

Train loss 0.07256669544100303 accuracy 0.9866431355476379 macro_avg {'precision': 0.9864878620742441, 'recall': 0.9865670335622065, 'f1-score': 0.9865045910052166, 'support': 10182} weighted_avg {'precision': 0.9866826645012108, 'recall': 0.9866430956590061, 'f1-score': 0.9866393863813295, 'support': 10182}
 
time = 21.48 secondes

Val loss 1.0761123847791885 accuracy 0.8666077852249146 macro_avg {'precision': 0.8857127917157939, 'recall': 0.87050924793125, 'f1-score': 0.8694601701336022, 'support': 1132} weighted_avg {'precision': 0.8877783722129482, 'recall': 0.8666077738515902, 'f1-score': 0.8681293463513361, 'support': 1132}
 
----------
Epoch 17/40
time = 703.86 secondes

Train loss 0.08226310823394078 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860862812453279, 'recall': 0.9859821072805651, 'f1-score': 0.9860092044452424, 'support': 10182} weighted_avg {'precision': 0.9863694605782292, 'recall': 0.9863484580632489, 'f1-score': 0.9863330161665136, 'support': 10182}
 
time = 21.00 secondes

Val loss 0.9512951463068635 accuracy 0.880742073059082 macro_avg {'precision': 0.8892570711515984, 'recall': 0.8838023447508127, 'f1-score': 0.8837065412596324, 'support': 1132} weighted_avg {'precision': 0.8885338818820876, 'recall': 0.8807420494699647, 'f1-score': 0.8815531069712201, 'support': 1132}
 
----------
Epoch 18/40
time = 706.69 secondes

Train loss 0.06583956096286986 accuracy 0.9883127212524414 macro_avg {'precision': 0.9879759745271921, 'recall': 0.9880367845986097, 'f1-score': 0.9879990604833886, 'support': 10182} weighted_avg {'precision': 0.9883356887909751, 'recall': 0.9883127087016303, 'f1-score': 0.9883171167043273, 'support': 10182}
 
time = 21.26 secondes

Val loss 0.9716631421289722 accuracy 0.8851590156555176 macro_avg {'precision': 0.8907503671755105, 'recall': 0.8885455190564968, 'f1-score': 0.8876144829445867, 'support': 1132} weighted_avg {'precision': 0.8920035777982743, 'recall': 0.8851590106007067, 'f1-score': 0.8865040684979207, 'support': 1132}
 
----------
Epoch 19/40
time = 704.69 secondes

Train loss 0.07458173049252617 accuracy 0.9871341586112976 macro_avg {'precision': 0.9866151935998693, 'recall': 0.9870062654443321, 'f1-score': 0.9867909347428755, 'support': 10182} weighted_avg {'precision': 0.9871751911790048, 'recall': 0.9871341583186014, 'f1-score': 0.9871380597195486, 'support': 10182}
 
time = 21.43 secondes

Val loss 1.0510698059446901 accuracy 0.8736749291419983 macro_avg {'precision': 0.8770775055974511, 'recall': 0.8788532085496559, 'f1-score': 0.8745193566255486, 'support': 1132} weighted_avg {'precision': 0.8812584546811169, 'recall': 0.8736749116607774, 'f1-score': 0.8739535981005717, 'support': 1132}
 
----------
Epoch 20/40
time = 712.92 secondes

Train loss 0.05827744971126093 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885058858070346, 'recall': 0.9885540060536595, 'f1-score': 0.9885183032362466, 'support': 10182} weighted_avg {'precision': 0.9888337480645996, 'recall': 0.9888037713612257, 'f1-score': 0.9888071670813554, 'support': 10182}
 
time = 22.73 secondes

Val loss 0.9113514228915782 accuracy 0.8754417300224304 macro_avg {'precision': 0.8783642542057297, 'recall': 0.8811695663990241, 'f1-score': 0.8768913572358479, 'support': 1132} weighted_avg {'precision': 0.88027049403999, 'recall': 0.8754416961130742, 'f1-score': 0.874989055526413, 'support': 1132}
 
----------
Epoch 21/40
time = 713.83 secondes

Train loss 0.05414249188574364 accuracy 0.9899823665618896 macro_avg {'precision': 0.9896811373235022, 'recall': 0.9896857934266231, 'f1-score': 0.9896766156350276, 'support': 10182} weighted_avg {'precision': 0.9899830158296052, 'recall': 0.9899823217442546, 'f1-score': 0.989975721491508, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.9406612613523284 accuracy 0.8833922147750854 macro_avg {'precision': 0.8864774228495398, 'recall': 0.8868482932133638, 'f1-score': 0.8845347749620582, 'support': 1132} weighted_avg {'precision': 0.8880506029243672, 'recall': 0.8833922261484098, 'f1-score': 0.8834232818629714, 'support': 1132}
 
----------
Epoch 22/40
time = 709.07 secondes

Train loss 0.06321538336166756 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885349925498985, 'recall': 0.988619905777308, 'f1-score': 0.9885633007210728, 'support': 10182} weighted_avg {'precision': 0.9888276773514048, 'recall': 0.9888037713612257, 'f1-score': 0.9888017059262472, 'support': 10182}
 
time = 22.23 secondes

Val loss 0.9494373546134431 accuracy 0.8904593586921692 macro_avg {'precision': 0.8964239749844956, 'recall': 0.8922292994369618, 'f1-score': 0.891969584475252, 'support': 1132} weighted_avg {'precision': 0.8951258398891432, 'recall': 0.8904593639575972, 'f1-score': 0.8904251473573744, 'support': 1132}
 
----------
Epoch 23/40
time = 691.88 secondes

Train loss 0.04857952967429116 accuracy 0.9911609292030334 macro_avg {'precision': 0.9907975937648537, 'recall': 0.990839082682229, 'f1-score': 0.990810605221346, 'support': 10182} weighted_avg {'precision': 0.9911795119385237, 'recall': 0.9911608721272834, 'f1-score': 0.9911627469753196, 'support': 10182}
 
time = 20.71 secondes

Val loss 0.9655102952009413 accuracy 0.8833922147750854 macro_avg {'precision': 0.8886718481419615, 'recall': 0.8870599470472408, 'f1-score': 0.8857946870419733, 'support': 1132} weighted_avg {'precision': 0.8903540304441377, 'recall': 0.8833922261484098, 'f1-score': 0.8847178543076476, 'support': 1132}
 
----------
Epoch 24/40
time = 699.92 secondes

Train loss 0.0450729193765154 accuracy 0.9923394322395325 macro_avg {'precision': 0.9924901388510726, 'recall': 0.9924470850931696, 'f1-score': 0.9924512443871001, 'support': 10182} weighted_avg {'precision': 0.9923676629113869, 'recall': 0.9923394225103123, 'f1-score': 0.9923355509710997, 'support': 10182}
 
time = 19.41 secondes

Val loss 0.836745535082128 accuracy 0.880742073059082 macro_avg {'precision': 0.8880632550218042, 'recall': 0.8885674242227573, 'f1-score': 0.8836372572968904, 'support': 1132} weighted_avg {'precision': 0.8890579400123074, 'recall': 0.8807420494699647, 'f1-score': 0.8798031601983608, 'support': 1132}
 
----------
Epoch 25/40
time = 696.96 secondes

Train loss 0.041573701396991736 accuracy 0.9928305149078369 macro_avg {'precision': 0.9926707685663384, 'recall': 0.9927095162963937, 'f1-score': 0.9926770180932033, 'support': 10182} weighted_avg {'precision': 0.9928525212902264, 'recall': 0.9928304851699077, 'f1-score': 0.9928280889061362, 'support': 10182}
 
time = 20.79 secondes

Val loss 0.9172713470946126 accuracy 0.8904593586921692 macro_avg {'precision': 0.8977775497432579, 'recall': 0.8930249060989794, 'f1-score': 0.8929279155286448, 'support': 1132} weighted_avg {'precision': 0.8981227098162188, 'recall': 0.8904593639575972, 'f1-score': 0.8919707046493922, 'support': 1132}
 
----------
Epoch 26/40
time = 695.29 secondes

Train loss 0.051566629921358166 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918855819986678, 'recall': 0.9919605736432617, 'f1-score': 0.9919130991547908, 'support': 10182} weighted_avg {'precision': 0.9921668416481433, 'recall': 0.9921429974464742, 'f1-score': 0.9921450926916305, 'support': 10182}
 
time = 20.91 secondes

Val loss 0.8739972566411228 accuracy 0.898409903049469 macro_avg {'precision': 0.9012356060438425, 'recall': 0.9031105712105127, 'f1-score': 0.8998764371975436, 'support': 1132} weighted_avg {'precision': 0.9034981314415198, 'recall': 0.8984098939929329, 'f1-score': 0.898513288727122, 'support': 1132}
 
----------
Epoch 27/40
time = 701.29 secondes

Train loss 0.03362585368210504 accuracy 0.993812620639801 macro_avg {'precision': 0.9936813701782633, 'recall': 0.993651087279944, 'f1-score': 0.9936605836350786, 'support': 10182} weighted_avg {'precision': 0.9938260102210492, 'recall': 0.9938126104890984, 'f1-score': 0.993813584954164, 'support': 10182}
 
time = 21.78 secondes

Val loss 0.9841584200487336 accuracy 0.8869258165359497 macro_avg {'precision': 0.8928491765519961, 'recall': 0.8895534368326056, 'f1-score': 0.8884768804384828, 'support': 1132} weighted_avg {'precision': 0.8940190248694975, 'recall': 0.8869257950530035, 'f1-score': 0.8876188808040355, 'support': 1132}
 
----------
Epoch 28/40
time = 712.54 secondes

Train loss 0.03560435815925131 accuracy 0.9941073060035706 macro_avg {'precision': 0.993901640495395, 'recall': 0.9940760487261853, 'f1-score': 0.9939835844048668, 'support': 10182} weighted_avg {'precision': 0.9941153024384927, 'recall': 0.9941072480848556, 'f1-score': 0.9941063078036233, 'support': 10182}
 
time = 22.65 secondes

Val loss 0.907973636499943 accuracy 0.8922261595726013 macro_avg {'precision': 0.8986013058814274, 'recall': 0.8947767306738778, 'f1-score': 0.8944735758358444, 'support': 1132} weighted_avg {'precision': 0.8970462600507981, 'recall': 0.892226148409894, 'f1-score': 0.8923185442350859, 'support': 1132}
 
----------
Epoch 29/40
time = 711.03 secondes

Train loss 0.0322029616904022 accuracy 0.9944019317626953 macro_avg {'precision': 0.9942696711601255, 'recall': 0.9943981985336577, 'f1-score': 0.9943275607647631, 'support': 10182} weighted_avg {'precision': 0.9944133378799135, 'recall': 0.9944018856806128, 'f1-score': 0.9944018538096763, 'support': 10182}
 
time = 22.86 secondes

Val loss 1.0846933569888457 accuracy 0.8736749291419983 macro_avg {'precision': 0.9032072288139238, 'recall': 0.8766037779772992, 'f1-score': 0.8835065943098448, 'support': 1132} weighted_avg {'precision': 0.8997056982124427, 'recall': 0.8736749116607774, 'f1-score': 0.8796482107509905, 'support': 1132}
 
----------
Epoch 30/40
time = 714.34 secondes

Train loss 0.04390207801046144 accuracy 0.9927322864532471 macro_avg {'precision': 0.9928927709334676, 'recall': 0.9927686700216203, 'f1-score': 0.9928191125276473, 'support': 10182} weighted_avg {'precision': 0.992759222675427, 'recall': 0.9927322726379886, 'f1-score': 0.9927339674971646, 'support': 10182}
 
time = 23.52 secondes

Val loss 0.97769883338338 accuracy 0.8895759582519531 macro_avg {'precision': 0.8999506151752122, 'recall': 0.8932693509929666, 'f1-score': 0.8933086365215439, 'support': 1132} weighted_avg {'precision': 0.899727154883964, 'recall': 0.8895759717314488, 'f1-score': 0.8911901160520143, 'support': 1132}
 
----------
Epoch 31/40
time = 713.65 secondes

Train loss 0.03768539344519998 accuracy 0.9939108490943909 macro_avg {'precision': 0.9940811145014619, 'recall': 0.9940208663248304, 'f1-score': 0.9940416375339247, 'support': 10182} weighted_avg {'precision': 0.9939334031716122, 'recall': 0.9939108230210175, 'f1-score': 0.9939124582771408, 'support': 10182}
 
time = 23.38 secondes

Val loss 1.0496889290219078 accuracy 0.8860424160957336 macro_avg {'precision': 0.8906881951325689, 'recall': 0.8883084314455004, 'f1-score': 0.8868118834854863, 'support': 1132} weighted_avg {'precision': 0.8919113180176217, 'recall': 0.8860424028268551, 'f1-score': 0.8862005230438254, 'support': 1132}
 
----------
Epoch 32/40
time = 653.77 secondes

Train loss 0.02706357283376471 accuracy 0.9950894117355347 macro_avg {'precision': 0.9952409133951537, 'recall': 0.9951504626502177, 'f1-score': 0.9951884939765808, 'support': 10182} weighted_avg {'precision': 0.9951138158768448, 'recall': 0.9950893734040464, 'f1-score': 0.995094267219817, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9302681963955353 accuracy 0.8931095600128174 macro_avg {'precision': 0.8928497230841828, 'recall': 0.8957077229084442, 'f1-score': 0.8927317692573087, 'support': 1132} weighted_avg {'precision': 0.8962022591747876, 'recall': 0.8931095406360424, 'f1-score': 0.893076508444322, 'support': 1132}
 
----------
Epoch 33/40
time = 683.45 secondes

Train loss 0.025361298259636407 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959508938265327, 'recall': 0.9959884946603067, 'f1-score': 0.9959655254919765, 'support': 10182} weighted_avg {'precision': 0.9960741844524214, 'recall': 0.9960714987232371, 'f1-score': 0.9960685545101935, 'support': 10182}
 
time = 18.55 secondes

Val loss 1.0081298280417965 accuracy 0.8913427591323853 macro_avg {'precision': 0.9023920959352804, 'recall': 0.8917292988200985, 'f1-score': 0.894601658931505, 'support': 1132} weighted_avg {'precision': 0.9008028136990566, 'recall': 0.8913427561837456, 'f1-score': 0.8934007229770258, 'support': 1132}
 
----------
Epoch 34/40
time = 678.98 secondes

Train loss 0.025458554901564314 accuracy 0.9963661432266235 macro_avg {'precision': 0.9964063705808023, 'recall': 0.9962222254469509, 'f1-score': 0.9963042095751732, 'support': 10182} weighted_avg {'precision': 0.9963930880506273, 'recall': 0.9963661363189943, 'f1-score': 0.9963695133467236, 'support': 10182}
 
time = 22.45 secondes

Val loss 0.9037004050345863 accuracy 0.9010601043701172 macro_avg {'precision': 0.9040137393888521, 'recall': 0.904111122935673, 'f1-score': 0.9021453306483747, 'support': 1132} weighted_avg {'precision': 0.9062686449108778, 'recall': 0.901060070671378, 'f1-score': 0.9015265011929081, 'support': 1132}
 
----------
Epoch 35/40
time = 682.30 secondes

Train loss 0.019751426164674023 accuracy 0.9969554543495178 macro_avg {'precision': 0.9970698626179555, 'recall': 0.997047539246241, 'f1-score': 0.9970550599423305, 'support': 10182} weighted_avg {'precision': 0.9969624559255742, 'recall': 0.9969554115105087, 'f1-score': 0.996955171732931, 'support': 10182}
 
time = 19.71 secondes

Val loss 0.9164097473412894 accuracy 0.898409903049469 macro_avg {'precision': 0.9033335063455921, 'recall': 0.9002338099032864, 'f1-score': 0.8995990886469393, 'support': 1132} weighted_avg {'precision': 0.9055019949002336, 'recall': 0.8984098939929329, 'f1-score': 0.8996726968246683, 'support': 1132}
 
----------
Epoch 36/40
time = 651.33 secondes

Train loss 0.015566366553085263 accuracy 0.9974464774131775 macro_avg {'precision': 0.9974816972709475, 'recall': 0.9975090592363942, 'f1-score': 0.9974938102139564, 'support': 10182} weighted_avg {'precision': 0.9974522002547943, 'recall': 0.9974464741701041, 'f1-score': 0.9974477393460691, 'support': 10182}
 
time = 16.49 secondes

Val loss 0.8430173347981214 accuracy 0.9045936465263367 macro_avg {'precision': 0.9088606239398981, 'recall': 0.9067041708807878, 'f1-score': 0.9060410874843683, 'support': 1132} weighted_avg {'precision': 0.9103726613330795, 'recall': 0.9045936395759717, 'f1-score': 0.9056116676543543, 'support': 1132}
 
----------
Epoch 37/40
time = 630.80 secondes

Train loss 0.008411392220468727 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981792721550404, 'recall': 0.9981675830676011, 'f1-score': 0.9981718137996921, 'support': 10182} weighted_avg {'precision': 0.9981370987829821, 'recall': 0.9981339618935376, 'f1-score': 0.9981338602150323, 'support': 10182}
 
time = 17.78 secondes

Val loss 0.8666398737408548 accuracy 0.9072438478469849 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}
 
----------
Epoch 38/40
time = 657.08 secondes

Train loss 0.00363665757710664 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991479970546828, 'recall': 0.9991442419023459, 'f1-score': 0.999145760441634, 'support': 10182} weighted_avg {'precision': 0.999116631275601, 'recall': 0.9991160872127284, 'f1-score': 0.9991159874346697, 'support': 10182}
 
time = 20.75 secondes

Val loss 0.9295898494970637 accuracy 0.9028268456459045 macro_avg {'precision': 0.9060399377803906, 'recall': 0.9056944083481362, 'f1-score': 0.9044988995544063, 'support': 1132} weighted_avg {'precision': 0.9065984939144717, 'recall': 0.9028268551236749, 'f1-score': 0.9032727859370949, 'support': 1132}
 
----------
Epoch 39/40
time = 735.68 secondes

Train loss 0.0073776574524289365 accuracy 0.998821496963501 macro_avg {'precision': 0.9988446447385501, 'recall': 0.9988559297558119, 'f1-score': 0.9988491227300283, 'support': 10182} weighted_avg {'precision': 0.9988234807892794, 'recall': 0.9988214496169712, 'f1-score': 0.9988212604229645, 'support': 10182}
 
time = 20.87 secondes

Val loss 0.9766664895803739 accuracy 0.8992933034896851 macro_avg {'precision': 0.9031340386036965, 'recall': 0.9028152435072675, 'f1-score': 0.901175336518987, 'support': 1132} weighted_avg {'precision': 0.9035455724944119, 'recall': 0.8992932862190812, 'f1-score': 0.8994590099560085, 'support': 1132}
 
----------
Epoch 40/40
time = 733.80 secondes

Train loss 0.0013381021140298549 accuracy 0.9996072053909302 macro_avg {'precision': 0.999619535206102, 'recall': 0.9996171073534079, 'f1-score': 0.9996180539138934, 'support': 10182} weighted_avg {'precision': 0.9996077034874572, 'recall': 0.9996071498723237, 'f1-score': 0.9996071486778729, 'support': 10182}
 
time = 20.86 secondes

Val loss 0.9683842703135512 accuracy 0.9001767039299011 macro_avg {'precision': 0.9049967233911268, 'recall': 0.9031661481628822, 'f1-score': 0.9025115850836439, 'support': 1132} weighted_avg {'precision': 0.9047317864972204, 'recall': 0.9001766784452296, 'f1-score': 0.9007451703857408, 'support': 1132}
 
----------
best_accuracy 0.9072438478469849 best_epoch 37 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}

average train time 710.1203987717629

average val time 21.27267496585846
 
time = 136.86 secondes

test_accuracy 0.8296601176261902 macro_avg {'precision': 0.8261694392580499, 'recall': 0.8224345462904866, 'f1-score': 0.8221196564902696, 'support': 7532} weighted_avg {'precision': 0.8336363981546475, 'recall': 0.829660116834838, 'f1-score': 0.8295233448050705, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 488.17 secondes

Train loss 1.372230394902746 accuracy 0.6279709339141846 macro_avg {'precision': 0.6134986424362526, 'recall': 0.6129635552418231, 'f1-score': 0.6060368639532894, 'support': 10182} weighted_avg {'precision': 0.6262844028878005, 'recall': 0.627970929090552, 'f1-score': 0.6205845935912996, 'support': 10182}
 
time = 13.61 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.7827829303036273 accuracy 0.7588339447975159 macro_avg {'precision': 0.7414010329079515, 'recall': 0.7519130459253796, 'f1-score': 0.739521506874756, 'support': 1132} weighted_avg {'precision': 0.7486685046889161, 'recall': 0.758833922261484, 'f1-score': 0.7457319008112446, 'support': 1132}
 
----------
Epoch 2/40
time = 489.15 secondes

Train loss 0.5661003756420204 accuracy 0.827440619468689 macro_avg {'precision': 0.8147678466302217, 'recall': 0.8158370966826813, 'f1-score': 0.8124413299970389, 'support': 10182} weighted_avg {'precision': 0.8230306057456931, 'recall': 0.827440581418189, 'f1-score': 0.8231434523553137, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.6228134159890699 accuracy 0.8127208352088928 macro_avg {'precision': 0.8184673457899517, 'recall': 0.809688721738919, 'f1-score': 0.8083539561335371, 'support': 1132} weighted_avg {'precision': 0.8247300743455266, 'recall': 0.8127208480565371, 'f1-score': 0.8126672420729907, 'support': 1132}
 
----------
Epoch 3/40
time = 491.28 secondes

Train loss 0.33805252711348577 accuracy 0.9015910625457764 macro_avg {'precision': 0.8957571854167836, 'recall': 0.8953094824603985, 'f1-score': 0.895339588984726, 'support': 10182} weighted_avg {'precision': 0.9010649766918674, 'recall': 0.901591043017089, 'f1-score': 0.9011625070151672, 'support': 10182}
 
time = 17.79 secondes

Val loss 0.5765100382006084 accuracy 0.843639612197876 macro_avg {'precision': 0.8421845395505955, 'recall': 0.8433724466720106, 'f1-score': 0.8400549172690479, 'support': 1132} weighted_avg {'precision': 0.8484319877702833, 'recall': 0.8436395759717314, 'f1-score': 0.8432237679969962, 'support': 1132}
 
----------
Epoch 4/40
time = 491.14 secondes

Train loss 0.2288811775070602 accuracy 0.9349833130836487 macro_avg {'precision': 0.9312153196858393, 'recall': 0.9310185014458814, 'f1-score': 0.9310589110266136, 'support': 10182} weighted_avg {'precision': 0.9350689782123511, 'recall': 0.9349833038695737, 'f1-score': 0.9349687755698205, 'support': 10182}
 
time = 17.83 secondes

Val loss 0.5590408811227642 accuracy 0.880742073059082 macro_avg {'precision': 0.8845080012108, 'recall': 0.882472471066747, 'f1-score': 0.881267876937239, 'support': 1132} weighted_avg {'precision': 0.886225079068045, 'recall': 0.8807420494699647, 'f1-score': 0.8810748498825536, 'support': 1132}
 
----------
Epoch 5/40
time = 490.57 secondes

Train loss 0.1857722676421254 accuracy 0.9504026770591736 macro_avg {'precision': 0.9480834602951884, 'recall': 0.9485453763437274, 'f1-score': 0.9482459793105406, 'support': 10182} weighted_avg {'precision': 0.950653561700645, 'recall': 0.9504026713808682, 'f1-score': 0.9504711492450918, 'support': 10182}
 
time = 15.60 secondes

Val loss 0.7408904056163164 accuracy 0.8551236987113953 macro_avg {'precision': 0.8611180769010952, 'recall': 0.854606225684463, 'f1-score': 0.8522397877748296, 'support': 1132} weighted_avg {'precision': 0.8628258380080642, 'recall': 0.8551236749116607, 'f1-score': 0.8533244085846735, 'support': 1132}
 
----------
Epoch 6/40
time = 490.37 secondes

Train loss 0.15462405650527034 accuracy 0.9615989327430725 macro_avg {'precision': 0.9598932908325567, 'recall': 0.9599465519921091, 'f1-score': 0.9598828051434406, 'support': 10182} weighted_avg {'precision': 0.9616245166317874, 'recall': 0.9615989000196425, 'f1-score': 0.9615741195984013, 'support': 10182}
 
time = 13.76 secondes

Val loss 0.7150365061341444 accuracy 0.8754417300224304 macro_avg {'precision': 0.878739346260199, 'recall': 0.8760024770493183, 'f1-score': 0.8734891524807982, 'support': 1132} weighted_avg {'precision': 0.8820861260425824, 'recall': 0.8754416961130742, 'f1-score': 0.8752574340459215, 'support': 1132}
 
----------
Epoch 7/40
time = 494.37 secondes

Train loss 0.14585145360540183 accuracy 0.9639560580253601 macro_avg {'precision': 0.9623347317696279, 'recall': 0.9622403292495353, 'f1-score': 0.9622596178820302, 'support': 10182} weighted_avg {'precision': 0.9640556077331855, 'recall': 0.9639560007857002, 'f1-score': 0.9639770889392808, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.8331980400269484 accuracy 0.8613074421882629 macro_avg {'precision': 0.868494389634822, 'recall': 0.8573161469789887, 'f1-score': 0.8581150544115875, 'support': 1132} weighted_avg {'precision': 0.8682268049920878, 'recall': 0.8613074204946997, 'f1-score': 0.859760914451488, 'support': 1132}
 
----------
Epoch 8/40
time = 487.60 secondes

Train loss 0.1186752834756094 accuracy 0.9718130230903625 macro_avg {'precision': 0.9713017162299213, 'recall': 0.9707824655697375, 'f1-score': 0.9710097538676095, 'support': 10182} weighted_avg {'precision': 0.9718727633802077, 'recall': 0.971813003339226, 'f1-score': 0.9718136489595701, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.8462979193300527 accuracy 0.8630741834640503 macro_avg {'precision': 0.8725732539327089, 'recall': 0.8673504791744057, 'f1-score': 0.8663530343110819, 'support': 1132} weighted_avg {'precision': 0.872618110774337, 'recall': 0.8630742049469965, 'f1-score': 0.8640104617219612, 'support': 1132}
 
----------
Epoch 9/40
time = 488.58 secondes

Train loss 0.11825049903272655 accuracy 0.9743665456771851 macro_avg {'precision': 0.9740086854920506, 'recall': 0.974112404271855, 'f1-score': 0.9740159629028021, 'support': 10182} weighted_avg {'precision': 0.974465338982123, 'recall': 0.974366529169122, 'f1-score': 0.9743709731066372, 'support': 10182}
 
time = 16.43 secondes

Val loss 0.9256451609122246 accuracy 0.8639575839042664 macro_avg {'precision': 0.8824459459285106, 'recall': 0.8625915616704909, 'f1-score': 0.8619694083914471, 'support': 1132} weighted_avg {'precision': 0.8806347128863042, 'recall': 0.8639575971731449, 'f1-score': 0.8620541476430885, 'support': 1132}
 
----------
Epoch 10/40
time = 486.19 secondes

Train loss 0.11346419836974556 accuracy 0.9750540256500244 macro_avg {'precision': 0.97450725055481, 'recall': 0.9743253265364838, 'f1-score': 0.9743980761514989, 'support': 10182} weighted_avg {'precision': 0.9750587087134146, 'recall': 0.9750540168925554, 'f1-score': 0.9750386996645554, 'support': 10182}
 
time = 16.46 secondes

Val loss 0.8181793919307816 accuracy 0.8816254734992981 macro_avg {'precision': 0.8870936772739799, 'recall': 0.8787759075554369, 'f1-score': 0.8796876771208831, 'support': 1132} weighted_avg {'precision': 0.8868924462024713, 'recall': 0.8816254416961131, 'f1-score': 0.8812846585930596, 'support': 1132}
 
----------
Epoch 11/40
time = 486.58 secondes

Train loss 0.10685138974943782 accuracy 0.9750540256500244 macro_avg {'precision': 0.9741895940350366, 'recall': 0.9740720774068772, 'f1-score': 0.9740559897593369, 'support': 10182} weighted_avg {'precision': 0.9751324577830939, 'recall': 0.9750540168925554, 'f1-score': 0.9750184803027615, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.7958596906719835 accuracy 0.8833922147750854 macro_avg {'precision': 0.8881437786434876, 'recall': 0.8858844799921325, 'f1-score': 0.8836898021982268, 'support': 1132} weighted_avg {'precision': 0.8926884265146741, 'recall': 0.8833922261484098, 'f1-score': 0.8848140538233903, 'support': 1132}
 
----------
Epoch 12/40
time = 506.69 secondes

Train loss 0.10075849265040077 accuracy 0.9801610708236694 macro_avg {'precision': 0.9797901599964524, 'recall': 0.9797899321281885, 'f1-score': 0.9797558861134699, 'support': 10182} weighted_avg {'precision': 0.9802004472266795, 'recall': 0.9801610685523473, 'f1-score': 0.9801461661898113, 'support': 10182}
 
time = 14.34 secondes

Val loss 0.9541186206231327 accuracy 0.879858672618866 macro_avg {'precision': 0.8828713936030749, 'recall': 0.8784922752829685, 'f1-score': 0.8778538292449707, 'support': 1132} weighted_avg {'precision': 0.8856776000815779, 'recall': 0.8798586572438163, 'f1-score': 0.8797755253078842, 'support': 1132}
 
----------
Epoch 13/40
time = 488.93 secondes

Train loss 0.10441090892515148 accuracy 0.9802592992782593 macro_avg {'precision': 0.9794845718966325, 'recall': 0.9797048143007034, 'f1-score': 0.9795638484449899, 'support': 10182} weighted_avg {'precision': 0.9803275513052511, 'recall': 0.9802592810842663, 'f1-score': 0.9802628398848975, 'support': 10182}
 
time = 14.75 secondes

Val loss 0.8988799220143693 accuracy 0.8745583295822144 macro_avg {'precision': 0.8814277598646584, 'recall': 0.8738627496219035, 'f1-score': 0.8739511900593356, 'support': 1132} weighted_avg {'precision': 0.8858681322468805, 'recall': 0.8745583038869258, 'f1-score': 0.876847167364503, 'support': 1132}
 
----------
Epoch 14/40
time = 489.73 secondes

Train loss 0.08451853798011269 accuracy 0.9827145934104919 macro_avg {'precision': 0.9823634188430204, 'recall': 0.9824499123150842, 'f1-score': 0.9823833808999947, 'support': 10182} weighted_avg {'precision': 0.9827651600725505, 'recall': 0.9827145943822432, 'f1-score': 0.9827185574201125, 'support': 10182}
 
time = 18.26 secondes

Val loss 1.005025987142392 accuracy 0.8666077852249146 macro_avg {'precision': 0.8707890007422545, 'recall': 0.8623199144754998, 'f1-score': 0.8620408912045308, 'support': 1132} weighted_avg {'precision': 0.8717789109663399, 'recall': 0.8666077738515902, 'f1-score': 0.8647975551135907, 'support': 1132}
 
----------
Epoch 15/40
time = 491.91 secondes

Train loss 0.09230599000317968 accuracy 0.9824199676513672 macro_avg {'precision': 0.9823548887811533, 'recall': 0.9823786354922104, 'f1-score': 0.9823358200226784, 'support': 10182} weighted_avg {'precision': 0.9825093061296726, 'recall': 0.982419956786486, 'f1-score': 0.9824330277513538, 'support': 10182}
 
time = 18.04 secondes

Val loss 0.7845906613662701 accuracy 0.8851590156555176 macro_avg {'precision': 0.8951839296464218, 'recall': 0.8860687816631868, 'f1-score': 0.8875806482059341, 'support': 1132} weighted_avg {'precision': 0.8934525128527322, 'recall': 0.8851590106007067, 'f1-score': 0.8864657235022194, 'support': 1132}
 
----------
Epoch 16/40
time = 487.17 secondes

Train loss 0.08120033956571945 accuracy 0.9857591986656189 macro_avg {'precision': 0.9856007649918759, 'recall': 0.985589411973374, 'f1-score': 0.9855879929316487, 'support': 10182} weighted_avg {'precision': 0.9857882740708496, 'recall': 0.9857591828717345, 'f1-score': 0.9857664248721059, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.8467162548196272 accuracy 0.8886925578117371 macro_avg {'precision': 0.8894714861259192, 'recall': 0.8910452145586675, 'f1-score': 0.8883126872628445, 'support': 1132} weighted_avg {'precision': 0.8950558166496053, 'recall': 0.8886925795053003, 'f1-score': 0.8899516681041303, 'support': 1132}
 
----------
Epoch 17/40
time = 487.28 secondes

Train loss 0.08028282645871948 accuracy 0.9842860102653503 macro_avg {'precision': 0.9845290160187709, 'recall': 0.9841880577887079, 'f1-score': 0.9843210876134163, 'support': 10182} weighted_avg {'precision': 0.9843540375810377, 'recall': 0.9842859948929483, 'f1-score': 0.9842830317126103, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.9497336844923807 accuracy 0.8816254734992981 macro_avg {'precision': 0.8873666179939917, 'recall': 0.8833658572109119, 'f1-score': 0.8828998120156791, 'support': 1132} weighted_avg {'precision': 0.8886393377323234, 'recall': 0.8816254416961131, 'f1-score': 0.8825970831400709, 'support': 1132}
 
----------
Epoch 18/40
time = 490.02 secondes

Train loss 0.07437754537806691 accuracy 0.9868395328521729 macro_avg {'precision': 0.9867719032975376, 'recall': 0.9869686569225546, 'f1-score': 0.9868560537388754, 'support': 10182} weighted_avg {'precision': 0.9868616052400053, 'recall': 0.9868395207228442, 'f1-score': 0.9868369893768763, 'support': 10182}
 
time = 17.09 secondes

Val loss 0.9334095772064757 accuracy 0.8772084712982178 macro_avg {'precision': 0.8905713211610389, 'recall': 0.8806413338281516, 'f1-score': 0.8798014196876822, 'support': 1132} weighted_avg {'precision': 0.8915907330242588, 'recall': 0.877208480565371, 'f1-score': 0.8784170098739621, 'support': 1132}
 
----------
Epoch 19/40
time = 488.29 secondes

Train loss 0.09132055171308819 accuracy 0.9840896129608154 macro_avg {'precision': 0.9842839487160475, 'recall': 0.9840497680018687, 'f1-score': 0.9841323301804465, 'support': 10182} weighted_avg {'precision': 0.9841800430700687, 'recall': 0.9840895698291102, 'f1-score': 0.9840991999695425, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.8979851967291529 accuracy 0.8833922147750854 macro_avg {'precision': 0.8852721517452874, 'recall': 0.8822380930033369, 'f1-score': 0.8821195781358651, 'support': 1132} weighted_avg {'precision': 0.8869370745239983, 'recall': 0.8833922261484098, 'f1-score': 0.883579286845738, 'support': 1132}
 
----------
Epoch 20/40
time = 485.94 secondes

Train loss 0.07078124692998816 accuracy 0.9886073470115662 macro_avg {'precision': 0.9882883552952432, 'recall': 0.9885152509074665, 'f1-score': 0.9883874603655458, 'support': 10182} weighted_avg {'precision': 0.9886287808102308, 'recall': 0.9886073462973876, 'f1-score': 0.9886044643734994, 'support': 10182}
 
time = 17.05 secondes

Val loss 0.9121021994102244 accuracy 0.879858672618866 macro_avg {'precision': 0.8863520453601899, 'recall': 0.8858818411917095, 'f1-score': 0.8824003912134566, 'support': 1132} weighted_avg {'precision': 0.8907662149939454, 'recall': 0.8798586572438163, 'f1-score': 0.8814693791356971, 'support': 1132}
 
----------
Epoch 21/40
time = 487.08 secondes

Train loss 0.07294998872044513 accuracy 0.9873306155204773 macro_avg {'precision': 0.986532473077764, 'recall': 0.9865166261139251, 'f1-score': 0.9865043176403641, 'support': 10182} weighted_avg {'precision': 0.9873672841744154, 'recall': 0.9873305833824396, 'f1-score': 0.987330229957416, 'support': 10182}
 
time = 16.95 secondes

Val loss 0.8688818541219955 accuracy 0.8860424160957336 macro_avg {'precision': 0.8862351848124492, 'recall': 0.8869942262601409, 'f1-score': 0.8838019377910195, 'support': 1132} weighted_avg {'precision': 0.8907075506545076, 'recall': 0.8860424028268551, 'f1-score': 0.88573891202981, 'support': 1132}
 
----------
Epoch 22/40
time = 490.66 secondes

Train loss 0.043440933120939086 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913243832135695, 'recall': 0.9911799788027315, 'f1-score': 0.9912445970561737, 'support': 10182} weighted_avg {'precision': 0.9914609482103978, 'recall': 0.9914555097230406, 'f1-score': 0.9914505544804166, 'support': 10182}
 
time = 15.58 secondes

Val loss 0.9318128447770838 accuracy 0.8878092169761658 macro_avg {'precision': 0.8963237600320598, 'recall': 0.889199630755362, 'f1-score': 0.8883786247394371, 'support': 1132} weighted_avg {'precision': 0.8956585814142959, 'recall': 0.8878091872791519, 'f1-score': 0.8875604069497222, 'support': 1132}
 
----------
Epoch 23/40
time = 491.01 secondes

Train loss 0.06255713016332239 accuracy 0.9885091781616211 macro_avg {'precision': 0.988523195874824, 'recall': 0.9882103683856995, 'f1-score': 0.988338273754849, 'support': 10182} weighted_avg {'precision': 0.9885446289318368, 'recall': 0.9885091337654685, 'f1-score': 0.9885004727756067, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.9402312323518472 accuracy 0.8878092169761658 macro_avg {'precision': 0.8987763811563193, 'recall': 0.8896794112269883, 'f1-score': 0.8910679558539568, 'support': 1132} weighted_avg {'precision': 0.8975640029252027, 'recall': 0.8878091872791519, 'f1-score': 0.8892913361189201, 'support': 1132}
 
----------
Epoch 24/40
time = 490.83 secondes

Train loss 0.055328569931412254 accuracy 0.989589512348175 macro_avg {'precision': 0.9893423849098216, 'recall': 0.9891398619656012, 'f1-score': 0.9892320066001252, 'support': 10182} weighted_avg {'precision': 0.9896097211723638, 'recall': 0.9895894716165783, 'f1-score': 0.9895909720870555, 'support': 10182}
 
time = 18.10 secondes

Val loss 0.8536099085987432 accuracy 0.8931095600128174 macro_avg {'precision': 0.8978794390144269, 'recall': 0.8952682902981536, 'f1-score': 0.8952666377968598, 'support': 1132} weighted_avg {'precision': 0.8965989555736836, 'recall': 0.8931095406360424, 'f1-score': 0.8934271640108543, 'support': 1132}
 
----------
Epoch 25/40
time = 492.02 secondes

Train loss 0.048025573856519906 accuracy 0.9914555549621582 macro_avg {'precision': 0.9910891263122237, 'recall': 0.9912474357616755, 'f1-score': 0.9911592092081717, 'support': 10182} weighted_avg {'precision': 0.9914795215813981, 'recall': 0.9914555097230406, 'f1-score': 0.9914586028952662, 'support': 10182}
 
time = 18.23 secondes

Val loss 0.9816776340711852 accuracy 0.8851590156555176 macro_avg {'precision': 0.89216978991629, 'recall': 0.8912719765222672, 'f1-score': 0.8882022192522887, 'support': 1132} weighted_avg {'precision': 0.8922891582191874, 'recall': 0.8851590106007067, 'f1-score': 0.8848010215787145, 'support': 1132}
 
----------
Epoch 26/40
time = 490.14 secondes

Train loss 0.053180109787220944 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901019634156555, 'recall': 0.9899631812789288, 'f1-score': 0.9900226691265948, 'support': 10182} weighted_avg {'precision': 0.9902853722822829, 'recall': 0.9902769593400118, 'f1-score': 0.9902710489264681, 'support': 10182}
 
time = 16.04 secondes

Val loss 0.8954135703127795 accuracy 0.8948763608932495 macro_avg {'precision': 0.9032181452001661, 'recall': 0.8966401913830161, 'f1-score': 0.8983986906619524, 'support': 1132} weighted_avg {'precision': 0.8994401272587367, 'recall': 0.8948763250883393, 'f1-score': 0.8956565251777344, 'support': 1132}
 
----------
Epoch 27/40
time = 484.89 secondes

Train loss 0.042838661891403104 accuracy 0.9928305149078369 macro_avg {'precision': 0.992779989232632, 'recall': 0.9925686410324687, 'f1-score': 0.9926652998691445, 'support': 10182} weighted_avg {'precision': 0.9928536683523782, 'recall': 0.9928304851699077, 'f1-score': 0.9928332035536895, 'support': 10182}
 
time = 13.95 secondes

Val loss 0.783622395410059 accuracy 0.8957597017288208 macro_avg {'precision': 0.9053960765158007, 'recall': 0.8976766010382423, 'f1-score': 0.8994368968521333, 'support': 1132} weighted_avg {'precision': 0.9031240259548763, 'recall': 0.8957597173144877, 'f1-score': 0.8972480218915037, 'support': 1132}
 
----------
Epoch 28/40
time = 488.09 secondes

Train loss 0.04538817257733406 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925276289487466, 'recall': 0.9924504435329224, 'f1-score': 0.9924583061202862, 'support': 10182} weighted_avg {'precision': 0.9924788647576538, 'recall': 0.9924376350422314, 'f1-score': 0.9924264228565537, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.8187132704896241 accuracy 0.898409903049469 macro_avg {'precision': 0.9047068451525082, 'recall': 0.9011550982814628, 'f1-score': 0.9017240528964837, 'support': 1132} weighted_avg {'precision': 0.9033973202378874, 'recall': 0.8984098939929329, 'f1-score': 0.8996291268308446, 'support': 1132}
 
----------
Epoch 29/40
time = 487.02 secondes

Train loss 0.03546970920377554 accuracy 0.9936162233352661 macro_avg {'precision': 0.993438009869314, 'recall': 0.9936223354618058, 'f1-score': 0.9935193618824207, 'support': 10182} weighted_avg {'precision': 0.9936573239949072, 'recall': 0.9936161854252603, 'f1-score': 0.9936261725135686, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.9601371724073571 accuracy 0.8913427591323853 macro_avg {'precision': 0.8963699808616876, 'recall': 0.8920662500095216, 'f1-score': 0.8910116232891095, 'support': 1132} weighted_avg {'precision': 0.897333147374894, 'recall': 0.8913427561837456, 'f1-score': 0.8911798464247624, 'support': 1132}
 
----------
Epoch 30/40
time = 485.73 secondes

Train loss 0.047092177982953363 accuracy 0.9927322864532471 macro_avg {'precision': 0.9926148432180856, 'recall': 0.9928958896739545, 'f1-score': 0.9927369345088103, 'support': 10182} weighted_avg {'precision': 0.9927693663149169, 'recall': 0.9927322726379886, 'f1-score': 0.9927331042465847, 'support': 10182}
 
time = 16.88 secondes

Val loss 0.8546571832748284 accuracy 0.9019434452056885 macro_avg {'precision': 0.9094320126124791, 'recall': 0.9035783027462891, 'f1-score': 0.9040339276222668, 'support': 1132} weighted_avg {'precision': 0.9082984916503419, 'recall': 0.9019434628975265, 'f1-score': 0.9025831044499247, 'support': 1132}
 
----------
Epoch 31/40
time = 486.96 secondes

Train loss 0.034184968343536494 accuracy 0.9947947859764099 macro_avg {'precision': 0.9948178065580633, 'recall': 0.9947239046346447, 'f1-score': 0.994765473560555, 'support': 10182} weighted_avg {'precision': 0.9948098324599354, 'recall': 0.9947947358082891, 'f1-score': 0.9947970880322522, 'support': 10182}
 
time = 17.00 secondes

Val loss 0.8772415368557759 accuracy 0.8975265026092529 macro_avg {'precision': 0.9010416020691002, 'recall': 0.9000388807733468, 'f1-score': 0.8983944025432467, 'support': 1132} weighted_avg {'precision': 0.9043372530067465, 'recall': 0.8975265017667845, 'f1-score': 0.8988259660448761, 'support': 1132}
 
----------
Epoch 32/40
time = 487.65 secondes

Train loss 0.02907559409452214 accuracy 0.994892954826355 macro_avg {'precision': 0.9946961216282444, 'recall': 0.9947656267053133, 'f1-score': 0.9947177909580999, 'support': 10182} weighted_avg {'precision': 0.9949175162410399, 'recall': 0.9948929483402082, 'f1-score': 0.9948926388513117, 'support': 10182}
 
time = 14.17 secondes

Val loss 0.8864078008758645 accuracy 0.9063604474067688 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}
 
----------
Epoch 33/40
time = 491.51 secondes

Train loss 0.018558030947326123 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961598519809417, 'recall': 0.9962079437863531, 'f1-score': 0.9961809548320988, 'support': 10182} weighted_avg {'precision': 0.9961749802862734, 'recall': 0.9961697112551562, 'f1-score': 0.9961695639904631, 'support': 10182}
 
time = 17.70 secondes

Val loss 0.9240517644173732 accuracy 0.8948763608932495 macro_avg {'precision': 0.8992828271654106, 'recall': 0.8981555553207621, 'f1-score': 0.8970924601966054, 'support': 1132} weighted_avg {'precision': 0.8993005922681244, 'recall': 0.8948763250883393, 'f1-score': 0.8954393011399944, 'support': 1132}
 
----------
Epoch 34/40
time = 495.19 secondes

Train loss 0.015434786263873118 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973201221154783, 'recall': 0.9973587430373227, 'f1-score': 0.9973356899470944, 'support': 10182} weighted_avg {'precision': 0.9972579411593034, 'recall': 0.9972500491062659, 'f1-score': 0.9972501322836794, 'support': 10182}
 
time = 14.32 secondes

Val loss 0.970689211645357 accuracy 0.9010601043701172 macro_avg {'precision': 0.9081098265003671, 'recall': 0.9048019091298014, 'f1-score': 0.9048334082347476, 'support': 1132} weighted_avg {'precision': 0.9062698197846981, 'recall': 0.901060070671378, 'f1-score': 0.9019115077892547, 'support': 1132}
 
----------
Epoch 35/40
time = 490.50 secondes

Train loss 0.015224112326950704 accuracy 0.9970536828041077 macro_avg {'precision': 0.9971078988560829, 'recall': 0.9971290395992076, 'f1-score': 0.9971160947116736, 'support': 10182} weighted_avg {'precision': 0.9970564643820542, 'recall': 0.9970536240424278, 'f1-score': 0.9970526125758338, 'support': 10182}
 
time = 13.96 secondes

Val loss 1.0586093372875836 accuracy 0.8860424160957336 macro_avg {'precision': 0.8901913220712654, 'recall': 0.8899745896660238, 'f1-score': 0.887978243966247, 'support': 1132} weighted_avg {'precision': 0.8917902826546585, 'recall': 0.8860424028268551, 'f1-score': 0.8867095002665827, 'support': 1132}
 
----------
Epoch 36/40
time = 490.58 secondes

Train loss 0.011458166437499629 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977290675211758, 'recall': 0.9977344511960915, 'f1-score': 0.9977275275558508, 'support': 10182} weighted_avg {'precision': 0.9976505839908223, 'recall': 0.9976428992339422, 'f1-score': 0.9976422779565713, 'support': 10182}
 
time = 18.39 secondes

Val loss 1.0479406079636173 accuracy 0.8895759582519531 macro_avg {'precision': 0.8946014408162679, 'recall': 0.8946823636762374, 'f1-score': 0.8924248315725173, 'support': 1132} weighted_avg {'precision': 0.8951866512472697, 'recall': 0.8895759717314488, 'f1-score': 0.8900919336625984, 'support': 1132}
 
----------
Epoch 37/40
time = 491.32 secondes

Train loss 0.012433224166921986 accuracy 0.9976429343223572 macro_avg {'precision': 0.997666933043128, 'recall': 0.997660764647519, 'f1-score': 0.9976617643128012, 'support': 10182} weighted_avg {'precision': 0.997650076857833, 'recall': 0.9976428992339422, 'f1-score': 0.9976444077011188, 'support': 10182}
 
time = 13.64 secondes

Val loss 1.0875365298662716 accuracy 0.880742073059082 macro_avg {'precision': 0.8920760627723396, 'recall': 0.8828426313127318, 'f1-score': 0.883561513370473, 'support': 1132} weighted_avg {'precision': 0.8909768298742995, 'recall': 0.8807420494699647, 'f1-score': 0.8820504779987526, 'support': 1132}
 
----------
Epoch 38/40
time = 486.75 secondes

Train loss 0.00736699988197553 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986724793607479, 'recall': 0.9986177782746211, 'f1-score': 0.9986445191101117, 'support': 10182} weighted_avg {'precision': 0.9986261459605219, 'recall': 0.998625024553133, 'f1-score': 0.9986249982978715, 'support': 10182}
 
time = 14.33 secondes

Val loss 0.9899729756264823 accuracy 0.8966431021690369 macro_avg {'precision': 0.9033257307121026, 'recall': 0.8995797686037006, 'f1-score': 0.899380161965453, 'support': 1132} weighted_avg {'precision': 0.9008787333203346, 'recall': 0.8966431095406361, 'f1-score': 0.8966693539605891, 'support': 1132}
 
----------
Epoch 39/40
time = 487.93 secondes

Train loss 0.005694779054336971 accuracy 0.998919665813446 macro_avg {'precision': 0.9989580038204101, 'recall': 0.9989386812541543, 'f1-score': 0.9989469044544748, 'support': 10182} weighted_avg {'precision': 0.9989227880789354, 'recall': 0.9989196621488902, 'f1-score': 0.9989197384473645, 'support': 10182}
 
time = 14.26 secondes

Val loss 0.9627102215352121 accuracy 0.9037102460861206 macro_avg {'precision': 0.9093682933925138, 'recall': 0.9059448150132239, 'f1-score': 0.9058614675898525, 'support': 1132} weighted_avg {'precision': 0.9079005331950925, 'recall': 0.9037102473498233, 'f1-score': 0.9041046676552479, 'support': 1132}
 
----------
Epoch 40/40
time = 487.81 secondes

Train loss 0.00132249186964221 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994329792780207, 'recall': 0.9994311540244109, 'f1-score': 0.9994316208258944, 'support': 10182} weighted_avg {'precision': 0.9994118385793007, 'recall': 0.9994107248084856, 'f1-score': 0.9994108183455855, 'support': 10182}
 
time = 17.08 secondes

Val loss 0.9609772389760853 accuracy 0.9037102460861206 macro_avg {'precision': 0.9086078944814305, 'recall': 0.9057185509194206, 'f1-score': 0.9053069769314114, 'support': 1132} weighted_avg {'precision': 0.9082412875438725, 'recall': 0.9037102473498233, 'f1-score': 0.9040503657343512, 'support': 1132}
 
----------
best_accuracy 0.9063604474067688 best_epoch 32 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}

average train time 489.5902926445007

average val time 15.876436096429824
 
time = 108.31 secondes

test_accuracy 0.828066885471344 macro_avg {'precision': 0.8274202315415042, 'recall': 0.821766739596894, 'f1-score': 0.8224073284679108, 'support': 7532} weighted_avg {'precision': 0.8336561868218115, 'recall': 0.8280669144981413, 'f1-score': 0.8287879284705231, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 69.49 GiB already allocated; 161.62 MiB free; 70.56 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 68.59 GiB already allocated; 33.62 MiB free; 70.69 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 79.21 GiB total capacity; 66.38 GiB already allocated; 495.62 MiB free; 70.23 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 69.37 GiB already allocated; 405.62 MiB free; 70.32 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_4
----------
Epoch 1/40
time = 705.30 secondes

Train loss 1.1060675276060306 accuracy 0.6868984699249268 macro_avg {'precision': 0.6912446852383314, 'recall': 0.6731791282505873, 'f1-score': 0.6712349620356672, 'support': 10182} weighted_avg {'precision': 0.6988909620616774, 'recall': 0.6868984482419956, 'f1-score': 0.6836668714808398, 'support': 10182}
 
time = 26.07 secondes

Val loss 0.5286669056390373 accuracy 0.8471731543540955 macro_avg {'precision': 0.8472686007983714, 'recall': 0.8357032277465798, 'f1-score': 0.8279019482566463, 'support': 1132} weighted_avg {'precision': 0.8485481188132882, 'recall': 0.8471731448763251, 'f1-score': 0.8378357951330426, 'support': 1132}
 
----------
Epoch 2/40
time = 682.32 secondes

Train loss 0.3978598882419348 accuracy 0.8833235502243042 macro_avg {'precision': 0.8759068462412211, 'recall': 0.8751244981793697, 'f1-score': 0.875047420180022, 'support': 10182} weighted_avg {'precision': 0.8824652770853887, 'recall': 0.8833235120801414, 'f1-score': 0.8825159713444198, 'support': 10182}
 
time = 19.46 secondes

Val loss 0.4057910417954267 accuracy 0.8869258165359497 macro_avg {'precision': 0.8889799665980631, 'recall': 0.8861582263071087, 'f1-score': 0.8839589378606589, 'support': 1132} weighted_avg {'precision': 0.8915387292246331, 'recall': 0.8869257950530035, 'f1-score': 0.8854585051980637, 'support': 1132}
 
----------
Epoch 3/40
time = 596.00 secondes

Train loss 0.23685451580015607 accuracy 0.9334119558334351 macro_avg {'precision': 0.9301979073177152, 'recall': 0.9293517586328252, 'f1-score': 0.9296644330094257, 'support': 10182} weighted_avg {'precision': 0.9334374723906101, 'recall': 0.9334119033588686, 'f1-score': 0.9333293359157556, 'support': 10182}
 
time = 20.68 secondes

Val loss 0.5218494231156795 accuracy 0.8825088143348694 macro_avg {'precision': 0.885712851373954, 'recall': 0.8848041534201124, 'f1-score': 0.8813553475093755, 'support': 1132} weighted_avg {'precision': 0.8909162139592807, 'recall': 0.8825088339222615, 'f1-score': 0.8827363830550884, 'support': 1132}
 
----------
Epoch 4/40
time = 600.61 secondes

Train loss 0.1841260397070624 accuracy 0.9513848423957825 macro_avg {'precision': 0.9493771868075461, 'recall': 0.9485518198694969, 'f1-score': 0.9488723013099912, 'support': 10182} weighted_avg {'precision': 0.9515848942706286, 'recall': 0.9513847967000589, 'f1-score': 0.951394518218109, 'support': 10182}
 
time = 27.47 secondes

Val loss 0.5575415709377332 accuracy 0.8939929604530334 macro_avg {'precision': 0.8969716363061095, 'recall': 0.8983188436739713, 'f1-score': 0.8934728443982068, 'support': 1132} weighted_avg {'precision': 0.9009013961173981, 'recall': 0.8939929328621908, 'f1-score': 0.8928251713474634, 'support': 1132}
 
----------
Epoch 5/40
time = 737.69 secondes

Train loss 0.1618475667215603 accuracy 0.9597328901290894 macro_avg {'precision': 0.9585814501329857, 'recall': 0.9582446219287704, 'f1-score': 0.9583543266615256, 'support': 10182} weighted_avg {'precision': 0.9599442689185511, 'recall': 0.9597328619131801, 'f1-score': 0.9597799729996482, 'support': 10182}
 
time = 27.59 secondes

Val loss 0.6505570747482945 accuracy 0.8851590156555176 macro_avg {'precision': 0.89922688978667, 'recall': 0.8837955803108095, 'f1-score': 0.8845939451625988, 'support': 1132} weighted_avg {'precision': 0.8955478358911739, 'recall': 0.8851590106007067, 'f1-score': 0.8832450065119175, 'support': 1132}
 
----------
Epoch 6/40
time = 663.77 secondes

Train loss 0.13605199301077325 accuracy 0.9662148952484131 macro_avg {'precision': 0.9650446810491384, 'recall': 0.9650979604878012, 'f1-score': 0.9650446251308138, 'support': 10182} weighted_avg {'precision': 0.966290868694431, 'recall': 0.966214889019839, 'f1-score': 0.9662259015033429, 'support': 10182}
 
time = 20.24 secondes

Val loss 0.690308154780339 accuracy 0.8816254734992981 macro_avg {'precision': 0.8948453305151413, 'recall': 0.876315155342611, 'f1-score': 0.8793078137885797, 'support': 1132} weighted_avg {'precision': 0.8912771610085204, 'recall': 0.8816254416961131, 'f1-score': 0.8805164929925261, 'support': 1132}
 
----------
Epoch 7/40
time = 591.54 secondes

Train loss 0.13388681847423395 accuracy 0.9697505831718445 macro_avg {'precision': 0.96871088051502, 'recall': 0.9684726531550311, 'f1-score': 0.9685216841963967, 'support': 10182} weighted_avg {'precision': 0.9698889276833448, 'recall': 0.9697505401689256, 'f1-score': 0.9697530159155721, 'support': 10182}
 
time = 24.14 secondes

Val loss 0.5743945597787388 accuracy 0.9028268456459045 macro_avg {'precision': 0.907319086340857, 'recall': 0.9073387317926096, 'f1-score': 0.9045282429061057, 'support': 1132} weighted_avg {'precision': 0.9101459427296902, 'recall': 0.9028268551236749, 'f1-score': 0.903542176057734, 'support': 1132}
 
----------
Epoch 8/40
time = 696.13 secondes

Train loss 0.13252034265242058 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684956057779385, 'recall': 0.9685064743185684, 'f1-score': 0.9684294011763324, 'support': 10182} weighted_avg {'precision': 0.9698175682747254, 'recall': 0.9696523276370065, 'f1-score': 0.9696663239708587, 'support': 10182}
 
time = 26.88 secondes

Val loss 0.5323867150660256 accuracy 0.9178445339202881 macro_avg {'precision': 0.9216557235264993, 'recall': 0.9184208288807696, 'f1-score': 0.9186140388009134, 'support': 1132} weighted_avg {'precision': 0.9200747697275344, 'recall': 0.9178445229681979, 'f1-score': 0.9176474145586859, 'support': 1132}
 
----------
Epoch 9/40
time = 696.58 secondes

Train loss 0.10771712561635435 accuracy 0.9758397340774536 macro_avg {'precision': 0.9752500526860203, 'recall': 0.9750574344323087, 'f1-score': 0.9751295162105595, 'support': 10182} weighted_avg {'precision': 0.9758576934947365, 'recall': 0.9758397171479081, 'f1-score': 0.9758240595121059, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.5117967357382697 accuracy 0.9178445339202881 macro_avg {'precision': 0.9220901510027393, 'recall': 0.9167387930776668, 'f1-score': 0.9181575848274892, 'support': 1132} weighted_avg {'precision': 0.9198526828202191, 'recall': 0.9178445229681979, 'f1-score': 0.9177038508320591, 'support': 1132}
 
----------
Epoch 10/40
time = 640.72 secondes

Train loss 0.10899010083495217 accuracy 0.9778040051460266 macro_avg {'precision': 0.9777540238752934, 'recall': 0.9771476432101253, 'f1-score': 0.9774216100481932, 'support': 10182} weighted_avg {'precision': 0.9778292142296359, 'recall': 0.9778039677862895, 'f1-score': 0.9777891903176193, 'support': 10182}
 
time = 19.31 secondes

Val loss 0.6681109112974348 accuracy 0.9054770469665527 macro_avg {'precision': 0.9097256877636044, 'recall': 0.907997507579536, 'f1-score': 0.9050312726449965, 'support': 1132} weighted_avg {'precision': 0.9132857715872643, 'recall': 0.9054770318021201, 'f1-score': 0.9054054583341857, 'support': 1132}
 
----------
Epoch 11/40
time = 609.36 secondes

Train loss 0.10413005455183977 accuracy 0.9786878824234009 macro_avg {'precision': 0.978044083335637, 'recall': 0.9781025492966398, 'f1-score': 0.9780429513234588, 'support': 10182} weighted_avg {'precision': 0.9787549561320905, 'recall': 0.9786878805735612, 'f1-score': 0.9786917395363781, 'support': 10182}
 
time = 27.80 secondes

Val loss 0.6473687676285331 accuracy 0.9063604474067688 macro_avg {'precision': 0.9180492484949221, 'recall': 0.9076285562335175, 'f1-score': 0.9086999320878901, 'support': 1132} weighted_avg {'precision': 0.9160186837305626, 'recall': 0.9063604240282686, 'f1-score': 0.9070516650932384, 'support': 1132}
 
----------
Epoch 12/40
time = 741.65 secondes

Train loss 0.10119091835575839 accuracy 0.9797682762145996 macro_avg {'precision': 0.9795000177219366, 'recall': 0.9791976476251193, 'f1-score': 0.9793133155370329, 'support': 10182} weighted_avg {'precision': 0.97980539941072, 'recall': 0.979768218424671, 'f1-score': 0.9797509468823947, 'support': 10182}
 
time = 27.93 secondes

Val loss 0.6771856486325113 accuracy 0.9045936465263367 macro_avg {'precision': 0.9102385137720266, 'recall': 0.9049482055476844, 'f1-score': 0.9048612354083737, 'support': 1132} weighted_avg {'precision': 0.9095680500156623, 'recall': 0.9045936395759717, 'f1-score': 0.9046403421033066, 'support': 1132}
 
----------
Epoch 13/40
time = 639.81 secondes

Train loss 0.08585803825886126 accuracy 0.9830092787742615 macro_avg {'precision': 0.9827604179509757, 'recall': 0.9824351702377474, 'f1-score': 0.9825860071422369, 'support': 10182} weighted_avg {'precision': 0.9830270698992964, 'recall': 0.9830092319780004, 'f1-score': 0.9830069203379079, 'support': 10182}
 
time = 19.00 secondes

Val loss 0.5900274603154172 accuracy 0.916961133480072 macro_avg {'precision': 0.9209412309698781, 'recall': 0.9168673652720715, 'f1-score': 0.9174175716627484, 'support': 1132} weighted_avg {'precision': 0.9201833934027098, 'recall': 0.9169611307420494, 'f1-score': 0.9170738912461951, 'support': 1132}
 
----------
Epoch 14/40
time = 587.76 secondes

Train loss 0.09248712605375868 accuracy 0.9827145934104919 macro_avg {'precision': 0.9813820088136511, 'recall': 0.9818019907841379, 'f1-score': 0.9815589595694174, 'support': 10182} weighted_avg {'precision': 0.9828194248902724, 'recall': 0.9827145943822432, 'f1-score': 0.9827364401365913, 'support': 10182}
 
time = 23.53 secondes

Val loss 0.5817499518452678 accuracy 0.9231448769569397 macro_avg {'precision': 0.9295499052856476, 'recall': 0.9234835227956328, 'f1-score': 0.9253898049959355, 'support': 1132} weighted_avg {'precision': 0.9261676282878981, 'recall': 0.9231448763250883, 'f1-score': 0.9235688303951032, 'support': 1132}
 
----------
Epoch 15/40
time = 695.72 secondes

Train loss 0.08148616211262409 accuracy 0.9845806360244751 macro_avg {'precision': 0.9838972371720296, 'recall': 0.9838564616591607, 'f1-score': 0.983863810837829, 'support': 10182} weighted_avg {'precision': 0.9845882445974019, 'recall': 0.9845806324887055, 'f1-score': 0.9845712056234294, 'support': 10182}
 
time = 27.81 secondes

Val loss 0.6428248902748365 accuracy 0.9116607904434204 macro_avg {'precision': 0.9168341631872643, 'recall': 0.9130958831324026, 'f1-score': 0.9129289267015068, 'support': 1132} weighted_avg {'precision': 0.9162579266627331, 'recall': 0.911660777385159, 'f1-score': 0.911837507014717, 'support': 1132}
 
----------
Epoch 16/40
time = 703.04 secondes

Train loss 0.08350212321748933 accuracy 0.9848753213882446 macro_avg {'precision': 0.984127391242002, 'recall': 0.9839850491505638, 'f1-score': 0.9840462283090234, 'support': 10182} weighted_avg {'precision': 0.984880727412725, 'recall': 0.9848752700844627, 'f1-score': 0.9848683678863138, 'support': 10182}
 
time = 27.39 secondes

Val loss 0.691425802100972 accuracy 0.9063604474067688 macro_avg {'precision': 0.9152816118054625, 'recall': 0.9037073938222822, 'f1-score': 0.9041287672800747, 'support': 1132} weighted_avg {'precision': 0.9135942440439255, 'recall': 0.9063604240282686, 'f1-score': 0.9053957171937761, 'support': 1132}
 
----------
Epoch 17/40
time = 653.95 secondes

Train loss 0.08545175178308281 accuracy 0.9836967587471008 macro_avg {'precision': 0.9831744370368641, 'recall': 0.9834052312170941, 'f1-score': 0.9832617373784835, 'support': 10182} weighted_avg {'precision': 0.9837752317975386, 'recall': 0.9836967197014339, 'f1-score': 0.9837082719040301, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.7905226800173462 accuracy 0.9010601043701172 macro_avg {'precision': 0.908133028988131, 'recall': 0.9023480054597346, 'f1-score': 0.9015914277488009, 'support': 1132} weighted_avg {'precision': 0.9095412038744146, 'recall': 0.901060070671378, 'f1-score': 0.9015176035500834, 'support': 1132}
 
----------
Epoch 18/40
time = 607.97 secondes

Train loss 0.07429239696775224 accuracy 0.9863485097885132 macro_avg {'precision': 0.9862253378626212, 'recall': 0.9863236402798213, 'f1-score': 0.9862670808272161, 'support': 10182} weighted_avg {'precision': 0.9863641512937589, 'recall': 0.9863484580632489, 'f1-score': 0.9863487745563073, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.7154949730941387 accuracy 0.9045936465263367 macro_avg {'precision': 0.9122740610805613, 'recall': 0.9079966677160826, 'f1-score': 0.9062272244050437, 'support': 1132} weighted_avg {'precision': 0.9128248465382911, 'recall': 0.9045936395759717, 'f1-score': 0.9043473336959126, 'support': 1132}
 
----------
Epoch 19/40
time = 711.02 secondes

Train loss 0.06322611827293471 accuracy 0.9884109497070312 macro_avg {'precision': 0.9883716232952142, 'recall': 0.988385654130053, 'f1-score': 0.9883696257652099, 'support': 10182} weighted_avg {'precision': 0.9884523009944993, 'recall': 0.9884109212335495, 'f1-score': 0.9884231872355632, 'support': 10182}
 
time = 28.27 secondes

Val loss 0.6903213634339946 accuracy 0.9143109321594238 macro_avg {'precision': 0.9165861629374893, 'recall': 0.9131187961458499, 'f1-score': 0.9136065339862915, 'support': 1132} weighted_avg {'precision': 0.916367592050385, 'recall': 0.9143109540636042, 'f1-score': 0.9139502695336543, 'support': 1132}
 
----------
Epoch 20/40
time = 703.91 secondes

Train loss 0.06370170586600139 accuracy 0.987625241279602 macro_avg {'precision': 0.9876622272064459, 'recall': 0.9875979682749616, 'f1-score': 0.9876090207893835, 'support': 10182} weighted_avg {'precision': 0.9876805295241795, 'recall': 0.9876252209781968, 'f1-score': 0.9876313555066041, 'support': 10182}
 
time = 26.43 secondes

Val loss 0.8140881195395708 accuracy 0.8992933034896851 macro_avg {'precision': 0.9101433630108735, 'recall': 0.903807546291335, 'f1-score': 0.9028787486834874, 'support': 1132} weighted_avg {'precision': 0.9099515369987482, 'recall': 0.8992932862190812, 'f1-score': 0.9000997394107609, 'support': 1132}
 
----------
Epoch 21/40
time = 611.63 secondes

Train loss 0.06980787126894868 accuracy 0.9870359897613525 macro_avg {'precision': 0.9869789224145114, 'recall': 0.9869577896506447, 'f1-score': 0.9869430527920601, 'support': 10182} weighted_avg {'precision': 0.9870891977591097, 'recall': 0.9870359457866824, 'f1-score': 0.9870365318199881, 'support': 10182}
 
time = 18.35 secondes

Val loss 0.583161075158835 accuracy 0.9257950782775879 macro_avg {'precision': 0.9306286574728816, 'recall': 0.9269232561441803, 'f1-score': 0.9273308939536824, 'support': 1132} weighted_avg {'precision': 0.9291192950243722, 'recall': 0.9257950530035336, 'f1-score': 0.9259807252188786, 'support': 1132}
 
----------
Epoch 22/40
time = 625.28 secondes

Train loss 0.04929591415242001 accuracy 0.9905716180801392 macro_avg {'precision': 0.9901913120462951, 'recall': 0.9903451313292176, 'f1-score': 0.9902603738465654, 'support': 10182} weighted_avg {'precision': 0.9905932003493267, 'recall': 0.990571596935769, 'f1-score': 0.9905756010607671, 'support': 10182}
 
time = 25.32 secondes

Val loss 0.597238124483597 accuracy 0.9204947352409363 macro_avg {'precision': 0.9214044830058903, 'recall': 0.9201898065722419, 'f1-score': 0.9194187957298624, 'support': 1132} weighted_avg {'precision': 0.9216081116755768, 'recall': 0.9204946996466431, 'f1-score': 0.9197343243039526, 'support': 1132}
 
----------
Epoch 23/40
time = 696.97 secondes

Train loss 0.054166213144039535 accuracy 0.9901787638664246 macro_avg {'precision': 0.9899661030482336, 'recall': 0.989863192536187, 'f1-score': 0.9898999768862209, 'support': 10182} weighted_avg {'precision': 0.9902179472577962, 'recall': 0.9901787468080927, 'f1-score': 0.9901844723661855, 'support': 10182}
 
time = 26.60 secondes

Val loss 0.8195115862923353 accuracy 0.898409903049469 macro_avg {'precision': 0.9169869687624589, 'recall': 0.9045926618688374, 'f1-score': 0.9032761519159453, 'support': 1132} weighted_avg {'precision': 0.9193404920757998, 'recall': 0.8984098939929329, 'f1-score': 0.9005864377142849, 'support': 1132}
 
----------
Epoch 24/40
time = 696.79 secondes

Train loss 0.04356538374605625 accuracy 0.9922412633895874 macro_avg {'precision': 0.9923073718705743, 'recall': 0.9923324505639659, 'f1-score': 0.9923132205787455, 'support': 10182} weighted_avg {'precision': 0.992259492365566, 'recall': 0.9922412099783933, 'f1-score': 0.9922434598375655, 'support': 10182}
 
time = 26.36 secondes

Val loss 0.6636610788796453 accuracy 0.9204947352409363 macro_avg {'precision': 0.9245280401830843, 'recall': 0.9239281468705249, 'f1-score': 0.9232237470485624, 'support': 1132} weighted_avg {'precision': 0.9232758144280496, 'recall': 0.9204946996466431, 'f1-score': 0.9208297858338002, 'support': 1132}
 
----------
Epoch 25/40
time = 623.56 secondes

Train loss 0.04442561767454675 accuracy 0.9919465780258179 macro_avg {'precision': 0.9917652364253609, 'recall': 0.9917758383552087, 'f1-score': 0.9917495403902894, 'support': 10182} weighted_avg {'precision': 0.9919777758763085, 'recall': 0.9919465723826361, 'f1-score': 0.9919419169078556, 'support': 10182}
 
time = 19.38 secondes

Val loss 0.7743988546843494 accuracy 0.9098939895629883 macro_avg {'precision': 0.9149703794158031, 'recall': 0.9129398289623982, 'f1-score': 0.912640761480574, 'support': 1132} weighted_avg {'precision': 0.9133097658672248, 'recall': 0.9098939929328622, 'f1-score': 0.9102983167401695, 'support': 1132}
 
----------
Epoch 26/40
time = 593.51 secondes

Train loss 0.04405577227414343 accuracy 0.9921430349349976 macro_avg {'precision': 0.9923405245527064, 'recall': 0.9921843435335809, 'f1-score': 0.992251753610546, 'support': 10182} weighted_avg {'precision': 0.9921698885790088, 'recall': 0.9921429974464742, 'f1-score': 0.992145658635006, 'support': 10182}
 
time = 21.29 secondes

Val loss 0.7370792464841454 accuracy 0.9187279343605042 macro_avg {'precision': 0.9251129823915983, 'recall': 0.9203312833194099, 'f1-score': 0.9204582891422112, 'support': 1132} weighted_avg {'precision': 0.9231320332087978, 'recall': 0.9187279151943463, 'f1-score': 0.918658660048929, 'support': 1132}
 
----------
Epoch 27/40
time = 700.73 secondes

Train loss 0.047902431881980984 accuracy 0.9918484091758728 macro_avg {'precision': 0.9918177646233962, 'recall': 0.9918984406004878, 'f1-score': 0.991850270401045, 'support': 10182} weighted_avg {'precision': 0.9918524349644825, 'recall': 0.991848359850717, 'f1-score': 0.9918424089212325, 'support': 10182}
 
time = 27.95 secondes

Val loss 0.7159251871939567 accuracy 0.9151943325996399 macro_avg {'precision': 0.9172010831330697, 'recall': 0.9177046019317782, 'f1-score': 0.9164633249642697, 'support': 1132} weighted_avg {'precision': 0.917211976398288, 'recall': 0.9151943462897526, 'f1-score': 0.9153023465156732, 'support': 1132}
 
----------
Epoch 28/40
time = 713.01 secondes

Train loss 0.05265458361329188 accuracy 0.9922412633895874 macro_avg {'precision': 0.9919754250427623, 'recall': 0.9917530973833502, 'f1-score': 0.9918515435781348, 'support': 10182} weighted_avg {'precision': 0.9922523550140555, 'recall': 0.9922412099783933, 'f1-score': 0.9922346623108822, 'support': 10182}
 
time = 26.72 secondes

Val loss 0.6761692108318552 accuracy 0.9125441908836365 macro_avg {'precision': 0.9144155609191962, 'recall': 0.9132053676806366, 'f1-score': 0.9117773590662427, 'support': 1132} weighted_avg {'precision': 0.9163984599451592, 'recall': 0.9125441696113075, 'f1-score': 0.9123992584244972, 'support': 1132}
 
----------
Epoch 29/40
time = 623.68 secondes

Train loss 0.03723010137813049 accuracy 0.9930269122123718 macro_avg {'precision': 0.9923969087037925, 'recall': 0.9926255276146634, 'f1-score': 0.9924925233064312, 'support': 10182} weighted_avg {'precision': 0.9930762628268881, 'recall': 0.9930269102337458, 'f1-score': 0.99303594577261, 'support': 10182}
 
time = 23.72 secondes

Val loss 0.7755163902462735 accuracy 0.9054770469665527 macro_avg {'precision': 0.9082705504754018, 'recall': 0.8984981993344098, 'f1-score': 0.895968898392149, 'support': 1132} weighted_avg {'precision': 0.9101828245999619, 'recall': 0.9054770318021201, 'f1-score': 0.9021662389586872, 'support': 1132}
 
----------
Epoch 30/40
time = 676.55 secondes

Train loss 0.0331371460849127 accuracy 0.9944019317626953 macro_avg {'precision': 0.993815474965601, 'recall': 0.9935848967060853, 'f1-score': 0.9936953334805307, 'support': 10182} weighted_avg {'precision': 0.9943958958782103, 'recall': 0.9944018856806128, 'f1-score': 0.9943948538416383, 'support': 10182}
 
time = 28.45 secondes

Val loss 0.7394706521957066 accuracy 0.9107773900032043 macro_avg {'precision': 0.9125390272635909, 'recall': 0.9135206647238296, 'f1-score': 0.9113728786671272, 'support': 1132} weighted_avg {'precision': 0.9135388641660348, 'recall': 0.9107773851590106, 'f1-score': 0.9104671511381013, 'support': 1132}
 
----------
Epoch 31/40
time = 708.89 secondes

Train loss 0.03652404040292528 accuracy 0.9934197664260864 macro_avg {'precision': 0.9933030976243387, 'recall': 0.9933397725708912, 'f1-score': 0.9933056316481498, 'support': 10182} weighted_avg {'precision': 0.9934494477268754, 'recall': 0.9934197603614221, 'f1-score': 0.9934184128852765, 'support': 10182}
 
time = 28.74 secondes

Val loss 0.6802429843874436 accuracy 0.9240282773971558 macro_avg {'precision': 0.9269612525650874, 'recall': 0.9259771744489447, 'f1-score': 0.9250672014461012, 'support': 1132} weighted_avg {'precision': 0.926416227058555, 'recall': 0.9240282685512368, 'f1-score': 0.9238386514698844, 'support': 1132}
 
----------
Epoch 32/40
time = 682.71 secondes

Train loss 0.036610273318086514 accuracy 0.9947947859764099 macro_avg {'precision': 0.9947167792275721, 'recall': 0.9945818100179318, 'f1-score': 0.9946402361688941, 'support': 10182} weighted_avg {'precision': 0.9948061784591095, 'recall': 0.9947947358082891, 'f1-score': 0.9947927171417783, 'support': 10182}
 
time = 22.80 secondes

Val loss 0.6812933082429469 accuracy 0.9204947352409363 macro_avg {'precision': 0.9228387142474617, 'recall': 0.9199797358237835, 'f1-score': 0.920161694281958, 'support': 1132} weighted_avg {'precision': 0.921647023239589, 'recall': 0.9204946996466431, 'f1-score': 0.9198579182834276, 'support': 1132}
 
----------
Epoch 33/40
time = 611.77 secondes

Train loss 0.025893018248746298 accuracy 0.9949911832809448 macro_avg {'precision': 0.9950161227926675, 'recall': 0.9948893439284221, 'f1-score': 0.9949479431660991, 'support': 10182} weighted_avg {'precision': 0.99500781277529, 'recall': 0.9949911608721272, 'f1-score': 0.9949946954804524, 'support': 10182}
 
time = 21.34 secondes

Val loss 0.6255771583172146 accuracy 0.926678478717804 macro_avg {'precision': 0.932046484079858, 'recall': 0.9269041044438355, 'f1-score': 0.9284069573755875, 'support': 1132} weighted_avg {'precision': 0.9287665040191243, 'recall': 0.926678445229682, 'f1-score': 0.9266992759868344, 'support': 1132}
 
----------
Epoch 34/40
time = 735.10 secondes

Train loss 0.020180653476325024 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960735996777347, 'recall': 0.9961860290492238, 'f1-score': 0.9961281745161272, 'support': 10182} weighted_avg {'precision': 0.9961715956414416, 'recall': 0.9961697112551562, 'f1-score': 0.9961690286032697, 'support': 10182}
 
time = 28.21 secondes

Val loss 0.6108652519036132 accuracy 0.9302120208740234 macro_avg {'precision': 0.9333181761873073, 'recall': 0.931443065277411, 'f1-score': 0.9311875672952515, 'support': 1132} weighted_avg {'precision': 0.9319582665519985, 'recall': 0.9302120141342756, 'f1-score': 0.929828629530147, 'support': 1132}
 
----------
Epoch 35/40
time = 703.67 secondes

Train loss 0.013384737196130364 accuracy 0.996857225894928 macro_avg {'precision': 0.9969160809565508, 'recall': 0.9969438673604017, 'f1-score': 0.996927717825192, 'support': 10182} weighted_avg {'precision': 0.9968630197924128, 'recall': 0.9968571989785897, 'f1-score': 0.9968578391907479, 'support': 10182}
 
time = 28.31 secondes

Val loss 0.7458468108792992 accuracy 0.9125441908836365 macro_avg {'precision': 0.920039994825761, 'recall': 0.9149433765425361, 'f1-score': 0.9151550703675154, 'support': 1132} weighted_avg {'precision': 0.9183281306535528, 'recall': 0.9125441696113075, 'f1-score': 0.9129450085247252, 'support': 1132}
 
----------
Epoch 36/40
time = 621.24 secondes

Train loss 0.016556875870637425 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972805063742948, 'recall': 0.9973106430723139, 'f1-score': 0.9972933752756482, 'support': 10182} weighted_avg {'precision': 0.9972519416804106, 'recall': 0.9972500491062659, 'f1-score': 0.9972487535905936, 'support': 10182}
 
time = 27.41 secondes

Val loss 0.7119446248405848 accuracy 0.9249116778373718 macro_avg {'precision': 0.9270133652175563, 'recall': 0.9268664269169851, 'f1-score': 0.926162295295553, 'support': 1132} weighted_avg {'precision': 0.9259750687785058, 'recall': 0.9249116607773852, 'f1-score': 0.9246726850771582, 'support': 1132}
 
----------
Epoch 37/40
time = 679.61 secondes

Train loss 0.013919861226729969 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975079807853859, 'recall': 0.9975264367936066, 'f1-score': 0.997512869988349, 'support': 10182} weighted_avg {'precision': 0.9975520450098153, 'recall': 0.9975446867020232, 'f1-score': 0.9975438954164462, 'support': 10182}
 
time = 27.84 secondes

Val loss 0.6116368122778331 accuracy 0.9284452199935913 macro_avg {'precision': 0.9309369172096511, 'recall': 0.9288526501090054, 'f1-score': 0.928895025512035, 'support': 1132} weighted_avg {'precision': 0.9303366081094099, 'recall': 0.9284452296819788, 'f1-score': 0.9283748229922568, 'support': 1132}
 
----------
Epoch 38/40
time = 674.97 secondes

Train loss 0.010290060932206949 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983960247705579, 'recall': 0.9984201029246327, 'f1-score': 0.9984070644465841, 'support': 10182} weighted_avg {'precision': 0.9984299798628996, 'recall': 0.9984285994892949, 'f1-score': 0.9984283171994623, 'support': 10182}
 
time = 28.24 secondes

Val loss 0.669733625727736 accuracy 0.9249116778373718 macro_avg {'precision': 0.9291732958446545, 'recall': 0.925920596149344, 'f1-score': 0.9258018262841998, 'support': 1132} weighted_avg {'precision': 0.9288699070651483, 'recall': 0.9249116607773852, 'f1-score': 0.9250877226703653, 'support': 1132}
 
----------
Epoch 39/40
time = 675.67 secondes

Train loss 0.008411739502049868 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983625627714435, 'recall': 0.9984539581446207, 'f1-score': 0.9984063915504502, 'support': 10182} weighted_avg {'precision': 0.9984308764873713, 'recall': 0.9984285994892949, 'f1-score': 0.9984279634692939, 'support': 10182}
 
time = 27.05 secondes

Val loss 0.6490206598372052 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321141625342501, 'recall': 0.9294347603772039, 'f1-score': 0.9295096020090323, 'support': 1132} weighted_avg {'precision': 0.9305246573801035, 'recall': 0.9284452296819788, 'f1-score': 0.9282465783053647, 'support': 1132}
 
----------
Epoch 40/40
time = 678.91 secondes

Train loss 0.004953109803582936 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991551314033231, 'recall': 0.9991605277080037, 'f1-score': 0.9991572201615794, 'support': 10182} weighted_avg {'precision': 0.9991170055431035, 'recall': 0.9991160872127284, 'f1-score': 0.9991159056042657, 'support': 10182}
 
time = 27.57 secondes

Val loss 0.635465871139184 accuracy 0.9310954213142395 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}
 
----------
best_accuracy 0.9310954213142395 best_epoch 40 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}

average train time 664.97757076025

average val time 25.108302837610246
 
time = 177.83 secondes

test_accuracy 0.8637811541557312 macro_avg {'precision': 0.8619622881992794, 'recall': 0.8568902043892187, 'f1-score': 0.8573933439667325, 'support': 7532} weighted_avg {'precision': 0.8669934848523781, 'recall': 0.863781200212427, 'f1-score': 0.8635495729265222, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_4
----------
Epoch 1/40
time = 904.45 secondes

Train loss 1.085930619523327 accuracy 0.6867020726203918 macro_avg {'precision': 0.6865075689896771, 'recall': 0.6737792097754312, 'f1-score': 0.6700662454551063, 'support': 10182} weighted_avg {'precision': 0.6905970792110961, 'recall': 0.6867020231781575, 'f1-score': 0.6805359750626276, 'support': 10182}
 
time = 32.97 secondes

Val loss 0.5193957160686103 accuracy 0.8462897539138794 macro_avg {'precision': 0.8412125670626283, 'recall': 0.8402299982502687, 'f1-score': 0.8376936715326793, 'support': 1132} weighted_avg {'precision': 0.843922428205379, 'recall': 0.8462897526501767, 'f1-score': 0.842413568276659, 'support': 1132}
 
----------
Epoch 2/40
time = 895.94 secondes

Train loss 0.3838968490202161 accuracy 0.8871538043022156 macro_avg {'precision': 0.8815384222332305, 'recall': 0.8801776800723407, 'f1-score': 0.8803636926429504, 'support': 10182} weighted_avg {'precision': 0.8864567932606825, 'recall': 0.8871538008249853, 'f1-score': 0.8864063484907485, 'support': 10182}
 
time = 31.86 secondes

Val loss 0.41492575365053097 accuracy 0.8966431021690369 macro_avg {'precision': 0.8999323251246455, 'recall': 0.8975723282585276, 'f1-score': 0.8956750378397782, 'support': 1132} weighted_avg {'precision': 0.9005802693326558, 'recall': 0.8966431095406361, 'f1-score': 0.895143936676859, 'support': 1132}
 
----------
Epoch 3/40
time = 871.07 secondes

Train loss 0.23415676027746926 accuracy 0.9339029788970947 macro_avg {'precision': 0.9313366144984473, 'recall': 0.931048279689529, 'f1-score': 0.9311270378667762, 'support': 10182} weighted_avg {'precision': 0.9341356114413687, 'recall': 0.933902966018464, 'f1-score': 0.9339549314983527, 'support': 10182}
 
time = 31.74 secondes

Val loss 0.4685395577804408 accuracy 0.9028268456459045 macro_avg {'precision': 0.9048725084604504, 'recall': 0.9024120467548313, 'f1-score': 0.9002344086445928, 'support': 1132} weighted_avg {'precision': 0.9050233225133233, 'recall': 0.9028268551236749, 'f1-score': 0.9006327586233528, 'support': 1132}
 
----------
Epoch 4/40
time = 886.40 secondes

Train loss 0.1755128247609283 accuracy 0.9548222422599792 macro_avg {'precision': 0.9531579260691849, 'recall': 0.9528312455868295, 'f1-score': 0.9529470096924959, 'support': 10182} weighted_avg {'precision': 0.9548200036377498, 'recall': 0.9548222353172264, 'f1-score': 0.9547756605009832, 'support': 10182}
 
time = 30.38 secondes

Val loss 0.48899852524472165 accuracy 0.9063604474067688 macro_avg {'precision': 0.9113016963466535, 'recall': 0.9073621871432493, 'f1-score': 0.9063413900703441, 'support': 1132} weighted_avg {'precision': 0.9125648337918182, 'recall': 0.9063604240282686, 'f1-score': 0.9061862724231018, 'support': 1132}
 
----------
Epoch 5/40
time = 889.66 secondes

Train loss 0.15959863709026342 accuracy 0.9608132243156433 macro_avg {'precision': 0.9589868555310874, 'recall': 0.9586793542749328, 'f1-score': 0.9587745556055326, 'support': 10182} weighted_avg {'precision': 0.9607763663144321, 'recall': 0.9608131997642899, 'f1-score': 0.9607364885199169, 'support': 10182}
 
time = 31.15 secondes

Val loss 0.5388715893135104 accuracy 0.9010601043701172 macro_avg {'precision': 0.907591546568366, 'recall': 0.9013343999069345, 'f1-score': 0.9010584883871751, 'support': 1132} weighted_avg {'precision': 0.908005280658987, 'recall': 0.901060070671378, 'f1-score': 0.9011480861926803, 'support': 1132}
 
----------
Epoch 6/40
time = 888.10 secondes

Train loss 0.1381628696523092 accuracy 0.9673934578895569 macro_avg {'precision': 0.9665400416858814, 'recall': 0.9665452750523024, 'f1-score': 0.9664698139836971, 'support': 10182} weighted_avg {'precision': 0.9676099019947199, 'recall': 0.9673934394028678, 'f1-score': 0.967433825158669, 'support': 10182}
 
time = 30.86 secondes

Val loss 0.5589238259396975 accuracy 0.898409903049469 macro_avg {'precision': 0.9107780061389394, 'recall': 0.8990560839242434, 'f1-score': 0.9005934197614881, 'support': 1132} weighted_avg {'precision': 0.9088274890381041, 'recall': 0.8984098939929329, 'f1-score': 0.899540464371059, 'support': 1132}
 
----------
Epoch 7/40
time = 886.07 secondes

Train loss 0.12212684896103511 accuracy 0.9725987315177917 macro_avg {'precision': 0.972092109588592, 'recall': 0.9722323636192046, 'f1-score': 0.9721184211638796, 'support': 10182} weighted_avg {'precision': 0.9727148341507819, 'recall': 0.9725987035945787, 'f1-score': 0.9726144256906292, 'support': 10182}
 
time = 32.09 secondes

Val loss 0.5849548677535085 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126284591765751, 'recall': 0.9094974132947063, 'f1-score': 0.9083472707306803, 'support': 1132} weighted_avg {'precision': 0.9124542703248095, 'recall': 0.9081272084805654, 'f1-score': 0.9073014295784437, 'support': 1132}
 
----------
Epoch 8/40
time = 886.88 secondes

Train loss 0.11177829492930762 accuracy 0.9741701483726501 macro_avg {'precision': 0.973594696465962, 'recall': 0.9734491551783859, 'f1-score': 0.9734950780435249, 'support': 10182} weighted_avg {'precision': 0.974196918075608, 'recall': 0.9741701041052838, 'f1-score': 0.9741565543818885, 'support': 10182}
 
time = 31.16 secondes

Val loss 0.5017699991921816 accuracy 0.9204947352409363 macro_avg {'precision': 0.9244479644558574, 'recall': 0.9198750978312731, 'f1-score': 0.918678550890413, 'support': 1132} weighted_avg {'precision': 0.9249164074099199, 'recall': 0.9204946996466431, 'f1-score': 0.9196652619276384, 'support': 1132}
 
----------
Epoch 9/40
time = 881.07 secondes

Train loss 0.11146013088578437 accuracy 0.9759379625320435 macro_avg {'precision': 0.9750177619936367, 'recall': 0.97545290705052, 'f1-score': 0.9751860900778242, 'support': 10182} weighted_avg {'precision': 0.9759976803279738, 'recall': 0.9759379296798272, 'f1-score': 0.9759226007932119, 'support': 10182}
 
time = 31.52 secondes

Val loss 0.7485236363833062 accuracy 0.879858672618866 macro_avg {'precision': 0.896906504806414, 'recall': 0.8720591196309572, 'f1-score': 0.8712675490746763, 'support': 1132} weighted_avg {'precision': 0.896645497634433, 'recall': 0.8798586572438163, 'f1-score': 0.8778132357248053, 'support': 1132}
 
----------
Epoch 10/40
time = 888.16 secondes

Train loss 0.11016958717904105 accuracy 0.9777057766914368 macro_avg {'precision': 0.9767650159952659, 'recall': 0.9770413140656095, 'f1-score': 0.9768544129001375, 'support': 10182} weighted_avg {'precision': 0.9778079420816265, 'recall': 0.9777057552543704, 'f1-score': 0.9777171184522614, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.6425116605991924 accuracy 0.9107773900032043 macro_avg {'precision': 0.9217270403779807, 'recall': 0.9112960560306606, 'f1-score': 0.9132886534816338, 'support': 1132} weighted_avg {'precision': 0.9197899578043967, 'recall': 0.9107773851590106, 'f1-score': 0.9120199309815973, 'support': 1132}
 
----------
Epoch 11/40
time = 887.69 secondes

Train loss 0.10249908830617076 accuracy 0.9800629019737244 macro_avg {'precision': 0.9795009061695769, 'recall': 0.9797302742176737, 'f1-score': 0.9795970230580796, 'support': 10182} weighted_avg {'precision': 0.9800965897243733, 'recall': 0.9800628560204282, 'f1-score': 0.9800632197023552, 'support': 10182}
 
time = 31.40 secondes

Val loss 0.5195122392418545 accuracy 0.9196113348007202 macro_avg {'precision': 0.9222364650195294, 'recall': 0.9228078046566048, 'f1-score': 0.9214777802676926, 'support': 1132} weighted_avg {'precision': 0.9229993100415419, 'recall': 0.9196113074204947, 'f1-score': 0.9202951152689185, 'support': 1132}
 
----------
Epoch 12/40
time = 884.34 secondes

Train loss 0.09942209077085674 accuracy 0.9806521534919739 macro_avg {'precision': 0.9799102835107767, 'recall': 0.9796952108777759, 'f1-score': 0.9797671273381034, 'support': 10182} weighted_avg {'precision': 0.9806918441615122, 'recall': 0.9806521312119426, 'f1-score': 0.9806387957507825, 'support': 10182}
 
time = 31.12 secondes

Val loss 0.7199064678589168 accuracy 0.9045936465263367 macro_avg {'precision': 0.9142361637909909, 'recall': 0.9044086756644818, 'f1-score': 0.9064587066213372, 'support': 1132} weighted_avg {'precision': 0.9139669927240228, 'recall': 0.9045936395759717, 'f1-score': 0.9062910000462504, 'support': 1132}
 
----------
Epoch 13/40
time = 892.53 secondes

Train loss 0.10019335445704515 accuracy 0.9812414646148682 macro_avg {'precision': 0.9800448220615527, 'recall': 0.9804267281056586, 'f1-score': 0.9802047141721688, 'support': 10182} weighted_avg {'precision': 0.9813307964791219, 'recall': 0.981241406403457, 'f1-score': 0.9812596499994694, 'support': 10182}
 
time = 31.14 secondes

Val loss 0.8165900552287472 accuracy 0.8878092169761658 macro_avg {'precision': 0.9011281371267614, 'recall': 0.8852364533612294, 'f1-score': 0.8864581928861661, 'support': 1132} weighted_avg {'precision': 0.8986244409402355, 'recall': 0.8878091872791519, 'f1-score': 0.8867222613745912, 'support': 1132}
 
----------
Epoch 14/40
time = 849.97 secondes

Train loss 0.09773514877786488 accuracy 0.9814378619194031 macro_avg {'precision': 0.9813610444115877, 'recall': 0.9810298890042756, 'f1-score': 0.9811697066823106, 'support': 10182} weighted_avg {'precision': 0.9814497264505064, 'recall': 0.9814378314672952, 'f1-score': 0.9814182077101277, 'support': 10182}
 
time = 23.76 secondes

Val loss 0.8164968457526747 accuracy 0.8913427591323853 macro_avg {'precision': 0.9014434343927695, 'recall': 0.8960916809256038, 'f1-score': 0.8927996249156402, 'support': 1132} weighted_avg {'precision': 0.9050721572627863, 'recall': 0.8913427561837456, 'f1-score': 0.8917019108997021, 'support': 1132}
 
----------
Epoch 15/40
time = 809.63 secondes

Train loss 0.0852009838246766 accuracy 0.9847770929336548 macro_avg {'precision': 0.984738529277273, 'recall': 0.9845590137659823, 'f1-score': 0.9846202021731381, 'support': 10182} weighted_avg {'precision': 0.9848526790621743, 'recall': 0.9847770575525437, 'f1-score': 0.9847866931252149, 'support': 10182}
 
time = 31.26 secondes

Val loss 0.6942899270814477 accuracy 0.9090105891227722 macro_avg {'precision': 0.9135506304505899, 'recall': 0.9066611815332631, 'f1-score': 0.9088391604208, 'support': 1132} weighted_avg {'precision': 0.9109398970241406, 'recall': 0.9090106007067138, 'f1-score': 0.9087468740851598, 'support': 1132}
 
----------
Epoch 16/40
time = 832.00 secondes

Train loss 0.0820784205051791 accuracy 0.9854645729064941 macro_avg {'precision': 0.9855058740680616, 'recall': 0.985370173621485, 'f1-score': 0.9853833692723507, 'support': 10182} weighted_avg {'precision': 0.9855786158729254, 'recall': 0.9854645452759773, 'f1-score': 0.9854654057996362, 'support': 10182}
 
time = 31.48 secondes

Val loss 0.6275781476102616 accuracy 0.9125441908836365 macro_avg {'precision': 0.9187629424288086, 'recall': 0.9121109985551719, 'f1-score': 0.9145346774284221, 'support': 1132} weighted_avg {'precision': 0.914260494802553, 'recall': 0.9125441696113075, 'f1-score': 0.9124711805937453, 'support': 1132}
 
----------
Epoch 17/40
time = 847.80 secondes

Train loss 0.08730184219728378 accuracy 0.9851699471473694 macro_avg {'precision': 0.9849575776816355, 'recall': 0.9851428217879704, 'f1-score': 0.9850097983707263, 'support': 10182} weighted_avg {'precision': 0.9852473653884686, 'recall': 0.98516990768022, 'f1-score': 0.9851692857918276, 'support': 10182}
 
time = 25.74 secondes

Val loss 0.7229484111049318 accuracy 0.8992933034896851 macro_avg {'precision': 0.9022305834531945, 'recall': 0.9043702783368799, 'f1-score': 0.8999537426896568, 'support': 1132} weighted_avg {'precision': 0.9069119119456899, 'recall': 0.8992932862190812, 'f1-score': 0.8997867434282643, 'support': 1132}
 
----------
Epoch 18/40
time = 922.10 secondes

Train loss 0.07129670814004269 accuracy 0.9870359897613525 macro_avg {'precision': 0.9866693485698406, 'recall': 0.9871836831129777, 'f1-score': 0.9869032952034905, 'support': 10182} weighted_avg {'precision': 0.9870945904981376, 'recall': 0.9870359457866824, 'f1-score': 0.9870434803235079, 'support': 10182}
 
time = 32.26 secondes

Val loss 0.5969959354033435 accuracy 0.916961133480072 macro_avg {'precision': 0.9259543968350992, 'recall': 0.9205818030305034, 'f1-score': 0.9211064907549019, 'support': 1132} weighted_avg {'precision': 0.9230064219570709, 'recall': 0.9169611307420494, 'f1-score': 0.9177016493579521, 'support': 1132}
 
----------
Epoch 19/40
time = 931.96 secondes

Train loss 0.06571471136292421 accuracy 0.9877234697341919 macro_avg {'precision': 0.9874937388551459, 'recall': 0.987279933565938, 'f1-score': 0.9873746777387578, 'support': 10182} weighted_avg {'precision': 0.9877469769518392, 'recall': 0.9877234335101159, 'f1-score': 0.9877231923755789, 'support': 10182}
 
time = 33.13 secondes

Val loss 0.6810309944031219 accuracy 0.9090105891227722 macro_avg {'precision': 0.9139858929954672, 'recall': 0.9109036378960074, 'f1-score': 0.9107076115090409, 'support': 1132} weighted_avg {'precision': 0.9140579818744584, 'recall': 0.9090106007067138, 'f1-score': 0.9096541664120402, 'support': 1132}
 
----------
Epoch 20/40
time = 824.59 secondes

Train loss 0.06306088293250459 accuracy 0.9881163239479065 macro_avg {'precision': 0.9871770559180423, 'recall': 0.9870661817022851, 'f1-score': 0.9871115766407377, 'support': 10182} weighted_avg {'precision': 0.988111724482609, 'recall': 0.9881162836377921, 'f1-score': 0.9881043287784385, 'support': 10182}
 
time = 25.54 secondes

Val loss 0.6654901082767256 accuracy 0.9187279343605042 macro_avg {'precision': 0.9225022253885852, 'recall': 0.920677766004936, 'f1-score': 0.9199235289990169, 'support': 1132} weighted_avg {'precision': 0.9242391407004176, 'recall': 0.9187279151943463, 'f1-score': 0.9199027903917225, 'support': 1132}
 
----------
Epoch 21/40
time = 749.71 secondes

Train loss 0.05299371498184764 accuracy 0.989589512348175 macro_avg {'precision': 0.9887296085423477, 'recall': 0.988832172725511, 'f1-score': 0.9887677615139981, 'support': 10182} weighted_avg {'precision': 0.9896181715370865, 'recall': 0.9895894716165783, 'f1-score': 0.9895906788751021, 'support': 10182}
 
time = 24.74 secondes

Val loss 0.6802497056125734 accuracy 0.916077733039856 macro_avg {'precision': 0.9187116393897616, 'recall': 0.9179064496880024, 'f1-score': 0.9169774747079489, 'support': 1132} weighted_avg {'precision': 0.9193771327550203, 'recall': 0.916077738515901, 'f1-score': 0.9162875602048626, 'support': 1132}
 
----------
Epoch 22/40
time = 725.42 secondes

Train loss 0.06242271111844973 accuracy 0.9889020323753357 macro_avg {'precision': 0.9881938934300022, 'recall': 0.9881719683330811, 'f1-score': 0.9881682046838465, 'support': 10182} weighted_avg {'precision': 0.9889477766358592, 'recall': 0.9889019838931448, 'f1-score': 0.9889106281827171, 'support': 10182}
 
time = 24.69 secondes

Val loss 0.6513749236457417 accuracy 0.9257950782775879 macro_avg {'precision': 0.93231797412231, 'recall': 0.9238606887022037, 'f1-score': 0.9262688151741167, 'support': 1132} weighted_avg {'precision': 0.9294437721233918, 'recall': 0.9257950530035336, 'f1-score': 0.9258321831296487, 'support': 1132}
 
----------
Epoch 23/40
time = 721.05 secondes

Train loss 0.05685086062583413 accuracy 0.989589512348175 macro_avg {'precision': 0.989066353413764, 'recall': 0.9890039166038262, 'f1-score': 0.9890162405558197, 'support': 10182} weighted_avg {'precision': 0.9896006173984353, 'recall': 0.9895894716165783, 'f1-score': 0.9895767360402349, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7105753186485126 accuracy 0.9178445339202881 macro_avg {'precision': 0.9168506664443754, 'recall': 0.9210171993563337, 'f1-score': 0.9179118569345952, 'support': 1132} weighted_avg {'precision': 0.9189260577429352, 'recall': 0.9178445229681979, 'f1-score': 0.9173579302317096, 'support': 1132}
 
----------
Epoch 24/40
time = 723.17 secondes

Train loss 0.05538533817794597 accuracy 0.9908662438392639 macro_avg {'precision': 0.9909166988481599, 'recall': 0.9908721002456348, 'f1-score': 0.9908853517095133, 'support': 10182} weighted_avg {'precision': 0.990889139086868, 'recall': 0.9908662345315262, 'f1-score': 0.9908684828046269, 'support': 10182}
 
time = 24.35 secondes

Val loss 0.7588620925948112 accuracy 0.9054770469665527 macro_avg {'precision': 0.9111761909126249, 'recall': 0.9089792477308543, 'f1-score': 0.9061665829913517, 'support': 1132} weighted_avg {'precision': 0.9150934313022671, 'recall': 0.9054770318021201, 'f1-score': 0.9061167602309964, 'support': 1132}
 
----------
Epoch 25/40
time = 721.45 secondes

Train loss 0.04196974732863048 accuracy 0.9925358891487122 macro_avg {'precision': 0.9923421609613369, 'recall': 0.9925736264987691, 'f1-score': 0.9924446181074436, 'support': 10182} weighted_avg {'precision': 0.9925696076571987, 'recall': 0.9925358475741505, 'f1-score': 0.9925393657607952, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.6123379302967601 accuracy 0.9302120208740234 macro_avg {'precision': 0.9344926025439475, 'recall': 0.9304099728605759, 'f1-score': 0.9305748284696176, 'support': 1132} weighted_avg {'precision': 0.9345175032134959, 'recall': 0.9302120141342756, 'f1-score': 0.930474416830259, 'support': 1132}
 
----------
Epoch 26/40
time = 720.91 secondes

Train loss 0.04845086469917081 accuracy 0.9909644722938538 macro_avg {'precision': 0.99088961412954, 'recall': 0.9908579582373319, 'f1-score': 0.9908559577983175, 'support': 10182} weighted_avg {'precision': 0.990990255554527, 'recall': 0.9909644470634453, 'f1-score': 0.9909593388301886, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.6515468313973799 accuracy 0.9187279343605042 macro_avg {'precision': 0.9235763965287459, 'recall': 0.9210695551871797, 'f1-score': 0.9206373320575294, 'support': 1132} weighted_avg {'precision': 0.9231579262767182, 'recall': 0.9187279151943463, 'f1-score': 0.9191803382565835, 'support': 1132}
 
----------
Epoch 27/40
time = 746.80 secondes

Train loss 0.04168468048204432 accuracy 0.9928305149078369 macro_avg {'precision': 0.9925499255606015, 'recall': 0.9925200415637796, 'f1-score': 0.992529032890555, 'support': 10182} weighted_avg {'precision': 0.9928395079606481, 'recall': 0.9928304851699077, 'f1-score': 0.9928292377396122, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.6601591920423769 accuracy 0.9204947352409363 macro_avg {'precision': 0.9224227821208183, 'recall': 0.9214949051296937, 'f1-score': 0.9204901465424513, 'support': 1132} weighted_avg {'precision': 0.9239788503292518, 'recall': 0.9204946996466431, 'f1-score': 0.9206783818597479, 'support': 1132}
 
----------
Epoch 28/40
time = 985.60 secondes

Train loss 0.03838881240947985 accuracy 0.993812620639801 macro_avg {'precision': 0.9935769595247766, 'recall': 0.9935652362701312, 'f1-score': 0.9935642935237002, 'support': 10182} weighted_avg {'precision': 0.9938296889935495, 'recall': 0.9938126104890984, 'f1-score': 0.9938145105010365, 'support': 10182}
 
time = 34.95 secondes

Val loss 0.860883043595966 accuracy 0.8992933034896851 macro_avg {'precision': 0.9024835600071854, 'recall': 0.9033449379728232, 'f1-score': 0.8984828133129075, 'support': 1132} weighted_avg {'precision': 0.9079316562062043, 'recall': 0.8992932862190812, 'f1-score': 0.8990663151226878, 'support': 1132}
 
----------
Epoch 29/40
time = 1038.42 secondes

Train loss 0.04060292713660561 accuracy 0.993714451789856 macro_avg {'precision': 0.9937117463797953, 'recall': 0.9938319781744969, 'f1-score': 0.9937672216812059, 'support': 10182} weighted_avg {'precision': 0.9937201588059923, 'recall': 0.9937143979571793, 'f1-score': 0.9937126857096119, 'support': 10182}
 
time = 27.09 secondes

Val loss 0.6890976755303584 accuracy 0.9213780760765076 macro_avg {'precision': 0.922281037142921, 'recall': 0.9222590680862274, 'f1-score': 0.9203910822765398, 'support': 1132} weighted_avg {'precision': 0.9267961509911602, 'recall': 0.9213780918727915, 'f1-score': 0.922214289591987, 'support': 1132}
 
----------
Epoch 30/40
time = 858.29 secondes

Train loss 0.031173711125298934 accuracy 0.994892954826355 macro_avg {'precision': 0.994535827873061, 'recall': 0.9947610278644549, 'f1-score': 0.994641772197798, 'support': 10182} weighted_avg {'precision': 0.9949075764601065, 'recall': 0.9948929483402082, 'f1-score': 0.9948949755322696, 'support': 10182}
 
time = 34.05 secondes

Val loss 0.5181108321646117 accuracy 0.9381625652313232 macro_avg {'precision': 0.9397061516426184, 'recall': 0.9385536350939858, 'f1-score': 0.9385425372008287, 'support': 1132} weighted_avg {'precision': 0.9395799989536734, 'recall': 0.9381625441696113, 'f1-score': 0.9383633479438508, 'support': 1132}
 
----------
Epoch 31/40
time = 941.53 secondes

Train loss 0.030867749507702037 accuracy 0.993714451789856 macro_avg {'precision': 0.9937514821204327, 'recall': 0.9938023578428083, 'f1-score': 0.9937638990889566, 'support': 10182} weighted_avg {'precision': 0.9937537063880632, 'recall': 0.9937143979571793, 'f1-score': 0.993721086007801, 'support': 10182}
 
time = 33.27 secondes

Val loss 0.5612273408090991 accuracy 0.9337455630302429 macro_avg {'precision': 0.9359974509163143, 'recall': 0.93484449411371, 'f1-score': 0.9345026692250284, 'support': 1132} weighted_avg {'precision': 0.935810554555756, 'recall': 0.9337455830388692, 'f1-score': 0.9338709052223133, 'support': 1132}
 
----------
Epoch 32/40
time = 899.15 secondes

Train loss 0.02310575361171605 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963257524786006, 'recall': 0.9964232535783323, 'f1-score': 0.9963725519896849, 'support': 10182} weighted_avg {'precision': 0.9963712110158622, 'recall': 0.9963661363189943, 'f1-score': 0.9963668141470821, 'support': 10182}
 
time = 27.42 secondes

Val loss 0.5719641888216769 accuracy 0.9231448769569397 macro_avg {'precision': 0.9232094713707418, 'recall': 0.9252079619270377, 'f1-score': 0.9229192758373415, 'support': 1132} weighted_avg {'precision': 0.9260076461693314, 'recall': 0.9231448763250883, 'f1-score': 0.9232811127704171, 'support': 1132}
 
----------
Epoch 33/40
time = 802.84 secondes

Train loss 0.02288988167023907 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961711895226604, 'recall': 0.9960872234544421, 'f1-score': 0.9961276667985807, 'support': 10182} weighted_avg {'precision': 0.9960728919332007, 'recall': 0.9960714987232371, 'f1-score': 0.9960707790937092, 'support': 10182}
 
time = 25.43 secondes

Val loss 0.570196613516549 accuracy 0.9284452199935913 macro_avg {'precision': 0.930398041129781, 'recall': 0.9314545608623694, 'f1-score': 0.9302127048762674, 'support': 1132} weighted_avg {'precision': 0.9303285099956946, 'recall': 0.9284452296819788, 'f1-score': 0.9286587977714396, 'support': 1132}
 
----------
Epoch 34/40
time = 729.81 secondes

Train loss 0.022912930652256226 accuracy 0.9958751201629639 macro_avg {'precision': 0.99586094864021, 'recall': 0.996017571352667, 'f1-score': 0.9959375842810543, 'support': 10182} weighted_avg {'precision': 0.995876237591081, 'recall': 0.995875073659399, 'f1-score': 0.9958741272109735, 'support': 10182}
 
time = 25.02 secondes

Val loss 0.6081943999041113 accuracy 0.9293286204338074 macro_avg {'precision': 0.9308768834788852, 'recall': 0.9316163994078817, 'f1-score': 0.9303342030632656, 'support': 1132} weighted_avg {'precision': 0.931874792968735, 'recall': 0.9293286219081273, 'f1-score': 0.929633049931186, 'support': 1132}
 
----------
Epoch 35/40
time = 731.54 secondes

Train loss 0.012990592034385177 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976388217559149, 'recall': 0.9977231060685143, 'f1-score': 0.9976776629397343, 'support': 10182} weighted_avg {'precision': 0.9976510756655848, 'recall': 0.9976428992339422, 'f1-score': 0.9976436215766573, 'support': 10182}
 
time = 25.28 secondes

Val loss 0.5714157906219094 accuracy 0.9390459656715393 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}
 
----------
Epoch 36/40
time = 729.01 secondes

Train loss 0.01833871189036482 accuracy 0.9969554543495178 macro_avg {'precision': 0.996884086841674, 'recall': 0.9969676468006174, 'f1-score': 0.996919469712536, 'support': 10182} weighted_avg {'precision': 0.9969736934344191, 'recall': 0.9969554115105087, 'f1-score': 0.9969581469381175, 'support': 10182}
 
time = 25.98 secondes

Val loss 0.5994078302624267 accuracy 0.9293286204338074 macro_avg {'precision': 0.9299352449609296, 'recall': 0.9315913919887848, 'f1-score': 0.929768704288418, 'support': 1132} weighted_avg {'precision': 0.932670118027193, 'recall': 0.9293286219081273, 'f1-score': 0.9299518385785527, 'support': 1132}
 
----------
Epoch 37/40
time = 729.77 secondes

Train loss 0.011112356264953743 accuracy 0.9982321858406067 macro_avg {'precision': 0.9983171733400937, 'recall': 0.9982307827420612, 'f1-score': 0.9982710723288559, 'support': 10182} weighted_avg {'precision': 0.9982399977390333, 'recall': 0.9982321744254566, 'f1-score': 0.9982331126085662, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.5924408991639109 accuracy 0.9310954213142395 macro_avg {'precision': 0.9338731707688073, 'recall': 0.9336734436606633, 'f1-score': 0.9325406862964474, 'support': 1132} weighted_avg {'precision': 0.935230106640389, 'recall': 0.931095406360424, 'f1-score': 0.9318909013144914, 'support': 1132}
 
----------
Epoch 38/40
time = 728.57 secondes

Train loss 0.007094374627405235 accuracy 0.9985268115997314 macro_avg {'precision': 0.9983785635338565, 'recall': 0.9985166071708447, 'f1-score': 0.9984445929154344, 'support': 10182} weighted_avg {'precision': 0.9985332444686208, 'recall': 0.998526812021214, 'f1-score': 0.9985276773775542, 'support': 10182}
 
time = 25.39 secondes

Val loss 0.6083182109004168 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321705996842805, 'recall': 0.9312106288458313, 'f1-score': 0.9301701070542325, 'support': 1132} weighted_avg {'precision': 0.9331578994457744, 'recall': 0.9284452296819788, 'f1-score': 0.9291780103692845, 'support': 1132}
 
----------
Epoch 39/40
time = 834.23 secondes

Train loss 0.004099554753626863 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990445153619305, 'recall': 0.9990465124100428, 'f1-score': 0.9990450770469763, 'support': 10182} weighted_avg {'precision': 0.9990189772040283, 'recall': 0.9990178746808093, 'f1-score': 0.9990179675363912, 'support': 10182}
 
time = 34.52 secondes

Val loss 0.6324473496378501 accuracy 0.9337455630302429 macro_avg {'precision': 0.9389891292501433, 'recall': 0.9361597063520225, 'f1-score': 0.9362935689683122, 'support': 1132} weighted_avg {'precision': 0.938128479283786, 'recall': 0.9337455830388692, 'f1-score': 0.9345301109424841, 'support': 1132}
 
----------
Epoch 40/40
time = 973.10 secondes

Train loss 0.0029508336193605914 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993654156660551, 'recall': 0.9993890841637985, 'f1-score': 0.9993765447608427, 'support': 10182} weighted_avg {'precision': 0.9994121086721734, 'recall': 0.9994107248084856, 'f1-score': 0.9994107345412815, 'support': 10182}
 
time = 31.97 secondes

Val loss 0.604129914752852 accuracy 0.9337455630302429 macro_avg {'precision': 0.9364403679707334, 'recall': 0.935185174255696, 'f1-score': 0.9349140513727106, 'support': 1132} weighted_avg {'precision': 0.9359944263180545, 'recall': 0.9337455830388692, 'f1-score': 0.9339703121737567, 'support': 1132}
 
----------
best_accuracy 0.9390459656715393 best_epoch 35 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}

average train time 841.2686648905277

average val time 29.002124965190887
 
time = 199.06 secondes

test_accuracy 0.8559479117393494 macro_avg {'precision': 0.853801041312529, 'recall': 0.8495474935062125, 'f1-score': 0.8497281728064007, 'support': 7532} weighted_avg {'precision': 0.8607974784860157, 'recall': 0.8559479553903345, 'f1-score': 0.8564545903716746, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_4
----------
Epoch 1/40
time = 1224.70 secondes

Train loss 1.173128953370232 accuracy 0.6593989729881287 macro_avg {'precision': 0.662829769087903, 'recall': 0.6455535306271434, 'f1-score': 0.6410237550364425, 'support': 10182} weighted_avg {'precision': 0.6703989207273187, 'recall': 0.6593989393046553, 'f1-score': 0.6534405257138537, 'support': 10182}
 
time = 40.74 secondes

Val loss 0.589547368212485 accuracy 0.8242049813270569 macro_avg {'precision': 0.8513547433588059, 'recall': 0.8217635358966021, 'f1-score': 0.8070310135342676, 'support': 1132} weighted_avg {'precision': 0.8448801925737545, 'recall': 0.8242049469964664, 'f1-score': 0.8120437700387597, 'support': 1132}
 
----------
Epoch 2/40
time = 1292.61 secondes

Train loss 0.433301338121833 accuracy 0.8733058571815491 macro_avg {'precision': 0.8652638294358969, 'recall': 0.8641945615311402, 'f1-score': 0.8636283597576035, 'support': 10182} weighted_avg {'precision': 0.8718183863417169, 'recall': 0.873305833824396, 'f1-score': 0.8717080931309271, 'support': 10182}
 
time = 37.63 secondes

Val loss 0.5033257722224987 accuracy 0.8648409843444824 macro_avg {'precision': 0.8691521618456436, 'recall': 0.8624626086280799, 'f1-score': 0.8593810526738238, 'support': 1132} weighted_avg {'precision': 0.8751966966445278, 'recall': 0.8648409893992933, 'f1-score': 0.8635484994452928, 'support': 1132}
 
----------
Epoch 3/40
time = 1168.28 secondes

Train loss 0.26697434020467 accuracy 0.9230996370315552 macro_avg {'precision': 0.9188650171477862, 'recall': 0.9178367231555937, 'f1-score': 0.9181392721051699, 'support': 10182} weighted_avg {'precision': 0.9230208678322049, 'recall': 0.923099587507366, 'f1-score': 0.9228604440474881, 'support': 10182}
 
time = 31.54 secondes

Val loss 0.4773428943139357 accuracy 0.8878092169761658 macro_avg {'precision': 0.8893159478547924, 'recall': 0.8901384851693358, 'f1-score': 0.8843182079086016, 'support': 1132} weighted_avg {'precision': 0.8957682804469341, 'recall': 0.8878091872791519, 'f1-score': 0.8856897656047938, 'support': 1132}
 
----------
Epoch 4/40
time = 1113.69 secondes

Train loss 0.1947178938616143 accuracy 0.9453938603401184 macro_avg {'precision': 0.9427466024270726, 'recall': 0.9425265062203646, 'f1-score': 0.9425725025417689, 'support': 10182} weighted_avg {'precision': 0.945480084806776, 'recall': 0.9453938322529954, 'f1-score': 0.9453761839551973, 'support': 10182}
 
time = 30.97 secondes

Val loss 0.4491022658881954 accuracy 0.8948763608932495 macro_avg {'precision': 0.8996512456924854, 'recall': 0.8927313125982309, 'f1-score': 0.8921173758259456, 'support': 1132} weighted_avg {'precision': 0.9011924365315521, 'recall': 0.8948763250883393, 'f1-score': 0.893673234573963, 'support': 1132}
 
----------
Epoch 5/40
time = 1115.33 secondes

Train loss 0.1558833939708284 accuracy 0.9604203701019287 macro_avg {'precision': 0.9585975356538083, 'recall': 0.9587788823766434, 'f1-score': 0.9586219752270683, 'support': 10182} weighted_avg {'precision': 0.960574103478398, 'recall': 0.9604203496366136, 'f1-score': 0.9604363157078126, 'support': 10182}
 
time = 30.81 secondes

Val loss 0.4840479651088892 accuracy 0.9045936465263367 macro_avg {'precision': 0.9110295516794489, 'recall': 0.9027701981303082, 'f1-score': 0.9039572929440777, 'support': 1132} weighted_avg {'precision': 0.9100952857362941, 'recall': 0.9045936395759717, 'f1-score': 0.9046826167520323, 'support': 1132}
 
----------
Epoch 6/40
time = 1112.66 secondes

Train loss 0.13205229320740283 accuracy 0.9665095806121826 macro_avg {'precision': 0.9654723418428794, 'recall': 0.964841858873853, 'f1-score': 0.9651167315236387, 'support': 10182} weighted_avg {'precision': 0.966505152875396, 'recall': 0.9665095266155962, 'f1-score': 0.9664729666915374, 'support': 10182}
 
time = 29.48 secondes

Val loss 0.5088391571230269 accuracy 0.9045936465263367 macro_avg {'precision': 0.9130306601038022, 'recall': 0.901036550177752, 'f1-score': 0.9037126908571272, 'support': 1132} weighted_avg {'precision': 0.9090787836056673, 'recall': 0.9045936395759717, 'f1-score': 0.9036050004244318, 'support': 1132}
 
----------
Epoch 7/40
time = 1180.33 secondes

Train loss 0.1275869197653697 accuracy 0.968375563621521 macro_avg {'precision': 0.9671232772670066, 'recall': 0.9670273626391609, 'f1-score': 0.9670436412078562, 'support': 10182} weighted_avg {'precision': 0.968415866768847, 'recall': 0.9683755647220585, 'f1-score': 0.9683656847802719, 'support': 10182}
 
time = 41.00 secondes

Val loss 0.5309758744764955 accuracy 0.9116607904434204 macro_avg {'precision': 0.9187587319013115, 'recall': 0.9118835917962625, 'f1-score': 0.9130421130537897, 'support': 1132} weighted_avg {'precision': 0.917786147161771, 'recall': 0.911660777385159, 'f1-score': 0.9122863957441552, 'support': 1132}
 
----------
Epoch 8/40
time = 1282.49 secondes

Train loss 0.12002114570318403 accuracy 0.9730898141860962 macro_avg {'precision': 0.9723695992863715, 'recall': 0.9725255250033399, 'f1-score': 0.9724196049338719, 'support': 10182} weighted_avg {'precision': 0.9731267731823616, 'recall': 0.973089766254174, 'f1-score': 0.973079996811068, 'support': 10182}
 
time = 33.48 secondes

Val loss 0.610222482664796 accuracy 0.9010601043701172 macro_avg {'precision': 0.9083310837239571, 'recall': 0.9017994046940101, 'f1-score': 0.902471061050858, 'support': 1132} weighted_avg {'precision': 0.9061301049524046, 'recall': 0.901060070671378, 'f1-score': 0.9010895163950153, 'support': 1132}
 
----------
Epoch 9/40
time = 1246.58 secondes

Train loss 0.11085762805689209 accuracy 0.9742683172225952 macro_avg {'precision': 0.973686279384073, 'recall': 0.9738118937993816, 'f1-score': 0.9736728343620366, 'support': 10182} weighted_avg {'precision': 0.9744314222238106, 'recall': 0.9742683166372029, 'f1-score': 0.974272621149981, 'support': 10182}
 
time = 39.99 secondes

Val loss 0.7214796951718622 accuracy 0.8895759582519531 macro_avg {'precision': 0.8994128375388721, 'recall': 0.8895234200606467, 'f1-score': 0.8872931770524671, 'support': 1132} weighted_avg {'precision': 0.8976454810010577, 'recall': 0.8895759717314488, 'f1-score': 0.8870161223513768, 'support': 1132}
 
----------
Epoch 10/40
time = 1275.10 secondes

Train loss 0.10936332721249646 accuracy 0.9776075482368469 macro_avg {'precision': 0.9767742980562198, 'recall': 0.9769731977042383, 'f1-score': 0.9768160730254177, 'support': 10182} weighted_avg {'precision': 0.9777560649362148, 'recall': 0.9776075427224514, 'f1-score': 0.9776304879429484, 'support': 10182}
 
time = 32.49 secondes

Val loss 0.7261400397065174 accuracy 0.8922261595726013 macro_avg {'precision': 0.9029049154363806, 'recall': 0.8845884143093088, 'f1-score': 0.8869576307269895, 'support': 1132} weighted_avg {'precision': 0.8992483930448251, 'recall': 0.892226148409894, 'f1-score': 0.8902926862224189, 'support': 1132}
 
----------
Epoch 11/40
time = 1173.23 secondes

Train loss 0.1113884581535153 accuracy 0.9768218994140625 macro_avg {'precision': 0.9764015273357499, 'recall': 0.9762835552114361, 'f1-score': 0.9763053778161573, 'support': 10182} weighted_avg {'precision': 0.976946745757334, 'recall': 0.9768218424670988, 'f1-score': 0.9768490430920068, 'support': 10182}
 
time = 29.82 secondes

Val loss 0.7375211480754497 accuracy 0.8913427591323853 macro_avg {'precision': 0.9034405375273469, 'recall': 0.8937246809433292, 'f1-score': 0.894844329996282, 'support': 1132} weighted_avg {'precision': 0.900602132890465, 'recall': 0.8913427561837456, 'f1-score': 0.8919937340788233, 'support': 1132}
 
----------
Epoch 12/40
time = 1108.55 secondes

Train loss 0.08710213793374764 accuracy 0.9813396334648132 macro_avg {'precision': 0.9806174222910761, 'recall': 0.9803114936494837, 'f1-score': 0.9804177817813814, 'support': 10182} weighted_avg {'precision': 0.9813525144951474, 'recall': 0.9813396189353761, 'f1-score': 0.9812990831162066, 'support': 10182}
 
time = 29.72 secondes

Val loss 0.6837542199695312 accuracy 0.9054770469665527 macro_avg {'precision': 0.909983083412181, 'recall': 0.9059370038583193, 'f1-score': 0.9062647942244851, 'support': 1132} weighted_avg {'precision': 0.9097723472290224, 'recall': 0.9054770318021201, 'f1-score': 0.9061650393385801, 'support': 1132}
 
----------
Epoch 13/40
time = 1090.41 secondes

Train loss 0.09975643206413436 accuracy 0.9794735908508301 macro_avg {'precision': 0.9785171435016073, 'recall': 0.9787878927846843, 'f1-score': 0.9786211459867573, 'support': 10182} weighted_avg {'precision': 0.9795479839719737, 'recall': 0.9794735808289138, 'f1-score': 0.9794798817304826, 'support': 10182}
 
time = 29.36 secondes

Val loss 0.7395239552113221 accuracy 0.9028268456459045 macro_avg {'precision': 0.9065318876715376, 'recall': 0.9018933300113309, 'f1-score': 0.9010727985620935, 'support': 1132} weighted_avg {'precision': 0.9090351744299293, 'recall': 0.9028268551236749, 'f1-score': 0.9032605624516509, 'support': 1132}
 
----------
Epoch 14/40
time = 1072.60 secondes

Train loss 0.1041517634550082 accuracy 0.9807503819465637 macro_avg {'precision': 0.9803118434347358, 'recall': 0.9801581158287969, 'f1-score': 0.9802194703977467, 'support': 10182} weighted_avg {'precision': 0.9807725229012776, 'recall': 0.9807503437438617, 'f1-score': 0.9807480826984695, 'support': 10182}
 
time = 29.57 secondes

Val loss 0.6951771441406019 accuracy 0.9010601043701172 macro_avg {'precision': 0.9098368210121406, 'recall': 0.9074688763014256, 'f1-score': 0.9055443756944952, 'support': 1132} weighted_avg {'precision': 0.912072516182919, 'recall': 0.901060070671378, 'f1-score': 0.9034544070036912, 'support': 1132}
 
----------
Epoch 15/40
time = 1134.67 secondes

Train loss 0.09907813972971798 accuracy 0.9801610708236694 macro_avg {'precision': 0.9803470345623824, 'recall': 0.9801084447512854, 'f1-score': 0.9801644759369725, 'support': 10182} weighted_avg {'precision': 0.9802926297436175, 'recall': 0.9801610685523473, 'f1-score': 0.9801619759530473, 'support': 10182}
 
time = 39.75 secondes

Val loss 0.5585858548846273 accuracy 0.9116607904434204 macro_avg {'precision': 0.9143666532188124, 'recall': 0.9137448242853597, 'f1-score': 0.9113943401124687, 'support': 1132} weighted_avg {'precision': 0.9161052805227066, 'recall': 0.911660777385159, 'f1-score': 0.9111157622126106, 'support': 1132}
 
----------
Epoch 16/40
time = 1285.49 secondes

Train loss 0.07078671759552596 accuracy 0.9845806360244751 macro_avg {'precision': 0.9846564197876992, 'recall': 0.9847336787844652, 'f1-score': 0.9846853312421416, 'support': 10182} weighted_avg {'precision': 0.9845912730323304, 'recall': 0.9845806324887055, 'f1-score': 0.9845762128402021, 'support': 10182}
 
time = 35.27 secondes

Val loss 0.6790391367095241 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116774105898218, 'recall': 0.9044757834425546, 'f1-score': 0.9051812447696526, 'support': 1132} weighted_avg {'precision': 0.9105562910558808, 'recall': 0.9054770318021201, 'f1-score': 0.9052724476469872, 'support': 1132}
 
----------
Epoch 17/40
time = 1149.65 secondes

Train loss 0.08262343541803543 accuracy 0.98448246717453 macro_avg {'precision': 0.9838758636884674, 'recall': 0.983824785192455, 'f1-score': 0.9838377657089625, 'support': 10182} weighted_avg {'precision': 0.9845032314147716, 'recall': 0.9844824199567865, 'f1-score': 0.9844806506245479, 'support': 10182}
 
time = 28.90 secondes

Val loss 0.6675969711099062 accuracy 0.9098939895629883 macro_avg {'precision': 0.9175170331290108, 'recall': 0.9137003281628557, 'f1-score': 0.9130973781929667, 'support': 1132} weighted_avg {'precision': 0.9153607333580289, 'recall': 0.9098939929328622, 'f1-score': 0.9101382769290672, 'support': 1132}
 
----------
Epoch 18/40
time = 1237.76 secondes

Train loss 0.07865465861195815 accuracy 0.9847770929336548 macro_avg {'precision': 0.9842677434524223, 'recall': 0.9842331433022877, 'f1-score': 0.9842315516973337, 'support': 10182} weighted_avg {'precision': 0.9847936010201597, 'recall': 0.9847770575525437, 'f1-score': 0.9847667130802006, 'support': 10182}
 
time = 37.34 secondes

Val loss 0.6060551764832114 accuracy 0.916961133480072 macro_avg {'precision': 0.9263419664845014, 'recall': 0.9184225660001063, 'f1-score': 0.9209961047367257, 'support': 1132} weighted_avg {'precision': 0.9223100819699891, 'recall': 0.9169611307420494, 'f1-score': 0.9181423242742753, 'support': 1132}
 
----------
Epoch 19/40
time = 1209.37 secondes

Train loss 0.0673055721901956 accuracy 0.9873306155204773 macro_avg {'precision': 0.9871487143408387, 'recall': 0.9872925660679774, 'f1-score': 0.9872059543505107, 'support': 10182} weighted_avg {'precision': 0.9873643240524663, 'recall': 0.9873305833824396, 'f1-score': 0.9873326691980662, 'support': 10182}
 
time = 27.38 secondes

Val loss 0.6902313331825803 accuracy 0.9098939895629883 macro_avg {'precision': 0.916784055501925, 'recall': 0.9131119592189154, 'f1-score': 0.9135067568208598, 'support': 1132} weighted_avg {'precision': 0.9142045095375844, 'recall': 0.9098939929328622, 'f1-score': 0.9105594024373984, 'support': 1132}
 
----------
Epoch 20/40
time = 1108.04 secondes

Train loss 0.05156581461380206 accuracy 0.9898841381072998 macro_avg {'precision': 0.9898651280787847, 'recall': 0.9898505334572463, 'f1-score': 0.9898508146356513, 'support': 10182} weighted_avg {'precision': 0.989893612300699, 'recall': 0.9898841092123355, 'f1-score': 0.9898816337155468, 'support': 10182}
 
time = 28.30 secondes

Val loss 0.7284231496959249 accuracy 0.9072438478469849 macro_avg {'precision': 0.916677708864943, 'recall': 0.9065174217566927, 'f1-score': 0.9086229362405996, 'support': 1132} weighted_avg {'precision': 0.9147920204142058, 'recall': 0.907243816254417, 'f1-score': 0.9077452447160728, 'support': 1132}
 
----------
Epoch 21/40
time = 1089.44 secondes

Train loss 0.05262981496453508 accuracy 0.9903752207756042 macro_avg {'precision': 0.9897860448009699, 'recall': 0.9898247601087489, 'f1-score': 0.9897978347815505, 'support': 10182} weighted_avg {'precision': 0.9903830221973918, 'recall': 0.9903751718719308, 'f1-score': 0.9903715833742723, 'support': 10182}
 
time = 27.86 secondes

Val loss 0.5405368513932278 accuracy 0.9213780760765076 macro_avg {'precision': 0.922967290604376, 'recall': 0.9231754422651266, 'f1-score': 0.9223770243755471, 'support': 1132} weighted_avg {'precision': 0.9234580836900056, 'recall': 0.9213780918727915, 'f1-score': 0.9217048420196515, 'support': 1132}
 
----------
Epoch 22/40
time = 1085.43 secondes

Train loss 0.07800975690941762 accuracy 0.9861520528793335 macro_avg {'precision': 0.985552763132928, 'recall': 0.9847686519366258, 'f1-score': 0.9851033962781639, 'support': 10182} weighted_avg {'precision': 0.9862185499783711, 'recall': 0.9861520329994107, 'f1-score': 0.98613745173871, 'support': 10182}
 
time = 28.15 secondes

Val loss 0.7695977911254732 accuracy 0.9010601043701172 macro_avg {'precision': 0.9059755189411064, 'recall': 0.9005632335090912, 'f1-score': 0.9007980153053141, 'support': 1132} weighted_avg {'precision': 0.9056162411016176, 'recall': 0.901060070671378, 'f1-score': 0.9009348145572135, 'support': 1132}
 
----------
Epoch 23/40
time = 1079.60 secondes

Train loss 0.05152084587404902 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896574398550466, 'recall': 0.9895832316152815, 'f1-score': 0.9896138818934137, 'support': 10182} weighted_avg {'precision': 0.989898269358908, 'recall': 0.9898841092123355, 'f1-score': 0.9898848755434715, 'support': 10182}
 
time = 30.82 secondes

Val loss 0.7936162035389636 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131990828246564, 'recall': 0.9056719375921614, 'f1-score': 0.9071294265184106, 'support': 1132} weighted_avg {'precision': 0.9096255221803872, 'recall': 0.9028268551236749, 'f1-score': 0.9037552313881405, 'support': 1132}
 
----------
Epoch 24/40
time = 1114.59 secondes

Train loss 0.04399941098220479 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919961057368154, 'recall': 0.9920428267227223, 'f1-score': 0.9920009652372783, 'support': 10182} weighted_avg {'precision': 0.9920978220091236, 'recall': 0.9920447849145551, 'f1-score': 0.9920531696989157, 'support': 10182}
 
time = 40.98 secondes

Val loss 0.8122427599947502 accuracy 0.9028268456459045 macro_avg {'precision': 0.9121225761037076, 'recall': 0.9058953550979032, 'f1-score': 0.905512504831522, 'support': 1132} weighted_avg {'precision': 0.9099222693408211, 'recall': 0.9028268551236749, 'f1-score': 0.9026512794229142, 'support': 1132}
 
----------
Epoch 25/40
time = 1348.57 secondes

Train loss 0.05157633342244607 accuracy 0.9911609292030334 macro_avg {'precision': 0.991235079616599, 'recall': 0.9910128289878702, 'f1-score': 0.9911122496694889, 'support': 10182} weighted_avg {'precision': 0.9911831736760645, 'recall': 0.9911608721272834, 'f1-score': 0.9911614428459055, 'support': 10182}
 
time = 30.44 secondes

Val loss 0.7859033855928713 accuracy 0.9090105891227722 macro_avg {'precision': 0.9183370192209784, 'recall': 0.9097627734904264, 'f1-score': 0.9118822614216973, 'support': 1132} weighted_avg {'precision': 0.913194382116697, 'recall': 0.9090106007067138, 'f1-score': 0.9089501762847121, 'support': 1132}
 
----------
Epoch 26/40
time = 1185.48 secondes

Train loss 0.03815147458516545 accuracy 0.9931251406669617 macro_avg {'precision': 0.9931207056707281, 'recall': 0.9929949659658257, 'f1-score': 0.9930501461758221, 'support': 10182} weighted_avg {'precision': 0.9931428057080325, 'recall': 0.9931251227656649, 'f1-score': 0.9931262692119824, 'support': 10182}
 
time = 40.54 secondes

Val loss 0.7952744145332475 accuracy 0.9037102460861206 macro_avg {'precision': 0.9088168321864577, 'recall': 0.9068121564382429, 'f1-score': 0.9052162969949664, 'support': 1132} weighted_avg {'precision': 0.9104586189376747, 'recall': 0.9037102473498233, 'f1-score': 0.9044359095808839, 'support': 1132}
 
----------
Epoch 27/40
time = 1254.75 secondes

Train loss 0.04687636622501382 accuracy 0.9919465780258179 macro_avg {'precision': 0.9913783057134566, 'recall': 0.9913846991272063, 'f1-score': 0.9913749594686664, 'support': 10182} weighted_avg {'precision': 0.9919659922809686, 'recall': 0.9919465723826361, 'f1-score': 0.9919497431243338, 'support': 10182}
 
time = 40.42 secondes

Val loss 0.7230789358727634 accuracy 0.916961133480072 macro_avg {'precision': 0.9204045652749689, 'recall': 0.9212877533354302, 'f1-score': 0.9197161326455235, 'support': 1132} weighted_avg {'precision': 0.9189325883975328, 'recall': 0.9169611307420494, 'f1-score': 0.9167505934278293, 'support': 1132}
 
----------
Epoch 28/40
time = 1124.97 secondes

Train loss 0.0346876363987369 accuracy 0.993812620639801 macro_avg {'precision': 0.993785827075021, 'recall': 0.9936224631453333, 'f1-score': 0.9936974384926796, 'support': 10182} weighted_avg {'precision': 0.9938255842704584, 'recall': 0.9938126104890984, 'f1-score': 0.9938126507339887, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.7594218039683281 accuracy 0.916077733039856 macro_avg {'precision': 0.9247947601594305, 'recall': 0.9130417711642312, 'f1-score': 0.9149844122186469, 'support': 1132} weighted_avg {'precision': 0.9211981005629416, 'recall': 0.916077738515901, 'f1-score': 0.9152967708359533, 'support': 1132}
 
----------
Epoch 29/40
time = 1081.95 secondes

Train loss 0.029682740100603552 accuracy 0.9943037033081055 macro_avg {'precision': 0.994152605246059, 'recall': 0.9941700468110615, 'f1-score': 0.9941577637436951, 'support': 10182} weighted_avg {'precision': 0.9943066431011253, 'recall': 0.9943036731486937, 'f1-score': 0.9943015746604917, 'support': 10182}
 
time = 30.19 secondes

Val loss 0.6428052852110417 accuracy 0.9187279343605042 macro_avg {'precision': 0.923623845854396, 'recall': 0.9232728062023368, 'f1-score': 0.9216879608226309, 'support': 1132} weighted_avg {'precision': 0.924515784885518, 'recall': 0.9187279151943463, 'f1-score': 0.9198638392432227, 'support': 1132}
 
----------
Epoch 30/40
time = 1074.27 secondes

Train loss 0.04244267715503399 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934845743208314, 'recall': 0.9934108940008418, 'f1-score': 0.993441166493812, 'support': 10182} weighted_avg {'precision': 0.9935294528454889, 'recall': 0.9935179728933412, 'f1-score': 0.99351754358324, 'support': 10182}
 
time = 30.73 secondes

Val loss 0.780875301633092 accuracy 0.9134275913238525 macro_avg {'precision': 0.9190056543572901, 'recall': 0.915465232910684, 'f1-score': 0.9143606560772973, 'support': 1132} weighted_avg {'precision': 0.9205614363350298, 'recall': 0.9134275618374559, 'f1-score': 0.9145049263741012, 'support': 1132}
 
----------
Epoch 31/40
time = 1076.25 secondes

Train loss 0.037834766441223085 accuracy 0.9935179948806763 macro_avg {'precision': 0.9931024802076875, 'recall': 0.9934809968282673, 'f1-score': 0.9932820732796935, 'support': 10182} weighted_avg {'precision': 0.9935412159073012, 'recall': 0.9935179728933412, 'f1-score': 0.993521526366487, 'support': 10182}
 
time = 29.94 secondes

Val loss 0.7062834084915177 accuracy 0.9196113348007202 macro_avg {'precision': 0.9219231256832684, 'recall': 0.9212209318968796, 'f1-score': 0.920578487641141, 'support': 1132} weighted_avg {'precision': 0.9224772180909359, 'recall': 0.9196113074204947, 'f1-score': 0.9201709547124864, 'support': 1132}
 
----------
Epoch 32/40
time = 1083.77 secondes

Train loss 0.02412203981095539 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960304982541324, 'recall': 0.9960496465411574, 'f1-score': 0.9960362633148098, 'support': 10182} weighted_avg {'precision': 0.9961755640010032, 'recall': 0.9961697112551562, 'f1-score': 0.9961691980492696, 'support': 10182}
 
time = 30.89 secondes

Val loss 0.6580886034170247 accuracy 0.9187279343605042 macro_avg {'precision': 0.9228078252720765, 'recall': 0.9221267933109788, 'f1-score': 0.921600794979606, 'support': 1132} weighted_avg {'precision': 0.9211518836347686, 'recall': 0.9187279151943463, 'f1-score': 0.9190321449724921, 'support': 1132}
 
----------
Epoch 33/40
time = 1483.08 secondes

Train loss 0.02530337013519771 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959803073846893, 'recall': 0.9960673795778192, 'f1-score': 0.9960212070872515, 'support': 10182} weighted_avg {'precision': 0.9960757622558254, 'recall': 0.9960714987232371, 'f1-score': 0.9960711430269469, 'support': 10182}
 
time = 53.96 secondes

Val loss 0.6948370012062914 accuracy 0.9222614765167236 macro_avg {'precision': 0.9275029628835825, 'recall': 0.9267365730890184, 'f1-score': 0.9247489970310475, 'support': 1132} weighted_avg {'precision': 0.9268186803404175, 'recall': 0.9222614840989399, 'f1-score': 0.9218882711831319, 'support': 1132}
 
----------
Epoch 34/40
time = 1595.51 secondes

Train loss 0.023037698807479606 accuracy 0.9959732890129089 macro_avg {'precision': 0.9959533744853157, 'recall': 0.9960475313452296, 'f1-score': 0.9959961119491328, 'support': 10182} weighted_avg {'precision': 0.9959823435775503, 'recall': 0.995973286191318, 'f1-score': 0.9959735622130645, 'support': 10182}
 
time = 65.61 secondes

Val loss 0.6623712189526921 accuracy 0.9231448769569397 macro_avg {'precision': 0.9294943267729266, 'recall': 0.9269410391314814, 'f1-score': 0.9272632533574103, 'support': 1132} weighted_avg {'precision': 0.9271176145909381, 'recall': 0.9231448763250883, 'f1-score': 0.9241115349345486, 'support': 1132}
 
----------
Epoch 35/40
time = 1726.40 secondes

Train loss 0.016237483508767716 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973019046787233, 'recall': 0.9973426933472478, 'f1-score': 0.9973190077220812, 'support': 10182} weighted_avg {'precision': 0.9972512226311497, 'recall': 0.9972500491062659, 'f1-score': 0.9972472179248817, 'support': 10182}
 
time = 37.47 secondes

Val loss 0.8065760831423817 accuracy 0.9143109321594238 macro_avg {'precision': 0.9206712506578478, 'recall': 0.917771633361687, 'f1-score': 0.9172342597162807, 'support': 1132} weighted_avg {'precision': 0.9186255959463229, 'recall': 0.9143109540636042, 'f1-score': 0.9144636679258188, 'support': 1132}
 
----------
Epoch 36/40
time = 1370.85 secondes

Train loss 0.025357766442642087 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961844434895871, 'recall': 0.995781970627846, 'f1-score': 0.9959683345671918, 'support': 10182} weighted_avg {'precision': 0.9961005527206787, 'recall': 0.9960714987232371, 'f1-score': 0.9960720771807897, 'support': 10182}
 
time = 32.65 secondes

Val loss 0.6931538505031966 accuracy 0.9204947352409363 macro_avg {'precision': 0.9241523840368053, 'recall': 0.9233341733643927, 'f1-score': 0.9222089538293217, 'support': 1132} weighted_avg {'precision': 0.9233787330782004, 'recall': 0.9204946996466431, 'f1-score': 0.9203009665384038, 'support': 1132}
 
----------
Epoch 37/40
time = 1533.49 secondes

Train loss 0.009452947335321683 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985752726146846, 'recall': 0.9984050155717765, 'f1-score': 0.9984880995518857, 'support': 10182} weighted_avg {'precision': 0.9985299897051066, 'recall': 0.998526812021214, 'f1-score': 0.998526665216976, 'support': 10182}
 
time = 50.69 secondes

Val loss 0.6974155892021885 accuracy 0.9284452199935913 macro_avg {'precision': 0.9307141080246586, 'recall': 0.9309652097008814, 'f1-score': 0.9298610666221713, 'support': 1132} weighted_avg {'precision': 0.9300566201728419, 'recall': 0.9284452296819788, 'f1-score': 0.9281881674613488, 'support': 1132}
 
----------
Epoch 38/40
time = 1139.06 secondes

Train loss 0.0073112805066428985 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985532627046865, 'recall': 0.9985109141219939, 'f1-score': 0.9985313372215815, 'support': 10182} weighted_avg {'precision': 0.9985285375777367, 'recall': 0.998526812021214, 'f1-score': 0.998526968399147, 'support': 10182}
 
time = 29.80 secondes

Val loss 0.69951459828607 accuracy 0.9257950782775879 macro_avg {'precision': 0.9268087234630148, 'recall': 0.9281142214004829, 'f1-score': 0.9264451133408542, 'support': 1132} weighted_avg {'precision': 0.9268198393796826, 'recall': 0.9257950530035336, 'f1-score': 0.9252727130551571, 'support': 1132}
 
----------
Epoch 39/40
time = 1078.94 secondes

Train loss 0.007423831143256576 accuracy 0.9987232685089111 macro_avg {'precision': 0.9985803342149723, 'recall': 0.9986694626825277, 'f1-score': 0.9986238832749494, 'support': 10182} weighted_avg {'precision': 0.9987249263288509, 'recall': 0.9987232370850521, 'f1-score': 0.9987232157191313, 'support': 10182}
 
time = 30.88 secondes

Val loss 0.6638481289054153 accuracy 0.9319788217544556 macro_avg {'precision': 0.9348373272106537, 'recall': 0.9332568964087973, 'f1-score': 0.9331794425757571, 'support': 1132} weighted_avg {'precision': 0.9327407372835154, 'recall': 0.9319787985865724, 'f1-score': 0.931473466176567, 'support': 1132}
 
----------
Epoch 40/40
time = 1263.51 secondes

Train loss 0.0035627700361880585 accuracy 0.9993125200271606 macro_avg {'precision': 0.9993165108132139, 'recall': 0.9993443809685154, 'f1-score': 0.9993299794245303, 'support': 10182} weighted_avg {'precision': 0.9993134876840168, 'recall': 0.9993125122765665, 'f1-score': 0.9993125274778357, 'support': 10182}
 
time = 42.41 secondes

Val loss 0.6577107990499019 accuracy 0.9328622221946716 macro_avg {'precision': 0.9352309384925, 'recall': 0.9348459847930638, 'f1-score': 0.9344182622918487, 'support': 1132} weighted_avg {'precision': 0.93365478118775, 'recall': 0.9328621908127208, 'f1-score': 0.9325864091480177, 'support': 1132}
 
----------
best_accuracy 0.9328622221946716 best_epoch 40 macro_avg {'precision': 0.9352309384925, 'recall': 0.9348459847930638, 'f1-score': 0.9344182622918487, 'support': 1132} weighted_avg {'precision': 0.93365478118775, 'recall': 0.9328621908127208, 'f1-score': 0.9325864091480177, 'support': 1132}

average train time 1209.2859081029892

average val time 34.97829531431198
 
time = 245.03 secondes

test_accuracy 0.8592671155929565 macro_avg {'precision': 0.8576221432779153, 'recall': 0.8515066389187063, 'f1-score': 0.8524181344711739, 'support': 7532} weighted_avg {'precision': 0.8637431675034107, 'recall': 0.8592671269251195, 'f1-score': 0.8593961799461779, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_4
----------
Epoch 1/40
time = 2243.32 secondes

Train loss 1.059549014857463 accuracy 0.7002553939819336 macro_avg {'precision': 0.6991761379493664, 'recall': 0.6864622382657377, 'f1-score': 0.6822266176845848, 'support': 10182} weighted_avg {'precision': 0.7082734047094047, 'recall': 0.7002553525829895, 'f1-score': 0.6959017584953662, 'support': 10182}
 
time = 49.04 secondes

Val loss 0.542015372237689 accuracy 0.843639612197876 macro_avg {'precision': 0.8434036713472768, 'recall': 0.8352077213042557, 'f1-score': 0.823987845869403, 'support': 1132} weighted_avg {'precision': 0.8444404213191884, 'recall': 0.8436395759717314, 'f1-score': 0.8320128595064826, 'support': 1132}
 
----------
Epoch 2/40
time = 2070.34 secondes

Train loss 0.3780572526273866 accuracy 0.890787661075592 macro_avg {'precision': 0.8850657932027538, 'recall': 0.8827728610228511, 'f1-score': 0.8829732424897528, 'support': 10182} weighted_avg {'precision': 0.8904700500875041, 'recall': 0.890787664505991, 'f1-score': 0.8898567440713916, 'support': 10182}
 
time = 38.08 secondes

Val loss 0.48352061250102774 accuracy 0.8736749291419983 macro_avg {'precision': 0.876358959469982, 'recall': 0.8735641208237286, 'f1-score': 0.8711976371200526, 'support': 1132} weighted_avg {'precision': 0.8783487590308204, 'recall': 0.8736749116607774, 'f1-score': 0.8722276169716068, 'support': 1132}
 
----------
Epoch 3/40
time = 2003.11 secondes

Train loss 0.2327720494356059 accuracy 0.9342958331108093 macro_avg {'precision': 0.9319306291204553, 'recall': 0.9310620943948569, 'f1-score': 0.9313511575419524, 'support': 10182} weighted_avg {'precision': 0.9343889027918124, 'recall': 0.9342958161461402, 'f1-score': 0.9342052601308445, 'support': 10182}
 
time = 38.34 secondes

Val loss 0.4876463852796546 accuracy 0.8878092169761658 macro_avg {'precision': 0.8949966778044928, 'recall': 0.8925726232011945, 'f1-score': 0.8880402314698937, 'support': 1132} weighted_avg {'precision': 0.8981047831835887, 'recall': 0.8878091872791519, 'f1-score': 0.8864933699092781, 'support': 1132}
 
----------
Epoch 4/40
time = 2101.15 secondes

Train loss 0.1778091686303337 accuracy 0.9523669481277466 macro_avg {'precision': 0.9497223282565462, 'recall': 0.9497915880720486, 'f1-score': 0.9496941986288988, 'support': 10182} weighted_avg {'precision': 0.9524599458383759, 'recall': 0.9523669220192497, 'f1-score': 0.952351826422658, 'support': 10182}
 
time = 50.49 secondes

Val loss 0.5825318733007241 accuracy 0.8789752721786499 macro_avg {'precision': 0.8914980674501125, 'recall': 0.8708331136767102, 'f1-score': 0.8704373884198391, 'support': 1132} weighted_avg {'precision': 0.8908064609404862, 'recall': 0.8789752650176679, 'f1-score': 0.8762291682642198, 'support': 1132}
 
----------
Epoch 5/40
time = 2239.25 secondes

Train loss 0.15327352029728314 accuracy 0.9617953300476074 macro_avg {'precision': 0.9604358830864845, 'recall': 0.9602485486649355, 'f1-score': 0.9603036714976133, 'support': 10182} weighted_avg {'precision': 0.9619192360426724, 'recall': 0.9617953250834806, 'f1-score': 0.9618178083345703, 'support': 10182}
 
time = 48.14 secondes

Val loss 0.5501713399007969 accuracy 0.8939929604530334 macro_avg {'precision': 0.9011816456119226, 'recall': 0.8906070533572364, 'f1-score': 0.8918095290781386, 'support': 1132} weighted_avg {'precision': 0.9005902426099822, 'recall': 0.8939929328621908, 'f1-score': 0.8934616760612463, 'support': 1132}
 
----------
Epoch 6/40
time = 2151.62 secondes

Train loss 0.13776833367498528 accuracy 0.9666077494621277 macro_avg {'precision': 0.9655300945788579, 'recall': 0.9653487809088561, 'f1-score': 0.9654100925221247, 'support': 10182} weighted_avg {'precision': 0.966673646100108, 'recall': 0.9666077391475152, 'f1-score': 0.966612732944157, 'support': 10182}
 
time = 36.85 secondes

Val loss 0.5799911617494884 accuracy 0.9063604474067688 macro_avg {'precision': 0.9108829662473065, 'recall': 0.9075949571944927, 'f1-score': 0.9068328207209302, 'support': 1132} weighted_avg {'precision': 0.9098583631264552, 'recall': 0.9063604240282686, 'f1-score': 0.9056757296947632, 'support': 1132}
 
----------
Epoch 7/40
time = 1993.27 secondes

Train loss 0.1337626845888564 accuracy 0.9706344604492188 macro_avg {'precision': 0.969899476221989, 'recall': 0.9701116320677936, 'f1-score': 0.9699892591584769, 'support': 10182} weighted_avg {'precision': 0.9707086750846081, 'recall': 0.9706344529561972, 'f1-score': 0.9706552755334228, 'support': 10182}
 
time = 35.08 secondes

Val loss 0.6034530389895761 accuracy 0.9072438478469849 macro_avg {'precision': 0.9111990787663726, 'recall': 0.9040632453381917, 'f1-score': 0.9045671592793807, 'support': 1132} weighted_avg {'precision': 0.9117597692316076, 'recall': 0.907243816254417, 'f1-score': 0.9067742148846281, 'support': 1132}
 
----------
Epoch 8/40
time = 2000.17 secondes

Train loss 0.11524298709893623 accuracy 0.9741701483726501 macro_avg {'precision': 0.9735899063467451, 'recall': 0.973242296045463, 'f1-score': 0.9733773483662003, 'support': 10182} weighted_avg {'precision': 0.9742856003994201, 'recall': 0.9741701041052838, 'f1-score': 0.974190150615172, 'support': 10182}
 
time = 39.46 secondes

Val loss 0.6152933229229899 accuracy 0.9054770469665527 macro_avg {'precision': 0.9065914234275676, 'recall': 0.9086973401932976, 'f1-score': 0.9058817356742741, 'support': 1132} weighted_avg {'precision': 0.9087951508208847, 'recall': 0.9054770318021201, 'f1-score': 0.9054388405371235, 'support': 1132}
 
----------
Epoch 9/40
time = 2257.55 secondes

Train loss 0.11403048444314337 accuracy 0.9743665456771851 macro_avg {'precision': 0.973180267713485, 'recall': 0.9733217000050001, 'f1-score': 0.9732329356994771, 'support': 10182} weighted_avg {'precision': 0.9744010278227467, 'recall': 0.974366529169122, 'f1-score': 0.974365923041346, 'support': 10182}
 
time = 45.27 secondes

Val loss 0.639741974106816 accuracy 0.8992933034896851 macro_avg {'precision': 0.9023744434861201, 'recall': 0.9017297140948681, 'f1-score': 0.8994538261540381, 'support': 1132} weighted_avg {'precision': 0.9023663223416586, 'recall': 0.8992932862190812, 'f1-score': 0.8979853552053316, 'support': 1132}
 
----------
Epoch 10/40
time = 2216.95 secondes

Train loss 0.1018897864296506 accuracy 0.978295087814331 macro_avg {'precision': 0.9774471365243297, 'recall': 0.9775395880532389, 'f1-score': 0.9774356394496962, 'support': 10182} weighted_avg {'precision': 0.9784607685440637, 'recall': 0.978295030445885, 'f1-score': 0.9783271429294919, 'support': 10182}
 
time = 45.65 secondes

Val loss 0.6833716277490144 accuracy 0.898409903049469 macro_avg {'precision': 0.9076368690870927, 'recall': 0.9017955132122852, 'f1-score': 0.9010319310134154, 'support': 1132} weighted_avg {'precision': 0.9053672135331219, 'recall': 0.8984098939929329, 'f1-score': 0.8980445866463626, 'support': 1132}
 
----------
Epoch 11/40
time = 2213.70 secondes

Train loss 0.10006662081494662 accuracy 0.9799646735191345 macro_avg {'precision': 0.9796320266349777, 'recall': 0.9797284101733595, 'f1-score': 0.9796440878005891, 'support': 10182} weighted_avg {'precision': 0.9800493854573541, 'recall': 0.9799646434885091, 'f1-score': 0.9799721583807437, 'support': 10182}
 
time = 45.55 secondes

Val loss 0.7438561650118906 accuracy 0.898409903049469 macro_avg {'precision': 0.9047675164750402, 'recall': 0.9030113518032492, 'f1-score': 0.9013275995129444, 'support': 1132} weighted_avg {'precision': 0.9055353735715587, 'recall': 0.8984098939929329, 'f1-score': 0.8991189869091598, 'support': 1132}
 
----------
Epoch 12/40
time = 2202.67 secondes

Train loss 0.10153564484212003 accuracy 0.980553925037384 macro_avg {'precision': 0.9798993720084928, 'recall': 0.9799530608021844, 'f1-score': 0.9799073027566447, 'support': 10182} weighted_avg {'precision': 0.9805557023951337, 'recall': 0.9805539186800236, 'f1-score': 0.9805351819165006, 'support': 10182}
 
time = 45.99 secondes

Val loss 0.8536441428217919 accuracy 0.880742073059082 macro_avg {'precision': 0.8954054429671725, 'recall': 0.8857024107944003, 'f1-score': 0.8840026503382928, 'support': 1132} weighted_avg {'precision': 0.897897985205689, 'recall': 0.8807420494699647, 'f1-score': 0.8823052538678255, 'support': 1132}
 
----------
Epoch 13/40
time = 2198.29 secondes

Train loss 0.1059921272119578 accuracy 0.9798664450645447 macro_avg {'precision': 0.9800188907049877, 'recall': 0.979991791018262, 'f1-score': 0.9799825368002859, 'support': 10182} weighted_avg {'precision': 0.9799000407370625, 'recall': 0.9798664309565901, 'f1-score': 0.9798596978372531, 'support': 10182}
 
time = 48.69 secondes

Val loss 0.7320992776014822 accuracy 0.8966431021690369 macro_avg {'precision': 0.9055445179176308, 'recall': 0.898406871848203, 'f1-score': 0.898834659234861, 'support': 1132} weighted_avg {'precision': 0.9062955611158199, 'recall': 0.8966431095406361, 'f1-score': 0.8983192863317429, 'support': 1132}
 
----------
Epoch 14/40
time = 2197.17 secondes

Train loss 0.09852405178507394 accuracy 0.9823217988014221 macro_avg {'precision': 0.9816749679676617, 'recall': 0.9819454720781593, 'f1-score': 0.9817985284469479, 'support': 10182} weighted_avg {'precision': 0.982346600142384, 'recall': 0.9823217442545669, 'f1-score': 0.98232328122762, 'support': 10182}
 
time = 47.26 secondes

Val loss 0.7042125119640358 accuracy 0.9019434452056885 macro_avg {'precision': 0.9054322467214782, 'recall': 0.9034090580254389, 'f1-score': 0.9017446360401642, 'support': 1132} weighted_avg {'precision': 0.9071715487373676, 'recall': 0.9019434628975265, 'f1-score': 0.9018778620327541, 'support': 1132}
 
----------
Epoch 15/40
time = 2084.36 secondes

Train loss 0.08138138712711852 accuracy 0.9843842387199402 macro_avg {'precision': 0.984047944703305, 'recall': 0.98422529731273, 'f1-score': 0.9841236713938744, 'support': 10182} weighted_avg {'precision': 0.9844144416938134, 'recall': 0.9843842074248674, 'f1-score': 0.9843867898730997, 'support': 10182}
 
time = 39.01 secondes

Val loss 0.6579489896838835 accuracy 0.9107773900032043 macro_avg {'precision': 0.9169692071880051, 'recall': 0.9122385672997824, 'f1-score': 0.9126165014215424, 'support': 1132} weighted_avg {'precision': 0.9130783248633586, 'recall': 0.9107773851590106, 'f1-score': 0.9099694683427165, 'support': 1132}
 
----------
Epoch 16/40
time = 1953.17 secondes

Train loss 0.0732262019917862 accuracy 0.9849734902381897 macro_avg {'precision': 0.9843783300920748, 'recall': 0.9842207660032445, 'f1-score': 0.9842811823606746, 'support': 10182} weighted_avg {'precision': 0.9849836840126971, 'recall': 0.9849734826163818, 'f1-score': 0.9849604572833517, 'support': 10182}
 
time = 39.08 secondes

Val loss 0.60236141822464 accuracy 0.9187279343605042 macro_avg {'precision': 0.9218106413148602, 'recall': 0.9201404149421644, 'f1-score': 0.9198536847623539, 'support': 1132} weighted_avg {'precision': 0.9204712033736528, 'recall': 0.9187279151943463, 'f1-score': 0.9185686292807577, 'support': 1132}
 
----------
Epoch 17/40
time = 1952.26 secondes

Train loss 0.07461275247471086 accuracy 0.9870359897613525 macro_avg {'precision': 0.9866682787999388, 'recall': 0.9867703310935505, 'f1-score': 0.9867103632186256, 'support': 10182} weighted_avg {'precision': 0.9870666602794907, 'recall': 0.9870359457866824, 'f1-score': 0.9870425874012123, 'support': 10182}
 
time = 38.87 secondes

Val loss 0.8689273280072318 accuracy 0.8833922147750854 macro_avg {'precision': 0.9041968323783202, 'recall': 0.8909257037411544, 'f1-score': 0.8870411614721277, 'support': 1132} weighted_avg {'precision': 0.9048471812805035, 'recall': 0.8833922261484098, 'f1-score': 0.8818751687882025, 'support': 1132}
 
----------
Epoch 18/40
time = 1948.57 secondes

Train loss 0.05926845399382551 accuracy 0.9889020323753357 macro_avg {'precision': 0.988459945109559, 'recall': 0.9881269774573591, 'f1-score': 0.9882775445593621, 'support': 10182} weighted_avg {'precision': 0.9889130570125194, 'recall': 0.9889019838931448, 'f1-score': 0.9888928433444076, 'support': 10182}
 
time = 38.74 secondes

Val loss 0.7386733614316974 accuracy 0.9054770469665527 macro_avg {'precision': 0.9098056303186673, 'recall': 0.9054139745064793, 'f1-score': 0.9052410344096492, 'support': 1132} weighted_avg {'precision': 0.9101745758415543, 'recall': 0.9054770318021201, 'f1-score': 0.9054091385581162, 'support': 1132}
 
----------
Epoch 19/40
time = 1961.64 secondes

Train loss 0.06776501728845016 accuracy 0.9874288439750671 macro_avg {'precision': 0.9868602697508031, 'recall': 0.9869250830178627, 'f1-score': 0.9868837027564213, 'support': 10182} weighted_avg {'precision': 0.9874392608788158, 'recall': 0.9874287959143587, 'f1-score': 0.9874254772151602, 'support': 10182}
 
time = 39.29 secondes

Val loss 0.7558043607097434 accuracy 0.8975265026092529 macro_avg {'precision': 0.9065707619486514, 'recall': 0.9008582703318616, 'f1-score': 0.9009283486244876, 'support': 1132} weighted_avg {'precision': 0.9046348386483544, 'recall': 0.8975265017667845, 'f1-score': 0.897922669335482, 'support': 1132}
 
----------
Epoch 20/40
time = 2023.82 secondes

Train loss 0.07450043611406927 accuracy 0.9863485097885132 macro_avg {'precision': 0.9863995214678134, 'recall': 0.9864315444979054, 'f1-score': 0.9863823749099392, 'support': 10182} weighted_avg {'precision': 0.9864157005241835, 'recall': 0.9863484580632489, 'f1-score': 0.9863495180716941, 'support': 10182}
 
time = 45.31 secondes

Val loss 0.6979470930946007 accuracy 0.9063604474067688 macro_avg {'precision': 0.9138358602965166, 'recall': 0.9097497808528983, 'f1-score': 0.909591433154905, 'support': 1132} weighted_avg {'precision': 0.912452283340964, 'recall': 0.9063604240282686, 'f1-score': 0.9071746783072563, 'support': 1132}
 
----------
Epoch 21/40
Exception
CUDA out of memory. Tried to allocate 772.00 MiB (GPU 0; 79.21 GiB total capacity; 65.03 GiB already allocated; 763.62 MiB free; 67.05 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 372.00 MiB (GPU 0; 79.21 GiB total capacity; 66.18 GiB already allocated; 143.62 MiB free; 67.96 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 79.21 GiB total capacity; 63.69 GiB already allocated; 1.44 GiB free; 66.66 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_64_5
----------
Epoch 1/40
time = 50.37 secondes

Train loss 0.5785357464443553 accuracy 0.7209302186965942 macro_avg {'precision': 0.777877859845073, 'recall': 0.6253596216049282, 'f1-score': 0.6178406846609612, 'support': 516} weighted_avg {'precision': 0.757353588081762, 'recall': 0.7209302325581395, 'f1-score': 0.6724627585467795, 'support': 516}
 
time = 1.74 secondes

Val loss 0.4417421296238899 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 2/40
time = 49.92 secondes

Train loss 0.43623110245574603 accuracy 0.8003876209259033 macro_avg {'precision': 0.7851372914034971, 'recall': 0.778838808250573, 'f1-score': 0.7816927152861926, 'support': 516} weighted_avg {'precision': 0.7986719375309554, 'recall': 0.8003875968992248, 'f1-score': 0.7992733324322229, 'support': 516}
 
time = 1.78 secondes

Val loss 0.43553073704242706 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 46.49 secondes

Train loss 0.27082930889093515 accuracy 0.9031007885932922 macro_avg {'precision': 0.895860210663836, 'recall': 0.8940071192887213, 'f1-score': 0.8949169110459433, 'support': 516} weighted_avg {'precision': 0.9029024035628407, 'recall': 0.9031007751937985, 'f1-score': 0.9029871104139672, 'support': 516}
 
time = 1.27 secondes

Val loss 0.5664536282420158 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 4/40
time = 56.81 secondes

Train loss 0.2047454687682065 accuracy 0.9224806427955627 macro_avg {'precision': 0.9187103158241939, 'recall': 0.9126668075353932, 'f1-score': 0.9155316919853327, 'support': 516} weighted_avg {'precision': 0.9221868302071807, 'recall': 0.9224806201550387, 'f1-score': 0.9221989068508614, 'support': 516}
 
time = 1.74 secondes

Val loss 0.46314261853694916 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 5/40
time = 50.49 secondes

Train loss 0.16994805580400157 accuracy 0.9515503644943237 macro_avg {'precision': 0.9563953488372092, 'recall': 0.9389252799765941, 'f1-score': 0.9466075072328203, 'support': 516} weighted_avg {'precision': 0.9523954389760231, 'recall': 0.9515503875968992, 'f1-score': 0.9510781378805859, 'support': 516}
 
time = 1.79 secondes

Val loss 0.7137393206357956 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 6/40
time = 51.09 secondes

Train loss 0.17125710816771694 accuracy 0.9476743936538696 macro_avg {'precision': 0.941358024691358, 'recall': 0.9462721258716252, 'f1-score': 0.9437061340595667, 'support': 516} weighted_avg {'precision': 0.9481529332950521, 'recall': 0.9476744186046512, 'f1-score': 0.9478192465077563, 'support': 516}
 
time = 1.77 secondes

Val loss 0.5731381922960281 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 7/40
time = 45.77 secondes

Train loss 0.34058457927665475 accuracy 0.9108527302742004 macro_avg {'precision': 0.8990288244891617, 'recall': 0.9173967459324155, 'f1-score': 0.9059334527527225, 'support': 516} weighted_avg {'precision': 0.9168904435727455, 'recall': 0.9108527131782945, 'f1-score': 0.9118532407224786, 'support': 516}
 
time = 1.53 secondes

Val loss 1.2049719989299774 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 8/40
time = 36.26 secondes

Train loss 0.17929535172879696 accuracy 0.9457364082336426 macro_avg {'precision': 0.9491565412292085, 'recall': 0.9332119695073386, 'f1-score': 0.9402777777777778, 'support': 516} weighted_avg {'precision': 0.9462997458695805, 'recall': 0.9457364341085271, 'f1-score': 0.9452465546942291, 'support': 516}
 
time = 1.50 secondes

Val loss 0.624084485694766 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 9/40
time = 37.78 secondes

Train loss 0.08933507653912812 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.51 secondes

Val loss 0.9640759527683258 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 10/40
time = 37.23 secondes

Train loss 0.16304157955120457 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.51 secondes

Val loss 1.364451378583908 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 11/40
time = 37.49 secondes

Train loss 0.1857795735969293 accuracy 0.9496123790740967 macro_avg {'precision': 0.9615217504649021, 'recall': 0.931635323374998, 'f1-score': 0.9437955592794303, 'support': 516} weighted_avg {'precision': 0.9526210803296072, 'recall': 0.9496124031007752, 'f1-score': 0.9487714136326291, 'support': 516}
 
time = 1.50 secondes

Val loss 1.090748518705368 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 12/40
time = 36.40 secondes

Train loss 0.36802843679448194 accuracy 0.9147287011146545 macro_avg {'precision': 0.9048263131931957, 'recall': 0.9135120198949986, 'f1-score': 0.9087577160493827, 'support': 516} weighted_avg {'precision': 0.916352021347157, 'recall': 0.9147286821705426, 'f1-score': 0.9151810280888124, 'support': 516}
 
time = 1.53 secondes

Val loss 0.5019816942512989 accuracy 0.90625 macro_avg {'precision': 0.9019607843137255, 'recall': 0.9149797570850202, 'f1-score': 0.9047619047619049, 'support': 64} weighted_avg {'precision': 0.914828431372549, 'recall': 0.90625, 'f1-score': 0.9069940476190477, 'support': 64}
 
----------
Epoch 13/40
time = 38.02 secondes

Train loss 0.0328395896887576 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.56 secondes

Val loss 1.525788590312004 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 14/40
time = 36.96 secondes

Train loss 0.19201526149514725 accuracy 0.9651162624359131 macro_avg {'precision': 0.9622580173268533, 'recall': 0.9622580173268533, 'f1-score': 0.9622580173268533, 'support': 516} weighted_avg {'precision': 0.9651162790697675, 'recall': 0.9651162790697675, 'f1-score': 0.9651162790697675, 'support': 516}
 
time = 1.53 secondes

Val loss 1.5498851090669632 accuracy 0.71875 macro_avg {'precision': 0.7583333333333333, 'recall': 0.7510121457489879, 'f1-score': 0.718475073313783, 'support': 64} weighted_avg {'precision': 0.7880208333333333, 'recall': 0.71875, 'f1-score': 0.716825513196481, 'support': 64}
 
----------
Epoch 15/40
time = 40.01 secondes

Train loss 0.30489716843426734 accuracy 0.9379844665527344 macro_avg {'precision': 0.930653363063251, 'recall': 0.9363652617720202, 'f1-score': 0.9333548595414918, 'support': 516} weighted_avg {'precision': 0.9386612160988722, 'recall': 0.937984496124031, 'f1-score': 0.9381887447967902, 'support': 516}
 
time = 1.49 secondes

Val loss 1.1167567521333694 accuracy 0.8125 macro_avg {'precision': 0.8196078431372549, 'recall': 0.8299595141700404, 'f1-score': 0.8117647058823529, 'support': 64} weighted_avg {'precision': 0.8409313725490197, 'recall': 0.8125, 'f1-score': 0.8139705882352941, 'support': 64}
 
----------
Epoch 16/40
time = 36.55 secondes

Train loss 0.6880099339504148 accuracy 0.8875969052314758 macro_avg {'precision': 0.876850767577279, 'recall': 0.881849064577475, 'f1-score': 0.8792056829189538, 'support': 516} weighted_avg {'precision': 0.888588849838424, 'recall': 0.8875968992248062, 'f1-score': 0.887967099944182, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9743818044662476 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 17/40
time = 37.10 secondes

Train loss 0.04038924096631959 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.51 secondes

Val loss 0.8908985704183578 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 18/40
time = 36.67 secondes

Train loss 0.05158346899781574 accuracy 0.9864341020584106 macro_avg {'precision': 0.9837746206005813, 'recall': 0.9870536222225834, 'f1-score': 0.9853726689209712, 'support': 516} weighted_avg {'precision': 0.9865514388768326, 'recall': 0.9864341085271318, 'f1-score': 0.9864570172956102, 'support': 516}
 
time = 1.54 secondes

Val loss 1.136631190776825 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 19/40
time = 37.49 secondes

Train loss 0.3833118747555118 accuracy 0.9418604373931885 macro_avg {'precision': 0.9562390994133503, 'recall': 0.9209401362092227, 'f1-score': 0.9347815096311026, 'support': 516} weighted_avg {'precision': 0.9459271495639355, 'recall': 0.9418604651162791, 'f1-score': 0.9406945195069558, 'support': 516}
 
time = 1.59 secondes

Val loss 0.6167784109711647 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 20/40
time = 44.70 secondes

Train loss 0.1696175141352631 accuracy 0.963178277015686 macro_avg {'precision': 0.9579475308641976, 'recall': 0.9630463403930237, 'f1-score': 0.9603857980419174, 'support': 516} weighted_avg {'precision': 0.9635745645516317, 'recall': 0.9631782945736435, 'f1-score': 0.9632802105054582, 'support': 516}
 
time = 1.72 secondes

Val loss 1.8512237966060638 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 21/40
time = 48.18 secondes

Train loss 0.02433981015058111 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.69 secondes

Val loss 1.2347436770796776 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 22/40
time = 48.25 secondes

Train loss 0.3162043102497454 accuracy 0.9534883499145508 macro_avg {'precision': 0.9660056657223797, 'recall': 0.9358288770053476, 'f1-score': 0.9481189777963972, 'support': 516} weighted_avg {'precision': 0.9566506357467554, 'recall': 0.9534883720930233, 'f1-score': 0.9527120741224266, 'support': 516}
 
time = 1.92 secondes

Val loss 0.861766133835772 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 23/40
time = 43.40 secondes

Train loss 0.10592500182180876 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.24 secondes

Val loss 1.4977411963045597 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 24/40
time = 47.08 secondes

Train loss 0.09178342920825923 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.49 secondes

Val loss 0.8594629913568497 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 25/40
time = 36.17 secondes

Train loss 0.14807472024580365 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.51 secondes

Val loss 1.9010960161685944 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 26/40
time = 36.11 secondes

Train loss 0.038501093977670695 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.57 secondes

Val loss 0.7616828689642716 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 27/40
time = 36.70 secondes

Train loss 0.03727828310608553 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.89 secondes

Val loss 0.8963013953762129 accuracy 0.875 macro_avg {'precision': 0.8954545454545455, 'recall': 0.8522267206477733, 'f1-score': 0.8642629904559915, 'support': 64} weighted_avg {'precision': 0.8852272727272728, 'recall': 0.875, 'f1-score': 0.8714209968186639, 'support': 64}
 
----------
Epoch 28/40
time = 36.40 secondes

Train loss 0.02583663882427517 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.51 secondes

Val loss 0.7788073015399277 accuracy 0.875 macro_avg {'precision': 0.8831168831168831, 'recall': 0.8582995951417004, 'f1-score': 0.8666666666666667, 'support': 64} weighted_avg {'precision': 0.8782467532467533, 'recall': 0.875, 'f1-score': 0.8729166666666667, 'support': 64}
 
----------
Epoch 29/40
time = 36.78 secondes

Train loss 0.07138461387181781 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.50 secondes

Val loss 1.4827834218740463 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 30/40
time = 36.59 secondes

Train loss 0.017415500096059546 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.45 secondes

Val loss 1.6044223308563232 accuracy 0.75 macro_avg {'precision': 0.7773279352226721, 'recall': 0.7773279352226721, 'f1-score': 0.7499999999999999, 'support': 64} weighted_avg {'precision': 0.8046558704453441, 'recall': 0.75, 'f1-score': 0.7499999999999999, 'support': 64}
 
----------
Epoch 31/40
time = 38.34 secondes

Train loss 0.08602908646891151 accuracy 0.9806201457977295 macro_avg {'precision': 0.9746192893401016, 'recall': 0.9848024316109423, 'f1-score': 0.9792631172839505, 'support': 516} weighted_avg {'precision': 0.9816039035139495, 'recall': 0.9806201550387597, 'f1-score': 0.9807229609292756, 'support': 516}
 
time = 1.51 secondes

Val loss 1.71498404443264 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 32/40
time = 38.33 secondes

Train loss 0.03763934879040762 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.31 secondes

Val loss 0.5475304075080203 accuracy 0.90625 macro_avg {'precision': 0.9083333333333333, 'recall': 0.8967611336032388, 'f1-score': 0.9015384615384615, 'support': 64} weighted_avg {'precision': 0.9067708333333333, 'recall': 0.90625, 'f1-score': 0.9055769230769231, 'support': 64}
 
----------
Epoch 33/40
time = 47.89 secondes

Train loss 0.0011520596064766517 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.76 secondes

Val loss 0.6424322120892612 accuracy 0.921875 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}
 
----------
Epoch 34/40
time = 47.51 secondes

Train loss 0.05396978022690746 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.72 secondes

Val loss 1.2283049449324608 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 35/40
time = 47.89 secondes

Train loss 5.9699193529509515e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.140531338751316 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 36/40
time = 42.32 secondes

Train loss 0.07929666361572647 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.17 secondes

Val loss 1.1519591361284256 accuracy 0.875 macro_avg {'precision': 0.875, 'recall': 0.8643724696356275, 'f1-score': 0.8687179487179488, 'support': 64} weighted_avg {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.8741025641025642, 'support': 64}
 
----------
Epoch 37/40
time = 52.18 secondes

Train loss 0.0003500996348465736 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.75 secondes

Val loss 1.126236841082573 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 38/40
time = 47.40 secondes

Train loss 4.362430329572155e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.75 secondes

Val loss 1.299934297800064 accuracy 0.859375 macro_avg {'precision': 0.9042553191489362, 'recall': 0.8269230769230769, 'f1-score': 0.8424076607387141, 'support': 64} weighted_avg {'precision': 0.8863031914893617, 'recall': 0.859375, 'f1-score': 0.8521032831737346, 'support': 64}
 
----------
Epoch 39/40
time = 47.35 secondes

Train loss 0.01226048874399787 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.88 secondes

Val loss 1.7424597144126892 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 40/40
time = 45.58 secondes

Train loss 0.00027114622626510084 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.45 secondes

Val loss 1.4189036190509796 accuracy 0.84375 macro_avg {'precision': 0.8958333333333333, 'recall': 0.8076923076923077, 'f1-score': 0.8228128460686601, 'support': 64} weighted_avg {'precision': 0.8763020833333333, 'recall': 0.84375, 'f1-score': 0.834233111849391, 'support': 64}
 
----------
best_accuracy 0.921875 best_epoch 33 macro_avg {'precision': 0.9418604651162791, 'recall': 0.9038461538461539, 'f1-score': 0.9159443131074336, 'support': 64} weighted_avg {'precision': 0.9309593023255814, 'recall': 0.921875, 'f1-score': 0.9201306803257159, 'support': 64}

average train time 42.60167174935341

average val time 1.5871415555477142
 
time = 1.71 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9634146341463414, 'recall': 0.9444444444444444, 'f1-score': 0.9516008935219658, 'support': 65} weighted_avg {'precision': 0.9572232645403377, 'recall': 0.9538461538461539, 'f1-score': 0.9533650266338279, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_5
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 31.91 secondes

Train loss 0.6055088810848467 accuracy 0.6976743936538696 macro_avg {'precision': 0.7507756850063365, 'recall': 0.5932740601076021, 'f1-score': 0.5715015756749852, 'support': 516} weighted_avg {'precision': 0.7327364988124626, 'recall': 0.6976744186046512, 'f1-score': 0.6354892317321729, 'support': 516}
 
time = 1.71 secondes

Val loss 0.5178461596369743 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 2/40
time = 30.05 secondes

Train loss 0.41637915056763275 accuracy 0.815891444683075 macro_avg {'precision': 0.8009286412512219, 'recall': 0.8002291825821237, 'f1-score': 0.8005752480604701, 'support': 516} weighted_avg {'precision': 0.8156836557624254, 'recall': 0.8158914728682171, 'f1-score': 0.8157843664010298, 'support': 516}
 
time = 1.23 secondes

Val loss 0.4601578861474991 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 3/40
time = 28.72 secondes

Train loss 0.29384797359957837 accuracy 0.8837209343910217 macro_avg {'precision': 0.8747938270596881, 'recall': 0.8730393511369732, 'f1-score': 0.8739002932551321, 'support': 516} weighted_avg {'precision': 0.8834763520634384, 'recall': 0.8837209302325582, 'f1-score': 0.8835845324967607, 'support': 516}
 
time = 1.21 secondes

Val loss 0.4497328996658325 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 4/40
time = 28.76 secondes

Train loss 0.2003762016467976 accuracy 0.9457364082336426 macro_avg {'precision': 0.938269829858615, 'recall': 0.9459064089852576, 'f1-score': 0.9418123238018525, 'support': 516} weighted_avg {'precision': 0.9466845743307383, 'recall': 0.9457364341085271, 'f1-score': 0.9459707093507166, 'support': 516}
 
time = 1.27 secondes

Val loss 0.8374121934175491 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 5/40
time = 28.39 secondes

Train loss 0.19977518267026453 accuracy 0.9379844665527344 macro_avg {'precision': 0.9337797011513024, 'recall': 0.9317491019618679, 'f1-score': 0.9327468230694037, 'support': 516} weighted_avg {'precision': 0.9378692962617645, 'recall': 0.937984496124031, 'f1-score': 0.937911750664939, 'support': 516}
 
time = 1.14 secondes

Val loss 0.7177746891975403 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 6/40
time = 28.10 secondes

Train loss 0.2395004698668014 accuracy 0.9166666865348816 macro_avg {'precision': 0.9241996233521657, 'recall': 0.8954130975407572, 'f1-score': 0.9069166453410078, 'support': 516} weighted_avg {'precision': 0.9186283741368487, 'recall': 0.9166666666666666, 'f1-score': 0.9152070826358794, 'support': 516}
 
time = 1.22 secondes

Val loss 0.5157174468040466 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 7/40
time = 29.83 secondes

Train loss 0.3180221591681016 accuracy 0.9031007885932922 macro_avg {'precision': 0.8939347563431332, 'recall': 0.8974692391463355, 'f1-score': 0.8956361341682443, 'support': 516} weighted_avg {'precision': 0.9036480001998084, 'recall': 0.9031007751937985, 'f1-score': 0.9033171416003363, 'support': 516}
 
time = 1.40 secondes

Val loss 1.368193730711937 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 8/40
time = 28.59 secondes

Train loss 0.3218901076170644 accuracy 0.9186046719551086 macro_avg {'precision': 0.9135528971594545, 'recall': 0.9096272938575817, 'f1-score': 0.9115211888625786, 'support': 516} weighted_avg {'precision': 0.9183352242826127, 'recall': 0.9186046511627907, 'f1-score': 0.9184105837025108, 'support': 516}
 
time = 0.83 secondes

Val loss 1.0186066329479218 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 9/40
time = 28.10 secondes

Train loss 0.17021271953302802 accuracy 0.9496123790740967 macro_avg {'precision': 0.9430693466369368, 'recall': 0.9489459226630691, 'f1-score': 0.9458508233774621, 'support': 516} weighted_avg {'precision': 0.950216377543591, 'recall': 0.9496124031007752, 'f1-score': 0.9497783551473921, 'support': 516}
 
time = 1.61 secondes

Val loss 0.778531439602375 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 10/40
time = 30.01 secondes

Train loss 0.25808775011506496 accuracy 0.9244186282157898 macro_avg {'precision': 0.9132742257742257, 'recall': 0.9303431237098321, 'f1-score': 0.9200206664944459, 'support': 516} weighted_avg {'precision': 0.9290992437794763, 'recall': 0.9244186046511628, 'f1-score': 0.9251818831742294, 'support': 516}
 
time = 1.10 secondes

Val loss 1.4070512652397156 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 11/40
time = 28.49 secondes

Train loss 0.1316862459873047 accuracy 0.9651162624359131 macro_avg {'precision': 0.9622580173268533, 'recall': 0.9622580173268533, 'f1-score': 0.9622580173268533, 'support': 516} weighted_avg {'precision': 0.9651162790697675, 'recall': 0.9651162790697675, 'f1-score': 0.9651162790697675, 'support': 516}
 
time = 1.39 secondes

Val loss 1.4596914499998093 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 12/40
time = 27.91 secondes

Train loss 0.15253865611598347 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 1.28 secondes

Val loss 1.3049113750457764 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 13/40
time = 28.36 secondes

Train loss 0.08008079433630248 accuracy 0.9806201457977295 macro_avg {'precision': 0.9838535881836115, 'recall': 0.9744160720380997, 'f1-score': 0.9788312903067001, 'support': 516} weighted_avg {'precision': 0.9809475913065928, 'recall': 0.9806201550387597, 'f1-score': 0.9805247489197164, 'support': 516}
 
time = 1.44 secondes

Val loss 1.2245709523558617 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 14/40
time = 28.79 secondes

Train loss 0.16608708114081033 accuracy 0.961240291595459 macro_avg {'precision': 0.9624687101105714, 'recall': 0.9534483038863515, 'f1-score': 0.9576625806134003, 'support': 516} weighted_avg {'precision': 0.9613647050175752, 'recall': 0.9612403100775194, 'f1-score': 0.961049497839433, 'support': 516}
 
time = 1.22 secondes

Val loss 0.6278153154999018 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 15/40
time = 29.47 secondes

Train loss 0.1657902698462942 accuracy 0.963178277015686 macro_avg {'precision': 0.9679874974793305, 'recall': 0.952659980820181, 'f1-score': 0.9595262373519492, 'support': 516} weighted_avg {'precision': 0.9639225759757141, 'recall': 0.9631782945736435, 'f1-score': 0.9628719930002111, 'support': 516}
 
time = 1.19 secondes

Val loss 0.7917515523731709 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 16/40
time = 28.55 secondes

Train loss 0.082673484156134 accuracy 0.9786821603775024 macro_avg {'precision': 0.982398111827671, 'recall': 0.9717422752466558, 'f1-score': 0.9766856297878458, 'support': 516} weighted_avg {'precision': 0.9791002139372021, 'recall': 0.9786821705426356, 'f1-score': 0.9785631714248005, 'support': 516}
 
time = 0.90 secondes

Val loss 1.2155693173408508 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 17/40
time = 28.30 secondes

Train loss 0.2356311271891393 accuracy 0.9554263353347778 macro_avg {'precision': 0.9466008702781106, 'recall': 0.9604294328950149, 'f1-score': 0.9525521035314061, 'support': 516} weighted_avg {'precision': 0.9577903261367464, 'recall': 0.9554263565891473, 'f1-score': 0.9557658352967545, 'support': 516}
 
time = 1.71 secondes

Val loss 1.3267927467823029 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 18/40
time = 29.47 secondes

Train loss 0.0846989969087934 accuracy 0.9767441749572754 macro_avg {'precision': 0.9705138201549894, 'recall': 0.9806088779805926, 'f1-score': 0.9751157407407407, 'support': 516} weighted_avg {'precision': 0.9777655575041382, 'recall': 0.9767441860465116, 'f1-score': 0.9768675531151306, 'support': 516}
 
time = 1.37 secondes

Val loss 1.355791375041008 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 19/40
time = 28.66 secondes

Train loss 0.2298231251135638 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 1.24 secondes

Val loss 0.8663311451673508 accuracy 0.859375 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}
 
----------
Epoch 20/40
time = 29.09 secondes

Train loss 0.3805894045825963 accuracy 0.9341084957122803 macro_avg {'precision': 0.9510678223572513, 'recall': 0.9102449490434472, 'f1-score': 0.9256547165013984, 'support': 516} weighted_avg {'precision': 0.9393774343862973, 'recall': 0.9341085271317829, 'f1-score': 0.9325538033376891, 'support': 516}
 
time = 1.25 secondes

Val loss 1.0674018114805222 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 21/40
time = 28.59 secondes

Train loss 0.013893383962567896 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.23 secondes

Val loss 1.5000531673431396 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 22/40
time = 28.48 secondes

Train loss 0.13386091332402872 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.23 secondes

Val loss 1.0316883400082588 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 23/40
time = 28.56 secondes

Train loss 0.03982241804866741 accuracy 0.9903100728988647 macro_avg {'precision': 0.9889724961079398, 'recall': 0.9900931359003949, 'f1-score': 0.9895281582952815, 'support': 516} weighted_avg {'precision': 0.9903291858252575, 'recall': 0.9903100775193798, 'f1-score': 0.9903156230457919, 'support': 516}
 
time = 1.23 secondes

Val loss 0.7050020471215248 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 24/40
time = 28.85 secondes

Train loss 0.04280002636986672 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 0.96 secondes

Val loss 0.9664607867598534 accuracy 0.859375 macro_avg {'precision': 0.8709856035437431, 'recall': 0.8390688259109311, 'f1-score': 0.8486997635933806, 'support': 64} weighted_avg {'precision': 0.8646525470653379, 'recall': 0.859375, 'f1-score': 0.8562352245862884, 'support': 64}
 
----------
Epoch 25/40
time = 29.70 secondes

Train loss 0.06715802989977722 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.73 secondes

Val loss 1.373269572854042 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 26/40
time = 26.92 secondes

Train loss 0.04048553929015091 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 1.19 secondes

Val loss 1.654378354549408 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 27/40
time = 26.50 secondes

Train loss 0.015653184451035817 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.17 secondes

Val loss 1.4575733840465546 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 28/40
time = 26.41 secondes

Train loss 0.014280279892387405 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.17 secondes

Val loss 1.485522210597992 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 29/40
time = 26.42 secondes

Train loss 0.13605778625677692 accuracy 0.9767441749572754 macro_avg {'precision': 0.9698492462311558, 'recall': 0.9817629179331306, 'f1-score': 0.9751680328526284, 'support': 516} weighted_avg {'precision': 0.9781465466869229, 'recall': 0.9767441860465116, 'f1-score': 0.9768896771105624, 'support': 516}
 
time = 1.18 secondes

Val loss 0.9787640869617462 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 30/40
time = 27.02 secondes

Train loss 0.05264737793759471 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.22 secondes

Val loss 1.4045115411281586 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 31/40
time = 26.99 secondes

Train loss 0.01947837616678567 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.19 secondes

Val loss 1.0818202793598175 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 32/40
time = 26.46 secondes

Train loss 0.07363944264282261 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.23 secondes

Val loss 2.130279690027237 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 33/40
time = 26.37 secondes

Train loss 0.05635173305354053 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 1.18 secondes

Val loss 1.3625943809747696 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 34/40
time = 24.93 secondes

Train loss 0.008828196026584148 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.26 secondes

Val loss 1.3460484594106674 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 35/40
time = 24.88 secondes

Train loss 0.022749034476432964 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.25 secondes

Val loss 1.5586301684379578 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 36/40
time = 24.80 secondes

Train loss 0.002344031000878507 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.23 secondes

Val loss 1.2875741720199585 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 37/40
time = 24.85 secondes

Train loss 0.04667099496939706 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.23 secondes

Val loss 1.2418979294598103 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 38/40
time = 27.62 secondes

Train loss 0.02889695379748115 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.23 secondes

Val loss 1.493181973695755 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 39/40
time = 24.98 secondes

Train loss 0.00011823756711127123 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.25 secondes

Val loss 1.465138703584671 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 25.04 secondes

Train loss 0.00010699871486532643 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.24 secondes

Val loss 1.3879858255386353 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 19 macro_avg {'precision': 0.8626588465298143, 'recall': 0.8755060728744939, 'f1-score': 0.8585114222549742, 'support': 64} weighted_avg {'precision': 0.8823619257086999, 'recall': 0.859375, 'f1-score': 0.8605840088430361, 'support': 64}

average train time 27.84760047197342

average val time 1.258577471971512
 
time = 1.37 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9507722007722008, 'recall': 0.9551656920077972, 'f1-score': 0.9527272727272726, 'support': 65} weighted_avg {'precision': 0.9545292545292546, 'recall': 0.9538461538461539, 'f1-score': 0.9539580419580419, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 68.92 GiB already allocated; 55.62 MiB free; 70.41 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 79.21 GiB total capacity; 67.85 GiB already allocated; 29.62 MiB free; 70.44 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 79.21 GiB total capacity; 66.38 GiB already allocated; 143.62 MiB free; 70.32 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 69.37 GiB already allocated; 403.62 MiB free; 70.07 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_5
----------
Epoch 1/40
time = 39.47 secondes

Train loss 0.6596325906840238 accuracy 0.6356589198112488 macro_avg {'precision': 0.5417488494411571, 'recall': 0.5030964029712466, 'f1-score': 0.4079679718777463, 'support': 516} weighted_avg {'precision': 0.5685264182580819, 'recall': 0.6356589147286822, 'f1-score': 0.5090058277678491, 'support': 516}
 
time = 1.96 secondes

Val loss 0.6540125757455826 accuracy 0.59375 macro_avg {'precision': 0.296875, 'recall': 0.5, 'f1-score': 0.37254901960784315, 'support': 64} weighted_avg {'precision': 0.3525390625, 'recall': 0.59375, 'f1-score': 0.4424019607843137, 'support': 64}
 
----------
Epoch 2/40
time = 36.25 secondes

Train loss 0.41757593981244345 accuracy 0.817829430103302 macro_avg {'precision': 0.8215602836879432, 'recall': 0.7763600604651919, 'f1-score': 0.7899459534368071, 'support': 516} weighted_avg {'precision': 0.8192962779702018, 'recall': 0.8178294573643411, 'f1-score': 0.8110068978927104, 'support': 516}
 
time = 1.66 secondes

Val loss 0.46204736083745956 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 3/40
time = 37.09 secondes

Train loss 0.29561012918411783 accuracy 0.8875969052314758 macro_avg {'precision': 0.8804156015502598, 'recall': 0.8749248248622467, 'f1-score': 0.8775209533787325, 'support': 516} weighted_avg {'precision': 0.8870373175878287, 'recall': 0.8875968992248062, 'f1-score': 0.8871884149337493, 'support': 516}
 
time = 1.78 secondes

Val loss 0.6985491141676903 accuracy 0.765625 macro_avg {'precision': 0.7629521016617791, 'recall': 0.7722672064777327, 'f1-score': 0.7627872498146775, 'support': 64} weighted_avg {'precision': 0.7789894916911047, 'recall': 0.765625, 'f1-score': 0.7676519644180875, 'support': 64}
 
----------
Epoch 4/40
time = 36.21 secondes

Train loss 0.2553276833937024 accuracy 0.8972868323326111 macro_avg {'precision': 0.8879722311914756, 'recall': 0.890601888724542, 'f1-score': 0.8892502075444955, 'support': 516} weighted_avg {'precision': 0.8976977595222183, 'recall': 0.8972868217054264, 'f1-score': 0.897460273809619, 'support': 516}
 
time = 1.78 secondes

Val loss 0.6597933620214462 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 5/40
time = 36.19 secondes

Train loss 0.14953927009253565 accuracy 0.9379844665527344 macro_avg {'precision': 0.9289507474279917, 'recall': 0.9398273816296345, 'f1-score': 0.9337814209403422, 'support': 516} weighted_avg {'precision': 0.9398218687401746, 'recall': 0.937984496124031, 'f1-score': 0.9383724722948329, 'support': 516}
 
time = 1.68 secondes

Val loss 1.2888303995132446 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 6/40
time = 34.85 secondes

Train loss 0.24625496865976884 accuracy 0.9496123790740967 macro_avg {'precision': 0.9597513597513598, 'recall': 0.9327893633275361, 'f1-score': 0.9439505347593583, 'support': 516} weighted_avg {'precision': 0.9520108659643544, 'recall': 0.9496124031007752, 'f1-score': 0.9488528841769266, 'support': 516}
 
time = 1.80 secondes

Val loss 1.6546040177345276 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 7/40
time = 35.99 secondes

Train loss 0.30818482825469057 accuracy 0.9244186282157898 macro_avg {'precision': 0.9131185807656396, 'recall': 0.9314971636623701, 'f1-score': 0.9201729506733572, 'support': 516} weighted_avg {'precision': 0.9298331994296427, 'recall': 0.9244186046511628, 'f1-score': 0.9252391932351083, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6984992921352386 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 8/40
time = 36.62 secondes

Train loss 0.348958120164532 accuracy 0.9244186282157898 macro_avg {'precision': 0.9331973216154007, 'recall': 0.9038002048014564, 'f1-score': 0.9155755620534722, 'support': 516} weighted_avg {'precision': 0.9267047288605997, 'recall': 0.9244186046511628, 'f1-score': 0.9230947958790534, 'support': 516}
 
time = 1.76 secondes

Val loss 2.3076946139335632 accuracy 0.671875 macro_avg {'precision': 0.8220338983050848, 'recall': 0.5961538461538461, 'f1-score': 0.5530428999002328, 'support': 64} weighted_avg {'precision': 0.7886652542372881, 'recall': 0.671875, 'f1-score': 0.5962545726637845, 'support': 64}
 
----------
Epoch 9/40
time = 35.78 secondes

Train loss 0.31855761974249175 accuracy 0.9282945990562439 macro_avg {'precision': 0.9200070436063263, 'recall': 0.9264583976724152, 'f1-score': 0.9230257508134063, 'support': 516} weighted_avg {'precision': 0.9292010222412169, 'recall': 0.9282945736434108, 'f1-score': 0.9285677718642259, 'support': 516}
 
time = 1.66 secondes

Val loss 2.0324240922927856 accuracy 0.6875 macro_avg {'precision': 0.7333333333333334, 'recall': 0.6275303643724697, 'f1-score': 0.6135265700483092, 'support': 64} weighted_avg {'precision': 0.7208333333333333, 'recall': 0.6875, 'f1-score': 0.6452294685990339, 'support': 64}
 
----------
Epoch 10/40
time = 35.82 secondes

Train loss 0.4835658711187231 accuracy 0.8798449635505676 macro_avg {'precision': 0.8743192291579388, 'recall': 0.8630755977439332, 'f1-score': 0.86809598416756, 'support': 516} weighted_avg {'precision': 0.8790460602163528, 'recall': 0.8798449612403101, 'f1-score': 0.8789294565333425, 'support': 516}
 
time = 1.77 secondes

Val loss 1.5945920944213867 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 11/40
time = 37.52 secondes

Train loss 0.11010846042666923 accuracy 0.9689922332763672 macro_avg {'precision': 0.9674859149179391, 'recall': 0.965297531004665, 'f1-score': 0.9663734115347019, 'support': 516} weighted_avg {'precision': 0.9689509786608079, 'recall': 0.9689922480620154, 'f1-score': 0.9689558753324695, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6021197587251663 accuracy 0.78125 macro_avg {'precision': 0.7882352941176471, 'recall': 0.7975708502024291, 'f1-score': 0.780392156862745, 'support': 64} weighted_avg {'precision': 0.8091911764705884, 'recall': 0.78125, 'f1-score': 0.7829656862745098, 'support': 64}
 
----------
Epoch 12/40
time = 36.16 secondes

Train loss 0.28141708153381123 accuracy 0.9282945990562439 macro_avg {'precision': 0.9431623931623931, 'recall': 0.9045316385741917, 'f1-score': 0.9192136319591074, 'support': 516} weighted_avg {'precision': 0.9328132246736898, 'recall': 0.9282945736434108, 'f1-score': 0.9266673528791713, 'support': 516}
 
time = 1.65 secondes

Val loss 1.6205876916646957 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 13/40
time = 35.24 secondes

Train loss 0.10712611229709265 accuracy 0.9670542478561401 macro_avg {'precision': 0.9593354430379747, 'recall': 0.9718560538335257, 'f1-score': 0.9648578811369508, 'support': 516} weighted_avg {'precision': 0.9687843440290451, 'recall': 0.9670542635658915, 'f1-score': 0.9672756044308234, 'support': 516}
 
time = 1.77 secondes

Val loss 1.507264366489835 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 14/40
time = 36.48 secondes

Train loss 0.24680152282896664 accuracy 0.9341084957122803 macro_avg {'precision': 0.9253536591187563, 'recall': 0.9344797880467468, 'f1-score': 0.9294945987654321, 'support': 516} weighted_avg {'precision': 0.9355437513962136, 'recall': 0.9341085271317829, 'f1-score': 0.9344580671595367, 'support': 516}
 
time = 1.78 secondes

Val loss 2.0836925208568573 accuracy 0.6875 macro_avg {'precision': 0.6971428571428572, 'recall': 0.6396761133603239, 'f1-score': 0.6363636363636364, 'support': 64} weighted_avg {'precision': 0.6939285714285715, 'recall': 0.6875, 'f1-score': 0.6619318181818181, 'support': 64}
 
----------
Epoch 15/40
time = 35.99 secondes

Train loss 0.0598244810868037 accuracy 0.9844961166381836 macro_avg {'precision': 0.9794871794871796, 'recall': 0.9878419452887538, 'f1-score': 0.9833749496576721, 'support': 516} weighted_avg {'precision': 0.9851321804810177, 'recall': 0.9844961240310077, 'f1-score': 0.9845630598144903, 'support': 516}
 
time = 1.78 secondes

Val loss 2.3507427275180817 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 16/40
time = 35.46 secondes

Train loss 0.14621195546351373 accuracy 0.9670542478561401 macro_avg {'precision': 0.969533275713051, 'recall': 0.9591616143556069, 'f1-score': 0.9639687005812163, 'support': 516} weighted_avg {'precision': 0.9673331524324469, 'recall': 0.9670542635658915, 'f1-score': 0.966870355838328, 'support': 516}
 
time = 1.67 secondes

Val loss 1.8404104933142662 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 17/40
time = 35.98 secondes

Train loss 0.025181636091226457 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.77 secondes

Val loss 2.279051572084427 accuracy 0.65625 macro_avg {'precision': 0.6406926406926408, 'recall': 0.631578947368421, 'f1-score': 0.6333333333333333, 'support': 64} weighted_avg {'precision': 0.6500270562770563, 'recall': 0.65625, 'f1-score': 0.6505208333333334, 'support': 64}
 
----------
Epoch 18/40
time = 35.67 secondes

Train loss 0.014446764088819637 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.80 secondes

Val loss 2.2448810636997223 accuracy 0.6875 macro_avg {'precision': 0.6772727272727272, 'recall': 0.6578947368421053, 'f1-score': 0.6606574761399788, 'support': 64} weighted_avg {'precision': 0.6823863636363636, 'recall': 0.6875, 'f1-score': 0.6785524920466596, 'support': 64}
 
----------
Epoch 19/40
time = 35.71 secondes

Train loss 0.1239258512130508 accuracy 0.9806201457977295 macro_avg {'precision': 0.9761786361667656, 'recall': 0.9824943517058661, 'f1-score': 0.9791733936067162, 'support': 516} weighted_avg {'precision': 0.9810301413961745, 'recall': 0.9806201550387597, 'f1-score': 0.9806839827489969, 'support': 516}
 
time = 1.63 secondes

Val loss 1.9149967730045319 accuracy 0.703125 macro_avg {'precision': 0.6960591133004926, 'recall': 0.701417004048583, 'f1-score': 0.6971357409713573, 'support': 64} weighted_avg {'precision': 0.7101908866995075, 'recall': 0.703125, 'f1-score': 0.7051214196762141, 'support': 64}
 
----------
Epoch 20/40
time = 37.76 secondes

Train loss 0.08994716231906998 accuracy 0.9825581312179565 macro_avg {'precision': 0.9866863905325444, 'recall': 0.9759358288770054, 'f1-score': 0.9809246061900556, 'support': 516} weighted_avg {'precision': 0.9830225677721205, 'recall': 0.9825581395348837, 'f1-score': 0.9824607766202913, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9973073229193687 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 21/40
time = 36.19 secondes

Train loss 0.1763206832712802 accuracy 0.9651162624359131 macro_avg {'precision': 0.9565306347282772, 'recall': 0.9714903369471579, 'f1-score': 0.9629043853342919, 'support': 516} weighted_avg {'precision': 0.9676139210600191, 'recall': 0.9651162790697675, 'f1-score': 0.9653971544647485, 'support': 516}
 
time = 1.78 secondes

Val loss 1.8345214128494263 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 22/40
time = 35.88 secondes

Train loss 0.029560259027978947 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.71 secondes

Val loss 1.4371252357959747 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 23/40
time = 35.38 secondes

Train loss 0.09456860534643938 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.78 secondes

Val loss 2.2086907029151917 accuracy 0.734375 macro_avg {'precision': 0.7760180995475113, 'recall': 0.6852226720647773, 'f1-score': 0.686545664073754, 'support': 64} weighted_avg {'precision': 0.7628676470588236, 'recall': 0.734375, 'f1-score': 0.7095037453183521, 'support': 64}
 
----------
Epoch 24/40
time = 36.43 secondes

Train loss 0.26123174625646434 accuracy 0.9515503644943237 macro_avg {'precision': 0.9412231559290383, 'recall': 0.9608520390748175, 'f1-score': 0.9488288145342033, 'support': 516} weighted_avg {'precision': 0.9564988527710827, 'recall': 0.9515503875968992, 'f1-score': 0.9520764059199412, 'support': 516}
 
time = 1.74 secondes

Val loss 2.216898187994957 accuracy 0.71875 macro_avg {'precision': 0.71875, 'recall': 0.7267206477732794, 'f1-score': 0.716256157635468, 'support': 64} weighted_avg {'precision': 0.736328125, 'recall': 0.71875, 'f1-score': 0.7212438423645322, 'support': 64}
 
----------
Epoch 25/40
time = 36.08 secondes

Train loss 0.05011993380961058 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9723159074783325 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 26/40
time = 35.32 secondes

Train loss 0.040407819859396885 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.62 secondes

Val loss 1.5966625809669495 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 27/40
time = 36.63 secondes

Train loss 0.02180237731000957 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.80 secondes

Val loss 1.8547040633293363 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 28/40
time = 37.11 secondes

Train loss 0.025038175020337363 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.77 secondes

Val loss 2.257102608680725 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 29/40
time = 35.34 secondes

Train loss 0.03586251149659581 accuracy 0.9922480583190918 macro_avg {'precision': 0.9927655752429166, 'recall': 0.9904588527867627, 'f1-score': 0.9915933528836756, 'support': 516} weighted_avg {'precision': 0.9922622404600905, 'recall': 0.9922480620155039, 'f1-score': 0.9922389688331174, 'support': 516}
 
time = 1.73 secondes

Val loss 2.0248604118824005 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 30/40
time = 35.67 secondes

Train loss 0.010146453589958113 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.81 secondes

Val loss 2.6559970378875732 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 31/40
time = 35.76 secondes

Train loss 0.0011678848073973893 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.9615291208028793 accuracy 0.765625 macro_avg {'precision': 0.7591133004926109, 'recall': 0.7661943319838057, 'f1-score': 0.7608966376089665, 'support': 64} weighted_avg {'precision': 0.7721366995073893, 'recall': 0.765625, 'f1-score': 0.7672011207970113, 'support': 64}
 
----------
Epoch 32/40
time = 35.98 secondes

Train loss 0.09148746317000725 accuracy 0.9825581312179565 macro_avg {'precision': 0.9778286482679133, 'recall': 0.9851681484973099, 'f1-score': 0.9812765339816394, 'support': 516} weighted_avg {'precision': 0.9830754276422087, 'recall': 0.9825581395348837, 'f1-score': 0.9826245931561631, 'support': 516}
 
time = 1.77 secondes

Val loss 2.027755957096815 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 34.71 secondes

Train loss 0.10219918492718232 accuracy 0.9864341020584106 macro_avg {'precision': 0.9895833333333333, 'recall': 0.981283422459893, 'f1-score': 0.9852000573641189, 'support': 516} weighted_avg {'precision': 0.9867167312661498, 'recall': 0.9864341085271318, 'f1-score': 0.986376132969138, 'support': 516}
 
time = 1.78 secondes

Val loss 2.0863365456461906 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 34/40
time = 35.62 secondes

Train loss 0.014533261137716401 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.78 secondes

Val loss 1.8787337839603424 accuracy 0.796875 macro_avg {'precision': 0.7906403940886699, 'recall': 0.798582995951417, 'f1-score': 0.7927770859277709, 'support': 64} weighted_avg {'precision': 0.8031096059113301, 'recall': 0.796875, 'f1-score': 0.7982409713574097, 'support': 64}
 
----------
Epoch 35/40
time = 36.39 secondes

Train loss 0.01623848834325062 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9302708059549332 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 36/40
time = 37.74 secondes

Train loss 0.01358794819217027 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 1.66 secondes

Val loss 2.2175754010677338 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 37/40
time = 35.39 secondes

Train loss 1.8417606869744223e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.74 secondes

Val loss 2.108957454562187 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 38/40
time = 35.54 secondes

Train loss 0.00013098448636645281 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 2.141955181956291 accuracy 0.75 macro_avg {'precision': 0.7420634920634921, 'recall': 0.7469635627530364, 'f1-score': 0.7437437437437437, 'support': 64} weighted_avg {'precision': 0.753968253968254, 'recall': 0.75, 'f1-score': 0.7512512512512513, 'support': 64}
 
----------
Epoch 39/40
time = 35.75 secondes

Train loss 0.012624403157932455 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.70 secondes

Val loss 2.4175869673490524 accuracy 0.75 macro_avg {'precision': 0.7408906882591093, 'recall': 0.7408906882591093, 'f1-score': 0.7408906882591093, 'support': 64} weighted_avg {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 64}
 
----------
Epoch 40/40
time = 35.73 secondes

Train loss 1.640458757526975e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.77 secondes

Val loss 2.419247344136238 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 26 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}

average train time 36.12207238078118

average val time 1.752069318294525
 
time = 2.06 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_5
----------
Epoch 1/40
time = 50.51 secondes

Train loss 0.5910323840199094 accuracy 0.6666666865348816 macro_avg {'precision': 0.6399703144809672, 'recall': 0.573574110495262, 'f1-score': 0.5578318055001993, 'support': 516} weighted_avg {'precision': 0.6502159415360195, 'recall': 0.6666666666666666, 'f1-score': 0.6182011425534742, 'support': 516}
 
time = 2.26 secondes

Val loss 0.5481565296649933 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 2/40
time = 46.74 secondes

Train loss 0.36564857444979926 accuracy 0.8449612259864807 macro_avg {'precision': 0.8368675311467073, 'recall': 0.8230255351657103, 'f1-score': 0.828920975415679, 'support': 516} weighted_avg {'precision': 0.8434727420731359, 'recall': 0.8449612403100775, 'f1-score': 0.8433369096878599, 'support': 516}
 
time = 1.99 secondes

Val loss 0.44013357907533646 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 3/40
time = 47.68 secondes

Train loss 0.22042961548449416 accuracy 0.9321705102920532 macro_avg {'precision': 0.9288510890307298, 'recall': 0.9237277115875364, 'f1-score': 0.9261793522912605, 'support': 516} weighted_avg {'precision': 0.9319521575300713, 'recall': 0.9321705426356589, 'f1-score': 0.9319667606511556, 'support': 516}
 
time = 2.03 secondes

Val loss 0.487371064722538 accuracy 0.828125 macro_avg {'precision': 0.827677624602333, 'recall': 0.812753036437247, 'f1-score': 0.8181348488762593, 'support': 64} weighted_avg {'precision': 0.8279758748674444, 'recall': 0.828125, 'f1-score': 0.8261269697752518, 'support': 64}
 
----------
Epoch 4/40
time = 47.89 secondes

Train loss 0.13868150792338632 accuracy 0.9534883499145508 macro_avg {'precision': 0.9506328080346207, 'recall': 0.9485233164832665, 'f1-score': 0.9495601173020528, 'support': 516} weighted_avg {'precision': 0.9534101374612861, 'recall': 0.9534883720930233, 'f1-score': 0.9534338129987042, 'support': 516}
 
time = 2.03 secondes

Val loss 0.999733179807663 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 5/40
time = 47.51 secondes

Train loss 0.13043163808161448 accuracy 0.963178277015686 macro_avg {'precision': 0.9571780751744894, 'recall': 0.9642003803455619, 'f1-score': 0.9604726828501275, 'support': 516} weighted_avg {'precision': 0.9638345685704259, 'recall': 0.9631782945736435, 'f1-score': 0.9633185855518996, 'support': 516}
 
time = 1.97 secondes

Val loss 1.1745552122592926 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 6/40
time = 47.34 secondes

Train loss 0.23934848059434444 accuracy 0.9321705102920532 macro_avg {'precision': 0.9279072812991094, 'recall': 0.9248817515400745, 'f1-score': 0.9263551508577625, 'support': 516} weighted_avg {'precision': 0.9319977077166096, 'recall': 0.9321705426356589, 'f1-score': 0.9320502241850817, 'support': 516}
 
time = 2.03 secondes

Val loss 1.209568351507187 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 7/40
time = 47.67 secondes

Train loss 0.1828564876676396 accuracy 0.9593023061752319 macro_avg {'precision': 0.9666609996599796, 'recall': 0.9461583472847553, 'f1-score': 0.9550326797385621, 'support': 516} weighted_avg {'precision': 0.9607238876193037, 'recall': 0.9593023255813954, 'f1-score': 0.9588458225667528, 'support': 516}
 
time = 2.05 secondes

Val loss 0.9432844966650009 accuracy 0.8125 macro_avg {'precision': 0.8227272727272728, 'recall': 0.7874493927125505, 'f1-score': 0.7963944856839873, 'support': 64} weighted_avg {'precision': 0.8176136363636364, 'recall': 0.8125, 'f1-score': 0.8071314952279958, 'support': 64}
 
----------
Epoch 8/40
time = 47.61 secondes

Train loss 0.23287382603898135 accuracy 0.9476743936538696 macro_avg {'precision': 0.9377231443783276, 'recall': 0.9543504055393918, 'f1-score': 0.9445220943984518, 'support': 516} weighted_avg {'precision': 0.9513104611104232, 'recall': 0.9476744186046512, 'f1-score': 0.9481613629942266, 'support': 516}
 
time = 1.98 secondes

Val loss 1.283152848482132 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 9/40
time = 47.59 secondes

Train loss 0.20853390188792467 accuracy 0.9399224519729614 macro_avg {'precision': 0.9447296837810268, 'recall': 0.9251905791330072, 'f1-score': 0.9336196700902584, 'support': 516} weighted_avg {'precision': 0.9408511448671417, 'recall': 0.939922480620155, 'f1-score': 0.9392485952175874, 'support': 516}
 
time = 2.03 secondes

Val loss 1.7600042819976807 accuracy 0.734375 macro_avg {'precision': 0.8036020583190394, 'recall': 0.6791497975708503, 'f1-score': 0.6768636768636769, 'support': 64} weighted_avg {'precision': 0.7838228987993139, 'recall': 0.734375, 'f1-score': 0.7024242649242649, 'support': 64}
 
----------
Epoch 10/40
time = 47.53 secondes

Train loss 0.08870545986097898 accuracy 0.9844961166381836 macro_avg {'precision': 0.9881305637982196, 'recall': 0.9786096256684492, 'f1-score': 0.98306503224536, 'support': 516} weighted_avg {'precision': 0.9848641685643963, 'recall': 0.9844961240310077, 'f1-score': 0.9844197991357732, 'support': 516}
 
time = 2.08 secondes

Val loss 1.3058391511440277 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 11/40
time = 47.56 secondes

Train loss 0.14479094041885357 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.94 secondes

Val loss 1.5295238941907883 accuracy 0.765625 macro_avg {'precision': 0.7598091198303287, 'recall': 0.7479757085020242, 'f1-score': 0.7520020666494445, 'support': 64} weighted_avg {'precision': 0.7636863732767762, 'recall': 0.765625, 'f1-score': 0.7629004133298889, 'support': 64}
 
----------
Epoch 12/40
time = 46.89 secondes

Train loss 0.1398550421281746 accuracy 0.963178277015686 macro_avg {'precision': 0.9564732142857143, 'recall': 0.9653544202980999, 'f1-score': 0.9605579179858952, 'support': 516} weighted_avg {'precision': 0.9641516126799556, 'recall': 0.9631782945736435, 'f1-score': 0.9633556132901075, 'support': 516}
 
time = 2.04 secondes

Val loss 2.2241888642311096 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 13/40
time = 47.18 secondes

Train loss 0.4474029034648662 accuracy 0.9108527302742004 macro_avg {'precision': 0.9059454110662158, 'recall': 0.9000861466443444, 'f1-score': 0.9028614457831324, 'support': 516} weighted_avg {'precision': 0.91047032600073, 'recall': 0.9108527131782945, 'f1-score': 0.9105287428784906, 'support': 516}
 
time = 2.04 secondes

Val loss 1.702726811170578 accuracy 0.703125 macro_avg {'precision': 0.706256109481916, 'recall': 0.7135627530364372, 'f1-score': 0.7013018914271677, 'support': 64} weighted_avg {'precision': 0.7250427663734116, 'recall': 0.703125, 'f1-score': 0.705677352001965, 'support': 64}
 
----------
Epoch 14/40
time = 47.71 secondes

Train loss 0.18895393477798667 accuracy 0.9515503644943237 macro_avg {'precision': 0.9549808429118773, 'recall': 0.9400793199291322, 'f1-score': 0.9467450491473015, 'support': 516} weighted_avg {'precision': 0.9520812913956459, 'recall': 0.9515503875968992, 'f1-score': 0.9511473592108038, 'support': 516}
 
time = 1.64 secondes

Val loss 1.5786226093769073 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 46.60 secondes

Train loss 0.26798076624717476 accuracy 0.9302325248718262 macro_avg {'precision': 0.9245160346537067, 'recall': 0.9245160346537067, 'f1-score': 0.9245160346537067, 'support': 516} weighted_avg {'precision': 0.9302325581395349, 'recall': 0.9302325581395349, 'f1-score': 0.9302325581395349, 'support': 516}
 
time = 2.01 secondes

Val loss 1.1818162202835083 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 16/40
time = 47.25 secondes

Train loss 0.1367008129313807 accuracy 0.9728682041168213 macro_avg {'precision': 0.9687474828836086, 'recall': 0.9729532044926288, 'f1-score': 0.9707781175671084, 'support': 516} weighted_avg {'precision': 0.9731142310346013, 'recall': 0.9728682170542635, 'f1-score': 0.9729287996480942, 'support': 516}
 
time = 2.04 secondes

Val loss 1.9243815541267395 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 17/40
time = 47.26 secondes

Train loss 0.11368218480140169 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 2.02 secondes

Val loss 2.1379575729370117 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 18/40
time = 46.37 secondes

Train loss 0.3002762895842104 accuracy 0.9476743936538696 macro_avg {'precision': 0.9620786516853932, 'recall': 0.927807486631016, 'f1-score': 0.941387071667473, 'support': 516} weighted_avg {'precision': 0.9516429318003659, 'recall': 0.9476744186046512, 'f1-score': 0.9466699312241554, 'support': 516}
 
time = 2.06 secondes

Val loss 1.6149703040719032 accuracy 0.75 macro_avg {'precision': 0.7450980392156863, 'recall': 0.7530364372469636, 'f1-score': 0.746031746031746, 'support': 64} weighted_avg {'precision': 0.7598039215686274, 'recall': 0.75, 'f1-score': 0.751984126984127, 'support': 64}
 
----------
Epoch 19/40
time = 47.62 secondes

Train loss 0.27802333997026313 accuracy 0.9554263353347778 macro_avg {'precision': 0.9655593803786575, 'recall': 0.9396567137493295, 'f1-score': 0.9504854247414336, 'support': 516} weighted_avg {'precision': 0.9577393294106659, 'recall': 0.9554263565891473, 'f1-score': 0.9547897948173559, 'support': 516}
 
time = 2.03 secondes

Val loss 2.1017946600914 accuracy 0.703125 macro_avg {'precision': 0.8333333333333333, 'recall': 0.6346153846153846, 'f1-score': 0.6121212121212122, 'support': 64} weighted_avg {'precision': 0.8020833333333333, 'recall': 0.703125, 'f1-score': 0.647348484848485, 'support': 64}
 
----------
Epoch 20/40
time = 48.27 secondes

Train loss 0.036708026026176274 accuracy 0.9903100728988647 macro_avg {'precision': 0.990078201368524, 'recall': 0.988939095947857, 'f1-score': 0.9895039604242353, 'support': 516} weighted_avg {'precision': 0.9903068570172846, 'recall': 0.9903100775193798, 'f1-score': 0.9903044403368964, 'support': 516}
 
time = 2.04 secondes

Val loss 1.4314833283424377 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 21/40
time = 46.61 secondes

Train loss 0.02071020985000139 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.93 secondes

Val loss 1.6393872499465942 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 22/40
time = 47.48 secondes

Train loss 0.15497525026766004 accuracy 0.9709302186965942 macro_avg {'precision': 0.9701414353064431, 'recall': 0.9668172878435708, 'f1-score': 0.968437921796184, 'support': 516} weighted_avg {'precision': 0.9708982542911787, 'recall': 0.9709302325581395, 'f1-score': 0.9708786675078922, 'support': 516}
 
time = 2.04 secondes

Val loss 2.449527829885483 accuracy 0.71875 macro_avg {'precision': 0.7628205128205128, 'recall': 0.6659919028340081, 'f1-score': 0.6631578947368421, 'support': 64} weighted_avg {'precision': 0.749599358974359, 'recall': 0.71875, 'f1-score': 0.6888157894736842, 'support': 64}
 
----------
Epoch 23/40
time = 47.59 secondes

Train loss 0.019958430711884637 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 2.07 secondes

Val loss 1.7753691375255585 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 24/40
time = 46.98 secondes

Train loss 0.026676164117375403 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.93 secondes

Val loss 1.7789091765880585 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 25/40
time = 47.67 secondes

Train loss 0.024895357951181446 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 2.03 secondes

Val loss 1.5825062096118927 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 48.07 secondes

Train loss 0.04376842919637883 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 2.03 secondes

Val loss 1.4540241807699203 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 27/40
time = 46.61 secondes

Train loss 0.13242332182876868 accuracy 0.9767441749572754 macro_avg {'precision': 0.9824046920821115, 'recall': 0.9679144385026738, 'f1-score': 0.9744701904840438, 'support': 516} weighted_avg {'precision': 0.9775625724612972, 'recall': 0.9767441860465116, 'f1-score': 0.9765669915870987, 'support': 516}
 
time = 1.95 secondes

Val loss 1.6940194442868233 accuracy 0.765625 macro_avg {'precision': 0.7574358974358975, 'recall': 0.7540485829959513, 'f1-score': 0.7555385790679908, 'support': 64} weighted_avg {'precision': 0.7644551282051282, 'recall': 0.765625, 'f1-score': 0.7648491214667685, 'support': 64}
 
----------
Epoch 28/40
time = 46.97 secondes

Train loss 0.02142573737623796 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.03 secondes

Val loss 2.5181883573532104 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 29/40
time = 47.51 secondes

Train loss 0.04753035110766315 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.04 secondes

Val loss 2.033795490860939 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 30/40
time = 47.40 secondes

Train loss 0.030743188688079084 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.94 secondes

Val loss 2.5642741322517395 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 31/40
time = 47.45 secondes

Train loss 0.022605743973282657 accuracy 0.9961240291595459 macro_avg {'precision': 0.9969788519637462, 'recall': 0.9946524064171123, 'f1-score': 0.9957966764418378, 'support': 516} weighted_avg {'precision': 0.9961474507599709, 'recall': 0.9961240310077519, 'f1-score': 0.9961194844165587, 'support': 516}
 
time = 2.04 secondes

Val loss 1.8749131858348846 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 32/40
time = 47.22 secondes

Train loss 0.047096558171798475 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 2.04 secondes

Val loss 1.6534931063652039 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 33/40
time = 47.06 secondes

Train loss 0.017086773851505397 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.98 secondes

Val loss 1.576234057545662 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 34/40
time = 46.20 secondes

Train loss 0.006529018187751662 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.98 secondes

Val loss 2.0151139348745346 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 35/40
time = 47.21 secondes

Train loss 0.0023693594315166897 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.04 secondes

Val loss 2.5039400458335876 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 36/40
time = 48.61 secondes

Train loss 0.00038946697173797116 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.9285318553447723 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 47.49 secondes

Train loss 0.0002714873602544134 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.04 secondes

Val loss 1.5742321610450745 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 47.16 secondes

Train loss 0.0058480329138491825 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.03 secondes

Val loss 1.47617569565773 accuracy 0.828125 macro_avg {'precision': 0.8213213213213213, 'recall': 0.8248987854251012, 'f1-score': 0.8228930817610063, 'support': 64} weighted_avg {'precision': 0.8294857357357358, 'recall': 0.828125, 'f1-score': 0.8286006289308177, 'support': 64}
 
----------
Epoch 39/40
time = 47.57 secondes

Train loss 1.8546307397958696e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.05 secondes

Val loss 1.8630253672599792 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 40/40
time = 46.17 secondes

Train loss 1.9603210162269093e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.03 secondes

Val loss 2.07417294383049 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 2 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}

average train time 47.39488708376884

average val time 2.013846296072006
 
time = 2.34 secondes

test_accuracy 0.8615384697914124 macro_avg {'precision': 0.8731501057082452, 'recall': 0.8440545808966862, 'f1-score': 0.8526077097505669, 'support': 65} weighted_avg {'precision': 0.8670678159050252, 'recall': 0.8615384615384616, 'f1-score': 0.8587476016047444, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_5
----------
Epoch 1/40
time = 64.89 secondes

Train loss 0.6344757694186587 accuracy 0.6124030947685242 macro_avg {'precision': 0.492600422832981, 'recall': 0.49755376038229604, 'f1-score': 0.4405291120026022, 'support': 516} weighted_avg {'precision': 0.5321631676418048, 'recall': 0.6124031007751938, 'f1-score': 0.5258651483861966, 'support': 516}
 
time = 2.53 secondes

Val loss 0.7047123461961746 accuracy 0.625 macro_avg {'precision': 0.6436781609195402, 'recall': 0.5506072874493927, 'f1-score': 0.5, 'support': 64} weighted_avg {'precision': 0.639367816091954, 'recall': 0.625, 'f1-score': 0.546875, 'support': 64}
 
----------
Epoch 2/40
time = 63.24 secondes

Train loss 0.4081495079127225 accuracy 0.8275193572044373 macro_avg {'precision': 0.8182471264367817, 'recall': 0.8024234839003299, 'f1-score': 0.8089167204110927, 'support': 516} weighted_avg {'precision': 0.8255619041254566, 'recall': 0.8275193798449613, 'f1-score': 0.8253240349428277, 'support': 516}
 
time = 2.41 secondes

Val loss 0.47046664729714394 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 3/40
time = 64.15 secondes

Train loss 0.27177304368127475 accuracy 0.895348846912384 macro_avg {'precision': 0.8926338495761641, 'recall': 0.8786957723127936, 'f1-score': 0.8848214285714286, 'support': 516} weighted_avg {'precision': 0.8949016627756089, 'recall': 0.8953488372093024, 'f1-score': 0.8944040697674418, 'support': 516}
 
time = 2.40 secondes

Val loss 0.7492381855845451 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 4/40
time = 63.58 secondes

Train loss 0.2250140564459743 accuracy 0.9069767594337463 macro_avg {'precision': 0.8986942381437795, 'recall': 0.9005087528241471, 'f1-score': 0.8995848469122989, 'support': 516} weighted_avg {'precision': 0.9072168168249528, 'recall': 0.9069767441860465, 'f1-score': 0.9070823427185286, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0591700375080109 accuracy 0.703125 macro_avg {'precision': 0.7277526395173455, 'recall': 0.652834008097166, 'f1-score': 0.6496686833765485, 'support': 64} weighted_avg {'precision': 0.7199754901960784, 'recall': 0.703125, 'f1-score': 0.6753277153558052, 'support': 64}
 
----------
Epoch 5/40
time = 63.71 secondes

Train loss 0.11614983166201097 accuracy 0.9554263353347778 macro_avg {'precision': 0.9496527777777778, 'recall': 0.9546592331323245, 'f1-score': 0.9520459660507421, 'support': 516} weighted_avg {'precision': 0.9558637489233419, 'recall': 0.9554263565891473, 'f1-score': 0.9555497285066072, 'support': 516}
 
time = 2.41 secondes

Val loss 1.1028559058904648 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 6/40
time = 64.11 secondes

Train loss 0.17169949148647543 accuracy 0.9476743936538696 macro_avg {'precision': 0.9458281239718365, 'recall': 0.9405019261089349, 'f1-score': 0.9430526431961153, 'support': 516} weighted_avg {'precision': 0.9475529518524923, 'recall': 0.9476744186046512, 'f1-score': 0.9475172153594628, 'support': 516}
 
time = 2.43 secondes

Val loss 1.2844282239675522 accuracy 0.765625 macro_avg {'precision': 0.7646733111849391, 'recall': 0.7419028340080972, 'f1-score': 0.747832939322301, 'support': 64} weighted_avg {'precision': 0.7651924141749724, 'recall': 0.765625, 'f1-score': 0.7603920409771474, 'support': 64}
 
----------
Epoch 7/40
time = 63.99 secondes

Train loss 0.08162372033852576 accuracy 0.9767441749572754 macro_avg {'precision': 0.9738362215426435, 'recall': 0.9759927181704403, 'f1-score': 0.9748962117280747, 'support': 516} weighted_avg {'precision': 0.9768284748727107, 'recall': 0.9767441860465116, 'f1-score': 0.9767705856796322, 'support': 516}
 
time = 2.40 secondes

Val loss 2.0404615998268127 accuracy 0.671875 macro_avg {'precision': 0.6794871794871795, 'recall': 0.6204453441295547, 'f1-score': 0.6127917026793431, 'support': 64} weighted_avg {'precision': 0.6770833333333333, 'recall': 0.671875, 'f1-score': 0.6411516853932584, 'support': 64}
 
----------
Epoch 8/40
time = 63.13 secondes

Train loss 0.04511403784801422 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 2.29 secondes

Val loss 1.523890107870102 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 9/40
time = 64.03 secondes

Train loss 0.25329303799949365 accuracy 0.9496123790740967 macro_avg {'precision': 0.9474228326687344, 'recall': 0.9431757229003788, 'f1-score': 0.9452274026292153, 'support': 516} weighted_avg {'precision': 0.9494956260110663, 'recall': 0.9496124031007752, 'f1-score': 0.9494922661015543, 'support': 516}
 
time = 2.39 secondes

Val loss 3.3487228751182556 accuracy 0.640625 macro_avg {'precision': 0.8114754098360656, 'recall': 0.5576923076923077, 'f1-score': 0.4872866597004528, 'support': 64} weighted_avg {'precision': 0.7761270491803278, 'recall': 0.640625, 'f1-score': 0.5398598049460118, 'support': 64}
 
----------
Epoch 10/40
time = 63.56 secondes

Train loss 0.15164010854950352 accuracy 0.963178277015686 macro_avg {'precision': 0.9710472628357701, 'recall': 0.9503519009151049, 'f1-score': 0.9593152816682228, 'support': 516} weighted_avg {'precision': 0.964698436169736, 'recall': 0.9631782945736435, 'f1-score': 0.9627652680365858, 'support': 516}
 
time = 2.31 secondes

Val loss 1.323911041021347 accuracy 0.8125 macro_avg {'precision': 0.8125, 'recall': 0.8238866396761133, 'f1-score': 0.8108374384236454, 'support': 64} weighted_avg {'precision': 0.830078125, 'recall': 0.8125, 'f1-score': 0.8141625615763547, 'support': 64}
 
----------
Epoch 11/40
time = 63.48 secondes

Train loss 0.3907353119745191 accuracy 0.9108527302742004 macro_avg {'precision': 0.9112128146453089, 'recall': 0.894315946881654, 'f1-score': 0.9016295608640154, 'support': 516} weighted_avg {'precision': 0.9109189387354466, 'recall': 0.9108527131782945, 'f1-score': 0.9099187230705195, 'support': 516}
 
time = 2.40 secondes

Val loss 1.1457586586475372 accuracy 0.796875 macro_avg {'precision': 0.8083743842364532, 'recall': 0.8168016194331984, 'f1-score': 0.7964276975776854, 'support': 64} weighted_avg {'precision': 0.8313731527093596, 'recall': 0.796875, 'f1-score': 0.7982169072669439, 'support': 64}
 
----------
Epoch 12/40
time = 63.95 secondes

Train loss 0.08500378701424008 accuracy 0.9786821603775024 macro_avg {'precision': 0.9729272959183674, 'recall': 0.9821286348194984, 'f1-score': 0.9771651104128867, 'support': 516} weighted_avg {'precision': 0.9795175555687392, 'recall': 0.9786821705426356, 'f1-score': 0.9787848287469044, 'support': 516}
 
time = 2.33 secondes

Val loss 1.5894540846347809 accuracy 0.78125 macro_avg {'precision': 0.7971014492753623, 'recall': 0.7489878542510121, 'f1-score': 0.7575757575757576, 'support': 64} weighted_avg {'precision': 0.7903079710144928, 'recall': 0.78125, 'f1-score': 0.771780303030303, 'support': 64}
 
----------
Epoch 13/40
time = 63.24 secondes

Train loss 0.36790513601127633 accuracy 0.9205426573753357 macro_avg {'precision': 0.9161183128248996, 'recall': 0.9111470506964875, 'f1-score': 0.9135243841126194, 'support': 516} weighted_avg {'precision': 0.9202515617882558, 'recall': 0.9205426356589147, 'f1-score': 0.920303919619925, 'support': 516}
 
time = 2.41 secondes

Val loss 1.8764704167842865 accuracy 0.734375 macro_avg {'precision': 0.7375366568914956, 'recall': 0.7459514170040487, 'f1-score': 0.7327437975927291, 'support': 64} weighted_avg {'precision': 0.7565065982404693, 'recall': 0.734375, 'f1-score': 0.7366586833701794, 'support': 64}
 
----------
Epoch 14/40
time = 64.01 secondes

Train loss 0.30232763955515995 accuracy 0.9457364082336426 macro_avg {'precision': 0.9588662409238037, 'recall': 0.9262877297921103, 'f1-score': 0.9393022786852188, 'support': 516} weighted_avg {'precision': 0.9492557637703538, 'recall': 0.9457364341085271, 'f1-score': 0.9447406719596818, 'support': 516}
 
time = 2.43 secondes

Val loss 1.405108779668808 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 15/40
time = 64.06 secondes

Train loss 0.105212262044502 accuracy 0.9806201457977295 macro_avg {'precision': 0.975365444524323, 'recall': 0.9836483916584042, 'f1-score': 0.9792186870720903, 'support': 516} weighted_avg {'precision': 0.9812874198659898, 'recall': 0.9806201550387597, 'f1-score': 0.9807038247681131, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0011996626853943 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 16/40
time = 63.50 secondes

Train loss 0.10744832911873484 accuracy 0.9748061895370483 macro_avg {'precision': 0.9809941520467836, 'recall': 0.96524064171123, 'f1-score': 0.9723074255565969, 'support': 516} weighted_avg {'precision': 0.9757638605557822, 'recall': 0.9748062015503876, 'f1-score': 0.9745966267896181, 'support': 516}
 
time = 2.40 secondes

Val loss 1.3794954717159271 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 17/40
time = 63.66 secondes

Train loss 0.15484984128852375 accuracy 0.9767441749572754 macro_avg {'precision': 0.9782798713614249, 'recall': 0.971376558360288, 'f1-score': 0.9746595075955997, 'support': 516} weighted_avg {'precision': 0.976863849837284, 'recall': 0.9767441860465116, 'f1-score': 0.9766596720552585, 'support': 516}
 
time = 2.42 secondes

Val loss 3.537547469139099 accuracy 0.625 macro_avg {'precision': 0.8064516129032258, 'recall': 0.5384615384615384, 'f1-score': 0.45142857142857146, 'support': 64} weighted_avg {'precision': 0.7701612903225806, 'recall': 0.625, 'f1-score': 0.5092857142857142, 'support': 64}
 
----------
Epoch 18/40
time = 63.80 secondes

Train loss 0.31025361128757306 accuracy 0.9496123790740967 macro_avg {'precision': 0.9549453343503687, 'recall': 0.9362514831851503, 'f1-score': 0.9443993170100957, 'support': 516} weighted_avg {'precision': 0.9505931720662176, 'recall': 0.9496124031007752, 'f1-score': 0.9490844956485546, 'support': 516}
 
time = 2.34 secondes

Val loss 1.9575761426240206 accuracy 0.6875 macro_avg {'precision': 0.6941176470588235, 'recall': 0.7004048582995952, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7139705882352941, 'recall': 0.6875, 'f1-score': 0.6899509803921569, 'support': 64}
 
----------
Epoch 19/40
time = 64.03 secondes

Train loss 0.07327435472104822 accuracy 0.9786821603775024 macro_avg {'precision': 0.9838235294117648, 'recall': 0.9705882352941176, 'f1-score': 0.9766272591384699, 'support': 516} weighted_avg {'precision': 0.9793718650250798, 'recall': 0.9786821705426356, 'f1-score': 0.9785344318142316, 'support': 516}
 
time = 2.39 secondes

Val loss 1.4731745550743653 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 20/40
time = 63.88 secondes

Train loss 0.02493490790452184 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 2.39 secondes

Val loss 2.337515354156494 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 21/40
time = 63.57 secondes

Train loss 0.30126284278837073 accuracy 0.9573643207550049 macro_avg {'precision': 0.9488746742478086, 'recall': 0.9619491897339207, 'f1-score': 0.9545687391944676, 'support': 516} weighted_avg {'precision': 0.9594495224137709, 'recall': 0.9573643410852714, 'f1-score': 0.9576701100420781, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5259078741073608 accuracy 0.75 macro_avg {'precision': 0.75, 'recall': 0.7591093117408907, 'f1-score': 0.7477832512315271, 'support': 64} weighted_avg {'precision': 0.767578125, 'recall': 0.75, 'f1-score': 0.7522167487684729, 'support': 64}
 
----------
Epoch 22/40
time = 63.71 secondes

Train loss 0.14629958515235392 accuracy 0.9689922332763672 macro_avg {'precision': 0.9768115942028985, 'recall': 0.9572192513368984, 'f1-score': 0.9657841950831357, 'support': 516} weighted_avg {'precision': 0.9704302887316032, 'recall': 0.9689922480620154, 'f1-score': 0.968667381937572, 'support': 516}
 
time = 2.40 secondes

Val loss 1.9173211306333542 accuracy 0.71875 macro_avg {'precision': 0.7428571428571429, 'recall': 0.6720647773279352, 'f1-score': 0.6727272727272726, 'support': 64} weighted_avg {'precision': 0.7348214285714285, 'recall': 0.71875, 'f1-score': 0.6957386363636363, 'support': 64}
 
----------
Epoch 23/40
time = 63.39 secondes

Train loss 0.11955594053385236 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 2.33 secondes

Val loss 2.036495476961136 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 24/40
time = 64.45 secondes

Train loss 0.04826089989783765 accuracy 0.9883720874786377 macro_avg {'precision': 0.989760252055334, 'recall': 0.985111259203875, 'f1-score': 0.9873601698375112, 'support': 516} weighted_avg {'precision': 0.9884461281716332, 'recall': 0.9883720930232558, 'f1-score': 0.9883443691003586, 'support': 516}
 
time = 2.39 secondes

Val loss 2.3925761580467224 accuracy 0.71875 macro_avg {'precision': 0.7083333333333333, 'recall': 0.7024291497975709, 'f1-score': 0.7046153846153846, 'support': 64} weighted_avg {'precision': 0.7161458333333333, 'recall': 0.71875, 'f1-score': 0.7167307692307692, 'support': 64}
 
----------
Epoch 25/40
time = 63.42 secondes

Train loss 0.007716502251710292 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.10 secondes

Val loss 2.354571968317032 accuracy 0.71875 macro_avg {'precision': 0.7136363636363636, 'recall': 0.6902834008097165, 'f1-score': 0.6945917285259808, 'support': 64} weighted_avg {'precision': 0.7161931818181818, 'recall': 0.71875, 'f1-score': 0.7106972428419936, 'support': 64}
 
----------
Epoch 26/40
time = 63.93 secondes

Train loss 0.04601316248370109 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 2.40 secondes

Val loss 1.5618539154529572 accuracy 0.8125 macro_avg {'precision': 0.8056680161943319, 'recall': 0.8056680161943319, 'f1-score': 0.8056680161943319, 'support': 64} weighted_avg {'precision': 0.8125, 'recall': 0.8125, 'f1-score': 0.8125, 'support': 64}
 
----------
Epoch 27/40
time = 63.69 secondes

Train loss 0.029210912724066118 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 2.40 secondes

Val loss 1.4712326377630234 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 28/40
time = 62.79 secondes

Train loss 0.013589704758267158 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.41 secondes

Val loss 1.9226640537381172 accuracy 0.734375 macro_avg {'precision': 0.7246153846153847, 'recall': 0.7216599190283401, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7329807692307693, 'recall': 0.734375, 'f1-score': 0.733495670995671, 'support': 64}
 
----------
Epoch 29/40
time = 63.54 secondes

Train loss 0.010797472032925614 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.35 secondes

Val loss 2.7729963660240173 accuracy 0.71875 macro_avg {'precision': 0.7291666666666667, 'recall': 0.6781376518218624, 'f1-score': 0.681063122923588, 'support': 64} weighted_avg {'precision': 0.7252604166666667, 'recall': 0.71875, 'f1-score': 0.7016196013289037, 'support': 64}
 
----------
Epoch 30/40
time = 63.12 secondes

Train loss 0.004680027035481709 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.24 secondes

Val loss 1.8207261264324188 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 31/40
time = 63.53 secondes

Train loss 0.00021894843016387753 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.37 secondes

Val loss 2.4117945432662964 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 32/40
time = 63.21 secondes

Train loss 0.06950217944843946 accuracy 0.9922480583190918 macro_avg {'precision': 0.993993993993994, 'recall': 0.9893048128342246, 'f1-score': 0.9915734465583409, 'support': 516} weighted_avg {'precision': 0.99234117838769, 'recall': 0.9922480620155039, 'f1-score': 0.9922295794002391, 'support': 516}
 
time = 2.34 secondes

Val loss 1.668237030506134 accuracy 0.796875 macro_avg {'precision': 0.7902564102564102, 'recall': 0.7864372469635628, 'f1-score': 0.7881334351922588, 'support': 64} weighted_avg {'precision': 0.7959294871794872, 'recall': 0.796875, 'f1-score': 0.7962025719378661, 'support': 64}
 
----------
Epoch 33/40
time = 64.19 secondes

Train loss 8.767282611877431e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.21 secondes

Val loss 2.0411403477191925 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 34/40
time = 63.39 secondes

Train loss 0.0038068929507889234 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 2.28 secondes

Val loss 1.8155798316001892 accuracy 0.8125 macro_avg {'precision': 0.8138528138528138, 'recall': 0.7935222672064777, 'f1-score': 0.8, 'support': 64} weighted_avg {'precision': 0.8130411255411256, 'recall': 0.8125, 'f1-score': 0.8093750000000002, 'support': 64}
 
----------
Epoch 35/40
time = 64.15 secondes

Train loss 0.036502424025512126 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.41 secondes

Val loss 1.784977287054062 accuracy 0.8125 macro_avg {'precision': 0.8055555555555556, 'recall': 0.811740890688259, 'f1-score': 0.8078078078078078, 'support': 64} weighted_avg {'precision': 0.8159722222222222, 'recall': 0.8125, 'f1-score': 0.8134384384384383, 'support': 64}
 
----------
Epoch 36/40
time = 63.51 secondes

Train loss 0.0033578467760945027 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 2.34 secondes

Val loss 2.149091988801956 accuracy 0.765625 macro_avg {'precision': 0.7841051314142677, 'recall': 0.7297570850202428, 'f1-score': 0.73734610123119, 'support': 64} weighted_avg {'precision': 0.7767130788485607, 'recall': 0.765625, 'f1-score': 0.7535054719562242, 'support': 64}
 
----------
Epoch 37/40
time = 63.80 secondes

Train loss 0.00033578165378209883 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.33 secondes

Val loss 2.1878055930137634 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 38/40
time = 63.28 secondes

Train loss 1.858470466576171e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.35 secondes

Val loss 2.3817780762910843 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 39/40
time = 170.05 secondes

Train loss 0.03543913245856388 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 2.15 secondes

Val loss 2.4503409564495087 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
Epoch 40/40
time = 120.57 secondes

Train loss 1.6785312116994508e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.17 secondes

Val loss 2.401164799928665 accuracy 0.75 macro_avg {'precision': 0.7416666666666667, 'recall': 0.7348178137651822, 'f1-score': 0.7374358974358974, 'support': 64} weighted_avg {'precision': 0.7479166666666667, 'recall': 0.75, 'f1-score': 0.7482051282051283, 'support': 64}
 
----------
best_accuracy 0.828125 best_epoch 15 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}

average train time 67.78205339312554

average val time 2.357852375507355
 
time = 2.38 secondes

test_accuracy 0.9384615421295166 macro_avg {'precision': 0.9343869731800767, 'recall': 0.9420077972709551, 'f1-score': 0.9372586872586872, 'support': 65} weighted_avg {'precision': 0.9407898614795167, 'recall': 0.9384615384615385, 'f1-score': 0.9387288387288387, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_5
----------
Epoch 1/40
time = 192.84 secondes

Train loss 0.6138419942422346 accuracy 0.6666666865348816 macro_avg {'precision': 0.6832928962365288, 'recall': 0.5528013913495766, 'f1-score': 0.5096357850070721, 'support': 516} weighted_avg {'precision': 0.6779514378679306, 'recall': 0.6666666666666666, 'f1-score': 0.5860001178689297, 'support': 516}
 
time = 2.41 secondes

Val loss 0.6610721051692963 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 2/40
Exception
CUDA out of memory. Tried to allocate 772.00 MiB (GPU 0; 79.21 GiB total capacity; 65.03 GiB already allocated; 277.62 MiB free; 67.46 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 79.21 GiB total capacity; 65.99 GiB already allocated; 65.62 MiB free; 68.03 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 79.21 GiB total capacity; 65.40 GiB already allocated; 47.62 MiB free; 68.05 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_5
----------
Epoch 1/40
time = 1788.71 secondes

Train loss 1.3786950255488302 accuracy 0.6239442229270935 macro_avg {'precision': 0.6081682041418829, 'recall': 0.6096291609248189, 'f1-score': 0.5986664627650635, 'support': 10182} weighted_avg {'precision': 0.6181615735406033, 'recall': 0.6239442152818699, 'f1-score': 0.6116215685798886, 'support': 10182}
 
time = 29.14 secondes

Val loss 0.8001236311146911 accuracy 0.7561837434768677 macro_avg {'precision': 0.7485353624310889, 'recall': 0.750474430604535, 'f1-score': 0.7331642297503929, 'support': 1132} weighted_avg {'precision': 0.7497056335630506, 'recall': 0.7561837455830389, 'f1-score': 0.7394388678488424, 'support': 1132}
 
----------
Epoch 2/40
time = 1699.50 secondes

Train loss 0.5639604486794075 accuracy 0.8327440619468689 macro_avg {'precision': 0.8220357141807038, 'recall': 0.8230365453683408, 'f1-score': 0.8214796446521954, 'support': 10182} weighted_avg {'precision': 0.8296733277590417, 'recall': 0.8327440581418188, 'f1-score': 0.830385242648105, 'support': 10182}
 
time = 27.98 secondes

Val loss 0.607989388137636 accuracy 0.8233215808868408 macro_avg {'precision': 0.8248934993166473, 'recall': 0.8161228625874497, 'f1-score': 0.8134463971188375, 'support': 1132} weighted_avg {'precision': 0.8321271668749511, 'recall': 0.823321554770318, 'f1-score': 0.8207931050948845, 'support': 1132}
 
----------
Epoch 3/40
time = 1335.40 secondes

Train loss 0.32328436933048477 accuracy 0.9080730676651001 macro_avg {'precision': 0.9036087541059828, 'recall': 0.90255696845989, 'f1-score': 0.9028078367250773, 'support': 10182} weighted_avg {'precision': 0.9082212293288707, 'recall': 0.9080730701237478, 'f1-score': 0.9078938144182148, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.5448974306157357 accuracy 0.8657243847846985 macro_avg {'precision': 0.8719553380378882, 'recall': 0.8681658022171128, 'f1-score': 0.8667084066947306, 'support': 1132} weighted_avg {'precision': 0.8750140295237152, 'recall': 0.8657243816254417, 'f1-score': 0.8671920492061694, 'support': 1132}
 
----------
Epoch 4/40
Exception
CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 79.21 GiB total capacity; 26.47 GiB already allocated; 72.62 MiB free; 26.79 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_5
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 1047.64 secondes

Train loss 1.3788351330034774 accuracy 0.6270870566368103 macro_avg {'precision': 0.6105342016392441, 'recall': 0.6109424990427931, 'f1-score': 0.6009516501381424, 'support': 10182} weighted_avg {'precision': 0.6227090785747184, 'recall': 0.6270870163032803, 'f1-score': 0.6161413440671322, 'support': 10182}
 
time = 18.45 secondes

Val loss 0.77729252988184 accuracy 0.7561837434768677 macro_avg {'precision': 0.7853536759292143, 'recall': 0.7536744370723232, 'f1-score': 0.7405888110216353, 'support': 1132} weighted_avg {'precision': 0.7742914463483487, 'recall': 0.7561837455830389, 'f1-score': 0.7425412353996268, 'support': 1132}
 
----------
Epoch 2/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 32.45 GiB already allocated; 624.62 MiB free; 32.52 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 672.00 MiB (GPU 0; 79.21 GiB total capacity; 64.53 GiB already allocated; 437.62 MiB free; 66.51 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 79.21 GiB total capacity; 64.19 GiB already allocated; 237.62 MiB free; 66.71 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.09 GiB (GPU 0; 79.21 GiB total capacity; 62.10 GiB already allocated; 103.62 MiB free; 66.84 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.11 GiB (GPU 0; 79.21 GiB total capacity; 63.52 GiB already allocated; 357.62 MiB free; 66.59 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_5
----------
Epoch 1/40
time = 807.38 secondes

Train loss 1.1040069466950941 accuracy 0.6919072866439819 macro_avg {'precision': 0.690214312030634, 'recall': 0.67751610095091, 'f1-score': 0.6731659396900953, 'support': 10182} weighted_avg {'precision': 0.6984463302971171, 'recall': 0.6919072873698684, 'f1-score': 0.6861120332645047, 'support': 10182}
 
time = 31.40 secondes

Val loss 0.561519819456087 accuracy 0.8356890678405762 macro_avg {'precision': 0.8326253326601213, 'recall': 0.8285081834557078, 'f1-score': 0.8197973738214543, 'support': 1132} weighted_avg {'precision': 0.8366070371785759, 'recall': 0.8356890459363958, 'f1-score': 0.8269871298181244, 'support': 1132}
 
----------
Epoch 2/40
time = 773.20 secondes

Train loss 0.40969288906190704 accuracy 0.8785111308097839 macro_avg {'precision': 0.8712340489968478, 'recall': 0.8702461692672421, 'f1-score': 0.8703378299703243, 'support': 10182} weighted_avg {'precision': 0.8776170751461674, 'recall': 0.8785110980161068, 'f1-score': 0.8777350780891504, 'support': 10182}
 
time = 33.18 secondes

Val loss 0.5062230128899846 accuracy 0.8630741834640503 macro_avg {'precision': 0.8654010126509629, 'recall': 0.8595765395572773, 'f1-score': 0.8542955859714203, 'support': 1132} weighted_avg {'precision': 0.8724695110020947, 'recall': 0.8630742049469965, 'f1-score': 0.8596754284127089, 'support': 1132}
 
----------
Epoch 3/40
time = 747.98 secondes

Train loss 0.251614892118416 accuracy 0.9294834136962891 macro_avg {'precision': 0.9254888148833793, 'recall': 0.9245678526308378, 'f1-score': 0.9248973540428441, 'support': 10182} weighted_avg {'precision': 0.9293785539557267, 'recall': 0.9294834020821057, 'f1-score': 0.9293165753466207, 'support': 10182}
 
time = 33.15 secondes

Val loss 0.47290605285637816 accuracy 0.8886925578117371 macro_avg {'precision': 0.8940912302632282, 'recall': 0.8862961121392008, 'f1-score': 0.8872055880840618, 'support': 1132} weighted_avg {'precision': 0.894705061839053, 'recall': 0.8886925795053003, 'f1-score': 0.889011533419947, 'support': 1132}
 
----------
Epoch 4/40
time = 854.15 secondes

Train loss 0.18146463255602663 accuracy 0.9514830112457275 macro_avg {'precision': 0.9494742626944553, 'recall': 0.9493136974812924, 'f1-score': 0.9493459164780826, 'support': 10182} weighted_avg {'precision': 0.9517810385048157, 'recall': 0.951483009231978, 'f1-score': 0.9515839881380637, 'support': 10182}
 
time = 31.26 secondes

Val loss 0.46420306945219636 accuracy 0.9010601043701172 macro_avg {'precision': 0.9015430520324665, 'recall': 0.8999366306056737, 'f1-score': 0.8991506888119144, 'support': 1132} weighted_avg {'precision': 0.9033809703227991, 'recall': 0.901060070671378, 'f1-score': 0.900615589174653, 'support': 1132}
 
----------
Epoch 5/40
time = 844.72 secondes

Train loss 0.15472720080260713 accuracy 0.9598311185836792 macro_avg {'precision': 0.9583032729774585, 'recall': 0.9585400223635583, 'f1-score': 0.9583366076863568, 'support': 10182} weighted_avg {'precision': 0.9600673055840175, 'recall': 0.9598310744450992, 'f1-score': 0.9598765394859399, 'support': 10182}
 
time = 34.00 secondes

Val loss 0.5761889871193463 accuracy 0.9010601043701172 macro_avg {'precision': 0.9107739466269862, 'recall': 0.9041653601384254, 'f1-score': 0.9049531450560607, 'support': 1132} weighted_avg {'precision': 0.9097657742540818, 'recall': 0.901060070671378, 'f1-score': 0.9027639086172752, 'support': 1132}
 
----------
Epoch 6/40
time = 843.15 secondes

Train loss 0.15636962117591444 accuracy 0.9638578295707703 macro_avg {'precision': 0.9627383530916717, 'recall': 0.9627858460810724, 'f1-score': 0.9627270625132021, 'support': 10182} weighted_avg {'precision': 0.9638911224578283, 'recall': 0.9638577882537812, 'f1-score': 0.9638405637785629, 'support': 10182}
 
time = 32.76 secondes

Val loss 0.5501171116484329 accuracy 0.9063604474067688 macro_avg {'precision': 0.9113841962692583, 'recall': 0.9044217242261441, 'f1-score': 0.9050920380237388, 'support': 1132} weighted_avg {'precision': 0.9091843451552422, 'recall': 0.9063604240282686, 'f1-score': 0.9054377132614223, 'support': 1132}
 
----------
Epoch 7/40
time = 846.52 secondes

Train loss 0.1310386887026528 accuracy 0.9709291458129883 macro_avg {'precision': 0.9698953159529407, 'recall': 0.9697187309760331, 'f1-score': 0.9697820394451261, 'support': 10182} weighted_avg {'precision': 0.9709353570118635, 'recall': 0.9709290905519544, 'f1-score': 0.970906914008199, 'support': 10182}
 
time = 34.21 secondes

Val loss 0.6911237750769738 accuracy 0.9019434452056885 macro_avg {'precision': 0.9105841551233705, 'recall': 0.9049842856466637, 'f1-score': 0.9039706723602029, 'support': 1132} weighted_avg {'precision': 0.9074792866506454, 'recall': 0.9019434628975265, 'f1-score': 0.9004252642302906, 'support': 1132}
 
----------
Epoch 8/40
time = 1192.41 secondes

Train loss 0.1330441684599014 accuracy 0.9717147946357727 macro_avg {'precision': 0.9712555843106842, 'recall': 0.9712230694621005, 'f1-score': 0.9711844080208533, 'support': 10182} weighted_avg {'precision': 0.9716829494457713, 'recall': 0.971714790807307, 'f1-score': 0.9716428185398664, 'support': 10182}
 
time = 50.29 secondes

Val loss 0.5628764587073278 accuracy 0.9116607904434204 macro_avg {'precision': 0.9143646826683897, 'recall': 0.9147253007836561, 'f1-score': 0.9136975083145396, 'support': 1132} weighted_avg {'precision': 0.9136388234550684, 'recall': 0.911660777385159, 'f1-score': 0.9117493036940542, 'support': 1132}
 
----------
Epoch 9/40
time = 1243.34 secondes

Train loss 0.1260938455323832 accuracy 0.9729915857315063 macro_avg {'precision': 0.9724067016222788, 'recall': 0.9723662939061761, 'f1-score': 0.9723368343788985, 'support': 10182} weighted_avg {'precision': 0.9730106182904603, 'recall': 0.972991553722255, 'f1-score': 0.9729499893537557, 'support': 10182}
 
time = 46.88 secondes

Val loss 0.7649277871893555 accuracy 0.8922261595726013 macro_avg {'precision': 0.9004636037402836, 'recall': 0.8940124617065066, 'f1-score': 0.8918989416741585, 'support': 1132} weighted_avg {'precision': 0.8997840460961315, 'recall': 0.892226148409894, 'f1-score': 0.8902482939312276, 'support': 1132}
 
----------
Epoch 10/40
time = 1164.88 secondes

Train loss 0.14218513524897025 accuracy 0.9718130230903625 macro_avg {'precision': 0.971000733496774, 'recall': 0.9710422862868556, 'f1-score': 0.9709793264635003, 'support': 10182} weighted_avg {'precision': 0.9718770231681603, 'recall': 0.971813003339226, 'f1-score': 0.9718036857490919, 'support': 10182}
 
time = 49.29 secondes

Val loss 0.7602788953903348 accuracy 0.8913427591323853 macro_avg {'precision': 0.9057600035378869, 'recall': 0.8955219843344139, 'f1-score': 0.8955440928730083, 'support': 1132} weighted_avg {'precision': 0.9063860084309113, 'recall': 0.8913427561837456, 'f1-score': 0.8935217560470764, 'support': 1132}
 
----------
Epoch 11/40
time = 1040.49 secondes

Train loss 0.0987577843101965 accuracy 0.9801610708236694 macro_avg {'precision': 0.9797608336439838, 'recall': 0.9796708744193579, 'f1-score': 0.9796790478526253, 'support': 10182} weighted_avg {'precision': 0.9802495050622807, 'recall': 0.9801610685523473, 'f1-score': 0.9801724812791398, 'support': 10182}
 
time = 48.51 secondes

Val loss 0.6287684796466557 accuracy 0.9063604474067688 macro_avg {'precision': 0.916682253221531, 'recall': 0.905538194926369, 'f1-score': 0.907510755711251, 'support': 1132} weighted_avg {'precision': 0.9132051548756368, 'recall': 0.9063604240282686, 'f1-score': 0.9066794750092682, 'support': 1132}
 
----------
Epoch 12/40
time = 1177.10 secondes

Train loss 0.10455448816134193 accuracy 0.9803575277328491 macro_avg {'precision': 0.9797830389811988, 'recall': 0.9796861995605537, 'f1-score': 0.9797054456581545, 'support': 10182} weighted_avg {'precision': 0.9803980147708814, 'recall': 0.9803574936161854, 'f1-score': 0.98035114252689, 'support': 10182}
 
time = 47.27 secondes

Val loss 0.5893521174303957 accuracy 0.9125441908836365 macro_avg {'precision': 0.9174117963390456, 'recall': 0.9141243372756221, 'f1-score': 0.9131058288885358, 'support': 1132} weighted_avg {'precision': 0.9152243881689415, 'recall': 0.9125441696113075, 'f1-score': 0.9108568776923144, 'support': 1132}
 
----------
Epoch 13/40
time = 1041.97 secondes

Train loss 0.09860536837436805 accuracy 0.9799646735191345 macro_avg {'precision': 0.9786515927472333, 'recall': 0.9786204061300234, 'f1-score': 0.9786203010285017, 'support': 10182} weighted_avg {'precision': 0.9799966075089349, 'recall': 0.9799646434885091, 'f1-score': 0.9799650590181598, 'support': 10182}
 
time = 29.88 secondes

Val loss 0.6354265314421098 accuracy 0.9178445339202881 macro_avg {'precision': 0.9247422578165937, 'recall': 0.9181332458880377, 'f1-score': 0.919913034731213, 'support': 1132} weighted_avg {'precision': 0.9219383257115167, 'recall': 0.9178445229681979, 'f1-score': 0.9184769743438468, 'support': 1132}
 
----------
Epoch 14/40
time = 756.30 secondes

Train loss 0.09330315272587594 accuracy 0.9818307161331177 macro_avg {'precision': 0.9814291221789718, 'recall': 0.9814145533273058, 'f1-score': 0.9813755860428426, 'support': 10182} weighted_avg {'precision': 0.981859053316555, 'recall': 0.9818306815949716, 'f1-score': 0.9817975178585573, 'support': 10182}
 
time = 27.15 secondes

Val loss 0.6178208560074933 accuracy 0.9134275913238525 macro_avg {'precision': 0.9187371558834327, 'recall': 0.9177261677075016, 'f1-score': 0.9141361367631182, 'support': 1132} weighted_avg {'precision': 0.9197850106570585, 'recall': 0.9134275618374559, 'f1-score': 0.9119028641687703, 'support': 1132}
 
----------
Epoch 15/40
time = 752.95 secondes

Train loss 0.08706610918655357 accuracy 0.9849734902381897 macro_avg {'precision': 0.9852017977423714, 'recall': 0.9851392787226125, 'f1-score': 0.9851549441110616, 'support': 10182} weighted_avg {'precision': 0.9849658104446745, 'recall': 0.9849734826163818, 'f1-score': 0.9849536309488466, 'support': 10182}
 
time = 27.32 secondes

Val loss 0.6252948301952925 accuracy 0.9187279343605042 macro_avg {'precision': 0.9238565056405443, 'recall': 0.9224721815714807, 'f1-score': 0.9222578653789333, 'support': 1132} weighted_avg {'precision': 0.9215426515934276, 'recall': 0.9187279151943463, 'f1-score': 0.9191803481701379, 'support': 1132}
 
----------
Epoch 16/40
time = 1023.23 secondes

Train loss 0.09397099677517534 accuracy 0.9839913845062256 macro_avg {'precision': 0.9835733723208129, 'recall': 0.9834917288045929, 'f1-score': 0.9835126568045627, 'support': 10182} weighted_avg {'precision': 0.9840333265782872, 'recall': 0.9839913572971911, 'f1-score': 0.9839928003819778, 'support': 10182}
 
time = 32.46 secondes

Val loss 0.7244440299669087 accuracy 0.9028268456459045 macro_avg {'precision': 0.9143353795090953, 'recall': 0.9043144555397904, 'f1-score': 0.9055839273532997, 'support': 1132} weighted_avg {'precision': 0.9099787750889553, 'recall': 0.9028268551236749, 'f1-score': 0.9024770646213283, 'support': 1132}
 
----------
Epoch 17/40
time = 1017.79 secondes

Train loss 0.08425429959159093 accuracy 0.9843842387199402 macro_avg {'precision': 0.9839053720515955, 'recall': 0.9840411058794505, 'f1-score': 0.9839572342391092, 'support': 10182} weighted_avg {'precision': 0.9844259882006391, 'recall': 0.9843842074248674, 'f1-score': 0.9843891542008636, 'support': 10182}
 
time = 32.83 secondes

Val loss 0.6817993710301636 accuracy 0.9116607904434204 macro_avg {'precision': 0.9200696122198135, 'recall': 0.9151901863531435, 'f1-score': 0.9152644604897903, 'support': 1132} weighted_avg {'precision': 0.9181076263840288, 'recall': 0.911660777385159, 'f1-score': 0.912606936621121, 'support': 1132}
 
----------
Epoch 18/40
Exception
CUDA out of memory. Tried to allocate 290.00 MiB (GPU 0; 79.21 GiB total capacity; 25.79 GiB already allocated; 283.62 MiB free; 26.43 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_5
----------
Epoch 1/40
time = 1278.03 secondes

Train loss 1.0410066138795069 accuracy 0.7082105875015259 macro_avg {'precision': 0.7029482640919367, 'recall': 0.6941421907349189, 'f1-score': 0.6877377367338036, 'support': 10182} weighted_avg {'precision': 0.7089482693394742, 'recall': 0.7082105676684345, 'f1-score': 0.7001035724858343, 'support': 10182}
 
time = 47.50 secondes

Val loss 0.5471607497040655 accuracy 0.8365724682807922 macro_avg {'precision': 0.8263871441339103, 'recall': 0.8256853607315865, 'f1-score': 0.814109882696699, 'support': 1132} weighted_avg {'precision': 0.8317530798349507, 'recall': 0.8365724381625441, 'f1-score': 0.824460556183695, 'support': 1132}
 
----------
Epoch 2/40
time = 1265.66 secondes

Train loss 0.3660952147283537 accuracy 0.8939304947853088 macro_avg {'precision': 0.8883287092298089, 'recall': 0.8861978900741889, 'f1-score': 0.8863358634688308, 'support': 10182} weighted_avg {'precision': 0.8932312824502139, 'recall': 0.8939304655274013, 'f1-score': 0.8928774726725832, 'support': 10182}
 
time = 44.52 secondes

Val loss 0.5028679795878034 accuracy 0.8736749291419983 macro_avg {'precision': 0.8812620943950005, 'recall': 0.8729330435929917, 'f1-score': 0.8696474172392238, 'support': 1132} weighted_avg {'precision': 0.8833324823305789, 'recall': 0.8736749116607774, 'f1-score': 0.8713639244217642, 'support': 1132}
 
----------
Epoch 3/40
time = 1251.49 secondes

Train loss 0.21385439735467385 accuracy 0.9386171698570251 macro_avg {'precision': 0.9356398794585594, 'recall': 0.9348388079416822, 'f1-score': 0.9351067919764574, 'support': 10182} weighted_avg {'precision': 0.9385468581343115, 'recall': 0.9386171675505794, 'f1-score': 0.9384681785503812, 'support': 10182}
 
time = 43.65 secondes

Val loss 0.4897728716547955 accuracy 0.8966431021690369 macro_avg {'precision': 0.8990645550321492, 'recall': 0.8963040792909165, 'f1-score': 0.8946906810219776, 'support': 1132} weighted_avg {'precision': 0.8987085965495601, 'recall': 0.8966431095406361, 'f1-score': 0.8947535496146685, 'support': 1132}
 
----------
Epoch 4/40
time = 1264.50 secondes

Train loss 0.16279420425078803 accuracy 0.9566882848739624 macro_avg {'precision': 0.954835838338911, 'recall': 0.9550507478249475, 'f1-score': 0.9548759820308265, 'support': 10182} weighted_avg {'precision': 0.9568703019172888, 'recall': 0.9566882734236889, 'f1-score': 0.9567182180570666, 'support': 10182}
 
time = 40.84 secondes

Val loss 0.48358213460125343 accuracy 0.9045936465263367 macro_avg {'precision': 0.9097813899265503, 'recall': 0.9044359012333674, 'f1-score': 0.9049299760106525, 'support': 1132} weighted_avg {'precision': 0.9074283934692466, 'recall': 0.9045936395759717, 'f1-score': 0.903919524942915, 'support': 1132}
 
----------
Epoch 5/40
time = 1261.97 secondes

Train loss 0.148579688592349 accuracy 0.9631703495979309 macro_avg {'precision': 0.9612722178045463, 'recall': 0.9614293869052121, 'f1-score': 0.9612849494144078, 'support': 10182} weighted_avg {'precision': 0.9634177326798685, 'recall': 0.9631703005303477, 'f1-score': 0.9632361931799226, 'support': 10182}
 
time = 42.53 secondes

Val loss 0.4881502291946803 accuracy 0.916961133480072 macro_avg {'precision': 0.9209246489996256, 'recall': 0.9179116804626458, 'f1-score': 0.9180379292469534, 'support': 1132} weighted_avg {'precision': 0.9167533845316717, 'recall': 0.9169611307420494, 'f1-score': 0.9155353962148769, 'support': 1132}
 
----------
Epoch 6/40
time = 1261.35 secondes

Train loss 0.1456805533983341 accuracy 0.9649381637573242 macro_avg {'precision': 0.9639392069483957, 'recall': 0.9641015694680641, 'f1-score': 0.9639809013132832, 'support': 10182} weighted_avg {'precision': 0.9650115334128779, 'recall': 0.9649381261048909, 'f1-score': 0.9649345475358673, 'support': 10182}
 
time = 44.03 secondes

Val loss 0.5439284573781343 accuracy 0.9045936465263367 macro_avg {'precision': 0.9082047218855449, 'recall': 0.9024674494091064, 'f1-score': 0.9011391677375624, 'support': 1132} weighted_avg {'precision': 0.9073333158046251, 'recall': 0.9045936395759717, 'f1-score': 0.9024077629770623, 'support': 1132}
 
----------
Epoch 7/40
time = 1271.72 secondes

Train loss 0.13599951193357995 accuracy 0.9682773947715759 macro_avg {'precision': 0.9679788080401917, 'recall': 0.9674384622529472, 'f1-score': 0.9676416151966338, 'support': 10182} weighted_avg {'precision': 0.9683091365941926, 'recall': 0.9682773521901394, 'f1-score': 0.9682335059606366, 'support': 10182}
 
time = 43.78 secondes

Val loss 0.6720750675771162 accuracy 0.898409903049469 macro_avg {'precision': 0.9095902352686913, 'recall': 0.8998642833950731, 'f1-score': 0.900030191103607, 'support': 1132} weighted_avg {'precision': 0.9057373344097834, 'recall': 0.8984098939929329, 'f1-score': 0.8974433304929748, 'support': 1132}
 
----------
Epoch 8/40
time = 1251.92 secondes

Train loss 0.10997186288777798 accuracy 0.9756433367729187 macro_avg {'precision': 0.9752824210963403, 'recall': 0.9751900133915201, 'f1-score': 0.9752022389619844, 'support': 10182} weighted_avg {'precision': 0.9756970610416366, 'recall': 0.97564329208407, 'f1-score': 0.975635140923291, 'support': 10182}
 
time = 39.84 secondes

Val loss 0.667114541862606 accuracy 0.9010601043701172 macro_avg {'precision': 0.9092774999845075, 'recall': 0.8993305173818216, 'f1-score': 0.9003149196646651, 'support': 1132} weighted_avg {'precision': 0.9078171346435945, 'recall': 0.901060070671378, 'f1-score': 0.9001778767462966, 'support': 1132}
 
----------
Epoch 9/40
time = 1261.48 secondes

Train loss 0.10784836513070892 accuracy 0.976527214050293 macro_avg {'precision': 0.9755654362070432, 'recall': 0.9754687656772812, 'f1-score': 0.9755013910773341, 'support': 10182} weighted_avg {'precision': 0.9765405057773149, 'recall': 0.9765272048713416, 'f1-score': 0.976520159387736, 'support': 10182}
 
time = 39.26 secondes

Val loss 0.6398391171943062 accuracy 0.9028268456459045 macro_avg {'precision': 0.9099987293326283, 'recall': 0.902750467759601, 'f1-score': 0.904226974438685, 'support': 1132} weighted_avg {'precision': 0.9073220780704142, 'recall': 0.9028268551236749, 'f1-score': 0.9030028805382366, 'support': 1132}
 
----------
Epoch 10/40
time = 1252.79 secondes

Train loss 0.10562860691659313 accuracy 0.9787861108779907 macro_avg {'precision': 0.977319361694531, 'recall': 0.9773039613607934, 'f1-score': 0.9772893793574677, 'support': 10182} weighted_avg {'precision': 0.9788136652921988, 'recall': 0.9787860931054803, 'f1-score': 0.9787796712338008, 'support': 10182}
 
time = 44.62 secondes

Val loss 0.6436800062992531 accuracy 0.8948763608932495 macro_avg {'precision': 0.9019601933526686, 'recall': 0.8984695874210955, 'f1-score': 0.8967710953444085, 'support': 1132} weighted_avg {'precision': 0.9035825026823225, 'recall': 0.8948763250883393, 'f1-score': 0.8954450061065078, 'support': 1132}
 
----------
Epoch 11/40
time = 1250.77 secondes

Train loss 0.08888991892924353 accuracy 0.9815360903739929 macro_avg {'precision': 0.9813157300467431, 'recall': 0.9815251649772726, 'f1-score': 0.9813917785109817, 'support': 10182} weighted_avg {'precision': 0.9816361567385283, 'recall': 0.9815360439992143, 'f1-score': 0.9815587703612366, 'support': 10182}
 
time = 41.34 secondes

Val loss 0.7337902416788701 accuracy 0.8957597017288208 macro_avg {'precision': 0.9083691631940717, 'recall': 0.8952080749251319, 'f1-score': 0.8959246268080847, 'support': 1132} weighted_avg {'precision': 0.9041590406499347, 'recall': 0.8957597173144877, 'f1-score': 0.8939263301581506, 'support': 1132}
 
----------
Epoch 12/40
time = 1178.18 secondes

Train loss 0.09620683605307889 accuracy 0.981634259223938 macro_avg {'precision': 0.981449140730367, 'recall': 0.9812136333406404, 'f1-score': 0.9812854418810467, 'support': 10182} weighted_avg {'precision': 0.9816962584035613, 'recall': 0.9816342565311333, 'f1-score': 0.9816193756271911, 'support': 10182}
 
time = 41.54 secondes

Val loss 0.8171910391866335 accuracy 0.8992933034896851 macro_avg {'precision': 0.9065257436553, 'recall': 0.9034553664770488, 'f1-score': 0.9012317414222096, 'support': 1132} weighted_avg {'precision': 0.9068160208741999, 'recall': 0.8992932862190812, 'f1-score': 0.8992679586460046, 'support': 1132}
 
----------
Epoch 13/40
time = 1138.26 secondes

Train loss 0.09559244924944331 accuracy 0.9811432361602783 macro_avg {'precision': 0.9809180783248859, 'recall': 0.980868606309361, 'f1-score': 0.9808647843217138, 'support': 10182} weighted_avg {'precision': 0.9811761573990974, 'recall': 0.981143193871538, 'f1-score': 0.9811310562035233, 'support': 10182}
 
time = 42.00 secondes

Val loss 0.7723643653675616 accuracy 0.9090105891227722 macro_avg {'precision': 0.9117568991379595, 'recall': 0.9090898467579873, 'f1-score': 0.9084833620991404, 'support': 1132} weighted_avg {'precision': 0.9111319112543579, 'recall': 0.9090106007067138, 'f1-score': 0.9080215974897606, 'support': 1132}
 
----------
Epoch 14/40
time = 1124.54 secondes

Train loss 0.0814916079215489 accuracy 0.9836967587471008 macro_avg {'precision': 0.9833862172813678, 'recall': 0.983364398083514, 'f1-score': 0.9833576834945704, 'support': 10182} weighted_avg {'precision': 0.9837028809857377, 'recall': 0.9836967197014339, 'f1-score': 0.9836820213380901, 'support': 10182}
 
time = 41.51 secondes

Val loss 0.7219847984142432 accuracy 0.9028268456459045 macro_avg {'precision': 0.9095676003164993, 'recall': 0.9047117284470512, 'f1-score': 0.9049702373425712, 'support': 1132} weighted_avg {'precision': 0.9088716865741259, 'recall': 0.9028268551236749, 'f1-score': 0.9034853617746318, 'support': 1132}
 
----------
Epoch 15/40
time = 1118.64 secondes

Train loss 0.09349864044196689 accuracy 0.9822235703468323 macro_avg {'precision': 0.9821886703007952, 'recall': 0.9820099965000001, 'f1-score': 0.9820563733173392, 'support': 10182} weighted_avg {'precision': 0.9823922145984311, 'recall': 0.9822235317226478, 'f1-score': 0.9822641067008587, 'support': 10182}
 
time = 37.90 secondes

Val loss 1.0347046369854171 accuracy 0.8736749291419983 macro_avg {'precision': 0.8934776485855831, 'recall': 0.8763760190422183, 'f1-score': 0.878622370953436, 'support': 1132} weighted_avg {'precision': 0.8934756840359399, 'recall': 0.8736749116607774, 'f1-score': 0.8772723131312008, 'support': 1132}
 
----------
Epoch 16/40
time = 1142.08 secondes

Train loss 0.08546897212090555 accuracy 0.9845806360244751 macro_avg {'precision': 0.9847963363585246, 'recall': 0.9845491342770865, 'f1-score': 0.9846484924934689, 'support': 10182} weighted_avg {'precision': 0.9846011804265655, 'recall': 0.9845806324887055, 'f1-score': 0.9845675598028777, 'support': 10182}
 
time = 41.71 secondes

Val loss 0.7052467561753846 accuracy 0.9072438478469849 macro_avg {'precision': 0.9087586009550657, 'recall': 0.9068622685605174, 'f1-score': 0.9056630139230932, 'support': 1132} weighted_avg {'precision': 0.910730122067205, 'recall': 0.907243816254417, 'f1-score': 0.9069886565087558, 'support': 1132}
 
----------
Epoch 17/40
time = 984.14 secondes

Train loss 0.06754512823318354 accuracy 0.9861520528793335 macro_avg {'precision': 0.9858022133208688, 'recall': 0.9857200785342544, 'f1-score': 0.9857532187663711, 'support': 10182} weighted_avg {'precision': 0.9861691677893012, 'recall': 0.9861520329994107, 'f1-score': 0.9861526481306957, 'support': 10182}
 
time = 31.89 secondes

Val loss 0.7591919435507292 accuracy 0.9045936465263367 macro_avg {'precision': 0.9133183203203117, 'recall': 0.9043738468470325, 'f1-score': 0.906112029477135, 'support': 1132} weighted_avg {'precision': 0.9116921194438198, 'recall': 0.9045936395759717, 'f1-score': 0.9052468314525771, 'support': 1132}
 
----------
Epoch 18/40
time = 853.95 secondes

Train loss 0.06260714792223206 accuracy 0.9877234697341919 macro_avg {'precision': 0.9874038058629427, 'recall': 0.9872925463560904, 'f1-score': 0.987333396447408, 'support': 10182} weighted_avg {'precision': 0.9877619463508348, 'recall': 0.9877234335101159, 'f1-score': 0.9877283581110511, 'support': 10182}
 
time = 29.64 secondes

Val loss 0.663980843581183 accuracy 0.9143109321594238 macro_avg {'precision': 0.9205762522508225, 'recall': 0.9143730493592445, 'f1-score': 0.9150562278391352, 'support': 1132} weighted_avg {'precision': 0.9197992172205032, 'recall': 0.9143109540636042, 'f1-score': 0.9146463488380763, 'support': 1132}
 
----------
Epoch 19/40
time = 859.11 secondes

Train loss 0.07463403753531259 accuracy 0.9871341586112976 macro_avg {'precision': 0.9867026146315314, 'recall': 0.9866129342249221, 'f1-score': 0.9866418053720288, 'support': 10182} weighted_avg {'precision': 0.9871930720557713, 'recall': 0.9871341583186014, 'f1-score': 0.9871473375624276, 'support': 10182}
 
time = 30.09 secondes

Val loss 0.7655369853778147 accuracy 0.9054770469665527 macro_avg {'precision': 0.9113870447953584, 'recall': 0.9057525319579064, 'f1-score': 0.9057885143623225, 'support': 1132} weighted_avg {'precision': 0.9104160623027439, 'recall': 0.9054770318021201, 'f1-score': 0.9051768435385642, 'support': 1132}
 
----------
Epoch 20/40
time = 852.52 secondes

Train loss 0.05961765103982221 accuracy 0.9889020323753357 macro_avg {'precision': 0.9889816519565635, 'recall': 0.9890676841825424, 'f1-score': 0.9890074868668931, 'support': 10182} weighted_avg {'precision': 0.9889460262899427, 'recall': 0.9889019838931448, 'f1-score': 0.9889071727799348, 'support': 10182}
 
time = 29.90 secondes

Val loss 0.8321129928302416 accuracy 0.9019434452056885 macro_avg {'precision': 0.9133012794345685, 'recall': 0.9077429201627671, 'f1-score': 0.9067454043382677, 'support': 1132} weighted_avg {'precision': 0.9150498047052216, 'recall': 0.9019434628975265, 'f1-score': 0.9047363482263753, 'support': 1132}
 
----------
Epoch 21/40
time = 852.96 secondes

Train loss 0.059427638276235886 accuracy 0.9889020323753357 macro_avg {'precision': 0.988643711000288, 'recall': 0.9886518583276726, 'f1-score': 0.9886382106454461, 'support': 10182} weighted_avg {'precision': 0.9889249725570338, 'recall': 0.9889019838931448, 'f1-score': 0.9889039231530038, 'support': 10182}
 
time = 26.93 secondes

Val loss 0.7601776000866125 accuracy 0.9037102460861206 macro_avg {'precision': 0.9153043370359122, 'recall': 0.9066816307303484, 'f1-score': 0.9066290037656367, 'support': 1132} weighted_avg {'precision': 0.915299886443193, 'recall': 0.9037102473498233, 'f1-score': 0.9045804488162794, 'support': 1132}
 
----------
Epoch 22/40
time = 857.53 secondes

Train loss 0.0579601059042582 accuracy 0.9894912838935852 macro_avg {'precision': 0.9893842314930748, 'recall': 0.9893540388965182, 'f1-score': 0.9893217614085845, 'support': 10182} weighted_avg {'precision': 0.98960971726177, 'recall': 0.9894912590846592, 'f1-score': 0.9895019277451077, 'support': 10182}
 
time = 27.40 secondes

Val loss 0.7379221126518555 accuracy 0.9037102460861206 macro_avg {'precision': 0.9146840114140881, 'recall': 0.9049455595546375, 'f1-score': 0.9051983691388816, 'support': 1132} weighted_avg {'precision': 0.9155642649351061, 'recall': 0.9037102473498233, 'f1-score': 0.9046688557644291, 'support': 1132}
 
----------
Epoch 23/40
time = 848.30 secondes

Train loss 0.055728540437653684 accuracy 0.9898841381072998 macro_avg {'precision': 0.9900389974152362, 'recall': 0.9897590293501086, 'f1-score': 0.989875817258534, 'support': 10182} weighted_avg {'precision': 0.9899444035768236, 'recall': 0.9898841092123355, 'f1-score': 0.9898915115822058, 'support': 10182}
 
time = 28.80 secondes

Val loss 0.8499182992213911 accuracy 0.8992933034896851 macro_avg {'precision': 0.9111239602374608, 'recall': 0.902143169065053, 'f1-score': 0.9028438175558829, 'support': 1132} weighted_avg {'precision': 0.9117001100521408, 'recall': 0.8992932862190812, 'f1-score': 0.9013759803529592, 'support': 1132}
 
----------
Epoch 24/40
time = 856.96 secondes

Train loss 0.05498439313461339 accuracy 0.9891966581344604 macro_avg {'precision': 0.9884833386792848, 'recall': 0.9880332781593564, 'f1-score': 0.9882354048556033, 'support': 10182} weighted_avg {'precision': 0.9891872662096036, 'recall': 0.989196621488902, 'f1-score': 0.9891733863433227, 'support': 10182}
 
time = 28.30 secondes

Val loss 0.7449860824281259 accuracy 0.898409903049469 macro_avg {'precision': 0.9066364414110367, 'recall': 0.8995952106346146, 'f1-score': 0.9007261618222456, 'support': 1132} weighted_avg {'precision': 0.9070715840180344, 'recall': 0.8984098939929329, 'f1-score': 0.9001576406749707, 'support': 1132}
 
----------
Epoch 25/40
time = 853.96 secondes

Train loss 0.03776003312569961 accuracy 0.992634117603302 macro_avg {'precision': 0.9921292258007293, 'recall': 0.9921787539689534, 'f1-score': 0.9921491719151947, 'support': 10182} weighted_avg {'precision': 0.9926388344811653, 'recall': 0.9926340601060696, 'f1-score': 0.992631619424834, 'support': 10182}
 
time = 30.05 secondes

Val loss 0.7397243759463583 accuracy 0.916961133480072 macro_avg {'precision': 0.9183683184787176, 'recall': 0.9164070500035573, 'f1-score': 0.9162106206803671, 'support': 1132} weighted_avg {'precision': 0.9196135404051596, 'recall': 0.9169611307420494, 'f1-score': 0.9171894396924912, 'support': 1132}
 
----------
Epoch 26/40
time = 856.42 secondes

Train loss 0.05122490665910145 accuracy 0.9905716180801392 macro_avg {'precision': 0.9902228453297152, 'recall': 0.9901246572449598, 'f1-score': 0.9901647447004958, 'support': 10182} weighted_avg {'precision': 0.9905833083983221, 'recall': 0.990571596935769, 'f1-score': 0.9905688448136409, 'support': 10182}
 
time = 27.98 secondes

Val loss 0.7992157501555507 accuracy 0.9054770469665527 macro_avg {'precision': 0.9169034694061342, 'recall': 0.9027407541247653, 'f1-score': 0.9067534207539918, 'support': 1132} weighted_avg {'precision': 0.9120488352812897, 'recall': 0.9054770318021201, 'f1-score': 0.9056541043102705, 'support': 1132}
 
----------
Epoch 27/40
time = 852.77 secondes

Train loss 0.05716856041816665 accuracy 0.9916519522666931 macro_avg {'precision': 0.9916735066891578, 'recall': 0.9912515963354505, 'f1-score': 0.991441415045476, 'support': 10182} weighted_avg {'precision': 0.9916905004100165, 'recall': 0.9916519347868789, 'f1-score': 0.9916506863119843, 'support': 10182}
 
time = 29.47 secondes

Val loss 0.7453327474269801 accuracy 0.916077733039856 macro_avg {'precision': 0.9222156228206687, 'recall': 0.9150621308160408, 'f1-score': 0.9170430422455136, 'support': 1132} weighted_avg {'precision': 0.9186798090119166, 'recall': 0.916077738515901, 'f1-score': 0.9158023389751843, 'support': 1132}
 
----------
Epoch 28/40
time = 851.04 secondes

Train loss 0.039331617534531016 accuracy 0.993714451789856 macro_avg {'precision': 0.9933584777499871, 'recall': 0.9932209279230243, 'f1-score': 0.9932776055228816, 'support': 10182} weighted_avg {'precision': 0.9937353594668228, 'recall': 0.9937143979571793, 'f1-score': 0.9937133335461933, 'support': 10182}
 
time = 29.61 secondes

Val loss 0.798071673598725 accuracy 0.9116607904434204 macro_avg {'precision': 0.9174200254823038, 'recall': 0.9115161598808207, 'f1-score': 0.9124434321739233, 'support': 1132} weighted_avg {'precision': 0.9146394200693866, 'recall': 0.911660777385159, 'f1-score': 0.9111412411847691, 'support': 1132}
 
----------
Epoch 29/40
time = 857.07 secondes

Train loss 0.04142470813061509 accuracy 0.991750180721283 macro_avg {'precision': 0.9915775482831725, 'recall': 0.9914590483524552, 'f1-score': 0.9914936029461042, 'support': 10182} weighted_avg {'precision': 0.9918272159842144, 'recall': 0.9917501473187978, 'f1-score': 0.9917642027058032, 'support': 10182}
 
time = 30.80 secondes

Val loss 0.7242563167046555 accuracy 0.9178445339202881 macro_avg {'precision': 0.9258350868688229, 'recall': 0.9195154293685274, 'f1-score': 0.9207606291082483, 'support': 1132} weighted_avg {'precision': 0.9228854815126709, 'recall': 0.9178445229681979, 'f1-score': 0.918384472930696, 'support': 1132}
 
----------
Epoch 30/40
time = 862.97 secondes

Train loss 0.036637708850698295 accuracy 0.9936162233352661 macro_avg {'precision': 0.9936632713167732, 'recall': 0.9936432908454348, 'f1-score': 0.9936388392361973, 'support': 10182} weighted_avg {'precision': 0.9936549319646949, 'recall': 0.9936161854252603, 'f1-score': 0.9936210511222473, 'support': 10182}
 
time = 29.86 secondes

Val loss 0.6464378509682691 accuracy 0.9178445339202881 macro_avg {'precision': 0.9227777470740983, 'recall': 0.9187379759181449, 'f1-score': 0.919674479223912, 'support': 1132} weighted_avg {'precision': 0.9210131228394323, 'recall': 0.9178445229681979, 'f1-score': 0.9183631539990135, 'support': 1132}
 
----------
Epoch 31/40
time = 858.09 secondes

Train loss 0.027774398153863386 accuracy 0.9954822659492493 macro_avg {'precision': 0.9954917514453653, 'recall': 0.9954236725697099, 'f1-score': 0.9954491725422148, 'support': 10182} weighted_avg {'precision': 0.9954978695812576, 'recall': 0.9954822235317227, 'f1-score': 0.9954812213033093, 'support': 10182}
 
time = 30.03 secondes

Val loss 0.7845124446369957 accuracy 0.9151943325996399 macro_avg {'precision': 0.9222503650549218, 'recall': 0.9179047157754827, 'f1-score': 0.9177818093138977, 'support': 1132} weighted_avg {'precision': 0.9205456974120391, 'recall': 0.9151943462897526, 'f1-score': 0.9153983124199291, 'support': 1132}
 
----------
Epoch 32/40
time = 858.71 secondes

Train loss 0.03306070997749138 accuracy 0.9945001006126404 macro_avg {'precision': 0.994658492469973, 'recall': 0.9946267712472032, 'f1-score': 0.9946368924028188, 'support': 10182} weighted_avg {'precision': 0.9945077954580422, 'recall': 0.9945000982125319, 'f1-score': 0.9944980752591107, 'support': 10182}
 
time = 29.36 secondes

Val loss 0.745267776314097 accuracy 0.9116607904434204 macro_avg {'precision': 0.9210581645619366, 'recall': 0.91382607407627, 'f1-score': 0.9155132255305007, 'support': 1132} weighted_avg {'precision': 0.9181362020809369, 'recall': 0.911660777385159, 'f1-score': 0.9128666813325857, 'support': 1132}
 
----------
Epoch 33/40
time = 854.63 secondes

Train loss 0.02222806531685898 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961572924543611, 'recall': 0.9962608388942196, 'f1-score': 0.9962073457849367, 'support': 10182} weighted_avg {'precision': 0.9961754087338917, 'recall': 0.9961697112551562, 'f1-score': 0.9961708982385292, 'support': 10182}
 
time = 30.54 secondes

Val loss 0.7453445871989304 accuracy 0.9125441908836365 macro_avg {'precision': 0.926168800604368, 'recall': 0.9150188800206163, 'f1-score': 0.9173571722361411, 'support': 1132} weighted_avg {'precision': 0.9230178254435311, 'recall': 0.9125441696113075, 'f1-score': 0.9142233388617108, 'support': 1132}
 
----------
Epoch 34/40
time = 856.26 secondes

Train loss 0.015327444549988075 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972138008113328, 'recall': 0.99737369788386, 'f1-score': 0.9972904431223254, 'support': 10182} weighted_avg {'precision': 0.9973543886688778, 'recall': 0.997348261638185, 'f1-score': 0.9973482921549701, 'support': 10182}
 
time = 31.16 secondes

Val loss 0.681848058899767 accuracy 0.916961133480072 macro_avg {'precision': 0.9208856730842963, 'recall': 0.9182178768872417, 'f1-score': 0.9177825582001111, 'support': 1132} weighted_avg {'precision': 0.9209941102698507, 'recall': 0.9169611307420494, 'f1-score': 0.9170861855295437, 'support': 1132}
 
----------
Epoch 35/40
time = 868.31 secondes

Train loss 0.017208318330627016 accuracy 0.9973483085632324 macro_avg {'precision': 0.9972950489215162, 'recall': 0.9971656265073264, 'f1-score': 0.9972264382890306, 'support': 10182} weighted_avg {'precision': 0.9973538696145816, 'recall': 0.997348261638185, 'f1-score': 0.9973477758744823, 'support': 10182}
 
time = 31.88 secondes

Val loss 0.6644987162614764 accuracy 0.9196113348007202 macro_avg {'precision': 0.9247230557964142, 'recall': 0.9221587930206395, 'f1-score': 0.9214808346420575, 'support': 1132} weighted_avg {'precision': 0.9251294852786494, 'recall': 0.9196113074204947, 'f1-score': 0.9202345761129728, 'support': 1132}
 
----------
Epoch 36/40
time = 862.11 secondes

Train loss 0.015581840921161813 accuracy 0.9975447058677673 macro_avg {'precision': 0.997558486928632, 'recall': 0.9976096414123095, 'f1-score': 0.9975815026237221, 'support': 10182} weighted_avg {'precision': 0.9975460966873929, 'recall': 0.9975446867020232, 'f1-score': 0.9975428168082098, 'support': 10182}
 
time = 29.90 secondes

Val loss 0.6797184858581422 accuracy 0.9213780760765076 macro_avg {'precision': 0.9238006456718517, 'recall': 0.9228786730525403, 'f1-score': 0.9223153293503467, 'support': 1132} weighted_avg {'precision': 0.9245841342114436, 'recall': 0.9213780918727915, 'f1-score': 0.9219040087638087, 'support': 1132}
 
----------
Epoch 37/40
time = 858.48 secondes

Train loss 0.013806983781119537 accuracy 0.9973483085632324 macro_avg {'precision': 0.9974027768397387, 'recall': 0.9973938316281077, 'f1-score': 0.9973961410408687, 'support': 10182} weighted_avg {'precision': 0.9973531859596724, 'recall': 0.997348261638185, 'f1-score': 0.9973484907657797, 'support': 10182}
 
time = 30.80 secondes

Val loss 0.804871028646105 accuracy 0.9231448769569397 macro_avg {'precision': 0.9319711188385534, 'recall': 0.9245454650851738, 'f1-score': 0.9257997264661567, 'support': 1132} weighted_avg {'precision': 0.9308496110726515, 'recall': 0.9231448763250883, 'f1-score': 0.9243600459129587, 'support': 1132}
 
----------
Epoch 38/40
time = 855.21 secondes

Train loss 0.010794003921709159 accuracy 0.9985268115997314 macro_avg {'precision': 0.9985671706362995, 'recall': 0.9985447032983696, 'f1-score': 0.9985554705882068, 'support': 10182} weighted_avg {'precision': 0.9985271318619927, 'recall': 0.998526812021214, 'f1-score': 0.9985264992324384, 'support': 10182}
 
time = 30.05 secondes

Val loss 0.7302941198095781 accuracy 0.9240282773971558 macro_avg {'precision': 0.9300096413852609, 'recall': 0.9257847685812169, 'f1-score': 0.9267074978647594, 'support': 1132} weighted_avg {'precision': 0.9279225203369199, 'recall': 0.9240282685512368, 'f1-score': 0.9247391708879779, 'support': 1132}
 
----------
Epoch 39/40
time = 861.47 secondes

Train loss 0.011380939080050577 accuracy 0.9984286427497864 macro_avg {'precision': 0.9984966056501363, 'recall': 0.9984597823151914, 'f1-score': 0.9984753377070316, 'support': 10182} weighted_avg {'precision': 0.9984360639972933, 'recall': 0.9984285994892949, 'f1-score': 0.9984293812841731, 'support': 10182}
 
time = 30.23 secondes

Val loss 0.7874818144574535 accuracy 0.9187279343605042 macro_avg {'precision': 0.9269948500608315, 'recall': 0.920546303150098, 'f1-score': 0.921685395642722, 'support': 1132} weighted_avg {'precision': 0.9256446738587789, 'recall': 0.9187279151943463, 'f1-score': 0.9199305708118599, 'support': 1132}
 
----------
Epoch 40/40
time = 864.22 secondes

Train loss 0.001622616501164993 accuracy 0.9996072053909302 macro_avg {'precision': 0.9996283860557307, 'recall': 0.9996226139678146, 'f1-score': 0.9996252364308884, 'support': 10182} weighted_avg {'precision': 0.9996076962404251, 'recall': 0.9996071498723237, 'f1-score': 0.9996071470325572, 'support': 10182}
 
time = 29.69 secondes

Val loss 0.7293297224956328 accuracy 0.9257950782775879 macro_avg {'precision': 0.9322699492679736, 'recall': 0.9277151417669126, 'f1-score': 0.9288242092413274, 'support': 1132} weighted_avg {'precision': 0.9300862753065733, 'recall': 0.9257950530035336, 'f1-score': 0.9267039859714794, 'support': 1132}
 
----------
best_accuracy 0.9257950782775879 best_epoch 40 macro_avg {'precision': 0.9322699492679736, 'recall': 0.9277151417669126, 'f1-score': 0.9288242092413274, 'support': 1132} weighted_avg {'precision': 0.9300862753065733, 'recall': 0.9257950530035336, 'f1-score': 0.9267039859714794, 'support': 1132}

average train time 1006.7639273285865

average val time 34.7730585873127
 
time = 196.33 secondes

test_accuracy 0.8579394221305847 macro_avg {'precision': 0.8555628803386437, 'recall': 0.8499440395946329, 'f1-score': 0.850911266602864, 'support': 7532} weighted_avg {'precision': 0.8621982331852962, 'recall': 0.8579394583112055, 'f1-score': 0.8582808092412973, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_5
----------
Epoch 1/40
time = 1158.74 secondes

Train loss 1.1305344080906274 accuracy 0.6820860505104065 macro_avg {'precision': 0.6850373820133395, 'recall': 0.6689953496798119, 'f1-score': 0.6692851198214754, 'support': 10182} weighted_avg {'precision': 0.6923192210501069, 'recall': 0.6820860341779611, 'f1-score': 0.6804454498629472, 'support': 10182}
 
time = 38.78 secondes

Val loss 0.5575317289208023 accuracy 0.8374558091163635 macro_avg {'precision': 0.8338128485838858, 'recall': 0.8328304723036398, 'f1-score': 0.8241014059895895, 'support': 1132} weighted_avg {'precision': 0.8381286797824806, 'recall': 0.8374558303886925, 'f1-score': 0.8297660328817458, 'support': 1132}
 
----------
Epoch 2/40
time = 1143.28 secondes

Train loss 0.40187442868515216 accuracy 0.8809664249420166 macro_avg {'precision': 0.873702072866626, 'recall': 0.8729348031403328, 'f1-score': 0.8728477251250023, 'support': 10182} weighted_avg {'precision': 0.8800857449690599, 'recall': 0.8809664113140837, 'f1-score': 0.880145235801781, 'support': 10182}
 
time = 37.15 secondes

Val loss 0.5407826971315163 accuracy 0.8604240417480469 macro_avg {'precision': 0.8688497409436083, 'recall': 0.8644242039134422, 'f1-score': 0.8573736606194329, 'support': 1132} weighted_avg {'precision': 0.8733549456742314, 'recall': 0.8604240282685512, 'f1-score': 0.8566728758685138, 'support': 1132}
 
----------
Epoch 3/40
time = 1210.65 secondes

Train loss 0.23758739418915972 accuracy 0.9309566020965576 macro_avg {'precision': 0.9267232847283801, 'recall': 0.9262454705748265, 'f1-score': 0.9263835007615621, 'support': 10182} weighted_avg {'precision': 0.9308821603155657, 'recall': 0.9309565900608918, 'f1-score': 0.9308273045060012, 'support': 10182}
 
time = 35.94 secondes

Val loss 0.4170163656965318 accuracy 0.9019434452056885 macro_avg {'precision': 0.9070273541952982, 'recall': 0.9023568576375398, 'f1-score': 0.9021384201050923, 'support': 1132} weighted_avg {'precision': 0.9062141780615479, 'recall': 0.9019434628975265, 'f1-score': 0.9015070385768217, 'support': 1132}
 
----------
Epoch 4/40
time = 1217.25 secondes

Train loss 0.1749730537465687 accuracy 0.9523669481277466 macro_avg {'precision': 0.9503629538872694, 'recall': 0.9498952097401201, 'f1-score': 0.9500721321537823, 'support': 10182} weighted_avg {'precision': 0.9526071445926362, 'recall': 0.9523669220192497, 'f1-score': 0.9524299112961209, 'support': 10182}
 
time = 34.91 secondes

Val loss 0.49717233845190156 accuracy 0.8931095600128174 macro_avg {'precision': 0.8985333019345791, 'recall': 0.8918850364094402, 'f1-score': 0.8918611436879258, 'support': 1132} weighted_avg {'precision': 0.8972706381155869, 'recall': 0.8931095406360424, 'f1-score': 0.8919446526507887, 'support': 1132}
 
----------
Epoch 5/40
time = 1213.42 secondes

Train loss 0.14887764721577387 accuracy 0.9619917869567871 macro_avg {'precision': 0.9601035820962245, 'recall': 0.9600273611521054, 'f1-score': 0.9600352145892239, 'support': 10182} weighted_avg {'precision': 0.9620721512509437, 'recall': 0.9619917501473187, 'f1-score': 0.9620015940194782, 'support': 10182}
 
time = 41.74 secondes

Val loss 0.6723526065962546 accuracy 0.8754417300224304 macro_avg {'precision': 0.894968572273221, 'recall': 0.8663475489247446, 'f1-score': 0.8725534685724774, 'support': 1132} weighted_avg {'precision': 0.8903134473684027, 'recall': 0.8754416961130742, 'f1-score': 0.8749145918607554, 'support': 1132}
 
----------
Epoch 6/40
time = 1264.76 secondes

Train loss 0.13837236522739313 accuracy 0.9677863121032715 macro_avg {'precision': 0.9671931469728845, 'recall': 0.9668529736760965, 'f1-score': 0.9670018331685629, 'support': 10182} weighted_avg {'precision': 0.9677989261792014, 'recall': 0.9677862895305441, 'f1-score': 0.9677730851409737, 'support': 10182}
 
time = 39.76 secondes

Val loss 0.588329784348312 accuracy 0.9037102460861206 macro_avg {'precision': 0.9101592314420044, 'recall': 0.9055444707166853, 'f1-score': 0.9047220567275487, 'support': 1132} weighted_avg {'precision': 0.9096550829516835, 'recall': 0.9037102473498233, 'f1-score': 0.9032266521192527, 'support': 1132}
 
----------
Epoch 7/40
time = 1400.06 secondes

Train loss 0.12472769236166521 accuracy 0.9709291458129883 macro_avg {'precision': 0.9703085250074601, 'recall': 0.9702231310268642, 'f1-score': 0.9702421181501609, 'support': 10182} weighted_avg {'precision': 0.9709528427227425, 'recall': 0.9709290905519544, 'f1-score': 0.9709171076850264, 'support': 10182}
 
time = 50.70 secondes

Val loss 0.6630023712436603 accuracy 0.8992933034896851 macro_avg {'precision': 0.9066026529488891, 'recall': 0.9041010219387106, 'f1-score': 0.9006252916508787, 'support': 1132} weighted_avg {'precision': 0.9111850187671798, 'recall': 0.8992932862190812, 'f1-score': 0.9008921695832972, 'support': 1132}
 
----------
Epoch 8/40
time = 1788.24 secondes

Train loss 0.12507492639405837 accuracy 0.9715183973312378 macro_avg {'precision': 0.9703972672470021, 'recall': 0.9704413692920237, 'f1-score': 0.9703960971650213, 'support': 10182} weighted_avg {'precision': 0.9715600754175054, 'recall': 0.9715183657434688, 'f1-score': 0.9715159245448858, 'support': 10182}
 
time = 48.02 secondes

Val loss 0.6080183136050629 accuracy 0.9028268456459045 macro_avg {'precision': 0.9098572144783714, 'recall': 0.9044471910835371, 'f1-score': 0.9044492662271939, 'support': 1132} weighted_avg {'precision': 0.9078726508675276, 'recall': 0.9028268551236749, 'f1-score': 0.9022932430045096, 'support': 1132}
 
----------
Epoch 9/40
time = 1741.43 secondes

Train loss 0.12859460070856818 accuracy 0.9724023342132568 macro_avg {'precision': 0.9720826333431507, 'recall': 0.9716910095960747, 'f1-score': 0.9717940758645497, 'support': 10182} weighted_avg {'precision': 0.9723373940772726, 'recall': 0.9724022785307406, 'f1-score': 0.9722811491036726, 'support': 10182}
 
time = 96.78 secondes

Val loss 0.576187524891665 accuracy 0.9098939895629883 macro_avg {'precision': 0.9174313671232737, 'recall': 0.9072453524240732, 'f1-score': 0.9083803206091522, 'support': 1132} weighted_avg {'precision': 0.9149583742430102, 'recall': 0.9098939929328622, 'f1-score': 0.9089740087513175, 'support': 1132}
 
----------
Epoch 10/40
time = 2515.26 secondes

Train loss 0.0976811626864293 accuracy 0.9780004024505615 macro_avg {'precision': 0.9777889526124184, 'recall': 0.9774974470046628, 'f1-score': 0.9776313828307606, 'support': 10182} weighted_avg {'precision': 0.9780080718117166, 'recall': 0.9780003928501276, 'f1-score': 0.9779935440988431, 'support': 10182}
 
time = 78.06 secondes

Val loss 0.6970274205738515 accuracy 0.898409903049469 macro_avg {'precision': 0.9085908771574642, 'recall': 0.9021606091579054, 'f1-score': 0.9015754466210018, 'support': 1132} weighted_avg {'precision': 0.9096717529437047, 'recall': 0.8984098939929329, 'f1-score': 0.900087389775917, 'support': 1132}
 
----------
Epoch 11/40
time = 2389.86 secondes

Train loss 0.11280565700000587 accuracy 0.9777057766914368 macro_avg {'precision': 0.9768054538003996, 'recall': 0.9770668479341017, 'f1-score': 0.9768924977576766, 'support': 10182} weighted_avg {'precision': 0.9778241340749976, 'recall': 0.9777057552543704, 'f1-score': 0.9777218359602396, 'support': 10182}
 
time = 89.00 secondes

Val loss 0.7559369873041517 accuracy 0.8922261595726013 macro_avg {'precision': 0.9023529133889445, 'recall': 0.8950017181655363, 'f1-score': 0.8948262238442727, 'support': 1132} weighted_avg {'precision': 0.9011404042164843, 'recall': 0.892226148409894, 'f1-score': 0.8928866316850319, 'support': 1132}
 
----------
Epoch 12/40
time = 1321.09 secondes

Train loss 0.10476085289876347 accuracy 0.978295087814331 macro_avg {'precision': 0.977997700376285, 'recall': 0.9778072470193095, 'f1-score': 0.9778502725071674, 'support': 10182} weighted_avg {'precision': 0.9783768731464567, 'recall': 0.978295030445885, 'f1-score': 0.9782824732410752, 'support': 10182}
 
time = 46.60 secondes

Val loss 0.6623062740219839 accuracy 0.9107773900032043 macro_avg {'precision': 0.9136203500900008, 'recall': 0.9147066850522746, 'f1-score': 0.9119264574857479, 'support': 1132} weighted_avg {'precision': 0.9157980835645412, 'recall': 0.9107773851590106, 'f1-score': 0.9110578297072937, 'support': 1132}
 
----------
Epoch 13/40
time = 1800.13 secondes

Train loss 0.09222395056458424 accuracy 0.9820271134376526 macro_avg {'precision': 0.9815789808108392, 'recall': 0.9815360658481357, 'f1-score': 0.9815379351414194, 'support': 10182} weighted_avg {'precision': 0.9820651062015643, 'recall': 0.9820271066588097, 'f1-score': 0.9820265445303971, 'support': 10182}
 
time = 54.60 secondes

Val loss 0.8333549677217248 accuracy 0.8851590156555176 macro_avg {'precision': 0.8982208141559909, 'recall': 0.8899732060240876, 'f1-score': 0.8875379928141951, 'support': 1132} weighted_avg {'precision': 0.8992828896383976, 'recall': 0.8851590106007067, 'f1-score': 0.8846679551407592, 'support': 1132}
 
----------
Epoch 14/40
time = 1707.20 secondes

Train loss 0.09113939176834432 accuracy 0.9815360903739929 macro_avg {'precision': 0.9808630603119763, 'recall': 0.9810160086599456, 'f1-score': 0.9809290779943561, 'support': 10182} weighted_avg {'precision': 0.9815626689259355, 'recall': 0.9815360439992143, 'f1-score': 0.9815392516905038, 'support': 10182}
 
time = 54.28 secondes

Val loss 0.7265318556203799 accuracy 0.9063604474067688 macro_avg {'precision': 0.9096436783979571, 'recall': 0.9058792020308131, 'f1-score': 0.9058652045161892, 'support': 1132} weighted_avg {'precision': 0.9115270106808036, 'recall': 0.9063604240282686, 'f1-score': 0.9070310320098495, 'support': 1132}
 
----------
Epoch 15/40
time = 1701.98 secondes

Train loss 0.08464127557230744 accuracy 0.9841877818107605 macro_avg {'precision': 0.9836256785516546, 'recall': 0.9833482108893618, 'f1-score': 0.9834672172217722, 'support': 10182} weighted_avg {'precision': 0.9842138525786391, 'recall': 0.9841877823610292, 'f1-score': 0.9841817913910089, 'support': 10182}
 
time = 54.56 secondes

Val loss 0.7460037481230782 accuracy 0.9107773900032043 macro_avg {'precision': 0.9154972320665069, 'recall': 0.9146530025292623, 'f1-score': 0.9125179582019601, 'support': 1132} weighted_avg {'precision': 0.917195712252655, 'recall': 0.9107773851590106, 'f1-score': 0.911498241541149, 'support': 1132}
 
----------
Epoch 16/40
time = 1720.72 secondes

Train loss 0.10207240852046491 accuracy 0.9813396334648132 macro_avg {'precision': 0.9808294680562399, 'recall': 0.9810017543479654, 'f1-score': 0.9808770797177828, 'support': 10182} weighted_avg {'precision': 0.9814284369105609, 'recall': 0.9813396189353761, 'f1-score': 0.9813474441408492, 'support': 10182}
 
time = 55.77 secondes

Val loss 0.8083855497349925 accuracy 0.9028268456459045 macro_avg {'precision': 0.9075573983389502, 'recall': 0.9056358141832114, 'f1-score': 0.9037263107376532, 'support': 1132} weighted_avg {'precision': 0.9107805054415361, 'recall': 0.9028268551236749, 'f1-score': 0.9039978751083967, 'support': 1132}
 
----------
Epoch 17/40
time = 1708.23 secondes

Train loss 0.08065592809208359 accuracy 0.9851699471473694 macro_avg {'precision': 0.9845104390610253, 'recall': 0.9844617082552501, 'f1-score': 0.9844684966347057, 'support': 10182} weighted_avg {'precision': 0.9852012731898345, 'recall': 0.98516990768022, 'f1-score': 0.9851687063516796, 'support': 10182}
 
time = 55.79 secondes

Val loss 0.7177609835419735 accuracy 0.9045936465263367 macro_avg {'precision': 0.9090280336256974, 'recall': 0.9033866039569347, 'f1-score': 0.9041678741810157, 'support': 1132} weighted_avg {'precision': 0.9087963713871106, 'recall': 0.9045936395759717, 'f1-score': 0.9046482714108125, 'support': 1132}
 
----------
Epoch 18/40
time = 1573.09 secondes

Train loss 0.07094720301905812 accuracy 0.9866431355476379 macro_avg {'precision': 0.985706924244399, 'recall': 0.9857851007317244, 'f1-score': 0.9857291331903509, 'support': 10182} weighted_avg {'precision': 0.9866748690929084, 'recall': 0.9866430956590061, 'f1-score': 0.9866415412385727, 'support': 10182}
 
time = 40.42 secondes

Val loss 0.7480571825773796 accuracy 0.9001767039299011 macro_avg {'precision': 0.9095796892427991, 'recall': 0.9035556516185765, 'f1-score': 0.9031503597205409, 'support': 1132} weighted_avg {'precision': 0.9108631352001592, 'recall': 0.9001766784452296, 'f1-score': 0.901935404930142, 'support': 1132}
 
----------
Epoch 19/40
time = 1392.44 secondes

Train loss 0.07527019657045257 accuracy 0.9858574271202087 macro_avg {'precision': 0.9855096795105907, 'recall': 0.9853831067865402, 'f1-score': 0.9854259110239392, 'support': 10182} weighted_avg {'precision': 0.9859184008741201, 'recall': 0.9858573954036535, 'f1-score': 0.9858685975766042, 'support': 10182}
 
time = 39.29 secondes

Val loss 0.5616493090357169 accuracy 0.9204947352409363 macro_avg {'precision': 0.9227233908239612, 'recall': 0.9228383580064865, 'f1-score': 0.9218528184361345, 'support': 1132} weighted_avg {'precision': 0.922087071595895, 'recall': 0.9204946996466431, 'f1-score': 0.9203484676913775, 'support': 1132}
 
----------
Epoch 20/40
time = 1398.24 secondes

Train loss 0.050737213073691716 accuracy 0.98978590965271 macro_avg {'precision': 0.9893947826730047, 'recall': 0.9894096697769657, 'f1-score': 0.9893951672839097, 'support': 10182} weighted_avg {'precision': 0.9897874098692602, 'recall': 0.9897858966804164, 'f1-score': 0.989779532781744, 'support': 10182}
 
time = 36.89 secondes

Val loss 0.707198783521652 accuracy 0.9134275913238525 macro_avg {'precision': 0.9176158733113107, 'recall': 0.9173602071911974, 'f1-score': 0.9156736356111528, 'support': 1132} weighted_avg {'precision': 0.9190842371107043, 'recall': 0.9134275618374559, 'f1-score': 0.9143623562395508, 'support': 1132}
 
----------
Epoch 21/40
time = 1400.30 secondes

Train loss 0.07619439555388764 accuracy 0.9879198670387268 macro_avg {'precision': 0.9874735505786983, 'recall': 0.9877774318404597, 'f1-score': 0.987594966061676, 'support': 10182} weighted_avg {'precision': 0.9880058282936296, 'recall': 0.987919858573954, 'f1-score': 0.9879336805724702, 'support': 10182}
 
time = 41.61 secondes

Val loss 0.8041701002954833 accuracy 0.8966431021690369 macro_avg {'precision': 0.9108554328547658, 'recall': 0.9021392233687143, 'f1-score': 0.8996014647149628, 'support': 1132} weighted_avg {'precision': 0.9122529929620926, 'recall': 0.8966431095406361, 'f1-score': 0.8971749955494288, 'support': 1132}
 
----------
Epoch 22/40
time = 1406.93 secondes

Train loss 0.05821075624832874 accuracy 0.9901787638664246 macro_avg {'precision': 0.9901536150193371, 'recall': 0.9901358009665664, 'f1-score': 0.9901362095457719, 'support': 10182} weighted_avg {'precision': 0.9901959820932905, 'recall': 0.9901787468080927, 'f1-score': 0.9901791278646703, 'support': 10182}
 
time = 40.27 secondes

Val loss 0.6160226992520416 accuracy 0.9231448769569397 macro_avg {'precision': 0.9264078171661833, 'recall': 0.9233659403922202, 'f1-score': 0.924062190174249, 'support': 1132} weighted_avg {'precision': 0.9245511426007168, 'recall': 0.9231448763250883, 'f1-score': 0.9230048845392417, 'support': 1132}
 
----------
Epoch 23/40
time = 1403.22 secondes

Train loss 0.05566785504335678 accuracy 0.9899823665618896 macro_avg {'precision': 0.9897064181526825, 'recall': 0.9898317236820711, 'f1-score': 0.9897550764017335, 'support': 10182} weighted_avg {'precision': 0.9900045855355776, 'recall': 0.9899823217442546, 'f1-score': 0.9899798220775783, 'support': 10182}
 
time = 40.65 secondes

Val loss 0.6073500090537955 accuracy 0.9240282773971558 macro_avg {'precision': 0.9293066007668184, 'recall': 0.9261411934642609, 'f1-score': 0.9261450938144101, 'support': 1132} weighted_avg {'precision': 0.9275836709543789, 'recall': 0.9240282685512368, 'f1-score': 0.924196284945097, 'support': 1132}
 
----------
Epoch 24/40
time = 1493.57 secondes

Train loss 0.06600047455838054 accuracy 0.9888038039207458 macro_avg {'precision': 0.9886405739345301, 'recall': 0.9885526311657505, 'f1-score': 0.9885486023878391, 'support': 10182} weighted_avg {'precision': 0.9888919127385037, 'recall': 0.9888037713612257, 'f1-score': 0.9888017526858824, 'support': 10182}
 
time = 39.31 secondes

Val loss 0.6416098288124924 accuracy 0.9222614765167236 macro_avg {'precision': 0.9253814621743901, 'recall': 0.9248932778550193, 'f1-score': 0.9238604895854957, 'support': 1132} weighted_avg {'precision': 0.9254277545786035, 'recall': 0.9222614840989399, 'f1-score': 0.922494327098302, 'support': 1132}
 
----------
Epoch 25/40
time = 1594.67 secondes

Train loss 0.054765893018443916 accuracy 0.9901787638664246 macro_avg {'precision': 0.9902242333967044, 'recall': 0.9900586167070035, 'f1-score': 0.9901269686162502, 'support': 10182} weighted_avg {'precision': 0.9901963392526407, 'recall': 0.9901787468080927, 'f1-score': 0.9901729625989875, 'support': 10182}
 
time = 44.68 secondes

Val loss 0.7675280765288848 accuracy 0.9001767039299011 macro_avg {'precision': 0.9139748291135751, 'recall': 0.903779273710267, 'f1-score': 0.9045480238339193, 'support': 1132} weighted_avg {'precision': 0.9124109988086011, 'recall': 0.9001766784452296, 'f1-score': 0.9014116914249154, 'support': 1132}
 
----------
Epoch 26/40
time = 1716.63 secondes

Train loss 0.0612130660056195 accuracy 0.9893930554389954 macro_avg {'precision': 0.9894041079420791, 'recall': 0.9891852877188493, 'f1-score': 0.9892695708554321, 'support': 10182} weighted_avg {'precision': 0.9894879545639466, 'recall': 0.9893930465527401, 'f1-score': 0.9894151636256698, 'support': 10182}
 
time = 55.07 secondes

Val loss 0.6358479074949339 accuracy 0.916077733039856 macro_avg {'precision': 0.9197435840605216, 'recall': 0.9207693510634435, 'f1-score': 0.9184080808675654, 'support': 1132} weighted_avg {'precision': 0.920837390847071, 'recall': 0.916077738515901, 'f1-score': 0.9165556712776163, 'support': 1132}
 
----------
Epoch 27/40
time = 1768.63 secondes

Train loss 0.047665141433916654 accuracy 0.9911609292030334 macro_avg {'precision': 0.9909279733338783, 'recall': 0.9908696431287929, 'f1-score': 0.9908812573614535, 'support': 10182} weighted_avg {'precision': 0.9912106426848722, 'recall': 0.9911608721272834, 'f1-score': 0.9911675366199921, 'support': 10182}
 
time = 54.06 secondes

Val loss 0.5772119487015183 accuracy 0.9213780760765076 macro_avg {'precision': 0.9248846062607912, 'recall': 0.9238012391271818, 'f1-score': 0.9229678784351367, 'support': 1132} weighted_avg {'precision': 0.9245769269633028, 'recall': 0.9213780918727915, 'f1-score': 0.9215337459960716, 'support': 1132}
 
----------
Epoch 28/40
time = 1774.87 secondes

Train loss 0.04000872611076984 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934710162025127, 'recall': 0.9935303399184875, 'f1-score': 0.993495722976985, 'support': 10182} weighted_avg {'precision': 0.993528389825299, 'recall': 0.9935179728933412, 'f1-score': 0.9935180872340954, 'support': 10182}
 
time = 58.93 secondes

Val loss 0.6434107668229303 accuracy 0.9213780760765076 macro_avg {'precision': 0.9285221864362538, 'recall': 0.9221251731401482, 'f1-score': 0.9229292862745764, 'support': 1132} weighted_avg {'precision': 0.9270456641936767, 'recall': 0.9213780918727915, 'f1-score': 0.9219181373356892, 'support': 1132}
 
----------
Epoch 29/40
time = 1784.27 secondes

Train loss 0.027891033626350165 accuracy 0.9947947859764099 macro_avg {'precision': 0.9948107115201579, 'recall': 0.99452790784131, 'f1-score': 0.9946616834767976, 'support': 10182} weighted_avg {'precision': 0.9948008416888167, 'recall': 0.9947947358082891, 'f1-score': 0.994791222324211, 'support': 10182}
 
time = 51.84 secondes

Val loss 0.6736052075085726 accuracy 0.9249116778373718 macro_avg {'precision': 0.9276408805753338, 'recall': 0.9272865738120266, 'f1-score': 0.9256489019163959, 'support': 1132} weighted_avg {'precision': 0.9289071113734977, 'recall': 0.9249116607773852, 'f1-score': 0.9251318023205112, 'support': 1132}
 
----------
Epoch 30/40
time = 1797.70 secondes

Train loss 0.03540460405201884 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934825190867222, 'recall': 0.9934803634109043, 'f1-score': 0.9934754353669997, 'support': 10182} weighted_avg {'precision': 0.9935292579790387, 'recall': 0.9935179728933412, 'f1-score': 0.9935174840555993, 'support': 10182}
 
time = 56.42 secondes

Val loss 0.6631120628119622 accuracy 0.9151943325996399 macro_avg {'precision': 0.9217475868454053, 'recall': 0.9181371932996631, 'f1-score': 0.9177973288272581, 'support': 1132} weighted_avg {'precision': 0.9218695804542374, 'recall': 0.9151943462897526, 'f1-score': 0.9161886134957098, 'support': 1132}
 
----------
Epoch 31/40
time = 1787.69 secondes

Train loss 0.027699407553542527 accuracy 0.9951876401901245 macro_avg {'precision': 0.9953175193278231, 'recall': 0.9953233222637898, 'f1-score': 0.9953148243020011, 'support': 10182} weighted_avg {'precision': 0.9951913026635637, 'recall': 0.9951875859359655, 'f1-score': 0.9951836964188637, 'support': 10182}
 
time = 57.50 secondes

Val loss 0.6066643394000827 accuracy 0.926678478717804 macro_avg {'precision': 0.9283366114445327, 'recall': 0.9278526047985169, 'f1-score': 0.9270327013161248, 'support': 1132} weighted_avg {'precision': 0.9290727547846553, 'recall': 0.926678445229682, 'f1-score': 0.9267484484099504, 'support': 1132}
 
----------
Epoch 32/40
time = 1686.51 secondes

Train loss 0.02783537795889406 accuracy 0.9944019317626953 macro_avg {'precision': 0.9940104163164104, 'recall': 0.9942120610085512, 'f1-score': 0.9940949395208314, 'support': 10182} weighted_avg {'precision': 0.9944371608898261, 'recall': 0.9944018856806128, 'f1-score': 0.9944056988087661, 'support': 10182}
 
time = 44.12 secondes

Val loss 0.6685229087647393 accuracy 0.9213780760765076 macro_avg {'precision': 0.927276927279531, 'recall': 0.9215974721167557, 'f1-score': 0.9221967094152272, 'support': 1132} weighted_avg {'precision': 0.9269729451792571, 'recall': 0.9213780918727915, 'f1-score': 0.9219293548202676, 'support': 1132}
 
----------
Epoch 33/40
time = 1568.07 secondes

Train loss 0.0193779758511101 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960206854994235, 'recall': 0.9960134621554729, 'f1-score': 0.9960096727623288, 'support': 10182} weighted_avg {'precision': 0.9961867513951065, 'recall': 0.9961697112551562, 'f1-score': 0.9961710662755333, 'support': 10182}
 
time = 43.02 secondes

Val loss 0.7528022624264593 accuracy 0.9081271886825562 macro_avg {'precision': 0.9172289023894207, 'recall': 0.9119414776649599, 'f1-score': 0.9114802563933615, 'support': 1132} weighted_avg {'precision': 0.9183835003999731, 'recall': 0.9081272084805654, 'f1-score': 0.9101379177502416, 'support': 1132}
 
----------
Epoch 34/40
time = 1388.12 secondes

Train loss 0.020970788584096366 accuracy 0.9958751201629639 macro_avg {'precision': 0.9959735911746399, 'recall': 0.99590866703295, 'f1-score': 0.9959329915809205, 'support': 10182} weighted_avg {'precision': 0.9958971193199402, 'recall': 0.995875073659399, 'f1-score': 0.9958777281648554, 'support': 10182}
 
time = 39.89 secondes

Val loss 0.7249698054715544 accuracy 0.9151943325996399 macro_avg {'precision': 0.9251122578834184, 'recall': 0.9192693789728986, 'f1-score': 0.9194348300569588, 'support': 1132} weighted_avg {'precision': 0.924341374560887, 'recall': 0.9151943462897526, 'f1-score': 0.9166072600600726, 'support': 1132}
 
----------
Epoch 35/40
time = 1292.15 secondes

Train loss 0.021882109113253785 accuracy 0.9967589974403381 macro_avg {'precision': 0.9968172693741945, 'recall': 0.9967784472335248, 'f1-score': 0.9967952457385026, 'support': 10182} weighted_avg {'precision': 0.9967644162565928, 'recall': 0.9967589864466706, 'f1-score': 0.9967591094403794, 'support': 10182}
 
time = 40.31 secondes

Val loss 0.6772329003110634 accuracy 0.9231448769569397 macro_avg {'precision': 0.9277668569916722, 'recall': 0.9264500882794389, 'f1-score': 0.9255432065941538, 'support': 1132} weighted_avg {'precision': 0.9267689959349648, 'recall': 0.9231448763250883, 'f1-score': 0.9233166084881061, 'support': 1132}
 
----------
Epoch 36/40
time = 1286.28 secondes

Train loss 0.016210656367525084 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973607996716127, 'recall': 0.997369023157287, 'f1-score': 0.9973607777849685, 'support': 10182} weighted_avg {'precision': 0.997256409136161, 'recall': 0.9972500491062659, 'f1-score': 0.9972489095572997, 'support': 10182}
 
time = 34.82 secondes

Val loss 0.69942385952245 accuracy 0.9178445339202881 macro_avg {'precision': 0.9235077275866784, 'recall': 0.9219908764226206, 'f1-score': 0.9204444120581009, 'support': 1132} weighted_avg {'precision': 0.9243818115347605, 'recall': 0.9178445229681979, 'f1-score': 0.9186517573640954, 'support': 1132}
 
----------
Epoch 37/40
time = 1285.74 secondes

Train loss 0.010134344625619853 accuracy 0.9976429343223572 macro_avg {'precision': 0.997608285484645, 'recall': 0.9976545816155087, 'f1-score': 0.997629594236406, 'support': 10182} weighted_avg {'precision': 0.9976462083290575, 'recall': 0.9976428992339422, 'f1-score': 0.9976426815293276, 'support': 10182}
 
time = 37.09 secondes

Val loss 0.6969437940724034 accuracy 0.9204947352409363 macro_avg {'precision': 0.9232007558825577, 'recall': 0.9227496431656865, 'f1-score': 0.9210965724409835, 'support': 1132} weighted_avg {'precision': 0.9256498810130085, 'recall': 0.9204946996466431, 'f1-score': 0.9210594439290632, 'support': 1132}
 
----------
Epoch 38/40
time = 1281.11 secondes

Train loss 0.00419865687570341 accuracy 0.9987232685089111 macro_avg {'precision': 0.9986552743652094, 'recall': 0.9987466391568234, 'f1-score': 0.9986998147815562, 'support': 10182} weighted_avg {'precision': 0.9987260428821306, 'recall': 0.9987232370850521, 'f1-score': 0.9987236130339551, 'support': 10182}
 
time = 38.55 secondes

Val loss 0.6921614385338332 accuracy 0.9257950782775879 macro_avg {'precision': 0.9331501157774132, 'recall': 0.9275327259908825, 'f1-score': 0.9277965072836782, 'support': 1132} weighted_avg {'precision': 0.9334226397011728, 'recall': 0.9257950530035336, 'f1-score': 0.9270477298179949, 'support': 1132}
 
----------
Epoch 39/40
time = 1283.79 secondes

Train loss 0.004758495891687037 accuracy 0.9986250400543213 macro_avg {'precision': 0.9985557083965922, 'recall': 0.9986313093803746, 'f1-score': 0.9985926201502886, 'support': 10182} weighted_avg {'precision': 0.9986271315824751, 'recall': 0.998625024553133, 'f1-score': 0.9986252079663189, 'support': 10182}
 
time = 36.16 secondes

Val loss 0.6723217470260121 accuracy 0.9240282773971558 macro_avg {'precision': 0.9317871502784835, 'recall': 0.9262912287730616, 'f1-score': 0.9263957258777212, 'support': 1132} weighted_avg {'precision': 0.931364771695833, 'recall': 0.9240282685512368, 'f1-score': 0.925004358555096, 'support': 1132}
 
----------
Epoch 40/40
time = 1291.84 secondes

Train loss 0.0020646654560068224 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993601772037453, 'recall': 0.999394593675839, 'f1-score': 0.9993764985275027, 'support': 10182} weighted_avg {'precision': 0.9994123508008663, 'recall': 0.9994107248084856, 'f1-score': 0.9994107197181057, 'support': 10182}
 
time = 35.49 secondes

Val loss 0.6236739793879883 accuracy 0.9319788217544556 macro_avg {'precision': 0.9398570938832664, 'recall': 0.9341695919040406, 'f1-score': 0.9351399730668428, 'support': 1132} weighted_avg {'precision': 0.9378455916100297, 'recall': 0.9319787985865724, 'f1-score': 0.9329664528297767, 'support': 1132}
 
----------
best_accuracy 0.9319788217544556 best_epoch 40 macro_avg {'precision': 0.9398570938832664, 'recall': 0.9341695919040406, 'f1-score': 0.9351399730668428, 'support': 1132} weighted_avg {'precision': 0.9378455916100297, 'recall': 0.9319787985865724, 'f1-score': 0.9329664528297767, 'support': 1132}

average train time 1541.4539187908172

average val time 47.97027012705803
 
time = 227.59 secondes

test_accuracy 0.8673658967018127 macro_avg {'precision': 0.8650566408359784, 'recall': 0.861064970065892, 'f1-score': 0.8614629511008991, 'support': 7532} weighted_avg {'precision': 0.8711740006301247, 'recall': 0.8673659054699947, 'f1-score': 0.867828831005756, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_512_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.13 GiB (GPU 0; 79.21 GiB total capacity; 59.87 GiB already allocated; 1.06 GiB free; 62.41 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_256_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.46 GiB (GPU 0; 79.21 GiB total capacity; 60.37 GiB already allocated; 1.12 GiB free; 62.35 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_4096_512_5
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 79.21 GiB total capacity; 60.11 GiB already allocated; 194.62 MiB free; 63.28 GiB reserved in total by PyTorch)
