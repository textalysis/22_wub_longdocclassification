[nltk_data] Downloading package punkt to /vol/fob-
[nltk_data]     vol3/nebenf20/wubingti/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/lib64/python3.6/site-packages/h5py/__init__.py:39: UserWarning: h5py is running against HDF5 1.10.8 when it was built against 1.10.7, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
/vol/fob-vol3/nebenf20/wubingti/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
##########
Hyperpartisan_Bigbird_1024_64_4
----------
Epoch 1/40
time = 68.12 secondes

Train loss 0.6153191075180516 accuracy 0.6647287011146545 macro_avg {'precision': 0.6513594164456233, 'recall': 0.5593599141784373, 'f1-score': 0.5289958686625125, 'support': 516} weighted_avg {'precision': 0.655967270166348, 'recall': 0.6647286821705426, 'f1-score': 0.5985773109662681, 'support': 516}
 
time = 1.37 secondes

Val loss 0.5174446180462837 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 2/40
time = 55.32 secondes

Train loss 0.41157210821455176 accuracy 0.819767415523529 macro_avg {'precision': 0.8057675857077055, 'recall': 0.8021146563073972, 'f1-score': 0.8038479932310635, 'support': 516} weighted_avg {'precision': 0.8188463986925204, 'recall': 0.8197674418604651, 'f1-score': 0.8192259640159276, 'support': 516}
 
time = 1.45 secondes

Val loss 0.4606687054038048 accuracy 0.78125 macro_avg {'precision': 0.8125, 'recall': 0.742914979757085, 'f1-score': 0.751937984496124, 'support': 64} weighted_avg {'precision': 0.80078125, 'recall': 0.78125, 'f1-score': 0.7679263565891474, 'support': 64}
 
----------
Epoch 3/40
time = 57.27 secondes

Train loss 0.2572311648365223 accuracy 0.9011628031730652 macro_avg {'precision': 0.8927413077322263, 'recall': 0.8936414024023536, 'f1-score': 0.8931872146118721, 'support': 516} weighted_avg {'precision': 0.9012830975971807, 'recall': 0.9011627906976745, 'f1-score': 0.9012193550670773, 'support': 516}
 
time = 1.44 secondes

Val loss 0.49736127257347107 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 4/40
time = 56.23 secondes

Train loss 0.19871302677149122 accuracy 0.9282945990562439 macro_avg {'precision': 0.9289675337769712, 'recall': 0.9149179981470345, 'f1-score': 0.9211826727380064, 'support': 516} weighted_avg {'precision': 0.9283987222355093, 'recall': 0.9282945736434108, 'f1-score': 0.9276980916319898, 'support': 516}
 
time = 1.53 secondes

Val loss 0.48872246593236923 accuracy 0.859375 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}
 
----------
Epoch 5/40
time = 58.11 secondes

Train loss 0.1334665554265181 accuracy 0.9554263353347778 macro_avg {'precision': 0.9554563492063493, 'recall': 0.947734993417096, 'f1-score': 0.9513716170535329, 'support': 516} weighted_avg {'precision': 0.9554290482342808, 'recall': 0.9554263565891473, 'f1-score': 0.9552358654700244, 'support': 516}
 
time = 1.50 secondes

Val loss 0.7548781484365463 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 6/40
time = 57.61 secondes

Train loss 0.23320880540731279 accuracy 0.9205426573753357 macro_avg {'precision': 0.9241584564860428, 'recall': 0.903068771028721, 'f1-score': 0.9119728712006159, 'support': 516} weighted_avg {'precision': 0.9213059756113086, 'recall': 0.9205426356589147, 'f1-score': 0.9195312969961341, 'support': 516}
 
time = 1.56 secondes

Val loss 0.5518350973725319 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 7/40
time = 57.96 secondes

Train loss 0.2628673800394278 accuracy 0.9282945990562439 macro_avg {'precision': 0.9189536878216124, 'recall': 0.9287664775774913, 'f1-score': 0.9233545434472792, 'support': 516} weighted_avg {'precision': 0.9300070693774072, 'recall': 0.9282945736434108, 'f1-score': 0.9287093853392693, 'support': 516}
 
time = 1.53 secondes

Val loss 1.1816385835409164 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 8/40
time = 58.93 secondes

Train loss 0.2524587168485265 accuracy 0.9341084957122803 macro_avg {'precision': 0.9348470883954755, 'recall': 0.9217853485688279, 'f1-score': 0.9276655397047908, 'support': 516} weighted_avg {'precision': 0.9342153070735217, 'recall': 0.9341085271317829, 'f1-score': 0.9336064761634458, 'support': 516}
 
time = 1.59 secondes

Val loss 1.4966325610876083 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 9/40
time = 57.95 secondes

Train loss 0.11853025468404997 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.48 secondes

Val loss 0.8987989872694016 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 10/40
time = 58.07 secondes

Train loss 0.1455599951141542 accuracy 0.961240291595459 macro_avg {'precision': 0.9529495380241649, 'recall': 0.9661427433642703, 'f1-score': 0.9586988538131523, 'support': 516} weighted_avg {'precision': 0.9632766400555363, 'recall': 0.9612403100775194, 'f1-score': 0.9615182818564345, 'support': 516}
 
time = 1.57 secondes

Val loss 1.8139927685260773 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 11/40
time = 57.52 secondes

Train loss 0.16063062787394633 accuracy 0.9534883499145508 macro_avg {'precision': 0.9453101469492573, 'recall': 0.956601596151033, 'f1-score': 0.9503360657052567, 'support': 516} weighted_avg {'precision': 0.9551517399188739, 'recall': 0.9534883720930233, 'f1-score': 0.9537793542211248, 'support': 516}
 
time = 1.56 secondes

Val loss 0.94292351603508 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 12/40
time = 57.96 secondes

Train loss 0.07956342408821608 accuracy 0.9864341020584106 macro_avg {'precision': 0.9847885313959522, 'recall': 0.9858995822700454, 'f1-score': 0.9853394216133943, 'support': 516} weighted_avg {'precision': 0.9864576167718629, 'recall': 0.9864341085271318, 'f1-score': 0.9864418722641087, 'support': 516}
 
time = 1.49 secondes

Val loss 0.9539240002632141 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 13/40
time = 58.60 secondes

Train loss 0.14827841556997914 accuracy 0.9728682041168213 macro_avg {'precision': 0.9664083509698773, 'recall': 0.9764153243502429, 'f1-score': 0.9709683641975309, 'support': 516} weighted_avg {'precision': 0.9739272114943269, 'recall': 0.9728682170542635, 'f1-score': 0.9730121453009857, 'support': 516}
 
time = 1.42 secondes

Val loss 1.1003360152244568 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 14/40
time = 59.25 secondes

Train loss 0.5446962917816233 accuracy 0.9069767594337463 macro_avg {'precision': 0.920650353805434, 'recall': 0.8797360336784616, 'f1-score': 0.8947296837810269, 'support': 516} weighted_avg {'precision': 0.9114043892056577, 'recall': 0.9069767441860465, 'f1-score': 0.9046108347896223, 'support': 516}
 
time = 1.57 secondes

Val loss 1.6026472672820091 accuracy 0.6875 macro_avg {'precision': 0.7402597402597402, 'recall': 0.7246963562753037, 'f1-score': 0.6862745098039216, 'support': 64} weighted_avg {'precision': 0.7719155844155844, 'recall': 0.6875, 'f1-score': 0.6825980392156863, 'support': 64}
 
----------
Epoch 15/40
time = 57.45 secondes

Train loss 0.434218908577212 accuracy 0.9108527302742004 macro_avg {'precision': 0.9028687927770497, 'recall': 0.9047023064544967, 'f1-score': 0.9037688116242866, 'support': 516} weighted_avg {'precision': 0.9110841311609394, 'recall': 0.9108527131782945, 'f1-score': 0.9109539117719233, 'support': 516}
 
time = 1.51 secondes

Val loss 0.885037012398243 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 16/40
time = 58.15 secondes

Train loss 0.17614273403799444 accuracy 0.9593023061752319 macro_avg {'precision': 0.9511708860759494, 'recall': 0.9634689465728264, 'f1-score': 0.9565891472868218, 'support': 516} weighted_avg {'precision': 0.9611248896084781, 'recall': 0.9593023255813954, 'f1-score': 0.9595757466498408, 'support': 516}
 
time = 1.57 secondes

Val loss 1.1502974927425385 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 17/40
time = 58.25 secondes

Train loss 0.11607593716877146 accuracy 0.9767441749572754 macro_avg {'precision': 0.9770590262393541, 'recall': 0.9725305983128261, 'f1-score': 0.9747203396750224, 'support': 516} weighted_avg {'precision': 0.9767609775234631, 'recall': 0.9767441860465116, 'f1-score': 0.9766887382007174, 'support': 516}
 
time = 1.43 secondes

Val loss 1.78080315887928 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 18/40
time = 58.10 secondes

Train loss 0.1036966544819403 accuracy 0.9786821603775024 macro_avg {'precision': 0.9754439780432677, 'recall': 0.9786665149618842, 'f1-score': 0.977014194018669, 'support': 516} weighted_avg {'precision': 0.9788250319764312, 'recall': 0.9786821705426356, 'f1-score': 0.9787181700359587, 'support': 516}
 
time = 1.48 secondes

Val loss 1.043642833828926 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 19/40
time = 59.61 secondes

Train loss 0.04387720590845371 accuracy 0.9922480583190918 macro_avg {'precision': 0.9916128927393008, 'recall': 0.9916128927393008, 'f1-score': 0.9916128927393008, 'support': 516} weighted_avg {'precision': 0.9922480620155039, 'recall': 0.9922480620155039, 'f1-score': 0.9922480620155039, 'support': 516}
 
time = 1.46 secondes

Val loss 1.057699915021658 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 20/40
time = 58.65 secondes

Train loss 0.037541744390954125 accuracy 0.9922480583190918 macro_avg {'precision': 0.9905344400757244, 'recall': 0.9927669326918388, 'f1-score': 0.9916320705760249, 'support': 516} weighted_avg {'precision': 0.9922977322166568, 'recall': 0.9922480620155039, 'f1-score': 0.9922568618932107, 'support': 516}
 
time = 1.51 secondes

Val loss 1.0658883154392242 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 21/40
time = 57.82 secondes

Train loss 0.022469222611768848 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.49 secondes

Val loss 1.4138997495174408 accuracy 0.8125 macro_avg {'precision': 0.8357487922705313, 'recall': 0.7813765182186234, 'f1-score': 0.7922077922077922, 'support': 64} weighted_avg {'precision': 0.8257850241545894, 'recall': 0.8125, 'f1-score': 0.8043831168831169, 'support': 64}
 
----------
Epoch 22/40
time = 58.14 secondes

Train loss 0.1305960425368429 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 1.45 secondes

Val loss 1.0970347225666046 accuracy 0.84375 macro_avg {'precision': 0.8509803921568628, 'recall': 0.8623481781376519, 'f1-score': 0.8431372549019608, 'support': 64} weighted_avg {'precision': 0.872671568627451, 'recall': 0.84375, 'f1-score': 0.8449754901960784, 'support': 64}
 
----------
Epoch 23/40
time = 58.16 secondes

Train loss 0.13053028398964228 accuracy 0.9709302186965942 macro_avg {'precision': 0.9781976744186047, 'recall': 0.9598930481283423, 'f1-score': 0.9679645043396921, 'support': 516} weighted_avg {'precision': 0.9721978096268253, 'recall': 0.9709302325581395, 'f1-score': 0.9706468827283516, 'support': 516}
 
time = 1.43 secondes

Val loss 1.3298837095499039 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 24/40
time = 58.85 secondes

Train loss 0.054781283178299695 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4081860333681107 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 25/40
time = 58.53 secondes

Train loss 0.05968497074685398 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 1.52 secondes

Val loss 1.5865978300571442 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 26/40
time = 57.49 secondes

Train loss 0.025103735711044548 accuracy 0.9941860437393188 macro_avg {'precision': 0.9931564608199274, 'recall': 0.9942866895307446, 'f1-score': 0.9937168949771689, 'support': 516} weighted_avg {'precision': 0.9942007548786522, 'recall': 0.9941860465116279, 'f1-score': 0.9941893738274752, 'support': 516}
 
time = 1.45 secondes

Val loss 1.4306539446115494 accuracy 0.78125 macro_avg {'precision': 0.7976190476190477, 'recall': 0.8036437246963564, 'f1-score': 0.7810361681329423, 'support': 64} weighted_avg {'precision': 0.8221726190476191, 'recall': 0.78125, 'f1-score': 0.7823191593352883, 'support': 64}
 
----------
Epoch 27/40
time = 57.73 secondes

Train loss 0.16369178507364157 accuracy 0.9689922332763672 macro_avg {'precision': 0.966451570957203, 'recall': 0.966451570957203, 'f1-score': 0.966451570957203, 'support': 516} weighted_avg {'precision': 0.9689922480620154, 'recall': 0.9689922480620154, 'f1-score': 0.9689922480620154, 'support': 516}
 
time = 1.50 secondes

Val loss 1.851192146539688 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 28/40
time = 59.18 secondes

Train loss 0.005236345648881979 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5091046690940857 accuracy 0.796875 macro_avg {'precision': 0.7942326490713587, 'recall': 0.8046558704453441, 'f1-score': 0.7944156165060539, 'support': 64} weighted_avg {'precision': 0.8100867546432062, 'recall': 0.796875, 'f1-score': 0.7986317024956758, 'support': 64}
 
----------
Epoch 29/40
time = 58.40 secondes

Train loss 0.1426365165534662 accuracy 0.9767441749572754 macro_avg {'precision': 0.9809509524523774, 'recall': 0.9690684784552119, 'f1-score': 0.9745344475883398, 'support': 516} weighted_avg {'precision': 0.9772635399237789, 'recall': 0.9767441860465116, 'f1-score': 0.9765988085163687, 'support': 516}
 
time = 1.49 secondes

Val loss 2.00705686211586 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 58.43 secondes

Train loss 0.0003581510629208589 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.907425582408905 accuracy 0.734375 macro_avg {'precision': 0.7275862068965517, 'recall': 0.7338056680161943, 'f1-score': 0.7290161892901619, 'support': 64} weighted_avg {'precision': 0.7411637931034483, 'recall': 0.734375, 'f1-score': 0.7361612702366127, 'support': 64}
 
----------
Epoch 31/40
time = 58.29 secondes

Train loss 0.13050016070580264 accuracy 0.9728682041168213 macro_avg {'precision': 0.9657593963508394, 'recall': 0.9775693643027811, 'f1-score': 0.9710293716613998, 'support': 516} weighted_avg {'precision': 0.9743140788922482, 'recall': 0.9728682170542635, 'f1-score': 0.9730379566289895, 'support': 516}
 
time = 1.52 secondes

Val loss 1.369198501110077 accuracy 0.84375 macro_avg {'precision': 0.8590909090909091, 'recall': 0.819838056680162, 'f1-score': 0.8303287380699893, 'support': 64} weighted_avg {'precision': 0.8514204545454547, 'recall': 0.84375, 'f1-score': 0.8392762460233298, 'support': 64}
 
----------
Epoch 32/40
time = 57.92 secondes

Train loss 0.02882400349754431 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.55 secondes

Val loss 1.362718105316162 accuracy 0.796875 macro_avg {'precision': 0.8000977517106549, 'recall': 0.8107287449392713, 'f1-score': 0.7956276099238516, 'support': 64} weighted_avg {'precision': 0.8194342619745845, 'recall': 0.796875, 'f1-score': 0.7986213461066076, 'support': 64}
 
----------
Epoch 33/40
time = 57.82 secondes

Train loss 0.05366902462485472 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.43 secondes

Val loss 1.574650526046753 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 34/40
time = 58.83 secondes

Train loss 0.11593728005810232 accuracy 0.9728682041168213 macro_avg {'precision': 0.9795918367346939, 'recall': 0.9625668449197862, 'f1-score': 0.9701388888888889, 'support': 516} weighted_avg {'precision': 0.9739756367663344, 'recall': 0.9728682170542635, 'f1-score': 0.9726232773471145, 'support': 516}
 
time = 1.55 secondes

Val loss 1.2834101170301437 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 35/40
time = 58.55 secondes

Train loss 0.0005483728027408661 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.46 secondes

Val loss 1.4318679571151733 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 36/40
time = 57.69 secondes

Train loss 0.014917325891226275 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.55 secondes

Val loss 1.4637317061424255 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 58.11 secondes

Train loss 0.00034030022321861577 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.44 secondes

Val loss 1.5544102787971497 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 38/40
time = 59.14 secondes

Train loss 0.012974465915414674 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 1.56 secondes

Val loss 1.5192304253578186 accuracy 0.828125 macro_avg {'precision': 0.8877551020408163, 'recall': 0.7884615384615384, 'f1-score': 0.8026352677319877, 'support': 64} weighted_avg {'precision': 0.8667091836734694, 'recall': 0.828125, 'f1-score': 0.8159342584805158, 'support': 64}
 
----------
Epoch 39/40
time = 56.62 secondes

Train loss 0.0002518649698961808 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.72 secondes

Val loss 1.492131769657135 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 54.25 secondes

Train loss 0.0002192168105852254 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.47 secondes

Val loss 1.4562963843345642 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 4 macro_avg {'precision': 0.8847953216374269, 'recall': 0.832995951417004, 'f1-score': 0.8457831325301204, 'support': 64} weighted_avg {'precision': 0.873062865497076, 'recall': 0.859375, 'f1-score': 0.8543674698795181, 'support': 64}

average train time 58.2268084526062

average val time 1.498611730337143
 
time = 1.60 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9187370600414079, 'recall': 0.8942495126705653, 'f1-score': 0.9025000000000001, 'support': 65} weighted_avg {'precision': 0.9123427297340341, 'recall': 0.9076923076923077, 'f1-score': 0.9063076923076923, 'support': 65}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 39.31 GiB already allocated; 38.62 MiB free; 39.45 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 38.57 GiB already allocated; 76.62 MiB free; 39.42 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.24 GiB already allocated; 504.62 MiB free; 39.00 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 79.21 GiB total capacity; 36.10 GiB already allocated; 626.62 MiB free; 38.88 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 38.48 GiB already allocated; 590.62 MiB free; 38.91 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_256_4
----------
Epoch 1/40
time = 42.50 secondes

Train loss 0.6502475828835459 accuracy 0.6182170510292053 macro_avg {'precision': 0.5408768497003791, 'recall': 0.5217317100921607, 'f1-score': 0.49484920315458353, 'support': 516} weighted_avg {'precision': 0.5707200808090002, 'recall': 0.6182170542635659, 'f1-score': 0.5635481633799777, 'support': 516}
 
time = 2.37 secondes

Val loss 0.6215917989611626 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 37.77 secondes

Train loss 0.509406199057897 accuracy 0.7655038833618164 macro_avg {'precision': 0.7535542391706775, 'recall': 0.7226321863368171, 'f1-score': 0.7317661008648133, 'support': 516} weighted_avg {'precision': 0.7611294553553235, 'recall': 0.7655038759689923, 'f1-score': 0.7579451394702418, 'support': 516}
 
time = 1.99 secondes

Val loss 0.44741108268499374 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 3/40
time = 39.79 secondes

Train loss 0.42789786783131684 accuracy 0.8081395030021667 macro_avg {'precision': 0.7919287211740043, 'recall': 0.7987663150366529, 'f1-score': 0.7949216162508279, 'support': 516} weighted_avg {'precision': 0.811111517397169, 'recall': 0.8081395348837209, 'f1-score': 0.809249436448315, 'support': 516}
 
time = 1.69 secondes

Val loss 0.7124811410903931 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 4/40
time = 40.92 secondes

Train loss 0.3097408725456758 accuracy 0.8759689927101135 macro_avg {'precision': 0.8676506967922817, 'recall': 0.8623441639711977, 'f1-score': 0.8648507071765322, 'support': 516} weighted_avg {'precision': 0.8753208133813778, 'recall': 0.875968992248062, 'f1-score': 0.8755182509613785, 'support': 516}
 
time = 2.12 secondes

Val loss 0.6435048878192902 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 5/40
time = 38.93 secondes

Train loss 0.2929804043167017 accuracy 0.8992248177528381 macro_avg {'precision': 0.8992718653547738, 'recall': 0.8805812460380671, 'f1-score': 0.888504753673293, 'support': 516} weighted_avg {'precision': 0.8992343237831012, 'recall': 0.8992248062015504, 'f1-score': 0.8980188002921213, 'support': 516}
 
time = 2.05 secondes

Val loss 0.47357431799173355 accuracy 0.78125 macro_avg {'precision': 0.7792207792207793, 'recall': 0.7611336032388665, 'f1-score': 0.7666666666666666, 'support': 64} weighted_avg {'precision': 0.7804383116883117, 'recall': 0.78125, 'f1-score': 0.7776041666666667, 'support': 64}
 
----------
Epoch 6/40
time = 39.33 secondes

Train loss 0.25419013525331113 accuracy 0.9205426573753357 macro_avg {'precision': 0.9117468143689569, 'recall': 0.9180712904117159, 'f1-score': 0.9147042103608016, 'support': 516} weighted_avg {'precision': 0.9215046786125038, 'recall': 0.9205426356589147, 'f1-score': 0.9208453688225204, 'support': 516}
 
time = 1.87 secondes

Val loss 0.6549891345202923 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 7/40
time = 40.48 secondes

Train loss 0.1737329674052131 accuracy 0.9399224519729614 macro_avg {'precision': 0.9354349951124145, 'recall': 0.9344228987533117, 'f1-score': 0.9349245546302587, 'support': 516} weighted_avg {'precision': 0.9398601544325476, 'recall': 0.939922480620155, 'f1-score': 0.9398875300887571, 'support': 516}
 
time = 1.93 secondes

Val loss 0.41872819140553474 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 8/40
time = 39.11 secondes

Train loss 0.16758951770536828 accuracy 0.9496123790740967 macro_avg {'precision': 0.9430693466369368, 'recall': 0.9489459226630691, 'f1-score': 0.9458508233774621, 'support': 516} weighted_avg {'precision': 0.950216377543591, 'recall': 0.9496124031007752, 'f1-score': 0.9497783551473921, 'support': 516}
 
time = 1.53 secondes

Val loss 1.8777442574501038 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 9/40
time = 38.00 secondes

Train loss 0.2548922983661407 accuracy 0.9437984228134155 macro_avg {'precision': 0.9438036034838109, 'recall': 0.9340002925735091, 'f1-score': 0.9385348421679571, 'support': 516} weighted_avg {'precision': 0.9437990294229366, 'recall': 0.9437984496124031, 'f1-score': 0.9434847246653831, 'support': 516}
 
time = 1.88 secondes

Val loss 0.842892125248909 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
Epoch 10/40
time = 43.55 secondes

Train loss 0.1294738863608941 accuracy 0.9670542478561401 macro_avg {'precision': 0.9605867346938776, 'recall': 0.9695479739284496, 'f1-score': 0.964709716092643, 'support': 516} weighted_avg {'precision': 0.9679930984021515, 'recall': 0.9670542635658915, 'f1-score': 0.9672129171543067, 'support': 516}
 
time = 1.67 secondes

Val loss 1.2877298295497894 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 11/40
time = 38.03 secondes

Train loss 0.37414150096998183 accuracy 0.9341084957122803 macro_avg {'precision': 0.9510678223572513, 'recall': 0.9102449490434472, 'f1-score': 0.9256547165013984, 'support': 516} weighted_avg {'precision': 0.9393774343862973, 'recall': 0.9341085271317829, 'f1-score': 0.9325538033376891, 'support': 516}
 
time = 1.91 secondes

Val loss 1.1649150848388672 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 12/40
time = 40.47 secondes

Train loss 0.14792993520280684 accuracy 0.9670542478561401 macro_avg {'precision': 0.9648582600195503, 'recall': 0.9637777741657592, 'f1-score': 0.9643134654423999, 'support': 516} weighted_avg {'precision': 0.9670237635166368, 'recall': 0.9670542635658915, 'f1-score': 0.9670350971454476, 'support': 516}
 
time = 1.65 secondes

Val loss 1.3746942579746246 accuracy 0.796875 macro_avg {'precision': 0.8725490196078431, 'recall': 0.75, 'f1-score': 0.7602996254681648, 'support': 64} weighted_avg {'precision': 0.8486519607843137, 'recall': 0.796875, 'f1-score': 0.7778558052434457, 'support': 64}
 
----------
Epoch 13/40
time = 39.73 secondes

Train loss 0.19222142119454502 accuracy 0.9496123790740967 macro_avg {'precision': 0.9580666746735755, 'recall': 0.9339434032800741, 'f1-score': 0.9441027948602569, 'support': 516} weighted_avg {'precision': 0.9514704847651269, 'recall': 0.9496124031007752, 'f1-score': 0.948932204552563, 'support': 516}
 
time = 2.05 secondes

Val loss 2.012902110815048 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 14/40
time = 39.40 secondes

Train loss 0.12621477409310033 accuracy 0.9786821603775024 macro_avg {'precision': 0.9797821938540501, 'recall': 0.9740503551517319, 'f1-score': 0.9767992250058248, 'support': 516} weighted_avg {'precision': 0.9787545404973339, 'recall': 0.9786821705426356, 'f1-score': 0.9786181247760776, 'support': 516}
 
time = 1.95 secondes

Val loss 1.8121185898780823 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 15/40
time = 39.27 secondes

Train loss 0.22127158074352227 accuracy 0.9573643207550049 macro_avg {'precision': 0.9622002393029879, 'recall': 0.9457926303983876, 'f1-score': 0.9530753968253968, 'support': 516} weighted_avg {'precision': 0.9581608419681893, 'recall': 0.9573643410852714, 'f1-score': 0.9569794358311798, 'support': 516}
 
time = 1.82 secondes

Val loss 2.10396209359169 accuracy 0.765625 macro_avg {'precision': 0.8006802721088435, 'recall': 0.7236842105263157, 'f1-score': 0.7308662741799832, 'support': 64} weighted_avg {'precision': 0.7883078231292517, 'recall': 0.765625, 'f1-score': 0.7490012615643398, 'support': 64}
 
----------
Epoch 16/40
time = 40.10 secondes

Train loss 0.18444505678516263 accuracy 0.9748061895370483 macro_avg {'precision': 0.9795120320855615, 'recall': 0.9663946816637681, 'f1-score': 0.972377669890919, 'support': 516} weighted_avg {'precision': 0.975437471500228, 'recall': 0.9748062015503876, 'f1-score': 0.974631601235001, 'support': 516}
 
time = 1.62 secondes

Val loss 1.3474785685539246 accuracy 0.75 macro_avg {'precision': 0.7708333333333333, 'recall': 0.7105263157894737, 'f1-score': 0.7165005537098561, 'support': 64} weighted_avg {'precision': 0.7630208333333333, 'recall': 0.75, 'f1-score': 0.7347729789590256, 'support': 64}
 
----------
Epoch 17/40
time = 41.29 secondes

Train loss 0.06399768915037964 accuracy 0.9864341020584106 macro_avg {'precision': 0.9858748778103616, 'recall': 0.9847455423175073, 'f1-score': 0.9853055445939294, 'support': 516} weighted_avg {'precision': 0.9864263414338433, 'recall': 0.9864341085271318, 'f1-score': 0.9864262164716547, 'support': 516}
 
time = 1.97 secondes

Val loss 0.9417189881205559 accuracy 0.859375 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}
 
----------
Epoch 18/40
time = 39.05 secondes

Train loss 0.4419193771336171 accuracy 0.9186046719551086 macro_avg {'precision': 0.9105598066854612, 'recall': 0.914243453667734, 'f1-score': 0.9123343527013252, 'support': 516} weighted_avg {'precision': 0.9190849403853179, 'recall': 0.9186046511627907, 'f1-score': 0.9187863989442825, 'support': 516}
 
time = 1.47 secondes

Val loss 0.8806437849998474 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 19/40
time = 39.49 secondes

Train loss 0.16448156353947002 accuracy 0.961240291595459 macro_avg {'precision': 0.9612599983507875, 'recall': 0.9546023438388895, 'f1-score': 0.9577658459926663, 'support': 516} weighted_avg {'precision': 0.9612418442286832, 'recall': 0.9612403100775194, 'f1-score': 0.9610994534254307, 'support': 516}
 
time = 2.17 secondes

Val loss 0.8274401426315308 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 20/40
time = 39.11 secondes

Train loss 0.12876486600990492 accuracy 0.9728682041168213 macro_avg {'precision': 0.9752996369543955, 'recall': 0.9660289647774003, 'f1-score': 0.97036380642938, 'support': 516} weighted_avg {'precision': 0.9731144367909859, 'recall': 0.9728682170542635, 'f1-score': 0.9727346484876029, 'support': 516}
 
time = 1.93 secondes

Val loss 0.8372616544365883 accuracy 0.859375 macro_avg {'precision': 0.8616118769883351, 'recall': 0.8451417004048583, 'f1-score': 0.8512012399896668, 'support': 64} weighted_avg {'precision': 0.8601206256627784, 'recall': 0.859375, 'f1-score': 0.8577402479979334, 'support': 64}
 
----------
Epoch 21/40
time = 38.67 secondes

Train loss 0.08721147193996744 accuracy 0.9786821603775024 macro_avg {'precision': 0.9764206019719772, 'recall': 0.9775124750093461, 'f1-score': 0.9769619482496196, 'support': 516} weighted_avg {'precision': 0.9787144786650737, 'recall': 0.9786821705426356, 'f1-score': 0.9786943707007423, 'support': 516}
 
time = 1.82 secondes

Val loss 1.062270313501358 accuracy 0.8125 macro_avg {'precision': 0.88, 'recall': 0.7692307692307692, 'f1-score': 0.7818181818181819, 'support': 64} weighted_avg {'precision': 0.8574999999999999, 'recall': 0.8125, 'f1-score': 0.797159090909091, 'support': 64}
 
----------
Epoch 22/40
time = 38.95 secondes

Train loss 0.058648511774442864 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.66 secondes

Val loss 1.291184887290001 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 23/40
time = 39.03 secondes

Train loss 0.0452318968741703 accuracy 0.9903100728988647 macro_avg {'precision': 0.99125851231011, 'recall': 0.9877850559953189, 'f1-score': 0.9894793072653947, 'support': 516} weighted_avg {'precision': 0.9903485275784635, 'recall': 0.9903100775193798, 'f1-score': 0.9902928891692975, 'support': 516}
 
time = 2.23 secondes

Val loss 1.9735469222068787 accuracy 0.734375 macro_avg {'precision': 0.8454545454545455, 'recall': 0.6730769230769231, 'f1-score': 0.6657450076804916, 'support': 64} weighted_avg {'precision': 0.8164772727272727, 'recall': 0.734375, 'f1-score': 0.6941436251920123, 'support': 64}
 
----------
Epoch 24/40
time = 40.91 secondes

Train loss 0.34293285790111194 accuracy 0.9418604373931885 macro_avg {'precision': 0.9311009245590863, 'recall': 0.9509451749752125, 'f1-score': 0.9386522517952539, 'support': 516} weighted_avg {'precision': 0.9473546985922924, 'recall': 0.9418604651162791, 'f1-score': 0.9425129830798774, 'support': 516}
 
time = 1.43 secondes

Val loss 1.6655630320310593 accuracy 0.75 macro_avg {'precision': 0.7568627450980392, 'recall': 0.7651821862348178, 'f1-score': 0.7490196078431374, 'support': 64} weighted_avg {'precision': 0.777450980392157, 'recall': 0.75, 'f1-score': 0.7519607843137257, 'support': 64}
 
----------
Epoch 25/40
time = 41.02 secondes

Train loss 0.09535022647469305 accuracy 0.9786821603775024 macro_avg {'precision': 0.974537037037037, 'recall': 0.9798205549144223, 'f1-score': 0.9770654620242679, 'support': 516} weighted_avg {'precision': 0.9789961958082114, 'recall': 0.9786821705426356, 'f1-score': 0.9787411745031601, 'support': 516}
 
time = 1.75 secondes

Val loss 1.0390583989210427 accuracy 0.84375 macro_avg {'precision': 0.8373015873015872, 'recall': 0.8441295546558705, 'f1-score': 0.8398398398398399, 'support': 64} weighted_avg {'precision': 0.8469742063492063, 'recall': 0.84375, 'f1-score': 0.8445320320320321, 'support': 64}
 
----------
Epoch 26/40
time = 40.02 secondes

Train loss 0.13972099651062198 accuracy 0.9786821603775024 macro_avg {'precision': 0.9774682306940372, 'recall': 0.976358435056808, 'f1-score': 0.9769087129333176, 'support': 516} weighted_avg {'precision': 0.9786653102669607, 'recall': 0.9786821705426356, 'f1-score': 0.978669768741172, 'support': 516}
 
time = 1.30 secondes

Val loss 1.4147384315729141 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 27/40
time = 38.41 secondes

Train loss 0.058669980899360256 accuracy 0.9844961166381836 macro_avg {'precision': 0.9803172973579941, 'recall': 0.9866879053362156, 'f1-score': 0.9833387148853729, 'support': 516} weighted_avg {'precision': 0.9848818618777474, 'recall': 0.9844961240310077, 'f1-score': 0.9845471861991977, 'support': 516}
 
time = 2.09 secondes

Val loss 0.903839536011219 accuracy 0.859375 macro_avg {'precision': 0.8558974358974358, 'recall': 0.8512145748987854, 'f1-score': 0.8533231474407945, 'support': 64} weighted_avg {'precision': 0.8588782051282051, 'recall': 0.859375, 'f1-score': 0.858909472880061, 'support': 64}
 
----------
Epoch 28/40
time = 38.97 secondes

Train loss 0.06214826349451235 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.80 secondes

Val loss 0.728185917250812 accuracy 0.859375 macro_avg {'precision': 0.8536945812807881, 'recall': 0.8633603238866396, 'f1-score': 0.8565379825653798, 'support': 64} weighted_avg {'precision': 0.8650554187192118, 'recall': 0.859375, 'f1-score': 0.8603206724782068, 'support': 64}
 
----------
Epoch 29/40
time = 38.54 secondes

Train loss 0.010623939959755675 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6172033548355103 accuracy 0.75 macro_avg {'precision': 0.8518518518518519, 'recall': 0.6923076923076923, 'f1-score': 0.6908212560386473, 'support': 64} weighted_avg {'precision': 0.8240740740740741, 'recall': 0.75, 'f1-score': 0.716183574879227, 'support': 64}
 
----------
Epoch 30/40
time = 38.79 secondes

Train loss 0.07192157786586463 accuracy 0.9883720874786377 macro_avg {'precision': 0.991044776119403, 'recall': 0.9839572192513368, 'f1-score': 0.9873297537977999, 'support': 516} weighted_avg {'precision': 0.9885803540437349, 'recall': 0.9883720930232558, 'f1-score': 0.9883298360276292, 'support': 516}
 
time = 1.82 secondes

Val loss 1.2587793618440628 accuracy 0.84375 macro_avg {'precision': 0.8416666666666667, 'recall': 0.8319838056680162, 'f1-score': 0.8358974358974359, 'support': 64} weighted_avg {'precision': 0.8432291666666667, 'recall': 0.84375, 'f1-score': 0.8426282051282052, 'support': 64}
 
----------
Epoch 31/40
time = 36.69 secondes

Train loss 0.012085543607650889 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.34 secondes

Val loss 1.4146884232759476 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 32/40
time = 36.32 secondes

Train loss 0.017149427898843758 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.48 secondes

Val loss 1.5102647494059056 accuracy 0.8125 macro_avg {'precision': 0.807843137254902, 'recall': 0.8178137651821862, 'f1-score': 0.8095238095238094, 'support': 64} weighted_avg {'precision': 0.821813725490196, 'recall': 0.8125, 'f1-score': 0.8139880952380951, 'support': 64}
 
----------
Epoch 33/40
time = 34.84 secondes

Train loss 0.09528234315075679 accuracy 0.9883720874786377 macro_avg {'precision': 0.9853725332259364, 'recall': 0.9897274190140273, 'f1-score': 0.9874763361001893, 'support': 516} weighted_avg {'precision': 0.9885511712201107, 'recall': 0.9883720930232558, 'f1-score': 0.9883980569920404, 'support': 516}
 
time = 1.33 secondes

Val loss 1.3578190803527832 accuracy 0.84375 macro_avg {'precision': 0.8743961352657005, 'recall': 0.8137651821862348, 'f1-score': 0.8268398268398268, 'support': 64} weighted_avg {'precision': 0.861262077294686, 'recall': 0.84375, 'f1-score': 0.8369859307359306, 'support': 64}
 
----------
Epoch 34/40
time = 36.44 secondes

Train loss 0.002466697441625663 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.66 secondes

Val loss 1.0218378957360983 accuracy 0.828125 macro_avg {'precision': 0.823076923076923, 'recall': 0.8188259109311742, 'f1-score': 0.8207282913165266, 'support': 64} weighted_avg {'precision': 0.8274038461538462, 'recall': 0.828125, 'f1-score': 0.8275560224089636, 'support': 64}
 
----------
Epoch 35/40
time = 36.86 secondes

Train loss 0.0346477697074244 accuracy 0.9903100728988647 macro_avg {'precision': 0.9879399418792381, 'recall': 0.9912471758529331, 'f1-score': 0.9895519063721223, 'support': 516} weighted_avg {'precision': 0.9904146423270332, 'recall': 0.9903100775193798, 'f1-score': 0.9903264409254359, 'support': 516}
 
time = 1.75 secondes

Val loss 1.3860953450202942 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 36/40
time = 35.81 secondes

Train loss 0.07223866712637105 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.64 secondes

Val loss 1.2280682548880577 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 37/40
time = 36.47 secondes

Train loss 0.021948573842096128 accuracy 0.9961240291595459 macro_avg {'precision': 0.9958064463696503, 'recall': 0.9958064463696503, 'f1-score': 0.9958064463696503, 'support': 516} weighted_avg {'precision': 0.9961240310077519, 'recall': 0.9961240310077519, 'f1-score': 0.9961240310077519, 'support': 516}
 
time = 1.90 secondes

Val loss 1.1350205773487687 accuracy 0.828125 macro_avg {'precision': 0.8313782991202345, 'recall': 0.8431174089068827, 'f1-score': 0.827069516089413, 'support': 64} weighted_avg {'precision': 0.8508980938416422, 'recall': 0.828125, 'f1-score': 0.829602677474822, 'support': 64}
 
----------
Epoch 38/40
time = 36.94 secondes

Train loss 0.012120993220543658 accuracy 0.9961240291595459 macro_avg {'precision': 0.9947089947089947, 'recall': 0.9969604863221885, 'f1-score': 0.9958160352880125, 'support': 516} weighted_avg {'precision': 0.9961650465526435, 'recall': 0.9961240310077519, 'f1-score': 0.9961284309466054, 'support': 516}
 
time = 1.49 secondes

Val loss 1.3076321929693222 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 39/40
time = 36.49 secondes

Train loss 0.009670125583149704 accuracy 0.998062014579773 macro_avg {'precision': 0.9984848484848485, 'recall': 0.9973262032085561, 'f1-score': 0.997900792084847, 'support': 516} weighted_avg {'precision': 0.9980678881841673, 'recall': 0.998062015503876, 'f1-score': 0.9980608880673791, 'support': 516}
 
time = 1.66 secondes

Val loss 1.4507780820131302 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 40/40
time = 36.42 secondes

Train loss 0.00014191514073348972 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.38 secondes

Val loss 1.4333347380161285 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
best_accuracy 0.859375 best_epoch 17 macro_avg {'precision': 0.8533533533533533, 'recall': 0.8572874493927125, 'f1-score': 0.8550943396226415, 'support': 64} weighted_avg {'precision': 0.8605793293293293, 'recall': 0.859375, 'f1-score': 0.8597641509433962, 'support': 64}

average train time 38.82262225151062

average val time 1.7757685899734497
 
time = 1.87 secondes

test_accuracy 0.9076923131942749 macro_avg {'precision': 0.9032567049808429, 'recall': 0.9103313840155945, 'f1-score': 0.9058880308880309, 'support': 65} weighted_avg {'precision': 0.9102269378131447, 'recall': 0.9076923076923077, 'f1-score': 0.9080932580932581, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_1024_512_4
----------
Epoch 1/40
time = 54.61 secondes

Train loss 0.6052206285072096 accuracy 0.6220930218696594 macro_avg {'precision': 0.5354737854737854, 'recall': 0.5143848641971295, 'f1-score': 0.47217399058914866, 'support': 516} weighted_avg {'precision': 0.5656206770547857, 'recall': 0.622093023255814, 'f1-score': 0.5495867274570267, 'support': 516}
 
time = 2.24 secondes

Val loss 0.665861502289772 accuracy 0.75 macro_avg {'precision': 0.8141025641025641, 'recall': 0.6983805668016194, 'f1-score': 0.7005847953216375, 'support': 64} weighted_avg {'precision': 0.7948717948717949, 'recall': 0.75, 'f1-score': 0.7233918128654971, 'support': 64}
 
----------
Epoch 2/40
time = 53.84 secondes

Train loss 0.3566817093753453 accuracy 0.8507751822471619 macro_avg {'precision': 0.8415441176470588, 'recall': 0.8322009654925799, 'f1-score': 0.8363908139692894, 'support': 516} weighted_avg {'precision': 0.8495368787049704, 'recall': 0.8507751937984496, 'f1-score': 0.8497410226996212, 'support': 516}
 
time = 2.00 secondes

Val loss 0.44534941762685776 accuracy 0.78125 macro_avg {'precision': 0.775, 'recall': 0.7672064777327935, 'f1-score': 0.7702564102564102, 'support': 64} weighted_avg {'precision': 0.7796875000000001, 'recall': 0.78125, 'f1-score': 0.7796794871794871, 'support': 64}
 
----------
Epoch 3/40
time = 52.19 secondes

Train loss 0.24334063615198387 accuracy 0.9147287011146545 macro_avg {'precision': 0.912154392280386, 'recall': 0.9019716203696179, 'f1-score': 0.9066263078239126, 'support': 516} weighted_avg {'precision': 0.9144108686038567, 'recall': 0.9147286821705426, 'f1-score': 0.9141956312266853, 'support': 516}
 
time = 2.06 secondes

Val loss 0.5378583557903767 accuracy 0.796875 macro_avg {'precision': 0.7892892892892893, 'recall': 0.7925101214574899, 'f1-score': 0.790691823899371, 'support': 64} weighted_avg {'precision': 0.7983921421421422, 'recall': 0.796875, 'f1-score': 0.7974371069182389, 'support': 64}
 
----------
Epoch 4/40
time = 51.95 secondes

Train loss 0.1814212049922031 accuracy 0.9515503644943237 macro_avg {'precision': 0.9500723827071132, 'recall': 0.9446954797392846, 'f1-score': 0.947270965922329, 'support': 516} weighted_avg {'precision': 0.9514531504330975, 'recall': 0.9515503875968992, 'f1-score': 0.9514048290365398, 'support': 516}
 
time = 1.95 secondes

Val loss 0.8098108023405075 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 5/40
time = 51.21 secondes

Train loss 0.10685272798450156 accuracy 0.9709302186965942 macro_avg {'precision': 0.9662422839506173, 'recall': 0.971433447653723, 'f1-score': 0.9687256300330926, 'support': 516} weighted_avg {'precision': 0.9712853801799215, 'recall': 0.9709302325581395, 'f1-score': 0.9710106925043092, 'support': 516}
 
time = 2.39 secondes

Val loss 1.0759399235248566 accuracy 0.796875 macro_avg {'precision': 0.8241551939924906, 'recall': 0.7621457489878543, 'f1-score': 0.7723666210670315, 'support': 64} weighted_avg {'precision': 0.8132431163954943, 'recall': 0.796875, 'f1-score': 0.7863714090287277, 'support': 64}
 
----------
Epoch 6/40
time = 63.39 secondes

Train loss 0.19757196083876558 accuracy 0.9437984228134155 macro_avg {'precision': 0.9348417721518987, 'recall': 0.946694732051428, 'f1-score': 0.9400516795865634, 'support': 516} weighted_avg {'precision': 0.9458059807673437, 'recall': 0.9437984496124031, 'f1-score': 0.9441760310878754, 'support': 516}
 
time = 2.20 secondes

Val loss 1.289656475186348 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 7/40
time = 61.12 secondes

Train loss 0.2610441936306994 accuracy 0.9341084957122803 macro_avg {'precision': 0.931475220582172, 'recall': 0.9252474684264422, 'f1-score': 0.9282019381875328, 'support': 516} weighted_avg {'precision': 0.9339033344136316, 'recall': 0.9341085271317829, 'f1-score': 0.9338690708232323, 'support': 516}
 
time = 2.50 secondes

Val loss 1.5010225176811218 accuracy 0.75 macro_avg {'precision': 0.7885714285714285, 'recall': 0.7044534412955465, 'f1-score': 0.709090909090909, 'support': 64} weighted_avg {'precision': 0.7757142857142857, 'recall': 0.75, 'f1-score': 0.7295454545454545, 'support': 64}
 
----------
Epoch 8/40
time = 61.58 secondes

Train loss 0.24086559725180973 accuracy 0.9437984228134155 macro_avg {'precision': 0.9379560865353568, 'recall': 0.9409245322887376, 'f1-score': 0.9394010569583089, 'support': 516} weighted_avg {'precision': 0.9440562009246258, 'recall': 0.9437984496124031, 'f1-score': 0.9438933573675274, 'support': 516}
 
time = 2.37 secondes

Val loss 1.2972755208611488 accuracy 0.796875 macro_avg {'precision': 0.793743372216331, 'recall': 0.7803643724696356, 'f1-score': 0.785068457762852, 'support': 64} weighted_avg {'precision': 0.7958311240721103, 'recall': 0.796875, 'f1-score': 0.7945136915525703, 'support': 64}
 
----------
Epoch 9/40
time = 62.57 secondes

Train loss 0.17100825949896578 accuracy 0.9554263353347778 macro_avg {'precision': 0.9513168137000518, 'recall': 0.9523511532272484, 'f1-score': 0.9518295281582952, 'support': 516} weighted_avg {'precision': 0.9554850643447058, 'recall': 0.9554263565891473, 'f1-score': 0.9554518660106426, 'support': 516}
 
time = 2.40 secondes

Val loss 1.391263633966446 accuracy 0.8125 macro_avg {'precision': 0.8541666666666667, 'recall': 0.7753036437246963, 'f1-score': 0.787375415282392, 'support': 64} weighted_avg {'precision': 0.8385416666666667, 'recall': 0.8125, 'f1-score': 0.801079734219269, 'support': 64}
 
----------
Epoch 10/40
time = 61.73 secondes

Train loss 0.10851525875940835 accuracy 0.9728682041168213 macro_avg {'precision': 0.9716991916387687, 'recall': 0.9694910846350147, 'f1-score': 0.970576735092864, 'support': 516} weighted_avg {'precision': 0.9728361889606885, 'recall': 0.9728682170542635, 'f1-score': 0.9728363909159108, 'support': 516}
 
time = 2.51 secondes

Val loss 1.0451386719942093 accuracy 0.765625 macro_avg {'precision': 0.776847290640394, 'recall': 0.784412955465587, 'f1-score': 0.7651088818204062, 'support': 64} weighted_avg {'precision': 0.7992918719211823, 'recall': 0.765625, 'f1-score': 0.7671733545387815, 'support': 64}
 
----------
Epoch 11/40
time = 62.26 secondes

Train loss 0.08287082006272888 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.48 secondes

Val loss 1.8729027807712555 accuracy 0.78125 macro_avg {'precision': 0.8653846153846154, 'recall': 0.7307692307692308, 'f1-score': 0.7380116959064327, 'support': 64} weighted_avg {'precision': 0.8401442307692307, 'recall': 0.78125, 'f1-score': 0.7579678362573098, 'support': 64}
 
----------
Epoch 12/40
time = 60.71 secondes

Train loss 0.09569069002949011 accuracy 0.9806201457977295 macro_avg {'precision': 0.9801257450804279, 'recall': 0.9778781918957138, 'f1-score': 0.9789833822091887, 'support': 516} weighted_avg {'precision': 0.9806066095604492, 'recall': 0.9806201550387597, 'f1-score': 0.9805974220827934, 'support': 516}
 
time = 2.45 secondes

Val loss 1.5543503165245056 accuracy 0.765625 macro_avg {'precision': 0.8584905660377358, 'recall': 0.7115384615384616, 'f1-score': 0.7148797148797148, 'support': 64} weighted_avg {'precision': 0.8319575471698113, 'recall': 0.765625, 'f1-score': 0.737433174933175, 'support': 64}
 
----------
Epoch 13/40
time = 61.53 secondes

Train loss 0.1608647581667879 accuracy 0.9573643207550049 macro_avg {'precision': 0.9652643964326518, 'recall': 0.9434845504933115, 'f1-score': 0.9528289342463933, 'support': 516} weighted_avg {'precision': 0.9589621050881123, 'recall': 0.9573643410852714, 'f1-score': 0.9568541078158976, 'support': 516}
 
time = 2.26 secondes

Val loss 2.117667078971863 accuracy 0.71875 macro_avg {'precision': 0.8392857142857143, 'recall': 0.6538461538461539, 'f1-score': 0.6395494367959951, 'support': 64} weighted_avg {'precision': 0.8091517857142858, 'recall': 0.71875, 'f1-score': 0.671229662077597, 'support': 64}
 
----------
Epoch 14/40
time = 62.03 secondes

Train loss 0.9873484827412264 accuracy 0.8449612259864807 macro_avg {'precision': 0.8341594416723306, 'recall': 0.8276416949758627, 'f1-score': 0.830650322453601, 'support': 516} weighted_avg {'precision': 0.8438673872834702, 'recall': 0.8449612403100775, 'f1-score': 0.8441979913577321, 'support': 516}
 
time = 2.38 secondes

Val loss 1.617888018488884 accuracy 0.765625 macro_avg {'precision': 0.8005128205128205, 'recall': 0.7965587044534412, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.8304166666666666, 'recall': 0.765625, 'f1-score': 0.7648809523809523, 'support': 64}
 
----------
Epoch 15/40
time = 62.55 secondes

Train loss 0.2168506928402084 accuracy 0.9573643207550049 macro_avg {'precision': 0.9499864742294288, 'recall': 0.9596411098288444, 'f1-score': 0.9543788580246912, 'support': 516} weighted_avg {'precision': 0.9585738274550816, 'recall': 0.9573643410852714, 'f1-score': 0.957590514044406, 'support': 516}
 
time = 2.47 secondes

Val loss 1.4157423079013824 accuracy 0.765625 macro_avg {'precision': 0.7872872872872874, 'recall': 0.7904858299595142, 'f1-score': 0.7655677655677655, 'support': 64} weighted_avg {'precision': 0.813282032032032, 'recall': 0.765625, 'f1-score': 0.7662545787545787, 'support': 64}
 
----------
Epoch 16/40
time = 62.15 secondes

Train loss 0.3946956769972475 accuracy 0.9244186282157898 macro_avg {'precision': 0.9194604504976427, 'recall': 0.9164946442793752, 'f1-score': 0.9179385966700785, 'support': 516} weighted_avg {'precision': 0.9242175984016957, 'recall': 0.9244186046511628, 'f1-score': 0.9242845355205198, 'support': 516}
 
time = 2.35 secondes

Val loss 1.1583004891872406 accuracy 0.828125 macro_avg {'precision': 0.8473684210526315, 'recall': 0.8006072874493927, 'f1-score': 0.811512717536814, 'support': 64} weighted_avg {'precision': 0.8384868421052631, 'recall': 0.828125, 'f1-score': 0.8220046854082999, 'support': 64}
 
----------
Epoch 17/40
time = 61.35 secondes

Train loss 0.0524032155808527 accuracy 0.9825581312179565 macro_avg {'precision': 0.9786844135802468, 'recall': 0.9840141085447718, 'f1-score': 0.9812353780198556, 'support': 516} weighted_avg {'precision': 0.9828516036223562, 'recall': 0.9825581395348837, 'f1-score': 0.9826064155025854, 'support': 516}
 
time = 2.59 secondes

Val loss 1.6846273094415665 accuracy 0.734375 macro_avg {'precision': 0.7676923076923077, 'recall': 0.76417004048583, 'f1-score': 0.7343101343101343, 'support': 64} weighted_avg {'precision': 0.79625, 'recall': 0.734375, 'f1-score': 0.733531746031746, 'support': 64}
 
----------
Epoch 18/40
time = 61.86 secondes

Train loss 0.34373950946434034 accuracy 0.9263566136360168 macro_avg {'precision': 0.9220203810367744, 'recall': 0.9180144011182809, 'f1-score': 0.9199477423042377, 'support': 516} weighted_avg {'precision': 0.926125324714726, 'recall': 0.9263565891472868, 'f1-score': 0.9261810043022717, 'support': 516}
 
time = 2.43 secondes

Val loss 1.6776372492313385 accuracy 0.78125 macro_avg {'precision': 0.8342857142857143, 'recall': 0.736842105263158, 'f1-score': 0.7454545454545455, 'support': 64} weighted_avg {'precision': 0.8166071428571429, 'recall': 0.78125, 'f1-score': 0.7633522727272728, 'support': 64}
 
----------
Epoch 19/40
time = 61.59 secondes

Train loss 0.08670012707421626 accuracy 0.9825581312179565 macro_avg {'precision': 0.9770408163265306, 'recall': 0.9863221884498481, 'f1-score': 0.9813169085196345, 'support': 516} weighted_avg {'precision': 0.9833590412909349, 'recall': 0.9825581395348837, 'f1-score': 0.9826421326111036, 'support': 516}
 
time = 2.45 secondes

Val loss 1.7826304137706757 accuracy 0.75 macro_avg {'precision': 0.7584541062801933, 'recall': 0.7165991902834008, 'f1-score': 0.722943722943723, 'support': 64} weighted_avg {'precision': 0.7548309178743962, 'recall': 0.75, 'f1-score': 0.7391774891774892, 'support': 64}
 
----------
Epoch 20/40
time = 59.85 secondes

Train loss 0.15885241739857575 accuracy 0.9728682041168213 macro_avg {'precision': 0.9780812735651445, 'recall': 0.9637208848723242, 'f1-score': 0.9702152222313847, 'support': 516} weighted_avg {'precision': 0.9736219119714994, 'recall': 0.9728682170542635, 'f1-score': 0.9726614901849484, 'support': 516}
 
time = 1.78 secondes

Val loss 2.010408192873001 accuracy 0.71875 macro_avg {'precision': 0.7254901960784315, 'recall': 0.7327935222672065, 'f1-score': 0.7176470588235293, 'support': 64} weighted_avg {'precision': 0.7457107843137255, 'recall': 0.71875, 'f1-score': 0.7209558823529412, 'support': 64}
 
----------
Epoch 21/40
time = 50.90 secondes

Train loss 0.032350728449245886 accuracy 0.9941860437393188 macro_avg {'precision': 0.9942815249266862, 'recall': 0.9931326495782065, 'f1-score': 0.9937023762545412, 'support': 516} weighted_avg {'precision': 0.994187372600726, 'recall': 0.9941860465116279, 'f1-score': 0.9941826642021377, 'support': 516}
 
time = 1.75 secondes

Val loss 1.9708139672875404 accuracy 0.734375 macro_avg {'precision': 0.7453201970443349, 'recall': 0.7520242914979758, 'f1-score': 0.7337900660631269, 'support': 64} weighted_avg {'precision': 0.7672105911330048, 'recall': 0.734375, 'f1-score': 0.736129801810619, 'support': 64}
 
----------
Epoch 22/40
time = 51.22 secondes

Train loss 0.14020680028911695 accuracy 0.9748061895370483 macro_avg {'precision': 0.9675, 'recall': 0.9802431610942249, 'f1-score': 0.9731266149870801, 'support': 516} weighted_avg {'precision': 0.9764437984496125, 'recall': 0.9748062015503876, 'f1-score': 0.9749754622118062, 'support': 516}
 
time = 1.92 secondes

Val loss 1.6221761107444763 accuracy 0.78125 macro_avg {'precision': 0.7863636363636364, 'recall': 0.7550607287449393, 'f1-score': 0.7624602332979852, 'support': 64} weighted_avg {'precision': 0.7838068181818182, 'recall': 0.78125, 'f1-score': 0.7749867444326617, 'support': 64}
 
----------
Epoch 23/40
time = 53.36 secondes

Train loss 0.04975731879720556 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.94 secondes

Val loss 1.6517925560474396 accuracy 0.828125 macro_avg {'precision': 0.8642052565707135, 'recall': 0.7945344129554657, 'f1-score': 0.8073871409028728, 'support': 64} weighted_avg {'precision': 0.849773153942428, 'recall': 0.828125, 'f1-score': 0.8192373461012312, 'support': 64}
 
----------
Epoch 24/40
time = 53.40 secondes

Train loss 0.14401069832224908 accuracy 0.9651162624359131 macro_avg {'precision': 0.970896038018841, 'recall': 0.9541797376590868, 'f1-score': 0.9616071428571429, 'support': 516} weighted_avg {'precision': 0.9660682393672618, 'recall': 0.9651162790697675, 'f1-score': 0.9648013565891472, 'support': 516}
 
time = 1.86 secondes

Val loss 1.6974860578775406 accuracy 0.703125 macro_avg {'precision': 0.7137931034482758, 'recall': 0.7196356275303644, 'f1-score': 0.7024712503058478, 'support': 64} weighted_avg {'precision': 0.7351293103448275, 'recall': 0.703125, 'f1-score': 0.7050862490824565, 'support': 64}
 
----------
Epoch 25/40
time = 54.26 secondes

Train loss 0.0782484006027296 accuracy 0.9825581312179565 macro_avg {'precision': 0.9828116815086433, 'recall': 0.9793979487346196, 'f1-score': 0.9810627530777105, 'support': 516} weighted_avg {'precision': 0.9825684182635497, 'recall': 0.9825581395348837, 'f1-score': 0.9825272005047354, 'support': 516}
 
time = 2.16 secondes

Val loss 1.621832400560379 accuracy 0.796875 macro_avg {'precision': 0.8099415204678362, 'recall': 0.7682186234817814, 'f1-score': 0.7772423025435075, 'support': 64} weighted_avg {'precision': 0.8039108187134503, 'recall': 0.796875, 'f1-score': 0.7896419009370819, 'support': 64}
 
----------
Epoch 26/40
time = 54.42 secondes

Train loss 0.06845679857647294 accuracy 0.9883720874786377 macro_avg {'precision': 0.9844559585492227, 'recall': 0.9908814589665653, 'f1-score': 0.9875040361640297, 'support': 516} weighted_avg {'precision': 0.9887335823593204, 'recall': 0.9883720930232558, 'f1-score': 0.9884103896493981, 'support': 516}
 
time = 2.03 secondes

Val loss 1.8443526327610016 accuracy 0.765625 macro_avg {'precision': 0.7725146198830409, 'recall': 0.73582995951417, 'f1-score': 0.7429718875502007, 'support': 64} weighted_avg {'precision': 0.7693347953216374, 'recall': 0.765625, 'f1-score': 0.7572791164658634, 'support': 64}
 
----------
Epoch 27/40
time = 53.62 secondes

Train loss 0.07718372638346134 accuracy 0.9864341020584106 macro_avg {'precision': 0.9882707113246035, 'recall': 0.9824374624124311, 'f1-score': 0.9852358704582521, 'support': 516} weighted_avg {'precision': 0.9865549376585444, 'recall': 0.9864341085271318, 'f1-score': 0.9863933521302312, 'support': 516}
 
time = 2.13 secondes

Val loss 0.8541925735771656 accuracy 0.828125 macro_avg {'precision': 0.8255131964809383, 'recall': 0.8370445344129555, 'f1-score': 0.8260439831974302, 'support': 64} weighted_avg {'precision': 0.8411840175953079, 'recall': 0.828125, 'f1-score': 0.8296114405732642, 'support': 64}
 
----------
Epoch 28/40
time = 53.58 secondes

Train loss 0.01471875214536505 accuracy 0.9941860437393188 macro_avg {'precision': 0.9954819277108433, 'recall': 0.9919786096256684, 'f1-score': 0.9936875843592369, 'support': 516} weighted_avg {'precision': 0.9942385822359204, 'recall': 0.9941860465116279, 'f1-score': 0.9941757335015786, 'support': 516}
 
time = 2.07 secondes

Val loss 1.1719386577606201 accuracy 0.828125 macro_avg {'precision': 0.8355481727574751, 'recall': 0.8066801619433198, 'f1-score': 0.8150774888363541, 'support': 64} weighted_avg {'precision': 0.831499169435216, 'recall': 0.828125, 'f1-score': 0.8242874967165746, 'support': 64}
 
----------
Epoch 29/40
time = 53.66 secondes

Train loss 0.0024413235792466862 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 2.01 secondes

Val loss 1.2058558948338032 accuracy 0.8125 macro_avg {'precision': 0.8083333333333333, 'recall': 0.7995951417004048, 'f1-score': 0.803076923076923, 'support': 64} weighted_avg {'precision': 0.8114583333333333, 'recall': 0.8125, 'f1-score': 0.8111538461538461, 'support': 64}
 
----------
Epoch 30/40
time = 52.92 secondes

Train loss 0.06301927973022843 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 2.08 secondes

Val loss 1.9099354445934296 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 31/40
time = 54.50 secondes

Train loss 0.0012452832337602917 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.79 secondes

Val loss 1.8820369988679886 accuracy 0.765625 macro_avg {'precision': 0.7688172043010753, 'recall': 0.7783400809716599, 'f1-score': 0.7641857037582904, 'support': 64} weighted_avg {'precision': 0.7879704301075268, 'recall': 0.765625, 'f1-score': 0.7676400147383935, 'support': 64}
 
----------
Epoch 32/40
time = 51.50 secondes

Train loss 0.029958484159909527 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.82 secondes

Val loss 2.15250226855278 accuracy 0.765625 macro_avg {'precision': 0.8242835595776772, 'recall': 0.7176113360323887, 'f1-score': 0.7234226447709595, 'support': 64} weighted_avg {'precision': 0.8057598039215685, 'recall': 0.765625, 'f1-score': 0.743679775280899, 'support': 64}
 
----------
Epoch 33/40
time = 51.21 secondes

Train loss 0.05022731599660112 accuracy 0.9903100728988647 macro_avg {'precision': 0.9925149700598803, 'recall': 0.9866310160427807, 'f1-score': 0.9894541931844658, 'support': 516} weighted_avg {'precision': 0.9904551362391496, 'recall': 0.9903100775193798, 'f1-score': 0.990280965807308, 'support': 516}
 
time = 1.72 secondes

Val loss 1.7247264087200165 accuracy 0.78125 macro_avg {'precision': 0.7732793522267206, 'recall': 0.7732793522267206, 'f1-score': 0.7732793522267205, 'support': 64} weighted_avg {'precision': 0.78125, 'recall': 0.78125, 'f1-score': 0.7812499999999999, 'support': 64}
 
----------
Epoch 34/40
time = 50.71 secondes

Train loss 0.040888782590848154 accuracy 0.9922480583190918 macro_avg {'precision': 0.9895287958115183, 'recall': 0.993920972644377, 'f1-score': 0.9916508907334596, 'support': 516} weighted_avg {'precision': 0.992410406266488, 'recall': 0.9922480620155039, 'f1-score': 0.9922653713280268, 'support': 516}
 
time = 1.68 secondes

Val loss 1.8039852678775787 accuracy 0.78125 macro_avg {'precision': 0.776470588235294, 'recall': 0.785425101214575, 'f1-score': 0.7777777777777777, 'support': 64} weighted_avg {'precision': 0.7908088235294117, 'recall': 0.78125, 'f1-score': 0.782986111111111, 'support': 64}
 
----------
Epoch 35/40
time = 51.41 secondes

Train loss 7.64346513085801e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.78 secondes

Val loss 1.6951496303081512 accuracy 0.796875 macro_avg {'precision': 0.8442176870748299, 'recall': 0.7560728744939271, 'f1-score': 0.7667507709559854, 'support': 64} weighted_avg {'precision': 0.8275085034013605, 'recall': 0.796875, 'f1-score': 0.7824677600224279, 'support': 64}
 
----------
Epoch 36/40
time = 55.03 secondes

Train loss 0.0001358925539093572 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.64 secondes

Val loss 1.6230476200580597 accuracy 0.796875 macro_avg {'precision': 0.800110741971207, 'recall': 0.7742914979757085, 'f1-score': 0.7814552140793275, 'support': 64} weighted_avg {'precision': 0.7983457918050941, 'recall': 0.796875, 'f1-score': 0.792339768846861, 'support': 64}
 
----------
Epoch 37/40
time = 51.52 secondes

Train loss 4.082438560241523e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.36 secondes

Val loss 1.4412242770195007 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 38/40
time = 50.16 secondes

Train loss 0.04809678205635988 accuracy 0.9941860437393188 macro_avg {'precision': 0.9921052631578947, 'recall': 0.9954407294832827, 'f1-score': 0.9937311438232733, 'support': 516} weighted_avg {'precision': 0.9942778457772338, 'recall': 0.9941860465116279, 'f1-score': 0.9941958645552614, 'support': 516}
 
time = 1.34 secondes

Val loss 1.2933878004550934 accuracy 0.828125 macro_avg {'precision': 0.822167487684729, 'recall': 0.8309716599190283, 'f1-score': 0.8246575342465753, 'support': 64} weighted_avg {'precision': 0.8340825123152709, 'recall': 0.828125, 'f1-score': 0.829280821917808, 'support': 64}
 
----------
Epoch 39/40
time = 51.09 secondes

Train loss 0.00479410793476828 accuracy 0.998062014579773 macro_avg {'precision': 0.9973404255319149, 'recall': 0.9984802431610942, 'f1-score': 0.9979056316590563, 'support': 516} weighted_avg {'precision': 0.9980723239320469, 'recall': 0.998062015503876, 'f1-score': 0.9980631246091585, 'support': 516}
 
time = 1.90 secondes

Val loss 1.3506575971841812 accuracy 0.84375 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}
 
----------
Epoch 40/40
time = 53.81 secondes

Train loss 2.7775521768048886e-05 accuracy 1.0 macro_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516} weighted_avg {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 516}
 
time = 1.85 secondes

Val loss 1.3970402926206589 accuracy 0.84375 macro_avg {'precision': 0.8484848484848485, 'recall': 0.8259109311740891, 'f1-score': 0.8333333333333333, 'support': 64} weighted_avg {'precision': 0.8456439393939394, 'recall': 0.84375, 'f1-score': 0.8411458333333333, 'support': 64}
 
----------
best_accuracy 0.84375 best_epoch 39 macro_avg {'precision': 0.8380566801619433, 'recall': 0.8380566801619433, 'f1-score': 0.8380566801619433, 'support': 64} weighted_avg {'precision': 0.84375, 'recall': 0.84375, 'f1-score': 0.84375, 'support': 64}

average train time 56.059385776519775

average val time 2.077598822116852
 
time = 2.04 secondes

test_accuracy 0.9538461565971375 macro_avg {'precision': 0.9551282051282051, 'recall': 0.9498050682261209, 'f1-score': 0.9522175937270277, 'support': 65} weighted_avg {'precision': 0.954043392504931, 'recall': 0.9538461538461539, 'f1-score': 0.9537104405028934, 'support': 65}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 720.00 MiB (GPU 0; 79.21 GiB total capacity; 37.65 GiB already allocated; 592.62 MiB free; 38.91 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_2048_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 770.00 MiB (GPU 0; 79.21 GiB total capacity; 37.45 GiB already allocated; 162.62 MiB free; 39.33 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_256_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 79.21 GiB total capacity; 36.54 GiB already allocated; 740.62 MiB free; 38.77 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
Hyperpartisan_Longformer_4096_512_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 79.21 GiB total capacity; 38.18 GiB already allocated; 604.62 MiB free; 38.90 GiB reserved in total by PyTorch)
datasets imported
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_64_4
----------
Epoch 1/40
time = 745.27 secondes

Train loss 1.3620169442527148 accuracy 0.6241406798362732 macro_avg {'precision': 0.6219353346972651, 'recall': 0.6093775343137428, 'f1-score': 0.6038378794281871, 'support': 10182} weighted_avg {'precision': 0.6313274750649881, 'recall': 0.6241406403457082, 'f1-score': 0.6175725358091669, 'support': 10182}
 
time = 22.36 secondes

Val loss 0.7721365014432182 accuracy 0.7597173452377319 macro_avg {'precision': 0.7510064078283013, 'recall': 0.7575722002372418, 'f1-score': 0.7333221118737335, 'support': 1132} weighted_avg {'precision': 0.7658912605288779, 'recall': 0.7597173144876325, 'f1-score': 0.7376422287608863, 'support': 1132}
 
----------
Epoch 2/40
time = 766.24 secondes

Train loss 0.546149585969173 accuracy 0.8348065614700317 macro_avg {'precision': 0.8236073259763789, 'recall': 0.8245366376709649, 'f1-score': 0.8223070801175615, 'support': 10182} weighted_avg {'precision': 0.8310555458212395, 'recall': 0.8348065213121194, 'f1-score': 0.8316300753948395, 'support': 10182}
 
time = 23.17 secondes

Val loss 0.6738081362465738 accuracy 0.814487636089325 macro_avg {'precision': 0.8165992188440303, 'recall': 0.8043235652313483, 'f1-score': 0.8017284224585145, 'support': 1132} weighted_avg {'precision': 0.8195720156833913, 'recall': 0.8144876325088339, 'f1-score': 0.809553568452201, 'support': 1132}
 
----------
Epoch 3/40
time = 768.31 secondes

Train loss 0.3193511044404804 accuracy 0.9082695245742798 macro_avg {'precision': 0.9038035449565139, 'recall': 0.9032763062642241, 'f1-score': 0.9033817246880691, 'support': 10182} weighted_avg {'precision': 0.9082510812578475, 'recall': 0.9082694951875859, 'f1-score': 0.908112436578834, 'support': 10182}
 
time = 22.62 secondes

Val loss 0.5849336762846985 accuracy 0.8454063534736633 macro_avg {'precision': 0.849900965163863, 'recall': 0.8460074205288585, 'f1-score': 0.8439324710790324, 'support': 1132} weighted_avg {'precision': 0.8542639253863423, 'recall': 0.8454063604240283, 'f1-score': 0.8457747090933558, 'support': 1132}
 
----------
Epoch 4/40
time = 773.58 secondes

Train loss 0.20227789867660573 accuracy 0.9434295892715454 macro_avg {'precision': 0.9405317590672155, 'recall': 0.9401481633333828, 'f1-score': 0.9402355111462699, 'support': 10182} weighted_avg {'precision': 0.943535975587809, 'recall': 0.943429581614614, 'f1-score': 0.9433797877924599, 'support': 10182}
 
time = 22.87 secondes

Val loss 0.7339574697781617 accuracy 0.8418728113174438 macro_avg {'precision': 0.84419152931348, 'recall': 0.8410633327348359, 'f1-score': 0.8388628420054788, 'support': 1132} weighted_avg {'precision': 0.8501978305965588, 'recall': 0.8418727915194346, 'f1-score': 0.8421960297837339, 'support': 1132}
 
----------
Epoch 5/40
time = 771.98 secondes

Train loss 0.1737769185960164 accuracy 0.9549204707145691 macro_avg {'precision': 0.9531487007597782, 'recall': 0.9528330497148285, 'f1-score': 0.952963187484175, 'support': 10182} weighted_avg {'precision': 0.9549531711986364, 'recall': 0.9549204478491455, 'f1-score': 0.9549092989161182, 'support': 10182}
 
time = 23.21 secondes

Val loss 0.9111240202393777 accuracy 0.8312720656394958 macro_avg {'precision': 0.8455761824246381, 'recall': 0.8375173263457919, 'f1-score': 0.8294228629011243, 'support': 1132} weighted_avg {'precision': 0.8537160674498004, 'recall': 0.8312720848056537, 'f1-score': 0.8300448546692971, 'support': 1132}
 
----------
Epoch 6/40
time = 773.24 secondes

Train loss 0.15160615080503345 accuracy 0.9617953300476074 macro_avg {'precision': 0.9610260638246407, 'recall': 0.9604506611626145, 'f1-score': 0.9607005253697132, 'support': 10182} weighted_avg {'precision': 0.9618160264973088, 'recall': 0.9617953250834806, 'f1-score': 0.961770041507121, 'support': 10182}
 
time = 22.85 secondes

Val loss 0.998122779804964 accuracy 0.8445229530334473 macro_avg {'precision': 0.86176540409393, 'recall': 0.8371493208463822, 'f1-score': 0.8373026897444229, 'support': 1132} weighted_avg {'precision': 0.8565802864566736, 'recall': 0.8445229681978799, 'f1-score': 0.8406369555904527, 'support': 1132}
 
----------
Epoch 7/40
time = 773.70 secondes

Train loss 0.13249409085351993 accuracy 0.9710273146629333 macro_avg {'precision': 0.9704108841346606, 'recall': 0.9700146838761171, 'f1-score': 0.9701941170730904, 'support': 10182} weighted_avg {'precision': 0.9710566094241091, 'recall': 0.9710273030838735, 'f1-score': 0.9710243416756901, 'support': 10182}
 
time = 23.08 secondes

Val loss 0.8362880445931526 accuracy 0.8639575839042664 macro_avg {'precision': 0.8681998035408321, 'recall': 0.8681591102441922, 'f1-score': 0.8645186873143812, 'support': 1132} weighted_avg {'precision': 0.8718214855734102, 'recall': 0.8639575971731449, 'f1-score': 0.8641791456507038, 'support': 1132}
 
----------
Epoch 8/40
time = 758.75 secondes

Train loss 0.13370663273675307 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684523782408114, 'recall': 0.9677270730485317, 'f1-score': 0.9680024685834953, 'support': 10182} weighted_avg {'precision': 0.9696792400102836, 'recall': 0.9696523276370065, 'f1-score': 0.9695957000383791, 'support': 10182}
 
time = 20.58 secondes

Val loss 0.8870222394192316 accuracy 0.8657243847846985 macro_avg {'precision': 0.8743692474806753, 'recall': 0.8684181330159395, 'f1-score': 0.8667837124379828, 'support': 1132} weighted_avg {'precision': 0.8780266374755173, 'recall': 0.8657243816254417, 'f1-score': 0.8671335891632083, 'support': 1132}
 
----------
Epoch 9/40
time = 698.45 secondes

Train loss 0.12476795982899147 accuracy 0.9742683172225952 macro_avg {'precision': 0.9734524805354475, 'recall': 0.9730562821113491, 'f1-score': 0.9732113025726197, 'support': 10182} weighted_avg {'precision': 0.9743408213655522, 'recall': 0.9742683166372029, 'f1-score': 0.974264383294331, 'support': 10182}
 
time = 20.01 secondes

Val loss 1.0709312920914438 accuracy 0.851590096950531 macro_avg {'precision': 0.8618469341045939, 'recall': 0.8506343820580625, 'f1-score': 0.8488575863227006, 'support': 1132} weighted_avg {'precision': 0.8606690731130928, 'recall': 0.8515901060070671, 'f1-score': 0.8488655818227334, 'support': 1132}
 
----------
Epoch 10/40
time = 699.35 secondes

Train loss 0.10657032142415952 accuracy 0.9776075482368469 macro_avg {'precision': 0.9769480650107714, 'recall': 0.9770833438378135, 'f1-score': 0.9769876055665282, 'support': 10182} weighted_avg {'precision': 0.9777417859206715, 'recall': 0.9776075427224514, 'f1-score': 0.977648333241033, 'support': 10182}
 
time = 20.72 secondes

Val loss 0.8671397315576004 accuracy 0.8772084712982178 macro_avg {'precision': 0.8790587520681088, 'recall': 0.87829477409379, 'f1-score': 0.8767878389616722, 'support': 1132} weighted_avg {'precision': 0.8815916966721384, 'recall': 0.877208480565371, 'f1-score': 0.8776737900561747, 'support': 1132}
 
----------
Epoch 11/40
time = 703.64 secondes

Train loss 0.10393895805039219 accuracy 0.9787861108779907 macro_avg {'precision': 0.9778726796861175, 'recall': 0.9780146405470868, 'f1-score': 0.9779145709832899, 'support': 10182} weighted_avg {'precision': 0.9788332416846702, 'recall': 0.9787860931054803, 'f1-score': 0.9787801712601663, 'support': 10182}
 
time = 20.65 secondes

Val loss 0.9710595562056357 accuracy 0.8692579865455627 macro_avg {'precision': 0.8718157550565303, 'recall': 0.8710751745676049, 'f1-score': 0.8684620167480812, 'support': 1132} weighted_avg {'precision': 0.8777388931596417, 'recall': 0.8692579505300353, 'f1-score': 0.8704451067827041, 'support': 1132}
 
----------
Epoch 12/40
time = 689.91 secondes

Train loss 0.10528037115589575 accuracy 0.9807503819465637 macro_avg {'precision': 0.9804643394641822, 'recall': 0.9802863378013882, 'f1-score': 0.9803451952507197, 'support': 10182} weighted_avg {'precision': 0.9808097000871195, 'recall': 0.9807503437438617, 'f1-score': 0.980748975135919, 'support': 10182}
 
time = 20.74 secondes

Val loss 1.2224667010100028 accuracy 0.8312720656394958 macro_avg {'precision': 0.864524379948219, 'recall': 0.8297763668257702, 'f1-score': 0.8267850206468976, 'support': 1132} weighted_avg {'precision': 0.8595217923061619, 'recall': 0.8312720848056537, 'f1-score': 0.8265133905669328, 'support': 1132}
 
----------
Epoch 13/40
time = 700.54 secondes

Train loss 0.09644961703639607 accuracy 0.9803575277328491 macro_avg {'precision': 0.9800837171113825, 'recall': 0.9802778822976173, 'f1-score': 0.980135990312105, 'support': 10182} weighted_avg {'precision': 0.9804062785539409, 'recall': 0.9803574936161854, 'f1-score': 0.9803358166878084, 'support': 10182}
 
time = 21.35 secondes

Val loss 0.9216421468471977 accuracy 0.8780918717384338 macro_avg {'precision': 0.8812960716770168, 'recall': 0.8822794153471014, 'f1-score': 0.8793194896482628, 'support': 1132} weighted_avg {'precision': 0.8859058558683396, 'recall': 0.8780918727915195, 'f1-score': 0.8794953527575989, 'support': 1132}
 
----------
Epoch 14/40
time = 699.16 secondes

Train loss 0.09607161275642775 accuracy 0.9819289445877075 macro_avg {'precision': 0.9822522626749933, 'recall': 0.9820770697621208, 'f1-score': 0.982131037783696, 'support': 10182} weighted_avg {'precision': 0.9820279917307982, 'recall': 0.9819288941268906, 'f1-score': 0.9819440098992143, 'support': 10182}
 
time = 20.95 secondes

Val loss 0.9335599796425118 accuracy 0.8745583295822144 macro_avg {'precision': 0.8852245172900725, 'recall': 0.877608305894492, 'f1-score': 0.8777894613070318, 'support': 1132} weighted_avg {'precision': 0.8844214411749265, 'recall': 0.8745583038869258, 'f1-score': 0.8757253421009883, 'support': 1132}
 
----------
Epoch 15/40
time = 682.30 secondes

Train loss 0.08353636490348401 accuracy 0.9842860102653503 macro_avg {'precision': 0.9835806520904248, 'recall': 0.9834871336192673, 'f1-score': 0.983525805895978, 'support': 10182} weighted_avg {'precision': 0.9843032987367522, 'recall': 0.9842859948929483, 'f1-score': 0.984286306191619, 'support': 10182}
 
time = 20.20 secondes

Val loss 1.0414238832224878 accuracy 0.8657243847846985 macro_avg {'precision': 0.8778192106122139, 'recall': 0.8683858423141085, 'f1-score': 0.8692654664556635, 'support': 1132} weighted_avg {'precision': 0.876649614312357, 'recall': 0.8657243816254417, 'f1-score': 0.8673841186677678, 'support': 1132}
 
----------
Epoch 16/40
time = 705.24 secondes

Train loss 0.07256669544100303 accuracy 0.9866431355476379 macro_avg {'precision': 0.9864878620742441, 'recall': 0.9865670335622065, 'f1-score': 0.9865045910052166, 'support': 10182} weighted_avg {'precision': 0.9866826645012108, 'recall': 0.9866430956590061, 'f1-score': 0.9866393863813295, 'support': 10182}
 
time = 21.48 secondes

Val loss 1.0761123847791885 accuracy 0.8666077852249146 macro_avg {'precision': 0.8857127917157939, 'recall': 0.87050924793125, 'f1-score': 0.8694601701336022, 'support': 1132} weighted_avg {'precision': 0.8877783722129482, 'recall': 0.8666077738515902, 'f1-score': 0.8681293463513361, 'support': 1132}
 
----------
Epoch 17/40
time = 703.86 secondes

Train loss 0.08226310823394078 accuracy 0.9863485097885132 macro_avg {'precision': 0.9860862812453279, 'recall': 0.9859821072805651, 'f1-score': 0.9860092044452424, 'support': 10182} weighted_avg {'precision': 0.9863694605782292, 'recall': 0.9863484580632489, 'f1-score': 0.9863330161665136, 'support': 10182}
 
time = 21.00 secondes

Val loss 0.9512951463068635 accuracy 0.880742073059082 macro_avg {'precision': 0.8892570711515984, 'recall': 0.8838023447508127, 'f1-score': 0.8837065412596324, 'support': 1132} weighted_avg {'precision': 0.8885338818820876, 'recall': 0.8807420494699647, 'f1-score': 0.8815531069712201, 'support': 1132}
 
----------
Epoch 18/40
time = 706.69 secondes

Train loss 0.06583956096286986 accuracy 0.9883127212524414 macro_avg {'precision': 0.9879759745271921, 'recall': 0.9880367845986097, 'f1-score': 0.9879990604833886, 'support': 10182} weighted_avg {'precision': 0.9883356887909751, 'recall': 0.9883127087016303, 'f1-score': 0.9883171167043273, 'support': 10182}
 
time = 21.26 secondes

Val loss 0.9716631421289722 accuracy 0.8851590156555176 macro_avg {'precision': 0.8907503671755105, 'recall': 0.8885455190564968, 'f1-score': 0.8876144829445867, 'support': 1132} weighted_avg {'precision': 0.8920035777982743, 'recall': 0.8851590106007067, 'f1-score': 0.8865040684979207, 'support': 1132}
 
----------
Epoch 19/40
time = 704.69 secondes

Train loss 0.07458173049252617 accuracy 0.9871341586112976 macro_avg {'precision': 0.9866151935998693, 'recall': 0.9870062654443321, 'f1-score': 0.9867909347428755, 'support': 10182} weighted_avg {'precision': 0.9871751911790048, 'recall': 0.9871341583186014, 'f1-score': 0.9871380597195486, 'support': 10182}
 
time = 21.43 secondes

Val loss 1.0510698059446901 accuracy 0.8736749291419983 macro_avg {'precision': 0.8770775055974511, 'recall': 0.8788532085496559, 'f1-score': 0.8745193566255486, 'support': 1132} weighted_avg {'precision': 0.8812584546811169, 'recall': 0.8736749116607774, 'f1-score': 0.8739535981005717, 'support': 1132}
 
----------
Epoch 20/40
time = 712.92 secondes

Train loss 0.05827744971126093 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885058858070346, 'recall': 0.9885540060536595, 'f1-score': 0.9885183032362466, 'support': 10182} weighted_avg {'precision': 0.9888337480645996, 'recall': 0.9888037713612257, 'f1-score': 0.9888071670813554, 'support': 10182}
 
time = 22.73 secondes

Val loss 0.9113514228915782 accuracy 0.8754417300224304 macro_avg {'precision': 0.8783642542057297, 'recall': 0.8811695663990241, 'f1-score': 0.8768913572358479, 'support': 1132} weighted_avg {'precision': 0.88027049403999, 'recall': 0.8754416961130742, 'f1-score': 0.874989055526413, 'support': 1132}
 
----------
Epoch 21/40
time = 713.83 secondes

Train loss 0.05414249188574364 accuracy 0.9899823665618896 macro_avg {'precision': 0.9896811373235022, 'recall': 0.9896857934266231, 'f1-score': 0.9896766156350276, 'support': 10182} weighted_avg {'precision': 0.9899830158296052, 'recall': 0.9899823217442546, 'f1-score': 0.989975721491508, 'support': 10182}
 
time = 23.13 secondes

Val loss 0.9406612613523284 accuracy 0.8833922147750854 macro_avg {'precision': 0.8864774228495398, 'recall': 0.8868482932133638, 'f1-score': 0.8845347749620582, 'support': 1132} weighted_avg {'precision': 0.8880506029243672, 'recall': 0.8833922261484098, 'f1-score': 0.8834232818629714, 'support': 1132}
 
----------
Epoch 22/40
time = 709.07 secondes

Train loss 0.06321538336166756 accuracy 0.9888038039207458 macro_avg {'precision': 0.9885349925498985, 'recall': 0.988619905777308, 'f1-score': 0.9885633007210728, 'support': 10182} weighted_avg {'precision': 0.9888276773514048, 'recall': 0.9888037713612257, 'f1-score': 0.9888017059262472, 'support': 10182}
 
time = 22.23 secondes

Val loss 0.9494373546134431 accuracy 0.8904593586921692 macro_avg {'precision': 0.8964239749844956, 'recall': 0.8922292994369618, 'f1-score': 0.891969584475252, 'support': 1132} weighted_avg {'precision': 0.8951258398891432, 'recall': 0.8904593639575972, 'f1-score': 0.8904251473573744, 'support': 1132}
 
----------
Epoch 23/40
time = 691.88 secondes

Train loss 0.04857952967429116 accuracy 0.9911609292030334 macro_avg {'precision': 0.9907975937648537, 'recall': 0.990839082682229, 'f1-score': 0.990810605221346, 'support': 10182} weighted_avg {'precision': 0.9911795119385237, 'recall': 0.9911608721272834, 'f1-score': 0.9911627469753196, 'support': 10182}
 
time = 20.71 secondes

Val loss 0.9655102952009413 accuracy 0.8833922147750854 macro_avg {'precision': 0.8886718481419615, 'recall': 0.8870599470472408, 'f1-score': 0.8857946870419733, 'support': 1132} weighted_avg {'precision': 0.8903540304441377, 'recall': 0.8833922261484098, 'f1-score': 0.8847178543076476, 'support': 1132}
 
----------
Epoch 24/40
time = 699.92 secondes

Train loss 0.0450729193765154 accuracy 0.9923394322395325 macro_avg {'precision': 0.9924901388510726, 'recall': 0.9924470850931696, 'f1-score': 0.9924512443871001, 'support': 10182} weighted_avg {'precision': 0.9923676629113869, 'recall': 0.9923394225103123, 'f1-score': 0.9923355509710997, 'support': 10182}
 
time = 19.41 secondes

Val loss 0.836745535082128 accuracy 0.880742073059082 macro_avg {'precision': 0.8880632550218042, 'recall': 0.8885674242227573, 'f1-score': 0.8836372572968904, 'support': 1132} weighted_avg {'precision': 0.8890579400123074, 'recall': 0.8807420494699647, 'f1-score': 0.8798031601983608, 'support': 1132}
 
----------
Epoch 25/40
time = 696.96 secondes

Train loss 0.041573701396991736 accuracy 0.9928305149078369 macro_avg {'precision': 0.9926707685663384, 'recall': 0.9927095162963937, 'f1-score': 0.9926770180932033, 'support': 10182} weighted_avg {'precision': 0.9928525212902264, 'recall': 0.9928304851699077, 'f1-score': 0.9928280889061362, 'support': 10182}
 
time = 20.79 secondes

Val loss 0.9172713470946126 accuracy 0.8904593586921692 macro_avg {'precision': 0.8977775497432579, 'recall': 0.8930249060989794, 'f1-score': 0.8929279155286448, 'support': 1132} weighted_avg {'precision': 0.8981227098162188, 'recall': 0.8904593639575972, 'f1-score': 0.8919707046493922, 'support': 1132}
 
----------
Epoch 26/40
time = 695.29 secondes

Train loss 0.051566629921358166 accuracy 0.9921430349349976 macro_avg {'precision': 0.9918855819986678, 'recall': 0.9919605736432617, 'f1-score': 0.9919130991547908, 'support': 10182} weighted_avg {'precision': 0.9921668416481433, 'recall': 0.9921429974464742, 'f1-score': 0.9921450926916305, 'support': 10182}
 
time = 20.91 secondes

Val loss 0.8739972566411228 accuracy 0.898409903049469 macro_avg {'precision': 0.9012356060438425, 'recall': 0.9031105712105127, 'f1-score': 0.8998764371975436, 'support': 1132} weighted_avg {'precision': 0.9034981314415198, 'recall': 0.8984098939929329, 'f1-score': 0.898513288727122, 'support': 1132}
 
----------
Epoch 27/40
time = 701.29 secondes

Train loss 0.03362585368210504 accuracy 0.993812620639801 macro_avg {'precision': 0.9936813701782633, 'recall': 0.993651087279944, 'f1-score': 0.9936605836350786, 'support': 10182} weighted_avg {'precision': 0.9938260102210492, 'recall': 0.9938126104890984, 'f1-score': 0.993813584954164, 'support': 10182}
 
time = 21.78 secondes

Val loss 0.9841584200487336 accuracy 0.8869258165359497 macro_avg {'precision': 0.8928491765519961, 'recall': 0.8895534368326056, 'f1-score': 0.8884768804384828, 'support': 1132} weighted_avg {'precision': 0.8940190248694975, 'recall': 0.8869257950530035, 'f1-score': 0.8876188808040355, 'support': 1132}
 
----------
Epoch 28/40
time = 712.54 secondes

Train loss 0.03560435815925131 accuracy 0.9941073060035706 macro_avg {'precision': 0.993901640495395, 'recall': 0.9940760487261853, 'f1-score': 0.9939835844048668, 'support': 10182} weighted_avg {'precision': 0.9941153024384927, 'recall': 0.9941072480848556, 'f1-score': 0.9941063078036233, 'support': 10182}
 
time = 22.65 secondes

Val loss 0.907973636499943 accuracy 0.8922261595726013 macro_avg {'precision': 0.8986013058814274, 'recall': 0.8947767306738778, 'f1-score': 0.8944735758358444, 'support': 1132} weighted_avg {'precision': 0.8970462600507981, 'recall': 0.892226148409894, 'f1-score': 0.8923185442350859, 'support': 1132}
 
----------
Epoch 29/40
time = 711.03 secondes

Train loss 0.0322029616904022 accuracy 0.9944019317626953 macro_avg {'precision': 0.9942696711601255, 'recall': 0.9943981985336577, 'f1-score': 0.9943275607647631, 'support': 10182} weighted_avg {'precision': 0.9944133378799135, 'recall': 0.9944018856806128, 'f1-score': 0.9944018538096763, 'support': 10182}
 
time = 22.86 secondes

Val loss 1.0846933569888457 accuracy 0.8736749291419983 macro_avg {'precision': 0.9032072288139238, 'recall': 0.8766037779772992, 'f1-score': 0.8835065943098448, 'support': 1132} weighted_avg {'precision': 0.8997056982124427, 'recall': 0.8736749116607774, 'f1-score': 0.8796482107509905, 'support': 1132}
 
----------
Epoch 30/40
time = 714.34 secondes

Train loss 0.04390207801046144 accuracy 0.9927322864532471 macro_avg {'precision': 0.9928927709334676, 'recall': 0.9927686700216203, 'f1-score': 0.9928191125276473, 'support': 10182} weighted_avg {'precision': 0.992759222675427, 'recall': 0.9927322726379886, 'f1-score': 0.9927339674971646, 'support': 10182}
 
time = 23.52 secondes

Val loss 0.97769883338338 accuracy 0.8895759582519531 macro_avg {'precision': 0.8999506151752122, 'recall': 0.8932693509929666, 'f1-score': 0.8933086365215439, 'support': 1132} weighted_avg {'precision': 0.899727154883964, 'recall': 0.8895759717314488, 'f1-score': 0.8911901160520143, 'support': 1132}
 
----------
Epoch 31/40
time = 713.65 secondes

Train loss 0.03768539344519998 accuracy 0.9939108490943909 macro_avg {'precision': 0.9940811145014619, 'recall': 0.9940208663248304, 'f1-score': 0.9940416375339247, 'support': 10182} weighted_avg {'precision': 0.9939334031716122, 'recall': 0.9939108230210175, 'f1-score': 0.9939124582771408, 'support': 10182}
 
time = 23.38 secondes

Val loss 1.0496889290219078 accuracy 0.8860424160957336 macro_avg {'precision': 0.8906881951325689, 'recall': 0.8883084314455004, 'f1-score': 0.8868118834854863, 'support': 1132} weighted_avg {'precision': 0.8919113180176217, 'recall': 0.8860424028268551, 'f1-score': 0.8862005230438254, 'support': 1132}
 
----------
Epoch 32/40
time = 653.77 secondes

Train loss 0.02706357283376471 accuracy 0.9950894117355347 macro_avg {'precision': 0.9952409133951537, 'recall': 0.9951504626502177, 'f1-score': 0.9951884939765808, 'support': 10182} weighted_avg {'precision': 0.9951138158768448, 'recall': 0.9950893734040464, 'f1-score': 0.995094267219817, 'support': 10182}
 
time = 18.80 secondes

Val loss 0.9302681963955353 accuracy 0.8931095600128174 macro_avg {'precision': 0.8928497230841828, 'recall': 0.8957077229084442, 'f1-score': 0.8927317692573087, 'support': 1132} weighted_avg {'precision': 0.8962022591747876, 'recall': 0.8931095406360424, 'f1-score': 0.893076508444322, 'support': 1132}
 
----------
Epoch 33/40
time = 683.45 secondes

Train loss 0.025361298259636407 accuracy 0.9960715174674988 macro_avg {'precision': 0.9959508938265327, 'recall': 0.9959884946603067, 'f1-score': 0.9959655254919765, 'support': 10182} weighted_avg {'precision': 0.9960741844524214, 'recall': 0.9960714987232371, 'f1-score': 0.9960685545101935, 'support': 10182}
 
time = 18.55 secondes

Val loss 1.0081298280417965 accuracy 0.8913427591323853 macro_avg {'precision': 0.9023920959352804, 'recall': 0.8917292988200985, 'f1-score': 0.894601658931505, 'support': 1132} weighted_avg {'precision': 0.9008028136990566, 'recall': 0.8913427561837456, 'f1-score': 0.8934007229770258, 'support': 1132}
 
----------
Epoch 34/40
time = 678.98 secondes

Train loss 0.025458554901564314 accuracy 0.9963661432266235 macro_avg {'precision': 0.9964063705808023, 'recall': 0.9962222254469509, 'f1-score': 0.9963042095751732, 'support': 10182} weighted_avg {'precision': 0.9963930880506273, 'recall': 0.9963661363189943, 'f1-score': 0.9963695133467236, 'support': 10182}
 
time = 22.45 secondes

Val loss 0.9037004050345863 accuracy 0.9010601043701172 macro_avg {'precision': 0.9040137393888521, 'recall': 0.904111122935673, 'f1-score': 0.9021453306483747, 'support': 1132} weighted_avg {'precision': 0.9062686449108778, 'recall': 0.901060070671378, 'f1-score': 0.9015265011929081, 'support': 1132}
 
----------
Epoch 35/40
time = 682.30 secondes

Train loss 0.019751426164674023 accuracy 0.9969554543495178 macro_avg {'precision': 0.9970698626179555, 'recall': 0.997047539246241, 'f1-score': 0.9970550599423305, 'support': 10182} weighted_avg {'precision': 0.9969624559255742, 'recall': 0.9969554115105087, 'f1-score': 0.996955171732931, 'support': 10182}
 
time = 19.71 secondes

Val loss 0.9164097473412894 accuracy 0.898409903049469 macro_avg {'precision': 0.9033335063455921, 'recall': 0.9002338099032864, 'f1-score': 0.8995990886469393, 'support': 1132} weighted_avg {'precision': 0.9055019949002336, 'recall': 0.8984098939929329, 'f1-score': 0.8996726968246683, 'support': 1132}
 
----------
Epoch 36/40
time = 651.33 secondes

Train loss 0.015566366553085263 accuracy 0.9974464774131775 macro_avg {'precision': 0.9974816972709475, 'recall': 0.9975090592363942, 'f1-score': 0.9974938102139564, 'support': 10182} weighted_avg {'precision': 0.9974522002547943, 'recall': 0.9974464741701041, 'f1-score': 0.9974477393460691, 'support': 10182}
 
time = 16.49 secondes

Val loss 0.8430173347981214 accuracy 0.9045936465263367 macro_avg {'precision': 0.9088606239398981, 'recall': 0.9067041708807878, 'f1-score': 0.9060410874843683, 'support': 1132} weighted_avg {'precision': 0.9103726613330795, 'recall': 0.9045936395759717, 'f1-score': 0.9056116676543543, 'support': 1132}
 
----------
Epoch 37/40
time = 630.80 secondes

Train loss 0.008411392220468727 accuracy 0.9981340169906616 macro_avg {'precision': 0.9981792721550404, 'recall': 0.9981675830676011, 'f1-score': 0.9981718137996921, 'support': 10182} weighted_avg {'precision': 0.9981370987829821, 'recall': 0.9981339618935376, 'f1-score': 0.9981338602150323, 'support': 10182}
 
time = 17.78 secondes

Val loss 0.8666398737408548 accuracy 0.9072438478469849 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}
 
----------
Epoch 38/40
time = 657.08 secondes

Train loss 0.00363665757710664 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991479970546828, 'recall': 0.9991442419023459, 'f1-score': 0.999145760441634, 'support': 10182} weighted_avg {'precision': 0.999116631275601, 'recall': 0.9991160872127284, 'f1-score': 0.9991159874346697, 'support': 10182}
 
time = 20.75 secondes

Val loss 0.9295898494970637 accuracy 0.9028268456459045 macro_avg {'precision': 0.9060399377803906, 'recall': 0.9056944083481362, 'f1-score': 0.9044988995544063, 'support': 1132} weighted_avg {'precision': 0.9065984939144717, 'recall': 0.9028268551236749, 'f1-score': 0.9032727859370949, 'support': 1132}
 
----------
Epoch 39/40
time = 735.68 secondes

Train loss 0.0073776574524289365 accuracy 0.998821496963501 macro_avg {'precision': 0.9988446447385501, 'recall': 0.9988559297558119, 'f1-score': 0.9988491227300283, 'support': 10182} weighted_avg {'precision': 0.9988234807892794, 'recall': 0.9988214496169712, 'f1-score': 0.9988212604229645, 'support': 10182}
 
time = 20.87 secondes

Val loss 0.9766664895803739 accuracy 0.8992933034896851 macro_avg {'precision': 0.9031340386036965, 'recall': 0.9028152435072675, 'f1-score': 0.901175336518987, 'support': 1132} weighted_avg {'precision': 0.9035455724944119, 'recall': 0.8992932862190812, 'f1-score': 0.8994590099560085, 'support': 1132}
 
----------
Epoch 40/40
time = 733.80 secondes

Train loss 0.0013381021140298549 accuracy 0.9996072053909302 macro_avg {'precision': 0.999619535206102, 'recall': 0.9996171073534079, 'f1-score': 0.9996180539138934, 'support': 10182} weighted_avg {'precision': 0.9996077034874572, 'recall': 0.9996071498723237, 'f1-score': 0.9996071486778729, 'support': 10182}
 
time = 20.86 secondes

Val loss 0.9683842703135512 accuracy 0.9001767039299011 macro_avg {'precision': 0.9049967233911268, 'recall': 0.9031661481628822, 'f1-score': 0.9025115850836439, 'support': 1132} weighted_avg {'precision': 0.9047317864972204, 'recall': 0.9001766784452296, 'f1-score': 0.9007451703857408, 'support': 1132}
 
----------
best_accuracy 0.9072438478469849 best_epoch 37 macro_avg {'precision': 0.9118723678580405, 'recall': 0.9101344267095748, 'f1-score': 0.909528075682983, 'support': 1132} weighted_avg {'precision': 0.9114943870301233, 'recall': 0.907243816254417, 'f1-score': 0.9078113677401176, 'support': 1132}

average train time 710.1203987717629

average val time 21.27267496585846
 
time = 136.86 secondes

test_accuracy 0.8296601176261902 macro_avg {'precision': 0.8261694392580499, 'recall': 0.8224345462904866, 'f1-score': 0.8221196564902696, 'support': 7532} weighted_avg {'precision': 0.8336363981546475, 'recall': 0.829660116834838, 'f1-score': 0.8295233448050705, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_1024_128_4
----------
Epoch 1/40
Attention type 'block_sparse' is not possible if sequence_length: 1024 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 1408 with config.block_size = 128, config.num_random_blocks = 3. Changing attention type to 'original_full'...
time = 488.17 secondes

Train loss 1.372230394902746 accuracy 0.6279709339141846 macro_avg {'precision': 0.6134986424362526, 'recall': 0.6129635552418231, 'f1-score': 0.6060368639532894, 'support': 10182} weighted_avg {'precision': 0.6262844028878005, 'recall': 0.627970929090552, 'f1-score': 0.6205845935912996, 'support': 10182}
 
time = 13.61 secondes

/usr/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss 0.7827829303036273 accuracy 0.7588339447975159 macro_avg {'precision': 0.7414010329079515, 'recall': 0.7519130459253796, 'f1-score': 0.739521506874756, 'support': 1132} weighted_avg {'precision': 0.7486685046889161, 'recall': 0.758833922261484, 'f1-score': 0.7457319008112446, 'support': 1132}
 
----------
Epoch 2/40
time = 489.15 secondes

Train loss 0.5661003756420204 accuracy 0.827440619468689 macro_avg {'precision': 0.8147678466302217, 'recall': 0.8158370966826813, 'f1-score': 0.8124413299970389, 'support': 10182} weighted_avg {'precision': 0.8230306057456931, 'recall': 0.827440581418189, 'f1-score': 0.8231434523553137, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.6228134159890699 accuracy 0.8127208352088928 macro_avg {'precision': 0.8184673457899517, 'recall': 0.809688721738919, 'f1-score': 0.8083539561335371, 'support': 1132} weighted_avg {'precision': 0.8247300743455266, 'recall': 0.8127208480565371, 'f1-score': 0.8126672420729907, 'support': 1132}
 
----------
Epoch 3/40
time = 491.28 secondes

Train loss 0.33805252711348577 accuracy 0.9015910625457764 macro_avg {'precision': 0.8957571854167836, 'recall': 0.8953094824603985, 'f1-score': 0.895339588984726, 'support': 10182} weighted_avg {'precision': 0.9010649766918674, 'recall': 0.901591043017089, 'f1-score': 0.9011625070151672, 'support': 10182}
 
time = 17.79 secondes

Val loss 0.5765100382006084 accuracy 0.843639612197876 macro_avg {'precision': 0.8421845395505955, 'recall': 0.8433724466720106, 'f1-score': 0.8400549172690479, 'support': 1132} weighted_avg {'precision': 0.8484319877702833, 'recall': 0.8436395759717314, 'f1-score': 0.8432237679969962, 'support': 1132}
 
----------
Epoch 4/40
time = 491.14 secondes

Train loss 0.2288811775070602 accuracy 0.9349833130836487 macro_avg {'precision': 0.9312153196858393, 'recall': 0.9310185014458814, 'f1-score': 0.9310589110266136, 'support': 10182} weighted_avg {'precision': 0.9350689782123511, 'recall': 0.9349833038695737, 'f1-score': 0.9349687755698205, 'support': 10182}
 
time = 17.83 secondes

Val loss 0.5590408811227642 accuracy 0.880742073059082 macro_avg {'precision': 0.8845080012108, 'recall': 0.882472471066747, 'f1-score': 0.881267876937239, 'support': 1132} weighted_avg {'precision': 0.886225079068045, 'recall': 0.8807420494699647, 'f1-score': 0.8810748498825536, 'support': 1132}
 
----------
Epoch 5/40
time = 490.57 secondes

Train loss 0.1857722676421254 accuracy 0.9504026770591736 macro_avg {'precision': 0.9480834602951884, 'recall': 0.9485453763437274, 'f1-score': 0.9482459793105406, 'support': 10182} weighted_avg {'precision': 0.950653561700645, 'recall': 0.9504026713808682, 'f1-score': 0.9504711492450918, 'support': 10182}
 
time = 15.60 secondes

Val loss 0.7408904056163164 accuracy 0.8551236987113953 macro_avg {'precision': 0.8611180769010952, 'recall': 0.854606225684463, 'f1-score': 0.8522397877748296, 'support': 1132} weighted_avg {'precision': 0.8628258380080642, 'recall': 0.8551236749116607, 'f1-score': 0.8533244085846735, 'support': 1132}
 
----------
Epoch 6/40
time = 490.37 secondes

Train loss 0.15462405650527034 accuracy 0.9615989327430725 macro_avg {'precision': 0.9598932908325567, 'recall': 0.9599465519921091, 'f1-score': 0.9598828051434406, 'support': 10182} weighted_avg {'precision': 0.9616245166317874, 'recall': 0.9615989000196425, 'f1-score': 0.9615741195984013, 'support': 10182}
 
time = 13.76 secondes

Val loss 0.7150365061341444 accuracy 0.8754417300224304 macro_avg {'precision': 0.878739346260199, 'recall': 0.8760024770493183, 'f1-score': 0.8734891524807982, 'support': 1132} weighted_avg {'precision': 0.8820861260425824, 'recall': 0.8754416961130742, 'f1-score': 0.8752574340459215, 'support': 1132}
 
----------
Epoch 7/40
time = 494.37 secondes

Train loss 0.14585145360540183 accuracy 0.9639560580253601 macro_avg {'precision': 0.9623347317696279, 'recall': 0.9622403292495353, 'f1-score': 0.9622596178820302, 'support': 10182} weighted_avg {'precision': 0.9640556077331855, 'recall': 0.9639560007857002, 'f1-score': 0.9639770889392808, 'support': 10182}
 
time = 14.09 secondes

Val loss 0.8331980400269484 accuracy 0.8613074421882629 macro_avg {'precision': 0.868494389634822, 'recall': 0.8573161469789887, 'f1-score': 0.8581150544115875, 'support': 1132} weighted_avg {'precision': 0.8682268049920878, 'recall': 0.8613074204946997, 'f1-score': 0.859760914451488, 'support': 1132}
 
----------
Epoch 8/40
time = 487.60 secondes

Train loss 0.1186752834756094 accuracy 0.9718130230903625 macro_avg {'precision': 0.9713017162299213, 'recall': 0.9707824655697375, 'f1-score': 0.9710097538676095, 'support': 10182} weighted_avg {'precision': 0.9718727633802077, 'recall': 0.971813003339226, 'f1-score': 0.9718136489595701, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.8462979193300527 accuracy 0.8630741834640503 macro_avg {'precision': 0.8725732539327089, 'recall': 0.8673504791744057, 'f1-score': 0.8663530343110819, 'support': 1132} weighted_avg {'precision': 0.872618110774337, 'recall': 0.8630742049469965, 'f1-score': 0.8640104617219612, 'support': 1132}
 
----------
Epoch 9/40
time = 488.58 secondes

Train loss 0.11825049903272655 accuracy 0.9743665456771851 macro_avg {'precision': 0.9740086854920506, 'recall': 0.974112404271855, 'f1-score': 0.9740159629028021, 'support': 10182} weighted_avg {'precision': 0.974465338982123, 'recall': 0.974366529169122, 'f1-score': 0.9743709731066372, 'support': 10182}
 
time = 16.43 secondes

Val loss 0.9256451609122246 accuracy 0.8639575839042664 macro_avg {'precision': 0.8824459459285106, 'recall': 0.8625915616704909, 'f1-score': 0.8619694083914471, 'support': 1132} weighted_avg {'precision': 0.8806347128863042, 'recall': 0.8639575971731449, 'f1-score': 0.8620541476430885, 'support': 1132}
 
----------
Epoch 10/40
time = 486.19 secondes

Train loss 0.11346419836974556 accuracy 0.9750540256500244 macro_avg {'precision': 0.97450725055481, 'recall': 0.9743253265364838, 'f1-score': 0.9743980761514989, 'support': 10182} weighted_avg {'precision': 0.9750587087134146, 'recall': 0.9750540168925554, 'f1-score': 0.9750386996645554, 'support': 10182}
 
time = 16.46 secondes

Val loss 0.8181793919307816 accuracy 0.8816254734992981 macro_avg {'precision': 0.8870936772739799, 'recall': 0.8787759075554369, 'f1-score': 0.8796876771208831, 'support': 1132} weighted_avg {'precision': 0.8868924462024713, 'recall': 0.8816254416961131, 'f1-score': 0.8812846585930596, 'support': 1132}
 
----------
Epoch 11/40
time = 486.58 secondes

Train loss 0.10685138974943782 accuracy 0.9750540256500244 macro_avg {'precision': 0.9741895940350366, 'recall': 0.9740720774068772, 'f1-score': 0.9740559897593369, 'support': 10182} weighted_avg {'precision': 0.9751324577830939, 'recall': 0.9750540168925554, 'f1-score': 0.9750184803027615, 'support': 10182}
 
time = 16.71 secondes

Val loss 0.7958596906719835 accuracy 0.8833922147750854 macro_avg {'precision': 0.8881437786434876, 'recall': 0.8858844799921325, 'f1-score': 0.8836898021982268, 'support': 1132} weighted_avg {'precision': 0.8926884265146741, 'recall': 0.8833922261484098, 'f1-score': 0.8848140538233903, 'support': 1132}
 
----------
Epoch 12/40
time = 506.69 secondes

Train loss 0.10075849265040077 accuracy 0.9801610708236694 macro_avg {'precision': 0.9797901599964524, 'recall': 0.9797899321281885, 'f1-score': 0.9797558861134699, 'support': 10182} weighted_avg {'precision': 0.9802004472266795, 'recall': 0.9801610685523473, 'f1-score': 0.9801461661898113, 'support': 10182}
 
time = 14.34 secondes

Val loss 0.9541186206231327 accuracy 0.879858672618866 macro_avg {'precision': 0.8828713936030749, 'recall': 0.8784922752829685, 'f1-score': 0.8778538292449707, 'support': 1132} weighted_avg {'precision': 0.8856776000815779, 'recall': 0.8798586572438163, 'f1-score': 0.8797755253078842, 'support': 1132}
 
----------
Epoch 13/40
time = 488.93 secondes

Train loss 0.10441090892515148 accuracy 0.9802592992782593 macro_avg {'precision': 0.9794845718966325, 'recall': 0.9797048143007034, 'f1-score': 0.9795638484449899, 'support': 10182} weighted_avg {'precision': 0.9803275513052511, 'recall': 0.9802592810842663, 'f1-score': 0.9802628398848975, 'support': 10182}
 
time = 14.75 secondes

Val loss 0.8988799220143693 accuracy 0.8745583295822144 macro_avg {'precision': 0.8814277598646584, 'recall': 0.8738627496219035, 'f1-score': 0.8739511900593356, 'support': 1132} weighted_avg {'precision': 0.8858681322468805, 'recall': 0.8745583038869258, 'f1-score': 0.876847167364503, 'support': 1132}
 
----------
Epoch 14/40
time = 489.73 secondes

Train loss 0.08451853798011269 accuracy 0.9827145934104919 macro_avg {'precision': 0.9823634188430204, 'recall': 0.9824499123150842, 'f1-score': 0.9823833808999947, 'support': 10182} weighted_avg {'precision': 0.9827651600725505, 'recall': 0.9827145943822432, 'f1-score': 0.9827185574201125, 'support': 10182}
 
time = 18.26 secondes

Val loss 1.005025987142392 accuracy 0.8666077852249146 macro_avg {'precision': 0.8707890007422545, 'recall': 0.8623199144754998, 'f1-score': 0.8620408912045308, 'support': 1132} weighted_avg {'precision': 0.8717789109663399, 'recall': 0.8666077738515902, 'f1-score': 0.8647975551135907, 'support': 1132}
 
----------
Epoch 15/40
time = 491.91 secondes

Train loss 0.09230599000317968 accuracy 0.9824199676513672 macro_avg {'precision': 0.9823548887811533, 'recall': 0.9823786354922104, 'f1-score': 0.9823358200226784, 'support': 10182} weighted_avg {'precision': 0.9825093061296726, 'recall': 0.982419956786486, 'f1-score': 0.9824330277513538, 'support': 10182}
 
time = 18.04 secondes

Val loss 0.7845906613662701 accuracy 0.8851590156555176 macro_avg {'precision': 0.8951839296464218, 'recall': 0.8860687816631868, 'f1-score': 0.8875806482059341, 'support': 1132} weighted_avg {'precision': 0.8934525128527322, 'recall': 0.8851590106007067, 'f1-score': 0.8864657235022194, 'support': 1132}
 
----------
Epoch 16/40
time = 487.17 secondes

Train loss 0.08120033956571945 accuracy 0.9857591986656189 macro_avg {'precision': 0.9856007649918759, 'recall': 0.985589411973374, 'f1-score': 0.9855879929316487, 'support': 10182} weighted_avg {'precision': 0.9857882740708496, 'recall': 0.9857591828717345, 'f1-score': 0.9857664248721059, 'support': 10182}
 
time = 14.62 secondes

Val loss 0.8467162548196272 accuracy 0.8886925578117371 macro_avg {'precision': 0.8894714861259192, 'recall': 0.8910452145586675, 'f1-score': 0.8883126872628445, 'support': 1132} weighted_avg {'precision': 0.8950558166496053, 'recall': 0.8886925795053003, 'f1-score': 0.8899516681041303, 'support': 1132}
 
----------
Epoch 17/40
time = 487.28 secondes

Train loss 0.08028282645871948 accuracy 0.9842860102653503 macro_avg {'precision': 0.9845290160187709, 'recall': 0.9841880577887079, 'f1-score': 0.9843210876134163, 'support': 10182} weighted_avg {'precision': 0.9843540375810377, 'recall': 0.9842859948929483, 'f1-score': 0.9842830317126103, 'support': 10182}
 
time = 13.97 secondes

Val loss 0.9497336844923807 accuracy 0.8816254734992981 macro_avg {'precision': 0.8873666179939917, 'recall': 0.8833658572109119, 'f1-score': 0.8828998120156791, 'support': 1132} weighted_avg {'precision': 0.8886393377323234, 'recall': 0.8816254416961131, 'f1-score': 0.8825970831400709, 'support': 1132}
 
----------
Epoch 18/40
time = 490.02 secondes

Train loss 0.07437754537806691 accuracy 0.9868395328521729 macro_avg {'precision': 0.9867719032975376, 'recall': 0.9869686569225546, 'f1-score': 0.9868560537388754, 'support': 10182} weighted_avg {'precision': 0.9868616052400053, 'recall': 0.9868395207228442, 'f1-score': 0.9868369893768763, 'support': 10182}
 
time = 17.09 secondes

Val loss 0.9334095772064757 accuracy 0.8772084712982178 macro_avg {'precision': 0.8905713211610389, 'recall': 0.8806413338281516, 'f1-score': 0.8798014196876822, 'support': 1132} weighted_avg {'precision': 0.8915907330242588, 'recall': 0.877208480565371, 'f1-score': 0.8784170098739621, 'support': 1132}
 
----------
Epoch 19/40
time = 488.29 secondes

Train loss 0.09132055171308819 accuracy 0.9840896129608154 macro_avg {'precision': 0.9842839487160475, 'recall': 0.9840497680018687, 'f1-score': 0.9841323301804465, 'support': 10182} weighted_avg {'precision': 0.9841800430700687, 'recall': 0.9840895698291102, 'f1-score': 0.9840991999695425, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.8979851967291529 accuracy 0.8833922147750854 macro_avg {'precision': 0.8852721517452874, 'recall': 0.8822380930033369, 'f1-score': 0.8821195781358651, 'support': 1132} weighted_avg {'precision': 0.8869370745239983, 'recall': 0.8833922261484098, 'f1-score': 0.883579286845738, 'support': 1132}
 
----------
Epoch 20/40
time = 485.94 secondes

Train loss 0.07078124692998816 accuracy 0.9886073470115662 macro_avg {'precision': 0.9882883552952432, 'recall': 0.9885152509074665, 'f1-score': 0.9883874603655458, 'support': 10182} weighted_avg {'precision': 0.9886287808102308, 'recall': 0.9886073462973876, 'f1-score': 0.9886044643734994, 'support': 10182}
 
time = 17.05 secondes

Val loss 0.9121021994102244 accuracy 0.879858672618866 macro_avg {'precision': 0.8863520453601899, 'recall': 0.8858818411917095, 'f1-score': 0.8824003912134566, 'support': 1132} weighted_avg {'precision': 0.8907662149939454, 'recall': 0.8798586572438163, 'f1-score': 0.8814693791356971, 'support': 1132}
 
----------
Epoch 21/40
time = 487.08 secondes

Train loss 0.07294998872044513 accuracy 0.9873306155204773 macro_avg {'precision': 0.986532473077764, 'recall': 0.9865166261139251, 'f1-score': 0.9865043176403641, 'support': 10182} weighted_avg {'precision': 0.9873672841744154, 'recall': 0.9873305833824396, 'f1-score': 0.987330229957416, 'support': 10182}
 
time = 16.95 secondes

Val loss 0.8688818541219955 accuracy 0.8860424160957336 macro_avg {'precision': 0.8862351848124492, 'recall': 0.8869942262601409, 'f1-score': 0.8838019377910195, 'support': 1132} weighted_avg {'precision': 0.8907075506545076, 'recall': 0.8860424028268551, 'f1-score': 0.88573891202981, 'support': 1132}
 
----------
Epoch 22/40
time = 490.66 secondes

Train loss 0.043440933120939086 accuracy 0.9914555549621582 macro_avg {'precision': 0.9913243832135695, 'recall': 0.9911799788027315, 'f1-score': 0.9912445970561737, 'support': 10182} weighted_avg {'precision': 0.9914609482103978, 'recall': 0.9914555097230406, 'f1-score': 0.9914505544804166, 'support': 10182}
 
time = 15.58 secondes

Val loss 0.9318128447770838 accuracy 0.8878092169761658 macro_avg {'precision': 0.8963237600320598, 'recall': 0.889199630755362, 'f1-score': 0.8883786247394371, 'support': 1132} weighted_avg {'precision': 0.8956585814142959, 'recall': 0.8878091872791519, 'f1-score': 0.8875604069497222, 'support': 1132}
 
----------
Epoch 23/40
time = 491.01 secondes

Train loss 0.06255713016332239 accuracy 0.9885091781616211 macro_avg {'precision': 0.988523195874824, 'recall': 0.9882103683856995, 'f1-score': 0.988338273754849, 'support': 10182} weighted_avg {'precision': 0.9885446289318368, 'recall': 0.9885091337654685, 'f1-score': 0.9885004727756067, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.9402312323518472 accuracy 0.8878092169761658 macro_avg {'precision': 0.8987763811563193, 'recall': 0.8896794112269883, 'f1-score': 0.8910679558539568, 'support': 1132} weighted_avg {'precision': 0.8975640029252027, 'recall': 0.8878091872791519, 'f1-score': 0.8892913361189201, 'support': 1132}
 
----------
Epoch 24/40
time = 490.83 secondes

Train loss 0.055328569931412254 accuracy 0.989589512348175 macro_avg {'precision': 0.9893423849098216, 'recall': 0.9891398619656012, 'f1-score': 0.9892320066001252, 'support': 10182} weighted_avg {'precision': 0.9896097211723638, 'recall': 0.9895894716165783, 'f1-score': 0.9895909720870555, 'support': 10182}
 
time = 18.10 secondes

Val loss 0.8536099085987432 accuracy 0.8931095600128174 macro_avg {'precision': 0.8978794390144269, 'recall': 0.8952682902981536, 'f1-score': 0.8952666377968598, 'support': 1132} weighted_avg {'precision': 0.8965989555736836, 'recall': 0.8931095406360424, 'f1-score': 0.8934271640108543, 'support': 1132}
 
----------
Epoch 25/40
time = 492.02 secondes

Train loss 0.048025573856519906 accuracy 0.9914555549621582 macro_avg {'precision': 0.9910891263122237, 'recall': 0.9912474357616755, 'f1-score': 0.9911592092081717, 'support': 10182} weighted_avg {'precision': 0.9914795215813981, 'recall': 0.9914555097230406, 'f1-score': 0.9914586028952662, 'support': 10182}
 
time = 18.23 secondes

Val loss 0.9816776340711852 accuracy 0.8851590156555176 macro_avg {'precision': 0.89216978991629, 'recall': 0.8912719765222672, 'f1-score': 0.8882022192522887, 'support': 1132} weighted_avg {'precision': 0.8922891582191874, 'recall': 0.8851590106007067, 'f1-score': 0.8848010215787145, 'support': 1132}
 
----------
Epoch 26/40
time = 490.14 secondes

Train loss 0.053180109787220944 accuracy 0.9902769923210144 macro_avg {'precision': 0.9901019634156555, 'recall': 0.9899631812789288, 'f1-score': 0.9900226691265948, 'support': 10182} weighted_avg {'precision': 0.9902853722822829, 'recall': 0.9902769593400118, 'f1-score': 0.9902710489264681, 'support': 10182}
 
time = 16.04 secondes

Val loss 0.8954135703127795 accuracy 0.8948763608932495 macro_avg {'precision': 0.9032181452001661, 'recall': 0.8966401913830161, 'f1-score': 0.8983986906619524, 'support': 1132} weighted_avg {'precision': 0.8994401272587367, 'recall': 0.8948763250883393, 'f1-score': 0.8956565251777344, 'support': 1132}
 
----------
Epoch 27/40
time = 484.89 secondes

Train loss 0.042838661891403104 accuracy 0.9928305149078369 macro_avg {'precision': 0.992779989232632, 'recall': 0.9925686410324687, 'f1-score': 0.9926652998691445, 'support': 10182} weighted_avg {'precision': 0.9928536683523782, 'recall': 0.9928304851699077, 'f1-score': 0.9928332035536895, 'support': 10182}
 
time = 13.95 secondes

Val loss 0.783622395410059 accuracy 0.8957597017288208 macro_avg {'precision': 0.9053960765158007, 'recall': 0.8976766010382423, 'f1-score': 0.8994368968521333, 'support': 1132} weighted_avg {'precision': 0.9031240259548763, 'recall': 0.8957597173144877, 'f1-score': 0.8972480218915037, 'support': 1132}
 
----------
Epoch 28/40
time = 488.09 secondes

Train loss 0.04538817257733406 accuracy 0.9924376606941223 macro_avg {'precision': 0.9925276289487466, 'recall': 0.9924504435329224, 'f1-score': 0.9924583061202862, 'support': 10182} weighted_avg {'precision': 0.9924788647576538, 'recall': 0.9924376350422314, 'f1-score': 0.9924264228565537, 'support': 10182}
 
time = 14.31 secondes

Val loss 0.8187132704896241 accuracy 0.898409903049469 macro_avg {'precision': 0.9047068451525082, 'recall': 0.9011550982814628, 'f1-score': 0.9017240528964837, 'support': 1132} weighted_avg {'precision': 0.9033973202378874, 'recall': 0.8984098939929329, 'f1-score': 0.8996291268308446, 'support': 1132}
 
----------
Epoch 29/40
time = 487.02 secondes

Train loss 0.03546970920377554 accuracy 0.9936162233352661 macro_avg {'precision': 0.993438009869314, 'recall': 0.9936223354618058, 'f1-score': 0.9935193618824207, 'support': 10182} weighted_avg {'precision': 0.9936573239949072, 'recall': 0.9936161854252603, 'f1-score': 0.9936261725135686, 'support': 10182}
 
time = 17.07 secondes

Val loss 0.9601371724073571 accuracy 0.8913427591323853 macro_avg {'precision': 0.8963699808616876, 'recall': 0.8920662500095216, 'f1-score': 0.8910116232891095, 'support': 1132} weighted_avg {'precision': 0.897333147374894, 'recall': 0.8913427561837456, 'f1-score': 0.8911798464247624, 'support': 1132}
 
----------
Epoch 30/40
time = 485.73 secondes

Train loss 0.047092177982953363 accuracy 0.9927322864532471 macro_avg {'precision': 0.9926148432180856, 'recall': 0.9928958896739545, 'f1-score': 0.9927369345088103, 'support': 10182} weighted_avg {'precision': 0.9927693663149169, 'recall': 0.9927322726379886, 'f1-score': 0.9927331042465847, 'support': 10182}
 
time = 16.88 secondes

Val loss 0.8546571832748284 accuracy 0.9019434452056885 macro_avg {'precision': 0.9094320126124791, 'recall': 0.9035783027462891, 'f1-score': 0.9040339276222668, 'support': 1132} weighted_avg {'precision': 0.9082984916503419, 'recall': 0.9019434628975265, 'f1-score': 0.9025831044499247, 'support': 1132}
 
----------
Epoch 31/40
time = 486.96 secondes

Train loss 0.034184968343536494 accuracy 0.9947947859764099 macro_avg {'precision': 0.9948178065580633, 'recall': 0.9947239046346447, 'f1-score': 0.994765473560555, 'support': 10182} weighted_avg {'precision': 0.9948098324599354, 'recall': 0.9947947358082891, 'f1-score': 0.9947970880322522, 'support': 10182}
 
time = 17.00 secondes

Val loss 0.8772415368557759 accuracy 0.8975265026092529 macro_avg {'precision': 0.9010416020691002, 'recall': 0.9000388807733468, 'f1-score': 0.8983944025432467, 'support': 1132} weighted_avg {'precision': 0.9043372530067465, 'recall': 0.8975265017667845, 'f1-score': 0.8988259660448761, 'support': 1132}
 
----------
Epoch 32/40
time = 487.65 secondes

Train loss 0.02907559409452214 accuracy 0.994892954826355 macro_avg {'precision': 0.9946961216282444, 'recall': 0.9947656267053133, 'f1-score': 0.9947177909580999, 'support': 10182} weighted_avg {'precision': 0.9949175162410399, 'recall': 0.9948929483402082, 'f1-score': 0.9948926388513117, 'support': 10182}
 
time = 14.17 secondes

Val loss 0.8864078008758645 accuracy 0.9063604474067688 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}
 
----------
Epoch 33/40
time = 491.51 secondes

Train loss 0.018558030947326123 accuracy 0.9961697459220886 macro_avg {'precision': 0.9961598519809417, 'recall': 0.9962079437863531, 'f1-score': 0.9961809548320988, 'support': 10182} weighted_avg {'precision': 0.9961749802862734, 'recall': 0.9961697112551562, 'f1-score': 0.9961695639904631, 'support': 10182}
 
time = 17.70 secondes

Val loss 0.9240517644173732 accuracy 0.8948763608932495 macro_avg {'precision': 0.8992828271654106, 'recall': 0.8981555553207621, 'f1-score': 0.8970924601966054, 'support': 1132} weighted_avg {'precision': 0.8993005922681244, 'recall': 0.8948763250883393, 'f1-score': 0.8954393011399944, 'support': 1132}
 
----------
Epoch 34/40
time = 495.19 secondes

Train loss 0.015434786263873118 accuracy 0.9972500801086426 macro_avg {'precision': 0.9973201221154783, 'recall': 0.9973587430373227, 'f1-score': 0.9973356899470944, 'support': 10182} weighted_avg {'precision': 0.9972579411593034, 'recall': 0.9972500491062659, 'f1-score': 0.9972501322836794, 'support': 10182}
 
time = 14.32 secondes

Val loss 0.970689211645357 accuracy 0.9010601043701172 macro_avg {'precision': 0.9081098265003671, 'recall': 0.9048019091298014, 'f1-score': 0.9048334082347476, 'support': 1132} weighted_avg {'precision': 0.9062698197846981, 'recall': 0.901060070671378, 'f1-score': 0.9019115077892547, 'support': 1132}
 
----------
Epoch 35/40
time = 490.50 secondes

Train loss 0.015224112326950704 accuracy 0.9970536828041077 macro_avg {'precision': 0.9971078988560829, 'recall': 0.9971290395992076, 'f1-score': 0.9971160947116736, 'support': 10182} weighted_avg {'precision': 0.9970564643820542, 'recall': 0.9970536240424278, 'f1-score': 0.9970526125758338, 'support': 10182}
 
time = 13.96 secondes

Val loss 1.0586093372875836 accuracy 0.8860424160957336 macro_avg {'precision': 0.8901913220712654, 'recall': 0.8899745896660238, 'f1-score': 0.887978243966247, 'support': 1132} weighted_avg {'precision': 0.8917902826546585, 'recall': 0.8860424028268551, 'f1-score': 0.8867095002665827, 'support': 1132}
 
----------
Epoch 36/40
time = 490.58 secondes

Train loss 0.011458166437499629 accuracy 0.9976429343223572 macro_avg {'precision': 0.9977290675211758, 'recall': 0.9977344511960915, 'f1-score': 0.9977275275558508, 'support': 10182} weighted_avg {'precision': 0.9976505839908223, 'recall': 0.9976428992339422, 'f1-score': 0.9976422779565713, 'support': 10182}
 
time = 18.39 secondes

Val loss 1.0479406079636173 accuracy 0.8895759582519531 macro_avg {'precision': 0.8946014408162679, 'recall': 0.8946823636762374, 'f1-score': 0.8924248315725173, 'support': 1132} weighted_avg {'precision': 0.8951866512472697, 'recall': 0.8895759717314488, 'f1-score': 0.8900919336625984, 'support': 1132}
 
----------
Epoch 37/40
time = 491.32 secondes

Train loss 0.012433224166921986 accuracy 0.9976429343223572 macro_avg {'precision': 0.997666933043128, 'recall': 0.997660764647519, 'f1-score': 0.9976617643128012, 'support': 10182} weighted_avg {'precision': 0.997650076857833, 'recall': 0.9976428992339422, 'f1-score': 0.9976444077011188, 'support': 10182}
 
time = 13.64 secondes

Val loss 1.0875365298662716 accuracy 0.880742073059082 macro_avg {'precision': 0.8920760627723396, 'recall': 0.8828426313127318, 'f1-score': 0.883561513370473, 'support': 1132} weighted_avg {'precision': 0.8909768298742995, 'recall': 0.8807420494699647, 'f1-score': 0.8820504779987526, 'support': 1132}
 
----------
Epoch 38/40
time = 486.75 secondes

Train loss 0.00736699988197553 accuracy 0.9986250400543213 macro_avg {'precision': 0.9986724793607479, 'recall': 0.9986177782746211, 'f1-score': 0.9986445191101117, 'support': 10182} weighted_avg {'precision': 0.9986261459605219, 'recall': 0.998625024553133, 'f1-score': 0.9986249982978715, 'support': 10182}
 
time = 14.33 secondes

Val loss 0.9899729756264823 accuracy 0.8966431021690369 macro_avg {'precision': 0.9033257307121026, 'recall': 0.8995797686037006, 'f1-score': 0.899380161965453, 'support': 1132} weighted_avg {'precision': 0.9008787333203346, 'recall': 0.8966431095406361, 'f1-score': 0.8966693539605891, 'support': 1132}
 
----------
Epoch 39/40
time = 487.93 secondes

Train loss 0.005694779054336971 accuracy 0.998919665813446 macro_avg {'precision': 0.9989580038204101, 'recall': 0.9989386812541543, 'f1-score': 0.9989469044544748, 'support': 10182} weighted_avg {'precision': 0.9989227880789354, 'recall': 0.9989196621488902, 'f1-score': 0.9989197384473645, 'support': 10182}
 
time = 14.26 secondes

Val loss 0.9627102215352121 accuracy 0.9037102460861206 macro_avg {'precision': 0.9093682933925138, 'recall': 0.9059448150132239, 'f1-score': 0.9058614675898525, 'support': 1132} weighted_avg {'precision': 0.9079005331950925, 'recall': 0.9037102473498233, 'f1-score': 0.9041046676552479, 'support': 1132}
 
----------
Epoch 40/40
time = 487.81 secondes

Train loss 0.00132249186964221 accuracy 0.9994107484817505 macro_avg {'precision': 0.9994329792780207, 'recall': 0.9994311540244109, 'f1-score': 0.9994316208258944, 'support': 10182} weighted_avg {'precision': 0.9994118385793007, 'recall': 0.9994107248084856, 'f1-score': 0.9994108183455855, 'support': 10182}
 
time = 17.08 secondes

Val loss 0.9609772389760853 accuracy 0.9037102460861206 macro_avg {'precision': 0.9086078944814305, 'recall': 0.9057185509194206, 'f1-score': 0.9053069769314114, 'support': 1132} weighted_avg {'precision': 0.9082412875438725, 'recall': 0.9037102473498233, 'f1-score': 0.9040503657343512, 'support': 1132}
 
----------
best_accuracy 0.9063604474067688 best_epoch 32 macro_avg {'precision': 0.910255130785225, 'recall': 0.9076347713129358, 'f1-score': 0.9071865526402035, 'support': 1132} weighted_avg {'precision': 0.9110623771336845, 'recall': 0.9063604240282686, 'f1-score': 0.906944080294217, 'support': 1132}

average train time 489.5902926445007

average val time 15.876436096429824
 
time = 108.31 secondes

test_accuracy 0.828066885471344 macro_avg {'precision': 0.8274202315415042, 'recall': 0.821766739596894, 'f1-score': 0.8224073284679108, 'support': 7532} weighted_avg {'precision': 0.8336561868218115, 'recall': 0.8280669144981413, 'f1-score': 0.8287879284705231, 'support': 7532}

----------
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 79.21 GiB total capacity; 69.49 GiB already allocated; 161.62 MiB free; 70.56 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_2048_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 79.21 GiB total capacity; 68.59 GiB already allocated; 33.62 MiB free; 70.69 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_64_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 79.21 GiB total capacity; 66.38 GiB already allocated; 495.62 MiB free; 70.23 GiB reserved in total by PyTorch)
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Bigbird_4096_128_4
----------
Epoch 1/40
Exception
CUDA out of memory. Tried to allocate 1008.00 MiB (GPU 0; 79.21 GiB total capacity; 69.37 GiB already allocated; 405.62 MiB free; 70.32 GiB reserved in total by PyTorch)
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_256_4
----------
Epoch 1/40
time = 705.30 secondes

Train loss 1.1060675276060306 accuracy 0.6868984699249268 macro_avg {'precision': 0.6912446852383314, 'recall': 0.6731791282505873, 'f1-score': 0.6712349620356672, 'support': 10182} weighted_avg {'precision': 0.6988909620616774, 'recall': 0.6868984482419956, 'f1-score': 0.6836668714808398, 'support': 10182}
 
time = 26.07 secondes

Val loss 0.5286669056390373 accuracy 0.8471731543540955 macro_avg {'precision': 0.8472686007983714, 'recall': 0.8357032277465798, 'f1-score': 0.8279019482566463, 'support': 1132} weighted_avg {'precision': 0.8485481188132882, 'recall': 0.8471731448763251, 'f1-score': 0.8378357951330426, 'support': 1132}
 
----------
Epoch 2/40
time = 682.32 secondes

Train loss 0.3978598882419348 accuracy 0.8833235502243042 macro_avg {'precision': 0.8759068462412211, 'recall': 0.8751244981793697, 'f1-score': 0.875047420180022, 'support': 10182} weighted_avg {'precision': 0.8824652770853887, 'recall': 0.8833235120801414, 'f1-score': 0.8825159713444198, 'support': 10182}
 
time = 19.46 secondes

Val loss 0.4057910417954267 accuracy 0.8869258165359497 macro_avg {'precision': 0.8889799665980631, 'recall': 0.8861582263071087, 'f1-score': 0.8839589378606589, 'support': 1132} weighted_avg {'precision': 0.8915387292246331, 'recall': 0.8869257950530035, 'f1-score': 0.8854585051980637, 'support': 1132}
 
----------
Epoch 3/40
time = 596.00 secondes

Train loss 0.23685451580015607 accuracy 0.9334119558334351 macro_avg {'precision': 0.9301979073177152, 'recall': 0.9293517586328252, 'f1-score': 0.9296644330094257, 'support': 10182} weighted_avg {'precision': 0.9334374723906101, 'recall': 0.9334119033588686, 'f1-score': 0.9333293359157556, 'support': 10182}
 
time = 20.68 secondes

Val loss 0.5218494231156795 accuracy 0.8825088143348694 macro_avg {'precision': 0.885712851373954, 'recall': 0.8848041534201124, 'f1-score': 0.8813553475093755, 'support': 1132} weighted_avg {'precision': 0.8909162139592807, 'recall': 0.8825088339222615, 'f1-score': 0.8827363830550884, 'support': 1132}
 
----------
Epoch 4/40
time = 600.61 secondes

Train loss 0.1841260397070624 accuracy 0.9513848423957825 macro_avg {'precision': 0.9493771868075461, 'recall': 0.9485518198694969, 'f1-score': 0.9488723013099912, 'support': 10182} weighted_avg {'precision': 0.9515848942706286, 'recall': 0.9513847967000589, 'f1-score': 0.951394518218109, 'support': 10182}
 
time = 27.47 secondes

Val loss 0.5575415709377332 accuracy 0.8939929604530334 macro_avg {'precision': 0.8969716363061095, 'recall': 0.8983188436739713, 'f1-score': 0.8934728443982068, 'support': 1132} weighted_avg {'precision': 0.9009013961173981, 'recall': 0.8939929328621908, 'f1-score': 0.8928251713474634, 'support': 1132}
 
----------
Epoch 5/40
time = 737.69 secondes

Train loss 0.1618475667215603 accuracy 0.9597328901290894 macro_avg {'precision': 0.9585814501329857, 'recall': 0.9582446219287704, 'f1-score': 0.9583543266615256, 'support': 10182} weighted_avg {'precision': 0.9599442689185511, 'recall': 0.9597328619131801, 'f1-score': 0.9597799729996482, 'support': 10182}
 
time = 27.59 secondes

Val loss 0.6505570747482945 accuracy 0.8851590156555176 macro_avg {'precision': 0.89922688978667, 'recall': 0.8837955803108095, 'f1-score': 0.8845939451625988, 'support': 1132} weighted_avg {'precision': 0.8955478358911739, 'recall': 0.8851590106007067, 'f1-score': 0.8832450065119175, 'support': 1132}
 
----------
Epoch 6/40
time = 663.77 secondes

Train loss 0.13605199301077325 accuracy 0.9662148952484131 macro_avg {'precision': 0.9650446810491384, 'recall': 0.9650979604878012, 'f1-score': 0.9650446251308138, 'support': 10182} weighted_avg {'precision': 0.966290868694431, 'recall': 0.966214889019839, 'f1-score': 0.9662259015033429, 'support': 10182}
 
time = 20.24 secondes

Val loss 0.690308154780339 accuracy 0.8816254734992981 macro_avg {'precision': 0.8948453305151413, 'recall': 0.876315155342611, 'f1-score': 0.8793078137885797, 'support': 1132} weighted_avg {'precision': 0.8912771610085204, 'recall': 0.8816254416961131, 'f1-score': 0.8805164929925261, 'support': 1132}
 
----------
Epoch 7/40
time = 591.54 secondes

Train loss 0.13388681847423395 accuracy 0.9697505831718445 macro_avg {'precision': 0.96871088051502, 'recall': 0.9684726531550311, 'f1-score': 0.9685216841963967, 'support': 10182} weighted_avg {'precision': 0.9698889276833448, 'recall': 0.9697505401689256, 'f1-score': 0.9697530159155721, 'support': 10182}
 
time = 24.14 secondes

Val loss 0.5743945597787388 accuracy 0.9028268456459045 macro_avg {'precision': 0.907319086340857, 'recall': 0.9073387317926096, 'f1-score': 0.9045282429061057, 'support': 1132} weighted_avg {'precision': 0.9101459427296902, 'recall': 0.9028268551236749, 'f1-score': 0.903542176057734, 'support': 1132}
 
----------
Epoch 8/40
time = 696.13 secondes

Train loss 0.13252034265242058 accuracy 0.9696523547172546 macro_avg {'precision': 0.9684956057779385, 'recall': 0.9685064743185684, 'f1-score': 0.9684294011763324, 'support': 10182} weighted_avg {'precision': 0.9698175682747254, 'recall': 0.9696523276370065, 'f1-score': 0.9696663239708587, 'support': 10182}
 
time = 26.88 secondes

Val loss 0.5323867150660256 accuracy 0.9178445339202881 macro_avg {'precision': 0.9216557235264993, 'recall': 0.9184208288807696, 'f1-score': 0.9186140388009134, 'support': 1132} weighted_avg {'precision': 0.9200747697275344, 'recall': 0.9178445229681979, 'f1-score': 0.9176474145586859, 'support': 1132}
 
----------
Epoch 9/40
time = 696.58 secondes

Train loss 0.10771712561635435 accuracy 0.9758397340774536 macro_avg {'precision': 0.9752500526860203, 'recall': 0.9750574344323087, 'f1-score': 0.9751295162105595, 'support': 10182} weighted_avg {'precision': 0.9758576934947365, 'recall': 0.9758397171479081, 'f1-score': 0.9758240595121059, 'support': 10182}
 
time = 26.39 secondes

Val loss 0.5117967357382697 accuracy 0.9178445339202881 macro_avg {'precision': 0.9220901510027393, 'recall': 0.9167387930776668, 'f1-score': 0.9181575848274892, 'support': 1132} weighted_avg {'precision': 0.9198526828202191, 'recall': 0.9178445229681979, 'f1-score': 0.9177038508320591, 'support': 1132}
 
----------
Epoch 10/40
time = 640.72 secondes

Train loss 0.10899010083495217 accuracy 0.9778040051460266 macro_avg {'precision': 0.9777540238752934, 'recall': 0.9771476432101253, 'f1-score': 0.9774216100481932, 'support': 10182} weighted_avg {'precision': 0.9778292142296359, 'recall': 0.9778039677862895, 'f1-score': 0.9777891903176193, 'support': 10182}
 
time = 19.31 secondes

Val loss 0.6681109112974348 accuracy 0.9054770469665527 macro_avg {'precision': 0.9097256877636044, 'recall': 0.907997507579536, 'f1-score': 0.9050312726449965, 'support': 1132} weighted_avg {'precision': 0.9132857715872643, 'recall': 0.9054770318021201, 'f1-score': 0.9054054583341857, 'support': 1132}
 
----------
Epoch 11/40
time = 609.36 secondes

Train loss 0.10413005455183977 accuracy 0.9786878824234009 macro_avg {'precision': 0.978044083335637, 'recall': 0.9781025492966398, 'f1-score': 0.9780429513234588, 'support': 10182} weighted_avg {'precision': 0.9787549561320905, 'recall': 0.9786878805735612, 'f1-score': 0.9786917395363781, 'support': 10182}
 
time = 27.80 secondes

Val loss 0.6473687676285331 accuracy 0.9063604474067688 macro_avg {'precision': 0.9180492484949221, 'recall': 0.9076285562335175, 'f1-score': 0.9086999320878901, 'support': 1132} weighted_avg {'precision': 0.9160186837305626, 'recall': 0.9063604240282686, 'f1-score': 0.9070516650932384, 'support': 1132}
 
----------
Epoch 12/40
time = 741.65 secondes

Train loss 0.10119091835575839 accuracy 0.9797682762145996 macro_avg {'precision': 0.9795000177219366, 'recall': 0.9791976476251193, 'f1-score': 0.9793133155370329, 'support': 10182} weighted_avg {'precision': 0.97980539941072, 'recall': 0.979768218424671, 'f1-score': 0.9797509468823947, 'support': 10182}
 
time = 27.93 secondes

Val loss 0.6771856486325113 accuracy 0.9045936465263367 macro_avg {'precision': 0.9102385137720266, 'recall': 0.9049482055476844, 'f1-score': 0.9048612354083737, 'support': 1132} weighted_avg {'precision': 0.9095680500156623, 'recall': 0.9045936395759717, 'f1-score': 0.9046403421033066, 'support': 1132}
 
----------
Epoch 13/40
time = 639.81 secondes

Train loss 0.08585803825886126 accuracy 0.9830092787742615 macro_avg {'precision': 0.9827604179509757, 'recall': 0.9824351702377474, 'f1-score': 0.9825860071422369, 'support': 10182} weighted_avg {'precision': 0.9830270698992964, 'recall': 0.9830092319780004, 'f1-score': 0.9830069203379079, 'support': 10182}
 
time = 19.00 secondes

Val loss 0.5900274603154172 accuracy 0.916961133480072 macro_avg {'precision': 0.9209412309698781, 'recall': 0.9168673652720715, 'f1-score': 0.9174175716627484, 'support': 1132} weighted_avg {'precision': 0.9201833934027098, 'recall': 0.9169611307420494, 'f1-score': 0.9170738912461951, 'support': 1132}
 
----------
Epoch 14/40
time = 587.76 secondes

Train loss 0.09248712605375868 accuracy 0.9827145934104919 macro_avg {'precision': 0.9813820088136511, 'recall': 0.9818019907841379, 'f1-score': 0.9815589595694174, 'support': 10182} weighted_avg {'precision': 0.9828194248902724, 'recall': 0.9827145943822432, 'f1-score': 0.9827364401365913, 'support': 10182}
 
time = 23.53 secondes

Val loss 0.5817499518452678 accuracy 0.9231448769569397 macro_avg {'precision': 0.9295499052856476, 'recall': 0.9234835227956328, 'f1-score': 0.9253898049959355, 'support': 1132} weighted_avg {'precision': 0.9261676282878981, 'recall': 0.9231448763250883, 'f1-score': 0.9235688303951032, 'support': 1132}
 
----------
Epoch 15/40
time = 695.72 secondes

Train loss 0.08148616211262409 accuracy 0.9845806360244751 macro_avg {'precision': 0.9838972371720296, 'recall': 0.9838564616591607, 'f1-score': 0.983863810837829, 'support': 10182} weighted_avg {'precision': 0.9845882445974019, 'recall': 0.9845806324887055, 'f1-score': 0.9845712056234294, 'support': 10182}
 
time = 27.81 secondes

Val loss 0.6428248902748365 accuracy 0.9116607904434204 macro_avg {'precision': 0.9168341631872643, 'recall': 0.9130958831324026, 'f1-score': 0.9129289267015068, 'support': 1132} weighted_avg {'precision': 0.9162579266627331, 'recall': 0.911660777385159, 'f1-score': 0.911837507014717, 'support': 1132}
 
----------
Epoch 16/40
time = 703.04 secondes

Train loss 0.08350212321748933 accuracy 0.9848753213882446 macro_avg {'precision': 0.984127391242002, 'recall': 0.9839850491505638, 'f1-score': 0.9840462283090234, 'support': 10182} weighted_avg {'precision': 0.984880727412725, 'recall': 0.9848752700844627, 'f1-score': 0.9848683678863138, 'support': 10182}
 
time = 27.39 secondes

Val loss 0.691425802100972 accuracy 0.9063604474067688 macro_avg {'precision': 0.9152816118054625, 'recall': 0.9037073938222822, 'f1-score': 0.9041287672800747, 'support': 1132} weighted_avg {'precision': 0.9135942440439255, 'recall': 0.9063604240282686, 'f1-score': 0.9053957171937761, 'support': 1132}
 
----------
Epoch 17/40
time = 653.95 secondes

Train loss 0.08545175178308281 accuracy 0.9836967587471008 macro_avg {'precision': 0.9831744370368641, 'recall': 0.9834052312170941, 'f1-score': 0.9832617373784835, 'support': 10182} weighted_avg {'precision': 0.9837752317975386, 'recall': 0.9836967197014339, 'f1-score': 0.9837082719040301, 'support': 10182}
 
time = 23.33 secondes

Val loss 0.7905226800173462 accuracy 0.9010601043701172 macro_avg {'precision': 0.908133028988131, 'recall': 0.9023480054597346, 'f1-score': 0.9015914277488009, 'support': 1132} weighted_avg {'precision': 0.9095412038744146, 'recall': 0.901060070671378, 'f1-score': 0.9015176035500834, 'support': 1132}
 
----------
Epoch 18/40
time = 607.97 secondes

Train loss 0.07429239696775224 accuracy 0.9863485097885132 macro_avg {'precision': 0.9862253378626212, 'recall': 0.9863236402798213, 'f1-score': 0.9862670808272161, 'support': 10182} weighted_avg {'precision': 0.9863641512937589, 'recall': 0.9863484580632489, 'f1-score': 0.9863487745563073, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.7154949730941387 accuracy 0.9045936465263367 macro_avg {'precision': 0.9122740610805613, 'recall': 0.9079966677160826, 'f1-score': 0.9062272244050437, 'support': 1132} weighted_avg {'precision': 0.9128248465382911, 'recall': 0.9045936395759717, 'f1-score': 0.9043473336959126, 'support': 1132}
 
----------
Epoch 19/40
time = 711.02 secondes

Train loss 0.06322611827293471 accuracy 0.9884109497070312 macro_avg {'precision': 0.9883716232952142, 'recall': 0.988385654130053, 'f1-score': 0.9883696257652099, 'support': 10182} weighted_avg {'precision': 0.9884523009944993, 'recall': 0.9884109212335495, 'f1-score': 0.9884231872355632, 'support': 10182}
 
time = 28.27 secondes

Val loss 0.6903213634339946 accuracy 0.9143109321594238 macro_avg {'precision': 0.9165861629374893, 'recall': 0.9131187961458499, 'f1-score': 0.9136065339862915, 'support': 1132} weighted_avg {'precision': 0.916367592050385, 'recall': 0.9143109540636042, 'f1-score': 0.9139502695336543, 'support': 1132}
 
----------
Epoch 20/40
time = 703.91 secondes

Train loss 0.06370170586600139 accuracy 0.987625241279602 macro_avg {'precision': 0.9876622272064459, 'recall': 0.9875979682749616, 'f1-score': 0.9876090207893835, 'support': 10182} weighted_avg {'precision': 0.9876805295241795, 'recall': 0.9876252209781968, 'f1-score': 0.9876313555066041, 'support': 10182}
 
time = 26.43 secondes

Val loss 0.8140881195395708 accuracy 0.8992933034896851 macro_avg {'precision': 0.9101433630108735, 'recall': 0.903807546291335, 'f1-score': 0.9028787486834874, 'support': 1132} weighted_avg {'precision': 0.9099515369987482, 'recall': 0.8992932862190812, 'f1-score': 0.9000997394107609, 'support': 1132}
 
----------
Epoch 21/40
time = 611.63 secondes

Train loss 0.06980787126894868 accuracy 0.9870359897613525 macro_avg {'precision': 0.9869789224145114, 'recall': 0.9869577896506447, 'f1-score': 0.9869430527920601, 'support': 10182} weighted_avg {'precision': 0.9870891977591097, 'recall': 0.9870359457866824, 'f1-score': 0.9870365318199881, 'support': 10182}
 
time = 18.35 secondes

Val loss 0.583161075158835 accuracy 0.9257950782775879 macro_avg {'precision': 0.9306286574728816, 'recall': 0.9269232561441803, 'f1-score': 0.9273308939536824, 'support': 1132} weighted_avg {'precision': 0.9291192950243722, 'recall': 0.9257950530035336, 'f1-score': 0.9259807252188786, 'support': 1132}
 
----------
Epoch 22/40
time = 625.28 secondes

Train loss 0.04929591415242001 accuracy 0.9905716180801392 macro_avg {'precision': 0.9901913120462951, 'recall': 0.9903451313292176, 'f1-score': 0.9902603738465654, 'support': 10182} weighted_avg {'precision': 0.9905932003493267, 'recall': 0.990571596935769, 'f1-score': 0.9905756010607671, 'support': 10182}
 
time = 25.32 secondes

Val loss 0.597238124483597 accuracy 0.9204947352409363 macro_avg {'precision': 0.9214044830058903, 'recall': 0.9201898065722419, 'f1-score': 0.9194187957298624, 'support': 1132} weighted_avg {'precision': 0.9216081116755768, 'recall': 0.9204946996466431, 'f1-score': 0.9197343243039526, 'support': 1132}
 
----------
Epoch 23/40
time = 696.97 secondes

Train loss 0.054166213144039535 accuracy 0.9901787638664246 macro_avg {'precision': 0.9899661030482336, 'recall': 0.989863192536187, 'f1-score': 0.9898999768862209, 'support': 10182} weighted_avg {'precision': 0.9902179472577962, 'recall': 0.9901787468080927, 'f1-score': 0.9901844723661855, 'support': 10182}
 
time = 26.60 secondes

Val loss 0.8195115862923353 accuracy 0.898409903049469 macro_avg {'precision': 0.9169869687624589, 'recall': 0.9045926618688374, 'f1-score': 0.9032761519159453, 'support': 1132} weighted_avg {'precision': 0.9193404920757998, 'recall': 0.8984098939929329, 'f1-score': 0.9005864377142849, 'support': 1132}
 
----------
Epoch 24/40
time = 696.79 secondes

Train loss 0.04356538374605625 accuracy 0.9922412633895874 macro_avg {'precision': 0.9923073718705743, 'recall': 0.9923324505639659, 'f1-score': 0.9923132205787455, 'support': 10182} weighted_avg {'precision': 0.992259492365566, 'recall': 0.9922412099783933, 'f1-score': 0.9922434598375655, 'support': 10182}
 
time = 26.36 secondes

Val loss 0.6636610788796453 accuracy 0.9204947352409363 macro_avg {'precision': 0.9245280401830843, 'recall': 0.9239281468705249, 'f1-score': 0.9232237470485624, 'support': 1132} weighted_avg {'precision': 0.9232758144280496, 'recall': 0.9204946996466431, 'f1-score': 0.9208297858338002, 'support': 1132}
 
----------
Epoch 25/40
time = 623.56 secondes

Train loss 0.04442561767454675 accuracy 0.9919465780258179 macro_avg {'precision': 0.9917652364253609, 'recall': 0.9917758383552087, 'f1-score': 0.9917495403902894, 'support': 10182} weighted_avg {'precision': 0.9919777758763085, 'recall': 0.9919465723826361, 'f1-score': 0.9919419169078556, 'support': 10182}
 
time = 19.38 secondes

Val loss 0.7743988546843494 accuracy 0.9098939895629883 macro_avg {'precision': 0.9149703794158031, 'recall': 0.9129398289623982, 'f1-score': 0.912640761480574, 'support': 1132} weighted_avg {'precision': 0.9133097658672248, 'recall': 0.9098939929328622, 'f1-score': 0.9102983167401695, 'support': 1132}
 
----------
Epoch 26/40
time = 593.51 secondes

Train loss 0.04405577227414343 accuracy 0.9921430349349976 macro_avg {'precision': 0.9923405245527064, 'recall': 0.9921843435335809, 'f1-score': 0.992251753610546, 'support': 10182} weighted_avg {'precision': 0.9921698885790088, 'recall': 0.9921429974464742, 'f1-score': 0.992145658635006, 'support': 10182}
 
time = 21.29 secondes

Val loss 0.7370792464841454 accuracy 0.9187279343605042 macro_avg {'precision': 0.9251129823915983, 'recall': 0.9203312833194099, 'f1-score': 0.9204582891422112, 'support': 1132} weighted_avg {'precision': 0.9231320332087978, 'recall': 0.9187279151943463, 'f1-score': 0.918658660048929, 'support': 1132}
 
----------
Epoch 27/40
time = 700.73 secondes

Train loss 0.047902431881980984 accuracy 0.9918484091758728 macro_avg {'precision': 0.9918177646233962, 'recall': 0.9918984406004878, 'f1-score': 0.991850270401045, 'support': 10182} weighted_avg {'precision': 0.9918524349644825, 'recall': 0.991848359850717, 'f1-score': 0.9918424089212325, 'support': 10182}
 
time = 27.95 secondes

Val loss 0.7159251871939567 accuracy 0.9151943325996399 macro_avg {'precision': 0.9172010831330697, 'recall': 0.9177046019317782, 'f1-score': 0.9164633249642697, 'support': 1132} weighted_avg {'precision': 0.917211976398288, 'recall': 0.9151943462897526, 'f1-score': 0.9153023465156732, 'support': 1132}
 
----------
Epoch 28/40
time = 713.01 secondes

Train loss 0.05265458361329188 accuracy 0.9922412633895874 macro_avg {'precision': 0.9919754250427623, 'recall': 0.9917530973833502, 'f1-score': 0.9918515435781348, 'support': 10182} weighted_avg {'precision': 0.9922523550140555, 'recall': 0.9922412099783933, 'f1-score': 0.9922346623108822, 'support': 10182}
 
time = 26.72 secondes

Val loss 0.6761692108318552 accuracy 0.9125441908836365 macro_avg {'precision': 0.9144155609191962, 'recall': 0.9132053676806366, 'f1-score': 0.9117773590662427, 'support': 1132} weighted_avg {'precision': 0.9163984599451592, 'recall': 0.9125441696113075, 'f1-score': 0.9123992584244972, 'support': 1132}
 
----------
Epoch 29/40
time = 623.68 secondes

Train loss 0.03723010137813049 accuracy 0.9930269122123718 macro_avg {'precision': 0.9923969087037925, 'recall': 0.9926255276146634, 'f1-score': 0.9924925233064312, 'support': 10182} weighted_avg {'precision': 0.9930762628268881, 'recall': 0.9930269102337458, 'f1-score': 0.99303594577261, 'support': 10182}
 
time = 23.72 secondes

Val loss 0.7755163902462735 accuracy 0.9054770469665527 macro_avg {'precision': 0.9082705504754018, 'recall': 0.8984981993344098, 'f1-score': 0.895968898392149, 'support': 1132} weighted_avg {'precision': 0.9101828245999619, 'recall': 0.9054770318021201, 'f1-score': 0.9021662389586872, 'support': 1132}
 
----------
Epoch 30/40
time = 676.55 secondes

Train loss 0.0331371460849127 accuracy 0.9944019317626953 macro_avg {'precision': 0.993815474965601, 'recall': 0.9935848967060853, 'f1-score': 0.9936953334805307, 'support': 10182} weighted_avg {'precision': 0.9943958958782103, 'recall': 0.9944018856806128, 'f1-score': 0.9943948538416383, 'support': 10182}
 
time = 28.45 secondes

Val loss 0.7394706521957066 accuracy 0.9107773900032043 macro_avg {'precision': 0.9125390272635909, 'recall': 0.9135206647238296, 'f1-score': 0.9113728786671272, 'support': 1132} weighted_avg {'precision': 0.9135388641660348, 'recall': 0.9107773851590106, 'f1-score': 0.9104671511381013, 'support': 1132}
 
----------
Epoch 31/40
time = 708.89 secondes

Train loss 0.03652404040292528 accuracy 0.9934197664260864 macro_avg {'precision': 0.9933030976243387, 'recall': 0.9933397725708912, 'f1-score': 0.9933056316481498, 'support': 10182} weighted_avg {'precision': 0.9934494477268754, 'recall': 0.9934197603614221, 'f1-score': 0.9934184128852765, 'support': 10182}
 
time = 28.74 secondes

Val loss 0.6802429843874436 accuracy 0.9240282773971558 macro_avg {'precision': 0.9269612525650874, 'recall': 0.9259771744489447, 'f1-score': 0.9250672014461012, 'support': 1132} weighted_avg {'precision': 0.926416227058555, 'recall': 0.9240282685512368, 'f1-score': 0.9238386514698844, 'support': 1132}
 
----------
Epoch 32/40
time = 682.71 secondes

Train loss 0.036610273318086514 accuracy 0.9947947859764099 macro_avg {'precision': 0.9947167792275721, 'recall': 0.9945818100179318, 'f1-score': 0.9946402361688941, 'support': 10182} weighted_avg {'precision': 0.9948061784591095, 'recall': 0.9947947358082891, 'f1-score': 0.9947927171417783, 'support': 10182}
 
time = 22.80 secondes

Val loss 0.6812933082429469 accuracy 0.9204947352409363 macro_avg {'precision': 0.9228387142474617, 'recall': 0.9199797358237835, 'f1-score': 0.920161694281958, 'support': 1132} weighted_avg {'precision': 0.921647023239589, 'recall': 0.9204946996466431, 'f1-score': 0.9198579182834276, 'support': 1132}
 
----------
Epoch 33/40
time = 611.77 secondes

Train loss 0.025893018248746298 accuracy 0.9949911832809448 macro_avg {'precision': 0.9950161227926675, 'recall': 0.9948893439284221, 'f1-score': 0.9949479431660991, 'support': 10182} weighted_avg {'precision': 0.99500781277529, 'recall': 0.9949911608721272, 'f1-score': 0.9949946954804524, 'support': 10182}
 
time = 21.34 secondes

Val loss 0.6255771583172146 accuracy 0.926678478717804 macro_avg {'precision': 0.932046484079858, 'recall': 0.9269041044438355, 'f1-score': 0.9284069573755875, 'support': 1132} weighted_avg {'precision': 0.9287665040191243, 'recall': 0.926678445229682, 'f1-score': 0.9266992759868344, 'support': 1132}
 
----------
Epoch 34/40
time = 735.10 secondes

Train loss 0.020180653476325024 accuracy 0.9961697459220886 macro_avg {'precision': 0.9960735996777347, 'recall': 0.9961860290492238, 'f1-score': 0.9961281745161272, 'support': 10182} weighted_avg {'precision': 0.9961715956414416, 'recall': 0.9961697112551562, 'f1-score': 0.9961690286032697, 'support': 10182}
 
time = 28.21 secondes

Val loss 0.6108652519036132 accuracy 0.9302120208740234 macro_avg {'precision': 0.9333181761873073, 'recall': 0.931443065277411, 'f1-score': 0.9311875672952515, 'support': 1132} weighted_avg {'precision': 0.9319582665519985, 'recall': 0.9302120141342756, 'f1-score': 0.929828629530147, 'support': 1132}
 
----------
Epoch 35/40
time = 703.67 secondes

Train loss 0.013384737196130364 accuracy 0.996857225894928 macro_avg {'precision': 0.9969160809565508, 'recall': 0.9969438673604017, 'f1-score': 0.996927717825192, 'support': 10182} weighted_avg {'precision': 0.9968630197924128, 'recall': 0.9968571989785897, 'f1-score': 0.9968578391907479, 'support': 10182}
 
time = 28.31 secondes

Val loss 0.7458468108792992 accuracy 0.9125441908836365 macro_avg {'precision': 0.920039994825761, 'recall': 0.9149433765425361, 'f1-score': 0.9151550703675154, 'support': 1132} weighted_avg {'precision': 0.9183281306535528, 'recall': 0.9125441696113075, 'f1-score': 0.9129450085247252, 'support': 1132}
 
----------
Epoch 36/40
time = 621.24 secondes

Train loss 0.016556875870637425 accuracy 0.9972500801086426 macro_avg {'precision': 0.9972805063742948, 'recall': 0.9973106430723139, 'f1-score': 0.9972933752756482, 'support': 10182} weighted_avg {'precision': 0.9972519416804106, 'recall': 0.9972500491062659, 'f1-score': 0.9972487535905936, 'support': 10182}
 
time = 27.41 secondes

Val loss 0.7119446248405848 accuracy 0.9249116778373718 macro_avg {'precision': 0.9270133652175563, 'recall': 0.9268664269169851, 'f1-score': 0.926162295295553, 'support': 1132} weighted_avg {'precision': 0.9259750687785058, 'recall': 0.9249116607773852, 'f1-score': 0.9246726850771582, 'support': 1132}
 
----------
Epoch 37/40
time = 679.61 secondes

Train loss 0.013919861226729969 accuracy 0.9975447058677673 macro_avg {'precision': 0.9975079807853859, 'recall': 0.9975264367936066, 'f1-score': 0.997512869988349, 'support': 10182} weighted_avg {'precision': 0.9975520450098153, 'recall': 0.9975446867020232, 'f1-score': 0.9975438954164462, 'support': 10182}
 
time = 27.84 secondes

Val loss 0.6116368122778331 accuracy 0.9284452199935913 macro_avg {'precision': 0.9309369172096511, 'recall': 0.9288526501090054, 'f1-score': 0.928895025512035, 'support': 1132} weighted_avg {'precision': 0.9303366081094099, 'recall': 0.9284452296819788, 'f1-score': 0.9283748229922568, 'support': 1132}
 
----------
Epoch 38/40
time = 674.97 secondes

Train loss 0.010290060932206949 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983960247705579, 'recall': 0.9984201029246327, 'f1-score': 0.9984070644465841, 'support': 10182} weighted_avg {'precision': 0.9984299798628996, 'recall': 0.9984285994892949, 'f1-score': 0.9984283171994623, 'support': 10182}
 
time = 28.24 secondes

Val loss 0.669733625727736 accuracy 0.9249116778373718 macro_avg {'precision': 0.9291732958446545, 'recall': 0.925920596149344, 'f1-score': 0.9258018262841998, 'support': 1132} weighted_avg {'precision': 0.9288699070651483, 'recall': 0.9249116607773852, 'f1-score': 0.9250877226703653, 'support': 1132}
 
----------
Epoch 39/40
time = 675.67 secondes

Train loss 0.008411739502049868 accuracy 0.9984286427497864 macro_avg {'precision': 0.9983625627714435, 'recall': 0.9984539581446207, 'f1-score': 0.9984063915504502, 'support': 10182} weighted_avg {'precision': 0.9984308764873713, 'recall': 0.9984285994892949, 'f1-score': 0.9984279634692939, 'support': 10182}
 
time = 27.05 secondes

Val loss 0.6490206598372052 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321141625342501, 'recall': 0.9294347603772039, 'f1-score': 0.9295096020090323, 'support': 1132} weighted_avg {'precision': 0.9305246573801035, 'recall': 0.9284452296819788, 'f1-score': 0.9282465783053647, 'support': 1132}
 
----------
Epoch 40/40
time = 678.91 secondes

Train loss 0.004953109803582936 accuracy 0.9991161227226257 macro_avg {'precision': 0.9991551314033231, 'recall': 0.9991605277080037, 'f1-score': 0.9991572201615794, 'support': 10182} weighted_avg {'precision': 0.9991170055431035, 'recall': 0.9991160872127284, 'f1-score': 0.9991159056042657, 'support': 10182}
 
time = 27.57 secondes

Val loss 0.635465871139184 accuracy 0.9310954213142395 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}
 
----------
best_accuracy 0.9310954213142395 best_epoch 40 macro_avg {'precision': 0.932480295422034, 'recall': 0.9318556289863931, 'f1-score': 0.931497579800211, 'support': 1132} weighted_avg {'precision': 0.9316150509667315, 'recall': 0.931095406360424, 'f1-score': 0.9307144868703747, 'support': 1132}

average train time 664.97757076025

average val time 25.108302837610246
 
time = 177.83 secondes

test_accuracy 0.8637811541557312 macro_avg {'precision': 0.8619622881992794, 'recall': 0.8568902043892187, 'f1-score': 0.8573933439667325, 'support': 7532} weighted_avg {'precision': 0.8669934848523781, 'recall': 0.863781200212427, 'f1-score': 0.8635495729265222, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_1024_512_4
----------
Epoch 1/40
time = 904.45 secondes

Train loss 1.085930619523327 accuracy 0.6867020726203918 macro_avg {'precision': 0.6865075689896771, 'recall': 0.6737792097754312, 'f1-score': 0.6700662454551063, 'support': 10182} weighted_avg {'precision': 0.6905970792110961, 'recall': 0.6867020231781575, 'f1-score': 0.6805359750626276, 'support': 10182}
 
time = 32.97 secondes

Val loss 0.5193957160686103 accuracy 0.8462897539138794 macro_avg {'precision': 0.8412125670626283, 'recall': 0.8402299982502687, 'f1-score': 0.8376936715326793, 'support': 1132} weighted_avg {'precision': 0.843922428205379, 'recall': 0.8462897526501767, 'f1-score': 0.842413568276659, 'support': 1132}
 
----------
Epoch 2/40
time = 895.94 secondes

Train loss 0.3838968490202161 accuracy 0.8871538043022156 macro_avg {'precision': 0.8815384222332305, 'recall': 0.8801776800723407, 'f1-score': 0.8803636926429504, 'support': 10182} weighted_avg {'precision': 0.8864567932606825, 'recall': 0.8871538008249853, 'f1-score': 0.8864063484907485, 'support': 10182}
 
time = 31.86 secondes

Val loss 0.41492575365053097 accuracy 0.8966431021690369 macro_avg {'precision': 0.8999323251246455, 'recall': 0.8975723282585276, 'f1-score': 0.8956750378397782, 'support': 1132} weighted_avg {'precision': 0.9005802693326558, 'recall': 0.8966431095406361, 'f1-score': 0.895143936676859, 'support': 1132}
 
----------
Epoch 3/40
time = 871.07 secondes

Train loss 0.23415676027746926 accuracy 0.9339029788970947 macro_avg {'precision': 0.9313366144984473, 'recall': 0.931048279689529, 'f1-score': 0.9311270378667762, 'support': 10182} weighted_avg {'precision': 0.9341356114413687, 'recall': 0.933902966018464, 'f1-score': 0.9339549314983527, 'support': 10182}
 
time = 31.74 secondes

Val loss 0.4685395577804408 accuracy 0.9028268456459045 macro_avg {'precision': 0.9048725084604504, 'recall': 0.9024120467548313, 'f1-score': 0.9002344086445928, 'support': 1132} weighted_avg {'precision': 0.9050233225133233, 'recall': 0.9028268551236749, 'f1-score': 0.9006327586233528, 'support': 1132}
 
----------
Epoch 4/40
time = 886.40 secondes

Train loss 0.1755128247609283 accuracy 0.9548222422599792 macro_avg {'precision': 0.9531579260691849, 'recall': 0.9528312455868295, 'f1-score': 0.9529470096924959, 'support': 10182} weighted_avg {'precision': 0.9548200036377498, 'recall': 0.9548222353172264, 'f1-score': 0.9547756605009832, 'support': 10182}
 
time = 30.38 secondes

Val loss 0.48899852524472165 accuracy 0.9063604474067688 macro_avg {'precision': 0.9113016963466535, 'recall': 0.9073621871432493, 'f1-score': 0.9063413900703441, 'support': 1132} weighted_avg {'precision': 0.9125648337918182, 'recall': 0.9063604240282686, 'f1-score': 0.9061862724231018, 'support': 1132}
 
----------
Epoch 5/40
time = 889.66 secondes

Train loss 0.15959863709026342 accuracy 0.9608132243156433 macro_avg {'precision': 0.9589868555310874, 'recall': 0.9586793542749328, 'f1-score': 0.9587745556055326, 'support': 10182} weighted_avg {'precision': 0.9607763663144321, 'recall': 0.9608131997642899, 'f1-score': 0.9607364885199169, 'support': 10182}
 
time = 31.15 secondes

Val loss 0.5388715893135104 accuracy 0.9010601043701172 macro_avg {'precision': 0.907591546568366, 'recall': 0.9013343999069345, 'f1-score': 0.9010584883871751, 'support': 1132} weighted_avg {'precision': 0.908005280658987, 'recall': 0.901060070671378, 'f1-score': 0.9011480861926803, 'support': 1132}
 
----------
Epoch 6/40
time = 888.10 secondes

Train loss 0.1381628696523092 accuracy 0.9673934578895569 macro_avg {'precision': 0.9665400416858814, 'recall': 0.9665452750523024, 'f1-score': 0.9664698139836971, 'support': 10182} weighted_avg {'precision': 0.9676099019947199, 'recall': 0.9673934394028678, 'f1-score': 0.967433825158669, 'support': 10182}
 
time = 30.86 secondes

Val loss 0.5589238259396975 accuracy 0.898409903049469 macro_avg {'precision': 0.9107780061389394, 'recall': 0.8990560839242434, 'f1-score': 0.9005934197614881, 'support': 1132} weighted_avg {'precision': 0.9088274890381041, 'recall': 0.8984098939929329, 'f1-score': 0.899540464371059, 'support': 1132}
 
----------
Epoch 7/40
time = 886.07 secondes

Train loss 0.12212684896103511 accuracy 0.9725987315177917 macro_avg {'precision': 0.972092109588592, 'recall': 0.9722323636192046, 'f1-score': 0.9721184211638796, 'support': 10182} weighted_avg {'precision': 0.9727148341507819, 'recall': 0.9725987035945787, 'f1-score': 0.9726144256906292, 'support': 10182}
 
time = 32.09 secondes

Val loss 0.5849548677535085 accuracy 0.9081271886825562 macro_avg {'precision': 0.9126284591765751, 'recall': 0.9094974132947063, 'f1-score': 0.9083472707306803, 'support': 1132} weighted_avg {'precision': 0.9124542703248095, 'recall': 0.9081272084805654, 'f1-score': 0.9073014295784437, 'support': 1132}
 
----------
Epoch 8/40
time = 886.88 secondes

Train loss 0.11177829492930762 accuracy 0.9741701483726501 macro_avg {'precision': 0.973594696465962, 'recall': 0.9734491551783859, 'f1-score': 0.9734950780435249, 'support': 10182} weighted_avg {'precision': 0.974196918075608, 'recall': 0.9741701041052838, 'f1-score': 0.9741565543818885, 'support': 10182}
 
time = 31.16 secondes

Val loss 0.5017699991921816 accuracy 0.9204947352409363 macro_avg {'precision': 0.9244479644558574, 'recall': 0.9198750978312731, 'f1-score': 0.918678550890413, 'support': 1132} weighted_avg {'precision': 0.9249164074099199, 'recall': 0.9204946996466431, 'f1-score': 0.9196652619276384, 'support': 1132}
 
----------
Epoch 9/40
time = 881.07 secondes

Train loss 0.11146013088578437 accuracy 0.9759379625320435 macro_avg {'precision': 0.9750177619936367, 'recall': 0.97545290705052, 'f1-score': 0.9751860900778242, 'support': 10182} weighted_avg {'precision': 0.9759976803279738, 'recall': 0.9759379296798272, 'f1-score': 0.9759226007932119, 'support': 10182}
 
time = 31.52 secondes

Val loss 0.7485236363833062 accuracy 0.879858672618866 macro_avg {'precision': 0.896906504806414, 'recall': 0.8720591196309572, 'f1-score': 0.8712675490746763, 'support': 1132} weighted_avg {'precision': 0.896645497634433, 'recall': 0.8798586572438163, 'f1-score': 0.8778132357248053, 'support': 1132}
 
----------
Epoch 10/40
time = 888.16 secondes

Train loss 0.11016958717904105 accuracy 0.9777057766914368 macro_avg {'precision': 0.9767650159952659, 'recall': 0.9770413140656095, 'f1-score': 0.9768544129001375, 'support': 10182} weighted_avg {'precision': 0.9778079420816265, 'recall': 0.9777057552543704, 'f1-score': 0.9777171184522614, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.6425116605991924 accuracy 0.9107773900032043 macro_avg {'precision': 0.9217270403779807, 'recall': 0.9112960560306606, 'f1-score': 0.9132886534816338, 'support': 1132} weighted_avg {'precision': 0.9197899578043967, 'recall': 0.9107773851590106, 'f1-score': 0.9120199309815973, 'support': 1132}
 
----------
Epoch 11/40
time = 887.69 secondes

Train loss 0.10249908830617076 accuracy 0.9800629019737244 macro_avg {'precision': 0.9795009061695769, 'recall': 0.9797302742176737, 'f1-score': 0.9795970230580796, 'support': 10182} weighted_avg {'precision': 0.9800965897243733, 'recall': 0.9800628560204282, 'f1-score': 0.9800632197023552, 'support': 10182}
 
time = 31.40 secondes

Val loss 0.5195122392418545 accuracy 0.9196113348007202 macro_avg {'precision': 0.9222364650195294, 'recall': 0.9228078046566048, 'f1-score': 0.9214777802676926, 'support': 1132} weighted_avg {'precision': 0.9229993100415419, 'recall': 0.9196113074204947, 'f1-score': 0.9202951152689185, 'support': 1132}
 
----------
Epoch 12/40
time = 884.34 secondes

Train loss 0.09942209077085674 accuracy 0.9806521534919739 macro_avg {'precision': 0.9799102835107767, 'recall': 0.9796952108777759, 'f1-score': 0.9797671273381034, 'support': 10182} weighted_avg {'precision': 0.9806918441615122, 'recall': 0.9806521312119426, 'f1-score': 0.9806387957507825, 'support': 10182}
 
time = 31.12 secondes

Val loss 0.7199064678589168 accuracy 0.9045936465263367 macro_avg {'precision': 0.9142361637909909, 'recall': 0.9044086756644818, 'f1-score': 0.9064587066213372, 'support': 1132} weighted_avg {'precision': 0.9139669927240228, 'recall': 0.9045936395759717, 'f1-score': 0.9062910000462504, 'support': 1132}
 
----------
Epoch 13/40
time = 892.53 secondes

Train loss 0.10019335445704515 accuracy 0.9812414646148682 macro_avg {'precision': 0.9800448220615527, 'recall': 0.9804267281056586, 'f1-score': 0.9802047141721688, 'support': 10182} weighted_avg {'precision': 0.9813307964791219, 'recall': 0.981241406403457, 'f1-score': 0.9812596499994694, 'support': 10182}
 
time = 31.14 secondes

Val loss 0.8165900552287472 accuracy 0.8878092169761658 macro_avg {'precision': 0.9011281371267614, 'recall': 0.8852364533612294, 'f1-score': 0.8864581928861661, 'support': 1132} weighted_avg {'precision': 0.8986244409402355, 'recall': 0.8878091872791519, 'f1-score': 0.8867222613745912, 'support': 1132}
 
----------
Epoch 14/40
time = 849.97 secondes

Train loss 0.09773514877786488 accuracy 0.9814378619194031 macro_avg {'precision': 0.9813610444115877, 'recall': 0.9810298890042756, 'f1-score': 0.9811697066823106, 'support': 10182} weighted_avg {'precision': 0.9814497264505064, 'recall': 0.9814378314672952, 'f1-score': 0.9814182077101277, 'support': 10182}
 
time = 23.76 secondes

Val loss 0.8164968457526747 accuracy 0.8913427591323853 macro_avg {'precision': 0.9014434343927695, 'recall': 0.8960916809256038, 'f1-score': 0.8927996249156402, 'support': 1132} weighted_avg {'precision': 0.9050721572627863, 'recall': 0.8913427561837456, 'f1-score': 0.8917019108997021, 'support': 1132}
 
----------
Epoch 15/40
time = 809.63 secondes

Train loss 0.0852009838246766 accuracy 0.9847770929336548 macro_avg {'precision': 0.984738529277273, 'recall': 0.9845590137659823, 'f1-score': 0.9846202021731381, 'support': 10182} weighted_avg {'precision': 0.9848526790621743, 'recall': 0.9847770575525437, 'f1-score': 0.9847866931252149, 'support': 10182}
 
time = 31.26 secondes

Val loss 0.6942899270814477 accuracy 0.9090105891227722 macro_avg {'precision': 0.9135506304505899, 'recall': 0.9066611815332631, 'f1-score': 0.9088391604208, 'support': 1132} weighted_avg {'precision': 0.9109398970241406, 'recall': 0.9090106007067138, 'f1-score': 0.9087468740851598, 'support': 1132}
 
----------
Epoch 16/40
time = 832.00 secondes

Train loss 0.0820784205051791 accuracy 0.9854645729064941 macro_avg {'precision': 0.9855058740680616, 'recall': 0.985370173621485, 'f1-score': 0.9853833692723507, 'support': 10182} weighted_avg {'precision': 0.9855786158729254, 'recall': 0.9854645452759773, 'f1-score': 0.9854654057996362, 'support': 10182}
 
time = 31.48 secondes

Val loss 0.6275781476102616 accuracy 0.9125441908836365 macro_avg {'precision': 0.9187629424288086, 'recall': 0.9121109985551719, 'f1-score': 0.9145346774284221, 'support': 1132} weighted_avg {'precision': 0.914260494802553, 'recall': 0.9125441696113075, 'f1-score': 0.9124711805937453, 'support': 1132}
 
----------
Epoch 17/40
time = 847.80 secondes

Train loss 0.08730184219728378 accuracy 0.9851699471473694 macro_avg {'precision': 0.9849575776816355, 'recall': 0.9851428217879704, 'f1-score': 0.9850097983707263, 'support': 10182} weighted_avg {'precision': 0.9852473653884686, 'recall': 0.98516990768022, 'f1-score': 0.9851692857918276, 'support': 10182}
 
time = 25.74 secondes

Val loss 0.7229484111049318 accuracy 0.8992933034896851 macro_avg {'precision': 0.9022305834531945, 'recall': 0.9043702783368799, 'f1-score': 0.8999537426896568, 'support': 1132} weighted_avg {'precision': 0.9069119119456899, 'recall': 0.8992932862190812, 'f1-score': 0.8997867434282643, 'support': 1132}
 
----------
Epoch 18/40
time = 922.10 secondes

Train loss 0.07129670814004269 accuracy 0.9870359897613525 macro_avg {'precision': 0.9866693485698406, 'recall': 0.9871836831129777, 'f1-score': 0.9869032952034905, 'support': 10182} weighted_avg {'precision': 0.9870945904981376, 'recall': 0.9870359457866824, 'f1-score': 0.9870434803235079, 'support': 10182}
 
time = 32.26 secondes

Val loss 0.5969959354033435 accuracy 0.916961133480072 macro_avg {'precision': 0.9259543968350992, 'recall': 0.9205818030305034, 'f1-score': 0.9211064907549019, 'support': 1132} weighted_avg {'precision': 0.9230064219570709, 'recall': 0.9169611307420494, 'f1-score': 0.9177016493579521, 'support': 1132}
 
----------
Epoch 19/40
time = 931.96 secondes

Train loss 0.06571471136292421 accuracy 0.9877234697341919 macro_avg {'precision': 0.9874937388551459, 'recall': 0.987279933565938, 'f1-score': 0.9873746777387578, 'support': 10182} weighted_avg {'precision': 0.9877469769518392, 'recall': 0.9877234335101159, 'f1-score': 0.9877231923755789, 'support': 10182}
 
time = 33.13 secondes

Val loss 0.6810309944031219 accuracy 0.9090105891227722 macro_avg {'precision': 0.9139858929954672, 'recall': 0.9109036378960074, 'f1-score': 0.9107076115090409, 'support': 1132} weighted_avg {'precision': 0.9140579818744584, 'recall': 0.9090106007067138, 'f1-score': 0.9096541664120402, 'support': 1132}
 
----------
Epoch 20/40
time = 824.59 secondes

Train loss 0.06306088293250459 accuracy 0.9881163239479065 macro_avg {'precision': 0.9871770559180423, 'recall': 0.9870661817022851, 'f1-score': 0.9871115766407377, 'support': 10182} weighted_avg {'precision': 0.988111724482609, 'recall': 0.9881162836377921, 'f1-score': 0.9881043287784385, 'support': 10182}
 
time = 25.54 secondes

Val loss 0.6654901082767256 accuracy 0.9187279343605042 macro_avg {'precision': 0.9225022253885852, 'recall': 0.920677766004936, 'f1-score': 0.9199235289990169, 'support': 1132} weighted_avg {'precision': 0.9242391407004176, 'recall': 0.9187279151943463, 'f1-score': 0.9199027903917225, 'support': 1132}
 
----------
Epoch 21/40
time = 749.71 secondes

Train loss 0.05299371498184764 accuracy 0.989589512348175 macro_avg {'precision': 0.9887296085423477, 'recall': 0.988832172725511, 'f1-score': 0.9887677615139981, 'support': 10182} weighted_avg {'precision': 0.9896181715370865, 'recall': 0.9895894716165783, 'f1-score': 0.9895906788751021, 'support': 10182}
 
time = 24.74 secondes

Val loss 0.6802497056125734 accuracy 0.916077733039856 macro_avg {'precision': 0.9187116393897616, 'recall': 0.9179064496880024, 'f1-score': 0.9169774747079489, 'support': 1132} weighted_avg {'precision': 0.9193771327550203, 'recall': 0.916077738515901, 'f1-score': 0.9162875602048626, 'support': 1132}
 
----------
Epoch 22/40
time = 725.42 secondes

Train loss 0.06242271111844973 accuracy 0.9889020323753357 macro_avg {'precision': 0.9881938934300022, 'recall': 0.9881719683330811, 'f1-score': 0.9881682046838465, 'support': 10182} weighted_avg {'precision': 0.9889477766358592, 'recall': 0.9889019838931448, 'f1-score': 0.9889106281827171, 'support': 10182}
 
time = 24.69 secondes

Val loss 0.6513749236457417 accuracy 0.9257950782775879 macro_avg {'precision': 0.93231797412231, 'recall': 0.9238606887022037, 'f1-score': 0.9262688151741167, 'support': 1132} weighted_avg {'precision': 0.9294437721233918, 'recall': 0.9257950530035336, 'f1-score': 0.9258321831296487, 'support': 1132}
 
----------
Epoch 23/40
time = 721.05 secondes

Train loss 0.05685086062583413 accuracy 0.989589512348175 macro_avg {'precision': 0.989066353413764, 'recall': 0.9890039166038262, 'f1-score': 0.9890162405558197, 'support': 10182} weighted_avg {'precision': 0.9896006173984353, 'recall': 0.9895894716165783, 'f1-score': 0.9895767360402349, 'support': 10182}
 
time = 26.32 secondes

Val loss 0.7105753186485126 accuracy 0.9178445339202881 macro_avg {'precision': 0.9168506664443754, 'recall': 0.9210171993563337, 'f1-score': 0.9179118569345952, 'support': 1132} weighted_avg {'precision': 0.9189260577429352, 'recall': 0.9178445229681979, 'f1-score': 0.9173579302317096, 'support': 1132}
 
----------
Epoch 24/40
time = 723.17 secondes

Train loss 0.05538533817794597 accuracy 0.9908662438392639 macro_avg {'precision': 0.9909166988481599, 'recall': 0.9908721002456348, 'f1-score': 0.9908853517095133, 'support': 10182} weighted_avg {'precision': 0.990889139086868, 'recall': 0.9908662345315262, 'f1-score': 0.9908684828046269, 'support': 10182}
 
time = 24.35 secondes

Val loss 0.7588620925948112 accuracy 0.9054770469665527 macro_avg {'precision': 0.9111761909126249, 'recall': 0.9089792477308543, 'f1-score': 0.9061665829913517, 'support': 1132} weighted_avg {'precision': 0.9150934313022671, 'recall': 0.9054770318021201, 'f1-score': 0.9061167602309964, 'support': 1132}
 
----------
Epoch 25/40
time = 721.45 secondes

Train loss 0.04196974732863048 accuracy 0.9925358891487122 macro_avg {'precision': 0.9923421609613369, 'recall': 0.9925736264987691, 'f1-score': 0.9924446181074436, 'support': 10182} weighted_avg {'precision': 0.9925696076571987, 'recall': 0.9925358475741505, 'f1-score': 0.9925393657607952, 'support': 10182}
 
time = 24.44 secondes

Val loss 0.6123379302967601 accuracy 0.9302120208740234 macro_avg {'precision': 0.9344926025439475, 'recall': 0.9304099728605759, 'f1-score': 0.9305748284696176, 'support': 1132} weighted_avg {'precision': 0.9345175032134959, 'recall': 0.9302120141342756, 'f1-score': 0.930474416830259, 'support': 1132}
 
----------
Epoch 26/40
time = 720.91 secondes

Train loss 0.04845086469917081 accuracy 0.9909644722938538 macro_avg {'precision': 0.99088961412954, 'recall': 0.9908579582373319, 'f1-score': 0.9908559577983175, 'support': 10182} weighted_avg {'precision': 0.990990255554527, 'recall': 0.9909644470634453, 'f1-score': 0.9909593388301886, 'support': 10182}
 
time = 22.97 secondes

Val loss 0.6515468313973799 accuracy 0.9187279343605042 macro_avg {'precision': 0.9235763965287459, 'recall': 0.9210695551871797, 'f1-score': 0.9206373320575294, 'support': 1132} weighted_avg {'precision': 0.9231579262767182, 'recall': 0.9187279151943463, 'f1-score': 0.9191803382565835, 'support': 1132}
 
----------
Epoch 27/40
time = 746.80 secondes

Train loss 0.04168468048204432 accuracy 0.9928305149078369 macro_avg {'precision': 0.9925499255606015, 'recall': 0.9925200415637796, 'f1-score': 0.992529032890555, 'support': 10182} weighted_avg {'precision': 0.9928395079606481, 'recall': 0.9928304851699077, 'f1-score': 0.9928292377396122, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.6601591920423769 accuracy 0.9204947352409363 macro_avg {'precision': 0.9224227821208183, 'recall': 0.9214949051296937, 'f1-score': 0.9204901465424513, 'support': 1132} weighted_avg {'precision': 0.9239788503292518, 'recall': 0.9204946996466431, 'f1-score': 0.9206783818597479, 'support': 1132}
 
----------
Epoch 28/40
time = 985.60 secondes

Train loss 0.03838881240947985 accuracy 0.993812620639801 macro_avg {'precision': 0.9935769595247766, 'recall': 0.9935652362701312, 'f1-score': 0.9935642935237002, 'support': 10182} weighted_avg {'precision': 0.9938296889935495, 'recall': 0.9938126104890984, 'f1-score': 0.9938145105010365, 'support': 10182}
 
time = 34.95 secondes

Val loss 0.860883043595966 accuracy 0.8992933034896851 macro_avg {'precision': 0.9024835600071854, 'recall': 0.9033449379728232, 'f1-score': 0.8984828133129075, 'support': 1132} weighted_avg {'precision': 0.9079316562062043, 'recall': 0.8992932862190812, 'f1-score': 0.8990663151226878, 'support': 1132}
 
----------
Epoch 29/40
time = 1038.42 secondes

Train loss 0.04060292713660561 accuracy 0.993714451789856 macro_avg {'precision': 0.9937117463797953, 'recall': 0.9938319781744969, 'f1-score': 0.9937672216812059, 'support': 10182} weighted_avg {'precision': 0.9937201588059923, 'recall': 0.9937143979571793, 'f1-score': 0.9937126857096119, 'support': 10182}
 
time = 27.09 secondes

Val loss 0.6890976755303584 accuracy 0.9213780760765076 macro_avg {'precision': 0.922281037142921, 'recall': 0.9222590680862274, 'f1-score': 0.9203910822765398, 'support': 1132} weighted_avg {'precision': 0.9267961509911602, 'recall': 0.9213780918727915, 'f1-score': 0.922214289591987, 'support': 1132}
 
----------
Epoch 30/40
time = 858.29 secondes

Train loss 0.031173711125298934 accuracy 0.994892954826355 macro_avg {'precision': 0.994535827873061, 'recall': 0.9947610278644549, 'f1-score': 0.994641772197798, 'support': 10182} weighted_avg {'precision': 0.9949075764601065, 'recall': 0.9948929483402082, 'f1-score': 0.9948949755322696, 'support': 10182}
 
time = 34.05 secondes

Val loss 0.5181108321646117 accuracy 0.9381625652313232 macro_avg {'precision': 0.9397061516426184, 'recall': 0.9385536350939858, 'f1-score': 0.9385425372008287, 'support': 1132} weighted_avg {'precision': 0.9395799989536734, 'recall': 0.9381625441696113, 'f1-score': 0.9383633479438508, 'support': 1132}
 
----------
Epoch 31/40
time = 941.53 secondes

Train loss 0.030867749507702037 accuracy 0.993714451789856 macro_avg {'precision': 0.9937514821204327, 'recall': 0.9938023578428083, 'f1-score': 0.9937638990889566, 'support': 10182} weighted_avg {'precision': 0.9937537063880632, 'recall': 0.9937143979571793, 'f1-score': 0.993721086007801, 'support': 10182}
 
time = 33.27 secondes

Val loss 0.5612273408090991 accuracy 0.9337455630302429 macro_avg {'precision': 0.9359974509163143, 'recall': 0.93484449411371, 'f1-score': 0.9345026692250284, 'support': 1132} weighted_avg {'precision': 0.935810554555756, 'recall': 0.9337455830388692, 'f1-score': 0.9338709052223133, 'support': 1132}
 
----------
Epoch 32/40
time = 899.15 secondes

Train loss 0.02310575361171605 accuracy 0.9963661432266235 macro_avg {'precision': 0.9963257524786006, 'recall': 0.9964232535783323, 'f1-score': 0.9963725519896849, 'support': 10182} weighted_avg {'precision': 0.9963712110158622, 'recall': 0.9963661363189943, 'f1-score': 0.9963668141470821, 'support': 10182}
 
time = 27.42 secondes

Val loss 0.5719641888216769 accuracy 0.9231448769569397 macro_avg {'precision': 0.9232094713707418, 'recall': 0.9252079619270377, 'f1-score': 0.9229192758373415, 'support': 1132} weighted_avg {'precision': 0.9260076461693314, 'recall': 0.9231448763250883, 'f1-score': 0.9232811127704171, 'support': 1132}
 
----------
Epoch 33/40
time = 802.84 secondes

Train loss 0.02288988167023907 accuracy 0.9960715174674988 macro_avg {'precision': 0.9961711895226604, 'recall': 0.9960872234544421, 'f1-score': 0.9961276667985807, 'support': 10182} weighted_avg {'precision': 0.9960728919332007, 'recall': 0.9960714987232371, 'f1-score': 0.9960707790937092, 'support': 10182}
 
time = 25.43 secondes

Val loss 0.570196613516549 accuracy 0.9284452199935913 macro_avg {'precision': 0.930398041129781, 'recall': 0.9314545608623694, 'f1-score': 0.9302127048762674, 'support': 1132} weighted_avg {'precision': 0.9303285099956946, 'recall': 0.9284452296819788, 'f1-score': 0.9286587977714396, 'support': 1132}
 
----------
Epoch 34/40
time = 729.81 secondes

Train loss 0.022912930652256226 accuracy 0.9958751201629639 macro_avg {'precision': 0.99586094864021, 'recall': 0.996017571352667, 'f1-score': 0.9959375842810543, 'support': 10182} weighted_avg {'precision': 0.995876237591081, 'recall': 0.995875073659399, 'f1-score': 0.9958741272109735, 'support': 10182}
 
time = 25.02 secondes

Val loss 0.6081943999041113 accuracy 0.9293286204338074 macro_avg {'precision': 0.9308768834788852, 'recall': 0.9316163994078817, 'f1-score': 0.9303342030632656, 'support': 1132} weighted_avg {'precision': 0.931874792968735, 'recall': 0.9293286219081273, 'f1-score': 0.929633049931186, 'support': 1132}
 
----------
Epoch 35/40
time = 731.54 secondes

Train loss 0.012990592034385177 accuracy 0.9976429343223572 macro_avg {'precision': 0.9976388217559149, 'recall': 0.9977231060685143, 'f1-score': 0.9976776629397343, 'support': 10182} weighted_avg {'precision': 0.9976510756655848, 'recall': 0.9976428992339422, 'f1-score': 0.9976436215766573, 'support': 10182}
 
time = 25.28 secondes

Val loss 0.5714157906219094 accuracy 0.9390459656715393 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}
 
----------
Epoch 36/40
time = 729.01 secondes

Train loss 0.01833871189036482 accuracy 0.9969554543495178 macro_avg {'precision': 0.996884086841674, 'recall': 0.9969676468006174, 'f1-score': 0.996919469712536, 'support': 10182} weighted_avg {'precision': 0.9969736934344191, 'recall': 0.9969554115105087, 'f1-score': 0.9969581469381175, 'support': 10182}
 
time = 25.98 secondes

Val loss 0.5994078302624267 accuracy 0.9293286204338074 macro_avg {'precision': 0.9299352449609296, 'recall': 0.9315913919887848, 'f1-score': 0.929768704288418, 'support': 1132} weighted_avg {'precision': 0.932670118027193, 'recall': 0.9293286219081273, 'f1-score': 0.9299518385785527, 'support': 1132}
 
----------
Epoch 37/40
time = 729.77 secondes

Train loss 0.011112356264953743 accuracy 0.9982321858406067 macro_avg {'precision': 0.9983171733400937, 'recall': 0.9982307827420612, 'f1-score': 0.9982710723288559, 'support': 10182} weighted_avg {'precision': 0.9982399977390333, 'recall': 0.9982321744254566, 'f1-score': 0.9982331126085662, 'support': 10182}
 
time = 25.27 secondes

Val loss 0.5924408991639109 accuracy 0.9310954213142395 macro_avg {'precision': 0.9338731707688073, 'recall': 0.9336734436606633, 'f1-score': 0.9325406862964474, 'support': 1132} weighted_avg {'precision': 0.935230106640389, 'recall': 0.931095406360424, 'f1-score': 0.9318909013144914, 'support': 1132}
 
----------
Epoch 38/40
time = 728.57 secondes

Train loss 0.007094374627405235 accuracy 0.9985268115997314 macro_avg {'precision': 0.9983785635338565, 'recall': 0.9985166071708447, 'f1-score': 0.9984445929154344, 'support': 10182} weighted_avg {'precision': 0.9985332444686208, 'recall': 0.998526812021214, 'f1-score': 0.9985276773775542, 'support': 10182}
 
time = 25.39 secondes

Val loss 0.6083182109004168 accuracy 0.9284452199935913 macro_avg {'precision': 0.9321705996842805, 'recall': 0.9312106288458313, 'f1-score': 0.9301701070542325, 'support': 1132} weighted_avg {'precision': 0.9331578994457744, 'recall': 0.9284452296819788, 'f1-score': 0.9291780103692845, 'support': 1132}
 
----------
Epoch 39/40
time = 834.23 secondes

Train loss 0.004099554753626863 accuracy 0.9990178942680359 macro_avg {'precision': 0.9990445153619305, 'recall': 0.9990465124100428, 'f1-score': 0.9990450770469763, 'support': 10182} weighted_avg {'precision': 0.9990189772040283, 'recall': 0.9990178746808093, 'f1-score': 0.9990179675363912, 'support': 10182}
 
time = 34.52 secondes

Val loss 0.6324473496378501 accuracy 0.9337455630302429 macro_avg {'precision': 0.9389891292501433, 'recall': 0.9361597063520225, 'f1-score': 0.9362935689683122, 'support': 1132} weighted_avg {'precision': 0.938128479283786, 'recall': 0.9337455830388692, 'f1-score': 0.9345301109424841, 'support': 1132}
 
----------
Epoch 40/40
time = 973.10 secondes

Train loss 0.0029508336193605914 accuracy 0.9994107484817505 macro_avg {'precision': 0.9993654156660551, 'recall': 0.9993890841637985, 'f1-score': 0.9993765447608427, 'support': 10182} weighted_avg {'precision': 0.9994121086721734, 'recall': 0.9994107248084856, 'f1-score': 0.9994107345412815, 'support': 10182}
 
time = 31.97 secondes

Val loss 0.604129914752852 accuracy 0.9337455630302429 macro_avg {'precision': 0.9364403679707334, 'recall': 0.935185174255696, 'f1-score': 0.9349140513727106, 'support': 1132} weighted_avg {'precision': 0.9359944263180545, 'recall': 0.9337455830388692, 'f1-score': 0.9339703121737567, 'support': 1132}
 
----------
best_accuracy 0.9390459656715393 best_epoch 35 macro_avg {'precision': 0.9415367020556641, 'recall': 0.9414401310961995, 'f1-score': 0.9403980499548823, 'support': 1132} weighted_avg {'precision': 0.942874986871251, 'recall': 0.9390459363957597, 'f1-score': 0.9398004265984141, 'support': 1132}

average train time 841.2686648905277

average val time 29.002124965190887
 
time = 199.06 secondes

test_accuracy 0.8559479117393494 macro_avg {'precision': 0.853801041312529, 'recall': 0.8495474935062125, 'f1-score': 0.8497281728064007, 'support': 7532} weighted_avg {'precision': 0.8607974784860157, 'recall': 0.8559479553903345, 'f1-score': 0.8564545903716746, 'support': 7532}

----------
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
There are 3 GPU(s) available.
We will use the GPU: NVIDIA A100 80GB PCIe
##########
20newsgroups_Longformer_2048_256_4
----------
Epoch 1/40
time = 1224.70 secondes

Train loss 1.173128953370232 accuracy 0.6593989729881287 macro_avg {'precision': 0.662829769087903, 'recall': 0.6455535306271434, 'f1-score': 0.6410237550364425, 'support': 10182} weighted_avg {'precision': 0.6703989207273187, 'recall': 0.6593989393046553, 'f1-score': 0.6534405257138537, 'support': 10182}
 
time = 40.74 secondes

Val loss 0.589547368212485 accuracy 0.8242049813270569 macro_avg {'precision': 0.8513547433588059, 'recall': 0.8217635358966021, 'f1-score': 0.8070310135342676, 'support': 1132} weighted_avg {'precision': 0.8448801925737545, 'recall': 0.8242049469964664, 'f1-score': 0.8120437700387597, 'support': 1132}
 
----------
Epoch 2/40
time = 1292.61 secondes

Train loss 0.433301338121833 accuracy 0.8733058571815491 macro_avg {'precision': 0.8652638294358969, 'recall': 0.8641945615311402, 'f1-score': 0.8636283597576035, 'support': 10182} weighted_avg {'precision': 0.8718183863417169, 'recall': 0.873305833824396, 'f1-score': 0.8717080931309271, 'support': 10182}
 
time = 37.63 secondes

Val loss 0.5033257722224987 accuracy 0.8648409843444824 macro_avg {'precision': 0.8691521618456436, 'recall': 0.8624626086280799, 'f1-score': 0.8593810526738238, 'support': 1132} weighted_avg {'precision': 0.8751966966445278, 'recall': 0.8648409893992933, 'f1-score': 0.8635484994452928, 'support': 1132}
 
----------
Epoch 3/40
time = 1168.28 secondes

Train loss 0.26697434020467 accuracy 0.9230996370315552 macro_avg {'precision': 0.9188650171477862, 'recall': 0.9178367231555937, 'f1-score': 0.9181392721051699, 'support': 10182} weighted_avg {'precision': 0.9230208678322049, 'recall': 0.923099587507366, 'f1-score': 0.9228604440474881, 'support': 10182}
 
time = 31.54 secondes

Val loss 0.4773428943139357 accuracy 0.8878092169761658 macro_avg {'precision': 0.8893159478547924, 'recall': 0.8901384851693358, 'f1-score': 0.8843182079086016, 'support': 1132} weighted_avg {'precision': 0.8957682804469341, 'recall': 0.8878091872791519, 'f1-score': 0.8856897656047938, 'support': 1132}
 
----------
Epoch 4/40
time = 1113.69 secondes

Train loss 0.1947178938616143 accuracy 0.9453938603401184 macro_avg {'precision': 0.9427466024270726, 'recall': 0.9425265062203646, 'f1-score': 0.9425725025417689, 'support': 10182} weighted_avg {'precision': 0.945480084806776, 'recall': 0.9453938322529954, 'f1-score': 0.9453761839551973, 'support': 10182}
 
time = 30.97 secondes

Val loss 0.4491022658881954 accuracy 0.8948763608932495 macro_avg {'precision': 0.8996512456924854, 'recall': 0.8927313125982309, 'f1-score': 0.8921173758259456, 'support': 1132} weighted_avg {'precision': 0.9011924365315521, 'recall': 0.8948763250883393, 'f1-score': 0.893673234573963, 'support': 1132}
 
----------
Epoch 5/40
time = 1115.33 secondes

Train loss 0.1558833939708284 accuracy 0.9604203701019287 macro_avg {'precision': 0.9585975356538083, 'recall': 0.9587788823766434, 'f1-score': 0.9586219752270683, 'support': 10182} weighted_avg {'precision': 0.960574103478398, 'recall': 0.9604203496366136, 'f1-score': 0.9604363157078126, 'support': 10182}
 
time = 30.81 secondes

Val loss 0.4840479651088892 accuracy 0.9045936465263367 macro_avg {'precision': 0.9110295516794489, 'recall': 0.9027701981303082, 'f1-score': 0.9039572929440777, 'support': 1132} weighted_avg {'precision': 0.9100952857362941, 'recall': 0.9045936395759717, 'f1-score': 0.9046826167520323, 'support': 1132}
 
----------
Epoch 6/40
time = 1112.66 secondes

Train loss 0.13205229320740283 accuracy 0.9665095806121826 macro_avg {'precision': 0.9654723418428794, 'recall': 0.964841858873853, 'f1-score': 0.9651167315236387, 'support': 10182} weighted_avg {'precision': 0.966505152875396, 'recall': 0.9665095266155962, 'f1-score': 0.9664729666915374, 'support': 10182}
 
time = 29.48 secondes

Val loss 0.5088391571230269 accuracy 0.9045936465263367 macro_avg {'precision': 0.9130306601038022, 'recall': 0.901036550177752, 'f1-score': 0.9037126908571272, 'support': 1132} weighted_avg {'precision': 0.9090787836056673, 'recall': 0.9045936395759717, 'f1-score': 0.9036050004244318, 'support': 1132}
 
----------
Epoch 7/40
time = 1180.33 secondes

Train loss 0.1275869197653697 accuracy 0.968375563621521 macro_avg {'precision': 0.9671232772670066, 'recall': 0.9670273626391609, 'f1-score': 0.9670436412078562, 'support': 10182} weighted_avg {'precision': 0.968415866768847, 'recall': 0.9683755647220585, 'f1-score': 0.9683656847802719, 'support': 10182}
 
time = 41.00 secondes

Val loss 0.5309758744764955 accuracy 0.9116607904434204 macro_avg {'precision': 0.9187587319013115, 'recall': 0.9118835917962625, 'f1-score': 0.9130421130537897, 'support': 1132} weighted_avg {'precision': 0.917786147161771, 'recall': 0.911660777385159, 'f1-score': 0.9122863957441552, 'support': 1132}
 
----------
Epoch 8/40
time = 1282.49 secondes

Train loss 0.12002114570318403 accuracy 0.9730898141860962 macro_avg {'precision': 0.9723695992863715, 'recall': 0.9725255250033399, 'f1-score': 0.9724196049338719, 'support': 10182} weighted_avg {'precision': 0.9731267731823616, 'recall': 0.973089766254174, 'f1-score': 0.973079996811068, 'support': 10182}
 
time = 33.48 secondes

Val loss 0.610222482664796 accuracy 0.9010601043701172 macro_avg {'precision': 0.9083310837239571, 'recall': 0.9017994046940101, 'f1-score': 0.902471061050858, 'support': 1132} weighted_avg {'precision': 0.9061301049524046, 'recall': 0.901060070671378, 'f1-score': 0.9010895163950153, 'support': 1132}
 
----------
Epoch 9/40
time = 1246.58 secondes

Train loss 0.11085762805689209 accuracy 0.9742683172225952 macro_avg {'precision': 0.973686279384073, 'recall': 0.9738118937993816, 'f1-score': 0.9736728343620366, 'support': 10182} weighted_avg {'precision': 0.9744314222238106, 'recall': 0.9742683166372029, 'f1-score': 0.974272621149981, 'support': 10182}
 
time = 39.99 secondes

Val loss 0.7214796951718622 accuracy 0.8895759582519531 macro_avg {'precision': 0.8994128375388721, 'recall': 0.8895234200606467, 'f1-score': 0.8872931770524671, 'support': 1132} weighted_avg {'precision': 0.8976454810010577, 'recall': 0.8895759717314488, 'f1-score': 0.8870161223513768, 'support': 1132}
 
----------
Epoch 10/40
time = 1275.10 secondes

Train loss 0.10936332721249646 accuracy 0.9776075482368469 macro_avg {'precision': 0.9767742980562198, 'recall': 0.9769731977042383, 'f1-score': 0.9768160730254177, 'support': 10182} weighted_avg {'precision': 0.9777560649362148, 'recall': 0.9776075427224514, 'f1-score': 0.9776304879429484, 'support': 10182}
 
time = 32.49 secondes

Val loss 0.7261400397065174 accuracy 0.8922261595726013 macro_avg {'precision': 0.9029049154363806, 'recall': 0.8845884143093088, 'f1-score': 0.8869576307269895, 'support': 1132} weighted_avg {'precision': 0.8992483930448251, 'recall': 0.892226148409894, 'f1-score': 0.8902926862224189, 'support': 1132}
 
----------
Epoch 11/40
time = 1173.23 secondes

Train loss 0.1113884581535153 accuracy 0.9768218994140625 macro_avg {'precision': 0.9764015273357499, 'recall': 0.9762835552114361, 'f1-score': 0.9763053778161573, 'support': 10182} weighted_avg {'precision': 0.976946745757334, 'recall': 0.9768218424670988, 'f1-score': 0.9768490430920068, 'support': 10182}
 
time = 29.82 secondes

Val loss 0.7375211480754497 accuracy 0.8913427591323853 macro_avg {'precision': 0.9034405375273469, 'recall': 0.8937246809433292, 'f1-score': 0.894844329996282, 'support': 1132} weighted_avg {'precision': 0.900602132890465, 'recall': 0.8913427561837456, 'f1-score': 0.8919937340788233, 'support': 1132}
 
----------
Epoch 12/40
time = 1108.55 secondes

Train loss 0.08710213793374764 accuracy 0.9813396334648132 macro_avg {'precision': 0.9806174222910761, 'recall': 0.9803114936494837, 'f1-score': 0.9804177817813814, 'support': 10182} weighted_avg {'precision': 0.9813525144951474, 'recall': 0.9813396189353761, 'f1-score': 0.9812990831162066, 'support': 10182}
 
time = 29.72 secondes

Val loss 0.6837542199695312 accuracy 0.9054770469665527 macro_avg {'precision': 0.909983083412181, 'recall': 0.9059370038583193, 'f1-score': 0.9062647942244851, 'support': 1132} weighted_avg {'precision': 0.9097723472290224, 'recall': 0.9054770318021201, 'f1-score': 0.9061650393385801, 'support': 1132}
 
----------
Epoch 13/40
time = 1090.41 secondes

Train loss 0.09975643206413436 accuracy 0.9794735908508301 macro_avg {'precision': 0.9785171435016073, 'recall': 0.9787878927846843, 'f1-score': 0.9786211459867573, 'support': 10182} weighted_avg {'precision': 0.9795479839719737, 'recall': 0.9794735808289138, 'f1-score': 0.9794798817304826, 'support': 10182}
 
time = 29.36 secondes

Val loss 0.7395239552113221 accuracy 0.9028268456459045 macro_avg {'precision': 0.9065318876715376, 'recall': 0.9018933300113309, 'f1-score': 0.9010727985620935, 'support': 1132} weighted_avg {'precision': 0.9090351744299293, 'recall': 0.9028268551236749, 'f1-score': 0.9032605624516509, 'support': 1132}
 
----------
Epoch 14/40
time = 1072.60 secondes

Train loss 0.1041517634550082 accuracy 0.9807503819465637 macro_avg {'precision': 0.9803118434347358, 'recall': 0.9801581158287969, 'f1-score': 0.9802194703977467, 'support': 10182} weighted_avg {'precision': 0.9807725229012776, 'recall': 0.9807503437438617, 'f1-score': 0.9807480826984695, 'support': 10182}
 
time = 29.57 secondes

Val loss 0.6951771441406019 accuracy 0.9010601043701172 macro_avg {'precision': 0.9098368210121406, 'recall': 0.9074688763014256, 'f1-score': 0.9055443756944952, 'support': 1132} weighted_avg {'precision': 0.912072516182919, 'recall': 0.901060070671378, 'f1-score': 0.9034544070036912, 'support': 1132}
 
----------
Epoch 15/40
time = 1134.67 secondes

Train loss 0.09907813972971798 accuracy 0.9801610708236694 macro_avg {'precision': 0.9803470345623824, 'recall': 0.9801084447512854, 'f1-score': 0.9801644759369725, 'support': 10182} weighted_avg {'precision': 0.9802926297436175, 'recall': 0.9801610685523473, 'f1-score': 0.9801619759530473, 'support': 10182}
 
time = 39.75 secondes

Val loss 0.5585858548846273 accuracy 0.9116607904434204 macro_avg {'precision': 0.9143666532188124, 'recall': 0.9137448242853597, 'f1-score': 0.9113943401124687, 'support': 1132} weighted_avg {'precision': 0.9161052805227066, 'recall': 0.911660777385159, 'f1-score': 0.9111157622126106, 'support': 1132}
 
----------
Epoch 16/40
time = 1285.49 secondes

Train loss 0.07078671759552596 accuracy 0.9845806360244751 macro_avg {'precision': 0.9846564197876992, 'recall': 0.9847336787844652, 'f1-score': 0.9846853312421416, 'support': 10182} weighted_avg {'precision': 0.9845912730323304, 'recall': 0.9845806324887055, 'f1-score': 0.9845762128402021, 'support': 10182}
 
time = 35.27 secondes

Val loss 0.6790391367095241 accuracy 0.9054770469665527 macro_avg {'precision': 0.9116774105898218, 'recall': 0.9044757834425546, 'f1-score': 0.9051812447696526, 'support': 1132} weighted_avg {'precision': 0.9105562910558808, 'recall': 0.9054770318021201, 'f1-score': 0.9052724476469872, 'support': 1132}
 
----------
Epoch 17/40
time = 1149.65 secondes

Train loss 0.08262343541803543 accuracy 0.98448246717453 macro_avg {'precision': 0.9838758636884674, 'recall': 0.983824785192455, 'f1-score': 0.9838377657089625, 'support': 10182} weighted_avg {'precision': 0.9845032314147716, 'recall': 0.9844824199567865, 'f1-score': 0.9844806506245479, 'support': 10182}
 
time = 28.90 secondes

Val loss 0.6675969711099062 accuracy 0.9098939895629883 macro_avg {'precision': 0.9175170331290108, 'recall': 0.9137003281628557, 'f1-score': 0.9130973781929667, 'support': 1132} weighted_avg {'precision': 0.9153607333580289, 'recall': 0.9098939929328622, 'f1-score': 0.9101382769290672, 'support': 1132}
 
----------
Epoch 18/40
time = 1237.76 secondes

Train loss 0.07865465861195815 accuracy 0.9847770929336548 macro_avg {'precision': 0.9842677434524223, 'recall': 0.9842331433022877, 'f1-score': 0.9842315516973337, 'support': 10182} weighted_avg {'precision': 0.9847936010201597, 'recall': 0.9847770575525437, 'f1-score': 0.9847667130802006, 'support': 10182}
 
time = 37.34 secondes

Val loss 0.6060551764832114 accuracy 0.916961133480072 macro_avg {'precision': 0.9263419664845014, 'recall': 0.9184225660001063, 'f1-score': 0.9209961047367257, 'support': 1132} weighted_avg {'precision': 0.9223100819699891, 'recall': 0.9169611307420494, 'f1-score': 0.9181423242742753, 'support': 1132}
 
----------
Epoch 19/40
time = 1209.37 secondes

Train loss 0.0673055721901956 accuracy 0.9873306155204773 macro_avg {'precision': 0.9871487143408387, 'recall': 0.9872925660679774, 'f1-score': 0.9872059543505107, 'support': 10182} weighted_avg {'precision': 0.9873643240524663, 'recall': 0.9873305833824396, 'f1-score': 0.9873326691980662, 'support': 10182}
 
time = 27.38 secondes

Val loss 0.6902313331825803 accuracy 0.9098939895629883 macro_avg {'precision': 0.916784055501925, 'recall': 0.9131119592189154, 'f1-score': 0.9135067568208598, 'support': 1132} weighted_avg {'precision': 0.9142045095375844, 'recall': 0.9098939929328622, 'f1-score': 0.9105594024373984, 'support': 1132}
 
----------
Epoch 20/40
time = 1108.04 secondes

Train loss 0.05156581461380206 accuracy 0.9898841381072998 macro_avg {'precision': 0.9898651280787847, 'recall': 0.9898505334572463, 'f1-score': 0.9898508146356513, 'support': 10182} weighted_avg {'precision': 0.989893612300699, 'recall': 0.9898841092123355, 'f1-score': 0.9898816337155468, 'support': 10182}
 
time = 28.30 secondes

Val loss 0.7284231496959249 accuracy 0.9072438478469849 macro_avg {'precision': 0.916677708864943, 'recall': 0.9065174217566927, 'f1-score': 0.9086229362405996, 'support': 1132} weighted_avg {'precision': 0.9147920204142058, 'recall': 0.907243816254417, 'f1-score': 0.9077452447160728, 'support': 1132}
 
----------
Epoch 21/40
time = 1089.44 secondes

Train loss 0.05262981496453508 accuracy 0.9903752207756042 macro_avg {'precision': 0.9897860448009699, 'recall': 0.9898247601087489, 'f1-score': 0.9897978347815505, 'support': 10182} weighted_avg {'precision': 0.9903830221973918, 'recall': 0.9903751718719308, 'f1-score': 0.9903715833742723, 'support': 10182}
 
time = 27.86 secondes

Val loss 0.5405368513932278 accuracy 0.9213780760765076 macro_avg {'precision': 0.922967290604376, 'recall': 0.9231754422651266, 'f1-score': 0.9223770243755471, 'support': 1132} weighted_avg {'precision': 0.9234580836900056, 'recall': 0.9213780918727915, 'f1-score': 0.9217048420196515, 'support': 1132}
 
----------
Epoch 22/40
time = 1085.43 secondes

Train loss 0.07800975690941762 accuracy 0.9861520528793335 macro_avg {'precision': 0.985552763132928, 'recall': 0.9847686519366258, 'f1-score': 0.9851033962781639, 'support': 10182} weighted_avg {'precision': 0.9862185499783711, 'recall': 0.9861520329994107, 'f1-score': 0.98613745173871, 'support': 10182}
 
time = 28.15 secondes

Val loss 0.7695977911254732 accuracy 0.9010601043701172 macro_avg {'precision': 0.9059755189411064, 'recall': 0.9005632335090912, 'f1-score': 0.9007980153053141, 'support': 1132} weighted_avg {'precision': 0.9056162411016176, 'recall': 0.901060070671378, 'f1-score': 0.9009348145572135, 'support': 1132}
 
----------
Epoch 23/40
time = 1079.60 secondes

Train loss 0.05152084587404902 accuracy 0.9898841381072998 macro_avg {'precision': 0.9896574398550466, 'recall': 0.9895832316152815, 'f1-score': 0.9896138818934137, 'support': 10182} weighted_avg {'precision': 0.989898269358908, 'recall': 0.9898841092123355, 'f1-score': 0.9898848755434715, 'support': 10182}
 
time = 30.82 secondes

Val loss 0.7936162035389636 accuracy 0.9028268456459045 macro_avg {'precision': 0.9131990828246564, 'recall': 0.9056719375921614, 'f1-score': 0.9071294265184106, 'support': 1132} weighted_avg {'precision': 0.9096255221803872, 'recall': 0.9028268551236749, 'f1-score': 0.9037552313881405, 'support': 1132}
 
----------
Epoch 24/40
time = 1114.59 secondes

Train loss 0.04399941098220479 accuracy 0.9920448064804077 macro_avg {'precision': 0.9919961057368154, 'recall': 0.9920428267227223, 'f1-score': 0.9920009652372783, 'support': 10182} weighted_avg {'precision': 0.9920978220091236, 'recall': 0.9920447849145551, 'f1-score': 0.9920531696989157, 'support': 10182}
 
time = 40.98 secondes

Val loss 0.8122427599947502 accuracy 0.9028268456459045 macro_avg {'precision': 0.9121225761037076, 'recall': 0.9058953550979032, 'f1-score': 0.905512504831522, 'support': 1132} weighted_avg {'precision': 0.9099222693408211, 'recall': 0.9028268551236749, 'f1-score': 0.9026512794229142, 'support': 1132}
 
----------
Epoch 25/40
time = 1348.57 secondes

Train loss 0.05157633342244607 accuracy 0.9911609292030334 macro_avg {'precision': 0.991235079616599, 'recall': 0.9910128289878702, 'f1-score': 0.9911122496694889, 'support': 10182} weighted_avg {'precision': 0.9911831736760645, 'recall': 0.9911608721272834, 'f1-score': 0.9911614428459055, 'support': 10182}
 
time = 30.44 secondes

Val loss 0.7859033855928713 accuracy 0.9090105891227722 macro_avg {'precision': 0.9183370192209784, 'recall': 0.9097627734904264, 'f1-score': 0.9118822614216973, 'support': 1132} weighted_avg {'precision': 0.913194382116697, 'recall': 0.9090106007067138, 'f1-score': 0.9089501762847121, 'support': 1132}
 
----------
Epoch 26/40
time = 1185.48 secondes

Train loss 0.03815147458516545 accuracy 0.9931251406669617 macro_avg {'precision': 0.9931207056707281, 'recall': 0.9929949659658257, 'f1-score': 0.9930501461758221, 'support': 10182} weighted_avg {'precision': 0.9931428057080325, 'recall': 0.9931251227656649, 'f1-score': 0.9931262692119824, 'support': 10182}
 
time = 40.54 secondes

Val loss 0.7952744145332475 accuracy 0.9037102460861206 macro_avg {'precision': 0.9088168321864577, 'recall': 0.9068121564382429, 'f1-score': 0.9052162969949664, 'support': 1132} weighted_avg {'precision': 0.9104586189376747, 'recall': 0.9037102473498233, 'f1-score': 0.9044359095808839, 'support': 1132}
 
----------
Epoch 27/40
time = 1254.75 secondes

Train loss 0.04687636622501382 accuracy 0.9919465780258179 macro_avg {'precision': 0.9913783057134566, 'recall': 0.9913846991272063, 'f1-score': 0.9913749594686664, 'support': 10182} weighted_avg {'precision': 0.9919659922809686, 'recall': 0.9919465723826361, 'f1-score': 0.9919497431243338, 'support': 10182}
 
time = 40.42 secondes

Val loss 0.7230789358727634 accuracy 0.916961133480072 macro_avg {'precision': 0.9204045652749689, 'recall': 0.9212877533354302, 'f1-score': 0.9197161326455235, 'support': 1132} weighted_avg {'precision': 0.9189325883975328, 'recall': 0.9169611307420494, 'f1-score': 0.9167505934278293, 'support': 1132}
 
----------
Epoch 28/40
time = 1124.97 secondes

Train loss 0.0346876363987369 accuracy 0.993812620639801 macro_avg {'precision': 0.993785827075021, 'recall': 0.9936224631453333, 'f1-score': 0.9936974384926796, 'support': 10182} weighted_avg {'precision': 0.9938255842704584, 'recall': 0.9938126104890984, 'f1-score': 0.9938126507339887, 'support': 10182}
 
time = 31.13 secondes

Val loss 0.7594218039683281 accuracy 0.916077733039856 macro_avg {'precision': 0.9247947601594305, 'recall': 0.9130417711642312, 'f1-score': 0.9149844122186469, 'support': 1132} weighted_avg {'precision': 0.9211981005629416, 'recall': 0.916077738515901, 'f1-score': 0.9152967708359533, 'support': 1132}
 
----------
Epoch 29/40
time = 1081.95 secondes

Train loss 0.029682740100603552 accuracy 0.9943037033081055 macro_avg {'precision': 0.994152605246059, 'recall': 0.9941700468110615, 'f1-score': 0.9941577637436951, 'support': 10182} weighted_avg {'precision': 0.9943066431011253, 'recall': 0.9943036731486937, 'f1-score': 0.9943015746604917, 'support': 10182}
 
time = 30.19 secondes

Val loss 0.6428052852110417 accuracy 0.9187279343605042 macro_avg {'precision': 0.923623845854396, 'recall': 0.9232728062023368, 'f1-score': 0.9216879608226309, 'support': 1132} weighted_avg {'precision': 0.924515784885518, 'recall': 0.9187279151943463, 'f1-score': 0.9198638392432227, 'support': 1132}
 
----------
Epoch 30/40
time = 1074.27 secondes

Train loss 0.04244267715503399 accuracy 0.9935179948806763 macro_avg {'precision': 0.9934845743208314, 'recall': 0.9934108940008418, 'f1-score': 0.993441166493812, 'support': 10182} weighted_avg {'precision': 0.9935294528454889, 'recall': 0.9935179728933412, 'f1-score': 0.99351754358324, 'support': 10182}
 
time = 30.73 secondes

Val loss 0.780875301633092 accuracy 0.9134275913238525 macro_avg {'precision': 0.9190056543572901, 'recall': 0.915465232910684, 'f1-score': 0.9143606560772973, 'support': 1132} weighted_avg {'precision': 0.9205614363350298, 'recall': 0.9134275618374559, 'f1-score': 0.9145049263741012, 'support': 1132}
 
----------
Epoch 31/40
